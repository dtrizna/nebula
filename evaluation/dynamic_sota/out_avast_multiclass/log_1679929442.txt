2023-03-27 17:15:39,230 WARNING  [!] Initialized tokenizer without pre-trained model.
	You need to train tokenizer with .train() or specify 'model_path=' during initialization!
2023-03-27 17:15:39,230 WARNING  [*] Initializing tokenizer training...
2023-03-27 17:15:39,230 WARNING  [*] Data preparation for SentencePiece tokenizer...
2023-03-27 17:15:46,430 WARNING  [*] Saving to disk...
2023-03-27 17:15:46,901 WARNING  [!] Training tokenizer with command: --input=out_avast_multiclass_1679929442\nebula_bpe_speakeasy_vocab_50000_seqlen_512\tokenizer_50000_trainset_1679930146.txt --model_prefix=out_avast_multiclass_1679929442\nebula_bpe_speakeasy_vocab_50000_seqlen_512\tokenizer_50000 --vocab_size=50000 --model_type=bpe --split_by_number=False --max_sentence_length=4192 --max_sentencepiece_length=64
2023-03-27 17:16:22,477 WARNING  [!] Loaded vocab with size 50001 from out_avast_multiclass_1679929442\nebula_bpe_speakeasy_vocab_50000_seqlen_512\tokenizer_50000.vocab
2023-03-27 17:16:22,631 WARNING  [*] Encoding and padding...
2023-03-27 17:17:31,640 WARNING  [!] Saved X as out_avast_multiclass_1679929442\nebula_bpe_speakeasy_vocab_50000_seqlen_512\x_train_full.npy
2023-03-27 17:17:31,655 WARNING  [!] Saved Y as out_avast_multiclass_1679929442\nebula_bpe_speakeasy_vocab_50000_seqlen_512\y_train_full.npy
2023-03-27 17:17:31,776 WARNING  [!] Successfully loaded pre-trained tokenizer model!
2023-03-27 17:17:31,821 WARNING  [!] Loaded vocab with size 50001 from out_avast_multiclass_1679929442\nebula_bpe_speakeasy_vocab_50000_seqlen_512\tokenizer_50000_vocab.json
2023-03-27 17:17:31,821 WARNING  [*] Encoding and padding...
2023-03-27 17:17:48,880 WARNING  [!] Saved X as out_avast_multiclass_1679929442\nebula_bpe_speakeasy_vocab_50000_seqlen_512\x_test_full.npy
2023-03-27 17:17:48,891 WARNING  [!] Saved Y as out_avast_multiclass_1679929442\nebula_bpe_speakeasy_vocab_50000_seqlen_512\y_test_full.npy
2023-03-27 17:17:48,929 WARNING  [*] Initializing tokenizer training...
2023-03-27 17:17:56,837 WARNING Dumped vocab to out_avast_multiclass_1679929442\nebula_wht_speakeasy_vocab_50000_seqlen_512\tokenizer_50000_vocab.json
2023-03-27 17:17:56,947 WARNING Dumped vocab counter to out_avast_multiclass_1679929442\nebula_wht_speakeasy_vocab_50000_seqlen_512\tokenizer_50000_counter.json
2023-03-27 17:17:56,947 WARNING  [*] Encoding and padding...
2023-03-27 17:18:07,224 WARNING  [!] Saved X as out_avast_multiclass_1679929442\nebula_wht_speakeasy_vocab_50000_seqlen_512\x_train_full.npy
2023-03-27 17:18:07,235 WARNING  [!] Saved Y as out_avast_multiclass_1679929442\nebula_wht_speakeasy_vocab_50000_seqlen_512\y_train_full.npy
2023-03-27 17:18:07,270 WARNING  [*] Encoding and padding...
2023-03-27 17:18:10,177 WARNING  [!] Saved X as out_avast_multiclass_1679929442\nebula_wht_speakeasy_vocab_50000_seqlen_512\x_test_full.npy
2023-03-27 17:18:10,192 WARNING  [!] Saved Y as out_avast_multiclass_1679929442\nebula_wht_speakeasy_vocab_50000_seqlen_512\y_test_full.npy
2023-03-27 17:18:10,205 WARNING  [*] Training NeurLux preprocessor on 37512 reports...
2023-03-27 17:18:19,161 WARNING  [*] Encoding and padding reports...
2023-03-27 17:18:27,529 WARNING  [!] Saved X as out_avast_multiclass_1679929442\neurlux_speakeasy_vocab_10000_seqlen_512\x_train_full.npy
2023-03-27 17:18:27,531 WARNING  [!] Saved Y as out_avast_multiclass_1679929442\neurlux_speakeasy_vocab_10000_seqlen_512\y_train_full.npy
2023-03-27 17:18:27,533 WARNING  [*] Loading NeurLux preprocessor from out_avast_multiclass_1679929442\neurlux_speakeasy_vocab_10000_seqlen_512\vocab_10000.json...
2023-03-27 17:18:27,539 WARNING  [*] Encoding and padding reports...
2023-03-27 17:18:30,173 WARNING  [!] Saved X as out_avast_multiclass_1679929442\neurlux_speakeasy_vocab_10000_seqlen_512\x_test_full.npy
2023-03-27 17:18:30,177 WARNING  [!] Saved Y as out_avast_multiclass_1679929442\neurlux_speakeasy_vocab_10000_seqlen_512\y_test_full.npy
2023-03-27 17:18:30,183 WARNING  [!] Multiclass classification with 10 classes
2023-03-27 17:18:30,245 WARNING  [!!!] Starting CV over neurlux!
2023-03-27 17:18:30,302 WARNING  [!] Training time budget: 300min
2023-03-27 17:18:30,303 WARNING  [!] Model config: {'embedding_dim': 256, 'vocab_size': 10000, 'seq_len': 512, 'num_classes': 10}
2023-03-27 17:18:30,336 WARNING  [1/3] Train set size: 25008, Validation set size: 12504
2023-03-27 17:18:31,532 WARNING  [!] Saved dataset splits to dataset_splits_1679930310.npz
2023-03-27 17:18:33,394 WARNING  [!] Iniatialized NeurLux. Total trainable parameters: 2.7948e6
2023-03-27 17:18:33,394 WARNING  [*] Training time budget set: 5.0 min
2023-03-27 17:18:33,423 WARNING  [*] Started epoch: 1
2023-03-27 17:18:34,418 WARNING  [*] 17:18:34: Train Epoch: 1 [  0  /25008 (0 %)] | Loss: 2.357948 | Elapsed: 0.99s
2023-03-27 17:18:37,956 WARNING  [*] 17:18:37: Train Epoch: 1 [9600 /25008 (38%)] | Loss: 0.838908 | Elapsed: 3.54s
2023-03-27 17:18:41,760 WARNING  [*] 17:18:41: Train Epoch: 1 [19200/25008 (77%)] | Loss: 0.536096 | Elapsed: 3.80s
2023-03-27 17:18:44,206 WARNING  [*] Mon Mar 27 17:18:44 2023:    1    | Tr.loss: 0.949057 | Elapsed:   10.78  s
2023-03-27 17:18:44,206 WARNING  [*] Started epoch: 2
2023-03-27 17:18:44,250 WARNING  [*] 17:18:44: Train Epoch: 2 [  0  /25008 (0 %)] | Loss: 0.363574 | Elapsed: 0.04s
2023-03-27 17:18:48,243 WARNING  [*] 17:18:48: Train Epoch: 2 [9600 /25008 (38%)] | Loss: 0.329513 | Elapsed: 3.99s
2023-03-27 17:18:52,153 WARNING  [*] 17:18:52: Train Epoch: 2 [19200/25008 (77%)] | Loss: 0.314098 | Elapsed: 3.91s
2023-03-27 17:18:54,479 WARNING  [*] Mon Mar 27 17:18:54 2023:    2    | Tr.loss: 0.314041 | Elapsed:   10.27  s
2023-03-27 17:18:54,479 WARNING  [*] Started epoch: 3
2023-03-27 17:18:54,518 WARNING  [*] 17:18:54: Train Epoch: 3 [  0  /25008 (0 %)] | Loss: 0.347038 | Elapsed: 0.04s
2023-03-27 17:18:58,441 WARNING  [*] 17:18:58: Train Epoch: 3 [9600 /25008 (38%)] | Loss: 0.160156 | Elapsed: 3.92s
2023-03-27 17:19:02,365 WARNING  [*] 17:19:02: Train Epoch: 3 [19200/25008 (77%)] | Loss: 0.242175 | Elapsed: 3.92s
2023-03-27 17:19:04,739 WARNING  [*] Mon Mar 27 17:19:04 2023:    3    | Tr.loss: 0.222099 | Elapsed:   10.26  s
2023-03-27 17:19:04,740 WARNING  [*] Started epoch: 4
2023-03-27 17:19:04,781 WARNING  [*] 17:19:04: Train Epoch: 4 [  0  /25008 (0 %)] | Loss: 0.182541 | Elapsed: 0.04s
2023-03-27 17:19:09,109 WARNING  [*] 17:19:09: Train Epoch: 4 [9600 /25008 (38%)] | Loss: 0.262577 | Elapsed: 4.33s
2023-03-27 17:19:13,101 WARNING  [*] 17:19:13: Train Epoch: 4 [19200/25008 (77%)] | Loss: 0.200403 | Elapsed: 3.99s
2023-03-27 17:19:15,362 WARNING  [*] Mon Mar 27 17:19:15 2023:    4    | Tr.loss: 0.201201 | Elapsed:   10.62  s
2023-03-27 17:19:15,362 WARNING  [*] Started epoch: 5
2023-03-27 17:19:15,401 WARNING  [*] 17:19:15: Train Epoch: 5 [  0  /25008 (0 %)] | Loss: 0.156709 | Elapsed: 0.04s
2023-03-27 17:19:19,257 WARNING  [*] 17:19:19: Train Epoch: 5 [9600 /25008 (38%)] | Loss: 0.221803 | Elapsed: 3.86s
2023-03-27 17:19:23,315 WARNING  [*] 17:19:23: Train Epoch: 5 [19200/25008 (77%)] | Loss: 0.255199 | Elapsed: 4.06s
2023-03-27 17:19:25,763 WARNING  [*] Mon Mar 27 17:19:25 2023:    5    | Tr.loss: 0.185494 | Elapsed:   10.40  s
2023-03-27 17:19:25,763 WARNING  [*] Started epoch: 6
2023-03-27 17:19:25,804 WARNING  [*] 17:19:25: Train Epoch: 6 [  0  /25008 (0 %)] | Loss: 0.231490 | Elapsed: 0.04s
2023-03-27 17:19:29,811 WARNING  [*] 17:19:29: Train Epoch: 6 [9600 /25008 (38%)] | Loss: 0.083066 | Elapsed: 4.01s
2023-03-27 17:19:33,496 WARNING  [*] 17:19:33: Train Epoch: 6 [19200/25008 (77%)] | Loss: 0.109817 | Elapsed: 3.69s
2023-03-27 17:19:35,695 WARNING  [*] Mon Mar 27 17:19:35 2023:    6    | Tr.loss: 0.185676 | Elapsed:   9.93   s
2023-03-27 17:19:35,695 WARNING  [*] Started epoch: 7
2023-03-27 17:19:35,741 WARNING  [*] 17:19:35: Train Epoch: 7 [  0  /25008 (0 %)] | Loss: 0.132280 | Elapsed: 0.05s
2023-03-27 17:19:39,501 WARNING  [*] 17:19:39: Train Epoch: 7 [9600 /25008 (38%)] | Loss: 0.217919 | Elapsed: 3.76s
2023-03-27 17:19:43,195 WARNING  [*] 17:19:43: Train Epoch: 7 [19200/25008 (77%)] | Loss: 0.160404 | Elapsed: 3.69s
2023-03-27 17:19:45,383 WARNING  [*] Mon Mar 27 17:19:45 2023:    7    | Tr.loss: 0.173557 | Elapsed:   9.69   s
2023-03-27 17:19:45,383 WARNING  [*] Started epoch: 8
2023-03-27 17:19:45,435 WARNING  [*] 17:19:45: Train Epoch: 8 [  0  /25008 (0 %)] | Loss: 0.225711 | Elapsed: 0.05s
2023-03-27 17:19:49,050 WARNING  [*] 17:19:49: Train Epoch: 8 [9600 /25008 (38%)] | Loss: 0.160454 | Elapsed: 3.61s
2023-03-27 17:19:53,139 WARNING  [*] 17:19:53: Train Epoch: 8 [19200/25008 (77%)] | Loss: 0.140080 | Elapsed: 4.09s
2023-03-27 17:19:55,397 WARNING  [*] Mon Mar 27 17:19:55 2023:    8    | Tr.loss: 0.160185 | Elapsed:   10.01  s
2023-03-27 17:19:55,398 WARNING  [*] Started epoch: 9
2023-03-27 17:19:55,440 WARNING  [*] 17:19:55: Train Epoch: 9 [  0  /25008 (0 %)] | Loss: 0.230877 | Elapsed: 0.04s
2023-03-27 17:19:59,344 WARNING  [*] 17:19:59: Train Epoch: 9 [9600 /25008 (38%)] | Loss: 0.092453 | Elapsed: 3.90s
2023-03-27 17:20:03,089 WARNING  [*] 17:20:03: Train Epoch: 9 [19200/25008 (77%)] | Loss: 0.113859 | Elapsed: 3.75s
2023-03-27 17:20:05,291 WARNING  [*] Mon Mar 27 17:20:05 2023:    9    | Tr.loss: 0.159989 | Elapsed:   9.89   s
2023-03-27 17:20:05,291 WARNING  [*] Started epoch: 10
2023-03-27 17:20:05,341 WARNING  [*] 17:20:05: Train Epoch: 10 [  0  /25008 (0 %)] | Loss: 0.179298 | Elapsed: 0.05s
2023-03-27 17:20:09,011 WARNING  [*] 17:20:09: Train Epoch: 10 [9600 /25008 (38%)] | Loss: 0.095862 | Elapsed: 3.67s
2023-03-27 17:20:12,901 WARNING  [*] 17:20:12: Train Epoch: 10 [19200/25008 (77%)] | Loss: 0.149461 | Elapsed: 3.89s
2023-03-27 17:20:15,086 WARNING  [*] Mon Mar 27 17:20:15 2023:   10    | Tr.loss: 0.155106 | Elapsed:   9.79   s
2023-03-27 17:20:15,086 WARNING  [*] Started epoch: 11
2023-03-27 17:20:15,131 WARNING  [*] 17:20:15: Train Epoch: 11 [  0  /25008 (0 %)] | Loss: 0.154650 | Elapsed: 0.05s
2023-03-27 17:20:19,031 WARNING  [*] 17:20:19: Train Epoch: 11 [9600 /25008 (38%)] | Loss: 0.191242 | Elapsed: 3.90s
2023-03-27 17:20:22,999 WARNING  [*] 17:20:22: Train Epoch: 11 [19200/25008 (77%)] | Loss: 0.206997 | Elapsed: 3.97s
2023-03-27 17:20:25,359 WARNING  [*] Mon Mar 27 17:20:25 2023:   11    | Tr.loss: 0.150775 | Elapsed:   10.27  s
2023-03-27 17:20:25,359 WARNING  [*] Started epoch: 12
2023-03-27 17:20:25,398 WARNING  [*] 17:20:25: Train Epoch: 12 [  0  /25008 (0 %)] | Loss: 0.113592 | Elapsed: 0.04s
2023-03-27 17:20:29,372 WARNING  [*] 17:20:29: Train Epoch: 12 [9600 /25008 (38%)] | Loss: 0.157806 | Elapsed: 3.97s
2023-03-27 17:20:33,103 WARNING  [*] 17:20:33: Train Epoch: 12 [19200/25008 (77%)] | Loss: 0.195934 | Elapsed: 3.73s
2023-03-27 17:20:35,422 WARNING  [*] Mon Mar 27 17:20:35 2023:   12    | Tr.loss: 0.155447 | Elapsed:   10.06  s
2023-03-27 17:20:35,422 WARNING  [*] Started epoch: 13
2023-03-27 17:20:35,467 WARNING  [*] 17:20:35: Train Epoch: 13 [  0  /25008 (0 %)] | Loss: 0.120580 | Elapsed: 0.04s
2023-03-27 17:20:39,688 WARNING  [*] 17:20:39: Train Epoch: 13 [9600 /25008 (38%)] | Loss: 0.111222 | Elapsed: 4.22s
2023-03-27 17:20:43,579 WARNING  [*] 17:20:43: Train Epoch: 13 [19200/25008 (77%)] | Loss: 0.136559 | Elapsed: 3.89s
2023-03-27 17:20:45,811 WARNING  [*] Mon Mar 27 17:20:45 2023:   13    | Tr.loss: 0.153213 | Elapsed:   10.39  s
2023-03-27 17:20:45,812 WARNING  [*] Started epoch: 14
2023-03-27 17:20:45,850 WARNING  [*] 17:20:45: Train Epoch: 14 [  0  /25008 (0 %)] | Loss: 0.167246 | Elapsed: 0.04s
2023-03-27 17:20:49,634 WARNING  [*] 17:20:49: Train Epoch: 14 [9600 /25008 (38%)] | Loss: 0.142839 | Elapsed: 3.78s
2023-03-27 17:20:53,516 WARNING  [*] 17:20:53: Train Epoch: 14 [19200/25008 (77%)] | Loss: 0.083490 | Elapsed: 3.88s
2023-03-27 17:20:55,853 WARNING  [*] Mon Mar 27 17:20:55 2023:   14    | Tr.loss: 0.153186 | Elapsed:   10.04  s
2023-03-27 17:20:55,853 WARNING  [*] Started epoch: 15
2023-03-27 17:20:55,892 WARNING  [*] 17:20:55: Train Epoch: 15 [  0  /25008 (0 %)] | Loss: 0.132236 | Elapsed: 0.04s
2023-03-27 17:20:59,606 WARNING  [*] 17:20:59: Train Epoch: 15 [9600 /25008 (38%)] | Loss: 0.098675 | Elapsed: 3.71s
2023-03-27 17:21:03,319 WARNING  [*] 17:21:03: Train Epoch: 15 [19200/25008 (77%)] | Loss: 0.125513 | Elapsed: 3.71s
2023-03-27 17:21:05,871 WARNING  [*] Mon Mar 27 17:21:05 2023:   15    | Tr.loss: 0.150646 | Elapsed:   10.02  s
2023-03-27 17:21:05,871 WARNING  [*] Started epoch: 16
2023-03-27 17:21:05,925 WARNING  [*] 17:21:05: Train Epoch: 16 [  0  /25008 (0 %)] | Loss: 0.092690 | Elapsed: 0.05s
2023-03-27 17:21:09,703 WARNING  [*] 17:21:09: Train Epoch: 16 [9600 /25008 (38%)] | Loss: 0.126330 | Elapsed: 3.78s
2023-03-27 17:21:13,489 WARNING  [*] 17:21:13: Train Epoch: 16 [19200/25008 (77%)] | Loss: 0.080063 | Elapsed: 3.79s
2023-03-27 17:21:15,848 WARNING  [*] Mon Mar 27 17:21:15 2023:   16    | Tr.loss: 0.141080 | Elapsed:   9.98   s
2023-03-27 17:21:15,848 WARNING  [*] Started epoch: 17
2023-03-27 17:21:15,897 WARNING  [*] 17:21:15: Train Epoch: 17 [  0  /25008 (0 %)] | Loss: 0.173738 | Elapsed: 0.05s
2023-03-27 17:21:19,628 WARNING  [*] 17:21:19: Train Epoch: 17 [9600 /25008 (38%)] | Loss: 0.080182 | Elapsed: 3.73s
2023-03-27 17:21:23,639 WARNING  [*] 17:21:23: Train Epoch: 17 [19200/25008 (77%)] | Loss: 0.290485 | Elapsed: 4.01s
2023-03-27 17:21:26,059 WARNING  [*] Mon Mar 27 17:21:26 2023:   17    | Tr.loss: 0.146038 | Elapsed:   10.21  s
2023-03-27 17:21:26,059 WARNING  [*] Started epoch: 18
2023-03-27 17:21:26,109 WARNING  [*] 17:21:26: Train Epoch: 18 [  0  /25008 (0 %)] | Loss: 0.202741 | Elapsed: 0.05s
2023-03-27 17:21:30,064 WARNING  [*] 17:21:30: Train Epoch: 18 [9600 /25008 (38%)] | Loss: 0.111869 | Elapsed: 3.95s
2023-03-27 17:21:33,900 WARNING  [*] 17:21:33: Train Epoch: 18 [19200/25008 (77%)] | Loss: 0.199168 | Elapsed: 3.84s
2023-03-27 17:21:36,281 WARNING  [*] Mon Mar 27 17:21:36 2023:   18    | Tr.loss: 0.148146 | Elapsed:   10.22  s
2023-03-27 17:21:36,281 WARNING  [*] Started epoch: 19
2023-03-27 17:21:36,322 WARNING  [*] 17:21:36: Train Epoch: 19 [  0  /25008 (0 %)] | Loss: 0.206726 | Elapsed: 0.04s
2023-03-27 17:21:40,343 WARNING  [*] 17:21:40: Train Epoch: 19 [9600 /25008 (38%)] | Loss: 0.073106 | Elapsed: 4.02s
2023-03-27 17:21:44,174 WARNING  [*] 17:21:44: Train Epoch: 19 [19200/25008 (77%)] | Loss: 0.149004 | Elapsed: 3.83s
2023-03-27 17:21:46,533 WARNING  [*] Mon Mar 27 17:21:46 2023:   19    | Tr.loss: 0.143124 | Elapsed:   10.25  s
2023-03-27 17:21:46,533 WARNING  [*] Started epoch: 20
2023-03-27 17:21:46,573 WARNING  [*] 17:21:46: Train Epoch: 20 [  0  /25008 (0 %)] | Loss: 0.130202 | Elapsed: 0.04s
2023-03-27 17:21:50,554 WARNING  [*] 17:21:50: Train Epoch: 20 [9600 /25008 (38%)] | Loss: 0.207046 | Elapsed: 3.98s
2023-03-27 17:21:54,565 WARNING  [*] 17:21:54: Train Epoch: 20 [19200/25008 (77%)] | Loss: 0.114543 | Elapsed: 4.01s
2023-03-27 17:21:56,801 WARNING  [*] Mon Mar 27 17:21:56 2023:   20    | Tr.loss: 0.141331 | Elapsed:   10.27  s
2023-03-27 17:21:56,801 WARNING  [*] Started epoch: 21
2023-03-27 17:21:56,840 WARNING  [*] 17:21:56: Train Epoch: 21 [  0  /25008 (0 %)] | Loss: 0.230211 | Elapsed: 0.04s
2023-03-27 17:22:00,502 WARNING  [*] 17:22:00: Train Epoch: 21 [9600 /25008 (38%)] | Loss: 0.150623 | Elapsed: 3.66s
2023-03-27 17:22:04,419 WARNING  [*] 17:22:04: Train Epoch: 21 [19200/25008 (77%)] | Loss: 0.051670 | Elapsed: 3.92s
2023-03-27 17:22:06,839 WARNING  [*] Mon Mar 27 17:22:06 2023:   21    | Tr.loss: 0.145997 | Elapsed:   10.04  s
2023-03-27 17:22:06,839 WARNING  [*] Started epoch: 22
2023-03-27 17:22:06,881 WARNING  [*] 17:22:06: Train Epoch: 22 [  0  /25008 (0 %)] | Loss: 0.157906 | Elapsed: 0.04s
2023-03-27 17:22:10,922 WARNING  [*] 17:22:10: Train Epoch: 22 [9600 /25008 (38%)] | Loss: 0.154239 | Elapsed: 4.04s
2023-03-27 17:22:14,988 WARNING  [*] 17:22:14: Train Epoch: 22 [19200/25008 (77%)] | Loss: 0.097206 | Elapsed: 4.07s
2023-03-27 17:22:17,487 WARNING  [*] Mon Mar 27 17:22:17 2023:   22    | Tr.loss: 0.137319 | Elapsed:   10.65  s
2023-03-27 17:22:17,487 WARNING  [*] Started epoch: 23
2023-03-27 17:22:17,529 WARNING  [*] 17:22:17: Train Epoch: 23 [  0  /25008 (0 %)] | Loss: 0.114848 | Elapsed: 0.04s
2023-03-27 17:22:21,631 WARNING  [*] 17:22:21: Train Epoch: 23 [9600 /25008 (38%)] | Loss: 0.082718 | Elapsed: 4.10s
2023-03-27 17:22:26,176 WARNING  [*] 17:22:26: Train Epoch: 23 [19200/25008 (77%)] | Loss: 0.237616 | Elapsed: 4.54s
2023-03-27 17:22:28,706 WARNING  [*] Mon Mar 27 17:22:28 2023:   23    | Tr.loss: 0.139027 | Elapsed:   11.22  s
2023-03-27 17:22:28,706 WARNING  [*] Started epoch: 24
2023-03-27 17:22:28,745 WARNING  [*] 17:22:28: Train Epoch: 24 [  0  /25008 (0 %)] | Loss: 0.175794 | Elapsed: 0.04s
2023-03-27 17:22:32,787 WARNING  [*] 17:22:32: Train Epoch: 24 [9600 /25008 (38%)] | Loss: 0.128596 | Elapsed: 4.04s
2023-03-27 17:22:36,828 WARNING  [*] 17:22:36: Train Epoch: 24 [19200/25008 (77%)] | Loss: 0.158661 | Elapsed: 4.04s
2023-03-27 17:22:39,116 WARNING  [*] Mon Mar 27 17:22:39 2023:   24    | Tr.loss: 0.136377 | Elapsed:   10.41  s
2023-03-27 17:22:39,116 WARNING  [*] Started epoch: 25
2023-03-27 17:22:39,164 WARNING  [*] 17:22:39: Train Epoch: 25 [  0  /25008 (0 %)] | Loss: 0.125386 | Elapsed: 0.05s
2023-03-27 17:22:43,054 WARNING  [*] 17:22:43: Train Epoch: 25 [9600 /25008 (38%)] | Loss: 0.141306 | Elapsed: 3.89s
2023-03-27 17:22:47,106 WARNING  [*] 17:22:47: Train Epoch: 25 [19200/25008 (77%)] | Loss: 0.142312 | Elapsed: 4.05s
2023-03-27 17:22:49,900 WARNING  [*] Mon Mar 27 17:22:49 2023:   25    | Tr.loss: 0.135146 | Elapsed:   10.78  s
2023-03-27 17:22:49,900 WARNING  [*] Started epoch: 26
2023-03-27 17:22:49,950 WARNING  [*] 17:22:49: Train Epoch: 26 [  0  /25008 (0 %)] | Loss: 0.125737 | Elapsed: 0.05s
2023-03-27 17:22:53,894 WARNING  [*] 17:22:53: Train Epoch: 26 [9600 /25008 (38%)] | Loss: 0.104527 | Elapsed: 3.94s
2023-03-27 17:22:57,813 WARNING  [*] 17:22:57: Train Epoch: 26 [19200/25008 (77%)] | Loss: 0.293496 | Elapsed: 3.92s
2023-03-27 17:23:00,166 WARNING  [*] Mon Mar 27 17:23:00 2023:   26    | Tr.loss: 0.137442 | Elapsed:   10.26  s
2023-03-27 17:23:00,166 WARNING  [*] Started epoch: 27
2023-03-27 17:23:00,206 WARNING  [*] 17:23:00: Train Epoch: 27 [  0  /25008 (0 %)] | Loss: 0.180531 | Elapsed: 0.04s
2023-03-27 17:23:03,994 WARNING  [*] 17:23:03: Train Epoch: 27 [9600 /25008 (38%)] | Loss: 0.140464 | Elapsed: 3.79s
2023-03-27 17:23:08,093 WARNING  [*] 17:23:08: Train Epoch: 27 [19200/25008 (77%)] | Loss: 0.137472 | Elapsed: 4.10s
2023-03-27 17:23:10,333 WARNING  [*] Mon Mar 27 17:23:10 2023:   27    | Tr.loss: 0.130063 | Elapsed:   10.17  s
2023-03-27 17:23:10,333 WARNING  [*] Started epoch: 28
2023-03-27 17:23:10,388 WARNING  [*] 17:23:10: Train Epoch: 28 [  0  /25008 (0 %)] | Loss: 0.109955 | Elapsed: 0.06s
2023-03-27 17:23:14,232 WARNING  [*] 17:23:14: Train Epoch: 28 [9600 /25008 (38%)] | Loss: 0.122670 | Elapsed: 3.84s
2023-03-27 17:23:18,133 WARNING  [*] 17:23:18: Train Epoch: 28 [19200/25008 (77%)] | Loss: 0.057512 | Elapsed: 3.90s
2023-03-27 17:23:20,538 WARNING  [*] Mon Mar 27 17:23:20 2023:   28    | Tr.loss: 0.133770 | Elapsed:   10.21  s
2023-03-27 17:23:20,539 WARNING  [*] Started epoch: 29
2023-03-27 17:23:20,578 WARNING  [*] 17:23:20: Train Epoch: 29 [  0  /25008 (0 %)] | Loss: 0.129716 | Elapsed: 0.04s
2023-03-27 17:23:24,670 WARNING  [*] 17:23:24: Train Epoch: 29 [9600 /25008 (38%)] | Loss: 0.182390 | Elapsed: 4.09s
2023-03-27 17:23:28,787 WARNING  [*] 17:23:28: Train Epoch: 29 [19200/25008 (77%)] | Loss: 0.121548 | Elapsed: 4.12s
2023-03-27 17:23:31,201 WARNING  [*] Mon Mar 27 17:23:31 2023:   29    | Tr.loss: 0.140029 | Elapsed:   10.66  s
2023-03-27 17:23:31,201 WARNING  [*] Started epoch: 30
2023-03-27 17:23:31,242 WARNING  [*] 17:23:31: Train Epoch: 30 [  0  /25008 (0 %)] | Loss: 0.133096 | Elapsed: 0.04s
2023-03-27 17:23:33,406 WARNING  [!] Time budget exceeded, training stopped.
2023-03-27 17:23:33,453 WARNING  [!] Mon Mar 27 17:23:33 2023: Dumped results:
                model       : 1679930310-model.torch
		train time  : 1679930310-trainTime.npy
		train losses: 1679930310-trainLosses.npy
		train AUC   : 1679930310-auc.npy
		train F1s   : 1679930310-trainF1s.npy
		train TPRs  : 1679930310-trainTPRs.npy
2023-03-27 17:23:33,476 WARNING  [!] Evaluating model on training set...
2023-03-27 17:23:36,876 WARNING  [!] This fold metrics on training set:
2023-03-27 17:23:36,924 WARNING 	AUC: 1.0000
2023-03-27 17:23:36,936 WARNING 	F1: 0.9953
2023-03-27 17:23:36,937 WARNING  [!] Evaluating model on validation set...
2023-03-27 17:23:38,393 WARNING  [!] This fold metrics on validation set:
2023-03-27 17:23:38,415 WARNING 	AUC: 0.9985
2023-03-27 17:23:38,420 WARNING 	F1: 0.9832
2023-03-27 17:23:38,714 WARNING  [2/3] Train set size: 25008, Validation set size: 12504
2023-03-27 17:23:40,217 WARNING  [!] Saved dataset splits to dataset_splits_1679930618.npz
2023-03-27 17:23:40,249 WARNING  [!] Iniatialized NeurLux. Total trainable parameters: 2.7948e6
2023-03-27 17:23:40,249 WARNING  [*] Training time budget set: 5.0 min
2023-03-27 17:23:40,266 WARNING  [*] Started epoch: 1
2023-03-27 17:23:40,361 WARNING  [*] 17:23:40: Train Epoch: 1 [  0  /25008 (0 %)] | Loss: 2.277790 | Elapsed: 0.09s
2023-03-27 17:23:44,470 WARNING  [*] 17:23:44: Train Epoch: 1 [9600 /25008 (38%)] | Loss: 0.671152 | Elapsed: 4.11s
2023-03-27 17:23:48,516 WARNING  [*] 17:23:48: Train Epoch: 1 [19200/25008 (77%)] | Loss: 0.615804 | Elapsed: 4.05s
2023-03-27 17:23:50,943 WARNING  [*] Mon Mar 27 17:23:50 2023:    1    | Tr.loss: 0.865092 | Elapsed:   10.68  s
2023-03-27 17:23:50,945 WARNING  [*] Started epoch: 2
2023-03-27 17:23:50,987 WARNING  [*] 17:23:50: Train Epoch: 2 [  0  /25008 (0 %)] | Loss: 0.452396 | Elapsed: 0.04s
2023-03-27 17:23:54,948 WARNING  [*] 17:23:54: Train Epoch: 2 [9600 /25008 (38%)] | Loss: 0.405167 | Elapsed: 3.96s
2023-03-27 17:23:58,862 WARNING  [*] 17:23:58: Train Epoch: 2 [19200/25008 (77%)] | Loss: 0.331574 | Elapsed: 3.91s
2023-03-27 17:24:01,393 WARNING  [*] Mon Mar 27 17:24:01 2023:    2    | Tr.loss: 0.354683 | Elapsed:   10.45  s
2023-03-27 17:24:01,394 WARNING  [*] Started epoch: 3
2023-03-27 17:24:01,435 WARNING  [*] 17:24:01: Train Epoch: 3 [  0  /25008 (0 %)] | Loss: 0.402411 | Elapsed: 0.04s
2023-03-27 17:24:05,248 WARNING  [*] 17:24:05: Train Epoch: 3 [9600 /25008 (38%)] | Loss: 0.201924 | Elapsed: 3.81s
2023-03-27 17:24:08,995 WARNING  [*] 17:24:08: Train Epoch: 3 [19200/25008 (77%)] | Loss: 0.352873 | Elapsed: 3.75s
2023-03-27 17:24:11,217 WARNING  [*] Mon Mar 27 17:24:11 2023:    3    | Tr.loss: 0.285141 | Elapsed:   9.82   s
2023-03-27 17:24:11,217 WARNING  [*] Started epoch: 4
2023-03-27 17:24:11,255 WARNING  [*] 17:24:11: Train Epoch: 4 [  0  /25008 (0 %)] | Loss: 0.319251 | Elapsed: 0.04s
2023-03-27 17:24:15,114 WARNING  [*] 17:24:15: Train Epoch: 4 [9600 /25008 (38%)] | Loss: 0.203726 | Elapsed: 3.86s
2023-03-27 17:24:19,896 WARNING  [*] 17:24:19: Train Epoch: 4 [19200/25008 (77%)] | Loss: 0.133531 | Elapsed: 4.78s
2023-03-27 17:24:22,665 WARNING  [*] Mon Mar 27 17:24:22 2023:    4    | Tr.loss: 0.218958 | Elapsed:   11.45  s
2023-03-27 17:24:22,666 WARNING  [*] Started epoch: 5
2023-03-27 17:24:22,709 WARNING  [*] 17:24:22: Train Epoch: 5 [  0  /25008 (0 %)] | Loss: 0.218844 | Elapsed: 0.04s
2023-03-27 17:24:26,538 WARNING  [*] 17:24:26: Train Epoch: 5 [9600 /25008 (38%)] | Loss: 0.194132 | Elapsed: 3.83s
2023-03-27 17:24:30,401 WARNING  [*] 17:24:30: Train Epoch: 5 [19200/25008 (77%)] | Loss: 0.109920 | Elapsed: 3.86s
2023-03-27 17:24:32,775 WARNING  [*] Mon Mar 27 17:24:32 2023:    5    | Tr.loss: 0.175064 | Elapsed:   10.11  s
2023-03-27 17:24:32,775 WARNING  [*] Started epoch: 6
2023-03-27 17:24:32,814 WARNING  [*] 17:24:32: Train Epoch: 6 [  0  /25008 (0 %)] | Loss: 0.257134 | Elapsed: 0.04s
2023-03-27 17:24:36,689 WARNING  [*] 17:24:36: Train Epoch: 6 [9600 /25008 (38%)] | Loss: 0.176824 | Elapsed: 3.87s
2023-03-27 17:24:40,783 WARNING  [*] 17:24:40: Train Epoch: 6 [19200/25008 (77%)] | Loss: 0.215803 | Elapsed: 4.09s
2023-03-27 17:24:43,264 WARNING  [*] Mon Mar 27 17:24:43 2023:    6    | Tr.loss: 0.165962 | Elapsed:   10.49  s
2023-03-27 17:24:43,265 WARNING  [*] Started epoch: 7
2023-03-27 17:24:43,307 WARNING  [*] 17:24:43: Train Epoch: 7 [  0  /25008 (0 %)] | Loss: 0.116261 | Elapsed: 0.04s
2023-03-27 17:24:47,423 WARNING  [*] 17:24:47: Train Epoch: 7 [9600 /25008 (38%)] | Loss: 0.140368 | Elapsed: 4.12s
2023-03-27 17:24:51,503 WARNING  [*] 17:24:51: Train Epoch: 7 [19200/25008 (77%)] | Loss: 0.236805 | Elapsed: 4.08s
2023-03-27 17:24:53,943 WARNING  [*] Mon Mar 27 17:24:53 2023:    7    | Tr.loss: 0.155234 | Elapsed:   10.66  s
2023-03-27 17:24:53,943 WARNING  [*] Started epoch: 8
2023-03-27 17:24:53,982 WARNING  [*] 17:24:53: Train Epoch: 8 [  0  /25008 (0 %)] | Loss: 0.252856 | Elapsed: 0.04s
2023-03-27 17:24:58,023 WARNING  [*] 17:24:58: Train Epoch: 8 [9600 /25008 (38%)] | Loss: 0.086301 | Elapsed: 4.04s
2023-03-27 17:25:02,333 WARNING  [*] 17:25:02: Train Epoch: 8 [19200/25008 (77%)] | Loss: 0.235568 | Elapsed: 4.31s
2023-03-27 17:25:04,746 WARNING  [*] Mon Mar 27 17:25:04 2023:    8    | Tr.loss: 0.151607 | Elapsed:   10.80  s
2023-03-27 17:25:04,746 WARNING  [*] Started epoch: 9
2023-03-27 17:25:04,805 WARNING  [*] 17:25:04: Train Epoch: 9 [  0  /25008 (0 %)] | Loss: 0.089734 | Elapsed: 0.06s
2023-03-27 17:25:09,788 WARNING  [*] 17:25:09: Train Epoch: 9 [9600 /25008 (38%)] | Loss: 0.147658 | Elapsed: 4.98s
2023-03-27 17:25:14,120 WARNING  [*] 17:25:14: Train Epoch: 9 [19200/25008 (77%)] | Loss: 0.098423 | Elapsed: 4.33s
2023-03-27 17:25:16,666 WARNING  [*] Mon Mar 27 17:25:16 2023:    9    | Tr.loss: 0.142596 | Elapsed:   11.92  s
2023-03-27 17:25:16,667 WARNING  [*] Started epoch: 10
2023-03-27 17:25:16,708 WARNING  [*] 17:25:16: Train Epoch: 10 [  0  /25008 (0 %)] | Loss: 0.109097 | Elapsed: 0.04s
2023-03-27 17:25:20,481 WARNING  [*] 17:25:20: Train Epoch: 10 [9600 /25008 (38%)] | Loss: 0.121226 | Elapsed: 3.77s
2023-03-27 17:25:24,203 WARNING  [*] 17:25:24: Train Epoch: 10 [19200/25008 (77%)] | Loss: 0.138776 | Elapsed: 3.72s
2023-03-27 17:25:26,517 WARNING  [*] Mon Mar 27 17:25:26 2023:   10    | Tr.loss: 0.141100 | Elapsed:   9.85   s
2023-03-27 17:25:26,517 WARNING  [*] Started epoch: 11
2023-03-27 17:25:26,557 WARNING  [*] 17:25:26: Train Epoch: 11 [  0  /25008 (0 %)] | Loss: 0.171821 | Elapsed: 0.04s
2023-03-27 17:25:30,352 WARNING  [*] 17:25:30: Train Epoch: 11 [9600 /25008 (38%)] | Loss: 0.069391 | Elapsed: 3.79s
2023-03-27 17:25:34,175 WARNING  [*] 17:25:34: Train Epoch: 11 [19200/25008 (77%)] | Loss: 0.264926 | Elapsed: 3.82s
2023-03-27 17:25:36,467 WARNING  [*] Mon Mar 27 17:25:36 2023:   11    | Tr.loss: 0.137006 | Elapsed:   9.95   s
2023-03-27 17:25:36,467 WARNING  [*] Started epoch: 12
2023-03-27 17:25:36,520 WARNING  [*] 17:25:36: Train Epoch: 12 [  0  /25008 (0 %)] | Loss: 0.176968 | Elapsed: 0.04s
2023-03-27 17:25:40,369 WARNING  [*] 17:25:40: Train Epoch: 12 [9600 /25008 (38%)] | Loss: 0.091843 | Elapsed: 3.85s
2023-03-27 17:25:44,384 WARNING  [*] 17:25:44: Train Epoch: 12 [19200/25008 (77%)] | Loss: 0.123341 | Elapsed: 4.01s
2023-03-27 17:25:47,008 WARNING  [*] Mon Mar 27 17:25:47 2023:   12    | Tr.loss: 0.130039 | Elapsed:   10.54  s
2023-03-27 17:25:47,009 WARNING  [*] Started epoch: 13
2023-03-27 17:25:47,051 WARNING  [*] 17:25:47: Train Epoch: 13 [  0  /25008 (0 %)] | Loss: 0.175927 | Elapsed: 0.04s
2023-03-27 17:25:51,241 WARNING  [*] 17:25:51: Train Epoch: 13 [9600 /25008 (38%)] | Loss: 0.114349 | Elapsed: 4.19s
2023-03-27 17:25:55,214 WARNING  [*] 17:25:55: Train Epoch: 13 [19200/25008 (77%)] | Loss: 0.085133 | Elapsed: 3.97s
2023-03-27 17:25:57,489 WARNING  [*] Mon Mar 27 17:25:57 2023:   13    | Tr.loss: 0.131078 | Elapsed:   10.48  s
2023-03-27 17:25:57,489 WARNING  [*] Started epoch: 14
2023-03-27 17:25:57,532 WARNING  [*] 17:25:57: Train Epoch: 14 [  0  /25008 (0 %)] | Loss: 0.098033 | Elapsed: 0.04s
2023-03-27 17:26:01,484 WARNING  [*] 17:26:01: Train Epoch: 14 [9600 /25008 (38%)] | Loss: 0.145679 | Elapsed: 3.95s
2023-03-27 17:26:05,577 WARNING  [*] 17:26:05: Train Epoch: 14 [19200/25008 (77%)] | Loss: 0.150499 | Elapsed: 4.09s
2023-03-27 17:26:07,912 WARNING  [*] Mon Mar 27 17:26:07 2023:   14    | Tr.loss: 0.119188 | Elapsed:   10.42  s
2023-03-27 17:26:07,913 WARNING  [*] Started epoch: 15
2023-03-27 17:26:07,953 WARNING  [*] 17:26:07: Train Epoch: 15 [  0  /25008 (0 %)] | Loss: 0.132565 | Elapsed: 0.04s
2023-03-27 17:26:11,972 WARNING  [*] 17:26:11: Train Epoch: 15 [9600 /25008 (38%)] | Loss: 0.147334 | Elapsed: 4.02s
2023-03-27 17:26:16,171 WARNING  [*] 17:26:16: Train Epoch: 15 [19200/25008 (77%)] | Loss: 0.049522 | Elapsed: 4.20s
2023-03-27 17:26:18,778 WARNING  [*] Mon Mar 27 17:26:18 2023:   15    | Tr.loss: 0.126771 | Elapsed:   10.87  s
2023-03-27 17:26:18,778 WARNING  [*] Started epoch: 16
2023-03-27 17:26:18,820 WARNING  [*] 17:26:18: Train Epoch: 16 [  0  /25008 (0 %)] | Loss: 0.086664 | Elapsed: 0.04s
2023-03-27 17:26:22,780 WARNING  [*] 17:26:22: Train Epoch: 16 [9600 /25008 (38%)] | Loss: 0.036176 | Elapsed: 3.96s
2023-03-27 17:26:26,885 WARNING  [*] 17:26:26: Train Epoch: 16 [19200/25008 (77%)] | Loss: 0.070841 | Elapsed: 4.10s
2023-03-27 17:26:29,734 WARNING  [*] Mon Mar 27 17:26:29 2023:   16    | Tr.loss: 0.123819 | Elapsed:   10.96  s
2023-03-27 17:26:29,735 WARNING  [*] Started epoch: 17
2023-03-27 17:26:29,778 WARNING  [*] 17:26:29: Train Epoch: 17 [  0  /25008 (0 %)] | Loss: 0.048332 | Elapsed: 0.04s
2023-03-27 17:26:34,060 WARNING  [*] 17:26:34: Train Epoch: 17 [9600 /25008 (38%)] | Loss: 0.157933 | Elapsed: 4.28s
2023-03-27 17:26:37,970 WARNING  [*] 17:26:37: Train Epoch: 17 [19200/25008 (77%)] | Loss: 0.188934 | Elapsed: 3.91s
2023-03-27 17:26:40,449 WARNING  [*] Mon Mar 27 17:26:40 2023:   17    | Tr.loss: 0.126241 | Elapsed:   10.71  s
2023-03-27 17:26:40,449 WARNING  [*] Started epoch: 18
2023-03-27 17:26:40,493 WARNING  [*] 17:26:40: Train Epoch: 18 [  0  /25008 (0 %)] | Loss: 0.065981 | Elapsed: 0.04s
2023-03-27 17:26:44,314 WARNING  [*] 17:26:44: Train Epoch: 18 [9600 /25008 (38%)] | Loss: 0.156981 | Elapsed: 3.82s
2023-03-27 17:26:48,109 WARNING  [*] 17:26:48: Train Epoch: 18 [19200/25008 (77%)] | Loss: 0.135769 | Elapsed: 3.80s
2023-03-27 17:26:50,627 WARNING  [*] Mon Mar 27 17:26:50 2023:   18    | Tr.loss: 0.125701 | Elapsed:   10.18  s
2023-03-27 17:26:50,627 WARNING  [*] Started epoch: 19
2023-03-27 17:26:50,675 WARNING  [*] 17:26:50: Train Epoch: 19 [  0  /25008 (0 %)] | Loss: 0.108640 | Elapsed: 0.05s
2023-03-27 17:26:54,666 WARNING  [*] 17:26:54: Train Epoch: 19 [9600 /25008 (38%)] | Loss: 0.097643 | Elapsed: 3.99s
2023-03-27 17:26:58,476 WARNING  [*] 17:26:58: Train Epoch: 19 [19200/25008 (77%)] | Loss: 0.096297 | Elapsed: 3.81s
2023-03-27 17:27:00,735 WARNING  [*] Mon Mar 27 17:27:00 2023:   19    | Tr.loss: 0.117884 | Elapsed:   10.11  s
2023-03-27 17:27:00,736 WARNING  [*] Started epoch: 20
2023-03-27 17:27:00,776 WARNING  [*] 17:27:00: Train Epoch: 20 [  0  /25008 (0 %)] | Loss: 0.091746 | Elapsed: 0.04s
2023-03-27 17:27:04,865 WARNING  [*] 17:27:04: Train Epoch: 20 [9600 /25008 (38%)] | Loss: 0.113564 | Elapsed: 4.09s
2023-03-27 17:27:09,422 WARNING  [*] 17:27:09: Train Epoch: 20 [19200/25008 (77%)] | Loss: 0.122225 | Elapsed: 4.56s
2023-03-27 17:27:12,006 WARNING  [*] Mon Mar 27 17:27:12 2023:   20    | Tr.loss: 0.117308 | Elapsed:   11.27  s
2023-03-27 17:27:12,006 WARNING  [*] Started epoch: 21
2023-03-27 17:27:12,059 WARNING  [*] 17:27:12: Train Epoch: 21 [  0  /25008 (0 %)] | Loss: 0.104553 | Elapsed: 0.05s
2023-03-27 17:27:16,288 WARNING  [*] 17:27:16: Train Epoch: 21 [9600 /25008 (38%)] | Loss: 0.078088 | Elapsed: 4.23s
2023-03-27 17:27:20,499 WARNING  [*] 17:27:20: Train Epoch: 21 [19200/25008 (77%)] | Loss: 0.042308 | Elapsed: 4.21s
2023-03-27 17:27:23,032 WARNING  [*] Mon Mar 27 17:27:23 2023:   21    | Tr.loss: 0.118649 | Elapsed:   11.03  s
2023-03-27 17:27:23,033 WARNING  [*] Started epoch: 22
2023-03-27 17:27:23,078 WARNING  [*] 17:27:23: Train Epoch: 22 [  0  /25008 (0 %)] | Loss: 0.098739 | Elapsed: 0.05s
2023-03-27 17:27:27,115 WARNING  [*] 17:27:27: Train Epoch: 22 [9600 /25008 (38%)] | Loss: 0.165634 | Elapsed: 4.04s
2023-03-27 17:27:31,285 WARNING  [*] 17:27:31: Train Epoch: 22 [19200/25008 (77%)] | Loss: 0.101342 | Elapsed: 4.17s
2023-03-27 17:27:33,821 WARNING  [*] Mon Mar 27 17:27:33 2023:   22    | Tr.loss: 0.120329 | Elapsed:   10.79  s
2023-03-27 17:27:33,822 WARNING  [*] Started epoch: 23
2023-03-27 17:27:33,862 WARNING  [*] 17:27:33: Train Epoch: 23 [  0  /25008 (0 %)] | Loss: 0.024577 | Elapsed: 0.04s
2023-03-27 17:27:38,149 WARNING  [*] 17:27:38: Train Epoch: 23 [9600 /25008 (38%)] | Loss: 0.086374 | Elapsed: 4.29s
2023-03-27 17:27:42,304 WARNING  [*] 17:27:42: Train Epoch: 23 [19200/25008 (77%)] | Loss: 0.051718 | Elapsed: 4.15s
2023-03-27 17:27:44,833 WARNING  [*] Mon Mar 27 17:27:44 2023:   23    | Tr.loss: 0.121246 | Elapsed:   11.01  s
2023-03-27 17:27:44,834 WARNING  [*] Started epoch: 24
2023-03-27 17:27:44,875 WARNING  [*] 17:27:44: Train Epoch: 24 [  0  /25008 (0 %)] | Loss: 0.098666 | Elapsed: 0.04s
2023-03-27 17:27:49,436 WARNING  [*] 17:27:49: Train Epoch: 24 [9600 /25008 (38%)] | Loss: 0.118914 | Elapsed: 4.56s
2023-03-27 17:27:54,133 WARNING  [*] 17:27:54: Train Epoch: 24 [19200/25008 (77%)] | Loss: 0.161391 | Elapsed: 4.70s
2023-03-27 17:27:56,807 WARNING  [*] Mon Mar 27 17:27:56 2023:   24    | Tr.loss: 0.108335 | Elapsed:   11.97  s
2023-03-27 17:27:56,807 WARNING  [*] Started epoch: 25
2023-03-27 17:27:56,858 WARNING  [*] 17:27:56: Train Epoch: 25 [  0  /25008 (0 %)] | Loss: 0.078506 | Elapsed: 0.05s
2023-03-27 17:28:01,410 WARNING  [*] 17:28:01: Train Epoch: 25 [9600 /25008 (38%)] | Loss: 0.058070 | Elapsed: 4.55s
2023-03-27 17:28:05,947 WARNING  [*] 17:28:05: Train Epoch: 25 [19200/25008 (77%)] | Loss: 0.074536 | Elapsed: 4.54s
2023-03-27 17:28:08,921 WARNING  [*] Mon Mar 27 17:28:08 2023:   25    | Tr.loss: 0.112357 | Elapsed:   12.11  s
2023-03-27 17:28:08,921 WARNING  [*] Started epoch: 26
2023-03-27 17:28:08,970 WARNING  [*] 17:28:08: Train Epoch: 26 [  0  /25008 (0 %)] | Loss: 0.101236 | Elapsed: 0.05s
2023-03-27 17:28:14,111 WARNING  [*] 17:28:14: Train Epoch: 26 [9600 /25008 (38%)] | Loss: 0.036211 | Elapsed: 5.14s
2023-03-27 17:28:18,521 WARNING  [*] 17:28:18: Train Epoch: 26 [19200/25008 (77%)] | Loss: 0.080909 | Elapsed: 4.41s
2023-03-27 17:28:21,587 WARNING  [*] Mon Mar 27 17:28:21 2023:   26    | Tr.loss: 0.115280 | Elapsed:   12.67  s
2023-03-27 17:28:21,587 WARNING  [*] Started epoch: 27
2023-03-27 17:28:21,630 WARNING  [*] 17:28:21: Train Epoch: 27 [  0  /25008 (0 %)] | Loss: 0.103500 | Elapsed: 0.04s
2023-03-27 17:28:25,809 WARNING  [*] 17:28:25: Train Epoch: 27 [9600 /25008 (38%)] | Loss: 0.150272 | Elapsed: 4.18s
2023-03-27 17:28:29,649 WARNING  [*] 17:28:29: Train Epoch: 27 [19200/25008 (77%)] | Loss: 0.069553 | Elapsed: 3.84s
2023-03-27 17:28:32,063 WARNING  [*] Mon Mar 27 17:28:32 2023:   27    | Tr.loss: 0.113011 | Elapsed:   10.48  s
2023-03-27 17:28:32,063 WARNING  [*] Started epoch: 28
2023-03-27 17:28:32,111 WARNING  [*] 17:28:32: Train Epoch: 28 [  0  /25008 (0 %)] | Loss: 0.034603 | Elapsed: 0.05s
2023-03-27 17:28:36,415 WARNING  [*] 17:28:36: Train Epoch: 28 [9600 /25008 (38%)] | Loss: 0.075507 | Elapsed: 4.30s
2023-03-27 17:28:40,285 WARNING  [!] Time budget exceeded, training stopped.
2023-03-27 17:28:40,321 WARNING  [!] Mon Mar 27 17:28:40 2023: Dumped results:
                model       : 1679930618-model.torch
		train time  : 1679930618-trainTime.npy
		train losses: 1679930618-trainLosses.npy
		train AUC   : 1679930618-auc.npy
		train F1s   : 1679930618-trainF1s.npy
		train TPRs  : 1679930618-trainTPRs.npy
2023-03-27 17:28:40,346 WARNING  [!] Evaluating model on training set...
2023-03-27 17:28:43,344 WARNING  [!] This fold metrics on training set:
2023-03-27 17:28:43,401 WARNING 	AUC: 1.0000
2023-03-27 17:28:43,413 WARNING 	F1: 0.9965
2023-03-27 17:28:43,414 WARNING  [!] Evaluating model on validation set...
2023-03-27 17:28:44,913 WARNING  [!] This fold metrics on validation set:
2023-03-27 17:28:44,934 WARNING 	AUC: 0.9984
2023-03-27 17:28:44,939 WARNING 	F1: 0.9844
2023-03-27 17:28:45,218 WARNING  [3/3] Train set size: 25008, Validation set size: 12504
2023-03-27 17:28:46,970 WARNING  [!] Saved dataset splits to dataset_splits_1679930925.npz
2023-03-27 17:28:47,004 WARNING  [!] Iniatialized NeurLux. Total trainable parameters: 2.7948e6
2023-03-27 17:28:47,004 WARNING  [*] Training time budget set: 5.0 min
2023-03-27 17:28:47,019 WARNING  [*] Started epoch: 1
2023-03-27 17:28:47,107 WARNING  [*] 17:28:47: Train Epoch: 1 [  0  /25008 (0 %)] | Loss: 2.373121 | Elapsed: 0.09s
2023-03-27 17:28:51,451 WARNING  [*] 17:28:51: Train Epoch: 1 [9600 /25008 (38%)] | Loss: 1.022570 | Elapsed: 4.34s
2023-03-27 17:28:55,981 WARNING  [*] 17:28:55: Train Epoch: 1 [19200/25008 (77%)] | Loss: 0.648733 | Elapsed: 4.53s
2023-03-27 17:28:58,671 WARNING  [*] Mon Mar 27 17:28:58 2023:    1    | Tr.loss: 0.975571 | Elapsed:   11.65  s
2023-03-27 17:28:58,672 WARNING  [*] Started epoch: 2
2023-03-27 17:28:58,713 WARNING  [*] 17:28:58: Train Epoch: 2 [  0  /25008 (0 %)] | Loss: 0.429825 | Elapsed: 0.04s
2023-03-27 17:29:03,062 WARNING  [*] 17:29:03: Train Epoch: 2 [9600 /25008 (38%)] | Loss: 0.313931 | Elapsed: 4.35s
2023-03-27 17:29:07,552 WARNING  [*] 17:29:07: Train Epoch: 2 [19200/25008 (77%)] | Loss: 0.409159 | Elapsed: 4.49s
2023-03-27 17:29:10,203 WARNING  [*] Mon Mar 27 17:29:10 2023:    2    | Tr.loss: 0.404155 | Elapsed:   11.53  s
2023-03-27 17:29:10,203 WARNING  [*] Started epoch: 3
2023-03-27 17:29:10,246 WARNING  [*] 17:29:10: Train Epoch: 3 [  0  /25008 (0 %)] | Loss: 0.289178 | Elapsed: 0.04s
2023-03-27 17:29:14,466 WARNING  [*] 17:29:14: Train Epoch: 3 [9600 /25008 (38%)] | Loss: 0.192018 | Elapsed: 4.22s
2023-03-27 17:29:18,599 WARNING  [*] 17:29:18: Train Epoch: 3 [19200/25008 (77%)] | Loss: 0.183120 | Elapsed: 4.13s
2023-03-27 17:29:21,163 WARNING  [*] Mon Mar 27 17:29:21 2023:    3    | Tr.loss: 0.284192 | Elapsed:   10.96  s
2023-03-27 17:29:21,163 WARNING  [*] Started epoch: 4
2023-03-27 17:29:21,211 WARNING  [*] 17:29:21: Train Epoch: 4 [  0  /25008 (0 %)] | Loss: 0.189651 | Elapsed: 0.05s
2023-03-27 17:29:25,449 WARNING  [*] 17:29:25: Train Epoch: 4 [9600 /25008 (38%)] | Loss: 0.284243 | Elapsed: 4.24s
2023-03-27 17:29:29,851 WARNING  [*] 17:29:29: Train Epoch: 4 [19200/25008 (77%)] | Loss: 0.286417 | Elapsed: 4.40s
2023-03-27 17:29:32,444 WARNING  [*] Mon Mar 27 17:29:32 2023:    4    | Tr.loss: 0.227888 | Elapsed:   11.28  s
2023-03-27 17:29:32,445 WARNING  [*] Started epoch: 5
2023-03-27 17:29:32,487 WARNING  [*] 17:29:32: Train Epoch: 5 [  0  /25008 (0 %)] | Loss: 0.122657 | Elapsed: 0.04s
2023-03-27 17:29:36,723 WARNING  [*] 17:29:36: Train Epoch: 5 [9600 /25008 (38%)] | Loss: 0.213942 | Elapsed: 4.24s
2023-03-27 17:29:40,882 WARNING  [*] 17:29:40: Train Epoch: 5 [19200/25008 (77%)] | Loss: 0.226268 | Elapsed: 4.16s
2023-03-27 17:29:43,426 WARNING  [*] Mon Mar 27 17:29:43 2023:    5    | Tr.loss: 0.194008 | Elapsed:   10.98  s
2023-03-27 17:29:43,427 WARNING  [*] Started epoch: 6
2023-03-27 17:29:43,466 WARNING  [*] 17:29:43: Train Epoch: 6 [  0  /25008 (0 %)] | Loss: 0.203105 | Elapsed: 0.04s
2023-03-27 17:29:47,779 WARNING  [*] 17:29:47: Train Epoch: 6 [9600 /25008 (38%)] | Loss: 0.250107 | Elapsed: 4.31s
2023-03-27 17:29:52,058 WARNING  [*] 17:29:52: Train Epoch: 6 [19200/25008 (77%)] | Loss: 0.205120 | Elapsed: 4.28s
2023-03-27 17:29:54,519 WARNING  [*] Mon Mar 27 17:29:54 2023:    6    | Tr.loss: 0.180751 | Elapsed:   11.09  s
2023-03-27 17:29:54,519 WARNING  [*] Started epoch: 7
2023-03-27 17:29:54,560 WARNING  [*] 17:29:54: Train Epoch: 7 [  0  /25008 (0 %)] | Loss: 0.086153 | Elapsed: 0.04s
2023-03-27 17:29:58,848 WARNING  [*] 17:29:58: Train Epoch: 7 [9600 /25008 (38%)] | Loss: 0.139631 | Elapsed: 4.29s
2023-03-27 17:30:03,189 WARNING  [*] 17:30:03: Train Epoch: 7 [19200/25008 (77%)] | Loss: 0.099703 | Elapsed: 4.34s
2023-03-27 17:30:05,796 WARNING  [*] Mon Mar 27 17:30:05 2023:    7    | Tr.loss: 0.163256 | Elapsed:   11.28  s
2023-03-27 17:30:05,796 WARNING  [*] Started epoch: 8
2023-03-27 17:30:05,836 WARNING  [*] 17:30:05: Train Epoch: 8 [  0  /25008 (0 %)] | Loss: 0.159045 | Elapsed: 0.04s
2023-03-27 17:30:10,133 WARNING  [*] 17:30:10: Train Epoch: 8 [9600 /25008 (38%)] | Loss: 0.187726 | Elapsed: 4.30s
2023-03-27 17:30:14,503 WARNING  [*] 17:30:14: Train Epoch: 8 [19200/25008 (77%)] | Loss: 0.083588 | Elapsed: 4.37s
2023-03-27 17:30:17,006 WARNING  [*] Mon Mar 27 17:30:17 2023:    8    | Tr.loss: 0.161993 | Elapsed:   11.21  s
2023-03-27 17:30:17,006 WARNING  [*] Started epoch: 9
2023-03-27 17:30:17,048 WARNING  [*] 17:30:17: Train Epoch: 9 [  0  /25008 (0 %)] | Loss: 0.159565 | Elapsed: 0.04s
2023-03-27 17:30:21,391 WARNING  [*] 17:30:21: Train Epoch: 9 [9600 /25008 (38%)] | Loss: 0.183672 | Elapsed: 4.34s
2023-03-27 17:30:25,539 WARNING  [*] 17:30:25: Train Epoch: 9 [19200/25008 (77%)] | Loss: 0.169377 | Elapsed: 4.15s
2023-03-27 17:30:28,066 WARNING  [*] Mon Mar 27 17:30:28 2023:    9    | Tr.loss: 0.151973 | Elapsed:   11.06  s
2023-03-27 17:30:28,067 WARNING  [*] Started epoch: 10
2023-03-27 17:30:28,106 WARNING  [*] 17:30:28: Train Epoch: 10 [  0  /25008 (0 %)] | Loss: 0.165725 | Elapsed: 0.04s
2023-03-27 17:30:32,274 WARNING  [*] 17:30:32: Train Epoch: 10 [9600 /25008 (38%)] | Loss: 0.198167 | Elapsed: 4.17s
2023-03-27 17:30:36,424 WARNING  [*] 17:30:36: Train Epoch: 10 [19200/25008 (77%)] | Loss: 0.152987 | Elapsed: 4.15s
2023-03-27 17:30:39,005 WARNING  [*] Mon Mar 27 17:30:39 2023:   10    | Tr.loss: 0.153142 | Elapsed:   10.94  s
2023-03-27 17:30:39,006 WARNING  [*] Started epoch: 11
2023-03-27 17:30:39,046 WARNING  [*] 17:30:39: Train Epoch: 11 [  0  /25008 (0 %)] | Loss: 0.030050 | Elapsed: 0.04s
2023-03-27 17:30:43,295 WARNING  [*] 17:30:43: Train Epoch: 11 [9600 /25008 (38%)] | Loss: 0.292030 | Elapsed: 4.25s
2023-03-27 17:30:47,617 WARNING  [*] 17:30:47: Train Epoch: 11 [19200/25008 (77%)] | Loss: 0.170318 | Elapsed: 4.32s
2023-03-27 17:30:50,155 WARNING  [*] Mon Mar 27 17:30:50 2023:   11    | Tr.loss: 0.140792 | Elapsed:   11.15  s
2023-03-27 17:30:50,155 WARNING  [*] Started epoch: 12
2023-03-27 17:30:50,199 WARNING  [*] 17:30:50: Train Epoch: 12 [  0  /25008 (0 %)] | Loss: 0.156843 | Elapsed: 0.04s
2023-03-27 17:30:54,475 WARNING  [*] 17:30:54: Train Epoch: 12 [9600 /25008 (38%)] | Loss: 0.138157 | Elapsed: 4.28s
2023-03-27 17:30:58,906 WARNING  [*] 17:30:58: Train Epoch: 12 [19200/25008 (77%)] | Loss: 0.138185 | Elapsed: 4.43s
2023-03-27 17:31:01,398 WARNING  [*] Mon Mar 27 17:31:01 2023:   12    | Tr.loss: 0.147043 | Elapsed:   11.24  s
2023-03-27 17:31:01,399 WARNING  [*] Started epoch: 13
2023-03-27 17:31:01,441 WARNING  [*] 17:31:01: Train Epoch: 13 [  0  /25008 (0 %)] | Loss: 0.169755 | Elapsed: 0.04s
2023-03-27 17:31:05,706 WARNING  [*] 17:31:05: Train Epoch: 13 [9600 /25008 (38%)] | Loss: 0.180711 | Elapsed: 4.26s
2023-03-27 17:31:09,835 WARNING  [*] 17:31:09: Train Epoch: 13 [19200/25008 (77%)] | Loss: 0.070914 | Elapsed: 4.13s
2023-03-27 17:31:12,347 WARNING  [*] Mon Mar 27 17:31:12 2023:   13    | Tr.loss: 0.145709 | Elapsed:   10.95  s
2023-03-27 17:31:12,347 WARNING  [*] Started epoch: 14
2023-03-27 17:31:12,388 WARNING  [*] 17:31:12: Train Epoch: 14 [  0  /25008 (0 %)] | Loss: 0.088479 | Elapsed: 0.04s
2023-03-27 17:31:16,619 WARNING  [*] 17:31:16: Train Epoch: 14 [9600 /25008 (38%)] | Loss: 0.216583 | Elapsed: 4.23s
2023-03-27 17:31:20,921 WARNING  [*] 17:31:20: Train Epoch: 14 [19200/25008 (77%)] | Loss: 0.222015 | Elapsed: 4.30s
2023-03-27 17:31:23,435 WARNING  [*] Mon Mar 27 17:31:23 2023:   14    | Tr.loss: 0.137359 | Elapsed:   11.09  s
2023-03-27 17:31:23,435 WARNING  [*] Started epoch: 15
2023-03-27 17:31:23,476 WARNING  [*] 17:31:23: Train Epoch: 15 [  0  /25008 (0 %)] | Loss: 0.069553 | Elapsed: 0.04s
2023-03-27 17:31:27,731 WARNING  [*] 17:31:27: Train Epoch: 15 [9600 /25008 (38%)] | Loss: 0.082345 | Elapsed: 4.25s
2023-03-27 17:31:31,941 WARNING  [*] 17:31:31: Train Epoch: 15 [19200/25008 (77%)] | Loss: 0.099472 | Elapsed: 4.21s
2023-03-27 17:31:34,553 WARNING  [*] Mon Mar 27 17:31:34 2023:   15    | Tr.loss: 0.134080 | Elapsed:   11.12  s
2023-03-27 17:31:34,553 WARNING  [*] Started epoch: 16
2023-03-27 17:31:34,594 WARNING  [*] 17:31:34: Train Epoch: 16 [  0  /25008 (0 %)] | Loss: 0.103978 | Elapsed: 0.04s
2023-03-27 17:31:38,870 WARNING  [*] 17:31:38: Train Epoch: 16 [9600 /25008 (38%)] | Loss: 0.058249 | Elapsed: 4.28s
2023-03-27 17:31:43,193 WARNING  [*] 17:31:43: Train Epoch: 16 [19200/25008 (77%)] | Loss: 0.108671 | Elapsed: 4.32s
2023-03-27 17:31:45,889 WARNING  [*] Mon Mar 27 17:31:45 2023:   16    | Tr.loss: 0.134229 | Elapsed:   11.34  s
2023-03-27 17:31:45,890 WARNING  [*] Started epoch: 17
2023-03-27 17:31:45,931 WARNING  [*] 17:31:45: Train Epoch: 17 [  0  /25008 (0 %)] | Loss: 0.115254 | Elapsed: 0.04s
2023-03-27 17:31:50,126 WARNING  [*] 17:31:50: Train Epoch: 17 [9600 /25008 (38%)] | Loss: 0.072815 | Elapsed: 4.19s
2023-03-27 17:31:54,316 WARNING  [*] 17:31:54: Train Epoch: 17 [19200/25008 (77%)] | Loss: 0.121272 | Elapsed: 4.19s
2023-03-27 17:31:56,831 WARNING  [*] Mon Mar 27 17:31:56 2023:   17    | Tr.loss: 0.132779 | Elapsed:   10.94  s
2023-03-27 17:31:56,832 WARNING  [*] Started epoch: 18
2023-03-27 17:31:56,869 WARNING  [*] 17:31:56: Train Epoch: 18 [  0  /25008 (0 %)] | Loss: 0.082953 | Elapsed: 0.04s
2023-03-27 17:32:01,193 WARNING  [*] 17:32:01: Train Epoch: 18 [9600 /25008 (38%)] | Loss: 0.061386 | Elapsed: 4.32s
2023-03-27 17:32:05,439 WARNING  [*] 17:32:05: Train Epoch: 18 [19200/25008 (77%)] | Loss: 0.059978 | Elapsed: 4.24s
2023-03-27 17:32:07,885 WARNING  [*] Mon Mar 27 17:32:07 2023:   18    | Tr.loss: 0.133442 | Elapsed:   11.05  s
2023-03-27 17:32:07,885 WARNING  [*] Started epoch: 19
2023-03-27 17:32:07,926 WARNING  [*] 17:32:07: Train Epoch: 19 [  0  /25008 (0 %)] | Loss: 0.168877 | Elapsed: 0.04s
2023-03-27 17:32:12,149 WARNING  [*] 17:32:12: Train Epoch: 19 [9600 /25008 (38%)] | Loss: 0.193169 | Elapsed: 4.22s
2023-03-27 17:32:16,346 WARNING  [*] 17:32:16: Train Epoch: 19 [19200/25008 (77%)] | Loss: 0.175230 | Elapsed: 4.20s
2023-03-27 17:32:18,814 WARNING  [*] Mon Mar 27 17:32:18 2023:   19    | Tr.loss: 0.128224 | Elapsed:   10.93  s
2023-03-27 17:32:18,814 WARNING  [*] Started epoch: 20
2023-03-27 17:32:18,853 WARNING  [*] 17:32:18: Train Epoch: 20 [  0  /25008 (0 %)] | Loss: 0.117935 | Elapsed: 0.04s
2023-03-27 17:32:23,175 WARNING  [*] 17:32:23: Train Epoch: 20 [9600 /25008 (38%)] | Loss: 0.025451 | Elapsed: 4.32s
2023-03-27 17:32:27,755 WARNING  [*] 17:32:27: Train Epoch: 20 [19200/25008 (77%)] | Loss: 0.130928 | Elapsed: 4.58s
2023-03-27 17:32:30,279 WARNING  [*] Mon Mar 27 17:32:30 2023:   20    | Tr.loss: 0.124869 | Elapsed:   11.47  s
2023-03-27 17:32:30,279 WARNING  [*] Started epoch: 21
2023-03-27 17:32:30,320 WARNING  [*] 17:32:30: Train Epoch: 21 [  0  /25008 (0 %)] | Loss: 0.110650 | Elapsed: 0.04s
2023-03-27 17:32:34,673 WARNING  [*] 17:32:34: Train Epoch: 21 [9600 /25008 (38%)] | Loss: 0.094948 | Elapsed: 4.35s
2023-03-27 17:32:39,038 WARNING  [*] 17:32:39: Train Epoch: 21 [19200/25008 (77%)] | Loss: 0.080266 | Elapsed: 4.36s
2023-03-27 17:32:41,563 WARNING  [*] Mon Mar 27 17:32:41 2023:   21    | Tr.loss: 0.122710 | Elapsed:   11.28  s
2023-03-27 17:32:41,565 WARNING  [*] Started epoch: 22
2023-03-27 17:32:41,606 WARNING  [*] 17:32:41: Train Epoch: 22 [  0  /25008 (0 %)] | Loss: 0.130798 | Elapsed: 0.04s
2023-03-27 17:32:46,021 WARNING  [*] 17:32:46: Train Epoch: 22 [9600 /25008 (38%)] | Loss: 0.085731 | Elapsed: 4.41s
2023-03-27 17:32:50,152 WARNING  [*] 17:32:50: Train Epoch: 22 [19200/25008 (77%)] | Loss: 0.089860 | Elapsed: 4.13s
2023-03-27 17:32:52,714 WARNING  [*] Mon Mar 27 17:32:52 2023:   22    | Tr.loss: 0.123196 | Elapsed:   11.15  s
2023-03-27 17:32:52,715 WARNING  [*] Started epoch: 23
2023-03-27 17:32:52,758 WARNING  [*] 17:32:52: Train Epoch: 23 [  0  /25008 (0 %)] | Loss: 0.118140 | Elapsed: 0.04s
2023-03-27 17:32:57,017 WARNING  [*] 17:32:57: Train Epoch: 23 [9600 /25008 (38%)] | Loss: 0.057304 | Elapsed: 4.26s
2023-03-27 17:33:01,256 WARNING  [*] 17:33:01: Train Epoch: 23 [19200/25008 (77%)] | Loss: 0.088834 | Elapsed: 4.24s
2023-03-27 17:33:03,762 WARNING  [*] Mon Mar 27 17:33:03 2023:   23    | Tr.loss: 0.122190 | Elapsed:   11.05  s
2023-03-27 17:33:03,762 WARNING  [*] Started epoch: 24
2023-03-27 17:33:03,802 WARNING  [*] 17:33:03: Train Epoch: 24 [  0  /25008 (0 %)] | Loss: 0.152415 | Elapsed: 0.04s
2023-03-27 17:33:07,977 WARNING  [*] 17:33:07: Train Epoch: 24 [9600 /25008 (38%)] | Loss: 0.072411 | Elapsed: 4.17s
2023-03-27 17:33:12,419 WARNING  [*] 17:33:12: Train Epoch: 24 [19200/25008 (77%)] | Loss: 0.113044 | Elapsed: 4.44s
2023-03-27 17:33:14,950 WARNING  [*] Mon Mar 27 17:33:14 2023:   24    | Tr.loss: 0.126185 | Elapsed:   11.19  s
2023-03-27 17:33:14,951 WARNING  [*] Started epoch: 25
2023-03-27 17:33:14,992 WARNING  [*] 17:33:14: Train Epoch: 25 [  0  /25008 (0 %)] | Loss: 0.044756 | Elapsed: 0.04s
2023-03-27 17:33:19,468 WARNING  [*] 17:33:19: Train Epoch: 25 [9600 /25008 (38%)] | Loss: 0.106399 | Elapsed: 4.47s
2023-03-27 17:33:23,974 WARNING  [*] 17:33:23: Train Epoch: 25 [19200/25008 (77%)] | Loss: 0.074720 | Elapsed: 4.51s
2023-03-27 17:33:26,602 WARNING  [*] Mon Mar 27 17:33:26 2023:   25    | Tr.loss: 0.122369 | Elapsed:   11.65  s
2023-03-27 17:33:26,603 WARNING  [*] Started epoch: 26
2023-03-27 17:33:26,647 WARNING  [*] 17:33:26: Train Epoch: 26 [  0  /25008 (0 %)] | Loss: 0.074906 | Elapsed: 0.04s
2023-03-27 17:33:30,989 WARNING  [*] 17:33:30: Train Epoch: 26 [9600 /25008 (38%)] | Loss: 0.096788 | Elapsed: 4.34s
2023-03-27 17:33:35,335 WARNING  [*] 17:33:35: Train Epoch: 26 [19200/25008 (77%)] | Loss: 0.226937 | Elapsed: 4.35s
2023-03-27 17:33:37,975 WARNING  [*] Mon Mar 27 17:33:37 2023:   26    | Tr.loss: 0.116892 | Elapsed:   11.37  s
2023-03-27 17:33:37,975 WARNING  [*] Started epoch: 27
2023-03-27 17:33:38,016 WARNING  [*] 17:33:38: Train Epoch: 27 [  0  /25008 (0 %)] | Loss: 0.154961 | Elapsed: 0.04s
2023-03-27 17:33:42,160 WARNING  [*] 17:33:42: Train Epoch: 27 [9600 /25008 (38%)] | Loss: 0.200986 | Elapsed: 4.14s
2023-03-27 17:33:46,380 WARNING  [*] 17:33:46: Train Epoch: 27 [19200/25008 (77%)] | Loss: 0.073669 | Elapsed: 4.22s
2023-03-27 17:33:47,036 WARNING  [!] Time budget exceeded, training stopped.
2023-03-27 17:33:47,070 WARNING  [!] Mon Mar 27 17:33:47 2023: Dumped results:
                model       : 1679930925-model.torch
		train time  : 1679930925-trainTime.npy
		train losses: 1679930925-trainLosses.npy
		train AUC   : 1679930925-auc.npy
		train F1s   : 1679930925-trainF1s.npy
		train TPRs  : 1679930925-trainTPRs.npy
2023-03-27 17:33:47,092 WARNING  [!] Evaluating model on training set...
2023-03-27 17:33:50,185 WARNING  [!] This fold metrics on training set:
2023-03-27 17:33:50,234 WARNING 	AUC: 0.9999
2023-03-27 17:33:50,243 WARNING 	F1: 0.9930
2023-03-27 17:33:50,243 WARNING  [!] Evaluating model on validation set...
2023-03-27 17:33:51,730 WARNING  [!] This fold metrics on validation set:
2023-03-27 17:33:51,750 WARNING 	AUC: 0.9992
2023-03-27 17:33:51,755 WARNING 	F1: 0.9840
2023-03-27 17:33:51,962 WARNING  [!] Metrics saved to out_avast_multiclass_1679929442\cv_neurlux_limNone_r1763_t5\neurlux_metrics_validation.json
2023-03-27 17:33:51,963 WARNING  [!] Metrics saved to out_avast_multiclass_1679929442\cv_neurlux_limNone_r1763_t5\neurlux_metrics_training.json
2023-03-27 17:33:51,964 WARNING  [!] Average epoch time: 0.03s | Mean values over 3 folds:
	AUC: 0.9987

2023-03-27 17:33:52,159 WARNING  [!!!] Starting CV over nebula_bpe!
2023-03-27 17:33:52,207 WARNING  [!] Training time budget: 300min
2023-03-27 17:33:52,207 WARNING  [!] Model config: {'vocab_size': 50001, 'maxlen': 512, 'chunk_size': 64, 'dModel': 64, 'nHeads': 8, 'dHidden': 256, 'nLayers': 2, 'numClasses': 10, 'hiddenNeurons': [64], 'layerNorm': False, 'dropout': 0.3, 'mean_over_sequence': False, 'norm_first': True}
2023-03-27 17:33:52,242 WARNING  [1/3] Train set size: 25008, Validation set size: 12504
2023-03-27 17:33:53,483 WARNING  [!] Saved dataset splits to dataset_splits_1679931232.npz
2023-03-27 17:33:53,597 WARNING  [!] Iniatialized TransformerEncoderChunks. Total trainable parameters: 5.3979e6
2023-03-27 17:33:53,597 WARNING  [*] Training time budget set: 5.0 min
2023-03-27 17:33:53,606 WARNING  [*] Started epoch: 1
2023-03-27 17:33:53,815 WARNING  [*] 17:33:53: Train Epoch: 1 [  0  /25008 (0 %)] | Loss: 8.976734 | Elapsed: 0.21s
2023-03-27 17:34:04,619 WARNING  [*] 17:34:04: Train Epoch: 1 [9600 /25008 (38%)] | Loss: 1.472816 | Elapsed: 10.80s
2023-03-27 17:34:15,249 WARNING  [*] 17:34:15: Train Epoch: 1 [19200/25008 (77%)] | Loss: 1.360192 | Elapsed: 10.63s
2023-03-27 17:34:21,602 WARNING  [*] Mon Mar 27 17:34:21 2023:    1    | Tr.loss: 1.476211 | Elapsed:   28.00  s
2023-03-27 17:34:21,603 WARNING  [*] Started epoch: 2
2023-03-27 17:34:21,707 WARNING  [*] 17:34:21: Train Epoch: 2 [  0  /25008 (0 %)] | Loss: 0.886143 | Elapsed: 0.10s
2023-03-27 17:34:32,171 WARNING  [*] 17:34:32: Train Epoch: 2 [9600 /25008 (38%)] | Loss: 0.788863 | Elapsed: 10.46s
2023-03-27 17:34:42,629 WARNING  [*] 17:34:42: Train Epoch: 2 [19200/25008 (77%)] | Loss: 0.991684 | Elapsed: 10.46s
2023-03-27 17:34:48,932 WARNING  [*] Mon Mar 27 17:34:48 2023:    2    | Tr.loss: 0.807952 | Elapsed:   27.33  s
2023-03-27 17:34:48,932 WARNING  [*] Started epoch: 3
2023-03-27 17:34:49,037 WARNING  [*] 17:34:49: Train Epoch: 3 [  0  /25008 (0 %)] | Loss: 0.667561 | Elapsed: 0.11s
2023-03-27 17:34:59,470 WARNING  [*] 17:34:59: Train Epoch: 3 [9600 /25008 (38%)] | Loss: 0.454377 | Elapsed: 10.43s
2023-03-27 17:35:09,827 WARNING  [*] 17:35:09: Train Epoch: 3 [19200/25008 (77%)] | Loss: 0.449131 | Elapsed: 10.36s
2023-03-27 17:35:16,181 WARNING  [*] Mon Mar 27 17:35:16 2023:    3    | Tr.loss: 0.552206 | Elapsed:   27.25  s
2023-03-27 17:35:16,182 WARNING  [*] Started epoch: 4
2023-03-27 17:35:16,290 WARNING  [*] 17:35:16: Train Epoch: 4 [  0  /25008 (0 %)] | Loss: 0.366323 | Elapsed: 0.11s
2023-03-27 17:35:26,832 WARNING  [*] 17:35:26: Train Epoch: 4 [9600 /25008 (38%)] | Loss: 0.390935 | Elapsed: 10.54s
2023-03-27 17:35:37,516 WARNING  [*] 17:35:37: Train Epoch: 4 [19200/25008 (77%)] | Loss: 0.268434 | Elapsed: 10.68s
2023-03-27 17:35:43,812 WARNING  [*] Mon Mar 27 17:35:43 2023:    4    | Tr.loss: 0.402870 | Elapsed:   27.63  s
2023-03-27 17:35:43,812 WARNING  [*] Started epoch: 5
2023-03-27 17:35:43,930 WARNING  [*] 17:35:43: Train Epoch: 5 [  0  /25008 (0 %)] | Loss: 0.332976 | Elapsed: 0.12s
2023-03-27 17:35:54,465 WARNING  [*] 17:35:54: Train Epoch: 5 [9600 /25008 (38%)] | Loss: 0.369722 | Elapsed: 10.53s
2023-03-27 17:36:05,064 WARNING  [*] 17:36:05: Train Epoch: 5 [19200/25008 (77%)] | Loss: 0.252032 | Elapsed: 10.60s
2023-03-27 17:36:11,261 WARNING  [*] Mon Mar 27 17:36:11 2023:    5    | Tr.loss: 0.280678 | Elapsed:   27.45  s
2023-03-27 17:36:11,261 WARNING  [*] Started epoch: 6
2023-03-27 17:36:11,365 WARNING  [*] 17:36:11: Train Epoch: 6 [  0  /25008 (0 %)] | Loss: 0.162914 | Elapsed: 0.10s
2023-03-27 17:36:21,746 WARNING  [*] 17:36:21: Train Epoch: 6 [9600 /25008 (38%)] | Loss: 0.209183 | Elapsed: 10.38s
2023-03-27 17:36:32,127 WARNING  [*] 17:36:32: Train Epoch: 6 [19200/25008 (77%)] | Loss: 0.104465 | Elapsed: 10.38s
2023-03-27 17:36:38,322 WARNING  [*] Mon Mar 27 17:36:38 2023:    6    | Tr.loss: 0.200796 | Elapsed:   27.06  s
2023-03-27 17:36:38,322 WARNING  [*] Started epoch: 7
2023-03-27 17:36:38,430 WARNING  [*] 17:36:38: Train Epoch: 7 [  0  /25008 (0 %)] | Loss: 0.359800 | Elapsed: 0.11s
2023-03-27 17:36:48,883 WARNING  [*] 17:36:48: Train Epoch: 7 [9600 /25008 (38%)] | Loss: 0.079176 | Elapsed: 10.45s
2023-03-27 17:36:59,442 WARNING  [*] 17:36:59: Train Epoch: 7 [19200/25008 (77%)] | Loss: 0.145697 | Elapsed: 10.56s
2023-03-27 17:37:05,754 WARNING  [*] Mon Mar 27 17:37:05 2023:    7    | Tr.loss: 0.158790 | Elapsed:   27.43  s
2023-03-27 17:37:05,755 WARNING  [*] Started epoch: 8
2023-03-27 17:37:05,863 WARNING  [*] 17:37:05: Train Epoch: 8 [  0  /25008 (0 %)] | Loss: 0.129640 | Elapsed: 0.11s
2023-03-27 17:37:16,349 WARNING  [*] 17:37:16: Train Epoch: 8 [9600 /25008 (38%)] | Loss: 0.224597 | Elapsed: 10.49s
2023-03-27 17:37:27,067 WARNING  [*] 17:37:27: Train Epoch: 8 [19200/25008 (77%)] | Loss: 0.138594 | Elapsed: 10.72s
2023-03-27 17:37:33,325 WARNING  [*] Mon Mar 27 17:37:33 2023:    8    | Tr.loss: 0.130889 | Elapsed:   27.57  s
2023-03-27 17:37:33,325 WARNING  [*] Started epoch: 9
2023-03-27 17:37:33,428 WARNING  [*] 17:37:33: Train Epoch: 9 [  0  /25008 (0 %)] | Loss: 0.121961 | Elapsed: 0.10s
2023-03-27 17:37:43,972 WARNING  [*] 17:37:43: Train Epoch: 9 [9600 /25008 (38%)] | Loss: 0.084649 | Elapsed: 10.54s
2023-03-27 17:37:54,512 WARNING  [*] 17:37:54: Train Epoch: 9 [19200/25008 (77%)] | Loss: 0.131040 | Elapsed: 10.54s
2023-03-27 17:38:00,822 WARNING  [*] Mon Mar 27 17:38:00 2023:    9    | Tr.loss: 0.113210 | Elapsed:   27.50  s
2023-03-27 17:38:00,823 WARNING  [*] Started epoch: 10
2023-03-27 17:38:00,936 WARNING  [*] 17:38:00: Train Epoch: 10 [  0  /25008 (0 %)] | Loss: 0.092720 | Elapsed: 0.11s
2023-03-27 17:38:11,397 WARNING  [*] 17:38:11: Train Epoch: 10 [9600 /25008 (38%)] | Loss: 0.035229 | Elapsed: 10.46s
2023-03-27 17:38:21,764 WARNING  [*] 17:38:21: Train Epoch: 10 [19200/25008 (77%)] | Loss: 0.082670 | Elapsed: 10.37s
2023-03-27 17:38:28,044 WARNING  [*] Mon Mar 27 17:38:28 2023:   10    | Tr.loss: 0.093516 | Elapsed:   27.22  s
2023-03-27 17:38:28,044 WARNING  [*] Started epoch: 11
2023-03-27 17:38:28,146 WARNING  [*] 17:38:28: Train Epoch: 11 [  0  /25008 (0 %)] | Loss: 0.046333 | Elapsed: 0.10s
2023-03-27 17:38:38,650 WARNING  [*] 17:38:38: Train Epoch: 11 [9600 /25008 (38%)] | Loss: 0.056871 | Elapsed: 10.50s
2023-03-27 17:38:49,167 WARNING  [*] 17:38:49: Train Epoch: 11 [19200/25008 (77%)] | Loss: 0.069419 | Elapsed: 10.52s
2023-03-27 17:38:53,615 WARNING  [!] Time budget exceeded, training stopped.
2023-03-27 17:38:53,652 WARNING  [!] Mon Mar 27 17:38:53 2023: Dumped results:
                model       : 1679931232-model.torch
		train time  : 1679931232-trainTime.npy
		train losses: 1679931232-trainLosses.npy
		train AUC   : 1679931232-auc.npy
		train F1s   : 1679931232-trainF1s.npy
		train TPRs  : 1679931232-trainTPRs.npy
2023-03-27 17:38:53,668 WARNING  [!] Evaluating model on training set...
2023-03-27 17:39:00,665 WARNING  [!] This fold metrics on training set:
2023-03-27 17:39:00,701 WARNING 	AUC: 0.9997
2023-03-27 17:39:00,711 WARNING 	F1: 0.9776
2023-03-27 17:39:00,711 WARNING  [!] Evaluating model on validation set...
2023-03-27 17:39:04,232 WARNING  [!] This fold metrics on validation set:
2023-03-27 17:39:04,255 WARNING 	AUC: 0.9993
2023-03-27 17:39:04,261 WARNING 	F1: 0.9695
2023-03-27 17:39:04,519 WARNING  [2/3] Train set size: 25008, Validation set size: 12504
2023-03-27 17:39:05,699 WARNING  [!] Saved dataset splits to dataset_splits_1679931544.npz
2023-03-27 17:39:05,795 WARNING  [!] Iniatialized TransformerEncoderChunks. Total trainable parameters: 5.3979e6
2023-03-27 17:39:05,795 WARNING  [*] Training time budget set: 5.0 min
2023-03-27 17:39:05,805 WARNING  [*] Started epoch: 1
2023-03-27 17:39:05,949 WARNING  [*] 17:39:05: Train Epoch: 1 [  0  /25008 (0 %)] | Loss: 12.774505 | Elapsed: 0.14s
2023-03-27 17:39:16,343 WARNING  [*] 17:39:16: Train Epoch: 1 [9600 /25008 (38%)] | Loss: 1.309557 | Elapsed: 10.39s
2023-03-27 17:39:26,770 WARNING  [*] 17:39:26: Train Epoch: 1 [19200/25008 (77%)] | Loss: 1.221873 | Elapsed: 10.43s
2023-03-27 17:39:33,098 WARNING  [*] Mon Mar 27 17:39:33 2023:    1    | Tr.loss: 1.414143 | Elapsed:   27.29  s
2023-03-27 17:39:33,099 WARNING  [*] Started epoch: 2
2023-03-27 17:39:33,204 WARNING  [*] 17:39:33: Train Epoch: 2 [  0  /25008 (0 %)] | Loss: 0.915584 | Elapsed: 0.10s
2023-03-27 17:39:43,715 WARNING  [*] 17:39:43: Train Epoch: 2 [9600 /25008 (38%)] | Loss: 0.722340 | Elapsed: 10.51s
2023-03-27 17:39:54,202 WARNING  [*] 17:39:54: Train Epoch: 2 [19200/25008 (77%)] | Loss: 0.857146 | Elapsed: 10.49s
2023-03-27 17:40:00,468 WARNING  [*] Mon Mar 27 17:40:00 2023:    2    | Tr.loss: 0.711154 | Elapsed:   27.37  s
2023-03-27 17:40:00,468 WARNING  [*] Started epoch: 3
2023-03-27 17:40:00,573 WARNING  [*] 17:40:00: Train Epoch: 3 [  0  /25008 (0 %)] | Loss: 0.617539 | Elapsed: 0.10s
2023-03-27 17:40:11,124 WARNING  [*] 17:40:11: Train Epoch: 3 [9600 /25008 (38%)] | Loss: 0.438845 | Elapsed: 10.55s
2023-03-27 17:40:21,585 WARNING  [*] 17:40:21: Train Epoch: 3 [19200/25008 (77%)] | Loss: 0.518947 | Elapsed: 10.46s
2023-03-27 17:40:27,893 WARNING  [*] Mon Mar 27 17:40:27 2023:    3    | Tr.loss: 0.481399 | Elapsed:   27.42  s
2023-03-27 17:40:27,893 WARNING  [*] Started epoch: 4
2023-03-27 17:40:27,999 WARNING  [*] 17:40:27: Train Epoch: 4 [  0  /25008 (0 %)] | Loss: 0.408241 | Elapsed: 0.11s
2023-03-27 17:40:38,478 WARNING  [*] 17:40:38: Train Epoch: 4 [9600 /25008 (38%)] | Loss: 0.509922 | Elapsed: 10.48s
2023-03-27 17:40:49,187 WARNING  [*] 17:40:49: Train Epoch: 4 [19200/25008 (77%)] | Loss: 0.211925 | Elapsed: 10.71s
2023-03-27 17:40:55,484 WARNING  [*] Mon Mar 27 17:40:55 2023:    4    | Tr.loss: 0.332950 | Elapsed:   27.59  s
2023-03-27 17:40:55,484 WARNING  [*] Started epoch: 5
2023-03-27 17:40:55,592 WARNING  [*] 17:40:55: Train Epoch: 5 [  0  /25008 (0 %)] | Loss: 0.270514 | Elapsed: 0.11s
2023-03-27 17:41:06,004 WARNING  [*] 17:41:06: Train Epoch: 5 [9600 /25008 (38%)] | Loss: 0.242280 | Elapsed: 10.41s
2023-03-27 17:41:16,533 WARNING  [*] 17:41:16: Train Epoch: 5 [19200/25008 (77%)] | Loss: 0.158901 | Elapsed: 10.53s
2023-03-27 17:41:22,785 WARNING  [*] Mon Mar 27 17:41:22 2023:    5    | Tr.loss: 0.229275 | Elapsed:   27.30  s
2023-03-27 17:41:22,785 WARNING  [*] Started epoch: 6
2023-03-27 17:41:22,906 WARNING  [*] 17:41:22: Train Epoch: 6 [  0  /25008 (0 %)] | Loss: 0.111750 | Elapsed: 0.12s
2023-03-27 17:41:33,414 WARNING  [*] 17:41:33: Train Epoch: 6 [9600 /25008 (38%)] | Loss: 0.121629 | Elapsed: 10.51s
2023-03-27 17:41:43,875 WARNING  [*] 17:41:43: Train Epoch: 6 [19200/25008 (77%)] | Loss: 0.089597 | Elapsed: 10.46s
2023-03-27 17:41:50,113 WARNING  [*] Mon Mar 27 17:41:50 2023:    6    | Tr.loss: 0.167450 | Elapsed:   27.33  s
2023-03-27 17:41:50,113 WARNING  [*] Started epoch: 7
2023-03-27 17:41:50,222 WARNING  [*] 17:41:50: Train Epoch: 7 [  0  /25008 (0 %)] | Loss: 0.124987 | Elapsed: 0.11s
2023-03-27 17:42:01,072 WARNING  [*] 17:42:01: Train Epoch: 7 [9600 /25008 (38%)] | Loss: 0.116807 | Elapsed: 10.85s
2023-03-27 17:42:14,083 WARNING  [*] 17:42:14: Train Epoch: 7 [19200/25008 (77%)] | Loss: 0.030117 | Elapsed: 13.01s
2023-03-27 17:42:21,430 WARNING  [*] Mon Mar 27 17:42:21 2023:    7    | Tr.loss: 0.126976 | Elapsed:   31.32  s
2023-03-27 17:42:21,431 WARNING  [*] Started epoch: 8
2023-03-27 17:42:21,549 WARNING  [*] 17:42:21: Train Epoch: 8 [  0  /25008 (0 %)] | Loss: 0.139101 | Elapsed: 0.12s
2023-03-27 17:42:33,308 WARNING  [*] 17:42:33: Train Epoch: 8 [9600 /25008 (38%)] | Loss: 0.060968 | Elapsed: 11.76s
2023-03-27 17:42:45,112 WARNING  [*] 17:42:45: Train Epoch: 8 [19200/25008 (77%)] | Loss: 0.055366 | Elapsed: 11.80s
2023-03-27 17:42:52,091 WARNING  [*] Mon Mar 27 17:42:52 2023:    8    | Tr.loss: 0.107913 | Elapsed:   30.66  s
2023-03-27 17:42:52,091 WARNING  [*] Started epoch: 9
2023-03-27 17:42:52,206 WARNING  [*] 17:42:52: Train Epoch: 9 [  0  /25008 (0 %)] | Loss: 0.056861 | Elapsed: 0.11s
2023-03-27 17:43:04,255 WARNING  [*] 17:43:04: Train Epoch: 9 [9600 /25008 (38%)] | Loss: 0.117787 | Elapsed: 12.05s
2023-03-27 17:43:16,393 WARNING  [*] 17:43:16: Train Epoch: 9 [19200/25008 (77%)] | Loss: 0.089319 | Elapsed: 12.14s
2023-03-27 17:43:23,354 WARNING  [*] Mon Mar 27 17:43:23 2023:    9    | Tr.loss: 0.087369 | Elapsed:   31.26  s
2023-03-27 17:43:23,355 WARNING  [*] Started epoch: 10
2023-03-27 17:43:23,468 WARNING  [*] 17:43:23: Train Epoch: 10 [  0  /25008 (0 %)] | Loss: 0.039069 | Elapsed: 0.11s
2023-03-27 17:43:35,213 WARNING  [*] 17:43:35: Train Epoch: 10 [9600 /25008 (38%)] | Loss: 0.102103 | Elapsed: 11.74s
2023-03-27 17:43:47,066 WARNING  [*] 17:43:47: Train Epoch: 10 [19200/25008 (77%)] | Loss: 0.035826 | Elapsed: 11.85s
2023-03-27 17:43:54,327 WARNING  [*] Mon Mar 27 17:43:54 2023:   10    | Tr.loss: 0.079348 | Elapsed:   30.97  s
2023-03-27 17:43:54,328 WARNING  [*] Started epoch: 11
2023-03-27 17:43:54,454 WARNING  [*] 17:43:54: Train Epoch: 11 [  0  /25008 (0 %)] | Loss: 0.048263 | Elapsed: 0.13s
2023-03-27 17:44:05,804 WARNING  [!] Time budget exceeded, training stopped.
2023-03-27 17:44:05,866 WARNING  [!] Mon Mar 27 17:44:05 2023: Dumped results:
                model       : 1679931544-model.torch
		train time  : 1679931544-trainTime.npy
		train losses: 1679931544-trainLosses.npy
		train AUC   : 1679931544-auc.npy
		train F1s   : 1679931544-trainF1s.npy
		train TPRs  : 1679931544-trainTPRs.npy
2023-03-27 17:44:05,888 WARNING  [!] Evaluating model on training set...
2023-03-27 17:44:13,339 WARNING  [!] This fold metrics on training set:
2023-03-27 17:44:13,421 WARNING 	AUC: 0.9998
2023-03-27 17:44:13,436 WARNING 	F1: 0.9804
2023-03-27 17:44:13,436 WARNING  [!] Evaluating model on validation set...
2023-03-27 17:44:17,171 WARNING  [!] This fold metrics on validation set:
2023-03-27 17:44:17,209 WARNING 	AUC: 0.9994
2023-03-27 17:44:17,215 WARNING 	F1: 0.9716
2023-03-27 17:44:17,489 WARNING  [3/3] Train set size: 25008, Validation set size: 12504
2023-03-27 17:44:18,715 WARNING  [!] Saved dataset splits to dataset_splits_1679931857.npz
2023-03-27 17:44:18,812 WARNING  [!] Iniatialized TransformerEncoderChunks. Total trainable parameters: 5.3979e6
2023-03-27 17:44:18,812 WARNING  [*] Training time budget set: 5.0 min
2023-03-27 17:44:18,828 WARNING  [*] Started epoch: 1
2023-03-27 17:44:18,964 WARNING  [*] 17:44:18: Train Epoch: 1 [  0  /25008 (0 %)] | Loss: 12.204796 | Elapsed: 0.14s
2023-03-27 17:44:29,877 WARNING  [*] 17:44:29: Train Epoch: 1 [9600 /25008 (38%)] | Loss: 1.217153 | Elapsed: 10.91s
2023-03-27 17:44:40,550 WARNING  [*] 17:44:40: Train Epoch: 1 [19200/25008 (77%)] | Loss: 1.010811 | Elapsed: 10.67s
2023-03-27 17:44:47,232 WARNING  [*] Mon Mar 27 17:44:47 2023:    1    | Tr.loss: 1.431862 | Elapsed:   28.40  s
2023-03-27 17:44:47,233 WARNING  [*] Started epoch: 2
2023-03-27 17:44:47,354 WARNING  [*] 17:44:47: Train Epoch: 2 [  0  /25008 (0 %)] | Loss: 1.029362 | Elapsed: 0.12s
2023-03-27 17:44:58,710 WARNING  [*] 17:44:58: Train Epoch: 2 [9600 /25008 (38%)] | Loss: 0.658682 | Elapsed: 11.36s
2023-03-27 17:45:10,490 WARNING  [*] 17:45:10: Train Epoch: 2 [19200/25008 (77%)] | Loss: 0.525489 | Elapsed: 11.78s
2023-03-27 17:45:17,732 WARNING  [*] Mon Mar 27 17:45:17 2023:    2    | Tr.loss: 0.806896 | Elapsed:   30.50  s
2023-03-27 17:45:17,733 WARNING  [*] Started epoch: 3
2023-03-27 17:45:17,852 WARNING  [*] 17:45:17: Train Epoch: 3 [  0  /25008 (0 %)] | Loss: 0.640211 | Elapsed: 0.12s
2023-03-27 17:45:29,956 WARNING  [*] 17:45:29: Train Epoch: 3 [9600 /25008 (38%)] | Loss: 0.596719 | Elapsed: 12.10s
2023-03-27 17:45:41,636 WARNING  [*] 17:45:41: Train Epoch: 3 [19200/25008 (77%)] | Loss: 0.461929 | Elapsed: 11.68s
2023-03-27 17:45:48,552 WARNING  [*] Mon Mar 27 17:45:48 2023:    3    | Tr.loss: 0.544893 | Elapsed:   30.82  s
2023-03-27 17:45:48,553 WARNING  [*] Started epoch: 4
2023-03-27 17:45:48,665 WARNING  [*] 17:45:48: Train Epoch: 4 [  0  /25008 (0 %)] | Loss: 0.661073 | Elapsed: 0.11s
2023-03-27 17:46:00,646 WARNING  [*] 17:46:00: Train Epoch: 4 [9600 /25008 (38%)] | Loss: 0.340583 | Elapsed: 11.98s
2023-03-27 17:46:11,602 WARNING  [*] 17:46:11: Train Epoch: 4 [19200/25008 (77%)] | Loss: 0.230902 | Elapsed: 10.96s
2023-03-27 17:46:17,897 WARNING  [*] Mon Mar 27 17:46:17 2023:    4    | Tr.loss: 0.378442 | Elapsed:   29.34  s
2023-03-27 17:46:17,897 WARNING  [*] Started epoch: 5
2023-03-27 17:46:18,019 WARNING  [*] 17:46:18: Train Epoch: 5 [  0  /25008 (0 %)] | Loss: 0.381760 | Elapsed: 0.12s
2023-03-27 17:46:28,575 WARNING  [*] 17:46:28: Train Epoch: 5 [9600 /25008 (38%)] | Loss: 0.297608 | Elapsed: 10.56s
2023-03-27 17:46:39,164 WARNING  [*] 17:46:39: Train Epoch: 5 [19200/25008 (77%)] | Loss: 0.127963 | Elapsed: 10.59s
2023-03-27 17:46:45,458 WARNING  [*] Mon Mar 27 17:46:45 2023:    5    | Tr.loss: 0.254455 | Elapsed:   27.56  s
2023-03-27 17:46:45,458 WARNING  [*] Started epoch: 6
2023-03-27 17:46:45,579 WARNING  [*] 17:46:45: Train Epoch: 6 [  0  /25008 (0 %)] | Loss: 0.122889 | Elapsed: 0.12s
2023-03-27 17:46:56,025 WARNING  [*] 17:46:56: Train Epoch: 6 [9600 /25008 (38%)] | Loss: 0.088258 | Elapsed: 10.45s
2023-03-27 17:47:06,610 WARNING  [*] 17:47:06: Train Epoch: 6 [19200/25008 (77%)] | Loss: 0.162931 | Elapsed: 10.58s
2023-03-27 17:47:12,871 WARNING  [*] Mon Mar 27 17:47:12 2023:    6    | Tr.loss: 0.178117 | Elapsed:   27.41  s
2023-03-27 17:47:12,871 WARNING  [*] Started epoch: 7
2023-03-27 17:47:13,006 WARNING  [*] 17:47:13: Train Epoch: 7 [  0  /25008 (0 %)] | Loss: 0.168937 | Elapsed: 0.14s
2023-03-27 17:47:23,913 WARNING  [*] 17:47:23: Train Epoch: 7 [9600 /25008 (38%)] | Loss: 0.177850 | Elapsed: 10.91s
2023-03-27 17:47:35,020 WARNING  [*] 17:47:35: Train Epoch: 7 [19200/25008 (77%)] | Loss: 0.183286 | Elapsed: 11.11s
2023-03-27 17:47:41,792 WARNING  [*] Mon Mar 27 17:47:41 2023:    7    | Tr.loss: 0.140136 | Elapsed:   28.92  s
2023-03-27 17:47:41,792 WARNING  [*] Started epoch: 8
2023-03-27 17:47:41,913 WARNING  [*] 17:47:41: Train Epoch: 8 [  0  /25008 (0 %)] | Loss: 0.149061 | Elapsed: 0.12s
2023-03-27 17:47:53,284 WARNING  [*] 17:47:53: Train Epoch: 8 [9600 /25008 (38%)] | Loss: 0.142834 | Elapsed: 11.37s
2023-03-27 17:48:04,999 WARNING  [*] 17:48:04: Train Epoch: 8 [19200/25008 (77%)] | Loss: 0.074663 | Elapsed: 11.71s
2023-03-27 17:48:11,891 WARNING  [*] Mon Mar 27 17:48:11 2023:    8    | Tr.loss: 0.117608 | Elapsed:   30.10  s
2023-03-27 17:48:11,891 WARNING  [*] Started epoch: 9
2023-03-27 17:48:12,005 WARNING  [*] 17:48:12: Train Epoch: 9 [  0  /25008 (0 %)] | Loss: 0.067727 | Elapsed: 0.11s
2023-03-27 17:48:23,323 WARNING  [*] 17:48:23: Train Epoch: 9 [9600 /25008 (38%)] | Loss: 0.053191 | Elapsed: 11.32s
2023-03-27 17:48:34,940 WARNING  [*] 17:48:34: Train Epoch: 9 [19200/25008 (77%)] | Loss: 0.273889 | Elapsed: 11.62s
2023-03-27 17:48:41,730 WARNING  [*] Mon Mar 27 17:48:41 2023:    9    | Tr.loss: 0.098783 | Elapsed:   29.84  s
2023-03-27 17:48:41,730 WARNING  [*] Started epoch: 10
2023-03-27 17:48:41,849 WARNING  [*] 17:48:41: Train Epoch: 10 [  0  /25008 (0 %)] | Loss: 0.193001 | Elapsed: 0.12s
2023-03-27 17:48:52,556 WARNING  [*] 17:48:52: Train Epoch: 10 [9600 /25008 (38%)] | Loss: 0.083269 | Elapsed: 10.71s
2023-03-27 17:49:03,516 WARNING  [*] 17:49:03: Train Epoch: 10 [19200/25008 (77%)] | Loss: 0.090458 | Elapsed: 10.96s
2023-03-27 17:49:10,359 WARNING  [*] Mon Mar 27 17:49:10 2023:   10    | Tr.loss: 0.087329 | Elapsed:   28.63  s
2023-03-27 17:49:10,360 WARNING  [*] Started epoch: 11
2023-03-27 17:49:10,479 WARNING  [*] 17:49:10: Train Epoch: 11 [  0  /25008 (0 %)] | Loss: 0.120593 | Elapsed: 0.12s
2023-03-27 17:49:18,849 WARNING  [!] Time budget exceeded, training stopped.
2023-03-27 17:49:18,896 WARNING  [!] Mon Mar 27 17:49:18 2023: Dumped results:
                model       : 1679931857-model.torch
		train time  : 1679931857-trainTime.npy
		train losses: 1679931857-trainLosses.npy
		train AUC   : 1679931857-auc.npy
		train F1s   : 1679931857-trainF1s.npy
		train TPRs  : 1679931857-trainTPRs.npy
2023-03-27 17:49:18,914 WARNING  [!] Evaluating model on training set...
2023-03-27 17:49:26,052 WARNING  [!] This fold metrics on training set:
2023-03-27 17:49:26,102 WARNING 	AUC: 0.9997
2023-03-27 17:49:26,111 WARNING 	F1: 0.9775
2023-03-27 17:49:26,112 WARNING  [!] Evaluating model on validation set...
2023-03-27 17:49:29,676 WARNING  [!] This fold metrics on validation set:
2023-03-27 17:49:29,704 WARNING 	AUC: 0.9991
2023-03-27 17:49:29,709 WARNING 	F1: 0.9622
2023-03-27 17:49:29,951 WARNING  [!] Metrics saved to out_avast_multiclass_1679929442\cv_nebula_bpe_limNone_r1763_t5\nebula_bpe_metrics_validation.json
2023-03-27 17:49:29,956 WARNING  [!] Metrics saved to out_avast_multiclass_1679929442\cv_nebula_bpe_limNone_r1763_t5\nebula_bpe_metrics_training.json
2023-03-27 17:49:29,956 WARNING  [!] Average epoch time: 0.03s | Mean values over 3 folds:
	AUC: 0.9993

2023-03-27 17:49:30,165 WARNING  [!!!] Starting CV over nebula_wht!
2023-03-27 17:49:30,232 WARNING  [!] Training time budget: 300min
2023-03-27 17:49:30,233 WARNING  [!] Model config: {'vocab_size': 37018, 'maxlen': 512, 'chunk_size': 64, 'dModel': 64, 'nHeads': 8, 'dHidden': 256, 'nLayers': 2, 'numClasses': 10, 'hiddenNeurons': [64], 'layerNorm': False, 'dropout': 0.3, 'mean_over_sequence': False, 'norm_first': True}
2023-03-27 17:49:30,270 WARNING  [1/3] Train set size: 25008, Validation set size: 12504
2023-03-27 17:49:31,545 WARNING  [!] Saved dataset splits to dataset_splits_1679932170.npz
2023-03-27 17:49:31,618 WARNING  [!] Iniatialized TransformerEncoderChunks. Total trainable parameters: 4.5670e6
2023-03-27 17:49:31,618 WARNING  [*] Training time budget set: 5.0 min
2023-03-27 17:49:31,633 WARNING  [*] Started epoch: 1
2023-03-27 17:49:31,843 WARNING  [*] 17:49:31: Train Epoch: 1 [  0  /25008 (0 %)] | Loss: 7.643339 | Elapsed: 0.21s
2023-03-27 17:49:42,216 WARNING  [*] 17:49:42: Train Epoch: 1 [9600 /25008 (38%)] | Loss: 1.407887 | Elapsed: 10.37s
2023-03-27 17:49:52,728 WARNING  [*] 17:49:52: Train Epoch: 1 [19200/25008 (77%)] | Loss: 1.102419 | Elapsed: 10.51s
2023-03-27 17:49:59,067 WARNING  [*] Mon Mar 27 17:49:59 2023:    1    | Tr.loss: 1.366879 | Elapsed:   27.43  s
2023-03-27 17:49:59,067 WARNING  [*] Started epoch: 2
2023-03-27 17:49:59,169 WARNING  [*] 17:49:59: Train Epoch: 2 [  0  /25008 (0 %)] | Loss: 0.874013 | Elapsed: 0.10s
2023-03-27 17:50:09,568 WARNING  [*] 17:50:09: Train Epoch: 2 [9600 /25008 (38%)] | Loss: 0.934276 | Elapsed: 10.38s
2023-03-27 17:50:20,136 WARNING  [*] 17:50:20: Train Epoch: 2 [19200/25008 (77%)] | Loss: 0.562839 | Elapsed: 10.57s
2023-03-27 17:50:27,603 WARNING  [*] Mon Mar 27 17:50:27 2023:    2    | Tr.loss: 0.745277 | Elapsed:   28.54  s
2023-03-27 17:50:27,603 WARNING  [*] Started epoch: 3
2023-03-27 17:50:27,727 WARNING  [*] 17:50:27: Train Epoch: 3 [  0  /25008 (0 %)] | Loss: 0.529985 | Elapsed: 0.12s
2023-03-27 17:50:38,207 WARNING  [*] 17:50:38: Train Epoch: 3 [9600 /25008 (38%)] | Loss: 0.494715 | Elapsed: 10.48s
2023-03-27 17:50:48,366 WARNING  [*] 17:50:48: Train Epoch: 3 [19200/25008 (77%)] | Loss: 0.628391 | Elapsed: 10.16s
2023-03-27 17:50:54,321 WARNING  [*] Mon Mar 27 17:50:54 2023:    3    | Tr.loss: 0.477077 | Elapsed:   26.72  s
2023-03-27 17:50:54,321 WARNING  [*] Started epoch: 4
2023-03-27 17:50:54,417 WARNING  [*] 17:50:54: Train Epoch: 4 [  0  /25008 (0 %)] | Loss: 0.373052 | Elapsed: 0.10s
2023-03-27 17:51:04,563 WARNING  [*] 17:51:04: Train Epoch: 4 [9600 /25008 (38%)] | Loss: 0.323226 | Elapsed: 10.15s
2023-03-27 17:51:14,940 WARNING  [*] 17:51:14: Train Epoch: 4 [19200/25008 (77%)] | Loss: 0.168110 | Elapsed: 10.38s
2023-03-27 17:51:20,983 WARNING  [*] Mon Mar 27 17:51:20 2023:    4    | Tr.loss: 0.316552 | Elapsed:   26.66  s
2023-03-27 17:51:20,999 WARNING  [*] Started epoch: 5
2023-03-27 17:51:21,102 WARNING  [*] 17:51:21: Train Epoch: 5 [  0  /25008 (0 %)] | Loss: 0.303364 | Elapsed: 0.10s
2023-03-27 17:51:31,238 WARNING  [*] 17:51:31: Train Epoch: 5 [9600 /25008 (38%)] | Loss: 0.247882 | Elapsed: 10.14s
2023-03-27 17:51:41,445 WARNING  [*] 17:51:41: Train Epoch: 5 [19200/25008 (77%)] | Loss: 0.290059 | Elapsed: 10.21s
2023-03-27 17:51:47,495 WARNING  [*] Mon Mar 27 17:51:47 2023:    5    | Tr.loss: 0.202290 | Elapsed:   26.50  s
2023-03-27 17:51:47,495 WARNING  [*] Started epoch: 6
2023-03-27 17:51:47,608 WARNING  [*] 17:51:47: Train Epoch: 6 [  0  /25008 (0 %)] | Loss: 0.088223 | Elapsed: 0.11s
2023-03-27 17:51:57,718 WARNING  [*] 17:51:57: Train Epoch: 6 [9600 /25008 (38%)] | Loss: 0.173960 | Elapsed: 10.11s
2023-03-27 17:52:07,828 WARNING  [*] 17:52:07: Train Epoch: 6 [19200/25008 (77%)] | Loss: 0.121590 | Elapsed: 10.11s
2023-03-27 17:52:13,842 WARNING  [*] Mon Mar 27 17:52:13 2023:    6    | Tr.loss: 0.147479 | Elapsed:   26.35  s
2023-03-27 17:52:13,842 WARNING  [*] Started epoch: 7
2023-03-27 17:52:13,948 WARNING  [*] 17:52:13: Train Epoch: 7 [  0  /25008 (0 %)] | Loss: 0.067616 | Elapsed: 0.11s
2023-03-27 17:52:24,023 WARNING  [*] 17:52:24: Train Epoch: 7 [9600 /25008 (38%)] | Loss: 0.276843 | Elapsed: 10.07s
2023-03-27 17:52:34,158 WARNING  [*] 17:52:34: Train Epoch: 7 [19200/25008 (77%)] | Loss: 0.191872 | Elapsed: 10.14s
2023-03-27 17:52:40,156 WARNING  [*] Mon Mar 27 17:52:40 2023:    7    | Tr.loss: 0.117140 | Elapsed:   26.31  s
2023-03-27 17:52:40,156 WARNING  [*] Started epoch: 8
2023-03-27 17:52:40,272 WARNING  [*] 17:52:40: Train Epoch: 8 [  0  /25008 (0 %)] | Loss: 0.018502 | Elapsed: 0.10s
2023-03-27 17:52:50,340 WARNING  [*] 17:52:50: Train Epoch: 8 [9600 /25008 (38%)] | Loss: 0.106961 | Elapsed: 10.07s
2023-03-27 17:53:00,667 WARNING  [*] 17:53:00: Train Epoch: 8 [19200/25008 (77%)] | Loss: 0.091488 | Elapsed: 10.33s
2023-03-27 17:53:06,868 WARNING  [*] Mon Mar 27 17:53:06 2023:    8    | Tr.loss: 0.096789 | Elapsed:   26.71  s
2023-03-27 17:53:06,868 WARNING  [*] Started epoch: 9
2023-03-27 17:53:06,980 WARNING  [*] 17:53:06: Train Epoch: 9 [  0  /25008 (0 %)] | Loss: 0.072034 | Elapsed: 0.11s
2023-03-27 17:53:17,120 WARNING  [*] 17:53:17: Train Epoch: 9 [9600 /25008 (38%)] | Loss: 0.038327 | Elapsed: 10.14s
2023-03-27 17:53:27,167 WARNING  [*] 17:53:27: Train Epoch: 9 [19200/25008 (77%)] | Loss: 0.101166 | Elapsed: 10.05s
2023-03-27 17:53:33,184 WARNING  [*] Mon Mar 27 17:53:33 2023:    9    | Tr.loss: 0.084421 | Elapsed:   26.32  s
2023-03-27 17:53:33,184 WARNING  [*] Started epoch: 10
2023-03-27 17:53:33,288 WARNING  [*] 17:53:33: Train Epoch: 10 [  0  /25008 (0 %)] | Loss: 0.081331 | Elapsed: 0.10s
2023-03-27 17:53:43,346 WARNING  [*] 17:53:43: Train Epoch: 10 [9600 /25008 (38%)] | Loss: 0.047751 | Elapsed: 10.06s
2023-03-27 17:53:53,395 WARNING  [*] 17:53:53: Train Epoch: 10 [19200/25008 (77%)] | Loss: 0.137675 | Elapsed: 10.05s
2023-03-27 17:53:59,401 WARNING  [*] Mon Mar 27 17:53:59 2023:   10    | Tr.loss: 0.073903 | Elapsed:   26.22  s
2023-03-27 17:53:59,401 WARNING  [*] Started epoch: 11
2023-03-27 17:53:59,511 WARNING  [*] 17:53:59: Train Epoch: 11 [  0  /25008 (0 %)] | Loss: 0.056748 | Elapsed: 0.11s
2023-03-27 17:54:09,557 WARNING  [*] 17:54:09: Train Epoch: 11 [9600 /25008 (38%)] | Loss: 0.017801 | Elapsed: 10.05s
2023-03-27 17:54:19,639 WARNING  [*] 17:54:19: Train Epoch: 11 [19200/25008 (77%)] | Loss: 0.187262 | Elapsed: 10.08s
2023-03-27 17:54:25,634 WARNING  [*] Mon Mar 27 17:54:25 2023:   11    | Tr.loss: 0.065703 | Elapsed:   26.23  s
2023-03-27 17:54:25,634 WARNING  [*] Started epoch: 12
2023-03-27 17:54:25,747 WARNING  [*] 17:54:25: Train Epoch: 12 [  0  /25008 (0 %)] | Loss: 0.057900 | Elapsed: 0.11s
2023-03-27 17:54:31,678 WARNING  [!] Time budget exceeded, training stopped.
2023-03-27 17:54:31,718 WARNING  [!] Mon Mar 27 17:54:31 2023: Dumped results:
                model       : 1679932170-model.torch
		train time  : 1679932170-trainTime.npy
		train losses: 1679932170-trainLosses.npy
		train AUC   : 1679932170-auc.npy
		train F1s   : 1679932170-trainF1s.npy
		train TPRs  : 1679932170-trainTPRs.npy
2023-03-27 17:54:31,731 WARNING  [!] Evaluating model on training set...
2023-03-27 17:54:38,450 WARNING  [!] This fold metrics on training set:
2023-03-27 17:54:38,497 WARNING 	AUC: 0.9997
2023-03-27 17:54:38,505 WARNING 	F1: 0.9826
2023-03-27 17:54:38,506 WARNING  [!] Evaluating model on validation set...
2023-03-27 17:54:41,864 WARNING  [!] This fold metrics on validation set:
2023-03-27 17:54:41,884 WARNING 	AUC: 0.9992
2023-03-27 17:54:41,898 WARNING 	F1: 0.9719
2023-03-27 17:54:42,137 WARNING  [2/3] Train set size: 25008, Validation set size: 12504
2023-03-27 17:54:43,476 WARNING  [!] Saved dataset splits to dataset_splits_1679932482.npz
2023-03-27 17:54:43,537 WARNING  [!] Iniatialized TransformerEncoderChunks. Total trainable parameters: 4.5670e6
2023-03-27 17:54:43,538 WARNING  [*] Training time budget set: 5.0 min
2023-03-27 17:54:43,548 WARNING  [*] Started epoch: 1
2023-03-27 17:54:43,655 WARNING  [*] 17:54:43: Train Epoch: 1 [  0  /25008 (0 %)] | Loss: 10.197890 | Elapsed: 0.11s
2023-03-27 17:54:53,756 WARNING  [*] 17:54:53: Train Epoch: 1 [9600 /25008 (38%)] | Loss: 1.425501 | Elapsed: 10.10s
2023-03-27 17:55:03,829 WARNING  [*] 17:55:03: Train Epoch: 1 [19200/25008 (77%)] | Loss: 1.089792 | Elapsed: 10.07s
2023-03-27 17:55:09,879 WARNING  [*] Mon Mar 27 17:55:09 2023:    1    | Tr.loss: 1.446754 | Elapsed:   26.33  s
2023-03-27 17:55:09,879 WARNING  [*] Started epoch: 2
2023-03-27 17:55:09,986 WARNING  [*] 17:55:09: Train Epoch: 2 [  0  /25008 (0 %)] | Loss: 0.704418 | Elapsed: 0.11s
2023-03-27 17:55:20,019 WARNING  [*] 17:55:20: Train Epoch: 2 [9600 /25008 (38%)] | Loss: 0.819301 | Elapsed: 10.03s
2023-03-27 17:55:30,066 WARNING  [*] 17:55:30: Train Epoch: 2 [19200/25008 (77%)] | Loss: 0.579947 | Elapsed: 10.05s
2023-03-27 17:55:36,059 WARNING  [*] Mon Mar 27 17:55:36 2023:    2    | Tr.loss: 0.739087 | Elapsed:   26.18  s
2023-03-27 17:55:36,059 WARNING  [*] Started epoch: 3
2023-03-27 17:55:36,166 WARNING  [*] 17:55:36: Train Epoch: 3 [  0  /25008 (0 %)] | Loss: 0.368516 | Elapsed: 0.11s
2023-03-27 17:55:46,193 WARNING  [*] 17:55:46: Train Epoch: 3 [9600 /25008 (38%)] | Loss: 0.322287 | Elapsed: 10.03s
2023-03-27 17:55:56,231 WARNING  [*] 17:55:56: Train Epoch: 3 [19200/25008 (77%)] | Loss: 0.480237 | Elapsed: 10.04s
2023-03-27 17:56:02,236 WARNING  [*] Mon Mar 27 17:56:02 2023:    3    | Tr.loss: 0.449987 | Elapsed:   26.18  s
2023-03-27 17:56:02,236 WARNING  [*] Started epoch: 4
2023-03-27 17:56:02,352 WARNING  [*] 17:56:02: Train Epoch: 4 [  0  /25008 (0 %)] | Loss: 0.361420 | Elapsed: 0.11s
2023-03-27 17:56:12,367 WARNING  [*] 17:56:12: Train Epoch: 4 [9600 /25008 (38%)] | Loss: 0.202835 | Elapsed: 10.02s
2023-03-27 17:56:22,614 WARNING  [*] 17:56:22: Train Epoch: 4 [19200/25008 (77%)] | Loss: 0.482137 | Elapsed: 10.25s
2023-03-27 17:56:28,615 WARNING  [*] Mon Mar 27 17:56:28 2023:    4    | Tr.loss: 0.304892 | Elapsed:   26.38  s
2023-03-27 17:56:28,615 WARNING  [*] Started epoch: 5
2023-03-27 17:56:28,720 WARNING  [*] 17:56:28: Train Epoch: 5 [  0  /25008 (0 %)] | Loss: 0.267075 | Elapsed: 0.10s
2023-03-27 17:56:38,763 WARNING  [*] 17:56:38: Train Epoch: 5 [9600 /25008 (38%)] | Loss: 0.184519 | Elapsed: 10.04s
2023-03-27 17:56:48,800 WARNING  [*] 17:56:48: Train Epoch: 5 [19200/25008 (77%)] | Loss: 0.161487 | Elapsed: 10.04s
2023-03-27 17:56:54,801 WARNING  [*] Mon Mar 27 17:56:54 2023:    5    | Tr.loss: 0.222265 | Elapsed:   26.19  s
2023-03-27 17:56:54,801 WARNING  [*] Started epoch: 6
2023-03-27 17:56:54,907 WARNING  [*] 17:56:54: Train Epoch: 6 [  0  /25008 (0 %)] | Loss: 0.208894 | Elapsed: 0.11s
2023-03-27 17:57:04,991 WARNING  [*] 17:57:04: Train Epoch: 6 [9600 /25008 (38%)] | Loss: 0.141029 | Elapsed: 10.08s
2023-03-27 17:57:15,074 WARNING  [*] 17:57:15: Train Epoch: 6 [19200/25008 (77%)] | Loss: 0.159679 | Elapsed: 10.08s
2023-03-27 17:57:21,069 WARNING  [*] Mon Mar 27 17:57:21 2023:    6    | Tr.loss: 0.165261 | Elapsed:   26.27  s
2023-03-27 17:57:21,069 WARNING  [*] Started epoch: 7
2023-03-27 17:57:21,186 WARNING  [*] 17:57:21: Train Epoch: 7 [  0  /25008 (0 %)] | Loss: 0.156340 | Elapsed: 0.12s
2023-03-27 17:57:31,260 WARNING  [*] 17:57:31: Train Epoch: 7 [9600 /25008 (38%)] | Loss: 0.174117 | Elapsed: 10.07s
2023-03-27 17:57:41,279 WARNING  [*] 17:57:41: Train Epoch: 7 [19200/25008 (77%)] | Loss: 0.092565 | Elapsed: 10.02s
2023-03-27 17:57:47,312 WARNING  [*] Mon Mar 27 17:57:47 2023:    7    | Tr.loss: 0.136044 | Elapsed:   26.24  s
2023-03-27 17:57:47,312 WARNING  [*] Started epoch: 8
2023-03-27 17:57:47,423 WARNING  [*] 17:57:47: Train Epoch: 8 [  0  /25008 (0 %)] | Loss: 0.308298 | Elapsed: 0.11s
2023-03-27 17:57:57,600 WARNING  [*] 17:57:57: Train Epoch: 8 [9600 /25008 (38%)] | Loss: 0.045722 | Elapsed: 10.18s
2023-03-27 17:58:08,071 WARNING  [*] 17:58:08: Train Epoch: 8 [19200/25008 (77%)] | Loss: 0.038534 | Elapsed: 10.47s
2023-03-27 17:58:14,186 WARNING  [*] Mon Mar 27 17:58:14 2023:    8    | Tr.loss: 0.112033 | Elapsed:   26.87  s
2023-03-27 17:58:14,186 WARNING  [*] Started epoch: 9
2023-03-27 17:58:14,301 WARNING  [*] 17:58:14: Train Epoch: 9 [  0  /25008 (0 %)] | Loss: 0.058320 | Elapsed: 0.12s
2023-03-27 17:58:24,453 WARNING  [*] 17:58:24: Train Epoch: 9 [9600 /25008 (38%)] | Loss: 0.262948 | Elapsed: 10.15s
2023-03-27 17:58:34,610 WARNING  [*] 17:58:34: Train Epoch: 9 [19200/25008 (77%)] | Loss: 0.110793 | Elapsed: 10.16s
2023-03-27 17:58:40,684 WARNING  [*] Mon Mar 27 17:58:40 2023:    9    | Tr.loss: 0.102153 | Elapsed:   26.50  s
2023-03-27 17:58:40,684 WARNING  [*] Started epoch: 10
2023-03-27 17:58:40,795 WARNING  [*] 17:58:40: Train Epoch: 10 [  0  /25008 (0 %)] | Loss: 0.055379 | Elapsed: 0.11s
2023-03-27 17:58:50,954 WARNING  [*] 17:58:50: Train Epoch: 10 [9600 /25008 (38%)] | Loss: 0.049660 | Elapsed: 10.16s
2023-03-27 17:59:01,115 WARNING  [*] 17:59:01: Train Epoch: 10 [19200/25008 (77%)] | Loss: 0.096208 | Elapsed: 10.16s
2023-03-27 17:59:07,202 WARNING  [*] Mon Mar 27 17:59:07 2023:   10    | Tr.loss: 0.082424 | Elapsed:   26.52  s
2023-03-27 17:59:07,202 WARNING  [*] Started epoch: 11
2023-03-27 17:59:07,306 WARNING  [*] 17:59:07: Train Epoch: 11 [  0  /25008 (0 %)] | Loss: 0.014233 | Elapsed: 0.10s
2023-03-27 17:59:17,476 WARNING  [*] 17:59:17: Train Epoch: 11 [9600 /25008 (38%)] | Loss: 0.030027 | Elapsed: 10.17s
2023-03-27 17:59:27,666 WARNING  [*] 17:59:27: Train Epoch: 11 [19200/25008 (77%)] | Loss: 0.030150 | Elapsed: 10.19s
2023-03-27 17:59:33,733 WARNING  [*] Mon Mar 27 17:59:33 2023:   11    | Tr.loss: 0.072784 | Elapsed:   26.53  s
2023-03-27 17:59:33,733 WARNING  [*] Started epoch: 12
2023-03-27 17:59:33,845 WARNING  [*] 17:59:33: Train Epoch: 12 [  0  /25008 (0 %)] | Loss: 0.099858 | Elapsed: 0.11s
2023-03-27 17:59:43,559 WARNING  [!] Time budget exceeded, training stopped.
2023-03-27 17:59:43,596 WARNING  [!] Mon Mar 27 17:59:43 2023: Dumped results:
                model       : 1679932482-model.torch
		train time  : 1679932482-trainTime.npy
		train losses: 1679932482-trainLosses.npy
		train AUC   : 1679932482-auc.npy
		train F1s   : 1679932482-trainF1s.npy
		train TPRs  : 1679932482-trainTPRs.npy
2023-03-27 17:59:43,612 WARNING  [!] Evaluating model on training set...
2023-03-27 17:59:50,329 WARNING  [!] This fold metrics on training set:
2023-03-27 17:59:50,368 WARNING 	AUC: 0.9997
2023-03-27 17:59:50,383 WARNING 	F1: 0.9784
2023-03-27 17:59:50,383 WARNING  [!] Evaluating model on validation set...
2023-03-27 17:59:53,731 WARNING  [!] This fold metrics on validation set:
2023-03-27 17:59:53,755 WARNING 	AUC: 0.9993
2023-03-27 17:59:53,772 WARNING 	F1: 0.9683
2023-03-27 17:59:54,022 WARNING  [3/3] Train set size: 25008, Validation set size: 12504
2023-03-27 17:59:55,440 WARNING  [!] Saved dataset splits to dataset_splits_1679932793.npz
2023-03-27 17:59:55,536 WARNING  [!] Iniatialized TransformerEncoderChunks. Total trainable parameters: 4.5670e6
2023-03-27 17:59:55,536 WARNING  [*] Training time budget set: 5.0 min
2023-03-27 17:59:55,538 WARNING  [*] Started epoch: 1
2023-03-27 17:59:55,689 WARNING  [*] 17:59:55: Train Epoch: 1 [  0  /25008 (0 %)] | Loss: 7.682115 | Elapsed: 0.15s
2023-03-27 18:00:05,849 WARNING  [*] 18:00:05: Train Epoch: 1 [9600 /25008 (38%)] | Loss: 1.043932 | Elapsed: 10.16s
2023-03-27 18:00:15,968 WARNING  [*] 18:00:15: Train Epoch: 1 [19200/25008 (77%)] | Loss: 0.820393 | Elapsed: 10.12s
2023-03-27 18:00:22,071 WARNING  [*] Mon Mar 27 18:00:22 2023:    1    | Tr.loss: 1.432950 | Elapsed:   26.53  s
2023-03-27 18:00:22,071 WARNING  [*] Started epoch: 2
2023-03-27 18:00:22,187 WARNING  [*] 18:00:22: Train Epoch: 2 [  0  /25008 (0 %)] | Loss: 0.903111 | Elapsed: 0.12s
2023-03-27 18:00:32,347 WARNING  [*] 18:00:32: Train Epoch: 2 [9600 /25008 (38%)] | Loss: 0.637171 | Elapsed: 10.16s
2023-03-27 18:00:42,465 WARNING  [*] 18:00:42: Train Epoch: 2 [19200/25008 (77%)] | Loss: 0.714572 | Elapsed: 10.12s
2023-03-27 18:00:48,524 WARNING  [*] Mon Mar 27 18:00:48 2023:    2    | Tr.loss: 0.706824 | Elapsed:   26.45  s
2023-03-27 18:00:48,524 WARNING  [*] Started epoch: 3
2023-03-27 18:00:48,640 WARNING  [*] 18:00:48: Train Epoch: 3 [  0  /25008 (0 %)] | Loss: 0.639883 | Elapsed: 0.12s
2023-03-27 18:00:58,741 WARNING  [*] 18:00:58: Train Epoch: 3 [9600 /25008 (38%)] | Loss: 0.517786 | Elapsed: 10.10s
2023-03-27 18:01:08,883 WARNING  [*] 18:01:08: Train Epoch: 3 [19200/25008 (77%)] | Loss: 0.372496 | Elapsed: 10.14s
2023-03-27 18:01:14,881 WARNING  [*] Mon Mar 27 18:01:14 2023:    3    | Tr.loss: 0.442417 | Elapsed:   26.36  s
2023-03-27 18:01:14,881 WARNING  [*] Started epoch: 4
2023-03-27 18:01:14,995 WARNING  [*] 18:01:14: Train Epoch: 4 [  0  /25008 (0 %)] | Loss: 0.359011 | Elapsed: 0.11s
2023-03-27 18:01:25,287 WARNING  [*] 18:01:25: Train Epoch: 4 [9600 /25008 (38%)] | Loss: 0.311604 | Elapsed: 10.29s
2023-03-27 18:01:35,553 WARNING  [*] 18:01:35: Train Epoch: 4 [19200/25008 (77%)] | Loss: 0.159679 | Elapsed: 10.27s
2023-03-27 18:01:41,572 WARNING  [*] Mon Mar 27 18:01:41 2023:    4    | Tr.loss: 0.290643 | Elapsed:   26.69  s
2023-03-27 18:01:41,572 WARNING  [*] Started epoch: 5
2023-03-27 18:01:41,672 WARNING  [*] 18:01:41: Train Epoch: 5 [  0  /25008 (0 %)] | Loss: 0.083644 | Elapsed: 0.10s
2023-03-27 18:01:51,722 WARNING  [*] 18:01:51: Train Epoch: 5 [9600 /25008 (38%)] | Loss: 0.275128 | Elapsed: 10.05s
2023-03-27 18:02:02,212 WARNING  [*] 18:02:02: Train Epoch: 5 [19200/25008 (77%)] | Loss: 0.266719 | Elapsed: 10.49s
2023-03-27 18:02:08,314 WARNING  [*] Mon Mar 27 18:02:08 2023:    5    | Tr.loss: 0.194058 | Elapsed:   26.74  s
2023-03-27 18:02:08,314 WARNING  [*] Started epoch: 6
2023-03-27 18:02:08,445 WARNING  [*] 18:02:08: Train Epoch: 6 [  0  /25008 (0 %)] | Loss: 0.183210 | Elapsed: 0.13s
2023-03-27 18:02:18,629 WARNING  [*] 18:02:18: Train Epoch: 6 [9600 /25008 (38%)] | Loss: 0.120477 | Elapsed: 10.18s
2023-03-27 18:02:28,866 WARNING  [*] 18:02:28: Train Epoch: 6 [19200/25008 (77%)] | Loss: 0.083793 | Elapsed: 10.24s
2023-03-27 18:02:34,931 WARNING  [*] Mon Mar 27 18:02:34 2023:    6    | Tr.loss: 0.145045 | Elapsed:   26.62  s
2023-03-27 18:02:34,931 WARNING  [*] Started epoch: 7
2023-03-27 18:02:35,035 WARNING  [*] 18:02:35: Train Epoch: 7 [  0  /25008 (0 %)] | Loss: 0.164859 | Elapsed: 0.10s
2023-03-27 18:02:45,115 WARNING  [*] 18:02:45: Train Epoch: 7 [9600 /25008 (38%)] | Loss: 0.095072 | Elapsed: 10.08s
2023-03-27 18:02:55,201 WARNING  [*] 18:02:55: Train Epoch: 7 [19200/25008 (77%)] | Loss: 0.189477 | Elapsed: 10.09s
2023-03-27 18:03:01,275 WARNING  [*] Mon Mar 27 18:03:01 2023:    7    | Tr.loss: 0.115701 | Elapsed:   26.34  s
2023-03-27 18:03:01,275 WARNING  [*] Started epoch: 8
2023-03-27 18:03:01,381 WARNING  [*] 18:03:01: Train Epoch: 8 [  0  /25008 (0 %)] | Loss: 0.161958 | Elapsed: 0.11s
2023-03-27 18:03:11,477 WARNING  [*] 18:03:11: Train Epoch: 8 [9600 /25008 (38%)] | Loss: 0.092088 | Elapsed: 10.10s
2023-03-27 18:03:21,775 WARNING  [*] 18:03:21: Train Epoch: 8 [19200/25008 (77%)] | Loss: 0.025335 | Elapsed: 10.30s
2023-03-27 18:03:27,790 WARNING  [*] Mon Mar 27 18:03:27 2023:    8    | Tr.loss: 0.099385 | Elapsed:   26.52  s
2023-03-27 18:03:27,790 WARNING  [*] Started epoch: 9
2023-03-27 18:03:27,899 WARNING  [*] 18:03:27: Train Epoch: 9 [  0  /25008 (0 %)] | Loss: 0.274367 | Elapsed: 0.11s
2023-03-27 18:03:37,983 WARNING  [*] 18:03:37: Train Epoch: 9 [9600 /25008 (38%)] | Loss: 0.056784 | Elapsed: 10.08s
2023-03-27 18:03:48,043 WARNING  [*] 18:03:48: Train Epoch: 9 [19200/25008 (77%)] | Loss: 0.053288 | Elapsed: 10.06s
2023-03-27 18:03:54,066 WARNING  [*] Mon Mar 27 18:03:54 2023:    9    | Tr.loss: 0.091380 | Elapsed:   26.28  s
2023-03-27 18:03:54,066 WARNING  [*] Started epoch: 10
2023-03-27 18:03:54,177 WARNING  [*] 18:03:54: Train Epoch: 10 [  0  /25008 (0 %)] | Loss: 0.072962 | Elapsed: 0.11s
2023-03-27 18:04:04,247 WARNING  [*] 18:04:04: Train Epoch: 10 [9600 /25008 (38%)] | Loss: 0.047705 | Elapsed: 10.07s
2023-03-27 18:04:14,360 WARNING  [*] 18:04:14: Train Epoch: 10 [19200/25008 (77%)] | Loss: 0.121786 | Elapsed: 10.11s
2023-03-27 18:04:20,361 WARNING  [*] Mon Mar 27 18:04:20 2023:   10    | Tr.loss: 0.074151 | Elapsed:   26.30  s
2023-03-27 18:04:20,361 WARNING  [*] Started epoch: 11
2023-03-27 18:04:20,467 WARNING  [*] 18:04:20: Train Epoch: 11 [  0  /25008 (0 %)] | Loss: 0.089817 | Elapsed: 0.11s
2023-03-27 18:04:30,546 WARNING  [*] 18:04:30: Train Epoch: 11 [9600 /25008 (38%)] | Loss: 0.056180 | Elapsed: 10.08s
2023-03-27 18:04:40,606 WARNING  [*] 18:04:40: Train Epoch: 11 [19200/25008 (77%)] | Loss: 0.055012 | Elapsed: 10.06s
2023-03-27 18:04:46,615 WARNING  [*] Mon Mar 27 18:04:46 2023:   11    | Tr.loss: 0.070631 | Elapsed:   26.25  s
2023-03-27 18:04:46,615 WARNING  [*] Started epoch: 12
2023-03-27 18:04:46,726 WARNING  [*] 18:04:46: Train Epoch: 12 [  0  /25008 (0 %)] | Loss: 0.151977 | Elapsed: 0.11s
2023-03-27 18:04:55,631 WARNING  [!] Time budget exceeded, training stopped.
2023-03-27 18:04:55,672 WARNING  [!] Mon Mar 27 18:04:55 2023: Dumped results:
                model       : 1679932793-model.torch
		train time  : 1679932793-trainTime.npy
		train losses: 1679932793-trainLosses.npy
		train AUC   : 1679932793-auc.npy
		train F1s   : 1679932793-trainF1s.npy
		train TPRs  : 1679932793-trainTPRs.npy
2023-03-27 18:04:55,679 WARNING  [!] Evaluating model on training set...
2023-03-27 18:05:02,369 WARNING  [!] This fold metrics on training set:
2023-03-27 18:05:02,424 WARNING 	AUC: 0.9998
2023-03-27 18:05:02,428 WARNING 	F1: 0.9834
2023-03-27 18:05:02,428 WARNING  [!] Evaluating model on validation set...
2023-03-27 18:05:05,787 WARNING  [!] This fold metrics on validation set:
2023-03-27 18:05:05,797 WARNING 	AUC: 0.9992
2023-03-27 18:05:05,817 WARNING 	F1: 0.9776
2023-03-27 18:05:06,025 WARNING  [!] Metrics saved to out_avast_multiclass_1679929442\cv_nebula_wht_limNone_r1763_t5\nebula_wht_metrics_validation.json
2023-03-27 18:05:06,025 WARNING  [!] Metrics saved to out_avast_multiclass_1679929442\cv_nebula_wht_limNone_r1763_t5\nebula_wht_metrics_training.json
2023-03-27 18:05:06,036 WARNING  [!] Average epoch time: 0.03s | Mean values over 3 folds:
	AUC: 0.9992

