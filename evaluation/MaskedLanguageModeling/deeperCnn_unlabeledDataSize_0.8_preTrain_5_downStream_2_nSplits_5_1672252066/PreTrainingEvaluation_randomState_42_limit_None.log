WARNING:root: [!] Starting Masked Language Model evaluation over 5 splits!
WARNING:root: [!] Loaded data and vocab. X train size: (76126, 2048), X test size: (17407, 2048), vocab size: 10000
WARNING:root: [!] Running pre-training split 1/5
WARNING:root: [!] Pre-training model...
WARNING:root: [*] Masking sequences...
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Wed Dec 28 19:28:09 2022: Train Epoch: 1 [  0  /60900 (0 %)]	Loss: 507.256531 | Not computing TPR and F1 | Elapsed: 5.67s
WARNING:root: [*] Wed Dec 28 19:28:29 2022: Train Epoch: 1 [12800/60900 (21%)]	Loss: 372.463257 | Not computing TPR and F1 | Elapsed: 20.25s
WARNING:root: [*] Wed Dec 28 19:28:49 2022: Train Epoch: 1 [25600/60900 (42%)]	Loss: 336.639496 | Not computing TPR and F1 | Elapsed: 20.35s
WARNING:root: [*] Wed Dec 28 19:29:10 2022: Train Epoch: 1 [38400/60900 (63%)]	Loss: 354.544006 | Not computing TPR and F1 | Elapsed: 20.30s
WARNING:root: [*] Wed Dec 28 19:29:30 2022: Train Epoch: 1 [51200/60900 (84%)]	Loss: 332.519897 | Not computing TPR and F1 | Elapsed: 20.30s
WARNING:root: [*] Wed Dec 28 19:29:45 2022:    1    | Tr.loss: 366.108430 | Not computing TPR and F1 | Elapsed:  101.87  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Wed Dec 28 19:29:45 2022: Train Epoch: 2 [  0  /60900 (0 %)]	Loss: 310.857239 | Not computing TPR and F1 | Elapsed: 0.41s
WARNING:root: [*] Wed Dec 28 19:30:06 2022: Train Epoch: 2 [12800/60900 (21%)]	Loss: 354.339539 | Not computing TPR and F1 | Elapsed: 20.30s
WARNING:root: [*] Wed Dec 28 19:30:26 2022: Train Epoch: 2 [25600/60900 (42%)]	Loss: 311.804657 | Not computing TPR and F1 | Elapsed: 20.37s
WARNING:root: [*] Wed Dec 28 19:30:46 2022: Train Epoch: 2 [38400/60900 (63%)]	Loss: 318.940247 | Not computing TPR and F1 | Elapsed: 20.44s
WARNING:root: [*] Wed Dec 28 19:31:07 2022: Train Epoch: 2 [51200/60900 (84%)]	Loss: 317.909882 | Not computing TPR and F1 | Elapsed: 20.48s
WARNING:root: [*] Wed Dec 28 19:31:22 2022:    2    | Tr.loss: 324.375610 | Not computing TPR and F1 | Elapsed:   97.28  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Wed Dec 28 19:31:23 2022: Train Epoch: 3 [  0  /60900 (0 %)]	Loss: 331.225525 | Not computing TPR and F1 | Elapsed: 0.45s
WARNING:root: [*] Wed Dec 28 19:31:43 2022: Train Epoch: 3 [12800/60900 (21%)]	Loss: 325.483643 | Not computing TPR and F1 | Elapsed: 20.54s
WARNING:root: [*] Wed Dec 28 19:32:04 2022: Train Epoch: 3 [25600/60900 (42%)]	Loss: 317.349579 | Not computing TPR and F1 | Elapsed: 20.74s
WARNING:root: [*] Wed Dec 28 19:32:25 2022: Train Epoch: 3 [38400/60900 (63%)]	Loss: 308.921051 | Not computing TPR and F1 | Elapsed: 20.72s
WARNING:root: [*] Wed Dec 28 19:32:45 2022: Train Epoch: 3 [51200/60900 (84%)]	Loss: 330.533600 | Not computing TPR and F1 | Elapsed: 20.80s
WARNING:root: [*] Wed Dec 28 19:33:01 2022:    3    | Tr.loss: 314.793937 | Not computing TPR and F1 | Elapsed:   98.72  s
WARNING:root: [*] Started epoch: 4
WARNING:root: [*] Wed Dec 28 19:33:01 2022: Train Epoch: 4 [  0  /60900 (0 %)]	Loss: 320.100037 | Not computing TPR and F1 | Elapsed: 0.47s
WARNING:root: [*] Wed Dec 28 19:33:22 2022: Train Epoch: 4 [12800/60900 (21%)]	Loss: 312.219330 | Not computing TPR and F1 | Elapsed: 20.64s
WARNING:root: [*] Wed Dec 28 19:33:43 2022: Train Epoch: 4 [25600/60900 (42%)]	Loss: 332.477356 | Not computing TPR and F1 | Elapsed: 20.74s
WARNING:root: [*] Wed Dec 28 19:34:03 2022: Train Epoch: 4 [38400/60900 (63%)]	Loss: 291.723938 | Not computing TPR and F1 | Elapsed: 20.79s
WARNING:root: [*] Wed Dec 28 19:34:24 2022: Train Epoch: 4 [51200/60900 (84%)]	Loss: 298.822235 | Not computing TPR and F1 | Elapsed: 20.80s
WARNING:root: [*] Wed Dec 28 19:34:40 2022:    4    | Tr.loss: 308.154755 | Not computing TPR and F1 | Elapsed:   98.91  s
WARNING:root: [*] Started epoch: 5
WARNING:root: [*] Wed Dec 28 19:34:40 2022: Train Epoch: 5 [  0  /60900 (0 %)]	Loss: 288.339569 | Not computing TPR and F1 | Elapsed: 0.41s
WARNING:root: [*] Wed Dec 28 19:35:01 2022: Train Epoch: 5 [12800/60900 (21%)]	Loss: 305.509430 | Not computing TPR and F1 | Elapsed: 20.67s
WARNING:root: [*] Wed Dec 28 19:35:22 2022: Train Epoch: 5 [25600/60900 (42%)]	Loss: 304.055603 | Not computing TPR and F1 | Elapsed: 20.93s
WARNING:root: [*] Wed Dec 28 19:35:43 2022: Train Epoch: 5 [38400/60900 (63%)]	Loss: 299.672577 | Not computing TPR and F1 | Elapsed: 20.81s
WARNING:root: [*] Wed Dec 28 19:36:03 2022: Train Epoch: 5 [51200/60900 (84%)]	Loss: 280.312317 | Not computing TPR and F1 | Elapsed: 20.72s
WARNING:root: [*] Wed Dec 28 19:36:19 2022:    5    | Tr.loss: 304.233771 | Not computing TPR and F1 | Elapsed:   98.87  s
WARNING:root:[!] Wed Dec 28 19:36:19 2022: Dumped results:
                model     : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\preTraining\trainingFiles_1672252579-model.torch
                losses    : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\preTraining\trainingFiles_1672252579-train_losses.npy
                duration  : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\preTraining\trainingFiles_1672252579-trainTime.npy
WARNING:root: [!] Training pretrained model on downstream task...
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Wed Dec 28 19:36:20 2022: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 0.844560 | FPR 0.01 -- TPR 0.0707 | F1 0.1320 | Elapsed: 0.45s
WARNING:root: [*] Wed Dec 28 19:36:39 2022: Train Epoch: 1 [12800/15226 (83%)]	Loss: 0.312089 | FPR 0.01 -- TPR 0.2484 | F1 0.3980 | Elapsed: 19.87s
WARNING:root: [*] Wed Dec 28 19:36:43 2022:    1    | Tr.loss: 0.366326 | FPR 0.01 -- TPR: 0.30 |  F1: 0.44 | Elapsed:   23.72  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Wed Dec 28 19:36:43 2022: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.191683 | FPR 0.01 -- TPR 0.7826 | F1 0.8780 | Elapsed: 0.40s
WARNING:root: [*] Wed Dec 28 19:37:03 2022: Train Epoch: 2 [12800/15226 (83%)]	Loss: 0.146449 | FPR 0.01 -- TPR 0.6906 | F1 0.8170 | Elapsed: 19.87s
WARNING:root: [*] Wed Dec 28 19:37:06 2022:    2    | Tr.loss: 0.172833 | FPR 0.01 -- TPR: 0.64 |  F1: 0.77 | Elapsed:   23.64  s
WARNING:root:[!] Wed Dec 28 19:37:07 2022: Dumped results:
                model     : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_pretrained\trainingFiles_1672252626-model.torch
                losses    : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_pretrained\trainingFiles_1672252626-train_losses.npy
                duration  : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_pretrained\trainingFiles_1672252626-trainTime.npy
		train F1s : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_pretrained\trainingFiles_1672252626-trainF1s.npy
		train TPRs: evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_pretrained\trainingFiles_1672252626-trainTPRs.npy
WARNING:root: [!] Training non_pretrained model on downstream task...
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Wed Dec 28 19:37:07 2022: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 0.693457 | FPR 0.01 -- TPR 0.0000 | F1 0.0000 | Elapsed: 0.39s
WARNING:root: [*] Wed Dec 28 19:37:27 2022: Train Epoch: 1 [12800/15226 (83%)]	Loss: 0.313351 | FPR 0.01 -- TPR 0.4360 | F1 0.6073 | Elapsed: 19.50s
WARNING:root: [*] Wed Dec 28 19:37:30 2022:    1    | Tr.loss: 0.489111 | FPR 0.01 -- TPR: 0.29 |  F1: 0.38 | Elapsed:   23.21  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Wed Dec 28 19:37:30 2022: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.234450 | FPR 0.01 -- TPR 0.7857 | F1 0.8800 | Elapsed: 0.40s
WARNING:root: [*] Wed Dec 28 19:37:50 2022: Train Epoch: 2 [12800/15226 (83%)]	Loss: 0.135794 | FPR 0.01 -- TPR 0.3829 | F1 0.5537 | Elapsed: 19.20s
WARNING:root: [*] Wed Dec 28 19:37:53 2022:    2    | Tr.loss: 0.144402 | FPR 0.01 -- TPR: 0.84 |  F1: 0.91 | Elapsed:   22.90  s
WARNING:root:[!] Wed Dec 28 19:37:53 2022: Dumped results:
                model     : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_non_pretrained\trainingFiles_1672252673-model.torch
                losses    : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_non_pretrained\trainingFiles_1672252673-train_losses.npy
                duration  : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_non_pretrained\trainingFiles_1672252673-trainTime.npy
		train F1s : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_non_pretrained\trainingFiles_1672252673-trainF1s.npy
		train TPRs: evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_non_pretrained\trainingFiles_1672252673-trainTPRs.npy
WARNING:root: [!] Training full_data model on downstream task...
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Wed Dec 28 19:37:54 2022: Train Epoch: 1 [  0  /76126 (0 %)]	Loss: 0.705293 | FPR 0.01 -- TPR 0.0172 | F1 0.0339 | Elapsed: 0.39s
WARNING:root: [*] Wed Dec 28 19:38:13 2022: Train Epoch: 1 [12800/76126 (17%)]	Loss: 0.228784 | FPR 0.01 -- TPR 0.9040 | F1 0.9496 | Elapsed: 19.41s
WARNING:root: [*] Wed Dec 28 19:38:33 2022: Train Epoch: 1 [25600/76126 (34%)]	Loss: 0.207846 | FPR 0.01 -- TPR 0.8883 | F1 0.9408 | Elapsed: 19.57s
WARNING:root: [*] Wed Dec 28 19:38:52 2022: Train Epoch: 1 [38400/76126 (50%)]	Loss: 0.080707 | FPR 0.01 -- TPR 0.9667 | F1 0.9831 | Elapsed: 19.53s
WARNING:root: [*] Wed Dec 28 19:39:12 2022: Train Epoch: 1 [51200/76126 (67%)]	Loss: 0.083485 | FPR 0.01 -- TPR 0.9758 | F1 0.9877 | Elapsed: 19.55s
WARNING:root: [*] Wed Dec 28 19:39:31 2022: Train Epoch: 1 [64000/76126 (84%)]	Loss: 0.075464 | FPR 0.01 -- TPR 0.9699 | F1 0.9847 | Elapsed: 19.54s
WARNING:root: [*] Wed Dec 28 19:39:49 2022:    1    | Tr.loss: 0.173922 | FPR 0.01 -- TPR: 0.76 |  F1: 0.82 | Elapsed:  116.14  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Wed Dec 28 19:39:50 2022: Train Epoch: 2 [  0  /76126 (0 %)]	Loss: 0.168355 | FPR 0.01 -- TPR 0.7919 | F1 0.8839 | Elapsed: 0.40s
WARNING:root: [*] Wed Dec 28 19:40:09 2022: Train Epoch: 2 [12800/76126 (17%)]	Loss: 0.058978 | FPR 0.01 -- TPR 0.9725 | F1 0.9861 | Elapsed: 19.63s
WARNING:root: [*] Wed Dec 28 19:40:29 2022: Train Epoch: 2 [25600/76126 (34%)]	Loss: 0.191065 | FPR 0.01 -- TPR 0.9176 | F1 0.9571 | Elapsed: 19.51s
WARNING:root: [*] Wed Dec 28 19:40:48 2022: Train Epoch: 2 [38400/76126 (50%)]	Loss: 0.069074 | FPR 0.01 -- TPR 0.9655 | F1 0.9825 | Elapsed: 19.53s
WARNING:root: [*] Wed Dec 28 19:41:08 2022: Train Epoch: 2 [51200/76126 (67%)]	Loss: 0.055902 | FPR 0.01 -- TPR 0.9806 | F1 0.9870 | Elapsed: 19.51s
WARNING:root: [*] Wed Dec 28 19:41:27 2022: Train Epoch: 2 [64000/76126 (84%)]	Loss: 0.087255 | FPR 0.01 -- TPR 0.9535 | F1 0.9762 | Elapsed: 19.53s
WARNING:root: [*] Wed Dec 28 19:41:46 2022:    2    | Tr.loss: 0.065735 | FPR 0.01 -- TPR: 0.93 |  F1: 0.96 | Elapsed:  116.26  s
WARNING:root:[!] Wed Dec 28 19:41:46 2022: Dumped results:
                model     : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_full_data\trainingFiles_1672252906-model.torch
                losses    : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_full_data\trainingFiles_1672252906-train_losses.npy
                duration  : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_full_data\trainingFiles_1672252906-trainTime.npy
		train F1s : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_full_data\trainingFiles_1672252906-trainF1s.npy
		train TPRs: evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_full_data\trainingFiles_1672252906-trainTPRs.npy
WARNING:root: [*] Evaluating pretrained model on test set...
WARNING:root: [!] Test F1 score for pretrained model at 0.01 FPR : 0.7258
WARNING:root: [!] Test TPR score for pretrained model at 0.01 FPR: 0.5773
WARNING:root: [*] Evaluating non_pretrained model on test set...
WARNING:root: [!] Test F1 score for non_pretrained model at 0.01 FPR : 0.8025
WARNING:root: [!] Test TPR score for non_pretrained model at 0.01 FPR: 0.6821
WARNING:root: [*] Evaluating full_data model on test set...
WARNING:root: [!] Test F1 score for full_data model at 0.01 FPR : 0.8839
WARNING:root: [!] Test TPR score for full_data model at 0.01 FPR: 0.8025
WARNING:root: [!] Running pre-training split 2/5
WARNING:root: [!] Pre-training model...
WARNING:root: [*] Masking sequences...
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Wed Dec 28 19:42:30 2022: Train Epoch: 1 [  0  /60900 (0 %)]	Loss: 510.367126 | Not computing TPR and F1 | Elapsed: 1.17s
WARNING:root: [*] Wed Dec 28 19:42:50 2022: Train Epoch: 1 [12800/60900 (21%)]	Loss: 360.630859 | Not computing TPR and F1 | Elapsed: 20.31s
WARNING:root: [*] Wed Dec 28 19:43:11 2022: Train Epoch: 1 [25600/60900 (42%)]	Loss: 360.628967 | Not computing TPR and F1 | Elapsed: 20.69s
WARNING:root: [*] Wed Dec 28 19:43:32 2022: Train Epoch: 1 [38400/60900 (63%)]	Loss: 366.496582 | Not computing TPR and F1 | Elapsed: 20.70s
WARNING:root: [*] Wed Dec 28 19:43:53 2022: Train Epoch: 1 [51200/60900 (84%)]	Loss: 349.428345 | Not computing TPR and F1 | Elapsed: 20.83s
WARNING:root: [*] Wed Dec 28 19:44:08 2022:    1    | Tr.loss: 366.049952 | Not computing TPR and F1 | Elapsed:   99.10  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Wed Dec 28 19:44:08 2022: Train Epoch: 2 [  0  /60900 (0 %)]	Loss: 318.428162 | Not computing TPR and F1 | Elapsed: 0.46s
WARNING:root: [*] Wed Dec 28 19:44:29 2022: Train Epoch: 2 [12800/60900 (21%)]	Loss: 309.806000 | Not computing TPR and F1 | Elapsed: 20.80s
WARNING:root: [*] Wed Dec 28 19:44:50 2022: Train Epoch: 2 [25600/60900 (42%)]	Loss: 314.481384 | Not computing TPR and F1 | Elapsed: 20.85s
WARNING:root: [*] Wed Dec 28 19:45:10 2022: Train Epoch: 2 [38400/60900 (63%)]	Loss: 333.479950 | Not computing TPR and F1 | Elapsed: 20.39s
WARNING:root: [*] Wed Dec 28 19:45:31 2022: Train Epoch: 2 [51200/60900 (84%)]	Loss: 307.134644 | Not computing TPR and F1 | Elapsed: 20.89s
WARNING:root: [*] Wed Dec 28 19:45:47 2022:    2    | Tr.loss: 323.547960 | Not computing TPR and F1 | Elapsed:   98.90  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Wed Dec 28 19:45:47 2022: Train Epoch: 3 [  0  /60900 (0 %)]	Loss: 327.058594 | Not computing TPR and F1 | Elapsed: 0.43s
WARNING:root: [*] Wed Dec 28 19:46:08 2022: Train Epoch: 3 [12800/60900 (21%)]	Loss: 300.329529 | Not computing TPR and F1 | Elapsed: 20.97s
WARNING:root: [*] Wed Dec 28 19:46:29 2022: Train Epoch: 3 [25600/60900 (42%)]	Loss: 323.032227 | Not computing TPR and F1 | Elapsed: 20.76s
WARNING:root: [*] Wed Dec 28 19:46:50 2022: Train Epoch: 3 [38400/60900 (63%)]	Loss: 305.900970 | Not computing TPR and F1 | Elapsed: 20.90s
WARNING:root: [*] Wed Dec 28 19:47:11 2022: Train Epoch: 3 [51200/60900 (84%)]	Loss: 337.779053 | Not computing TPR and F1 | Elapsed: 20.71s
WARNING:root: [*] Wed Dec 28 19:47:26 2022:    3    | Tr.loss: 312.881559 | Not computing TPR and F1 | Elapsed:   99.16  s
WARNING:root: [*] Started epoch: 4
WARNING:root: [*] Wed Dec 28 19:47:26 2022: Train Epoch: 4 [  0  /60900 (0 %)]	Loss: 324.831787 | Not computing TPR and F1 | Elapsed: 0.45s
WARNING:root: [*] Wed Dec 28 19:47:47 2022: Train Epoch: 4 [12800/60900 (21%)]	Loss: 291.594238 | Not computing TPR and F1 | Elapsed: 20.70s
WARNING:root: [*] Wed Dec 28 19:48:08 2022: Train Epoch: 4 [25600/60900 (42%)]	Loss: 313.591766 | Not computing TPR and F1 | Elapsed: 20.78s
WARNING:root: [*] Wed Dec 28 19:48:29 2022: Train Epoch: 4 [38400/60900 (63%)]	Loss: 306.963074 | Not computing TPR and F1 | Elapsed: 20.85s
WARNING:root: [*] Wed Dec 28 19:48:50 2022: Train Epoch: 4 [51200/60900 (84%)]	Loss: 302.563019 | Not computing TPR and F1 | Elapsed: 20.76s
WARNING:root: [*] Wed Dec 28 19:49:05 2022:    4    | Tr.loss: 306.666575 | Not computing TPR and F1 | Elapsed:   98.97  s
WARNING:root: [*] Started epoch: 5
WARNING:root: [*] Wed Dec 28 19:49:05 2022: Train Epoch: 5 [  0  /60900 (0 %)]	Loss: 291.392334 | Not computing TPR and F1 | Elapsed: 0.47s
WARNING:root: [*] Wed Dec 28 19:49:26 2022: Train Epoch: 5 [12800/60900 (21%)]	Loss: 288.332153 | Not computing TPR and F1 | Elapsed: 20.83s
WARNING:root: [*] Wed Dec 28 19:49:47 2022: Train Epoch: 5 [25600/60900 (42%)]	Loss: 297.021790 | Not computing TPR and F1 | Elapsed: 20.79s
WARNING:root: [*] Wed Dec 28 19:50:08 2022: Train Epoch: 5 [38400/60900 (63%)]	Loss: 303.891418 | Not computing TPR and F1 | Elapsed: 20.87s
WARNING:root: [*] Wed Dec 28 19:50:29 2022: Train Epoch: 5 [51200/60900 (84%)]	Loss: 310.655151 | Not computing TPR and F1 | Elapsed: 20.84s
WARNING:root: [*] Wed Dec 28 19:50:44 2022:    5    | Tr.loss: 301.905499 | Not computing TPR and F1 | Elapsed:   99.24  s
WARNING:root:[!] Wed Dec 28 19:50:44 2022: Dumped results:
                model     : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\preTraining\trainingFiles_1672253444-model.torch
                losses    : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\preTraining\trainingFiles_1672253444-train_losses.npy
                duration  : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\preTraining\trainingFiles_1672253444-trainTime.npy
WARNING:root: [!] Training pretrained model on downstream task...
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Wed Dec 28 19:50:45 2022: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 0.861730 | FPR 0.01 -- TPR 0.0526 | F1 0.1000 | Elapsed: 0.44s
WARNING:root: [*] Wed Dec 28 19:51:05 2022: Train Epoch: 1 [12800/15226 (83%)]	Loss: 0.206722 | FPR 0.01 -- TPR 0.7000 | F1 0.8235 | Elapsed: 19.86s
WARNING:root: [*] Wed Dec 28 19:51:08 2022:    1    | Tr.loss: 0.383719 | FPR 0.01 -- TPR: 0.30 |  F1: 0.43 | Elapsed:   23.69  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Wed Dec 28 19:51:09 2022: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.158929 | FPR 0.01 -- TPR 0.5146 | F1 0.6795 | Elapsed: 0.39s
WARNING:root: [*] Wed Dec 28 19:51:28 2022: Train Epoch: 2 [12800/15226 (83%)]	Loss: 0.128125 | FPR 0.01 -- TPR 0.9040 | F1 0.9496 | Elapsed: 19.59s
WARNING:root: [*] Wed Dec 28 19:51:32 2022:    2    | Tr.loss: 0.146909 | FPR 0.01 -- TPR: 0.78 |  F1: 0.87 | Elapsed:   23.34  s
WARNING:root:[!] Wed Dec 28 19:51:32 2022: Dumped results:
                model     : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_pretrained\trainingFiles_1672253492-model.torch
                losses    : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_pretrained\trainingFiles_1672253492-train_losses.npy
                duration  : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_pretrained\trainingFiles_1672253492-trainTime.npy
		train F1s : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_pretrained\trainingFiles_1672253492-trainF1s.npy
		train TPRs: evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_pretrained\trainingFiles_1672253492-trainTPRs.npy
WARNING:root: [!] Training non_pretrained model on downstream task...
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Wed Dec 28 19:51:32 2022: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 0.706355 | FPR 0.01 -- TPR 0.0347 | F1 0.0670 | Elapsed: 0.41s
WARNING:root: [*] Wed Dec 28 19:51:52 2022: Train Epoch: 1 [12800/15226 (83%)]	Loss: 0.243124 | FPR 0.01 -- TPR 0.7884 | F1 0.8817 | Elapsed: 19.58s
WARNING:root: [*] Wed Dec 28 19:51:55 2022:    1    | Tr.loss: 0.471645 | FPR 0.01 -- TPR: 0.34 |  F1: 0.43 | Elapsed:   23.31  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Wed Dec 28 19:51:56 2022: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.357116 | FPR 0.01 -- TPR 0.7733 | F1 0.8721 | Elapsed: 0.41s
WARNING:root: [*] Wed Dec 28 19:52:15 2022: Train Epoch: 2 [12800/15226 (83%)]	Loss: 0.119457 | FPR 0.01 -- TPR 0.8571 | F1 0.9231 | Elapsed: 19.58s
WARNING:root: [*] Wed Dec 28 19:52:19 2022:    2    | Tr.loss: 0.143781 | FPR 0.01 -- TPR: 0.85 |  F1: 0.91 | Elapsed:   23.32  s
WARNING:root:[!] Wed Dec 28 19:52:19 2022: Dumped results:
                model     : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_non_pretrained\trainingFiles_1672253539-model.torch
                losses    : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_non_pretrained\trainingFiles_1672253539-train_losses.npy
                duration  : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_non_pretrained\trainingFiles_1672253539-trainTime.npy
		train F1s : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_non_pretrained\trainingFiles_1672253539-trainF1s.npy
		train TPRs: evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_non_pretrained\trainingFiles_1672253539-trainTPRs.npy
WARNING:root: [!] Training full_data model on downstream task...
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Wed Dec 28 19:52:19 2022: Train Epoch: 1 [  0  /76126 (0 %)]	Loss: 0.718690 | FPR 0.01 -- TPR 0.0000 | F1 0.0000 | Elapsed: 0.40s
WARNING:root: [*] Wed Dec 28 19:52:39 2022: Train Epoch: 1 [12800/76126 (17%)]	Loss: 0.222858 | FPR 0.01 -- TPR 0.8895 | F1 0.9415 | Elapsed: 19.59s
WARNING:root: [*] Wed Dec 28 19:52:59 2022: Train Epoch: 1 [25600/76126 (34%)]	Loss: 0.124160 | FPR 0.01 -- TPR 0.8966 | F1 0.9455 | Elapsed: 19.57s
WARNING:root: [*] Wed Dec 28 19:53:18 2022: Train Epoch: 1 [38400/76126 (50%)]	Loss: 0.087573 | FPR 0.01 -- TPR 0.8895 | F1 0.9415 | Elapsed: 19.60s
WARNING:root: [*] Wed Dec 28 19:53:38 2022: Train Epoch: 1 [51200/76126 (67%)]	Loss: 0.050031 | FPR 0.01 -- TPR 0.9725 | F1 0.9861 | Elapsed: 19.53s
WARNING:root: [*] Wed Dec 28 19:53:57 2022: Train Epoch: 1 [64000/76126 (84%)]	Loss: 0.095246 | FPR 0.01 -- TPR 0.9255 | F1 0.9613 | Elapsed: 19.64s
WARNING:root: [*] Wed Dec 28 19:54:15 2022:    1    | Tr.loss: 0.176054 | FPR 0.01 -- TPR: 0.77 |  F1: 0.83 | Elapsed:  116.45  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Wed Dec 28 19:54:16 2022: Train Epoch: 2 [  0  /76126 (0 %)]	Loss: 0.070715 | FPR 0.01 -- TPR 0.9774 | F1 0.9886 | Elapsed: 0.40s
WARNING:root: [*] Wed Dec 28 19:54:35 2022: Train Epoch: 2 [12800/76126 (17%)]	Loss: 0.063424 | FPR 0.01 -- TPR 0.8049 | F1 0.8919 | Elapsed: 19.49s
WARNING:root: [*] Wed Dec 28 19:54:55 2022: Train Epoch: 2 [25600/76126 (34%)]	Loss: 0.047612 | FPR 0.01 -- TPR 0.9514 | F1 0.9751 | Elapsed: 19.32s
WARNING:root: [*] Wed Dec 28 19:55:14 2022: Train Epoch: 2 [38400/76126 (50%)]	Loss: 0.040673 | FPR 0.01 -- TPR 0.9940 | F1 0.9970 | Elapsed: 19.50s
WARNING:root: [*] Wed Dec 28 19:55:34 2022: Train Epoch: 2 [51200/76126 (67%)]	Loss: 0.046420 | FPR 0.01 -- TPR 0.9780 | F1 0.9889 | Elapsed: 19.52s
WARNING:root: [*] Wed Dec 28 19:55:53 2022: Train Epoch: 2 [64000/76126 (84%)]	Loss: 0.047077 | FPR 0.01 -- TPR 0.9349 | F1 0.9664 | Elapsed: 19.49s
WARNING:root: [*] Wed Dec 28 19:56:11 2022:    2    | Tr.loss: 0.064201 | FPR 0.01 -- TPR: 0.93 |  F1: 0.96 | Elapsed:  115.80  s
WARNING:root:[!] Wed Dec 28 19:56:11 2022: Dumped results:
                model     : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_full_data\trainingFiles_1672253771-model.torch
                losses    : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_full_data\trainingFiles_1672253771-train_losses.npy
                duration  : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_full_data\trainingFiles_1672253771-trainTime.npy
		train F1s : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_full_data\trainingFiles_1672253771-trainF1s.npy
		train TPRs: evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_full_data\trainingFiles_1672253771-trainTPRs.npy
WARNING:root: [*] Evaluating pretrained model on test set...
WARNING:root: [!] Test F1 score for pretrained model at 0.01 FPR : 0.8014
WARNING:root: [!] Test TPR score for pretrained model at 0.01 FPR: 0.6770
WARNING:root: [*] Evaluating non_pretrained model on test set...
WARNING:root: [!] Test F1 score for non_pretrained model at 0.01 FPR : 0.8330
WARNING:root: [!] Test TPR score for non_pretrained model at 0.01 FPR: 0.7223
WARNING:root: [*] Evaluating full_data model on test set...
WARNING:root: [!] Test F1 score for full_data model at 0.01 FPR : 0.8656
WARNING:root: [!] Test TPR score for full_data model at 0.01 FPR: 0.7698
WARNING:root: [!] Running pre-training split 3/5
WARNING:root: [!] Pre-training model...
WARNING:root: [*] Masking sequences...
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Wed Dec 28 19:56:54 2022: Train Epoch: 1 [  0  /60900 (0 %)]	Loss: 488.301575 | Not computing TPR and F1 | Elapsed: 0.69s
WARNING:root: [*] Wed Dec 28 19:57:15 2022: Train Epoch: 1 [12800/60900 (21%)]	Loss: 383.732971 | Not computing TPR and F1 | Elapsed: 20.38s
WARNING:root: [*] Wed Dec 28 19:57:36 2022: Train Epoch: 1 [25600/60900 (42%)]	Loss: 345.087708 | Not computing TPR and F1 | Elapsed: 20.88s
WARNING:root: [*] Wed Dec 28 19:57:57 2022: Train Epoch: 1 [38400/60900 (63%)]	Loss: 340.287048 | Not computing TPR and F1 | Elapsed: 20.89s
WARNING:root: [*] Wed Dec 28 19:58:17 2022: Train Epoch: 1 [51200/60900 (84%)]	Loss: 335.594238 | Not computing TPR and F1 | Elapsed: 20.85s
WARNING:root: [*] Wed Dec 28 19:58:33 2022:    1    | Tr.loss: 370.714134 | Not computing TPR and F1 | Elapsed:   99.09  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Wed Dec 28 19:58:33 2022: Train Epoch: 2 [  0  /60900 (0 %)]	Loss: 337.939270 | Not computing TPR and F1 | Elapsed: 0.47s
WARNING:root: [*] Wed Dec 28 19:58:54 2022: Train Epoch: 2 [12800/60900 (21%)]	Loss: 331.824585 | Not computing TPR and F1 | Elapsed: 20.82s
WARNING:root: [*] Wed Dec 28 19:59:15 2022: Train Epoch: 2 [25600/60900 (42%)]	Loss: 348.015625 | Not computing TPR and F1 | Elapsed: 20.92s
WARNING:root: [*] Wed Dec 28 19:59:36 2022: Train Epoch: 2 [38400/60900 (63%)]	Loss: 350.477753 | Not computing TPR and F1 | Elapsed: 20.92s
WARNING:root: [*] Wed Dec 28 19:59:56 2022: Train Epoch: 2 [51200/60900 (84%)]	Loss: 297.137268 | Not computing TPR and F1 | Elapsed: 20.49s
WARNING:root: [*] Wed Dec 28 20:00:12 2022:    2    | Tr.loss: 324.062677 | Not computing TPR and F1 | Elapsed:   98.78  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Wed Dec 28 20:00:12 2022: Train Epoch: 3 [  0  /60900 (0 %)]	Loss: 321.641632 | Not computing TPR and F1 | Elapsed: 0.47s
WARNING:root: [*] Wed Dec 28 20:00:33 2022: Train Epoch: 3 [12800/60900 (21%)]	Loss: 344.067139 | Not computing TPR and F1 | Elapsed: 20.95s
WARNING:root: [*] Wed Dec 28 20:00:54 2022: Train Epoch: 3 [25600/60900 (42%)]	Loss: 318.213074 | Not computing TPR and F1 | Elapsed: 20.86s
WARNING:root: [*] Wed Dec 28 20:01:15 2022: Train Epoch: 3 [38400/60900 (63%)]	Loss: 310.249329 | Not computing TPR and F1 | Elapsed: 20.84s
WARNING:root: [*] Wed Dec 28 20:01:36 2022: Train Epoch: 3 [51200/60900 (84%)]	Loss: 294.722961 | Not computing TPR and F1 | Elapsed: 21.01s
WARNING:root: [*] Wed Dec 28 20:01:51 2022:    3    | Tr.loss: 311.595181 | Not computing TPR and F1 | Elapsed:   99.56  s
WARNING:root: [*] Started epoch: 4
WARNING:root: [*] Wed Dec 28 20:01:52 2022: Train Epoch: 4 [  0  /60900 (0 %)]	Loss: 304.461548 | Not computing TPR and F1 | Elapsed: 0.45s
WARNING:root: [*] Wed Dec 28 20:02:12 2022: Train Epoch: 4 [12800/60900 (21%)]	Loss: 297.862213 | Not computing TPR and F1 | Elapsed: 20.91s
WARNING:root: [*] Wed Dec 28 20:02:33 2022: Train Epoch: 4 [25600/60900 (42%)]	Loss: 291.554016 | Not computing TPR and F1 | Elapsed: 20.81s
WARNING:root: [*] Wed Dec 28 20:02:54 2022: Train Epoch: 4 [38400/60900 (63%)]	Loss: 307.715271 | Not computing TPR and F1 | Elapsed: 20.85s
WARNING:root: [*] Wed Dec 28 20:03:15 2022: Train Epoch: 4 [51200/60900 (84%)]	Loss: 312.360107 | Not computing TPR and F1 | Elapsed: 20.79s
WARNING:root: [*] Wed Dec 28 20:03:30 2022:    4    | Tr.loss: 302.516627 | Not computing TPR and F1 | Elapsed:   99.27  s
WARNING:root: [*] Started epoch: 5
WARNING:root: [*] Wed Dec 28 20:03:31 2022: Train Epoch: 5 [  0  /60900 (0 %)]	Loss: 313.554199 | Not computing TPR and F1 | Elapsed: 0.42s
WARNING:root: [*] Wed Dec 28 20:03:52 2022: Train Epoch: 5 [12800/60900 (21%)]	Loss: 301.262146 | Not computing TPR and F1 | Elapsed: 20.84s
WARNING:root: [*] Wed Dec 28 20:04:12 2022: Train Epoch: 5 [25600/60900 (42%)]	Loss: 301.999390 | Not computing TPR and F1 | Elapsed: 20.83s
WARNING:root: [*] Wed Dec 28 20:04:33 2022: Train Epoch: 5 [38400/60900 (63%)]	Loss: 316.870209 | Not computing TPR and F1 | Elapsed: 20.86s
WARNING:root: [*] Wed Dec 28 20:04:54 2022: Train Epoch: 5 [51200/60900 (84%)]	Loss: 289.553009 | Not computing TPR and F1 | Elapsed: 20.82s
WARNING:root: [*] Wed Dec 28 20:05:10 2022:    5    | Tr.loss: 296.840836 | Not computing TPR and F1 | Elapsed:   99.17  s
WARNING:root:[!] Wed Dec 28 20:05:10 2022: Dumped results:
                model     : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\preTraining\trainingFiles_1672254310-model.torch
                losses    : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\preTraining\trainingFiles_1672254310-train_losses.npy
                duration  : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\preTraining\trainingFiles_1672254310-trainTime.npy
WARNING:root: [!] Training pretrained model on downstream task...
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Wed Dec 28 20:05:10 2022: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 0.715231 | FPR 0.01 -- TPR 0.0282 | F1 0.0549 | Elapsed: 0.40s
WARNING:root: [*] Wed Dec 28 20:05:30 2022: Train Epoch: 1 [12800/15226 (83%)]	Loss: 0.171079 | FPR 0.01 -- TPR 0.6893 | F1 0.8161 | Elapsed: 19.95s
WARNING:root: [*] Wed Dec 28 20:05:34 2022:    1    | Tr.loss: 0.357684 | FPR 0.01 -- TPR: 0.29 |  F1: 0.43 | Elapsed:   23.72  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Wed Dec 28 20:05:34 2022: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.197095 | FPR 0.01 -- TPR 0.7118 | F1 0.8316 | Elapsed: 0.41s
WARNING:root: [*] Wed Dec 28 20:05:54 2022: Train Epoch: 2 [12800/15226 (83%)]	Loss: 0.120511 | FPR 0.01 -- TPR 0.7966 | F1 0.8868 | Elapsed: 19.89s
WARNING:root: [*] Wed Dec 28 20:05:57 2022:    2    | Tr.loss: 0.151128 | FPR 0.01 -- TPR: 0.74 |  F1: 0.83 | Elapsed:   23.68  s
WARNING:root:[!] Wed Dec 28 20:05:58 2022: Dumped results:
                model     : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_pretrained\trainingFiles_1672254357-model.torch
                losses    : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_pretrained\trainingFiles_1672254357-train_losses.npy
                duration  : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_pretrained\trainingFiles_1672254357-trainTime.npy
		train F1s : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_pretrained\trainingFiles_1672254357-trainF1s.npy
		train TPRs: evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_pretrained\trainingFiles_1672254357-trainTPRs.npy
WARNING:root: [!] Training non_pretrained model on downstream task...
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Wed Dec 28 20:05:58 2022: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 0.688356 | FPR 0.01 -- TPR 0.0000 | F1 0.0000 | Elapsed: 0.43s
WARNING:root: [*] Wed Dec 28 20:06:18 2022: Train Epoch: 1 [12800/15226 (83%)]	Loss: 0.274089 | FPR 0.01 -- TPR 0.8715 | F1 0.9313 | Elapsed: 19.54s
WARNING:root: [*] Wed Dec 28 20:06:21 2022:    1    | Tr.loss: 0.438222 | FPR 0.01 -- TPR: 0.33 |  F1: 0.43 | Elapsed:   23.28  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Wed Dec 28 20:06:21 2022: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.185949 | FPR 0.01 -- TPR 0.8385 | F1 0.9122 | Elapsed: 0.39s
WARNING:root: [*] Wed Dec 28 20:06:41 2022: Train Epoch: 2 [12800/15226 (83%)]	Loss: 0.163894 | FPR 0.01 -- TPR 0.8563 | F1 0.9226 | Elapsed: 19.57s
WARNING:root: [*] Wed Dec 28 20:06:44 2022:    2    | Tr.loss: 0.137082 | FPR 0.01 -- TPR: 0.85 |  F1: 0.91 | Elapsed:   23.28  s
WARNING:root:[!] Wed Dec 28 20:06:44 2022: Dumped results:
                model     : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_non_pretrained\trainingFiles_1672254404-model.torch
                losses    : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_non_pretrained\trainingFiles_1672254404-train_losses.npy
                duration  : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_non_pretrained\trainingFiles_1672254404-trainTime.npy
		train F1s : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_non_pretrained\trainingFiles_1672254404-trainF1s.npy
		train TPRs: evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_non_pretrained\trainingFiles_1672254404-trainTPRs.npy
WARNING:root: [!] Training full_data model on downstream task...
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Wed Dec 28 20:06:45 2022: Train Epoch: 1 [  0  /76126 (0 %)]	Loss: 0.710744 | FPR 0.01 -- TPR 0.0000 | F1 0.0000 | Elapsed: 0.40s
WARNING:root: [*] Wed Dec 28 20:07:05 2022: Train Epoch: 1 [12800/76126 (17%)]	Loss: 0.304240 | FPR 0.01 -- TPR 0.6816 | F1 0.8106 | Elapsed: 19.59s
WARNING:root: [*] Wed Dec 28 20:07:24 2022: Train Epoch: 1 [25600/76126 (34%)]	Loss: 0.216244 | FPR 0.01 -- TPR 0.4076 | F1 0.5792 | Elapsed: 19.55s
WARNING:root: [*] Wed Dec 28 20:07:44 2022: Train Epoch: 1 [38400/76126 (50%)]	Loss: 0.095829 | FPR 0.01 -- TPR 0.9492 | F1 0.9739 | Elapsed: 19.66s
WARNING:root: [*] Wed Dec 28 20:08:03 2022: Train Epoch: 1 [51200/76126 (67%)]	Loss: 0.096811 | FPR 0.01 -- TPR 0.9205 | F1 0.9586 | Elapsed: 19.55s
WARNING:root: [*] Wed Dec 28 20:08:23 2022: Train Epoch: 1 [64000/76126 (84%)]	Loss: 0.080217 | FPR 0.01 -- TPR 0.9034 | F1 0.9493 | Elapsed: 19.56s
WARNING:root: [*] Wed Dec 28 20:08:41 2022:    1    | Tr.loss: 0.181273 | FPR 0.01 -- TPR: 0.77 |  F1: 0.83 | Elapsed:  116.44  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Wed Dec 28 20:08:42 2022: Train Epoch: 2 [  0  /76126 (0 %)]	Loss: 0.068873 | FPR 0.01 -- TPR 0.9593 | F1 0.9792 | Elapsed: 0.41s
WARNING:root: [*] Wed Dec 28 20:09:01 2022: Train Epoch: 2 [12800/76126 (17%)]	Loss: 0.045034 | FPR 0.01 -- TPR 0.9891 | F1 0.9945 | Elapsed: 19.55s
WARNING:root: [*] Wed Dec 28 20:09:21 2022: Train Epoch: 2 [25600/76126 (34%)]	Loss: 0.046563 | FPR 0.01 -- TPR 0.9704 | F1 0.9850 | Elapsed: 19.53s
WARNING:root: [*] Wed Dec 28 20:09:40 2022: Train Epoch: 2 [38400/76126 (50%)]	Loss: 0.047380 | FPR 0.01 -- TPR 0.8708 | F1 0.9309 | Elapsed: 19.53s
WARNING:root: [*] Wed Dec 28 20:10:00 2022: Train Epoch: 2 [51200/76126 (67%)]	Loss: 0.053009 | FPR 0.01 -- TPR 0.9645 | F1 0.9819 | Elapsed: 19.53s
WARNING:root: [*] Wed Dec 28 20:10:19 2022: Train Epoch: 2 [64000/76126 (84%)]	Loss: 0.046889 | FPR 0.01 -- TPR 0.9822 | F1 0.9910 | Elapsed: 19.54s
WARNING:root: [*] Wed Dec 28 20:10:37 2022:    2    | Tr.loss: 0.070182 | FPR 0.01 -- TPR: 0.93 |  F1: 0.96 | Elapsed:  116.21  s
WARNING:root:[!] Wed Dec 28 20:10:37 2022: Dumped results:
                model     : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_full_data\trainingFiles_1672254637-model.torch
                losses    : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_full_data\trainingFiles_1672254637-train_losses.npy
                duration  : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_full_data\trainingFiles_1672254637-trainTime.npy
		train F1s : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_full_data\trainingFiles_1672254637-trainF1s.npy
		train TPRs: evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_full_data\trainingFiles_1672254637-trainTPRs.npy
WARNING:root: [*] Evaluating pretrained model on test set...
WARNING:root: [!] Test F1 score for pretrained model at 0.01 FPR : 0.7544
WARNING:root: [!] Test TPR score for pretrained model at 0.01 FPR: 0.6153
WARNING:root: [*] Evaluating non_pretrained model on test set...
WARNING:root: [!] Test F1 score for non_pretrained model at 0.01 FPR : 0.7874
WARNING:root: [!] Test TPR score for non_pretrained model at 0.01 FPR: 0.6577
WARNING:root: [*] Evaluating full_data model on test set...
WARNING:root: [!] Test F1 score for full_data model at 0.01 FPR : 0.8654
WARNING:root: [!] Test TPR score for full_data model at 0.01 FPR: 0.7715
WARNING:root: [!] Running pre-training split 4/5
WARNING:root: [!] Pre-training model...
WARNING:root: [*] Masking sequences...
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Wed Dec 28 20:11:22 2022: Train Epoch: 1 [  0  /60900 (0 %)]	Loss: 488.171753 | Not computing TPR and F1 | Elapsed: 1.16s
WARNING:root: [*] Wed Dec 28 20:11:42 2022: Train Epoch: 1 [12800/60900 (21%)]	Loss: 359.452148 | Not computing TPR and F1 | Elapsed: 20.42s
WARNING:root: [*] Wed Dec 28 20:12:03 2022: Train Epoch: 1 [25600/60900 (42%)]	Loss: 377.013000 | Not computing TPR and F1 | Elapsed: 20.74s
WARNING:root: [*] Wed Dec 28 20:12:24 2022: Train Epoch: 1 [38400/60900 (63%)]	Loss: 392.758362 | Not computing TPR and F1 | Elapsed: 20.82s
WARNING:root: [*] Wed Dec 28 20:12:45 2022: Train Epoch: 1 [51200/60900 (84%)]	Loss: 340.431152 | Not computing TPR and F1 | Elapsed: 20.77s
WARNING:root: [*] Wed Dec 28 20:13:00 2022:    1    | Tr.loss: 369.888008 | Not computing TPR and F1 | Elapsed:   99.34  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Wed Dec 28 20:13:01 2022: Train Epoch: 2 [  0  /60900 (0 %)]	Loss: 303.366150 | Not computing TPR and F1 | Elapsed: 0.45s
WARNING:root: [*] Wed Dec 28 20:13:21 2022: Train Epoch: 2 [12800/60900 (21%)]	Loss: 323.419434 | Not computing TPR and F1 | Elapsed: 20.78s
WARNING:root: [*] Wed Dec 28 20:13:42 2022: Train Epoch: 2 [25600/60900 (42%)]	Loss: 304.604462 | Not computing TPR and F1 | Elapsed: 20.83s
WARNING:root: [*] Wed Dec 28 20:14:03 2022: Train Epoch: 2 [38400/60900 (63%)]	Loss: 332.193542 | Not computing TPR and F1 | Elapsed: 20.81s
WARNING:root: [*] Wed Dec 28 20:14:24 2022: Train Epoch: 2 [51200/60900 (84%)]	Loss: 319.935333 | Not computing TPR and F1 | Elapsed: 20.87s
WARNING:root: [*] Wed Dec 28 20:14:39 2022:    2    | Tr.loss: 323.985540 | Not computing TPR and F1 | Elapsed:   99.13  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Wed Dec 28 20:14:40 2022: Train Epoch: 3 [  0  /60900 (0 %)]	Loss: 302.745544 | Not computing TPR and F1 | Elapsed: 0.42s
WARNING:root: [*] Wed Dec 28 20:15:00 2022: Train Epoch: 3 [12800/60900 (21%)]	Loss: 318.968323 | Not computing TPR and F1 | Elapsed: 20.78s
WARNING:root: [*] Wed Dec 28 20:15:21 2022: Train Epoch: 3 [25600/60900 (42%)]	Loss: 326.197998 | Not computing TPR and F1 | Elapsed: 20.83s
WARNING:root: [*] Wed Dec 28 20:15:42 2022: Train Epoch: 3 [38400/60900 (63%)]	Loss: 313.774200 | Not computing TPR and F1 | Elapsed: 20.75s
WARNING:root: [*] Wed Dec 28 20:16:03 2022: Train Epoch: 3 [51200/60900 (84%)]	Loss: 290.827332 | Not computing TPR and F1 | Elapsed: 20.79s
WARNING:root: [*] Wed Dec 28 20:16:18 2022:    3    | Tr.loss: 313.193864 | Not computing TPR and F1 | Elapsed:   98.98  s
WARNING:root: [*] Started epoch: 4
WARNING:root: [*] Wed Dec 28 20:16:19 2022: Train Epoch: 4 [  0  /60900 (0 %)]	Loss: 295.932648 | Not computing TPR and F1 | Elapsed: 0.42s
WARNING:root: [*] Wed Dec 28 20:16:39 2022: Train Epoch: 4 [12800/60900 (21%)]	Loss: 305.254211 | Not computing TPR and F1 | Elapsed: 20.79s
WARNING:root: [*] Wed Dec 28 20:17:00 2022: Train Epoch: 4 [25600/60900 (42%)]	Loss: 293.300171 | Not computing TPR and F1 | Elapsed: 20.67s
WARNING:root: [*] Wed Dec 28 20:17:21 2022: Train Epoch: 4 [38400/60900 (63%)]	Loss: 295.908813 | Not computing TPR and F1 | Elapsed: 20.96s
WARNING:root: [*] Wed Dec 28 20:17:42 2022: Train Epoch: 4 [51200/60900 (84%)]	Loss: 309.652344 | Not computing TPR and F1 | Elapsed: 21.00s
WARNING:root: [*] Wed Dec 28 20:17:58 2022:    4    | Tr.loss: 307.139606 | Not computing TPR and F1 | Elapsed:   99.45  s
WARNING:root: [*] Started epoch: 5
WARNING:root: [*] Wed Dec 28 20:17:58 2022: Train Epoch: 5 [  0  /60900 (0 %)]	Loss: 316.710754 | Not computing TPR and F1 | Elapsed: 0.43s
WARNING:root: [*] Wed Dec 28 20:18:19 2022: Train Epoch: 5 [12800/60900 (21%)]	Loss: 325.778320 | Not computing TPR and F1 | Elapsed: 21.04s
WARNING:root: [*] Wed Dec 28 20:18:40 2022: Train Epoch: 5 [25600/60900 (42%)]	Loss: 268.828979 | Not computing TPR and F1 | Elapsed: 20.98s
WARNING:root: [*] Wed Dec 28 20:19:01 2022: Train Epoch: 5 [38400/60900 (63%)]	Loss: 305.211243 | Not computing TPR and F1 | Elapsed: 20.97s
WARNING:root: [*] Wed Dec 28 20:19:22 2022: Train Epoch: 5 [51200/60900 (84%)]	Loss: 289.709442 | Not computing TPR and F1 | Elapsed: 20.99s
WARNING:root: [*] Wed Dec 28 20:19:38 2022:    5    | Tr.loss: 303.115739 | Not computing TPR and F1 | Elapsed:   99.90  s
WARNING:root:[!] Wed Dec 28 20:19:38 2022: Dumped results:
                model     : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\preTraining\trainingFiles_1672255178-model.torch
                losses    : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\preTraining\trainingFiles_1672255178-train_losses.npy
                duration  : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\preTraining\trainingFiles_1672255178-trainTime.npy
WARNING:root: [!] Training pretrained model on downstream task...
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Wed Dec 28 20:19:39 2022: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 0.707066 | FPR 0.01 -- TPR 0.0402 | F1 0.0773 | Elapsed: 0.45s
WARNING:root: [*] Wed Dec 28 20:19:59 2022: Train Epoch: 1 [12800/15226 (83%)]	Loss: 0.298833 | FPR 0.01 -- TPR 0.3697 | F1 0.5398 | Elapsed: 19.97s
WARNING:root: [*] Wed Dec 28 20:20:02 2022:    1    | Tr.loss: 0.347477 | FPR 0.01 -- TPR: 0.30 |  F1: 0.44 | Elapsed:   23.84  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Wed Dec 28 20:20:03 2022: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.208940 | FPR 0.01 -- TPR 0.6932 | F1 0.8188 | Elapsed: 0.40s
WARNING:root: [*] Wed Dec 28 20:20:22 2022: Train Epoch: 2 [12800/15226 (83%)]	Loss: 0.092005 | FPR 0.01 -- TPR 0.9368 | F1 0.9674 | Elapsed: 19.93s
WARNING:root: [*] Wed Dec 28 20:20:26 2022:    2    | Tr.loss: 0.149496 | FPR 0.01 -- TPR: 0.79 |  F1: 0.87 | Elapsed:   23.70  s
WARNING:root:[!] Wed Dec 28 20:20:26 2022: Dumped results:
                model     : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_pretrained\trainingFiles_1672255226-model.torch
                losses    : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_pretrained\trainingFiles_1672255226-train_losses.npy
                duration  : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_pretrained\trainingFiles_1672255226-trainTime.npy
		train F1s : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_pretrained\trainingFiles_1672255226-trainF1s.npy
		train TPRs: evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_pretrained\trainingFiles_1672255226-trainTPRs.npy
WARNING:root: [!] Training non_pretrained model on downstream task...
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Wed Dec 28 20:20:27 2022: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 0.704569 | FPR 0.01 -- TPR 0.0345 | F1 0.0667 | Elapsed: 0.44s
WARNING:root: [*] Wed Dec 28 20:20:46 2022: Train Epoch: 1 [12800/15226 (83%)]	Loss: 0.240679 | FPR 0.01 -- TPR 0.6949 | F1 0.8200 | Elapsed: 19.59s
WARNING:root: [*] Wed Dec 28 20:20:49 2022:    1    | Tr.loss: 0.472947 | FPR 0.01 -- TPR: 0.29 |  F1: 0.38 | Elapsed:   23.36  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Wed Dec 28 20:20:50 2022: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.212182 | FPR 0.01 -- TPR 0.7048 | F1 0.8269 | Elapsed: 0.39s
WARNING:root: [*] Wed Dec 28 20:21:09 2022: Train Epoch: 2 [12800/15226 (83%)]	Loss: 0.116683 | FPR 0.01 -- TPR 0.9398 | F1 0.9689 | Elapsed: 19.53s
WARNING:root: [*] Wed Dec 28 20:21:13 2022:    2    | Tr.loss: 0.158875 | FPR 0.01 -- TPR: 0.85 |  F1: 0.91 | Elapsed:   23.25  s
WARNING:root:[!] Wed Dec 28 20:21:13 2022: Dumped results:
                model     : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_non_pretrained\trainingFiles_1672255273-model.torch
                losses    : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_non_pretrained\trainingFiles_1672255273-train_losses.npy
                duration  : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_non_pretrained\trainingFiles_1672255273-trainTime.npy
		train F1s : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_non_pretrained\trainingFiles_1672255273-trainF1s.npy
		train TPRs: evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_non_pretrained\trainingFiles_1672255273-trainTPRs.npy
WARNING:root: [!] Training full_data model on downstream task...
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Wed Dec 28 20:21:13 2022: Train Epoch: 1 [  0  /76126 (0 %)]	Loss: 0.685548 | FPR 0.01 -- TPR 0.0333 | F1 0.0645 | Elapsed: 0.40s
WARNING:root: [*] Wed Dec 28 20:21:33 2022: Train Epoch: 1 [12800/76126 (17%)]	Loss: 0.323855 | FPR 0.01 -- TPR 0.6059 | F1 0.7546 | Elapsed: 19.93s
WARNING:root: [*] Wed Dec 28 20:21:53 2022: Train Epoch: 1 [25600/76126 (34%)]	Loss: 0.094160 | FPR 0.01 -- TPR 0.9556 | F1 0.9773 | Elapsed: 19.67s
WARNING:root: [*] Wed Dec 28 20:22:13 2022: Train Epoch: 1 [38400/76126 (50%)]	Loss: 0.121000 | FPR 0.01 -- TPR 0.9379 | F1 0.9679 | Elapsed: 19.58s
WARNING:root: [*] Wed Dec 28 20:22:32 2022: Train Epoch: 1 [51200/76126 (67%)]	Loss: 0.116909 | FPR 0.01 -- TPR 0.3174 | F1 0.4818 | Elapsed: 19.59s
WARNING:root: [*] Wed Dec 28 20:22:52 2022: Train Epoch: 1 [64000/76126 (84%)]	Loss: 0.065927 | FPR 0.01 -- TPR 0.9699 | F1 0.9847 | Elapsed: 19.65s
WARNING:root: [*] Wed Dec 28 20:23:10 2022:    1    | Tr.loss: 0.185373 | FPR 0.01 -- TPR: 0.76 |  F1: 0.82 | Elapsed:  117.00  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Wed Dec 28 20:23:10 2022: Train Epoch: 2 [  0  /76126 (0 %)]	Loss: 0.067076 | FPR 0.01 -- TPR 0.9371 | F1 0.9676 | Elapsed: 0.43s
WARNING:root: [*] Wed Dec 28 20:23:30 2022: Train Epoch: 2 [12800/76126 (17%)]	Loss: 0.054782 | FPR 0.01 -- TPR 0.9577 | F1 0.9784 | Elapsed: 19.58s
WARNING:root: [*] Wed Dec 28 20:23:50 2022: Train Epoch: 2 [25600/76126 (34%)]	Loss: 0.054959 | FPR 0.01 -- TPR 0.9779 | F1 0.9888 | Elapsed: 19.54s
WARNING:root: [*] Wed Dec 28 20:24:09 2022: Train Epoch: 2 [38400/76126 (50%)]	Loss: 0.043572 | FPR 0.01 -- TPR 0.9593 | F1 0.9792 | Elapsed: 19.60s
WARNING:root: [*] Wed Dec 28 20:24:29 2022: Train Epoch: 2 [51200/76126 (67%)]	Loss: 0.073427 | FPR 0.01 -- TPR 0.9543 | F1 0.9766 | Elapsed: 19.55s
WARNING:root: [*] Wed Dec 28 20:24:48 2022: Train Epoch: 2 [64000/76126 (84%)]	Loss: 0.067029 | FPR 0.01 -- TPR 0.9200 | F1 0.9583 | Elapsed: 19.55s
WARNING:root: [*] Wed Dec 28 20:25:07 2022:    2    | Tr.loss: 0.066228 | FPR 0.01 -- TPR: 0.93 |  F1: 0.96 | Elapsed:  116.44  s
WARNING:root:[!] Wed Dec 28 20:25:07 2022: Dumped results:
                model     : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_full_data\trainingFiles_1672255507-model.torch
                losses    : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_full_data\trainingFiles_1672255507-train_losses.npy
                duration  : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_full_data\trainingFiles_1672255507-trainTime.npy
		train F1s : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_full_data\trainingFiles_1672255507-trainF1s.npy
		train TPRs: evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_full_data\trainingFiles_1672255507-trainTPRs.npy
WARNING:root: [*] Evaluating pretrained model on test set...
WARNING:root: [!] Test F1 score for pretrained model at 0.01 FPR : 0.7882
WARNING:root: [!] Test TPR score for pretrained model at 0.01 FPR: 0.6564
WARNING:root: [*] Evaluating non_pretrained model on test set...
WARNING:root: [!] Test F1 score for non_pretrained model at 0.01 FPR : 0.7925
WARNING:root: [!] Test TPR score for non_pretrained model at 0.01 FPR: 0.6662
WARNING:root: [*] Evaluating full_data model on test set...
WARNING:root: [!] Test F1 score for full_data model at 0.01 FPR : 0.8859
WARNING:root: [!] Test TPR score for full_data model at 0.01 FPR: 0.8036
WARNING:root: [!] Running pre-training split 5/5
WARNING:root: [!] Pre-training model...
WARNING:root: [*] Masking sequences...
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Wed Dec 28 20:25:52 2022: Train Epoch: 1 [  0  /60900 (0 %)]	Loss: 483.124176 | Not computing TPR and F1 | Elapsed: 0.79s
WARNING:root: [*] Wed Dec 28 20:26:12 2022: Train Epoch: 1 [12800/60900 (21%)]	Loss: 368.225433 | Not computing TPR and F1 | Elapsed: 20.49s
WARNING:root: [*] Wed Dec 28 20:26:33 2022: Train Epoch: 1 [25600/60900 (42%)]	Loss: 394.841309 | Not computing TPR and F1 | Elapsed: 20.89s
WARNING:root: [*] Wed Dec 28 20:26:54 2022: Train Epoch: 1 [38400/60900 (63%)]	Loss: 364.332672 | Not computing TPR and F1 | Elapsed: 21.04s
WARNING:root: [*] Wed Dec 28 20:27:16 2022: Train Epoch: 1 [51200/60900 (84%)]	Loss: 364.966309 | Not computing TPR and F1 | Elapsed: 21.43s
WARNING:root: [*] Wed Dec 28 20:27:31 2022:    1    | Tr.loss: 364.139986 | Not computing TPR and F1 | Elapsed:  100.23  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Wed Dec 28 20:27:32 2022: Train Epoch: 2 [  0  /60900 (0 %)]	Loss: 314.557404 | Not computing TPR and F1 | Elapsed: 0.44s
WARNING:root: [*] Wed Dec 28 20:27:53 2022: Train Epoch: 2 [12800/60900 (21%)]	Loss: 350.010132 | Not computing TPR and F1 | Elapsed: 21.11s
WARNING:root: [*] Wed Dec 28 20:28:14 2022: Train Epoch: 2 [25600/60900 (42%)]	Loss: 307.516968 | Not computing TPR and F1 | Elapsed: 20.97s
WARNING:root: [*] Wed Dec 28 20:28:34 2022: Train Epoch: 2 [38400/60900 (63%)]	Loss: 314.780670 | Not computing TPR and F1 | Elapsed: 20.76s
WARNING:root: [*] Wed Dec 28 20:28:55 2022: Train Epoch: 2 [51200/60900 (84%)]	Loss: 327.864685 | Not computing TPR and F1 | Elapsed: 20.86s
WARNING:root: [*] Wed Dec 28 20:29:11 2022:    2    | Tr.loss: 323.671106 | Not computing TPR and F1 | Elapsed:   99.60  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Wed Dec 28 20:29:11 2022: Train Epoch: 3 [  0  /60900 (0 %)]	Loss: 313.294464 | Not computing TPR and F1 | Elapsed: 0.45s
WARNING:root: [*] Wed Dec 28 20:29:32 2022: Train Epoch: 3 [12800/60900 (21%)]	Loss: 305.538452 | Not computing TPR and F1 | Elapsed: 20.76s
WARNING:root: [*] Wed Dec 28 20:29:53 2022: Train Epoch: 3 [25600/60900 (42%)]	Loss: 309.392273 | Not computing TPR and F1 | Elapsed: 20.77s
WARNING:root: [*] Wed Dec 28 20:30:14 2022: Train Epoch: 3 [38400/60900 (63%)]	Loss: 320.592194 | Not computing TPR and F1 | Elapsed: 20.83s
WARNING:root: [*] Wed Dec 28 20:30:35 2022: Train Epoch: 3 [51200/60900 (84%)]	Loss: 327.099792 | Not computing TPR and F1 | Elapsed: 20.92s
WARNING:root: [*] Wed Dec 28 20:30:50 2022:    3    | Tr.loss: 314.115466 | Not computing TPR and F1 | Elapsed:   99.26  s
WARNING:root: [*] Started epoch: 4
WARNING:root: [*] Wed Dec 28 20:30:51 2022: Train Epoch: 4 [  0  /60900 (0 %)]	Loss: 293.720917 | Not computing TPR and F1 | Elapsed: 0.45s
WARNING:root: [*] Wed Dec 28 20:31:11 2022: Train Epoch: 4 [12800/60900 (21%)]	Loss: 323.358276 | Not computing TPR and F1 | Elapsed: 20.79s
WARNING:root: [*] Wed Dec 28 20:31:32 2022: Train Epoch: 4 [25600/60900 (42%)]	Loss: 295.979370 | Not computing TPR and F1 | Elapsed: 20.83s
WARNING:root: [*] Wed Dec 28 20:31:53 2022: Train Epoch: 4 [38400/60900 (63%)]	Loss: 307.746338 | Not computing TPR and F1 | Elapsed: 20.89s
WARNING:root: [*] Wed Dec 28 20:32:14 2022: Train Epoch: 4 [51200/60900 (84%)]	Loss: 299.153809 | Not computing TPR and F1 | Elapsed: 20.92s
WARNING:root: [*] Wed Dec 28 20:32:29 2022:    4    | Tr.loss: 305.650574 | Not computing TPR and F1 | Elapsed:   99.29  s
WARNING:root: [*] Started epoch: 5
WARNING:root: [*] Wed Dec 28 20:32:30 2022: Train Epoch: 5 [  0  /60900 (0 %)]	Loss: 296.186615 | Not computing TPR and F1 | Elapsed: 0.47s
WARNING:root: [*] Wed Dec 28 20:32:51 2022: Train Epoch: 5 [12800/60900 (21%)]	Loss: 300.380676 | Not computing TPR and F1 | Elapsed: 20.83s
WARNING:root: [*] Wed Dec 28 20:33:11 2022: Train Epoch: 5 [25600/60900 (42%)]	Loss: 298.916504 | Not computing TPR and F1 | Elapsed: 20.85s
WARNING:root: [*] Wed Dec 28 20:33:32 2022: Train Epoch: 5 [38400/60900 (63%)]	Loss: 297.468018 | Not computing TPR and F1 | Elapsed: 20.88s
WARNING:root: [*] Wed Dec 28 20:33:54 2022: Train Epoch: 5 [51200/60900 (84%)]	Loss: 315.773193 | Not computing TPR and F1 | Elapsed: 21.15s
WARNING:root: [*] Wed Dec 28 20:34:09 2022:    5    | Tr.loss: 300.294419 | Not computing TPR and F1 | Elapsed:   99.34  s
WARNING:root:[!] Wed Dec 28 20:34:09 2022: Dumped results:
                model     : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\preTraining\trainingFiles_1672256049-model.torch
                losses    : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\preTraining\trainingFiles_1672256049-train_losses.npy
                duration  : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\preTraining\trainingFiles_1672256049-trainTime.npy
WARNING:root: [!] Training pretrained model on downstream task...
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Wed Dec 28 20:34:10 2022: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 0.834676 | FPR 0.01 -- TPR 0.0060 | F1 0.0119 | Elapsed: 0.39s
WARNING:root: [*] Wed Dec 28 20:34:29 2022: Train Epoch: 1 [12800/15226 (83%)]	Loss: 0.276238 | FPR 0.01 -- TPR 0.3408 | F1 0.5083 | Elapsed: 19.65s
WARNING:root: [*] Wed Dec 28 20:34:33 2022:    1    | Tr.loss: 0.417295 | FPR 0.01 -- TPR: 0.24 |  F1: 0.37 | Elapsed:   23.43  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Wed Dec 28 20:34:33 2022: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.215883 | FPR 0.01 -- TPR 0.4551 | F1 0.6255 | Elapsed: 0.41s
WARNING:root: [*] Wed Dec 28 20:34:53 2022: Train Epoch: 2 [12800/15226 (83%)]	Loss: 0.161836 | FPR 0.01 -- TPR 0.6171 | F1 0.7633 | Elapsed: 19.91s
WARNING:root: [*] Wed Dec 28 20:34:56 2022:    2    | Tr.loss: 0.163564 | FPR 0.01 -- TPR: 0.71 |  F1: 0.82 | Elapsed:   23.70  s
WARNING:root:[!] Wed Dec 28 20:34:56 2022: Dumped results:
                model     : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_pretrained\trainingFiles_1672256096-model.torch
                losses    : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_pretrained\trainingFiles_1672256096-train_losses.npy
                duration  : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_pretrained\trainingFiles_1672256096-trainTime.npy
		train F1s : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_pretrained\trainingFiles_1672256096-trainF1s.npy
		train TPRs: evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_pretrained\trainingFiles_1672256096-trainTPRs.npy
WARNING:root: [!] Training non_pretrained model on downstream task...
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Wed Dec 28 20:34:57 2022: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 0.693876 | FPR 0.01 -- TPR 0.0000 | F1 0.0000 | Elapsed: 0.42s
WARNING:root: [*] Wed Dec 28 20:35:17 2022: Train Epoch: 1 [12800/15226 (83%)]	Loss: 0.238876 | FPR 0.01 -- TPR 0.7257 | F1 0.8411 | Elapsed: 19.57s
WARNING:root: [*] Wed Dec 28 20:35:20 2022:    1    | Tr.loss: 0.457144 | FPR 0.01 -- TPR: 0.30 |  F1: 0.39 | Elapsed:   23.32  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Wed Dec 28 20:35:20 2022: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.156969 | FPR 0.01 -- TPR 0.8480 | F1 0.9177 | Elapsed: 0.41s
WARNING:root: [*] Wed Dec 28 20:35:40 2022: Train Epoch: 2 [12800/15226 (83%)]	Loss: 0.152172 | FPR 0.01 -- TPR 0.9329 | F1 0.9653 | Elapsed: 19.68s
WARNING:root: [*] Wed Dec 28 20:35:43 2022:    2    | Tr.loss: 0.139841 | FPR 0.01 -- TPR: 0.86 |  F1: 0.92 | Elapsed:   23.42  s
WARNING:root:[!] Wed Dec 28 20:35:43 2022: Dumped results:
                model     : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_non_pretrained\trainingFiles_1672256143-model.torch
                losses    : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_non_pretrained\trainingFiles_1672256143-train_losses.npy
                duration  : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_non_pretrained\trainingFiles_1672256143-trainTime.npy
		train F1s : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_non_pretrained\trainingFiles_1672256143-trainF1s.npy
		train TPRs: evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_non_pretrained\trainingFiles_1672256143-trainTPRs.npy
WARNING:root: [!] Training full_data model on downstream task...
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Wed Dec 28 20:35:44 2022: Train Epoch: 1 [  0  /76126 (0 %)]	Loss: 0.682438 | FPR 0.01 -- TPR 0.0118 | F1 0.0233 | Elapsed: 0.40s
WARNING:root: [*] Wed Dec 28 20:36:04 2022: Train Epoch: 1 [12800/76126 (17%)]	Loss: 0.310698 | FPR 0.01 -- TPR 0.5722 | F1 0.7279 | Elapsed: 19.59s
WARNING:root: [*] Wed Dec 28 20:36:23 2022: Train Epoch: 1 [25600/76126 (34%)]	Loss: 0.139984 | FPR 0.01 -- TPR 0.8785 | F1 0.9353 | Elapsed: 19.60s
WARNING:root: [*] Wed Dec 28 20:36:43 2022: Train Epoch: 1 [38400/76126 (50%)]	Loss: 0.125030 | FPR 0.01 -- TPR 0.9200 | F1 0.9583 | Elapsed: 19.57s
WARNING:root: [*] Wed Dec 28 20:37:02 2022: Train Epoch: 1 [51200/76126 (67%)]	Loss: 0.126037 | FPR 0.01 -- TPR 0.8294 | F1 0.9068 | Elapsed: 19.60s
WARNING:root: [*] Wed Dec 28 20:37:22 2022: Train Epoch: 1 [64000/76126 (84%)]	Loss: 0.100743 | FPR 0.01 -- TPR 0.8750 | F1 0.9333 | Elapsed: 19.59s
WARNING:root: [*] Wed Dec 28 20:37:40 2022:    1    | Tr.loss: 0.176132 | FPR 0.01 -- TPR: 0.75 |  F1: 0.81 | Elapsed:  116.56  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Wed Dec 28 20:37:41 2022: Train Epoch: 2 [  0  /76126 (0 %)]	Loss: 0.051251 | FPR 0.01 -- TPR 0.9653 | F1 0.9824 | Elapsed: 0.40s
WARNING:root: [*] Wed Dec 28 20:38:00 2022: Train Epoch: 2 [12800/76126 (17%)]	Loss: 0.037800 | FPR 0.01 -- TPR 0.9719 | F1 0.9858 | Elapsed: 19.61s
WARNING:root: [*] Wed Dec 28 20:38:20 2022: Train Epoch: 2 [25600/76126 (34%)]	Loss: 0.089055 | FPR 0.01 -- TPR 0.9207 | F1 0.9587 | Elapsed: 19.64s
WARNING:root: [*] Wed Dec 28 20:38:40 2022: Train Epoch: 2 [38400/76126 (50%)]	Loss: 0.025376 | FPR 0.01 -- TPR 0.9941 | F1 0.9970 | Elapsed: 19.61s
WARNING:root: [*] Wed Dec 28 20:38:59 2022: Train Epoch: 2 [51200/76126 (67%)]	Loss: 0.147843 | FPR 0.01 -- TPR 0.9713 | F1 0.9854 | Elapsed: 19.58s
WARNING:root: [*] Wed Dec 28 20:39:19 2022: Train Epoch: 2 [64000/76126 (84%)]	Loss: 0.072196 | FPR 0.01 -- TPR 0.8855 | F1 0.9393 | Elapsed: 19.59s
WARNING:root: [*] Wed Dec 28 20:39:37 2022:    2    | Tr.loss: 0.067361 | FPR 0.01 -- TPR: 0.92 |  F1: 0.96 | Elapsed:  116.64  s
WARNING:root:[!] Wed Dec 28 20:39:37 2022: Dumped results:
                model     : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_full_data\trainingFiles_1672256377-model.torch
                losses    : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_full_data\trainingFiles_1672256377-train_losses.npy
                duration  : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_full_data\trainingFiles_1672256377-trainTime.npy
		train F1s : evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_full_data\trainingFiles_1672256377-trainF1s.npy
		train TPRs: evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066\downstreamTask_full_data\trainingFiles_1672256377-trainTPRs.npy
WARNING:root: [*] Evaluating pretrained model on test set...
WARNING:root: [!] Test F1 score for pretrained model at 0.01 FPR : 0.7899
WARNING:root: [!] Test TPR score for pretrained model at 0.01 FPR: 0.6616
WARNING:root: [*] Evaluating non_pretrained model on test set...
WARNING:root: [!] Test F1 score for non_pretrained model at 0.01 FPR : 0.7676
WARNING:root: [!] Test TPR score for non_pretrained model at 0.01 FPR: 0.6310
WARNING:root: [*] Evaluating full_data model on test set...
WARNING:root: [!] Test F1 score for full_data model at 0.01 FPR : 0.8675
WARNING:root: [!] Test TPR score for full_data model at 0.01 FPR: 0.7726
WARNING:root: [!] Finished pre-training evaluation over 5 splits! Saved metrics to:
	evaluation\MaskedLanguageModeling\deeperCnn_unlabeledDataSize_0.8_preTrain_5_downStream_2_nSplits_5_1672252066/metrics_MaskedLanguageModel_nSplits_5_limit_None.json
