01/28/2023 10:54:13 AM  [!] Starting Masked Language Model evaluation over 3 splits!
01/28/2023 10:54:13 AM  [!] Loaded data and vocab. X train size: (76126, 512), X test size: (17407, 512), vocab size: 50002
01/28/2023 10:54:13 AM  [!] Initiating Self-Supervised Learning Pretraining
     Language Modeling MaskedLanguageModel
     Model TransformerEncoderLM with config:
	{'vocabSize': 50002, 'maxLen': 512, 'dModel': 64, 'nHeads': 8, 'dHidden': 256, 'nLayers': 2, 'numClasses': 1, 'hiddenNeurons': [64], 'dropout': 0.3}

01/28/2023 10:54:13 AM  [!] Running pre-training split 1/3
01/28/2023 10:54:16 AM  [!] Pre-training model...
01/28/2023 10:54:16 AM  [*] Masking sequences...
01/28/2023 10:54:32 AM  [*] Started epoch: 1
01/28/2023 10:54:34 AM  [*] Sat Jan 28 10:54:34 2023: Train Epoch: 1 [  0  /53288 (0 %)]	Loss: 412.843567 | Elapsed: 2.28s
01/28/2023 10:54:46 AM  [*] Sat Jan 28 10:54:46 2023: Train Epoch: 1 [6400 /53288 (12%)]	Loss: 212.443954 | Elapsed: 11.66s
01/28/2023 10:54:58 AM  [*] Sat Jan 28 10:54:58 2023: Train Epoch: 1 [12800/53288 (24%)]	Loss: 223.312286 | Elapsed: 12.17s
01/28/2023 10:55:11 AM  [*] Sat Jan 28 10:55:11 2023: Train Epoch: 1 [19200/53288 (36%)]	Loss: 210.177887 | Elapsed: 12.52s
01/28/2023 10:55:23 AM  [*] Sat Jan 28 10:55:23 2023: Train Epoch: 1 [25600/53288 (48%)]	Loss: 196.672455 | Elapsed: 12.61s
01/28/2023 10:55:36 AM  [*] Sat Jan 28 10:55:36 2023: Train Epoch: 1 [32000/53288 (60%)]	Loss: 182.938309 | Elapsed: 12.61s
01/28/2023 10:55:48 AM  [*] Sat Jan 28 10:55:48 2023: Train Epoch: 1 [38400/53288 (72%)]	Loss: 194.855072 | Elapsed: 12.63s
01/28/2023 10:56:01 AM  [*] Sat Jan 28 10:56:01 2023: Train Epoch: 1 [44800/53288 (84%)]	Loss: 187.755493 | Elapsed: 12.63s
01/28/2023 10:56:14 AM  [*] Sat Jan 28 10:56:14 2023: Train Epoch: 1 [51200/53288 (96%)]	Loss: 186.955383 | Elapsed: 12.71s
01/28/2023 10:56:19 AM  [*] Sat Jan 28 10:56:19 2023:    1    | Tr.loss: 210.963897 | Elapsed:  107.31  s
01/28/2023 10:56:19 AM  [*] Started epoch: 2
01/28/2023 10:56:19 AM  [*] Sat Jan 28 10:56:19 2023: Train Epoch: 2 [  0  /53288 (0 %)]	Loss: 187.930847 | Elapsed: 0.14s
01/28/2023 10:56:32 AM  [*] Sat Jan 28 10:56:32 2023: Train Epoch: 2 [6400 /53288 (12%)]	Loss: 199.672012 | Elapsed: 12.45s
01/28/2023 10:56:44 AM  [*] Sat Jan 28 10:56:44 2023: Train Epoch: 2 [12800/53288 (24%)]	Loss: 185.355194 | Elapsed: 12.36s
01/28/2023 10:56:57 AM  [*] Sat Jan 28 10:56:57 2023: Train Epoch: 2 [19200/53288 (36%)]	Loss: 202.900452 | Elapsed: 12.51s
01/28/2023 10:57:09 AM  [*] Sat Jan 28 10:57:09 2023: Train Epoch: 2 [25600/53288 (48%)]	Loss: 199.501892 | Elapsed: 12.42s
01/28/2023 10:57:22 AM  [*] Sat Jan 28 10:57:22 2023: Train Epoch: 2 [32000/53288 (60%)]	Loss: 182.359314 | Elapsed: 12.43s
01/28/2023 10:57:34 AM  [*] Sat Jan 28 10:57:34 2023: Train Epoch: 2 [38400/53288 (72%)]	Loss: 180.278702 | Elapsed: 12.55s
01/28/2023 10:57:47 AM  [*] Sat Jan 28 10:57:47 2023: Train Epoch: 2 [44800/53288 (84%)]	Loss: 193.087006 | Elapsed: 12.41s
01/28/2023 10:57:59 AM  [*] Sat Jan 28 10:57:59 2023: Train Epoch: 2 [51200/53288 (96%)]	Loss: 188.444946 | Elapsed: 12.48s
01/28/2023 10:58:05 AM  [*] Sat Jan 28 10:58:05 2023:    2    | Tr.loss: 190.469572 | Elapsed:  105.35  s
01/28/2023 10:58:05 AM  [*] Started epoch: 3
01/28/2023 10:58:05 AM  [*] Sat Jan 28 10:58:05 2023: Train Epoch: 3 [  0  /53288 (0 %)]	Loss: 193.641022 | Elapsed: 0.14s
01/28/2023 10:58:17 AM  [*] Sat Jan 28 10:58:17 2023: Train Epoch: 3 [6400 /53288 (12%)]	Loss: 199.730133 | Elapsed: 12.47s
01/28/2023 10:58:30 AM  [*] Sat Jan 28 10:58:30 2023: Train Epoch: 3 [12800/53288 (24%)]	Loss: 182.574295 | Elapsed: 12.46s
01/28/2023 10:58:42 AM  [*] Sat Jan 28 10:58:42 2023: Train Epoch: 3 [19200/53288 (36%)]	Loss: 173.859634 | Elapsed: 12.42s
01/28/2023 10:58:55 AM  [*] Sat Jan 28 10:58:55 2023: Train Epoch: 3 [25600/53288 (48%)]	Loss: 188.676208 | Elapsed: 12.50s
01/28/2023 10:59:07 AM  [*] Sat Jan 28 10:59:07 2023: Train Epoch: 3 [32000/53288 (60%)]	Loss: 194.819229 | Elapsed: 12.47s
01/28/2023 10:59:20 AM  [*] Sat Jan 28 10:59:20 2023: Train Epoch: 3 [38400/53288 (72%)]	Loss: 202.258087 | Elapsed: 12.49s
01/28/2023 10:59:32 AM  [*] Sat Jan 28 10:59:32 2023: Train Epoch: 3 [44800/53288 (84%)]	Loss: 163.892303 | Elapsed: 12.46s
01/28/2023 10:59:45 AM  [*] Sat Jan 28 10:59:45 2023: Train Epoch: 3 [51200/53288 (96%)]	Loss: 181.195602 | Elapsed: 12.55s
01/28/2023 10:59:50 AM  [*] Sat Jan 28 10:59:50 2023:    3    | Tr.loss: 185.250428 | Elapsed:  105.32  s
01/28/2023 10:59:50 AM  [*] Started epoch: 4
01/28/2023 10:59:50 AM  [*] Sat Jan 28 10:59:50 2023: Train Epoch: 4 [  0  /53288 (0 %)]	Loss: 176.674286 | Elapsed: 0.12s
01/28/2023 11:00:03 AM  [*] Sat Jan 28 11:00:03 2023: Train Epoch: 4 [6400 /53288 (12%)]	Loss: 185.875549 | Elapsed: 12.54s
01/28/2023 11:00:15 AM  [*] Sat Jan 28 11:00:15 2023: Train Epoch: 4 [12800/53288 (24%)]	Loss: 177.442184 | Elapsed: 12.67s
01/28/2023 11:00:28 AM  [*] Sat Jan 28 11:00:28 2023: Train Epoch: 4 [19200/53288 (36%)]	Loss: 173.568680 | Elapsed: 12.61s
01/28/2023 11:00:40 AM  [*] Sat Jan 28 11:00:40 2023: Train Epoch: 4 [25600/53288 (48%)]	Loss: 171.012207 | Elapsed: 12.42s
01/28/2023 11:00:53 AM  [*] Sat Jan 28 11:00:53 2023: Train Epoch: 4 [32000/53288 (60%)]	Loss: 177.297455 | Elapsed: 12.41s
01/28/2023 11:01:05 AM  [*] Sat Jan 28 11:01:05 2023: Train Epoch: 4 [38400/53288 (72%)]	Loss: 177.860168 | Elapsed: 12.41s
01/28/2023 11:01:18 AM  [*] Sat Jan 28 11:01:18 2023: Train Epoch: 4 [44800/53288 (84%)]	Loss: 176.514328 | Elapsed: 12.44s
01/28/2023 11:01:30 AM  [*] Sat Jan 28 11:01:30 2023: Train Epoch: 4 [51200/53288 (96%)]	Loss: 188.428329 | Elapsed: 12.47s
01/28/2023 11:01:35 AM  [*] Sat Jan 28 11:01:35 2023:    4    | Tr.loss: 182.500657 | Elapsed:  105.45  s
01/28/2023 11:01:35 AM  [*] Started epoch: 5
01/28/2023 11:01:36 AM  [*] Sat Jan 28 11:01:36 2023: Train Epoch: 5 [  0  /53288 (0 %)]	Loss: 191.630920 | Elapsed: 0.14s
01/28/2023 11:01:48 AM  [*] Sat Jan 28 11:01:48 2023: Train Epoch: 5 [6400 /53288 (12%)]	Loss: 185.934296 | Elapsed: 12.45s
01/28/2023 11:02:01 AM  [*] Sat Jan 28 11:02:01 2023: Train Epoch: 5 [12800/53288 (24%)]	Loss: 171.665985 | Elapsed: 12.49s
01/28/2023 11:02:13 AM  [*] Sat Jan 28 11:02:13 2023: Train Epoch: 5 [19200/53288 (36%)]	Loss: 156.562775 | Elapsed: 12.43s
01/28/2023 11:02:25 AM  [*] Sat Jan 28 11:02:25 2023: Train Epoch: 5 [25600/53288 (48%)]	Loss: 183.864868 | Elapsed: 12.44s
01/28/2023 11:02:38 AM  [*] Sat Jan 28 11:02:38 2023: Train Epoch: 5 [32000/53288 (60%)]	Loss: 175.563507 | Elapsed: 12.56s
01/28/2023 11:02:50 AM  [*] Sat Jan 28 11:02:50 2023: Train Epoch: 5 [38400/53288 (72%)]	Loss: 188.660034 | Elapsed: 12.46s
01/28/2023 11:03:03 AM  [*] Sat Jan 28 11:03:03 2023: Train Epoch: 5 [44800/53288 (84%)]	Loss: 162.419983 | Elapsed: 12.48s
01/28/2023 11:03:15 AM  [*] Sat Jan 28 11:03:15 2023: Train Epoch: 5 [51200/53288 (96%)]	Loss: 155.496643 | Elapsed: 12.47s
01/28/2023 11:03:21 AM  [*] Sat Jan 28 11:03:21 2023:    5    | Tr.loss: 180.748849 | Elapsed:  105.29  s
01/28/2023 11:03:21 AM  [*] Started epoch: 6
01/28/2023 11:03:21 AM  [*] Sat Jan 28 11:03:21 2023: Train Epoch: 6 [  0  /53288 (0 %)]	Loss: 181.143829 | Elapsed: 0.13s
01/28/2023 11:03:33 AM  [*] Sat Jan 28 11:03:33 2023: Train Epoch: 6 [6400 /53288 (12%)]	Loss: 186.335144 | Elapsed: 12.42s
01/28/2023 11:03:46 AM  [*] Sat Jan 28 11:03:46 2023: Train Epoch: 6 [12800/53288 (24%)]	Loss: 176.000931 | Elapsed: 12.42s
01/28/2023 11:03:58 AM  [*] Sat Jan 28 11:03:58 2023: Train Epoch: 6 [19200/53288 (36%)]	Loss: 196.432587 | Elapsed: 12.49s
01/28/2023 11:04:11 AM  [*] Sat Jan 28 11:04:11 2023: Train Epoch: 6 [25600/53288 (48%)]	Loss: 204.476227 | Elapsed: 12.45s
01/28/2023 11:04:23 AM  [*] Sat Jan 28 11:04:23 2023: Train Epoch: 6 [32000/53288 (60%)]	Loss: 183.572983 | Elapsed: 12.36s
01/28/2023 11:04:35 AM  [*] Sat Jan 28 11:04:35 2023: Train Epoch: 6 [38400/53288 (72%)]	Loss: 161.945892 | Elapsed: 12.41s
01/28/2023 11:04:48 AM  [*] Sat Jan 28 11:04:48 2023: Train Epoch: 6 [44800/53288 (84%)]	Loss: 181.132812 | Elapsed: 12.37s
01/28/2023 11:05:00 AM  [*] Sat Jan 28 11:05:00 2023: Train Epoch: 6 [51200/53288 (96%)]	Loss: 181.787872 | Elapsed: 12.37s
01/28/2023 11:05:06 AM  [*] Sat Jan 28 11:05:06 2023:    6    | Tr.loss: 179.379774 | Elapsed:  104.89  s
01/28/2023 11:05:06 AM  [*] Started epoch: 7
01/28/2023 11:05:06 AM  [*] Sat Jan 28 11:05:06 2023: Train Epoch: 7 [  0  /53288 (0 %)]	Loss: 191.112808 | Elapsed: 0.13s
01/28/2023 11:05:06 AM [!] Learning rate: 2.5e-05
01/28/2023 11:05:18 AM  [*] Sat Jan 28 11:05:18 2023: Train Epoch: 7 [6400 /53288 (12%)]	Loss: 174.714096 | Elapsed: 12.40s
01/28/2023 11:05:31 AM  [*] Sat Jan 28 11:05:31 2023: Train Epoch: 7 [12800/53288 (24%)]	Loss: 180.093643 | Elapsed: 12.46s
01/28/2023 11:05:43 AM  [*] Sat Jan 28 11:05:43 2023: Train Epoch: 7 [19200/53288 (36%)]	Loss: 168.638794 | Elapsed: 12.40s
01/28/2023 11:05:55 AM  [*] Sat Jan 28 11:05:55 2023: Train Epoch: 7 [25600/53288 (48%)]	Loss: 176.063446 | Elapsed: 12.36s
01/28/2023 11:06:08 AM  [*] Sat Jan 28 11:06:08 2023: Train Epoch: 7 [32000/53288 (60%)]	Loss: 168.175369 | Elapsed: 12.37s
01/28/2023 11:06:20 AM  [*] Sat Jan 28 11:06:20 2023: Train Epoch: 7 [38400/53288 (72%)]	Loss: 193.828827 | Elapsed: 12.40s
01/28/2023 11:06:32 AM  [*] Sat Jan 28 11:06:32 2023: Train Epoch: 7 [44800/53288 (84%)]	Loss: 195.927673 | Elapsed: 12.35s
01/28/2023 11:06:45 AM  [*] Sat Jan 28 11:06:45 2023: Train Epoch: 7 [51200/53288 (96%)]	Loss: 173.175537 | Elapsed: 12.38s
01/28/2023 11:06:50 AM  [*] Sat Jan 28 11:06:50 2023:    7    | Tr.loss: 177.966910 | Elapsed:  104.68  s
01/28/2023 11:06:50 AM  [*] Started epoch: 8
01/28/2023 11:06:50 AM  [*] Sat Jan 28 11:06:50 2023: Train Epoch: 8 [  0  /53288 (0 %)]	Loss: 169.216675 | Elapsed: 0.13s
01/28/2023 11:07:03 AM  [*] Sat Jan 28 11:07:03 2023: Train Epoch: 8 [6400 /53288 (12%)]	Loss: 174.809540 | Elapsed: 12.43s
01/28/2023 11:07:15 AM  [*] Sat Jan 28 11:07:15 2023: Train Epoch: 8 [12800/53288 (24%)]	Loss: 191.904694 | Elapsed: 12.39s
01/28/2023 11:07:28 AM  [*] Sat Jan 28 11:07:28 2023: Train Epoch: 8 [19200/53288 (36%)]	Loss: 175.944885 | Elapsed: 12.35s
01/28/2023 11:07:40 AM  [*] Sat Jan 28 11:07:40 2023: Train Epoch: 8 [25600/53288 (48%)]	Loss: 179.758270 | Elapsed: 12.40s
01/28/2023 11:07:53 AM  [*] Sat Jan 28 11:07:53 2023: Train Epoch: 8 [32000/53288 (60%)]	Loss: 180.633759 | Elapsed: 12.52s
01/28/2023 11:08:05 AM  [*] Sat Jan 28 11:08:05 2023: Train Epoch: 8 [38400/53288 (72%)]	Loss: 178.517731 | Elapsed: 12.39s
01/28/2023 11:08:17 AM  [*] Sat Jan 28 11:08:17 2023: Train Epoch: 8 [44800/53288 (84%)]	Loss: 179.619110 | Elapsed: 12.38s
01/28/2023 11:08:30 AM  [*] Sat Jan 28 11:08:30 2023: Train Epoch: 8 [51200/53288 (96%)]	Loss: 163.444473 | Elapsed: 12.32s
01/28/2023 11:08:35 AM  [*] Sat Jan 28 11:08:35 2023:    8    | Tr.loss: 177.655334 | Elapsed:  104.79  s
01/28/2023 11:08:35 AM  [*] Started epoch: 9
01/28/2023 11:08:35 AM  [*] Sat Jan 28 11:08:35 2023: Train Epoch: 9 [  0  /53288 (0 %)]	Loss: 173.285110 | Elapsed: 0.13s
01/28/2023 11:08:48 AM  [*] Sat Jan 28 11:08:48 2023: Train Epoch: 9 [6400 /53288 (12%)]	Loss: 160.153778 | Elapsed: 12.40s
01/28/2023 11:09:00 AM  [*] Sat Jan 28 11:09:00 2023: Train Epoch: 9 [12800/53288 (24%)]	Loss: 177.774567 | Elapsed: 12.35s
01/28/2023 11:09:12 AM  [*] Sat Jan 28 11:09:12 2023: Train Epoch: 9 [19200/53288 (36%)]	Loss: 175.444153 | Elapsed: 12.40s
01/28/2023 11:09:25 AM  [*] Sat Jan 28 11:09:25 2023: Train Epoch: 9 [25600/53288 (48%)]	Loss: 199.133392 | Elapsed: 12.40s
01/28/2023 11:09:37 AM  [*] Sat Jan 28 11:09:37 2023: Train Epoch: 9 [32000/53288 (60%)]	Loss: 179.570312 | Elapsed: 12.44s
01/28/2023 11:09:50 AM  [*] Sat Jan 28 11:09:50 2023: Train Epoch: 9 [38400/53288 (72%)]	Loss: 179.984222 | Elapsed: 12.41s
01/28/2023 11:10:02 AM  [*] Sat Jan 28 11:10:02 2023: Train Epoch: 9 [44800/53288 (84%)]	Loss: 187.093750 | Elapsed: 12.31s
01/28/2023 11:10:14 AM  [*] Sat Jan 28 11:10:14 2023: Train Epoch: 9 [51200/53288 (96%)]	Loss: 175.015350 | Elapsed: 12.37s
01/28/2023 11:10:20 AM  [*] Sat Jan 28 11:10:20 2023:    9    | Tr.loss: 177.451887 | Elapsed:  104.73  s
01/28/2023 11:10:20 AM  [*] Started epoch: 10
01/28/2023 11:10:20 AM  [*] Sat Jan 28 11:10:20 2023: Train Epoch: 10 [  0  /53288 (0 %)]	Loss: 162.054352 | Elapsed: 0.14s
01/28/2023 11:10:32 AM  [*] Sat Jan 28 11:10:32 2023: Train Epoch: 10 [6400 /53288 (12%)]	Loss: 171.980194 | Elapsed: 12.47s
01/28/2023 11:10:45 AM  [*] Sat Jan 28 11:10:45 2023: Train Epoch: 10 [12800/53288 (24%)]	Loss: 172.635315 | Elapsed: 12.49s
01/28/2023 11:10:57 AM  [*] Sat Jan 28 11:10:57 2023: Train Epoch: 10 [19200/53288 (36%)]	Loss: 186.875153 | Elapsed: 12.51s
01/28/2023 11:11:10 AM  [*] Sat Jan 28 11:11:10 2023: Train Epoch: 10 [25600/53288 (48%)]	Loss: 171.848846 | Elapsed: 12.46s
01/28/2023 11:11:22 AM  [*] Sat Jan 28 11:11:22 2023: Train Epoch: 10 [32000/53288 (60%)]	Loss: 195.455566 | Elapsed: 12.48s
01/28/2023 11:11:35 AM  [*] Sat Jan 28 11:11:35 2023: Train Epoch: 10 [38400/53288 (72%)]	Loss: 180.449570 | Elapsed: 12.42s
01/28/2023 11:11:47 AM  [*] Sat Jan 28 11:11:47 2023: Train Epoch: 10 [44800/53288 (84%)]	Loss: 174.516602 | Elapsed: 12.36s
01/28/2023 11:12:00 AM  [*] Sat Jan 28 11:12:00 2023: Train Epoch: 10 [51200/53288 (96%)]	Loss: 184.850677 | Elapsed: 12.53s
01/28/2023 11:12:05 AM  [*] Sat Jan 28 11:12:05 2023:   10    | Tr.loss: 177.268106 | Elapsed:  105.38  s
01/28/2023 11:12:06 AM [!] Sat Jan 28 11:12:06 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\preTraining\training_files\1674900725-model.torch
		train time: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\preTraining\training_files\1674900725-trainTime.npy
		train losses: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\preTraining\training_files\1674900725-trainLosses.npy
		train AUC: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\preTraining\training_files\1674900725-auc.npy
01/28/2023 11:12:06 AM  [!] Training pretrained model on downstream task...
01/28/2023 11:12:06 AM  [*] Started epoch: 1
01/28/2023 11:12:07 AM  [*] Sat Jan 28 11:12:07 2023: Train Epoch: 1 [  0  /22838 (0 %)]	Loss: 1.481398 | Elapsed: 0.33s | FPR 0.0003 -> TPR 0.2128 & F1 0.3509
01/28/2023 11:12:16 AM  [*] Sat Jan 28 11:12:16 2023: Train Epoch: 1 [6400 /22838 (28%)]	Loss: 0.436644 | Elapsed: 9.13s | FPR 0.0003 -> TPR 0.3924 & F1 0.5636
01/28/2023 11:12:25 AM  [*] Sat Jan 28 11:12:25 2023: Train Epoch: 1 [12800/22838 (56%)]	Loss: 0.404452 | Elapsed: 9.11s | FPR 0.0003 -> TPR 0.5694 & F1 0.7257
01/28/2023 11:12:34 AM  [*] Sat Jan 28 11:12:34 2023: Train Epoch: 1 [19200/22838 (84%)]	Loss: 0.304873 | Elapsed: 9.10s | FPR 0.0003 -> TPR 0.5714 & F1 0.7273
01/28/2023 11:12:40 AM  [*] Sat Jan 28 11:12:40 2023:    1    | Tr.loss: 0.431670 | Elapsed:   33.34  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.01 | AUC: 0.8500
01/28/2023 11:12:40 AM  [*] Started epoch: 2
01/28/2023 11:12:40 AM  [*] Sat Jan 28 11:12:40 2023: Train Epoch: 2 [  0  /22838 (0 %)]	Loss: 0.280210 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.5400 & F1 0.7013
01/28/2023 11:12:49 AM  [*] Sat Jan 28 11:12:49 2023: Train Epoch: 2 [6400 /22838 (28%)]	Loss: 0.228705 | Elapsed: 9.11s | FPR 0.0003 -> TPR 0.6757 & F1 0.8065
01/28/2023 11:12:58 AM  [*] Sat Jan 28 11:12:58 2023: Train Epoch: 2 [12800/22838 (56%)]	Loss: 0.157608 | Elapsed: 9.13s | FPR 0.0003 -> TPR 0.8615 & F1 0.9256
01/28/2023 11:13:07 AM  [*] Sat Jan 28 11:13:07 2023: Train Epoch: 2 [19200/22838 (84%)]	Loss: 0.131699 | Elapsed: 9.18s | FPR 0.0003 -> TPR 0.9143 & F1 0.9552
01/28/2023 11:13:13 AM  [*] Sat Jan 28 11:13:13 2023:    2    | Tr.loss: 0.234221 | Elapsed:   33.23  s | FPR 0.0003 -> TPR: 0.29 & F1: 0.45 | AUC: 0.9607
01/28/2023 11:13:13 AM  [*] Started epoch: 3
01/28/2023 11:13:13 AM  [*] Sat Jan 28 11:13:13 2023: Train Epoch: 3 [  0  /22838 (0 %)]	Loss: 0.126000 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.9787 & F1 0.9892
01/28/2023 11:13:22 AM  [*] Sat Jan 28 11:13:22 2023: Train Epoch: 3 [6400 /22838 (28%)]	Loss: 0.193998 | Elapsed: 9.12s | FPR 0.0003 -> TPR 0.7429 & F1 0.8525
01/28/2023 11:13:31 AM  [*] Sat Jan 28 11:13:31 2023: Train Epoch: 3 [12800/22838 (56%)]	Loss: 0.109639 | Elapsed: 9.10s | FPR 0.0003 -> TPR 0.9062 & F1 0.9508
01/28/2023 11:13:41 AM  [*] Sat Jan 28 11:13:41 2023: Train Epoch: 3 [19200/22838 (84%)]	Loss: 0.160614 | Elapsed: 9.09s | FPR 0.0003 -> TPR 0.6875 & F1 0.8148
01/28/2023 11:13:46 AM  [*] Sat Jan 28 11:13:46 2023:    3    | Tr.loss: 0.154231 | Elapsed:   33.07  s | FPR 0.0003 -> TPR: 0.48 & F1: 0.64 | AUC: 0.9837
01/28/2023 11:13:47 AM [!] Sat Jan 28 11:13:47 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_pretrained\training_files\1674900826-model.torch
		train time: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_pretrained\training_files\1674900826-trainTime.npy
		train losses: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_pretrained\training_files\1674900826-trainLosses.npy
		train AUC: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_pretrained\training_files\1674900826-auc.npy
		train F1s : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_pretrained\training_files\1674900826-trainF1s.npy
		train TPRs: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_pretrained\training_files\1674900826-trainTPRs.npy
01/28/2023 11:13:47 AM  [!] Training non_pretrained model on downstream task...
01/28/2023 11:13:47 AM  [*] Started epoch: 1
01/28/2023 11:13:47 AM  [*] Sat Jan 28 11:13:47 2023: Train Epoch: 1 [  0  /22838 (0 %)]	Loss: 1.491862 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0488 & F1 0.0930
01/28/2023 11:13:53 AM  [*] Sat Jan 28 11:13:53 2023: Train Epoch: 1 [6400 /22838 (28%)]	Loss: 0.521046 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.1912 & F1 0.3210
01/28/2023 11:14:00 AM  [*] Sat Jan 28 11:14:00 2023: Train Epoch: 1 [12800/22838 (56%)]	Loss: 0.266541 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.6000 & F1 0.7500
01/28/2023 11:14:06 AM  [*] Sat Jan 28 11:14:06 2023: Train Epoch: 1 [19200/22838 (84%)]	Loss: 0.282322 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.4627 & F1 0.6327
01/28/2023 11:14:10 AM  [*] Sat Jan 28 11:14:10 2023:    1    | Tr.loss: 0.420051 | Elapsed:   22.81  s | FPR 0.0003 -> TPR: 0.01 & F1: 0.02 | AUC: 0.8618
01/28/2023 11:14:10 AM  [*] Started epoch: 2
01/28/2023 11:14:10 AM  [*] Sat Jan 28 11:14:10 2023: Train Epoch: 2 [  0  /22838 (0 %)]	Loss: 0.192368 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.7826 & F1 0.8780
01/28/2023 11:14:16 AM  [*] Sat Jan 28 11:14:16 2023: Train Epoch: 2 [6400 /22838 (28%)]	Loss: 0.255298 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.7200 & F1 0.8372
01/28/2023 11:14:22 AM  [*] Sat Jan 28 11:14:22 2023: Train Epoch: 2 [12800/22838 (56%)]	Loss: 0.282976 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.6667 & F1 0.8000
01/28/2023 11:14:29 AM  [*] Sat Jan 28 11:14:29 2023: Train Epoch: 2 [19200/22838 (84%)]	Loss: 0.357899 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.7639 & F1 0.8661
01/28/2023 11:14:33 AM  [*] Sat Jan 28 11:14:33 2023:    2    | Tr.loss: 0.255161 | Elapsed:   22.69  s | FPR 0.0003 -> TPR: 0.27 & F1: 0.42 | AUC: 0.9527
01/28/2023 11:14:33 AM  [*] Started epoch: 3
01/28/2023 11:14:33 AM  [*] Sat Jan 28 11:14:33 2023: Train Epoch: 3 [  0  /22838 (0 %)]	Loss: 0.231795 | Elapsed: 0.05s | FPR 0.0003 -> TPR 0.6486 & F1 0.7869
01/28/2023 11:14:39 AM  [*] Sat Jan 28 11:14:39 2023: Train Epoch: 3 [6400 /22838 (28%)]	Loss: 0.206928 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.8889 & F1 0.9412
01/28/2023 11:14:45 AM  [*] Sat Jan 28 11:14:45 2023: Train Epoch: 3 [12800/22838 (56%)]	Loss: 0.153286 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.8308 & F1 0.9076
01/28/2023 11:14:50 AM [!] Learning rate: 2.5e-05
01/28/2023 11:14:51 AM  [*] Sat Jan 28 11:14:51 2023: Train Epoch: 3 [19200/22838 (84%)]	Loss: 0.150052 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.8889 & F1 0.9412
01/28/2023 11:14:55 AM  [*] Sat Jan 28 11:14:55 2023:    3    | Tr.loss: 0.180856 | Elapsed:   22.74  s | FPR 0.0003 -> TPR: 0.32 & F1: 0.48 | AUC: 0.9769
01/28/2023 11:14:56 AM [!] Sat Jan 28 11:14:56 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_non_pretrained\training_files\1674900895-model.torch
		train time: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_non_pretrained\training_files\1674900895-trainTime.npy
		train losses: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_non_pretrained\training_files\1674900895-trainLosses.npy
		train AUC: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_non_pretrained\training_files\1674900895-auc.npy
		train F1s : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_non_pretrained\training_files\1674900895-trainF1s.npy
		train TPRs: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_non_pretrained\training_files\1674900895-trainTPRs.npy
01/28/2023 11:14:56 AM  [!] Training full_data model on downstream task...
01/28/2023 11:14:56 AM  [*] Started epoch: 1
01/28/2023 11:14:56 AM  [*] Sat Jan 28 11:14:56 2023: Train Epoch: 1 [  0  /76126 (0 %)]	Loss: 3.610206 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 11:15:03 AM  [*] Sat Jan 28 11:15:03 2023: Train Epoch: 1 [6400 /76126 (8 %)]	Loss: 0.552404 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.2759 & F1 0.4324
01/28/2023 11:15:09 AM  [*] Sat Jan 28 11:15:09 2023: Train Epoch: 1 [12800/76126 (17%)]	Loss: 0.404754 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.4306 & F1 0.6019
01/28/2023 11:15:15 AM  [*] Sat Jan 28 11:15:15 2023: Train Epoch: 1 [19200/76126 (25%)]	Loss: 0.337533 | Elapsed: 6.27s | FPR 0.0003 -> TPR 0.4545 & F1 0.6250
01/28/2023 11:15:21 AM  [*] Sat Jan 28 11:15:21 2023: Train Epoch: 1 [25600/76126 (34%)]	Loss: 0.282945 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.5161 & F1 0.6809
01/28/2023 11:15:28 AM  [*] Sat Jan 28 11:15:28 2023: Train Epoch: 1 [32000/76126 (42%)]	Loss: 0.200557 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.6571 & F1 0.7931
01/28/2023 11:15:34 AM  [*] Sat Jan 28 11:15:34 2023: Train Epoch: 1 [38400/76126 (50%)]	Loss: 0.221706 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.8154 & F1 0.8983
01/28/2023 11:15:40 AM  [*] Sat Jan 28 11:15:40 2023: Train Epoch: 1 [44800/76126 (59%)]	Loss: 0.210340 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.7222 & F1 0.8387
01/28/2023 11:15:46 AM  [*] Sat Jan 28 11:15:46 2023: Train Epoch: 1 [51200/76126 (67%)]	Loss: 0.264241 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.6500 & F1 0.7879
01/28/2023 11:15:52 AM  [*] Sat Jan 28 11:15:52 2023: Train Epoch: 1 [57600/76126 (76%)]	Loss: 0.104771 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.8382 & F1 0.9120
01/28/2023 11:15:59 AM [!] Learning rate: 2.5e-05
01/28/2023 11:15:59 AM  [*] Sat Jan 28 11:15:59 2023: Train Epoch: 1 [64000/76126 (84%)]	Loss: 0.136184 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.7656 & F1 0.8673
01/28/2023 11:16:05 AM  [*] Sat Jan 28 11:16:05 2023: Train Epoch: 1 [70400/76126 (92%)]	Loss: 0.140870 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.7826 & F1 0.8780
01/28/2023 11:16:12 AM  [*] Sat Jan 28 11:16:12 2023:    1    | Tr.loss: 0.300045 | Elapsed:   76.11  s | FPR 0.0003 -> TPR: 0.04 & F1: 0.07 | AUC: 0.9347
01/28/2023 11:16:12 AM  [*] Started epoch: 2
01/28/2023 11:16:12 AM  [*] Sat Jan 28 11:16:12 2023: Train Epoch: 2 [  0  /76126 (0 %)]	Loss: 0.157157 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.9302 & F1 0.9639
01/28/2023 11:16:19 AM  [*] Sat Jan 28 11:16:19 2023: Train Epoch: 2 [6400 /76126 (8 %)]	Loss: 0.292527 | Elapsed: 6.26s | FPR 0.0003 -> TPR 0.1930 & F1 0.3235
01/28/2023 11:16:25 AM  [*] Sat Jan 28 11:16:25 2023: Train Epoch: 2 [12800/76126 (17%)]	Loss: 0.148306 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.9062 & F1 0.9508
01/28/2023 11:16:31 AM  [*] Sat Jan 28 11:16:31 2023: Train Epoch: 2 [19200/76126 (25%)]	Loss: 0.094815 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.9545 & F1 0.9767
01/28/2023 11:16:37 AM  [*] Sat Jan 28 11:16:37 2023: Train Epoch: 2 [25600/76126 (34%)]	Loss: 0.105342 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.9394 & F1 0.9688
01/28/2023 11:16:44 AM  [*] Sat Jan 28 11:16:44 2023: Train Epoch: 2 [32000/76126 (42%)]	Loss: 0.169877 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.7846 & F1 0.8793
01/28/2023 11:16:50 AM  [*] Sat Jan 28 11:16:50 2023: Train Epoch: 2 [38400/76126 (50%)]	Loss: 0.213008 | Elapsed: 6.28s | FPR 0.0003 -> TPR 0.6825 & F1 0.8113
01/28/2023 11:16:56 AM  [*] Sat Jan 28 11:16:56 2023: Train Epoch: 2 [44800/76126 (59%)]	Loss: 0.198967 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.8769 & F1 0.9344
01/28/2023 11:17:02 AM  [*] Sat Jan 28 11:17:02 2023: Train Epoch: 2 [51200/76126 (67%)]	Loss: 0.138932 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.8286 & F1 0.9062
01/28/2023 11:17:03 AM [!] Learning rate: 2.5e-06
01/28/2023 11:17:09 AM  [*] Sat Jan 28 11:17:09 2023: Train Epoch: 2 [57600/76126 (76%)]	Loss: 0.123435 | Elapsed: 6.26s | FPR 0.0003 -> TPR 0.7385 & F1 0.8496
01/28/2023 11:17:15 AM  [*] Sat Jan 28 11:17:15 2023: Train Epoch: 2 [64000/76126 (84%)]	Loss: 0.109684 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.8857 & F1 0.9394
01/28/2023 11:17:21 AM  [*] Sat Jan 28 11:17:21 2023: Train Epoch: 2 [70400/76126 (92%)]	Loss: 0.142210 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.9167 & F1 0.9565
01/28/2023 11:17:28 AM  [*] Sat Jan 28 11:17:28 2023:    2    | Tr.loss: 0.165885 | Elapsed:   76.06  s | FPR 0.0003 -> TPR: 0.47 & F1: 0.64 | AUC: 0.9810
01/28/2023 11:17:28 AM  [*] Started epoch: 3
01/28/2023 11:17:29 AM  [*] Sat Jan 28 11:17:29 2023: Train Epoch: 3 [  0  /76126 (0 %)]	Loss: 0.122842 | Elapsed: 0.13s | FPR 0.0003 -> TPR 0.9375 & F1 0.9677
01/28/2023 11:17:35 AM  [*] Sat Jan 28 11:17:35 2023: Train Epoch: 3 [6400 /76126 (8 %)]	Loss: 0.119600 | Elapsed: 6.29s | FPR 0.0003 -> TPR 0.8824 & F1 0.9375
01/28/2023 11:17:41 AM  [*] Sat Jan 28 11:17:41 2023: Train Epoch: 3 [12800/76126 (17%)]	Loss: 0.107604 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.9508 & F1 0.9748
01/28/2023 11:17:47 AM  [*] Sat Jan 28 11:17:47 2023: Train Epoch: 3 [19200/76126 (25%)]	Loss: 0.091252 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.9437 & F1 0.9710
01/28/2023 11:17:54 AM  [*] Sat Jan 28 11:17:54 2023: Train Epoch: 3 [25600/76126 (34%)]	Loss: 0.122900 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.7612 & F1 0.8644
01/28/2023 11:18:00 AM  [*] Sat Jan 28 11:18:00 2023: Train Epoch: 3 [32000/76126 (42%)]	Loss: 0.071000 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.7164 & F1 0.8348
01/28/2023 11:18:06 AM  [*] Sat Jan 28 11:18:06 2023: Train Epoch: 3 [38400/76126 (50%)]	Loss: 0.147315 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.6774 & F1 0.8077
01/28/2023 11:18:07 AM [!] Learning rate: 2.5000000000000004e-07
01/28/2023 11:18:12 AM  [*] Sat Jan 28 11:18:12 2023: Train Epoch: 3 [44800/76126 (59%)]	Loss: 0.151856 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.8793 & F1 0.9358
01/28/2023 11:18:18 AM  [*] Sat Jan 28 11:18:18 2023: Train Epoch: 3 [51200/76126 (67%)]	Loss: 0.297773 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.7432 & F1 0.8527
01/28/2023 11:18:25 AM  [*] Sat Jan 28 11:18:25 2023: Train Epoch: 3 [57600/76126 (76%)]	Loss: 0.218472 | Elapsed: 6.29s | FPR 0.0003 -> TPR 0.6714 & F1 0.8034
01/28/2023 11:18:31 AM  [*] Sat Jan 28 11:18:31 2023: Train Epoch: 3 [64000/76126 (84%)]	Loss: 0.144404 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.9067 & F1 0.9510
01/28/2023 11:18:37 AM  [*] Sat Jan 28 11:18:37 2023: Train Epoch: 3 [70400/76126 (92%)]	Loss: 0.145208 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.7903 & F1 0.8829
01/28/2023 11:18:45 AM  [*] Sat Jan 28 11:18:45 2023:    3    | Tr.loss: 0.158044 | Elapsed:   76.09  s | FPR 0.0003 -> TPR: 0.46 & F1: 0.63 | AUC: 0.9828
01/28/2023 11:18:45 AM [!] Sat Jan 28 11:18:45 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_full_data\training_files\1674901125-model.torch
		train time: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_full_data\training_files\1674901125-trainTime.npy
		train losses: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_full_data\training_files\1674901125-trainLosses.npy
		train AUC: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_full_data\training_files\1674901125-auc.npy
		train F1s : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_full_data\training_files\1674901125-trainF1s.npy
		train TPRs: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_full_data\training_files\1674901125-trainTPRs.npy
01/28/2023 11:18:45 AM  [*] Evaluating pretrained model on test set...
01/28/2023 11:18:50 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0731 | F1: 0.1362
01/28/2023 11:18:50 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.2942 | F1: 0.4545
01/28/2023 11:18:50 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.4277 | F1: 0.5988
01/28/2023 11:18:50 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.4614 | F1: 0.6304
01/28/2023 11:18:50 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.5571 | F1: 0.7116
01/28/2023 11:18:50 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.6641 | F1: 0.7861
01/28/2023 11:18:50 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.7968 | F1: 0.8468
01/28/2023 11:18:50 AM  [*] Evaluating non_pretrained model on test set...
01/28/2023 11:18:55 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0893 | F1: 0.1640
01/28/2023 11:18:55 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1939 | F1: 0.3247
01/28/2023 11:18:55 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.2965 | F1: 0.4571
01/28/2023 11:18:55 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3306 | F1: 0.4960
01/28/2023 11:18:55 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3698 | F1: 0.5366
01/28/2023 11:18:55 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.5153 | F1: 0.6688
01/28/2023 11:18:55 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.7037 | F1: 0.7869
01/28/2023 11:18:55 AM  [*] Evaluating full_data model on test set...
01/28/2023 11:19:00 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0281 | F1: 0.0546
01/28/2023 11:19:00 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.2737 | F1: 0.4298
01/28/2023 11:19:00 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.3426 | F1: 0.5100
01/28/2023 11:19:00 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.4143 | F1: 0.5849
01/28/2023 11:19:00 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.4890 | F1: 0.6531
01/28/2023 11:19:00 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.5900 | F1: 0.7304
01/28/2023 11:19:00 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.7944 | F1: 0.8454
01/28/2023 11:19:00 AM  [!] Running pre-training split 2/3
01/28/2023 11:19:03 AM  [!] Pre-training model...
01/28/2023 11:19:04 AM  [*] Masking sequences...
01/28/2023 11:19:21 AM  [*] Started epoch: 1
01/28/2023 11:19:22 AM  [*] Sat Jan 28 11:19:22 2023: Train Epoch: 1 [  0  /53288 (0 %)]	Loss: 414.126770 | Elapsed: 0.85s
01/28/2023 11:19:35 AM  [*] Sat Jan 28 11:19:35 2023: Train Epoch: 1 [6400 /53288 (12%)]	Loss: 200.671234 | Elapsed: 12.28s
01/28/2023 11:19:47 AM  [*] Sat Jan 28 11:19:47 2023: Train Epoch: 1 [12800/53288 (24%)]	Loss: 225.539368 | Elapsed: 12.30s
01/28/2023 11:19:59 AM  [*] Sat Jan 28 11:19:59 2023: Train Epoch: 1 [19200/53288 (36%)]	Loss: 236.964188 | Elapsed: 12.42s
01/28/2023 11:20:12 AM  [*] Sat Jan 28 11:20:12 2023: Train Epoch: 1 [25600/53288 (48%)]	Loss: 208.999008 | Elapsed: 12.43s
01/28/2023 11:20:24 AM  [*] Sat Jan 28 11:20:24 2023: Train Epoch: 1 [32000/53288 (60%)]	Loss: 189.723175 | Elapsed: 12.35s
01/28/2023 11:20:36 AM  [*] Sat Jan 28 11:20:36 2023: Train Epoch: 1 [38400/53288 (72%)]	Loss: 193.701904 | Elapsed: 12.42s
01/28/2023 11:20:49 AM  [*] Sat Jan 28 11:20:49 2023: Train Epoch: 1 [44800/53288 (84%)]	Loss: 194.880310 | Elapsed: 12.37s
01/28/2023 11:21:01 AM  [*] Sat Jan 28 11:21:01 2023: Train Epoch: 1 [51200/53288 (96%)]	Loss: 204.468292 | Elapsed: 12.40s
01/28/2023 11:21:07 AM  [*] Sat Jan 28 11:21:07 2023:    1    | Tr.loss: 215.109078 | Elapsed:  105.12  s
01/28/2023 11:21:07 AM  [*] Started epoch: 2
01/28/2023 11:21:07 AM  [*] Sat Jan 28 11:21:07 2023: Train Epoch: 2 [  0  /53288 (0 %)]	Loss: 206.584091 | Elapsed: 0.12s
01/28/2023 11:21:19 AM  [*] Sat Jan 28 11:21:19 2023: Train Epoch: 2 [6400 /53288 (12%)]	Loss: 211.576172 | Elapsed: 12.45s
01/28/2023 11:21:32 AM  [*] Sat Jan 28 11:21:32 2023: Train Epoch: 2 [12800/53288 (24%)]	Loss: 194.830750 | Elapsed: 12.50s
01/28/2023 11:21:44 AM  [*] Sat Jan 28 11:21:44 2023: Train Epoch: 2 [19200/53288 (36%)]	Loss: 206.314392 | Elapsed: 12.49s
01/28/2023 11:21:56 AM  [*] Sat Jan 28 11:21:56 2023: Train Epoch: 2 [25600/53288 (48%)]	Loss: 216.577194 | Elapsed: 12.39s
01/28/2023 11:22:09 AM  [*] Sat Jan 28 11:22:09 2023: Train Epoch: 2 [32000/53288 (60%)]	Loss: 189.320404 | Elapsed: 12.38s
01/28/2023 11:22:21 AM  [*] Sat Jan 28 11:22:21 2023: Train Epoch: 2 [38400/53288 (72%)]	Loss: 187.483337 | Elapsed: 12.37s
01/28/2023 11:22:34 AM  [*] Sat Jan 28 11:22:34 2023: Train Epoch: 2 [44800/53288 (84%)]	Loss: 193.726807 | Elapsed: 12.40s
01/28/2023 11:22:46 AM  [*] Sat Jan 28 11:22:46 2023: Train Epoch: 2 [51200/53288 (96%)]	Loss: 187.796829 | Elapsed: 12.37s
01/28/2023 11:22:51 AM  [*] Sat Jan 28 11:22:51 2023:    2    | Tr.loss: 196.648983 | Elapsed:  104.74  s
01/28/2023 11:22:51 AM  [*] Started epoch: 3
01/28/2023 11:22:51 AM  [*] Sat Jan 28 11:22:51 2023: Train Epoch: 3 [  0  /53288 (0 %)]	Loss: 194.620148 | Elapsed: 0.14s
01/28/2023 11:23:04 AM  [*] Sat Jan 28 11:23:04 2023: Train Epoch: 3 [6400 /53288 (12%)]	Loss: 197.234253 | Elapsed: 12.39s
01/28/2023 11:23:16 AM  [*] Sat Jan 28 11:23:16 2023: Train Epoch: 3 [12800/53288 (24%)]	Loss: 214.343338 | Elapsed: 12.50s
01/28/2023 11:23:29 AM  [*] Sat Jan 28 11:23:29 2023: Train Epoch: 3 [19200/53288 (36%)]	Loss: 207.132172 | Elapsed: 12.42s
01/28/2023 11:23:41 AM  [*] Sat Jan 28 11:23:41 2023: Train Epoch: 3 [25600/53288 (48%)]	Loss: 182.967316 | Elapsed: 12.35s
01/28/2023 11:23:54 AM  [*] Sat Jan 28 11:23:54 2023: Train Epoch: 3 [32000/53288 (60%)]	Loss: 171.320572 | Elapsed: 13.11s
01/28/2023 11:24:08 AM  [*] Sat Jan 28 11:24:08 2023: Train Epoch: 3 [38400/53288 (72%)]	Loss: 175.604416 | Elapsed: 13.60s
01/28/2023 11:24:21 AM  [*] Sat Jan 28 11:24:21 2023: Train Epoch: 3 [44800/53288 (84%)]	Loss: 213.732697 | Elapsed: 12.97s
01/28/2023 11:24:34 AM  [*] Sat Jan 28 11:24:34 2023: Train Epoch: 3 [51200/53288 (96%)]	Loss: 192.196869 | Elapsed: 13.04s
01/28/2023 11:24:39 AM  [*] Sat Jan 28 11:24:39 2023:    3    | Tr.loss: 190.062548 | Elapsed:  108.16  s
01/28/2023 11:24:39 AM  [*] Started epoch: 4
01/28/2023 11:24:40 AM  [*] Sat Jan 28 11:24:40 2023: Train Epoch: 4 [  0  /53288 (0 %)]	Loss: 236.839188 | Elapsed: 0.14s
01/28/2023 11:24:52 AM  [*] Sat Jan 28 11:24:52 2023: Train Epoch: 4 [6400 /53288 (12%)]	Loss: 183.435486 | Elapsed: 12.56s
01/28/2023 11:25:05 AM  [*] Sat Jan 28 11:25:05 2023: Train Epoch: 4 [12800/53288 (24%)]	Loss: 194.282684 | Elapsed: 12.43s
01/28/2023 11:25:17 AM  [*] Sat Jan 28 11:25:17 2023: Train Epoch: 4 [19200/53288 (36%)]	Loss: 190.695374 | Elapsed: 12.45s
01/28/2023 11:25:29 AM  [*] Sat Jan 28 11:25:29 2023: Train Epoch: 4 [25600/53288 (48%)]	Loss: 162.590729 | Elapsed: 12.43s
01/28/2023 11:25:42 AM  [*] Sat Jan 28 11:25:42 2023: Train Epoch: 4 [32000/53288 (60%)]	Loss: 179.147369 | Elapsed: 12.43s
01/28/2023 11:25:54 AM  [*] Sat Jan 28 11:25:54 2023: Train Epoch: 4 [38400/53288 (72%)]	Loss: 182.272766 | Elapsed: 12.40s
01/28/2023 11:26:07 AM  [*] Sat Jan 28 11:26:07 2023: Train Epoch: 4 [44800/53288 (84%)]	Loss: 177.724152 | Elapsed: 12.42s
01/28/2023 11:26:19 AM  [*] Sat Jan 28 11:26:19 2023: Train Epoch: 4 [51200/53288 (96%)]	Loss: 202.781158 | Elapsed: 12.43s
01/28/2023 11:26:24 AM  [*] Sat Jan 28 11:26:24 2023:    4    | Tr.loss: 186.255413 | Elapsed:  105.04  s
01/28/2023 11:26:24 AM  [*] Started epoch: 5
01/28/2023 11:26:25 AM  [*] Sat Jan 28 11:26:25 2023: Train Epoch: 5 [  0  /53288 (0 %)]	Loss: 188.865280 | Elapsed: 0.13s
01/28/2023 11:26:37 AM  [*] Sat Jan 28 11:26:37 2023: Train Epoch: 5 [6400 /53288 (12%)]	Loss: 195.425308 | Elapsed: 12.41s
01/28/2023 11:26:49 AM  [*] Sat Jan 28 11:26:49 2023: Train Epoch: 5 [12800/53288 (24%)]	Loss: 187.681580 | Elapsed: 12.41s
01/28/2023 11:27:02 AM  [*] Sat Jan 28 11:27:02 2023: Train Epoch: 5 [19200/53288 (36%)]	Loss: 185.629059 | Elapsed: 12.45s
01/28/2023 11:27:14 AM  [*] Sat Jan 28 11:27:14 2023: Train Epoch: 5 [25600/53288 (48%)]	Loss: 166.336624 | Elapsed: 12.38s
01/28/2023 11:27:27 AM  [*] Sat Jan 28 11:27:27 2023: Train Epoch: 5 [32000/53288 (60%)]	Loss: 187.386093 | Elapsed: 12.41s
01/28/2023 11:27:39 AM  [*] Sat Jan 28 11:27:39 2023: Train Epoch: 5 [38400/53288 (72%)]	Loss: 182.549774 | Elapsed: 12.40s
01/28/2023 11:27:51 AM  [*] Sat Jan 28 11:27:51 2023: Train Epoch: 5 [44800/53288 (84%)]	Loss: 201.463791 | Elapsed: 12.40s
01/28/2023 11:28:04 AM  [*] Sat Jan 28 11:28:04 2023: Train Epoch: 5 [51200/53288 (96%)]	Loss: 187.382034 | Elapsed: 12.38s
01/28/2023 11:28:09 AM  [*] Sat Jan 28 11:28:09 2023:    5    | Tr.loss: 183.592727 | Elapsed:  104.70  s
01/28/2023 11:28:09 AM  [*] Started epoch: 6
01/28/2023 11:28:09 AM  [*] Sat Jan 28 11:28:09 2023: Train Epoch: 6 [  0  /53288 (0 %)]	Loss: 200.013336 | Elapsed: 0.13s
01/28/2023 11:28:22 AM  [*] Sat Jan 28 11:28:22 2023: Train Epoch: 6 [6400 /53288 (12%)]	Loss: 178.669174 | Elapsed: 12.39s
01/28/2023 11:28:34 AM  [*] Sat Jan 28 11:28:34 2023: Train Epoch: 6 [12800/53288 (24%)]	Loss: 189.053513 | Elapsed: 12.33s
01/28/2023 11:28:46 AM  [*] Sat Jan 28 11:28:46 2023: Train Epoch: 6 [19200/53288 (36%)]	Loss: 182.434647 | Elapsed: 12.40s
01/28/2023 11:28:59 AM  [*] Sat Jan 28 11:28:59 2023: Train Epoch: 6 [25600/53288 (48%)]	Loss: 191.748169 | Elapsed: 12.36s
01/28/2023 11:29:11 AM  [*] Sat Jan 28 11:29:11 2023: Train Epoch: 6 [32000/53288 (60%)]	Loss: 189.641693 | Elapsed: 12.42s
01/28/2023 11:29:24 AM  [*] Sat Jan 28 11:29:24 2023: Train Epoch: 6 [38400/53288 (72%)]	Loss: 195.827484 | Elapsed: 12.46s
01/28/2023 11:29:36 AM  [*] Sat Jan 28 11:29:36 2023: Train Epoch: 6 [44800/53288 (84%)]	Loss: 207.073090 | Elapsed: 12.40s
01/28/2023 11:29:48 AM  [*] Sat Jan 28 11:29:48 2023: Train Epoch: 6 [51200/53288 (96%)]	Loss: 170.652039 | Elapsed: 12.36s
01/28/2023 11:29:54 AM  [*] Sat Jan 28 11:29:54 2023:    6    | Tr.loss: 181.940007 | Elapsed:  104.59  s
01/28/2023 11:29:54 AM  [*] Started epoch: 7
01/28/2023 11:29:54 AM  [*] Sat Jan 28 11:29:54 2023: Train Epoch: 7 [  0  /53288 (0 %)]	Loss: 194.803818 | Elapsed: 0.13s
01/28/2023 11:29:54 AM [!] Learning rate: 2.5e-05
01/28/2023 11:30:06 AM  [*] Sat Jan 28 11:30:06 2023: Train Epoch: 7 [6400 /53288 (12%)]	Loss: 179.550507 | Elapsed: 12.38s
01/28/2023 11:30:19 AM  [*] Sat Jan 28 11:30:19 2023: Train Epoch: 7 [12800/53288 (24%)]	Loss: 171.677429 | Elapsed: 12.45s
01/28/2023 11:30:31 AM  [*] Sat Jan 28 11:30:31 2023: Train Epoch: 7 [19200/53288 (36%)]	Loss: 175.573059 | Elapsed: 12.45s
01/28/2023 11:30:44 AM  [*] Sat Jan 28 11:30:44 2023: Train Epoch: 7 [25600/53288 (48%)]	Loss: 175.850891 | Elapsed: 12.38s
01/28/2023 11:30:56 AM  [*] Sat Jan 28 11:30:56 2023: Train Epoch: 7 [32000/53288 (60%)]	Loss: 188.045898 | Elapsed: 12.37s
01/28/2023 11:31:08 AM  [*] Sat Jan 28 11:31:08 2023: Train Epoch: 7 [38400/53288 (72%)]	Loss: 199.015381 | Elapsed: 12.36s
01/28/2023 11:31:21 AM  [*] Sat Jan 28 11:31:21 2023: Train Epoch: 7 [44800/53288 (84%)]	Loss: 179.488617 | Elapsed: 12.44s
01/28/2023 11:31:33 AM  [*] Sat Jan 28 11:31:33 2023: Train Epoch: 7 [51200/53288 (96%)]	Loss: 187.289429 | Elapsed: 12.39s
01/28/2023 11:31:38 AM  [*] Sat Jan 28 11:31:38 2023:    7    | Tr.loss: 180.183717 | Elapsed:  104.56  s
01/28/2023 11:31:38 AM  [*] Started epoch: 8
01/28/2023 11:31:38 AM  [*] Sat Jan 28 11:31:38 2023: Train Epoch: 8 [  0  /53288 (0 %)]	Loss: 179.921448 | Elapsed: 0.14s
01/28/2023 11:31:51 AM  [*] Sat Jan 28 11:31:51 2023: Train Epoch: 8 [6400 /53288 (12%)]	Loss: 163.165588 | Elapsed: 12.53s
01/28/2023 11:32:03 AM  [*] Sat Jan 28 11:32:03 2023: Train Epoch: 8 [12800/53288 (24%)]	Loss: 175.105438 | Elapsed: 12.46s
01/28/2023 11:32:16 AM  [*] Sat Jan 28 11:32:16 2023: Train Epoch: 8 [19200/53288 (36%)]	Loss: 182.684631 | Elapsed: 12.42s
01/28/2023 11:32:28 AM  [*] Sat Jan 28 11:32:28 2023: Train Epoch: 8 [25600/53288 (48%)]	Loss: 190.588226 | Elapsed: 12.38s
01/28/2023 11:32:41 AM  [*] Sat Jan 28 11:32:41 2023: Train Epoch: 8 [32000/53288 (60%)]	Loss: 174.895828 | Elapsed: 12.35s
01/28/2023 11:32:53 AM  [*] Sat Jan 28 11:32:53 2023: Train Epoch: 8 [38400/53288 (72%)]	Loss: 197.328949 | Elapsed: 12.42s
01/28/2023 11:33:05 AM  [*] Sat Jan 28 11:33:05 2023: Train Epoch: 8 [44800/53288 (84%)]	Loss: 189.453384 | Elapsed: 12.41s
01/28/2023 11:33:18 AM  [*] Sat Jan 28 11:33:18 2023: Train Epoch: 8 [51200/53288 (96%)]	Loss: 194.081558 | Elapsed: 12.44s
01/28/2023 11:33:23 AM  [*] Sat Jan 28 11:33:23 2023:    8    | Tr.loss: 180.027594 | Elapsed:  104.87  s
01/28/2023 11:33:23 AM  [*] Started epoch: 9
01/28/2023 11:33:23 AM  [*] Sat Jan 28 11:33:23 2023: Train Epoch: 9 [  0  /53288 (0 %)]	Loss: 177.382629 | Elapsed: 0.14s
01/28/2023 11:33:36 AM  [*] Sat Jan 28 11:33:36 2023: Train Epoch: 9 [6400 /53288 (12%)]	Loss: 172.226456 | Elapsed: 12.43s
01/28/2023 11:33:48 AM  [*] Sat Jan 28 11:33:48 2023: Train Epoch: 9 [12800/53288 (24%)]	Loss: 180.325302 | Elapsed: 12.42s
01/28/2023 11:34:01 AM  [*] Sat Jan 28 11:34:01 2023: Train Epoch: 9 [19200/53288 (36%)]	Loss: 169.003357 | Elapsed: 12.46s
01/28/2023 11:34:13 AM  [*] Sat Jan 28 11:34:13 2023: Train Epoch: 9 [25600/53288 (48%)]	Loss: 165.300262 | Elapsed: 12.39s
01/28/2023 11:34:25 AM  [*] Sat Jan 28 11:34:25 2023: Train Epoch: 9 [32000/53288 (60%)]	Loss: 206.026215 | Elapsed: 12.36s
01/28/2023 11:34:38 AM  [*] Sat Jan 28 11:34:38 2023: Train Epoch: 9 [38400/53288 (72%)]	Loss: 196.225281 | Elapsed: 12.36s
01/28/2023 11:34:50 AM  [*] Sat Jan 28 11:34:50 2023: Train Epoch: 9 [44800/53288 (84%)]	Loss: 181.993927 | Elapsed: 12.35s
01/28/2023 11:35:02 AM  [*] Sat Jan 28 11:35:02 2023: Train Epoch: 9 [51200/53288 (96%)]	Loss: 171.808075 | Elapsed: 12.36s
01/28/2023 11:35:08 AM  [*] Sat Jan 28 11:35:08 2023:    9    | Tr.loss: 179.757865 | Elapsed:  104.64  s
01/28/2023 11:35:08 AM  [*] Started epoch: 10
01/28/2023 11:35:08 AM  [*] Sat Jan 28 11:35:08 2023: Train Epoch: 10 [  0  /53288 (0 %)]	Loss: 173.564774 | Elapsed: 0.13s
01/28/2023 11:35:20 AM  [*] Sat Jan 28 11:35:20 2023: Train Epoch: 10 [6400 /53288 (12%)]	Loss: 189.356567 | Elapsed: 12.51s
01/28/2023 11:35:33 AM  [*] Sat Jan 28 11:35:33 2023: Train Epoch: 10 [12800/53288 (24%)]	Loss: 181.405273 | Elapsed: 12.44s
01/28/2023 11:35:45 AM  [*] Sat Jan 28 11:35:45 2023: Train Epoch: 10 [19200/53288 (36%)]	Loss: 194.289124 | Elapsed: 12.33s
01/28/2023 11:35:58 AM  [*] Sat Jan 28 11:35:58 2023: Train Epoch: 10 [25600/53288 (48%)]	Loss: 179.402908 | Elapsed: 12.41s
01/28/2023 11:36:10 AM  [*] Sat Jan 28 11:36:10 2023: Train Epoch: 10 [32000/53288 (60%)]	Loss: 180.790146 | Elapsed: 12.40s
01/28/2023 11:36:23 AM  [*] Sat Jan 28 11:36:23 2023: Train Epoch: 10 [38400/53288 (72%)]	Loss: 188.266388 | Elapsed: 12.49s
01/28/2023 11:36:35 AM  [*] Sat Jan 28 11:36:35 2023: Train Epoch: 10 [44800/53288 (84%)]	Loss: 176.646164 | Elapsed: 12.38s
01/28/2023 11:36:47 AM  [*] Sat Jan 28 11:36:47 2023: Train Epoch: 10 [51200/53288 (96%)]	Loss: 186.639435 | Elapsed: 12.32s
01/28/2023 11:36:52 AM  [*] Sat Jan 28 11:36:52 2023:   10    | Tr.loss: 179.696627 | Elapsed:  104.67  s
01/28/2023 11:36:53 AM [!] Sat Jan 28 11:36:53 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\preTraining\training_files\1674902212-model.torch
		train time: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\preTraining\training_files\1674902212-trainTime.npy
		train losses: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\preTraining\training_files\1674902212-trainLosses.npy
		train AUC: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\preTraining\training_files\1674902212-auc.npy
01/28/2023 11:36:54 AM  [!] Training pretrained model on downstream task...
01/28/2023 11:36:54 AM  [*] Started epoch: 1
01/28/2023 11:36:54 AM  [*] Sat Jan 28 11:36:54 2023: Train Epoch: 1 [  0  /22838 (0 %)]	Loss: 2.809530 | Elapsed: 0.36s | FPR 0.0003 -> TPR 0.1020 & F1 0.1852
01/28/2023 11:37:03 AM  [*] Sat Jan 28 11:37:03 2023: Train Epoch: 1 [6400 /22838 (28%)]	Loss: 0.498429 | Elapsed: 9.11s | FPR 0.0003 -> TPR 0.4028 & F1 0.5743
01/28/2023 11:37:12 AM  [*] Sat Jan 28 11:37:12 2023: Train Epoch: 1 [12800/22838 (56%)]	Loss: 0.373982 | Elapsed: 9.10s | FPR 0.0003 -> TPR 0.3906 & F1 0.5618
01/28/2023 11:37:22 AM  [*] Sat Jan 28 11:37:22 2023: Train Epoch: 1 [19200/22838 (84%)]	Loss: 0.388746 | Elapsed: 9.11s | FPR 0.0003 -> TPR 0.2931 & F1 0.4533
01/28/2023 11:37:27 AM  [*] Sat Jan 28 11:37:27 2023:    1    | Tr.loss: 0.508791 | Elapsed:   33.33  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8025
01/28/2023 11:37:27 AM  [*] Started epoch: 2
01/28/2023 11:37:27 AM  [*] Sat Jan 28 11:37:27 2023: Train Epoch: 2 [  0  /22838 (0 %)]	Loss: 0.386587 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.2174 & F1 0.3571
01/28/2023 11:37:36 AM  [*] Sat Jan 28 11:37:36 2023: Train Epoch: 2 [6400 /22838 (28%)]	Loss: 0.398477 | Elapsed: 9.09s | FPR 0.0003 -> TPR 0.6094 & F1 0.7573
01/28/2023 11:37:45 AM  [*] Sat Jan 28 11:37:45 2023: Train Epoch: 2 [12800/22838 (56%)]	Loss: 0.362650 | Elapsed: 9.09s | FPR 0.0003 -> TPR 0.4333 & F1 0.6047
01/28/2023 11:37:55 AM  [*] Sat Jan 28 11:37:55 2023: Train Epoch: 2 [19200/22838 (84%)]	Loss: 0.307140 | Elapsed: 9.10s | FPR 0.0003 -> TPR 0.6491 & F1 0.7872
01/28/2023 11:38:00 AM  [*] Sat Jan 28 11:38:00 2023:    2    | Tr.loss: 0.305358 | Elapsed:   33.01  s | FPR 0.0003 -> TPR: 0.19 & F1: 0.32 | AUC: 0.9271
01/28/2023 11:38:00 AM  [*] Started epoch: 3
01/28/2023 11:38:00 AM  [*] Sat Jan 28 11:38:00 2023: Train Epoch: 3 [  0  /22838 (0 %)]	Loss: 0.250132 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.7083 & F1 0.8293
01/28/2023 11:38:09 AM  [*] Sat Jan 28 11:38:09 2023: Train Epoch: 3 [6400 /22838 (28%)]	Loss: 0.179051 | Elapsed: 9.08s | FPR 0.0003 -> TPR 0.8356 & F1 0.9104
01/28/2023 11:38:18 AM  [*] Sat Jan 28 11:38:18 2023: Train Epoch: 3 [12800/22838 (56%)]	Loss: 0.249117 | Elapsed: 9.11s | FPR 0.0003 -> TPR 0.7681 & F1 0.8689
01/28/2023 11:38:28 AM  [*] Sat Jan 28 11:38:28 2023: Train Epoch: 3 [19200/22838 (84%)]	Loss: 0.249816 | Elapsed: 9.11s | FPR 0.0003 -> TPR 0.7922 & F1 0.8841
01/28/2023 11:38:33 AM  [*] Sat Jan 28 11:38:33 2023:    3    | Tr.loss: 0.204477 | Elapsed:   33.03  s | FPR 0.0003 -> TPR: 0.45 & F1: 0.62 | AUC: 0.9705
01/28/2023 11:38:34 AM [!] Sat Jan 28 11:38:34 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_pretrained\training_files\1674902313-model.torch
		train time: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_pretrained\training_files\1674902313-trainTime.npy
		train losses: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_pretrained\training_files\1674902313-trainLosses.npy
		train AUC: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_pretrained\training_files\1674902313-auc.npy
		train F1s : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_pretrained\training_files\1674902313-trainF1s.npy
		train TPRs: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_pretrained\training_files\1674902313-trainTPRs.npy
01/28/2023 11:38:34 AM  [!] Training non_pretrained model on downstream task...
01/28/2023 11:38:34 AM  [*] Started epoch: 1
01/28/2023 11:38:34 AM  [*] Sat Jan 28 11:38:34 2023: Train Epoch: 1 [  0  /22838 (0 %)]	Loss: 1.968449 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0256 & F1 0.0500
01/28/2023 11:38:40 AM  [*] Sat Jan 28 11:38:40 2023: Train Epoch: 1 [6400 /22838 (28%)]	Loss: 0.521723 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.2424 & F1 0.3902
01/28/2023 11:38:47 AM  [*] Sat Jan 28 11:38:47 2023: Train Epoch: 1 [12800/22838 (56%)]	Loss: 0.367563 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.3810 & F1 0.5517
01/28/2023 11:38:53 AM  [*] Sat Jan 28 11:38:53 2023: Train Epoch: 1 [19200/22838 (84%)]	Loss: 0.373733 | Elapsed: 6.28s | FPR 0.0003 -> TPR 0.4306 & F1 0.6019
01/28/2023 11:38:57 AM  [*] Sat Jan 28 11:38:57 2023:    1    | Tr.loss: 0.428112 | Elapsed:   22.75  s | FPR 0.0003 -> TPR: 0.01 & F1: 0.02 | AUC: 0.8574
01/28/2023 11:38:57 AM  [*] Started epoch: 2
01/28/2023 11:38:57 AM  [*] Sat Jan 28 11:38:57 2023: Train Epoch: 2 [  0  /22838 (0 %)]	Loss: 0.304296 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.7619 & F1 0.8649
01/28/2023 11:39:03 AM  [*] Sat Jan 28 11:39:03 2023: Train Epoch: 2 [6400 /22838 (28%)]	Loss: 0.237697 | Elapsed: 6.29s | FPR 0.0003 -> TPR 0.5000 & F1 0.6667
01/28/2023 11:39:09 AM  [*] Sat Jan 28 11:39:09 2023: Train Epoch: 2 [12800/22838 (56%)]	Loss: 0.295483 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.5424 & F1 0.7033
01/28/2023 11:39:16 AM  [*] Sat Jan 28 11:39:16 2023: Train Epoch: 2 [19200/22838 (84%)]	Loss: 0.242612 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.7467 & F1 0.8550
01/28/2023 11:39:20 AM  [*] Sat Jan 28 11:39:20 2023:    2    | Tr.loss: 0.260677 | Elapsed:   22.82  s | FPR 0.0003 -> TPR: 0.40 & F1: 0.57 | AUC: 0.9508
01/28/2023 11:39:20 AM  [*] Started epoch: 3
01/28/2023 11:39:20 AM  [*] Sat Jan 28 11:39:20 2023: Train Epoch: 3 [  0  /22838 (0 %)]	Loss: 0.171555 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.8140 & F1 0.8974
01/28/2023 11:39:26 AM  [*] Sat Jan 28 11:39:26 2023: Train Epoch: 3 [6400 /22838 (28%)]	Loss: 0.216214 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.7200 & F1 0.8372
01/28/2023 11:39:32 AM  [*] Sat Jan 28 11:39:32 2023: Train Epoch: 3 [12800/22838 (56%)]	Loss: 0.238451 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.4559 & F1 0.6263
01/28/2023 11:39:37 AM [!] Learning rate: 2.5e-05
01/28/2023 11:39:38 AM  [*] Sat Jan 28 11:39:38 2023: Train Epoch: 3 [19200/22838 (84%)]	Loss: 0.238115 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.5867 & F1 0.7395
01/28/2023 11:39:42 AM  [*] Sat Jan 28 11:39:42 2023:    3    | Tr.loss: 0.187325 | Elapsed:   22.74  s | FPR 0.0003 -> TPR: 0.38 & F1: 0.55 | AUC: 0.9754
01/28/2023 11:39:43 AM [!] Sat Jan 28 11:39:43 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_non_pretrained\training_files\1674902382-model.torch
		train time: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_non_pretrained\training_files\1674902382-trainTime.npy
		train losses: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_non_pretrained\training_files\1674902382-trainLosses.npy
		train AUC: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_non_pretrained\training_files\1674902382-auc.npy
		train F1s : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_non_pretrained\training_files\1674902382-trainF1s.npy
		train TPRs: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_non_pretrained\training_files\1674902382-trainTPRs.npy
01/28/2023 11:39:43 AM  [!] Training full_data model on downstream task...
01/28/2023 11:39:43 AM  [*] Started epoch: 1
01/28/2023 11:39:43 AM  [*] Sat Jan 28 11:39:43 2023: Train Epoch: 1 [  0  /76126 (0 %)]	Loss: 2.889488 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0488 & F1 0.0930
01/28/2023 11:39:50 AM  [*] Sat Jan 28 11:39:50 2023: Train Epoch: 1 [6400 /76126 (8 %)]	Loss: 0.431735 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.3077 & F1 0.4706
01/28/2023 11:39:56 AM  [*] Sat Jan 28 11:39:56 2023: Train Epoch: 1 [12800/76126 (17%)]	Loss: 0.470656 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.3636 & F1 0.5333
01/28/2023 11:40:02 AM  [*] Sat Jan 28 11:40:02 2023: Train Epoch: 1 [19200/76126 (25%)]	Loss: 0.312541 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.4058 & F1 0.5773
01/28/2023 11:40:08 AM  [*] Sat Jan 28 11:40:08 2023: Train Epoch: 1 [25600/76126 (34%)]	Loss: 0.370312 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.5286 & F1 0.6916
01/28/2023 11:40:14 AM  [*] Sat Jan 28 11:40:14 2023: Train Epoch: 1 [32000/76126 (42%)]	Loss: 0.336713 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.7681 & F1 0.8689
01/28/2023 11:40:21 AM  [*] Sat Jan 28 11:40:21 2023: Train Epoch: 1 [38400/76126 (50%)]	Loss: 0.143939 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.9306 & F1 0.9640
01/28/2023 11:40:27 AM  [*] Sat Jan 28 11:40:27 2023: Train Epoch: 1 [44800/76126 (59%)]	Loss: 0.375644 | Elapsed: 6.29s | FPR 0.0003 -> TPR 0.6351 & F1 0.7769
01/28/2023 11:40:33 AM  [*] Sat Jan 28 11:40:33 2023: Train Epoch: 1 [51200/76126 (67%)]	Loss: 0.271087 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.4923 & F1 0.6598
01/28/2023 11:40:39 AM  [*] Sat Jan 28 11:40:39 2023: Train Epoch: 1 [57600/76126 (76%)]	Loss: 0.180238 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.8611 & F1 0.9254
01/28/2023 11:40:46 AM [!] Learning rate: 2.5e-05
01/28/2023 11:40:46 AM  [*] Sat Jan 28 11:40:46 2023: Train Epoch: 1 [64000/76126 (84%)]	Loss: 0.276911 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.4925 & F1 0.6600
01/28/2023 11:40:52 AM  [*] Sat Jan 28 11:40:52 2023: Train Epoch: 1 [70400/76126 (92%)]	Loss: 0.245910 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.6571 & F1 0.7931
01/28/2023 11:40:59 AM  [*] Sat Jan 28 11:40:59 2023:    1    | Tr.loss: 0.303772 | Elapsed:   76.04  s | FPR 0.0003 -> TPR: 0.04 & F1: 0.08 | AUC: 0.9327
01/28/2023 11:40:59 AM  [*] Started epoch: 2
01/28/2023 11:40:59 AM  [*] Sat Jan 28 11:40:59 2023: Train Epoch: 2 [  0  /76126 (0 %)]	Loss: 0.144908 | Elapsed: 0.12s | FPR 0.0003 -> TPR 1.0000 & F1 1.0000
01/28/2023 11:41:06 AM  [*] Sat Jan 28 11:41:06 2023: Train Epoch: 2 [6400 /76126 (8 %)]	Loss: 0.164411 | Elapsed: 6.29s | FPR 0.0003 -> TPR 0.8125 & F1 0.8966
01/28/2023 11:41:12 AM  [*] Sat Jan 28 11:41:12 2023: Train Epoch: 2 [12800/76126 (17%)]	Loss: 0.140727 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.8475 & F1 0.9174
01/28/2023 11:41:18 AM  [*] Sat Jan 28 11:41:18 2023: Train Epoch: 2 [19200/76126 (25%)]	Loss: 0.128249 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.5970 & F1 0.7477
01/28/2023 11:41:24 AM  [*] Sat Jan 28 11:41:24 2023: Train Epoch: 2 [25600/76126 (34%)]	Loss: 0.103543 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.9104 & F1 0.9531
01/28/2023 11:41:31 AM  [*] Sat Jan 28 11:41:31 2023: Train Epoch: 2 [32000/76126 (42%)]	Loss: 0.166172 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.7910 & F1 0.8833
01/28/2023 11:41:37 AM  [*] Sat Jan 28 11:41:37 2023: Train Epoch: 2 [38400/76126 (50%)]	Loss: 0.180287 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.8611 & F1 0.9254
01/28/2023 11:41:43 AM  [*] Sat Jan 28 11:41:43 2023: Train Epoch: 2 [44800/76126 (59%)]	Loss: 0.178108 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.6970 & F1 0.8214
01/28/2023 11:41:49 AM  [*] Sat Jan 28 11:41:49 2023: Train Epoch: 2 [51200/76126 (67%)]	Loss: 0.111258 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.8676 & F1 0.9291
01/28/2023 11:41:50 AM [!] Learning rate: 2.5e-06
01/28/2023 11:41:56 AM  [*] Sat Jan 28 11:41:56 2023: Train Epoch: 2 [57600/76126 (76%)]	Loss: 0.187369 | Elapsed: 6.31s | FPR 0.0003 -> TPR 0.6769 & F1 0.8073
01/28/2023 11:42:02 AM  [*] Sat Jan 28 11:42:02 2023: Train Epoch: 2 [64000/76126 (84%)]	Loss: 0.222857 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.7576 & F1 0.8621
01/28/2023 11:42:08 AM  [*] Sat Jan 28 11:42:08 2023: Train Epoch: 2 [70400/76126 (92%)]	Loss: 0.175056 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.7808 & F1 0.8769
01/28/2023 11:42:15 AM  [*] Sat Jan 28 11:42:15 2023:    2    | Tr.loss: 0.172457 | Elapsed:   76.09  s | FPR 0.0003 -> TPR: 0.44 & F1: 0.61 | AUC: 0.9792
01/28/2023 11:42:15 AM  [*] Started epoch: 3
01/28/2023 11:42:15 AM  [*] Sat Jan 28 11:42:15 2023: Train Epoch: 3 [  0  /76126 (0 %)]	Loss: 0.191794 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.8421 & F1 0.9143
01/28/2023 11:42:22 AM  [*] Sat Jan 28 11:42:22 2023: Train Epoch: 3 [6400 /76126 (8 %)]	Loss: 0.254575 | Elapsed: 6.27s | FPR 0.0003 -> TPR 0.7612 & F1 0.8644
01/28/2023 11:42:28 AM  [*] Sat Jan 28 11:42:28 2023: Train Epoch: 3 [12800/76126 (17%)]	Loss: 0.103341 | Elapsed: 6.26s | FPR 0.0003 -> TPR 0.8462 & F1 0.9167
01/28/2023 11:42:34 AM  [*] Sat Jan 28 11:42:34 2023: Train Epoch: 3 [19200/76126 (25%)]	Loss: 0.153644 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.8413 & F1 0.9138
01/28/2023 11:42:40 AM  [*] Sat Jan 28 11:42:40 2023: Train Epoch: 3 [25600/76126 (34%)]	Loss: 0.138977 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.9254 & F1 0.9612
01/28/2023 11:42:47 AM  [*] Sat Jan 28 11:42:47 2023: Train Epoch: 3 [32000/76126 (42%)]	Loss: 0.156479 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.5385 & F1 0.7000
01/28/2023 11:42:53 AM  [*] Sat Jan 28 11:42:53 2023: Train Epoch: 3 [38400/76126 (50%)]	Loss: 0.092896 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.9342 & F1 0.9660
01/28/2023 11:42:54 AM [!] Learning rate: 2.5000000000000004e-07
01/28/2023 11:42:59 AM  [*] Sat Jan 28 11:42:59 2023: Train Epoch: 3 [44800/76126 (59%)]	Loss: 0.098656 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.9531 & F1 0.9760
01/28/2023 11:43:05 AM  [*] Sat Jan 28 11:43:05 2023: Train Epoch: 3 [51200/76126 (67%)]	Loss: 0.181050 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.7534 & F1 0.8594
01/28/2023 11:43:12 AM  [*] Sat Jan 28 11:43:12 2023: Train Epoch: 3 [57600/76126 (76%)]	Loss: 0.108847 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.8873 & F1 0.9403
01/28/2023 11:43:18 AM  [*] Sat Jan 28 11:43:18 2023: Train Epoch: 3 [64000/76126 (84%)]	Loss: 0.137318 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.6769 & F1 0.8073
01/28/2023 11:43:24 AM  [*] Sat Jan 28 11:43:24 2023: Train Epoch: 3 [70400/76126 (92%)]	Loss: 0.163366 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.8209 & F1 0.9016
01/28/2023 11:43:31 AM  [*] Sat Jan 28 11:43:31 2023:    3    | Tr.loss: 0.165322 | Elapsed:   76.08  s | FPR 0.0003 -> TPR: 0.48 & F1: 0.65 | AUC: 0.9810
01/28/2023 11:43:32 AM [!] Sat Jan 28 11:43:32 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_full_data\training_files\1674902611-model.torch
		train time: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_full_data\training_files\1674902611-trainTime.npy
		train losses: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_full_data\training_files\1674902611-trainLosses.npy
		train AUC: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_full_data\training_files\1674902611-auc.npy
		train F1s : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_full_data\training_files\1674902611-trainF1s.npy
		train TPRs: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_full_data\training_files\1674902611-trainTPRs.npy
01/28/2023 11:43:32 AM  [*] Evaluating pretrained model on test set...
01/28/2023 11:43:37 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.1580 | F1: 0.2729
01/28/2023 11:43:37 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.2803 | F1: 0.4378
01/28/2023 11:43:37 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.3108 | F1: 0.4739
01/28/2023 11:43:37 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3740 | F1: 0.5434
01/28/2023 11:43:37 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.4458 | F1: 0.6131
01/28/2023 11:43:37 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.5801 | F1: 0.7226
01/28/2023 11:43:37 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.7471 | F1: 0.8155
01/28/2023 11:43:37 AM  [*] Evaluating non_pretrained model on test set...
01/28/2023 11:43:42 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.1197 | F1: 0.2139
01/28/2023 11:43:42 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.2190 | F1: 0.3592
01/28/2023 11:43:42 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.2926 | F1: 0.4524
01/28/2023 11:43:42 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3608 | F1: 0.5293
01/28/2023 11:43:42 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.4153 | F1: 0.5834
01/28/2023 11:43:42 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.5325 | F1: 0.6835
01/28/2023 11:43:42 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.8077 | F1: 0.8535
01/28/2023 11:43:42 AM  [*] Evaluating full_data model on test set...
01/28/2023 11:43:47 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0287 | F1: 0.0558
01/28/2023 11:43:47 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.2007 | F1: 0.3342
01/28/2023 11:43:47 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.3272 | F1: 0.4928
01/28/2023 11:43:47 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3656 | F1: 0.5345
01/28/2023 11:43:47 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.4382 | F1: 0.6057
01/28/2023 11:43:47 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.5576 | F1: 0.7044
01/28/2023 11:43:47 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.7903 | F1: 0.8429
01/28/2023 11:43:47 AM  [!] Running pre-training split 3/3
01/28/2023 11:43:50 AM  [!] Pre-training model...
01/28/2023 11:43:51 AM  [*] Masking sequences...
01/28/2023 11:44:08 AM  [*] Started epoch: 1
01/28/2023 11:44:09 AM  [*] Sat Jan 28 11:44:09 2023: Train Epoch: 1 [  0  /53288 (0 %)]	Loss: 450.779633 | Elapsed: 0.82s
01/28/2023 11:44:22 AM  [*] Sat Jan 28 11:44:22 2023: Train Epoch: 1 [6400 /53288 (12%)]	Loss: 244.692200 | Elapsed: 12.34s
01/28/2023 11:44:34 AM  [*] Sat Jan 28 11:44:34 2023: Train Epoch: 1 [12800/53288 (24%)]	Loss: 225.739304 | Elapsed: 12.34s
01/28/2023 11:44:46 AM  [*] Sat Jan 28 11:44:46 2023: Train Epoch: 1 [19200/53288 (36%)]	Loss: 195.300537 | Elapsed: 12.37s
01/28/2023 11:44:59 AM  [*] Sat Jan 28 11:44:59 2023: Train Epoch: 1 [25600/53288 (48%)]	Loss: 215.400345 | Elapsed: 12.46s
01/28/2023 11:45:11 AM  [*] Sat Jan 28 11:45:11 2023: Train Epoch: 1 [32000/53288 (60%)]	Loss: 206.178238 | Elapsed: 12.45s
01/28/2023 11:45:24 AM  [*] Sat Jan 28 11:45:24 2023: Train Epoch: 1 [38400/53288 (72%)]	Loss: 210.721405 | Elapsed: 12.47s
01/28/2023 11:45:36 AM  [*] Sat Jan 28 11:45:36 2023: Train Epoch: 1 [44800/53288 (84%)]	Loss: 207.406738 | Elapsed: 12.58s
01/28/2023 11:45:49 AM  [*] Sat Jan 28 11:45:49 2023: Train Epoch: 1 [51200/53288 (96%)]	Loss: 180.476440 | Elapsed: 12.49s
01/28/2023 11:45:54 AM  [*] Sat Jan 28 11:45:54 2023:    1    | Tr.loss: 211.287931 | Elapsed:  105.64  s
01/28/2023 11:45:54 AM  [*] Started epoch: 2
01/28/2023 11:45:54 AM  [*] Sat Jan 28 11:45:54 2023: Train Epoch: 2 [  0  /53288 (0 %)]	Loss: 205.208527 | Elapsed: 0.13s
01/28/2023 11:46:07 AM  [*] Sat Jan 28 11:46:07 2023: Train Epoch: 2 [6400 /53288 (12%)]	Loss: 181.988113 | Elapsed: 12.43s
01/28/2023 11:46:19 AM  [*] Sat Jan 28 11:46:19 2023: Train Epoch: 2 [12800/53288 (24%)]	Loss: 217.278687 | Elapsed: 12.39s
01/28/2023 11:46:31 AM  [*] Sat Jan 28 11:46:31 2023: Train Epoch: 2 [19200/53288 (36%)]	Loss: 192.755829 | Elapsed: 12.49s
01/28/2023 11:46:44 AM  [*] Sat Jan 28 11:46:44 2023: Train Epoch: 2 [25600/53288 (48%)]	Loss: 175.081009 | Elapsed: 12.42s
01/28/2023 11:46:56 AM  [*] Sat Jan 28 11:46:56 2023: Train Epoch: 2 [32000/53288 (60%)]	Loss: 175.980530 | Elapsed: 12.48s
01/28/2023 11:47:09 AM  [*] Sat Jan 28 11:47:09 2023: Train Epoch: 2 [38400/53288 (72%)]	Loss: 199.049530 | Elapsed: 12.41s
01/28/2023 11:47:21 AM  [*] Sat Jan 28 11:47:21 2023: Train Epoch: 2 [44800/53288 (84%)]	Loss: 181.015579 | Elapsed: 12.44s
01/28/2023 11:47:34 AM  [*] Sat Jan 28 11:47:34 2023: Train Epoch: 2 [51200/53288 (96%)]	Loss: 188.517395 | Elapsed: 12.40s
01/28/2023 11:47:39 AM  [*] Sat Jan 28 11:47:39 2023:    2    | Tr.loss: 189.990941 | Elapsed:  104.94  s
01/28/2023 11:47:39 AM  [*] Started epoch: 3
01/28/2023 11:47:39 AM  [*] Sat Jan 28 11:47:39 2023: Train Epoch: 3 [  0  /53288 (0 %)]	Loss: 176.173645 | Elapsed: 0.14s
01/28/2023 11:47:52 AM  [*] Sat Jan 28 11:47:52 2023: Train Epoch: 3 [6400 /53288 (12%)]	Loss: 178.588165 | Elapsed: 12.48s
01/28/2023 11:48:04 AM  [*] Sat Jan 28 11:48:04 2023: Train Epoch: 3 [12800/53288 (24%)]	Loss: 171.456726 | Elapsed: 12.38s
01/28/2023 11:48:16 AM  [*] Sat Jan 28 11:48:16 2023: Train Epoch: 3 [19200/53288 (36%)]	Loss: 179.670288 | Elapsed: 12.42s
01/28/2023 11:48:29 AM  [*] Sat Jan 28 11:48:29 2023: Train Epoch: 3 [25600/53288 (48%)]	Loss: 174.205353 | Elapsed: 12.38s
01/28/2023 11:48:41 AM  [*] Sat Jan 28 11:48:41 2023: Train Epoch: 3 [32000/53288 (60%)]	Loss: 181.726761 | Elapsed: 12.41s
01/28/2023 11:48:54 AM  [*] Sat Jan 28 11:48:54 2023: Train Epoch: 3 [38400/53288 (72%)]	Loss: 194.292740 | Elapsed: 12.48s
01/28/2023 11:49:06 AM  [*] Sat Jan 28 11:49:06 2023: Train Epoch: 3 [44800/53288 (84%)]	Loss: 191.617249 | Elapsed: 12.40s
01/28/2023 11:49:18 AM  [*] Sat Jan 28 11:49:18 2023: Train Epoch: 3 [51200/53288 (96%)]	Loss: 166.474731 | Elapsed: 12.42s
01/28/2023 11:49:24 AM  [*] Sat Jan 28 11:49:24 2023:    3    | Tr.loss: 184.219615 | Elapsed:  104.83  s
01/28/2023 11:49:24 AM  [*] Started epoch: 4
01/28/2023 11:49:24 AM  [*] Sat Jan 28 11:49:24 2023: Train Epoch: 4 [  0  /53288 (0 %)]	Loss: 175.078064 | Elapsed: 0.13s
01/28/2023 11:49:36 AM  [*] Sat Jan 28 11:49:36 2023: Train Epoch: 4 [6400 /53288 (12%)]	Loss: 177.877457 | Elapsed: 12.38s
01/28/2023 11:49:49 AM  [*] Sat Jan 28 11:49:49 2023: Train Epoch: 4 [12800/53288 (24%)]	Loss: 169.197540 | Elapsed: 12.46s
01/28/2023 11:50:01 AM  [*] Sat Jan 28 11:50:01 2023: Train Epoch: 4 [19200/53288 (36%)]	Loss: 197.549774 | Elapsed: 12.37s
01/28/2023 11:50:14 AM  [*] Sat Jan 28 11:50:14 2023: Train Epoch: 4 [25600/53288 (48%)]	Loss: 179.151978 | Elapsed: 12.47s
01/28/2023 11:50:26 AM  [*] Sat Jan 28 11:50:26 2023: Train Epoch: 4 [32000/53288 (60%)]	Loss: 160.748901 | Elapsed: 12.44s
01/28/2023 11:50:38 AM  [*] Sat Jan 28 11:50:38 2023: Train Epoch: 4 [38400/53288 (72%)]	Loss: 192.383362 | Elapsed: 12.40s
01/28/2023 11:50:51 AM  [*] Sat Jan 28 11:50:51 2023: Train Epoch: 4 [44800/53288 (84%)]	Loss: 192.808685 | Elapsed: 12.45s
01/28/2023 11:51:03 AM  [*] Sat Jan 28 11:51:03 2023: Train Epoch: 4 [51200/53288 (96%)]	Loss: 187.840271 | Elapsed: 12.42s
01/28/2023 11:51:09 AM  [*] Sat Jan 28 11:51:09 2023:    4    | Tr.loss: 180.901925 | Elapsed:  104.91  s
01/28/2023 11:51:09 AM  [*] Started epoch: 5
01/28/2023 11:51:09 AM  [*] Sat Jan 28 11:51:09 2023: Train Epoch: 5 [  0  /53288 (0 %)]	Loss: 183.548340 | Elapsed: 0.13s
01/28/2023 11:51:21 AM  [*] Sat Jan 28 11:51:21 2023: Train Epoch: 5 [6400 /53288 (12%)]	Loss: 182.940231 | Elapsed: 12.64s
01/28/2023 11:51:34 AM  [*] Sat Jan 28 11:51:34 2023: Train Epoch: 5 [12800/53288 (24%)]	Loss: 179.311783 | Elapsed: 12.85s
01/28/2023 11:51:47 AM  [*] Sat Jan 28 11:51:47 2023: Train Epoch: 5 [19200/53288 (36%)]	Loss: 195.058563 | Elapsed: 12.73s
01/28/2023 11:52:00 AM  [*] Sat Jan 28 11:52:00 2023: Train Epoch: 5 [25600/53288 (48%)]	Loss: 180.651840 | Elapsed: 12.49s
01/28/2023 11:52:12 AM  [*] Sat Jan 28 11:52:12 2023: Train Epoch: 5 [32000/53288 (60%)]	Loss: 200.733292 | Elapsed: 12.36s
01/28/2023 11:52:24 AM  [*] Sat Jan 28 11:52:24 2023: Train Epoch: 5 [38400/53288 (72%)]	Loss: 182.011703 | Elapsed: 12.40s
01/28/2023 11:52:37 AM  [*] Sat Jan 28 11:52:37 2023: Train Epoch: 5 [44800/53288 (84%)]	Loss: 162.852524 | Elapsed: 12.38s
01/28/2023 11:52:49 AM  [*] Sat Jan 28 11:52:49 2023: Train Epoch: 5 [51200/53288 (96%)]	Loss: 172.863129 | Elapsed: 12.40s
01/28/2023 11:52:54 AM  [*] Sat Jan 28 11:52:54 2023:    5    | Tr.loss: 178.645072 | Elapsed:  105.72  s
01/28/2023 11:52:54 AM  [*] Started epoch: 6
01/28/2023 11:52:55 AM  [*] Sat Jan 28 11:52:55 2023: Train Epoch: 6 [  0  /53288 (0 %)]	Loss: 182.508331 | Elapsed: 0.12s
01/28/2023 11:53:07 AM  [*] Sat Jan 28 11:53:07 2023: Train Epoch: 6 [6400 /53288 (12%)]	Loss: 188.855713 | Elapsed: 12.46s
01/28/2023 11:53:20 AM  [*] Sat Jan 28 11:53:20 2023: Train Epoch: 6 [12800/53288 (24%)]	Loss: 180.318542 | Elapsed: 12.64s
01/28/2023 11:53:32 AM  [*] Sat Jan 28 11:53:32 2023: Train Epoch: 6 [19200/53288 (36%)]	Loss: 202.611191 | Elapsed: 12.55s
01/28/2023 11:53:45 AM  [*] Sat Jan 28 11:53:45 2023: Train Epoch: 6 [25600/53288 (48%)]	Loss: 177.585678 | Elapsed: 12.50s
01/28/2023 11:53:57 AM  [*] Sat Jan 28 11:53:57 2023: Train Epoch: 6 [32000/53288 (60%)]	Loss: 179.735321 | Elapsed: 12.53s
01/28/2023 11:54:10 AM  [*] Sat Jan 28 11:54:10 2023: Train Epoch: 6 [38400/53288 (72%)]	Loss: 179.891418 | Elapsed: 12.48s
01/28/2023 11:54:22 AM  [*] Sat Jan 28 11:54:22 2023: Train Epoch: 6 [44800/53288 (84%)]	Loss: 163.239258 | Elapsed: 12.34s
01/28/2023 11:54:34 AM  [*] Sat Jan 28 11:54:34 2023: Train Epoch: 6 [51200/53288 (96%)]	Loss: 171.295532 | Elapsed: 12.44s
01/28/2023 11:54:40 AM  [*] Sat Jan 28 11:54:40 2023:    6    | Tr.loss: 177.340000 | Elapsed:  105.45  s
01/28/2023 11:54:40 AM  [*] Started epoch: 7
01/28/2023 11:54:40 AM  [*] Sat Jan 28 11:54:40 2023: Train Epoch: 7 [  0  /53288 (0 %)]	Loss: 168.384583 | Elapsed: 0.13s
01/28/2023 11:54:40 AM [!] Learning rate: 2.5e-05
01/28/2023 11:54:52 AM  [*] Sat Jan 28 11:54:52 2023: Train Epoch: 7 [6400 /53288 (12%)]	Loss: 198.526245 | Elapsed: 12.38s
01/28/2023 11:55:05 AM  [*] Sat Jan 28 11:55:05 2023: Train Epoch: 7 [12800/53288 (24%)]	Loss: 188.732529 | Elapsed: 12.27s
01/28/2023 11:55:17 AM  [*] Sat Jan 28 11:55:17 2023: Train Epoch: 7 [19200/53288 (36%)]	Loss: 159.140625 | Elapsed: 12.26s
01/28/2023 11:55:29 AM  [*] Sat Jan 28 11:55:29 2023: Train Epoch: 7 [25600/53288 (48%)]	Loss: 162.469330 | Elapsed: 12.24s
01/28/2023 11:55:41 AM  [*] Sat Jan 28 11:55:41 2023: Train Epoch: 7 [32000/53288 (60%)]	Loss: 164.753113 | Elapsed: 12.30s
01/28/2023 11:55:54 AM  [*] Sat Jan 28 11:55:54 2023: Train Epoch: 7 [38400/53288 (72%)]	Loss: 167.707870 | Elapsed: 12.52s
01/28/2023 11:56:06 AM  [*] Sat Jan 28 11:56:06 2023: Train Epoch: 7 [44800/53288 (84%)]	Loss: 175.885071 | Elapsed: 12.30s
01/28/2023 11:56:18 AM  [*] Sat Jan 28 11:56:18 2023: Train Epoch: 7 [51200/53288 (96%)]	Loss: 200.114380 | Elapsed: 12.23s
01/28/2023 11:56:24 AM  [*] Sat Jan 28 11:56:24 2023:    7    | Tr.loss: 175.871893 | Elapsed:  103.77  s
01/28/2023 11:56:24 AM  [*] Started epoch: 8
01/28/2023 11:56:24 AM  [*] Sat Jan 28 11:56:24 2023: Train Epoch: 8 [  0  /53288 (0 %)]	Loss: 169.229279 | Elapsed: 0.14s
01/28/2023 11:56:36 AM  [*] Sat Jan 28 11:56:36 2023: Train Epoch: 8 [6400 /53288 (12%)]	Loss: 163.572662 | Elapsed: 12.38s
01/28/2023 11:56:48 AM  [*] Sat Jan 28 11:56:48 2023: Train Epoch: 8 [12800/53288 (24%)]	Loss: 174.036255 | Elapsed: 12.26s
01/28/2023 11:57:01 AM  [*] Sat Jan 28 11:57:01 2023: Train Epoch: 8 [19200/53288 (36%)]	Loss: 170.230774 | Elapsed: 12.23s
01/28/2023 11:57:13 AM  [*] Sat Jan 28 11:57:13 2023: Train Epoch: 8 [25600/53288 (48%)]	Loss: 197.265854 | Elapsed: 12.24s
01/28/2023 11:57:25 AM  [*] Sat Jan 28 11:57:25 2023: Train Epoch: 8 [32000/53288 (60%)]	Loss: 171.032410 | Elapsed: 12.25s
01/28/2023 11:57:37 AM  [*] Sat Jan 28 11:57:37 2023: Train Epoch: 8 [38400/53288 (72%)]	Loss: 168.759201 | Elapsed: 12.24s
01/28/2023 11:57:50 AM  [*] Sat Jan 28 11:57:50 2023: Train Epoch: 8 [44800/53288 (84%)]	Loss: 180.289566 | Elapsed: 12.18s
01/28/2023 11:58:02 AM  [*] Sat Jan 28 11:58:02 2023: Train Epoch: 8 [51200/53288 (96%)]	Loss: 188.618774 | Elapsed: 12.21s
01/28/2023 11:58:07 AM  [*] Sat Jan 28 11:58:07 2023:    8    | Tr.loss: 175.577463 | Elapsed:  103.31  s
01/28/2023 11:58:07 AM  [*] Started epoch: 9
01/28/2023 11:58:07 AM  [*] Sat Jan 28 11:58:07 2023: Train Epoch: 9 [  0  /53288 (0 %)]	Loss: 174.079010 | Elapsed: 0.14s
01/28/2023 11:58:19 AM  [*] Sat Jan 28 11:58:19 2023: Train Epoch: 9 [6400 /53288 (12%)]	Loss: 179.773361 | Elapsed: 12.31s
01/28/2023 11:58:32 AM  [*] Sat Jan 28 11:58:32 2023: Train Epoch: 9 [12800/53288 (24%)]	Loss: 178.839447 | Elapsed: 12.26s
01/28/2023 11:58:44 AM  [*] Sat Jan 28 11:58:44 2023: Train Epoch: 9 [19200/53288 (36%)]	Loss: 176.043121 | Elapsed: 12.33s
01/28/2023 11:58:56 AM  [*] Sat Jan 28 11:58:56 2023: Train Epoch: 9 [25600/53288 (48%)]	Loss: 181.421021 | Elapsed: 12.22s
01/28/2023 11:59:08 AM  [*] Sat Jan 28 11:59:08 2023: Train Epoch: 9 [32000/53288 (60%)]	Loss: 159.347229 | Elapsed: 12.27s
01/28/2023 11:59:21 AM  [*] Sat Jan 28 11:59:21 2023: Train Epoch: 9 [38400/53288 (72%)]	Loss: 198.224335 | Elapsed: 12.18s
01/28/2023 11:59:33 AM  [*] Sat Jan 28 11:59:33 2023: Train Epoch: 9 [44800/53288 (84%)]	Loss: 172.975449 | Elapsed: 12.23s
01/28/2023 11:59:45 AM  [*] Sat Jan 28 11:59:45 2023: Train Epoch: 9 [51200/53288 (96%)]	Loss: 194.777237 | Elapsed: 12.22s
01/28/2023 11:59:50 AM  [*] Sat Jan 28 11:59:50 2023:    9    | Tr.loss: 175.413676 | Elapsed:  103.41  s
01/28/2023 11:59:50 AM  [*] Started epoch: 10
01/28/2023 11:59:50 AM  [*] Sat Jan 28 11:59:50 2023: Train Epoch: 10 [  0  /53288 (0 %)]	Loss: 165.481812 | Elapsed: 0.13s
01/28/2023 12:00:03 PM  [*] Sat Jan 28 12:00:03 2023: Train Epoch: 10 [6400 /53288 (12%)]	Loss: 181.285919 | Elapsed: 12.28s
01/28/2023 12:00:15 PM  [*] Sat Jan 28 12:00:15 2023: Train Epoch: 10 [12800/53288 (24%)]	Loss: 169.865936 | Elapsed: 12.34s
01/28/2023 12:00:28 PM  [*] Sat Jan 28 12:00:28 2023: Train Epoch: 10 [19200/53288 (36%)]	Loss: 182.968292 | Elapsed: 12.41s
01/28/2023 12:00:40 PM  [*] Sat Jan 28 12:00:40 2023: Train Epoch: 10 [25600/53288 (48%)]	Loss: 183.834381 | Elapsed: 12.26s
01/28/2023 12:00:52 PM  [*] Sat Jan 28 12:00:52 2023: Train Epoch: 10 [32000/53288 (60%)]	Loss: 185.223907 | Elapsed: 12.24s
01/28/2023 12:01:04 PM  [*] Sat Jan 28 12:01:04 2023: Train Epoch: 10 [38400/53288 (72%)]	Loss: 186.750641 | Elapsed: 12.33s
01/28/2023 12:01:17 PM  [*] Sat Jan 28 12:01:17 2023: Train Epoch: 10 [44800/53288 (84%)]	Loss: 178.589844 | Elapsed: 12.23s
01/28/2023 12:01:29 PM  [*] Sat Jan 28 12:01:29 2023: Train Epoch: 10 [51200/53288 (96%)]	Loss: 183.985107 | Elapsed: 12.26s
01/28/2023 12:01:34 PM  [*] Sat Jan 28 12:01:34 2023:   10    | Tr.loss: 175.151651 | Elapsed:  103.84  s
01/28/2023 12:01:35 PM [!] Sat Jan 28 12:01:35 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\preTraining\training_files\1674903694-model.torch
		train time: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\preTraining\training_files\1674903694-trainTime.npy
		train losses: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\preTraining\training_files\1674903694-trainLosses.npy
		train AUC: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\preTraining\training_files\1674903694-auc.npy
01/28/2023 12:01:35 PM  [!] Training pretrained model on downstream task...
01/28/2023 12:01:35 PM  [*] Started epoch: 1
01/28/2023 12:01:36 PM  [*] Sat Jan 28 12:01:36 2023: Train Epoch: 1 [  0  /22838 (0 %)]	Loss: 3.877881 | Elapsed: 0.35s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 12:01:45 PM  [*] Sat Jan 28 12:01:45 2023: Train Epoch: 1 [6400 /22838 (28%)]	Loss: 0.341615 | Elapsed: 9.09s | FPR 0.0003 -> TPR 0.4625 & F1 0.6325
01/28/2023 12:01:54 PM  [*] Sat Jan 28 12:01:54 2023: Train Epoch: 1 [12800/22838 (56%)]	Loss: 0.383633 | Elapsed: 9.07s | FPR 0.0003 -> TPR 0.1406 & F1 0.2466
01/28/2023 12:02:03 PM  [*] Sat Jan 28 12:02:03 2023: Train Epoch: 1 [19200/22838 (84%)]	Loss: 0.411885 | Elapsed: 9.08s | FPR 0.0003 -> TPR 0.4030 & F1 0.5745
01/28/2023 12:02:09 PM  [*] Sat Jan 28 12:02:09 2023:    1    | Tr.loss: 0.456360 | Elapsed:   33.18  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8507
01/28/2023 12:02:09 PM  [*] Started epoch: 2
01/28/2023 12:02:09 PM  [*] Sat Jan 28 12:02:09 2023: Train Epoch: 2 [  0  /22838 (0 %)]	Loss: 0.331621 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.7209 & F1 0.8378
01/28/2023 12:02:18 PM  [*] Sat Jan 28 12:02:18 2023: Train Epoch: 2 [6400 /22838 (28%)]	Loss: 0.202780 | Elapsed: 9.06s | FPR 0.0003 -> TPR 0.7000 & F1 0.8235
01/28/2023 12:02:27 PM  [*] Sat Jan 28 12:02:27 2023: Train Epoch: 2 [12800/22838 (56%)]	Loss: 0.184082 | Elapsed: 9.07s | FPR 0.0003 -> TPR 0.7424 & F1 0.8522
01/28/2023 12:02:36 PM  [*] Sat Jan 28 12:02:36 2023: Train Epoch: 2 [19200/22838 (84%)]	Loss: 0.213074 | Elapsed: 9.07s | FPR 0.0003 -> TPR 0.8000 & F1 0.8889
01/28/2023 12:02:41 PM  [*] Sat Jan 28 12:02:41 2023:    2    | Tr.loss: 0.253411 | Elapsed:   32.87  s | FPR 0.0003 -> TPR: 0.25 & F1: 0.40 | AUC: 0.9531
01/28/2023 12:02:41 PM  [*] Started epoch: 3
01/28/2023 12:02:42 PM  [*] Sat Jan 28 12:02:42 2023: Train Epoch: 3 [  0  /22838 (0 %)]	Loss: 0.214455 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.8043 & F1 0.8916
01/28/2023 12:02:51 PM  [*] Sat Jan 28 12:02:51 2023: Train Epoch: 3 [6400 /22838 (28%)]	Loss: 0.284164 | Elapsed: 9.06s | FPR 0.0003 -> TPR 0.5938 & F1 0.7451
01/28/2023 12:03:00 PM  [*] Sat Jan 28 12:03:00 2023: Train Epoch: 3 [12800/22838 (56%)]	Loss: 0.205150 | Elapsed: 9.06s | FPR 0.0003 -> TPR 0.6462 & F1 0.7850
01/28/2023 12:03:09 PM  [*] Sat Jan 28 12:03:09 2023: Train Epoch: 3 [19200/22838 (84%)]	Loss: 0.159748 | Elapsed: 9.07s | FPR 0.0003 -> TPR 0.8548 & F1 0.9217
01/28/2023 12:03:14 PM  [*] Sat Jan 28 12:03:14 2023:    3    | Tr.loss: 0.185907 | Elapsed:   32.89  s | FPR 0.0003 -> TPR: 0.39 & F1: 0.56 | AUC: 0.9763
01/28/2023 12:03:15 PM [!] Sat Jan 28 12:03:15 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_pretrained\training_files\1674903794-model.torch
		train time: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_pretrained\training_files\1674903794-trainTime.npy
		train losses: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_pretrained\training_files\1674903794-trainLosses.npy
		train AUC: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_pretrained\training_files\1674903794-auc.npy
		train F1s : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_pretrained\training_files\1674903794-trainF1s.npy
		train TPRs: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_pretrained\training_files\1674903794-trainTPRs.npy
01/28/2023 12:03:15 PM  [!] Training non_pretrained model on downstream task...
01/28/2023 12:03:15 PM  [*] Started epoch: 1
01/28/2023 12:03:15 PM  [*] Sat Jan 28 12:03:15 2023: Train Epoch: 1 [  0  /22838 (0 %)]	Loss: 2.055013 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0435 & F1 0.0833
01/28/2023 12:03:21 PM  [*] Sat Jan 28 12:03:21 2023: Train Epoch: 1 [6400 /22838 (28%)]	Loss: 0.483711 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.3281 & F1 0.4941
01/28/2023 12:03:28 PM  [*] Sat Jan 28 12:03:28 2023: Train Epoch: 1 [12800/22838 (56%)]	Loss: 0.335528 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.4853 & F1 0.6535
01/28/2023 12:03:34 PM  [*] Sat Jan 28 12:03:34 2023: Train Epoch: 1 [19200/22838 (84%)]	Loss: 0.296662 | Elapsed: 6.27s | FPR 0.0003 -> TPR 0.4000 & F1 0.5714
01/28/2023 12:03:38 PM  [*] Sat Jan 28 12:03:38 2023:    1    | Tr.loss: 0.423576 | Elapsed:   22.64  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8639
01/28/2023 12:03:38 PM  [*] Started epoch: 2
01/28/2023 12:03:38 PM  [*] Sat Jan 28 12:03:38 2023: Train Epoch: 2 [  0  /22838 (0 %)]	Loss: 0.312943 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.5000 & F1 0.6667
01/28/2023 12:03:44 PM  [*] Sat Jan 28 12:03:44 2023: Train Epoch: 2 [6400 /22838 (28%)]	Loss: 0.266334 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.8276 & F1 0.9057
01/28/2023 12:03:50 PM  [*] Sat Jan 28 12:03:50 2023: Train Epoch: 2 [12800/22838 (56%)]	Loss: 0.283033 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.6129 & F1 0.7600
01/28/2023 12:03:57 PM  [*] Sat Jan 28 12:03:57 2023: Train Epoch: 2 [19200/22838 (84%)]	Loss: 0.238018 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.5278 & F1 0.6909
01/28/2023 12:04:00 PM  [*] Sat Jan 28 12:04:00 2023:    2    | Tr.loss: 0.243832 | Elapsed:   22.67  s | FPR 0.0003 -> TPR: 0.25 & F1: 0.40 | AUC: 0.9577
01/28/2023 12:04:00 PM  [*] Started epoch: 3
01/28/2023 12:04:01 PM  [*] Sat Jan 28 12:04:01 2023: Train Epoch: 3 [  0  /22838 (0 %)]	Loss: 0.105051 | Elapsed: 0.05s | FPR 0.0003 -> TPR 0.9000 & F1 0.9474
01/28/2023 12:04:07 PM  [*] Sat Jan 28 12:04:07 2023: Train Epoch: 3 [6400 /22838 (28%)]	Loss: 0.146472 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.9265 & F1 0.9618
01/28/2023 12:04:13 PM  [*] Sat Jan 28 12:04:13 2023: Train Epoch: 3 [12800/22838 (56%)]	Loss: 0.270863 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.5312 & F1 0.6939
01/28/2023 12:04:18 PM [!] Learning rate: 2.5e-05
01/28/2023 12:04:19 PM  [*] Sat Jan 28 12:04:19 2023: Train Epoch: 3 [19200/22838 (84%)]	Loss: 0.161333 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.7119 & F1 0.8317
01/28/2023 12:04:23 PM  [*] Sat Jan 28 12:04:23 2023:    3    | Tr.loss: 0.183146 | Elapsed:   22.63  s | FPR 0.0003 -> TPR: 0.42 & F1: 0.59 | AUC: 0.9765
01/28/2023 12:04:24 PM [!] Sat Jan 28 12:04:23 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_non_pretrained\training_files\1674903863-model.torch
		train time: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_non_pretrained\training_files\1674903863-trainTime.npy
		train losses: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_non_pretrained\training_files\1674903863-trainLosses.npy
		train AUC: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_non_pretrained\training_files\1674903863-auc.npy
		train F1s : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_non_pretrained\training_files\1674903863-trainF1s.npy
		train TPRs: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_non_pretrained\training_files\1674903863-trainTPRs.npy
01/28/2023 12:04:24 PM  [!] Training full_data model on downstream task...
01/28/2023 12:04:24 PM  [*] Started epoch: 1
01/28/2023 12:04:24 PM  [*] Sat Jan 28 12:04:24 2023: Train Epoch: 1 [  0  /76126 (0 %)]	Loss: 1.474212 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0435 & F1 0.0833
01/28/2023 12:04:30 PM  [*] Sat Jan 28 12:04:30 2023: Train Epoch: 1 [6400 /76126 (8 %)]	Loss: 0.552806 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.1000 & F1 0.1818
01/28/2023 12:04:36 PM  [*] Sat Jan 28 12:04:36 2023: Train Epoch: 1 [12800/76126 (17%)]	Loss: 0.412145 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.5286 & F1 0.6916
01/28/2023 12:04:43 PM  [*] Sat Jan 28 12:04:43 2023: Train Epoch: 1 [19200/76126 (25%)]	Loss: 0.364121 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.5625 & F1 0.7200
01/28/2023 12:04:49 PM  [*] Sat Jan 28 12:04:49 2023: Train Epoch: 1 [25600/76126 (34%)]	Loss: 0.353891 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.4237 & F1 0.5952
01/28/2023 12:04:55 PM  [*] Sat Jan 28 12:04:55 2023: Train Epoch: 1 [32000/76126 (42%)]	Loss: 0.230535 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.6883 & F1 0.8154
01/28/2023 12:05:01 PM  [*] Sat Jan 28 12:05:01 2023: Train Epoch: 1 [38400/76126 (50%)]	Loss: 0.246980 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.6400 & F1 0.7805
01/28/2023 12:05:08 PM  [*] Sat Jan 28 12:05:08 2023: Train Epoch: 1 [44800/76126 (59%)]	Loss: 0.240528 | Elapsed: 6.26s | FPR 0.0003 -> TPR 0.6462 & F1 0.7850
01/28/2023 12:05:14 PM  [*] Sat Jan 28 12:05:14 2023: Train Epoch: 1 [51200/76126 (67%)]	Loss: 0.123213 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.7031 & F1 0.8257
01/28/2023 12:05:20 PM  [*] Sat Jan 28 12:05:20 2023: Train Epoch: 1 [57600/76126 (76%)]	Loss: 0.238410 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.7941 & F1 0.8852
01/28/2023 12:05:26 PM [!] Learning rate: 2.5e-05
01/28/2023 12:05:26 PM  [*] Sat Jan 28 12:05:26 2023: Train Epoch: 1 [64000/76126 (84%)]	Loss: 0.189011 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.8154 & F1 0.8983
01/28/2023 12:05:32 PM  [*] Sat Jan 28 12:05:32 2023: Train Epoch: 1 [70400/76126 (92%)]	Loss: 0.199960 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.8730 & F1 0.9322
01/28/2023 12:05:40 PM  [*] Sat Jan 28 12:05:40 2023:    1    | Tr.loss: 0.290426 | Elapsed:   75.67  s | FPR 0.0003 -> TPR: 0.20 & F1: 0.33 | AUC: 0.9379
01/28/2023 12:05:40 PM  [*] Started epoch: 2
01/28/2023 12:05:40 PM  [*] Sat Jan 28 12:05:40 2023: Train Epoch: 2 [  0  /76126 (0 %)]	Loss: 0.183339 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.7500 & F1 0.8571
01/28/2023 12:05:46 PM  [*] Sat Jan 28 12:05:46 2023: Train Epoch: 2 [6400 /76126 (8 %)]	Loss: 0.179241 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.8986 & F1 0.9466
01/28/2023 12:05:52 PM  [*] Sat Jan 28 12:05:52 2023: Train Epoch: 2 [12800/76126 (17%)]	Loss: 0.188758 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.8824 & F1 0.9375
01/28/2023 12:05:58 PM  [*] Sat Jan 28 12:05:58 2023: Train Epoch: 2 [19200/76126 (25%)]	Loss: 0.125310 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.8060 & F1 0.8926
01/28/2023 12:06:05 PM  [*] Sat Jan 28 12:06:05 2023: Train Epoch: 2 [25600/76126 (34%)]	Loss: 0.200555 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.8939 & F1 0.9440
01/28/2023 12:06:11 PM  [*] Sat Jan 28 12:06:11 2023: Train Epoch: 2 [32000/76126 (42%)]	Loss: 0.085873 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.8615 & F1 0.9256
01/28/2023 12:06:17 PM  [*] Sat Jan 28 12:06:17 2023: Train Epoch: 2 [38400/76126 (50%)]	Loss: 0.181523 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.8451 & F1 0.9160
01/28/2023 12:06:23 PM  [*] Sat Jan 28 12:06:23 2023: Train Epoch: 2 [44800/76126 (59%)]	Loss: 0.154955 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.9254 & F1 0.9612
01/28/2023 12:06:29 PM  [*] Sat Jan 28 12:06:29 2023: Train Epoch: 2 [51200/76126 (67%)]	Loss: 0.227819 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.7973 & F1 0.8872
01/28/2023 12:06:30 PM [!] Learning rate: 2.5e-06
01/28/2023 12:06:36 PM  [*] Sat Jan 28 12:06:36 2023: Train Epoch: 2 [57600/76126 (76%)]	Loss: 0.194182 | Elapsed: 6.27s | FPR 0.0003 -> TPR 0.8243 & F1 0.9037
01/28/2023 12:06:42 PM  [*] Sat Jan 28 12:06:42 2023: Train Epoch: 2 [64000/76126 (84%)]	Loss: 0.143220 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.6923 & F1 0.8182
01/28/2023 12:06:48 PM  [*] Sat Jan 28 12:06:48 2023: Train Epoch: 2 [70400/76126 (92%)]	Loss: 0.150833 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.9211 & F1 0.9589
01/28/2023 12:06:55 PM  [*] Sat Jan 28 12:06:55 2023:    2    | Tr.loss: 0.160535 | Elapsed:   75.53  s | FPR 0.0003 -> TPR: 0.46 & F1: 0.63 | AUC: 0.9821
01/28/2023 12:06:55 PM  [*] Started epoch: 3
01/28/2023 12:06:55 PM  [*] Sat Jan 28 12:06:55 2023: Train Epoch: 3 [  0  /76126 (0 %)]	Loss: 0.119374 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.8958 & F1 0.9451
01/28/2023 12:07:01 PM  [*] Sat Jan 28 12:07:01 2023: Train Epoch: 3 [6400 /76126 (8 %)]	Loss: 0.114680 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.9014 & F1 0.9481
01/28/2023 12:07:08 PM  [*] Sat Jan 28 12:07:08 2023: Train Epoch: 3 [12800/76126 (17%)]	Loss: 0.256644 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.8169 & F1 0.8992
01/28/2023 12:07:14 PM  [*] Sat Jan 28 12:07:14 2023: Train Epoch: 3 [19200/76126 (25%)]	Loss: 0.126306 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.8806 & F1 0.9365
01/28/2023 12:07:20 PM  [*] Sat Jan 28 12:07:20 2023: Train Epoch: 3 [25600/76126 (34%)]	Loss: 0.108089 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.8636 & F1 0.9268
01/28/2023 12:07:26 PM  [*] Sat Jan 28 12:07:26 2023: Train Epoch: 3 [32000/76126 (42%)]	Loss: 0.217365 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.4928 & F1 0.6602
01/28/2023 12:07:33 PM  [*] Sat Jan 28 12:07:33 2023: Train Epoch: 3 [38400/76126 (50%)]	Loss: 0.125107 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.7692 & F1 0.8696
01/28/2023 12:07:34 PM [!] Learning rate: 2.5000000000000004e-07
01/28/2023 12:07:39 PM  [*] Sat Jan 28 12:07:39 2023: Train Epoch: 3 [44800/76126 (59%)]	Loss: 0.118509 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.9028 & F1 0.9489
01/28/2023 12:07:45 PM  [*] Sat Jan 28 12:07:45 2023: Train Epoch: 3 [51200/76126 (67%)]	Loss: 0.162888 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.8154 & F1 0.8983
01/28/2023 12:07:51 PM  [*] Sat Jan 28 12:07:51 2023: Train Epoch: 3 [57600/76126 (76%)]	Loss: 0.155822 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.7465 & F1 0.8548
01/28/2023 12:07:57 PM  [*] Sat Jan 28 12:07:57 2023: Train Epoch: 3 [64000/76126 (84%)]	Loss: 0.181735 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.8475 & F1 0.9174
01/28/2023 12:08:03 PM  [*] Sat Jan 28 12:08:03 2023: Train Epoch: 3 [70400/76126 (92%)]	Loss: 0.197022 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.7465 & F1 0.8548
01/28/2023 12:08:11 PM  [*] Sat Jan 28 12:08:11 2023:    3    | Tr.loss: 0.154981 | Elapsed:   75.53  s | FPR 0.0003 -> TPR: 0.48 & F1: 0.65 | AUC: 0.9833
01/28/2023 12:08:11 PM [!] Sat Jan 28 12:08:11 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_full_data\training_files\1674904091-model.torch
		train time: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_full_data\training_files\1674904091-trainTime.npy
		train losses: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_full_data\training_files\1674904091-trainLosses.npy
		train AUC: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_full_data\training_files\1674904091-auc.npy
		train F1s : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_full_data\training_files\1674904091-trainF1s.npy
		train TPRs: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653\downstreamTask_full_data\training_files\1674904091-trainTPRs.npy
01/28/2023 12:08:11 PM  [*] Evaluating pretrained model on test set...
01/28/2023 12:08:16 PM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0914 | F1: 0.1674
01/28/2023 12:08:16 PM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1380 | F1: 0.2425
01/28/2023 12:08:16 PM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.3678 | F1: 0.5374
01/28/2023 12:08:16 PM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.4436 | F1: 0.6135
01/28/2023 12:08:16 PM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.5178 | F1: 0.6785
01/28/2023 12:08:16 PM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.5953 | F1: 0.7346
01/28/2023 12:08:16 PM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.7789 | F1: 0.8359
01/28/2023 12:08:16 PM  [*] Evaluating non_pretrained model on test set...
01/28/2023 12:08:21 PM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0945 | F1: 0.1728
01/28/2023 12:08:21 PM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1359 | F1: 0.2393
01/28/2023 12:08:21 PM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.2995 | F1: 0.4606
01/28/2023 12:08:21 PM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3437 | F1: 0.5106
01/28/2023 12:08:21 PM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3986 | F1: 0.5665
01/28/2023 12:08:21 PM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.5085 | F1: 0.6630
01/28/2023 12:08:21 PM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.7753 | F1: 0.8335
01/28/2023 12:08:21 PM  [*] Evaluating full_data model on test set...
01/28/2023 12:08:26 PM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.1236 | F1: 0.2200
01/28/2023 12:08:26 PM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.3273 | F1: 0.4932
01/28/2023 12:08:26 PM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.3500 | F1: 0.5182
01/28/2023 12:08:26 PM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3939 | F1: 0.5642
01/28/2023 12:08:26 PM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.4498 | F1: 0.6168
01/28/2023 12:08:26 PM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.5642 | F1: 0.7098
01/28/2023 12:08:26 PM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.8241 | F1: 0.8633
01/28/2023 12:08:26 PM  [!] Finished pre-training evaluation over 3 splits! Saved metrics to:
	C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.7_1674899653/metrics_MaskedLanguageModel_nSplits_3_limit_None.json
01/28/2023 12:08:27 PM  [!] Starting Masked Language Model evaluation over 3 splits!
01/28/2023 12:08:27 PM  [!] Loaded data and vocab. X train size: (76126, 512), X test size: (17407, 512), vocab size: 50002
01/28/2023 12:08:27 PM  [!] Initiating Self-Supervised Learning Pretraining
     Language Modeling MaskedLanguageModel
     Model TransformerEncoderLM with config:
	{'vocabSize': 50002, 'maxLen': 512, 'dModel': 64, 'nHeads': 8, 'dHidden': 256, 'nLayers': 2, 'numClasses': 1, 'hiddenNeurons': [64], 'dropout': 0.3}

01/28/2023 12:08:27 PM  [!] Running pre-training split 1/3
01/28/2023 12:08:30 PM  [!] Pre-training model...
01/28/2023 12:08:31 PM  [*] Masking sequences...
01/28/2023 12:08:47 PM  [*] Started epoch: 1
01/28/2023 12:08:48 PM  [*] Sat Jan 28 12:08:48 2023: Train Epoch: 1 [  0  /57094 (0 %)]	Loss: 457.050629 | Elapsed: 0.84s
01/28/2023 12:09:01 PM  [*] Sat Jan 28 12:09:01 2023: Train Epoch: 1 [6400 /57094 (11%)]	Loss: 246.710449 | Elapsed: 12.22s
01/28/2023 12:09:13 PM  [*] Sat Jan 28 12:09:13 2023: Train Epoch: 1 [12800/57094 (22%)]	Loss: 237.526978 | Elapsed: 12.29s
01/28/2023 12:09:25 PM  [*] Sat Jan 28 12:09:25 2023: Train Epoch: 1 [19200/57094 (34%)]	Loss: 221.280716 | Elapsed: 12.27s
01/28/2023 12:09:37 PM  [*] Sat Jan 28 12:09:37 2023: Train Epoch: 1 [25600/57094 (45%)]	Loss: 195.528320 | Elapsed: 12.26s
01/28/2023 12:09:50 PM  [*] Sat Jan 28 12:09:50 2023: Train Epoch: 1 [32000/57094 (56%)]	Loss: 232.711258 | Elapsed: 12.23s
01/28/2023 12:10:02 PM  [*] Sat Jan 28 12:10:02 2023: Train Epoch: 1 [38400/57094 (67%)]	Loss: 213.084442 | Elapsed: 12.27s
01/28/2023 12:10:14 PM  [*] Sat Jan 28 12:10:14 2023: Train Epoch: 1 [44800/57094 (78%)]	Loss: 206.083221 | Elapsed: 12.29s
01/28/2023 12:10:26 PM  [*] Sat Jan 28 12:10:26 2023: Train Epoch: 1 [51200/57094 (90%)]	Loss: 200.400558 | Elapsed: 12.32s
01/28/2023 12:10:39 PM  [*] Sat Jan 28 12:10:39 2023:    1    | Tr.loss: 213.955269 | Elapsed:  111.80  s
01/28/2023 12:10:39 PM  [*] Started epoch: 2
01/28/2023 12:10:39 PM  [*] Sat Jan 28 12:10:39 2023: Train Epoch: 2 [  0  /57094 (0 %)]	Loss: 165.150284 | Elapsed: 0.14s
01/28/2023 12:10:52 PM  [*] Sat Jan 28 12:10:52 2023: Train Epoch: 2 [6400 /57094 (11%)]	Loss: 194.292831 | Elapsed: 12.33s
01/28/2023 12:11:04 PM  [*] Sat Jan 28 12:11:04 2023: Train Epoch: 2 [12800/57094 (22%)]	Loss: 184.928192 | Elapsed: 12.28s
01/28/2023 12:11:16 PM  [*] Sat Jan 28 12:11:16 2023: Train Epoch: 2 [19200/57094 (34%)]	Loss: 182.717010 | Elapsed: 12.32s
01/28/2023 12:11:29 PM  [*] Sat Jan 28 12:11:29 2023: Train Epoch: 2 [25600/57094 (45%)]	Loss: 186.507706 | Elapsed: 12.25s
01/28/2023 12:11:41 PM  [*] Sat Jan 28 12:11:41 2023: Train Epoch: 2 [32000/57094 (56%)]	Loss: 166.652313 | Elapsed: 12.35s
01/28/2023 12:11:53 PM  [*] Sat Jan 28 12:11:53 2023: Train Epoch: 2 [38400/57094 (67%)]	Loss: 180.609665 | Elapsed: 12.24s
01/28/2023 12:12:05 PM  [*] Sat Jan 28 12:12:05 2023: Train Epoch: 2 [44800/57094 (78%)]	Loss: 196.966492 | Elapsed: 12.28s
01/28/2023 12:12:18 PM  [*] Sat Jan 28 12:12:18 2023: Train Epoch: 2 [51200/57094 (90%)]	Loss: 215.116943 | Elapsed: 12.32s
01/28/2023 12:12:30 PM  [*] Sat Jan 28 12:12:30 2023:    2    | Tr.loss: 193.522560 | Elapsed:  111.11  s
01/28/2023 12:12:30 PM  [*] Started epoch: 3
01/28/2023 12:12:31 PM  [*] Sat Jan 28 12:12:31 2023: Train Epoch: 3 [  0  /57094 (0 %)]	Loss: 180.675095 | Elapsed: 0.13s
01/28/2023 12:12:43 PM  [*] Sat Jan 28 12:12:43 2023: Train Epoch: 3 [6400 /57094 (11%)]	Loss: 200.587860 | Elapsed: 12.33s
01/28/2023 12:12:55 PM  [*] Sat Jan 28 12:12:55 2023: Train Epoch: 3 [12800/57094 (22%)]	Loss: 201.703781 | Elapsed: 12.25s
01/28/2023 12:13:07 PM  [*] Sat Jan 28 12:13:07 2023: Train Epoch: 3 [19200/57094 (34%)]	Loss: 183.402069 | Elapsed: 12.32s
01/28/2023 12:13:20 PM  [*] Sat Jan 28 12:13:20 2023: Train Epoch: 3 [25600/57094 (45%)]	Loss: 173.134857 | Elapsed: 12.29s
01/28/2023 12:13:32 PM  [*] Sat Jan 28 12:13:32 2023: Train Epoch: 3 [32000/57094 (56%)]	Loss: 181.321991 | Elapsed: 12.31s
01/28/2023 12:13:44 PM  [*] Sat Jan 28 12:13:44 2023: Train Epoch: 3 [38400/57094 (67%)]	Loss: 183.629440 | Elapsed: 12.29s
01/28/2023 12:13:57 PM  [*] Sat Jan 28 12:13:57 2023: Train Epoch: 3 [44800/57094 (78%)]	Loss: 223.664993 | Elapsed: 12.23s
01/28/2023 12:14:09 PM  [*] Sat Jan 28 12:14:09 2023: Train Epoch: 3 [51200/57094 (90%)]	Loss: 181.836624 | Elapsed: 12.26s
01/28/2023 12:14:21 PM  [*] Sat Jan 28 12:14:21 2023:    3    | Tr.loss: 187.234365 | Elapsed:  111.03  s
01/28/2023 12:14:21 PM  [*] Started epoch: 4
01/28/2023 12:14:22 PM  [*] Sat Jan 28 12:14:22 2023: Train Epoch: 4 [  0  /57094 (0 %)]	Loss: 187.153458 | Elapsed: 0.14s
01/28/2023 12:14:34 PM  [*] Sat Jan 28 12:14:34 2023: Train Epoch: 4 [6400 /57094 (11%)]	Loss: 175.185028 | Elapsed: 12.32s
01/28/2023 12:14:46 PM  [*] Sat Jan 28 12:14:46 2023: Train Epoch: 4 [12800/57094 (22%)]	Loss: 179.692627 | Elapsed: 12.27s
01/28/2023 12:14:58 PM  [*] Sat Jan 28 12:14:58 2023: Train Epoch: 4 [19200/57094 (34%)]	Loss: 191.012451 | Elapsed: 12.27s
01/28/2023 12:15:11 PM  [*] Sat Jan 28 12:15:11 2023: Train Epoch: 4 [25600/57094 (45%)]	Loss: 183.181580 | Elapsed: 12.29s
01/28/2023 12:15:23 PM  [*] Sat Jan 28 12:15:23 2023: Train Epoch: 4 [32000/57094 (56%)]	Loss: 203.930878 | Elapsed: 12.26s
01/28/2023 12:15:35 PM  [*] Sat Jan 28 12:15:35 2023: Train Epoch: 4 [38400/57094 (67%)]	Loss: 173.646576 | Elapsed: 12.20s
01/28/2023 12:15:47 PM  [*] Sat Jan 28 12:15:47 2023: Train Epoch: 4 [44800/57094 (78%)]	Loss: 180.219833 | Elapsed: 12.26s
01/28/2023 12:16:00 PM  [*] Sat Jan 28 12:16:00 2023: Train Epoch: 4 [51200/57094 (90%)]	Loss: 166.084518 | Elapsed: 12.24s
01/28/2023 12:16:12 PM  [*] Sat Jan 28 12:16:12 2023:    4    | Tr.loss: 184.222909 | Elapsed:  111.00  s
01/28/2023 12:16:12 PM  [*] Started epoch: 5
01/28/2023 12:16:13 PM  [*] Sat Jan 28 12:16:13 2023: Train Epoch: 5 [  0  /57094 (0 %)]	Loss: 184.723328 | Elapsed: 0.14s
01/28/2023 12:16:25 PM  [*] Sat Jan 28 12:16:25 2023: Train Epoch: 5 [6400 /57094 (11%)]	Loss: 197.157166 | Elapsed: 12.28s
01/28/2023 12:16:37 PM  [*] Sat Jan 28 12:16:37 2023: Train Epoch: 5 [12800/57094 (22%)]	Loss: 198.554138 | Elapsed: 12.26s
01/28/2023 12:16:49 PM  [*] Sat Jan 28 12:16:49 2023: Train Epoch: 5 [19200/57094 (34%)]	Loss: 203.338043 | Elapsed: 12.28s
01/28/2023 12:17:02 PM  [*] Sat Jan 28 12:17:02 2023: Train Epoch: 5 [25600/57094 (45%)]	Loss: 183.921783 | Elapsed: 12.25s
01/28/2023 12:17:14 PM  [*] Sat Jan 28 12:17:14 2023: Train Epoch: 5 [32000/57094 (56%)]	Loss: 186.554413 | Elapsed: 12.22s
01/28/2023 12:17:26 PM  [*] Sat Jan 28 12:17:26 2023: Train Epoch: 5 [38400/57094 (67%)]	Loss: 166.534836 | Elapsed: 12.19s
01/28/2023 12:17:38 PM  [*] Sat Jan 28 12:17:38 2023: Train Epoch: 5 [44800/57094 (78%)]	Loss: 202.150421 | Elapsed: 12.24s
01/28/2023 12:17:51 PM  [*] Sat Jan 28 12:17:51 2023: Train Epoch: 5 [51200/57094 (90%)]	Loss: 184.407349 | Elapsed: 12.21s
01/28/2023 12:18:03 PM  [*] Sat Jan 28 12:18:03 2023:    5    | Tr.loss: 182.497677 | Elapsed:  110.76  s
01/28/2023 12:18:03 PM  [*] Started epoch: 6
01/28/2023 12:18:03 PM  [*] Sat Jan 28 12:18:03 2023: Train Epoch: 6 [  0  /57094 (0 %)]	Loss: 177.015869 | Elapsed: 0.13s
01/28/2023 12:18:16 PM  [*] Sat Jan 28 12:18:16 2023: Train Epoch: 6 [6400 /57094 (11%)]	Loss: 194.381866 | Elapsed: 12.24s
01/28/2023 12:18:28 PM  [*] Sat Jan 28 12:18:28 2023: Train Epoch: 6 [12800/57094 (22%)]	Loss: 186.781433 | Elapsed: 12.26s
01/28/2023 12:18:40 PM  [*] Sat Jan 28 12:18:40 2023: Train Epoch: 6 [19200/57094 (34%)]	Loss: 167.801636 | Elapsed: 12.21s
01/28/2023 12:18:52 PM  [*] Sat Jan 28 12:18:52 2023: Train Epoch: 6 [25600/57094 (45%)]	Loss: 185.228180 | Elapsed: 12.29s
01/28/2023 12:19:05 PM  [*] Sat Jan 28 12:19:05 2023: Train Epoch: 6 [32000/57094 (56%)]	Loss: 174.817719 | Elapsed: 12.25s
01/28/2023 12:19:09 PM [!] Learning rate: 2.5e-05
01/28/2023 12:19:17 PM  [*] Sat Jan 28 12:19:17 2023: Train Epoch: 6 [38400/57094 (67%)]	Loss: 161.264725 | Elapsed: 12.23s
01/28/2023 12:19:29 PM  [*] Sat Jan 28 12:19:29 2023: Train Epoch: 6 [44800/57094 (78%)]	Loss: 176.687195 | Elapsed: 12.18s
01/28/2023 12:19:41 PM  [*] Sat Jan 28 12:19:41 2023: Train Epoch: 6 [51200/57094 (90%)]	Loss: 183.546722 | Elapsed: 12.26s
01/28/2023 12:19:54 PM  [*] Sat Jan 28 12:19:54 2023:    6    | Tr.loss: 181.173223 | Elapsed:  110.66  s
01/28/2023 12:19:54 PM  [*] Started epoch: 7
01/28/2023 12:19:54 PM  [*] Sat Jan 28 12:19:54 2023: Train Epoch: 7 [  0  /57094 (0 %)]	Loss: 158.977478 | Elapsed: 0.12s
01/28/2023 12:20:06 PM  [*] Sat Jan 28 12:20:06 2023: Train Epoch: 7 [6400 /57094 (11%)]	Loss: 174.994568 | Elapsed: 12.28s
01/28/2023 12:20:19 PM  [*] Sat Jan 28 12:20:19 2023: Train Epoch: 7 [12800/57094 (22%)]	Loss: 197.377365 | Elapsed: 12.30s
01/28/2023 12:20:31 PM  [*] Sat Jan 28 12:20:31 2023: Train Epoch: 7 [19200/57094 (34%)]	Loss: 162.222290 | Elapsed: 12.30s
01/28/2023 12:20:43 PM  [*] Sat Jan 28 12:20:43 2023: Train Epoch: 7 [25600/57094 (45%)]	Loss: 173.902267 | Elapsed: 12.28s
01/28/2023 12:20:55 PM  [*] Sat Jan 28 12:20:55 2023: Train Epoch: 7 [32000/57094 (56%)]	Loss: 193.751877 | Elapsed: 12.22s
01/28/2023 12:21:08 PM  [*] Sat Jan 28 12:21:08 2023: Train Epoch: 7 [38400/57094 (67%)]	Loss: 161.987167 | Elapsed: 12.21s
01/28/2023 12:21:20 PM  [*] Sat Jan 28 12:21:20 2023: Train Epoch: 7 [44800/57094 (78%)]	Loss: 175.694275 | Elapsed: 12.26s
01/28/2023 12:21:32 PM  [*] Sat Jan 28 12:21:32 2023: Train Epoch: 7 [51200/57094 (90%)]	Loss: 174.176300 | Elapsed: 12.41s
01/28/2023 12:21:45 PM  [*] Sat Jan 28 12:21:45 2023:    7    | Tr.loss: 180.149738 | Elapsed:  111.07  s
01/28/2023 12:21:45 PM  [*] Started epoch: 8
01/28/2023 12:21:45 PM  [*] Sat Jan 28 12:21:45 2023: Train Epoch: 8 [  0  /57094 (0 %)]	Loss: 177.933655 | Elapsed: 0.13s
01/28/2023 12:21:57 PM  [*] Sat Jan 28 12:21:57 2023: Train Epoch: 8 [6400 /57094 (11%)]	Loss: 190.310852 | Elapsed: 12.31s
01/28/2023 12:22:10 PM  [*] Sat Jan 28 12:22:10 2023: Train Epoch: 8 [12800/57094 (22%)]	Loss: 157.093506 | Elapsed: 12.29s
01/28/2023 12:22:22 PM  [*] Sat Jan 28 12:22:22 2023: Train Epoch: 8 [19200/57094 (34%)]	Loss: 182.761948 | Elapsed: 12.28s
01/28/2023 12:22:34 PM  [*] Sat Jan 28 12:22:34 2023: Train Epoch: 8 [25600/57094 (45%)]	Loss: 191.752731 | Elapsed: 12.20s
01/28/2023 12:22:46 PM  [*] Sat Jan 28 12:22:46 2023: Train Epoch: 8 [32000/57094 (56%)]	Loss: 183.822495 | Elapsed: 12.25s
01/28/2023 12:22:59 PM  [*] Sat Jan 28 12:22:59 2023: Train Epoch: 8 [38400/57094 (67%)]	Loss: 181.028656 | Elapsed: 12.27s
01/28/2023 12:23:11 PM  [*] Sat Jan 28 12:23:11 2023: Train Epoch: 8 [44800/57094 (78%)]	Loss: 180.962173 | Elapsed: 12.26s
01/28/2023 12:23:23 PM  [*] Sat Jan 28 12:23:23 2023: Train Epoch: 8 [51200/57094 (90%)]	Loss: 171.059540 | Elapsed: 12.28s
01/28/2023 12:23:36 PM  [*] Sat Jan 28 12:23:36 2023:    8    | Tr.loss: 179.874298 | Elapsed:  110.96  s
01/28/2023 12:23:36 PM  [*] Started epoch: 9
01/28/2023 12:23:36 PM  [*] Sat Jan 28 12:23:36 2023: Train Epoch: 9 [  0  /57094 (0 %)]	Loss: 182.998291 | Elapsed: 0.13s
01/28/2023 12:23:48 PM  [*] Sat Jan 28 12:23:48 2023: Train Epoch: 9 [6400 /57094 (11%)]	Loss: 197.076630 | Elapsed: 12.26s
01/28/2023 12:24:01 PM  [*] Sat Jan 28 12:24:01 2023: Train Epoch: 9 [12800/57094 (22%)]	Loss: 179.208694 | Elapsed: 12.22s
01/28/2023 12:24:13 PM  [*] Sat Jan 28 12:24:13 2023: Train Epoch: 9 [19200/57094 (34%)]	Loss: 165.316772 | Elapsed: 12.40s
01/28/2023 12:24:25 PM  [*] Sat Jan 28 12:24:25 2023: Train Epoch: 9 [25600/57094 (45%)]	Loss: 179.629227 | Elapsed: 12.21s
01/28/2023 12:24:37 PM  [*] Sat Jan 28 12:24:37 2023: Train Epoch: 9 [32000/57094 (56%)]	Loss: 165.972290 | Elapsed: 12.23s
01/28/2023 12:24:50 PM  [*] Sat Jan 28 12:24:50 2023: Train Epoch: 9 [38400/57094 (67%)]	Loss: 172.987915 | Elapsed: 12.25s
01/28/2023 12:25:02 PM  [*] Sat Jan 28 12:25:02 2023: Train Epoch: 9 [44800/57094 (78%)]	Loss: 171.631958 | Elapsed: 12.21s
01/28/2023 12:25:14 PM  [*] Sat Jan 28 12:25:14 2023: Train Epoch: 9 [51200/57094 (90%)]	Loss: 191.210907 | Elapsed: 12.29s
01/28/2023 12:25:27 PM  [*] Sat Jan 28 12:25:27 2023:    9    | Tr.loss: 179.527891 | Elapsed:  110.86  s
01/28/2023 12:25:27 PM  [*] Started epoch: 10
01/28/2023 12:25:27 PM  [*] Sat Jan 28 12:25:27 2023: Train Epoch: 10 [  0  /57094 (0 %)]	Loss: 185.113922 | Elapsed: 0.12s
01/28/2023 12:25:39 PM  [*] Sat Jan 28 12:25:39 2023: Train Epoch: 10 [6400 /57094 (11%)]	Loss: 165.704025 | Elapsed: 12.34s
01/28/2023 12:25:51 PM  [*] Sat Jan 28 12:25:51 2023: Train Epoch: 10 [12800/57094 (22%)]	Loss: 165.693451 | Elapsed: 12.27s
01/28/2023 12:26:04 PM  [*] Sat Jan 28 12:26:04 2023: Train Epoch: 10 [19200/57094 (34%)]	Loss: 181.310532 | Elapsed: 12.21s
01/28/2023 12:26:16 PM  [*] Sat Jan 28 12:26:16 2023: Train Epoch: 10 [25600/57094 (45%)]	Loss: 167.471832 | Elapsed: 12.28s
01/28/2023 12:26:28 PM  [*] Sat Jan 28 12:26:28 2023: Train Epoch: 10 [32000/57094 (56%)]	Loss: 175.596832 | Elapsed: 12.27s
01/28/2023 12:26:41 PM  [*] Sat Jan 28 12:26:41 2023: Train Epoch: 10 [38400/57094 (67%)]	Loss: 180.296844 | Elapsed: 12.32s
01/28/2023 12:26:53 PM  [*] Sat Jan 28 12:26:53 2023: Train Epoch: 10 [44800/57094 (78%)]	Loss: 165.985596 | Elapsed: 12.24s
01/28/2023 12:27:06 PM  [*] Sat Jan 28 12:27:06 2023: Train Epoch: 10 [51200/57094 (90%)]	Loss: 183.682831 | Elapsed: 13.41s
01/28/2023 12:27:19 PM  [*] Sat Jan 28 12:27:19 2023:   10    | Tr.loss: 179.357013 | Elapsed:  112.60  s
01/28/2023 12:27:20 PM [!] Sat Jan 28 12:27:20 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\preTraining\training_files\1674905239-model.torch
		train time: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\preTraining\training_files\1674905239-trainTime.npy
		train losses: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\preTraining\training_files\1674905239-trainLosses.npy
		train AUC: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\preTraining\training_files\1674905239-auc.npy
01/28/2023 12:27:21 PM  [!] Training pretrained model on downstream task...
01/28/2023 12:27:21 PM  [*] Started epoch: 1
01/28/2023 12:27:21 PM  [*] Sat Jan 28 12:27:21 2023: Train Epoch: 1 [  0  /19032 (0 %)]	Loss: 3.921295 | Elapsed: 0.35s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 12:27:30 PM  [*] Sat Jan 28 12:27:30 2023: Train Epoch: 1 [6400 /19032 (34%)]	Loss: 0.436540 | Elapsed: 9.18s | FPR 0.0003 -> TPR 0.2464 & F1 0.3953
01/28/2023 12:27:40 PM  [*] Sat Jan 28 12:27:40 2023: Train Epoch: 1 [12800/19032 (67%)]	Loss: 0.452691 | Elapsed: 9.16s | FPR 0.0003 -> TPR 0.1667 & F1 0.2857
01/28/2023 12:27:49 PM  [*] Sat Jan 28 12:27:49 2023:    1    | Tr.loss: 0.580739 | Elapsed:   28.03  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7870
01/28/2023 12:27:49 PM  [*] Started epoch: 2
01/28/2023 12:27:49 PM  [*] Sat Jan 28 12:27:49 2023: Train Epoch: 2 [  0  /19032 (0 %)]	Loss: 0.277510 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.5000 & F1 0.6667
01/28/2023 12:27:58 PM  [*] Sat Jan 28 12:27:58 2023: Train Epoch: 2 [6400 /19032 (34%)]	Loss: 0.372526 | Elapsed: 9.16s | FPR 0.0003 -> TPR 0.3175 & F1 0.4819
01/28/2023 12:28:07 PM  [*] Sat Jan 28 12:28:07 2023: Train Epoch: 2 [12800/19032 (67%)]	Loss: 0.281330 | Elapsed: 9.17s | FPR 0.0003 -> TPR 0.6429 & F1 0.7826
01/28/2023 12:28:17 PM  [*] Sat Jan 28 12:28:17 2023:    2    | Tr.loss: 0.345463 | Elapsed:   27.76  s | FPR 0.0003 -> TPR: 0.07 & F1: 0.14 | AUC: 0.9094
01/28/2023 12:28:17 PM  [*] Started epoch: 3
01/28/2023 12:28:17 PM  [*] Sat Jan 28 12:28:17 2023: Train Epoch: 3 [  0  /19032 (0 %)]	Loss: 0.247500 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.8298 & F1 0.9070
01/28/2023 12:28:26 PM  [*] Sat Jan 28 12:28:26 2023: Train Epoch: 3 [6400 /19032 (34%)]	Loss: 0.281957 | Elapsed: 9.18s | FPR 0.0003 -> TPR 0.8333 & F1 0.9091
01/28/2023 12:28:35 PM  [*] Sat Jan 28 12:28:35 2023: Train Epoch: 3 [12800/19032 (67%)]	Loss: 0.139691 | Elapsed: 9.16s | FPR 0.0003 -> TPR 0.8281 & F1 0.9060
01/28/2023 12:28:44 PM  [*] Sat Jan 28 12:28:44 2023:    3    | Tr.loss: 0.245594 | Elapsed:   27.74  s | FPR 0.0003 -> TPR: 0.17 & F1: 0.29 | AUC: 0.9566
01/28/2023 12:28:45 PM [!] Sat Jan 28 12:28:45 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_pretrained\training_files\1674905324-model.torch
		train time: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_pretrained\training_files\1674905324-trainTime.npy
		train losses: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_pretrained\training_files\1674905324-trainLosses.npy
		train AUC: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_pretrained\training_files\1674905324-auc.npy
		train F1s : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_pretrained\training_files\1674905324-trainF1s.npy
		train TPRs: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_pretrained\training_files\1674905324-trainTPRs.npy
01/28/2023 12:28:45 PM  [!] Training non_pretrained model on downstream task...
01/28/2023 12:28:45 PM  [*] Started epoch: 1
01/28/2023 12:28:45 PM  [*] Sat Jan 28 12:28:45 2023: Train Epoch: 1 [  0  /19032 (0 %)]	Loss: 1.467192 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0256 & F1 0.0500
01/28/2023 12:28:52 PM  [*] Sat Jan 28 12:28:52 2023: Train Epoch: 1 [6400 /19032 (34%)]	Loss: 0.590549 | Elapsed: 6.28s | FPR 0.0003 -> TPR 0.3333 & F1 0.5000
01/28/2023 12:28:58 PM  [*] Sat Jan 28 12:28:58 2023: Train Epoch: 1 [12800/19032 (67%)]	Loss: 0.294993 | Elapsed: 6.26s | FPR 0.0003 -> TPR 0.1940 & F1 0.3250
01/28/2023 12:29:04 PM  [*] Sat Jan 28 12:29:04 2023:    1    | Tr.loss: 0.452233 | Elapsed:   19.19  s | FPR 0.0003 -> TPR: 0.01 & F1: 0.02 | AUC: 0.8365
01/28/2023 12:29:04 PM  [*] Started epoch: 2
01/28/2023 12:29:05 PM  [*] Sat Jan 28 12:29:05 2023: Train Epoch: 2 [  0  /19032 (0 %)]	Loss: 0.378257 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.5556 & F1 0.7143
01/28/2023 12:29:11 PM  [*] Sat Jan 28 12:29:11 2023: Train Epoch: 2 [6400 /19032 (34%)]	Loss: 0.413631 | Elapsed: 6.30s | FPR 0.0003 -> TPR 0.5312 & F1 0.6939
01/28/2023 12:29:17 PM  [*] Sat Jan 28 12:29:17 2023: Train Epoch: 2 [12800/19032 (67%)]	Loss: 0.300310 | Elapsed: 6.28s | FPR 0.0003 -> TPR 0.3158 & F1 0.4800
01/28/2023 12:29:24 PM  [*] Sat Jan 28 12:29:24 2023:    2    | Tr.loss: 0.279980 | Elapsed:   19.20  s | FPR 0.0003 -> TPR: 0.25 & F1: 0.40 | AUC: 0.9416
01/28/2023 12:29:24 PM  [*] Started epoch: 3
01/28/2023 12:29:24 PM  [*] Sat Jan 28 12:29:24 2023: Train Epoch: 3 [  0  /19032 (0 %)]	Loss: 0.284141 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.6000 & F1 0.7500
01/28/2023 12:29:30 PM  [*] Sat Jan 28 12:29:30 2023: Train Epoch: 3 [6400 /19032 (34%)]	Loss: 0.190615 | Elapsed: 6.30s | FPR 0.0003 -> TPR 0.8000 & F1 0.8889
01/28/2023 12:29:36 PM  [*] Sat Jan 28 12:29:36 2023: Train Epoch: 3 [12800/19032 (67%)]	Loss: 0.296180 | Elapsed: 6.35s | FPR 0.0003 -> TPR 0.6714 & F1 0.8034
01/28/2023 12:29:43 PM  [*] Sat Jan 28 12:29:43 2023:    3    | Tr.loss: 0.207382 | Elapsed:   19.33  s | FPR 0.0003 -> TPR: 0.27 & F1: 0.42 | AUC: 0.9694
01/28/2023 12:29:43 PM [!] Sat Jan 28 12:29:43 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_non_pretrained\training_files\1674905383-model.torch
		train time: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_non_pretrained\training_files\1674905383-trainTime.npy
		train losses: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_non_pretrained\training_files\1674905383-trainLosses.npy
		train AUC: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_non_pretrained\training_files\1674905383-auc.npy
		train F1s : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_non_pretrained\training_files\1674905383-trainF1s.npy
		train TPRs: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_non_pretrained\training_files\1674905383-trainTPRs.npy
01/28/2023 12:29:43 PM  [!] Training full_data model on downstream task...
01/28/2023 12:29:44 PM  [*] Started epoch: 1
01/28/2023 12:29:44 PM  [*] Sat Jan 28 12:29:44 2023: Train Epoch: 1 [  0  /76126 (0 %)]	Loss: 3.629414 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 12:29:50 PM  [*] Sat Jan 28 12:29:50 2023: Train Epoch: 1 [6400 /76126 (8 %)]	Loss: 0.480572 | Elapsed: 6.30s | FPR 0.0003 -> TPR 0.4483 & F1 0.6190
01/28/2023 12:29:57 PM  [*] Sat Jan 28 12:29:57 2023: Train Epoch: 1 [12800/76126 (17%)]	Loss: 0.537402 | Elapsed: 6.30s | FPR 0.0003 -> TPR 0.3056 & F1 0.4681
01/28/2023 12:30:03 PM  [*] Sat Jan 28 12:30:03 2023: Train Epoch: 1 [19200/76126 (25%)]	Loss: 0.323060 | Elapsed: 6.29s | FPR 0.0003 -> TPR 0.4091 & F1 0.5806
01/28/2023 12:30:09 PM  [*] Sat Jan 28 12:30:09 2023: Train Epoch: 1 [25600/76126 (34%)]	Loss: 0.316081 | Elapsed: 6.29s | FPR 0.0003 -> TPR 0.6452 & F1 0.7843
01/28/2023 12:30:16 PM  [*] Sat Jan 28 12:30:16 2023: Train Epoch: 1 [32000/76126 (42%)]	Loss: 0.244386 | Elapsed: 6.28s | FPR 0.0003 -> TPR 0.5857 & F1 0.7387
01/28/2023 12:30:22 PM  [*] Sat Jan 28 12:30:22 2023: Train Epoch: 1 [38400/76126 (50%)]	Loss: 0.252179 | Elapsed: 6.31s | FPR 0.0003 -> TPR 0.7385 & F1 0.8496
01/28/2023 12:30:28 PM  [*] Sat Jan 28 12:30:28 2023: Train Epoch: 1 [44800/76126 (59%)]	Loss: 0.147773 | Elapsed: 6.27s | FPR 0.0003 -> TPR 0.8889 & F1 0.9412
01/28/2023 12:30:34 PM  [*] Sat Jan 28 12:30:34 2023: Train Epoch: 1 [51200/76126 (67%)]	Loss: 0.259148 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.7000 & F1 0.8235
01/28/2023 12:30:41 PM  [*] Sat Jan 28 12:30:41 2023: Train Epoch: 1 [57600/76126 (76%)]	Loss: 0.117260 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.8382 & F1 0.9120
01/28/2023 12:30:47 PM [!] Learning rate: 2.5e-05
01/28/2023 12:30:47 PM  [*] Sat Jan 28 12:30:47 2023: Train Epoch: 1 [64000/76126 (84%)]	Loss: 0.096545 | Elapsed: 6.34s | FPR 0.0003 -> TPR 0.8594 & F1 0.9244
01/28/2023 12:30:53 PM  [*] Sat Jan 28 12:30:53 2023: Train Epoch: 1 [70400/76126 (92%)]	Loss: 0.133729 | Elapsed: 6.26s | FPR 0.0003 -> TPR 0.8696 & F1 0.9302
01/28/2023 12:31:01 PM  [*] Sat Jan 28 12:31:01 2023:    1    | Tr.loss: 0.300014 | Elapsed:   76.70  s | FPR 0.0003 -> TPR: 0.01 & F1: 0.02 | AUC: 0.9345
01/28/2023 12:31:01 PM  [*] Started epoch: 2
01/28/2023 12:31:01 PM  [*] Sat Jan 28 12:31:01 2023: Train Epoch: 2 [  0  /76126 (0 %)]	Loss: 0.159672 | Elapsed: 0.11s | FPR 0.0003 -> TPR 0.7442 & F1 0.8533
01/28/2023 12:31:07 PM  [*] Sat Jan 28 12:31:07 2023: Train Epoch: 2 [6400 /76126 (8 %)]	Loss: 0.242194 | Elapsed: 6.27s | FPR 0.0003 -> TPR 0.5614 & F1 0.7191
01/28/2023 12:31:13 PM  [*] Sat Jan 28 12:31:13 2023: Train Epoch: 2 [12800/76126 (17%)]	Loss: 0.164831 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.8906 & F1 0.9421
01/28/2023 12:31:20 PM  [*] Sat Jan 28 12:31:20 2023: Train Epoch: 2 [19200/76126 (25%)]	Loss: 0.167425 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.8333 & F1 0.9091
01/28/2023 12:31:26 PM  [*] Sat Jan 28 12:31:26 2023: Train Epoch: 2 [25600/76126 (34%)]	Loss: 0.088926 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.9242 & F1 0.9606
01/28/2023 12:31:32 PM  [*] Sat Jan 28 12:31:32 2023: Train Epoch: 2 [32000/76126 (42%)]	Loss: 0.163629 | Elapsed: 6.28s | FPR 0.0003 -> TPR 0.2923 & F1 0.4524
01/28/2023 12:31:38 PM  [*] Sat Jan 28 12:31:38 2023: Train Epoch: 2 [38400/76126 (50%)]	Loss: 0.163938 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.7778 & F1 0.8750
01/28/2023 12:31:45 PM  [*] Sat Jan 28 12:31:45 2023: Train Epoch: 2 [44800/76126 (59%)]	Loss: 0.133349 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.8769 & F1 0.9344
01/28/2023 12:31:51 PM  [*] Sat Jan 28 12:31:51 2023: Train Epoch: 2 [51200/76126 (67%)]	Loss: 0.101127 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.9429 & F1 0.9706
01/28/2023 12:31:51 PM [!] Learning rate: 2.5e-06
01/28/2023 12:31:57 PM  [*] Sat Jan 28 12:31:57 2023: Train Epoch: 2 [57600/76126 (76%)]	Loss: 0.136525 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.7231 & F1 0.8393
01/28/2023 12:32:03 PM  [*] Sat Jan 28 12:32:03 2023: Train Epoch: 2 [64000/76126 (84%)]	Loss: 0.088872 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.7571 & F1 0.8618
01/28/2023 12:32:10 PM  [*] Sat Jan 28 12:32:10 2023: Train Epoch: 2 [70400/76126 (92%)]	Loss: 0.147187 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.7778 & F1 0.8750
01/28/2023 12:32:17 PM  [*] Sat Jan 28 12:32:17 2023:    2    | Tr.loss: 0.164945 | Elapsed:   76.35  s | FPR 0.0003 -> TPR: 0.47 & F1: 0.64 | AUC: 0.9812
01/28/2023 12:32:17 PM  [*] Started epoch: 3
01/28/2023 12:32:17 PM  [*] Sat Jan 28 12:32:17 2023: Train Epoch: 3 [  0  /76126 (0 %)]	Loss: 0.180970 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.9375 & F1 0.9677
01/28/2023 12:32:23 PM  [*] Sat Jan 28 12:32:23 2023: Train Epoch: 3 [6400 /76126 (8 %)]	Loss: 0.171813 | Elapsed: 6.28s | FPR 0.0003 -> TPR 0.7647 & F1 0.8667
01/28/2023 12:32:30 PM  [*] Sat Jan 28 12:32:30 2023: Train Epoch: 3 [12800/76126 (17%)]	Loss: 0.143194 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.8689 & F1 0.9298
01/28/2023 12:32:36 PM  [*] Sat Jan 28 12:32:36 2023: Train Epoch: 3 [19200/76126 (25%)]	Loss: 0.104833 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.9577 & F1 0.9784
01/28/2023 12:32:42 PM  [*] Sat Jan 28 12:32:42 2023: Train Epoch: 3 [25600/76126 (34%)]	Loss: 0.099067 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.6269 & F1 0.7706
01/28/2023 12:32:48 PM  [*] Sat Jan 28 12:32:48 2023: Train Epoch: 3 [32000/76126 (42%)]	Loss: 0.092341 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.6119 & F1 0.7593
01/28/2023 12:32:55 PM  [*] Sat Jan 28 12:32:55 2023: Train Epoch: 3 [38400/76126 (50%)]	Loss: 0.171951 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.8387 & F1 0.9123
01/28/2023 12:32:56 PM [!] Learning rate: 2.5000000000000004e-07
01/28/2023 12:33:01 PM  [*] Sat Jan 28 12:33:01 2023: Train Epoch: 3 [44800/76126 (59%)]	Loss: 0.124623 | Elapsed: 6.27s | FPR 0.0003 -> TPR 0.9310 & F1 0.9643
01/28/2023 12:33:07 PM  [*] Sat Jan 28 12:33:07 2023: Train Epoch: 3 [51200/76126 (67%)]	Loss: 0.266995 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.7162 & F1 0.8346
01/28/2023 12:33:13 PM  [*] Sat Jan 28 12:33:13 2023: Train Epoch: 3 [57600/76126 (76%)]	Loss: 0.225824 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.8143 & F1 0.8976
01/28/2023 12:33:20 PM  [*] Sat Jan 28 12:33:20 2023: Train Epoch: 3 [64000/76126 (84%)]	Loss: 0.163652 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.9067 & F1 0.9510
01/28/2023 12:33:26 PM  [*] Sat Jan 28 12:33:26 2023: Train Epoch: 3 [70400/76126 (92%)]	Loss: 0.153596 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.8548 & F1 0.9217
01/28/2023 12:33:33 PM  [*] Sat Jan 28 12:33:33 2023:    3    | Tr.loss: 0.157919 | Elapsed:   76.29  s | FPR 0.0003 -> TPR: 0.45 & F1: 0.62 | AUC: 0.9827
01/28/2023 12:33:34 PM [!] Sat Jan 28 12:33:34 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_full_data\training_files\1674905613-model.torch
		train time: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_full_data\training_files\1674905613-trainTime.npy
		train losses: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_full_data\training_files\1674905613-trainLosses.npy
		train AUC: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_full_data\training_files\1674905613-auc.npy
		train F1s : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_full_data\training_files\1674905613-trainF1s.npy
		train TPRs: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_full_data\training_files\1674905613-trainTPRs.npy
01/28/2023 12:33:34 PM  [*] Evaluating pretrained model on test set...
01/28/2023 12:33:39 PM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0145 | F1: 0.0285
01/28/2023 12:33:39 PM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.0715 | F1: 0.1334
01/28/2023 12:33:39 PM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.2943 | F1: 0.4544
01/28/2023 12:33:39 PM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3766 | F1: 0.5461
01/28/2023 12:33:39 PM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.4141 | F1: 0.5822
01/28/2023 12:33:39 PM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4920 | F1: 0.6484
01/28/2023 12:33:39 PM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.7030 | F1: 0.7863
01/28/2023 12:33:39 PM  [*] Evaluating non_pretrained model on test set...
01/28/2023 12:33:44 PM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0552 | F1: 0.1046
01/28/2023 12:33:44 PM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1928 | F1: 0.3232
01/28/2023 12:33:44 PM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.2802 | F1: 0.4375
01/28/2023 12:33:44 PM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3120 | F1: 0.4747
01/28/2023 12:33:44 PM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3810 | F1: 0.5484
01/28/2023 12:33:44 PM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.5030 | F1: 0.6582
01/28/2023 12:33:44 PM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.6987 | F1: 0.7834
01/28/2023 12:33:44 PM  [*] Evaluating full_data model on test set...
01/28/2023 12:33:49 PM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0620 | F1: 0.1168
01/28/2023 12:33:49 PM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.2669 | F1: 0.4213
01/28/2023 12:33:49 PM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.3399 | F1: 0.5070
01/28/2023 12:33:49 PM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.4007 | F1: 0.5711
01/28/2023 12:33:49 PM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.4806 | F1: 0.6455
01/28/2023 12:33:49 PM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.5853 | F1: 0.7267
01/28/2023 12:33:49 PM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.8059 | F1: 0.8524
01/28/2023 12:33:49 PM  [!] Running pre-training split 2/3
01/28/2023 12:33:52 PM  [!] Pre-training model...
01/28/2023 12:33:52 PM  [*] Masking sequences...
01/28/2023 12:34:12 PM  [*] Started epoch: 1
01/28/2023 12:34:12 PM  [*] Sat Jan 28 12:34:12 2023: Train Epoch: 1 [  0  /57094 (0 %)]	Loss: 406.298767 | Elapsed: 0.42s
01/28/2023 12:34:25 PM  [*] Sat Jan 28 12:34:25 2023: Train Epoch: 1 [6400 /57094 (11%)]	Loss: 216.414520 | Elapsed: 12.42s
01/28/2023 12:34:37 PM  [*] Sat Jan 28 12:34:37 2023: Train Epoch: 1 [12800/57094 (22%)]	Loss: 206.720520 | Elapsed: 12.49s
01/28/2023 12:34:50 PM  [*] Sat Jan 28 12:34:50 2023: Train Epoch: 1 [19200/57094 (34%)]	Loss: 199.904663 | Elapsed: 12.51s
01/28/2023 12:35:02 PM  [*] Sat Jan 28 12:35:02 2023: Train Epoch: 1 [25600/57094 (45%)]	Loss: 194.705322 | Elapsed: 12.55s
01/28/2023 12:35:15 PM  [*] Sat Jan 28 12:35:15 2023: Train Epoch: 1 [32000/57094 (56%)]	Loss: 210.669464 | Elapsed: 12.56s
01/28/2023 12:35:27 PM  [*] Sat Jan 28 12:35:27 2023: Train Epoch: 1 [38400/57094 (67%)]	Loss: 226.335556 | Elapsed: 12.44s
01/28/2023 12:35:40 PM  [*] Sat Jan 28 12:35:40 2023: Train Epoch: 1 [44800/57094 (78%)]	Loss: 186.519348 | Elapsed: 12.41s
01/28/2023 12:35:52 PM  [*] Sat Jan 28 12:35:52 2023: Train Epoch: 1 [51200/57094 (90%)]	Loss: 204.320435 | Elapsed: 12.41s
01/28/2023 12:36:05 PM  [*] Sat Jan 28 12:36:05 2023:    1    | Tr.loss: 210.912386 | Elapsed:  113.15  s
01/28/2023 12:36:05 PM  [*] Started epoch: 2
01/28/2023 12:36:05 PM  [*] Sat Jan 28 12:36:05 2023: Train Epoch: 2 [  0  /57094 (0 %)]	Loss: 197.445862 | Elapsed: 0.15s
01/28/2023 12:36:18 PM  [*] Sat Jan 28 12:36:18 2023: Train Epoch: 2 [6400 /57094 (11%)]	Loss: 189.630768 | Elapsed: 12.59s
01/28/2023 12:36:30 PM  [*] Sat Jan 28 12:36:30 2023: Train Epoch: 2 [12800/57094 (22%)]	Loss: 181.014297 | Elapsed: 12.48s
01/28/2023 12:36:43 PM  [*] Sat Jan 28 12:36:43 2023: Train Epoch: 2 [19200/57094 (34%)]	Loss: 172.449615 | Elapsed: 12.68s
01/28/2023 12:36:55 PM  [*] Sat Jan 28 12:36:55 2023: Train Epoch: 2 [25600/57094 (45%)]	Loss: 216.752991 | Elapsed: 12.61s
01/28/2023 12:37:08 PM  [*] Sat Jan 28 12:37:08 2023: Train Epoch: 2 [32000/57094 (56%)]	Loss: 200.048340 | Elapsed: 12.54s
01/28/2023 12:37:20 PM  [*] Sat Jan 28 12:37:20 2023: Train Epoch: 2 [38400/57094 (67%)]	Loss: 188.437012 | Elapsed: 12.50s
01/28/2023 12:37:33 PM  [*] Sat Jan 28 12:37:33 2023: Train Epoch: 2 [44800/57094 (78%)]	Loss: 185.667755 | Elapsed: 12.58s
01/28/2023 12:37:46 PM  [*] Sat Jan 28 12:37:46 2023: Train Epoch: 2 [51200/57094 (90%)]	Loss: 184.085846 | Elapsed: 12.53s
01/28/2023 12:37:59 PM  [*] Sat Jan 28 12:37:59 2023:    2    | Tr.loss: 191.392191 | Elapsed:  113.68  s
01/28/2023 12:37:59 PM  [*] Started epoch: 3
01/28/2023 12:37:59 PM  [*] Sat Jan 28 12:37:59 2023: Train Epoch: 3 [  0  /57094 (0 %)]	Loss: 205.268250 | Elapsed: 0.13s
01/28/2023 12:38:11 PM  [*] Sat Jan 28 12:38:11 2023: Train Epoch: 3 [6400 /57094 (11%)]	Loss: 167.633377 | Elapsed: 12.63s
01/28/2023 12:38:24 PM  [*] Sat Jan 28 12:38:24 2023: Train Epoch: 3 [12800/57094 (22%)]	Loss: 203.635132 | Elapsed: 12.59s
01/28/2023 12:38:36 PM  [*] Sat Jan 28 12:38:36 2023: Train Epoch: 3 [19200/57094 (34%)]	Loss: 195.998245 | Elapsed: 12.53s
01/28/2023 12:38:49 PM  [*] Sat Jan 28 12:38:49 2023: Train Epoch: 3 [25600/57094 (45%)]	Loss: 200.823898 | Elapsed: 12.52s
01/28/2023 12:39:02 PM  [*] Sat Jan 28 12:39:02 2023: Train Epoch: 3 [32000/57094 (56%)]	Loss: 198.743011 | Elapsed: 12.60s
01/28/2023 12:39:14 PM  [*] Sat Jan 28 12:39:14 2023: Train Epoch: 3 [38400/57094 (67%)]	Loss: 172.188629 | Elapsed: 12.58s
01/28/2023 12:39:27 PM  [*] Sat Jan 28 12:39:27 2023: Train Epoch: 3 [44800/57094 (78%)]	Loss: 189.607727 | Elapsed: 12.45s
01/28/2023 12:39:39 PM  [*] Sat Jan 28 12:39:39 2023: Train Epoch: 3 [51200/57094 (90%)]	Loss: 165.738846 | Elapsed: 12.52s
01/28/2023 12:39:52 PM  [*] Sat Jan 28 12:39:52 2023:    3    | Tr.loss: 185.616054 | Elapsed:  113.40  s
01/28/2023 12:39:52 PM  [*] Started epoch: 4
01/28/2023 12:39:52 PM  [*] Sat Jan 28 12:39:52 2023: Train Epoch: 4 [  0  /57094 (0 %)]	Loss: 176.011475 | Elapsed: 0.13s
01/28/2023 12:40:05 PM  [*] Sat Jan 28 12:40:05 2023: Train Epoch: 4 [6400 /57094 (11%)]	Loss: 166.323761 | Elapsed: 12.49s
01/28/2023 12:40:17 PM  [*] Sat Jan 28 12:40:17 2023: Train Epoch: 4 [12800/57094 (22%)]	Loss: 162.371506 | Elapsed: 12.49s
01/28/2023 12:40:29 PM  [*] Sat Jan 28 12:40:29 2023: Train Epoch: 4 [19200/57094 (34%)]	Loss: 178.132385 | Elapsed: 12.42s
01/28/2023 12:40:42 PM  [*] Sat Jan 28 12:40:42 2023: Train Epoch: 4 [25600/57094 (45%)]	Loss: 187.259888 | Elapsed: 12.47s
01/28/2023 12:40:54 PM  [*] Sat Jan 28 12:40:54 2023: Train Epoch: 4 [32000/57094 (56%)]	Loss: 186.919769 | Elapsed: 12.46s
01/28/2023 12:41:07 PM  [*] Sat Jan 28 12:41:07 2023: Train Epoch: 4 [38400/57094 (67%)]	Loss: 194.973328 | Elapsed: 12.42s
01/28/2023 12:41:19 PM  [*] Sat Jan 28 12:41:19 2023: Train Epoch: 4 [44800/57094 (78%)]	Loss: 190.075714 | Elapsed: 12.44s
01/28/2023 12:41:32 PM  [*] Sat Jan 28 12:41:32 2023: Train Epoch: 4 [51200/57094 (90%)]	Loss: 193.873871 | Elapsed: 12.56s
01/28/2023 12:41:45 PM  [*] Sat Jan 28 12:41:45 2023:    4    | Tr.loss: 182.637248 | Elapsed:  112.83  s
01/28/2023 12:41:45 PM  [*] Started epoch: 5
01/28/2023 12:41:45 PM  [*] Sat Jan 28 12:41:45 2023: Train Epoch: 5 [  0  /57094 (0 %)]	Loss: 191.645782 | Elapsed: 0.12s
01/28/2023 12:41:57 PM  [*] Sat Jan 28 12:41:57 2023: Train Epoch: 5 [6400 /57094 (11%)]	Loss: 188.225586 | Elapsed: 12.62s
01/28/2023 12:42:10 PM  [*] Sat Jan 28 12:42:10 2023: Train Epoch: 5 [12800/57094 (22%)]	Loss: 199.544769 | Elapsed: 12.61s
01/28/2023 12:42:23 PM  [*] Sat Jan 28 12:42:23 2023: Train Epoch: 5 [19200/57094 (34%)]	Loss: 183.176376 | Elapsed: 12.56s
01/28/2023 12:42:35 PM  [*] Sat Jan 28 12:42:35 2023: Train Epoch: 5 [25600/57094 (45%)]	Loss: 168.464508 | Elapsed: 12.58s
01/28/2023 12:42:48 PM  [*] Sat Jan 28 12:42:48 2023: Train Epoch: 5 [32000/57094 (56%)]	Loss: 184.815216 | Elapsed: 12.57s
01/28/2023 12:43:00 PM  [*] Sat Jan 28 12:43:00 2023: Train Epoch: 5 [38400/57094 (67%)]	Loss: 184.612045 | Elapsed: 12.45s
01/28/2023 12:43:13 PM  [*] Sat Jan 28 12:43:13 2023: Train Epoch: 5 [44800/57094 (78%)]	Loss: 190.763123 | Elapsed: 12.51s
01/28/2023 12:43:25 PM  [*] Sat Jan 28 12:43:25 2023: Train Epoch: 5 [51200/57094 (90%)]	Loss: 172.571960 | Elapsed: 12.48s
01/28/2023 12:43:38 PM  [*] Sat Jan 28 12:43:38 2023:    5    | Tr.loss: 180.926216 | Elapsed:  113.31  s
01/28/2023 12:43:38 PM  [*] Started epoch: 6
01/28/2023 12:43:38 PM  [*] Sat Jan 28 12:43:38 2023: Train Epoch: 6 [  0  /57094 (0 %)]	Loss: 185.063492 | Elapsed: 0.14s
01/28/2023 12:43:51 PM  [*] Sat Jan 28 12:43:51 2023: Train Epoch: 6 [6400 /57094 (11%)]	Loss: 173.931763 | Elapsed: 12.49s
01/28/2023 12:44:03 PM  [*] Sat Jan 28 12:44:03 2023: Train Epoch: 6 [12800/57094 (22%)]	Loss: 153.549316 | Elapsed: 12.42s
01/28/2023 12:44:16 PM  [*] Sat Jan 28 12:44:16 2023: Train Epoch: 6 [19200/57094 (34%)]	Loss: 180.041016 | Elapsed: 12.44s
01/28/2023 12:44:28 PM  [*] Sat Jan 28 12:44:28 2023: Train Epoch: 6 [25600/57094 (45%)]	Loss: 169.491348 | Elapsed: 12.50s
01/28/2023 12:44:40 PM  [*] Sat Jan 28 12:44:40 2023: Train Epoch: 6 [32000/57094 (56%)]	Loss: 181.406723 | Elapsed: 12.43s
01/28/2023 12:44:45 PM [!] Learning rate: 2.5e-05
01/28/2023 12:44:53 PM  [*] Sat Jan 28 12:44:53 2023: Train Epoch: 6 [38400/57094 (67%)]	Loss: 191.021500 | Elapsed: 12.42s
01/28/2023 12:45:05 PM  [*] Sat Jan 28 12:45:05 2023: Train Epoch: 6 [44800/57094 (78%)]	Loss: 161.064590 | Elapsed: 12.41s
01/28/2023 12:45:18 PM  [*] Sat Jan 28 12:45:18 2023: Train Epoch: 6 [51200/57094 (90%)]	Loss: 167.476776 | Elapsed: 12.47s
01/28/2023 12:45:31 PM  [*] Sat Jan 28 12:45:31 2023:    6    | Tr.loss: 179.400447 | Elapsed:  112.65  s
01/28/2023 12:45:31 PM  [*] Started epoch: 7
01/28/2023 12:45:31 PM  [*] Sat Jan 28 12:45:31 2023: Train Epoch: 7 [  0  /57094 (0 %)]	Loss: 180.226151 | Elapsed: 0.14s
01/28/2023 12:45:43 PM  [*] Sat Jan 28 12:45:43 2023: Train Epoch: 7 [6400 /57094 (11%)]	Loss: 180.884811 | Elapsed: 12.56s
01/28/2023 12:45:56 PM  [*] Sat Jan 28 12:45:56 2023: Train Epoch: 7 [12800/57094 (22%)]	Loss: 182.751205 | Elapsed: 12.60s
01/28/2023 12:46:09 PM  [*] Sat Jan 28 12:46:09 2023: Train Epoch: 7 [19200/57094 (34%)]	Loss: 186.298584 | Elapsed: 12.53s
01/28/2023 12:46:21 PM  [*] Sat Jan 28 12:46:21 2023: Train Epoch: 7 [25600/57094 (45%)]	Loss: 169.627243 | Elapsed: 12.54s
01/28/2023 12:46:34 PM  [*] Sat Jan 28 12:46:34 2023: Train Epoch: 7 [32000/57094 (56%)]	Loss: 181.141571 | Elapsed: 12.55s
01/28/2023 12:46:46 PM  [*] Sat Jan 28 12:46:46 2023: Train Epoch: 7 [38400/57094 (67%)]	Loss: 178.587860 | Elapsed: 12.49s
01/28/2023 12:46:59 PM  [*] Sat Jan 28 12:46:59 2023: Train Epoch: 7 [44800/57094 (78%)]	Loss: 158.946869 | Elapsed: 12.56s
01/28/2023 12:47:11 PM  [*] Sat Jan 28 12:47:11 2023: Train Epoch: 7 [51200/57094 (90%)]	Loss: 174.978439 | Elapsed: 12.62s
01/28/2023 12:47:24 PM  [*] Sat Jan 28 12:47:24 2023:    7    | Tr.loss: 178.635407 | Elapsed:  113.56  s
01/28/2023 12:47:24 PM  [*] Started epoch: 8
01/28/2023 12:47:24 PM  [*] Sat Jan 28 12:47:24 2023: Train Epoch: 8 [  0  /57094 (0 %)]	Loss: 164.544922 | Elapsed: 0.15s
01/28/2023 12:47:37 PM  [*] Sat Jan 28 12:47:37 2023: Train Epoch: 8 [6400 /57094 (11%)]	Loss: 174.581421 | Elapsed: 12.48s
01/28/2023 12:47:49 PM  [*] Sat Jan 28 12:47:49 2023: Train Epoch: 8 [12800/57094 (22%)]	Loss: 155.196152 | Elapsed: 12.45s
01/28/2023 12:48:02 PM  [*] Sat Jan 28 12:48:02 2023: Train Epoch: 8 [19200/57094 (34%)]	Loss: 161.111511 | Elapsed: 12.46s
01/28/2023 12:48:14 PM  [*] Sat Jan 28 12:48:14 2023: Train Epoch: 8 [25600/57094 (45%)]	Loss: 184.190018 | Elapsed: 12.55s
01/28/2023 12:48:27 PM  [*] Sat Jan 28 12:48:27 2023: Train Epoch: 8 [32000/57094 (56%)]	Loss: 164.691864 | Elapsed: 12.44s
01/28/2023 12:48:39 PM  [*] Sat Jan 28 12:48:39 2023: Train Epoch: 8 [38400/57094 (67%)]	Loss: 179.999359 | Elapsed: 12.45s
01/28/2023 12:48:52 PM  [*] Sat Jan 28 12:48:52 2023: Train Epoch: 8 [44800/57094 (78%)]	Loss: 192.878540 | Elapsed: 12.51s
01/28/2023 12:49:04 PM  [*] Sat Jan 28 12:49:04 2023: Train Epoch: 8 [51200/57094 (90%)]	Loss: 195.721283 | Elapsed: 12.43s
01/28/2023 12:49:17 PM  [*] Sat Jan 28 12:49:17 2023:    8    | Tr.loss: 178.341253 | Elapsed:  112.88  s
01/28/2023 12:49:17 PM  [*] Started epoch: 9
01/28/2023 12:49:17 PM  [*] Sat Jan 28 12:49:17 2023: Train Epoch: 9 [  0  /57094 (0 %)]	Loss: 165.110916 | Elapsed: 0.13s
01/28/2023 12:49:30 PM  [*] Sat Jan 28 12:49:30 2023: Train Epoch: 9 [6400 /57094 (11%)]	Loss: 184.600159 | Elapsed: 12.48s
01/28/2023 12:49:42 PM  [*] Sat Jan 28 12:49:42 2023: Train Epoch: 9 [12800/57094 (22%)]	Loss: 184.961349 | Elapsed: 12.37s
01/28/2023 12:49:55 PM  [*] Sat Jan 28 12:49:55 2023: Train Epoch: 9 [19200/57094 (34%)]	Loss: 186.734497 | Elapsed: 12.53s
01/28/2023 12:50:07 PM  [*] Sat Jan 28 12:50:07 2023: Train Epoch: 9 [25600/57094 (45%)]	Loss: 200.275253 | Elapsed: 12.41s
01/28/2023 12:50:19 PM  [*] Sat Jan 28 12:50:19 2023: Train Epoch: 9 [32000/57094 (56%)]	Loss: 168.125977 | Elapsed: 12.39s
01/28/2023 12:50:32 PM  [*] Sat Jan 28 12:50:32 2023: Train Epoch: 9 [38400/57094 (67%)]	Loss: 184.544312 | Elapsed: 12.45s
01/28/2023 12:50:44 PM  [*] Sat Jan 28 12:50:44 2023: Train Epoch: 9 [44800/57094 (78%)]	Loss: 191.005234 | Elapsed: 12.38s
01/28/2023 12:50:57 PM  [*] Sat Jan 28 12:50:57 2023: Train Epoch: 9 [51200/57094 (90%)]	Loss: 191.335037 | Elapsed: 12.47s
01/28/2023 12:51:10 PM  [*] Sat Jan 28 12:51:10 2023:    9    | Tr.loss: 178.155806 | Elapsed:  112.60  s
01/28/2023 12:51:10 PM  [*] Started epoch: 10
01/28/2023 12:51:10 PM  [*] Sat Jan 28 12:51:10 2023: Train Epoch: 10 [  0  /57094 (0 %)]	Loss: 166.078766 | Elapsed: 0.14s
01/28/2023 12:51:22 PM  [*] Sat Jan 28 12:51:22 2023: Train Epoch: 10 [6400 /57094 (11%)]	Loss: 190.945663 | Elapsed: 12.58s
01/28/2023 12:51:35 PM  [*] Sat Jan 28 12:51:35 2023: Train Epoch: 10 [12800/57094 (22%)]	Loss: 180.954193 | Elapsed: 12.56s
01/28/2023 12:51:48 PM  [*] Sat Jan 28 12:51:48 2023: Train Epoch: 10 [19200/57094 (34%)]	Loss: 193.619537 | Elapsed: 12.59s
01/28/2023 12:52:01 PM  [*] Sat Jan 28 12:52:01 2023: Train Epoch: 10 [25600/57094 (45%)]	Loss: 162.808716 | Elapsed: 12.98s
01/28/2023 12:52:13 PM  [*] Sat Jan 28 12:52:13 2023: Train Epoch: 10 [32000/57094 (56%)]	Loss: 177.202606 | Elapsed: 12.59s
01/28/2023 12:52:26 PM  [*] Sat Jan 28 12:52:26 2023: Train Epoch: 10 [38400/57094 (67%)]	Loss: 172.148880 | Elapsed: 12.50s
01/28/2023 12:52:38 PM  [*] Sat Jan 28 12:52:38 2023: Train Epoch: 10 [44800/57094 (78%)]	Loss: 169.865952 | Elapsed: 12.62s
01/28/2023 12:52:51 PM  [*] Sat Jan 28 12:52:51 2023: Train Epoch: 10 [51200/57094 (90%)]	Loss: 185.564178 | Elapsed: 12.55s
01/28/2023 12:53:05 PM  [*] Sat Jan 28 12:53:05 2023:   10    | Tr.loss: 178.009110 | Elapsed:  114.75  s
01/28/2023 12:53:05 PM [!] Sat Jan 28 12:53:05 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\preTraining\training_files\1674906785-model.torch
		train time: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\preTraining\training_files\1674906785-trainTime.npy
		train losses: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\preTraining\training_files\1674906785-trainLosses.npy
		train AUC: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\preTraining\training_files\1674906785-auc.npy
01/28/2023 12:53:06 PM  [!] Training pretrained model on downstream task...
01/28/2023 12:53:06 PM  [*] Started epoch: 1
01/28/2023 12:53:06 PM  [*] Sat Jan 28 12:53:06 2023: Train Epoch: 1 [  0  /19032 (0 %)]	Loss: 1.290760 | Elapsed: 0.28s | FPR 0.0003 -> TPR 0.1111 & F1 0.2000
01/28/2023 12:53:16 PM  [*] Sat Jan 28 12:53:16 2023: Train Epoch: 1 [6400 /19032 (34%)]	Loss: 0.515092 | Elapsed: 9.29s | FPR 0.0003 -> TPR 0.2254 & F1 0.3678
01/28/2023 12:53:25 PM  [*] Sat Jan 28 12:53:25 2023: Train Epoch: 1 [12800/19032 (67%)]	Loss: 0.539883 | Elapsed: 9.20s | FPR 0.0003 -> TPR 0.2540 & F1 0.4051
01/28/2023 12:53:34 PM  [*] Sat Jan 28 12:53:34 2023:    1    | Tr.loss: 0.455166 | Elapsed:   28.09  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.01 | AUC: 0.8423
01/28/2023 12:53:34 PM  [*] Started epoch: 2
01/28/2023 12:53:34 PM  [*] Sat Jan 28 12:53:34 2023: Train Epoch: 2 [  0  /19032 (0 %)]	Loss: 0.307566 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.4186 & F1 0.5902
01/28/2023 12:53:43 PM  [*] Sat Jan 28 12:53:43 2023: Train Epoch: 2 [6400 /19032 (34%)]	Loss: 0.205892 | Elapsed: 9.14s | FPR 0.0003 -> TPR 0.7231 & F1 0.8393
01/28/2023 12:53:53 PM  [*] Sat Jan 28 12:53:53 2023: Train Epoch: 2 [12800/19032 (67%)]	Loss: 0.255215 | Elapsed: 9.15s | FPR 0.0003 -> TPR 0.7059 & F1 0.8276
01/28/2023 12:54:02 PM  [*] Sat Jan 28 12:54:02 2023:    2    | Tr.loss: 0.259275 | Elapsed:   27.89  s | FPR 0.0003 -> TPR: 0.35 & F1: 0.52 | AUC: 0.9513
01/28/2023 12:54:02 PM  [*] Started epoch: 3
01/28/2023 12:54:02 PM  [*] Sat Jan 28 12:54:02 2023: Train Epoch: 3 [  0  /19032 (0 %)]	Loss: 0.140441 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.8864 & F1 0.9398
01/28/2023 12:54:11 PM  [*] Sat Jan 28 12:54:11 2023: Train Epoch: 3 [6400 /19032 (34%)]	Loss: 0.219954 | Elapsed: 9.18s | FPR 0.0003 -> TPR 0.7258 & F1 0.8411
01/28/2023 12:54:21 PM  [*] Sat Jan 28 12:54:21 2023: Train Epoch: 3 [12800/19032 (67%)]	Loss: 0.129980 | Elapsed: 9.19s | FPR 0.0003 -> TPR 0.9315 & F1 0.9645
01/28/2023 12:54:30 PM  [*] Sat Jan 28 12:54:30 2023:    3    | Tr.loss: 0.171085 | Elapsed:   27.95  s | FPR 0.0003 -> TPR: 0.36 & F1: 0.53 | AUC: 0.9799
01/28/2023 12:54:30 PM [!] Sat Jan 28 12:54:30 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_pretrained\training_files\1674906870-model.torch
		train time: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_pretrained\training_files\1674906870-trainTime.npy
		train losses: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_pretrained\training_files\1674906870-trainLosses.npy
		train AUC: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_pretrained\training_files\1674906870-auc.npy
		train F1s : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_pretrained\training_files\1674906870-trainF1s.npy
		train TPRs: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_pretrained\training_files\1674906870-trainTPRs.npy
01/28/2023 12:54:30 PM  [!] Training non_pretrained model on downstream task...
01/28/2023 12:54:31 PM  [*] Started epoch: 1
01/28/2023 12:54:31 PM  [*] Sat Jan 28 12:54:31 2023: Train Epoch: 1 [  0  /19032 (0 %)]	Loss: 2.549270 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 12:54:37 PM  [*] Sat Jan 28 12:54:37 2023: Train Epoch: 1 [6400 /19032 (34%)]	Loss: 0.485021 | Elapsed: 6.37s | FPR 0.0003 -> TPR 0.2500 & F1 0.4000
01/28/2023 12:54:44 PM  [*] Sat Jan 28 12:54:44 2023: Train Epoch: 1 [12800/19032 (67%)]	Loss: 0.400275 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.3594 & F1 0.5287
01/28/2023 12:54:50 PM  [*] Sat Jan 28 12:54:50 2023:    1    | Tr.loss: 0.459849 | Elapsed:   19.22  s | FPR 0.0003 -> TPR: 0.01 & F1: 0.02 | AUC: 0.8355
01/28/2023 12:54:50 PM  [*] Started epoch: 2
01/28/2023 12:54:50 PM  [*] Sat Jan 28 12:54:50 2023: Train Epoch: 2 [  0  /19032 (0 %)]	Loss: 0.318967 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.6667 & F1 0.8000
01/28/2023 12:54:57 PM  [*] Sat Jan 28 12:54:57 2023: Train Epoch: 2 [6400 /19032 (34%)]	Loss: 0.307924 | Elapsed: 6.26s | FPR 0.0003 -> TPR 0.6197 & F1 0.7652
01/28/2023 12:55:03 PM  [*] Sat Jan 28 12:55:03 2023: Train Epoch: 2 [12800/19032 (67%)]	Loss: 0.396903 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.5000 & F1 0.6667
01/28/2023 12:55:09 PM  [*] Sat Jan 28 12:55:09 2023:    2    | Tr.loss: 0.279473 | Elapsed:   19.07  s | FPR 0.0003 -> TPR: 0.34 & F1: 0.51 | AUC: 0.9419
01/28/2023 12:55:09 PM  [*] Started epoch: 3
01/28/2023 12:55:09 PM  [*] Sat Jan 28 12:55:09 2023: Train Epoch: 3 [  0  /19032 (0 %)]	Loss: 0.252728 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.4400 & F1 0.6111
01/28/2023 12:55:16 PM  [*] Sat Jan 28 12:55:16 2023: Train Epoch: 3 [6400 /19032 (34%)]	Loss: 0.186056 | Elapsed: 6.29s | FPR 0.0003 -> TPR 0.7733 & F1 0.8722
01/28/2023 12:55:22 PM  [*] Sat Jan 28 12:55:22 2023: Train Epoch: 3 [12800/19032 (67%)]	Loss: 0.197180 | Elapsed: 6.31s | FPR 0.0003 -> TPR 0.7838 & F1 0.8788
01/28/2023 12:55:28 PM  [*] Sat Jan 28 12:55:28 2023:    3    | Tr.loss: 0.203284 | Elapsed:   19.20  s | FPR 0.0003 -> TPR: 0.26 & F1: 0.42 | AUC: 0.9709
01/28/2023 12:55:29 PM [!] Sat Jan 28 12:55:29 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_non_pretrained\training_files\1674906928-model.torch
		train time: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_non_pretrained\training_files\1674906928-trainTime.npy
		train losses: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_non_pretrained\training_files\1674906928-trainLosses.npy
		train AUC: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_non_pretrained\training_files\1674906928-auc.npy
		train F1s : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_non_pretrained\training_files\1674906928-trainF1s.npy
		train TPRs: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_non_pretrained\training_files\1674906928-trainTPRs.npy
01/28/2023 12:55:29 PM  [!] Training full_data model on downstream task...
01/28/2023 12:55:29 PM  [*] Started epoch: 1
01/28/2023 12:55:30 PM  [*] Sat Jan 28 12:55:30 2023: Train Epoch: 1 [  0  /76126 (0 %)]	Loss: 2.903152 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0976 & F1 0.1778
01/28/2023 12:55:36 PM  [*] Sat Jan 28 12:55:36 2023: Train Epoch: 1 [6400 /76126 (8 %)]	Loss: 0.512971 | Elapsed: 6.30s | FPR 0.0003 -> TPR 0.0462 & F1 0.0882
01/28/2023 12:55:42 PM  [*] Sat Jan 28 12:55:42 2023: Train Epoch: 1 [12800/76126 (17%)]	Loss: 0.503650 | Elapsed: 6.36s | FPR 0.0003 -> TPR 0.2879 & F1 0.4471
01/28/2023 12:55:49 PM  [*] Sat Jan 28 12:55:49 2023: Train Epoch: 1 [19200/76126 (25%)]	Loss: 0.316120 | Elapsed: 6.33s | FPR 0.0003 -> TPR 0.3913 & F1 0.5625
01/28/2023 12:55:55 PM  [*] Sat Jan 28 12:55:55 2023: Train Epoch: 1 [25600/76126 (34%)]	Loss: 0.383074 | Elapsed: 6.35s | FPR 0.0003 -> TPR 0.5143 & F1 0.6792
01/28/2023 12:56:01 PM  [*] Sat Jan 28 12:56:01 2023: Train Epoch: 1 [32000/76126 (42%)]	Loss: 0.280736 | Elapsed: 6.44s | FPR 0.0003 -> TPR 0.7971 & F1 0.8871
01/28/2023 12:56:08 PM  [*] Sat Jan 28 12:56:08 2023: Train Epoch: 1 [38400/76126 (50%)]	Loss: 0.174147 | Elapsed: 6.54s | FPR 0.0003 -> TPR 0.8056 & F1 0.8923
01/28/2023 12:56:14 PM  [*] Sat Jan 28 12:56:14 2023: Train Epoch: 1 [44800/76126 (59%)]	Loss: 0.287259 | Elapsed: 6.37s | FPR 0.0003 -> TPR 0.6351 & F1 0.7769
01/28/2023 12:56:21 PM  [*] Sat Jan 28 12:56:21 2023: Train Epoch: 1 [51200/76126 (67%)]	Loss: 0.213000 | Elapsed: 6.41s | FPR 0.0003 -> TPR 0.6615 & F1 0.7963
01/28/2023 12:56:27 PM  [*] Sat Jan 28 12:56:27 2023: Train Epoch: 1 [57600/76126 (76%)]	Loss: 0.174149 | Elapsed: 6.32s | FPR 0.0003 -> TPR 0.7639 & F1 0.8661
01/28/2023 12:56:33 PM [!] Learning rate: 2.5e-05
01/28/2023 12:56:33 PM  [*] Sat Jan 28 12:56:33 2023: Train Epoch: 1 [64000/76126 (84%)]	Loss: 0.208167 | Elapsed: 6.37s | FPR 0.0003 -> TPR 0.7164 & F1 0.8348
01/28/2023 12:56:40 PM  [*] Sat Jan 28 12:56:40 2023: Train Epoch: 1 [70400/76126 (92%)]	Loss: 0.187303 | Elapsed: 6.36s | FPR 0.0003 -> TPR 0.9286 & F1 0.9630
01/28/2023 12:56:47 PM  [*] Sat Jan 28 12:56:47 2023:    1    | Tr.loss: 0.307635 | Elapsed:   77.87  s | FPR 0.0003 -> TPR: 0.08 & F1: 0.15 | AUC: 0.9313
01/28/2023 12:56:47 PM  [*] Started epoch: 2
01/28/2023 12:56:47 PM  [*] Sat Jan 28 12:56:47 2023: Train Epoch: 2 [  0  /76126 (0 %)]	Loss: 0.087626 | Elapsed: 0.13s | FPR 0.0003 -> TPR 1.0000 & F1 1.0000
01/28/2023 12:56:54 PM  [*] Sat Jan 28 12:56:54 2023: Train Epoch: 2 [6400 /76126 (8 %)]	Loss: 0.148517 | Elapsed: 6.36s | FPR 0.0003 -> TPR 0.8750 & F1 0.9333
01/28/2023 12:57:00 PM  [*] Sat Jan 28 12:57:00 2023: Train Epoch: 2 [12800/76126 (17%)]	Loss: 0.120532 | Elapsed: 6.31s | FPR 0.0003 -> TPR 0.7458 & F1 0.8544
01/28/2023 12:57:06 PM  [*] Sat Jan 28 12:57:06 2023: Train Epoch: 2 [19200/76126 (25%)]	Loss: 0.102120 | Elapsed: 6.28s | FPR 0.0003 -> TPR 0.7761 & F1 0.8739
01/28/2023 12:57:13 PM  [*] Sat Jan 28 12:57:13 2023: Train Epoch: 2 [25600/76126 (34%)]	Loss: 0.101756 | Elapsed: 6.27s | FPR 0.0003 -> TPR 0.9254 & F1 0.9612
01/28/2023 12:57:19 PM  [*] Sat Jan 28 12:57:19 2023: Train Epoch: 2 [32000/76126 (42%)]	Loss: 0.165278 | Elapsed: 6.28s | FPR 0.0003 -> TPR 0.7463 & F1 0.8547
01/28/2023 12:57:25 PM  [*] Sat Jan 28 12:57:25 2023: Train Epoch: 2 [38400/76126 (50%)]	Loss: 0.230582 | Elapsed: 6.29s | FPR 0.0003 -> TPR 0.5278 & F1 0.6909
01/28/2023 12:57:32 PM  [*] Sat Jan 28 12:57:32 2023: Train Epoch: 2 [44800/76126 (59%)]	Loss: 0.200266 | Elapsed: 6.41s | FPR 0.0003 -> TPR 0.7727 & F1 0.8718
01/28/2023 12:57:38 PM  [*] Sat Jan 28 12:57:38 2023: Train Epoch: 2 [51200/76126 (67%)]	Loss: 0.177762 | Elapsed: 6.29s | FPR 0.0003 -> TPR 0.7941 & F1 0.8852
01/28/2023 12:57:39 PM [!] Learning rate: 2.5e-06
01/28/2023 12:57:44 PM  [*] Sat Jan 28 12:57:44 2023: Train Epoch: 2 [57600/76126 (76%)]	Loss: 0.190030 | Elapsed: 6.40s | FPR 0.0003 -> TPR 0.8000 & F1 0.8889
01/28/2023 12:57:51 PM  [*] Sat Jan 28 12:57:51 2023: Train Epoch: 2 [64000/76126 (84%)]	Loss: 0.221784 | Elapsed: 6.36s | FPR 0.0003 -> TPR 0.8333 & F1 0.9091
01/28/2023 12:57:57 PM  [*] Sat Jan 28 12:57:57 2023: Train Epoch: 2 [70400/76126 (92%)]	Loss: 0.159844 | Elapsed: 6.33s | FPR 0.0003 -> TPR 0.8219 & F1 0.9023
01/28/2023 12:58:05 PM  [*] Sat Jan 28 12:58:05 2023:    2    | Tr.loss: 0.176361 | Elapsed:   77.71  s | FPR 0.0003 -> TPR: 0.40 & F1: 0.57 | AUC: 0.9783
01/28/2023 12:58:05 PM  [*] Started epoch: 3
01/28/2023 12:58:05 PM  [*] Sat Jan 28 12:58:05 2023: Train Epoch: 3 [  0  /76126 (0 %)]	Loss: 0.238467 | Elapsed: 0.22s | FPR 0.0003 -> TPR 0.8158 & F1 0.8986
01/28/2023 12:58:12 PM  [*] Sat Jan 28 12:58:12 2023: Train Epoch: 3 [6400 /76126 (8 %)]	Loss: 0.222563 | Elapsed: 6.54s | FPR 0.0003 -> TPR 0.6866 & F1 0.8142
01/28/2023 12:58:18 PM  [*] Sat Jan 28 12:58:18 2023: Train Epoch: 3 [12800/76126 (17%)]	Loss: 0.127798 | Elapsed: 6.32s | FPR 0.0003 -> TPR 0.7846 & F1 0.8793
01/28/2023 12:58:25 PM  [*] Sat Jan 28 12:58:25 2023: Train Epoch: 3 [19200/76126 (25%)]	Loss: 0.140911 | Elapsed: 6.49s | FPR 0.0003 -> TPR 0.6349 & F1 0.7767
01/28/2023 12:58:31 PM  [*] Sat Jan 28 12:58:31 2023: Train Epoch: 3 [25600/76126 (34%)]	Loss: 0.167279 | Elapsed: 6.42s | FPR 0.0003 -> TPR 0.8060 & F1 0.8926
01/28/2023 12:58:38 PM  [*] Sat Jan 28 12:58:38 2023: Train Epoch: 3 [32000/76126 (42%)]	Loss: 0.186317 | Elapsed: 6.50s | FPR 0.0003 -> TPR 0.5385 & F1 0.7000
01/28/2023 12:58:44 PM  [*] Sat Jan 28 12:58:44 2023: Train Epoch: 3 [38400/76126 (50%)]	Loss: 0.157237 | Elapsed: 6.46s | FPR 0.0003 -> TPR 0.9474 & F1 0.9730
01/28/2023 12:58:45 PM [!] Learning rate: 2.5000000000000004e-07
01/28/2023 12:58:50 PM  [*] Sat Jan 28 12:58:50 2023: Train Epoch: 3 [44800/76126 (59%)]	Loss: 0.098730 | Elapsed: 6.31s | FPR 0.0003 -> TPR 0.9219 & F1 0.9593
01/28/2023 12:58:57 PM  [*] Sat Jan 28 12:58:57 2023: Train Epoch: 3 [51200/76126 (67%)]	Loss: 0.198689 | Elapsed: 6.32s | FPR 0.0003 -> TPR 0.6575 & F1 0.7934
01/28/2023 12:59:03 PM  [*] Sat Jan 28 12:59:03 2023: Train Epoch: 3 [57600/76126 (76%)]	Loss: 0.157463 | Elapsed: 6.31s | FPR 0.0003 -> TPR 0.9437 & F1 0.9710
01/28/2023 12:59:09 PM  [*] Sat Jan 28 12:59:09 2023: Train Epoch: 3 [64000/76126 (84%)]	Loss: 0.142196 | Elapsed: 6.35s | FPR 0.0003 -> TPR 0.7538 & F1 0.8596
01/28/2023 12:59:16 PM  [*] Sat Jan 28 12:59:16 2023: Train Epoch: 3 [70400/76126 (92%)]	Loss: 0.237618 | Elapsed: 6.26s | FPR 0.0003 -> TPR 0.7463 & F1 0.8547
01/28/2023 12:59:23 PM  [*] Sat Jan 28 12:59:23 2023:    3    | Tr.loss: 0.169925 | Elapsed:   78.07  s | FPR 0.0003 -> TPR: 0.42 & F1: 0.59 | AUC: 0.9799
01/28/2023 12:59:24 PM [!] Sat Jan 28 12:59:24 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_full_data\training_files\1674907163-model.torch
		train time: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_full_data\training_files\1674907163-trainTime.npy
		train losses: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_full_data\training_files\1674907163-trainLosses.npy
		train AUC: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_full_data\training_files\1674907163-auc.npy
		train F1s : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_full_data\training_files\1674907163-trainF1s.npy
		train TPRs: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_full_data\training_files\1674907163-trainTPRs.npy
01/28/2023 12:59:24 PM  [*] Evaluating pretrained model on test set...
01/28/2023 12:59:29 PM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.1664 | F1: 0.2854
01/28/2023 12:59:29 PM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.2299 | F1: 0.3738
01/28/2023 12:59:29 PM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.3123 | F1: 0.4757
01/28/2023 12:59:29 PM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.4477 | F1: 0.6175
01/28/2023 12:59:29 PM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.5655 | F1: 0.7185
01/28/2023 12:59:29 PM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.6397 | F1: 0.7683
01/28/2023 12:59:29 PM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.8325 | F1: 0.8683
01/28/2023 12:59:29 PM  [*] Evaluating non_pretrained model on test set...
01/28/2023 12:59:34 PM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0241 | F1: 0.0471
01/28/2023 12:59:34 PM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1579 | F1: 0.2727
01/28/2023 12:59:34 PM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.2801 | F1: 0.4374
01/28/2023 12:59:34 PM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3283 | F1: 0.4934
01/28/2023 12:59:34 PM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3785 | F1: 0.5458
01/28/2023 12:59:34 PM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.5197 | F1: 0.6727
01/28/2023 12:59:34 PM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.7994 | F1: 0.8484
01/28/2023 12:59:34 PM  [*] Evaluating full_data model on test set...
01/28/2023 12:59:39 PM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0111 | F1: 0.0219
01/28/2023 12:59:39 PM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.2419 | F1: 0.3896
01/28/2023 12:59:39 PM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.3195 | F1: 0.4839
01/28/2023 12:59:39 PM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3468 | F1: 0.5140
01/28/2023 12:59:39 PM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.4139 | F1: 0.5821
01/28/2023 12:59:39 PM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.5583 | F1: 0.7050
01/28/2023 12:59:39 PM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.8075 | F1: 0.8533
01/28/2023 12:59:39 PM  [!] Running pre-training split 3/3
01/28/2023 12:59:43 PM  [!] Pre-training model...
01/28/2023 12:59:43 PM  [*] Masking sequences...
01/28/2023 01:00:06 PM  [*] Started epoch: 1
01/28/2023 01:00:06 PM  [*] Sat Jan 28 13:00:06 2023: Train Epoch: 1 [  0  /57094 (0 %)]	Loss: 413.179626 | Elapsed: 0.30s
01/28/2023 01:00:19 PM  [*] Sat Jan 28 13:00:19 2023: Train Epoch: 1 [6400 /57094 (11%)]	Loss: 244.411865 | Elapsed: 12.63s
01/28/2023 01:00:32 PM  [*] Sat Jan 28 13:00:32 2023: Train Epoch: 1 [12800/57094 (22%)]	Loss: 211.540680 | Elapsed: 12.62s
01/28/2023 01:00:45 PM  [*] Sat Jan 28 13:00:45 2023: Train Epoch: 1 [19200/57094 (34%)]	Loss: 229.995483 | Elapsed: 12.97s
01/28/2023 01:00:57 PM  [*] Sat Jan 28 13:00:57 2023: Train Epoch: 1 [25600/57094 (45%)]	Loss: 192.498077 | Elapsed: 12.70s
01/28/2023 01:01:10 PM  [*] Sat Jan 28 13:01:10 2023: Train Epoch: 1 [32000/57094 (56%)]	Loss: 217.465881 | Elapsed: 13.12s
01/28/2023 01:01:23 PM  [*] Sat Jan 28 13:01:23 2023: Train Epoch: 1 [38400/57094 (67%)]	Loss: 201.781723 | Elapsed: 13.12s
01/28/2023 01:01:36 PM  [*] Sat Jan 28 13:01:36 2023: Train Epoch: 1 [44800/57094 (78%)]	Loss: 188.838120 | Elapsed: 12.76s
01/28/2023 01:01:49 PM  [*] Sat Jan 28 13:01:49 2023: Train Epoch: 1 [51200/57094 (90%)]	Loss: 184.851440 | Elapsed: 12.59s
01/28/2023 01:02:02 PM  [*] Sat Jan 28 13:02:02 2023:    1    | Tr.loss: 207.751345 | Elapsed:  116.34  s
01/28/2023 01:02:02 PM  [*] Started epoch: 2
01/28/2023 01:02:02 PM  [*] Sat Jan 28 13:02:02 2023: Train Epoch: 2 [  0  /57094 (0 %)]	Loss: 193.120163 | Elapsed: 0.13s
01/28/2023 01:02:15 PM  [*] Sat Jan 28 13:02:15 2023: Train Epoch: 2 [6400 /57094 (11%)]	Loss: 176.641205 | Elapsed: 12.80s
01/28/2023 01:02:28 PM  [*] Sat Jan 28 13:02:28 2023: Train Epoch: 2 [12800/57094 (22%)]	Loss: 160.952530 | Elapsed: 12.55s
01/28/2023 01:02:41 PM  [*] Sat Jan 28 13:02:41 2023: Train Epoch: 2 [19200/57094 (34%)]	Loss: 186.980988 | Elapsed: 12.75s
01/28/2023 01:02:53 PM  [*] Sat Jan 28 13:02:53 2023: Train Epoch: 2 [25600/57094 (45%)]	Loss: 186.861389 | Elapsed: 12.51s
01/28/2023 01:03:06 PM  [*] Sat Jan 28 13:03:06 2023: Train Epoch: 2 [32000/57094 (56%)]	Loss: 212.006119 | Elapsed: 13.23s
01/28/2023 01:03:20 PM  [*] Sat Jan 28 13:03:20 2023: Train Epoch: 2 [38400/57094 (67%)]	Loss: 195.585541 | Elapsed: 13.25s
01/28/2023 01:03:33 PM  [*] Sat Jan 28 13:03:33 2023: Train Epoch: 2 [44800/57094 (78%)]	Loss: 192.601837 | Elapsed: 13.07s
01/28/2023 01:03:46 PM  [*] Sat Jan 28 13:03:46 2023: Train Epoch: 2 [51200/57094 (90%)]	Loss: 193.245316 | Elapsed: 12.91s
01/28/2023 01:03:59 PM  [*] Sat Jan 28 13:03:59 2023:    2    | Tr.loss: 185.557483 | Elapsed:  116.46  s
01/28/2023 01:03:59 PM  [*] Started epoch: 3
01/28/2023 01:03:59 PM  [*] Sat Jan 28 13:03:59 2023: Train Epoch: 3 [  0  /57094 (0 %)]	Loss: 189.897705 | Elapsed: 0.13s
01/28/2023 01:04:12 PM  [*] Sat Jan 28 13:04:12 2023: Train Epoch: 3 [6400 /57094 (11%)]	Loss: 200.308853 | Elapsed: 12.64s
01/28/2023 01:04:24 PM  [*] Sat Jan 28 13:04:24 2023: Train Epoch: 3 [12800/57094 (22%)]	Loss: 190.978638 | Elapsed: 12.81s
01/28/2023 01:04:37 PM  [*] Sat Jan 28 13:04:37 2023: Train Epoch: 3 [19200/57094 (34%)]	Loss: 189.560455 | Elapsed: 12.78s
01/28/2023 01:04:50 PM  [*] Sat Jan 28 13:04:50 2023: Train Epoch: 3 [25600/57094 (45%)]	Loss: 179.188705 | Elapsed: 12.66s
01/28/2023 01:05:03 PM  [*] Sat Jan 28 13:05:03 2023: Train Epoch: 3 [32000/57094 (56%)]	Loss: 180.602753 | Elapsed: 12.78s
01/28/2023 01:05:15 PM  [*] Sat Jan 28 13:05:15 2023: Train Epoch: 3 [38400/57094 (67%)]	Loss: 175.326508 | Elapsed: 12.60s
01/28/2023 01:05:28 PM  [*] Sat Jan 28 13:05:28 2023: Train Epoch: 3 [44800/57094 (78%)]	Loss: 153.729858 | Elapsed: 12.47s
01/28/2023 01:05:40 PM  [*] Sat Jan 28 13:05:40 2023: Train Epoch: 3 [51200/57094 (90%)]	Loss: 180.672485 | Elapsed: 12.22s
01/28/2023 01:05:53 PM  [*] Sat Jan 28 13:05:53 2023:    3    | Tr.loss: 180.450198 | Elapsed:  114.01  s
01/28/2023 01:05:53 PM  [*] Started epoch: 4
01/28/2023 01:05:53 PM  [*] Sat Jan 28 13:05:53 2023: Train Epoch: 4 [  0  /57094 (0 %)]	Loss: 184.351410 | Elapsed: 0.13s
01/28/2023 01:06:06 PM  [*] Sat Jan 28 13:06:06 2023: Train Epoch: 4 [6400 /57094 (11%)]	Loss: 185.233780 | Elapsed: 12.93s
01/28/2023 01:06:19 PM  [*] Sat Jan 28 13:06:19 2023: Train Epoch: 4 [12800/57094 (22%)]	Loss: 191.994583 | Elapsed: 12.76s
01/28/2023 01:06:31 PM  [*] Sat Jan 28 13:06:31 2023: Train Epoch: 4 [19200/57094 (34%)]	Loss: 175.469788 | Elapsed: 12.53s
01/28/2023 01:06:44 PM  [*] Sat Jan 28 13:06:44 2023: Train Epoch: 4 [25600/57094 (45%)]	Loss: 181.342072 | Elapsed: 12.47s
01/28/2023 01:06:56 PM  [*] Sat Jan 28 13:06:56 2023: Train Epoch: 4 [32000/57094 (56%)]	Loss: 161.819000 | Elapsed: 12.57s
01/28/2023 01:07:09 PM  [*] Sat Jan 28 13:07:09 2023: Train Epoch: 4 [38400/57094 (67%)]	Loss: 180.370102 | Elapsed: 12.62s
01/28/2023 01:07:21 PM  [*] Sat Jan 28 13:07:21 2023: Train Epoch: 4 [44800/57094 (78%)]	Loss: 178.172302 | Elapsed: 12.43s
01/28/2023 01:07:34 PM  [*] Sat Jan 28 13:07:34 2023: Train Epoch: 4 [51200/57094 (90%)]	Loss: 176.137405 | Elapsed: 12.43s
01/28/2023 01:07:47 PM  [*] Sat Jan 28 13:07:47 2023:    4    | Tr.loss: 177.894459 | Elapsed:  114.04  s
01/28/2023 01:07:47 PM  [*] Started epoch: 5
01/28/2023 01:07:47 PM  [*] Sat Jan 28 13:07:47 2023: Train Epoch: 5 [  0  /57094 (0 %)]	Loss: 178.174255 | Elapsed: 0.13s
01/28/2023 01:08:00 PM  [*] Sat Jan 28 13:08:00 2023: Train Epoch: 5 [6400 /57094 (11%)]	Loss: 145.996307 | Elapsed: 12.68s
01/28/2023 01:08:12 PM  [*] Sat Jan 28 13:08:12 2023: Train Epoch: 5 [12800/57094 (22%)]	Loss: 155.351944 | Elapsed: 12.71s
01/28/2023 01:08:25 PM  [*] Sat Jan 28 13:08:25 2023: Train Epoch: 5 [19200/57094 (34%)]	Loss: 171.691574 | Elapsed: 12.45s
01/28/2023 01:08:37 PM  [*] Sat Jan 28 13:08:37 2023: Train Epoch: 5 [25600/57094 (45%)]	Loss: 172.934296 | Elapsed: 12.32s
01/28/2023 01:08:50 PM  [*] Sat Jan 28 13:08:50 2023: Train Epoch: 5 [32000/57094 (56%)]	Loss: 177.779968 | Elapsed: 12.49s
01/28/2023 01:09:02 PM  [*] Sat Jan 28 13:09:02 2023: Train Epoch: 5 [38400/57094 (67%)]	Loss: 183.372620 | Elapsed: 12.87s
01/28/2023 01:09:15 PM  [*] Sat Jan 28 13:09:15 2023: Train Epoch: 5 [44800/57094 (78%)]	Loss: 177.692734 | Elapsed: 12.99s
01/28/2023 01:09:28 PM  [*] Sat Jan 28 13:09:28 2023: Train Epoch: 5 [51200/57094 (90%)]	Loss: 175.043976 | Elapsed: 12.84s
01/28/2023 01:09:41 PM  [*] Sat Jan 28 13:09:41 2023:    5    | Tr.loss: 176.190012 | Elapsed:  114.53  s
01/28/2023 01:09:41 PM  [*] Started epoch: 6
01/28/2023 01:09:42 PM  [*] Sat Jan 28 13:09:42 2023: Train Epoch: 6 [  0  /57094 (0 %)]	Loss: 183.654938 | Elapsed: 0.13s
01/28/2023 01:09:54 PM  [*] Sat Jan 28 13:09:54 2023: Train Epoch: 6 [6400 /57094 (11%)]	Loss: 192.278854 | Elapsed: 12.49s
01/28/2023 01:10:07 PM  [*] Sat Jan 28 13:10:07 2023: Train Epoch: 6 [12800/57094 (22%)]	Loss: 162.259613 | Elapsed: 12.60s
01/28/2023 01:10:19 PM  [*] Sat Jan 28 13:10:19 2023: Train Epoch: 6 [19200/57094 (34%)]	Loss: 163.700714 | Elapsed: 12.39s
01/28/2023 01:10:31 PM  [*] Sat Jan 28 13:10:31 2023: Train Epoch: 6 [25600/57094 (45%)]	Loss: 183.329147 | Elapsed: 12.48s
01/28/2023 01:10:44 PM  [*] Sat Jan 28 13:10:44 2023: Train Epoch: 6 [32000/57094 (56%)]	Loss: 181.672394 | Elapsed: 12.34s
01/28/2023 01:10:48 PM [!] Learning rate: 2.5e-05
01/28/2023 01:10:56 PM  [*] Sat Jan 28 13:10:56 2023: Train Epoch: 6 [38400/57094 (67%)]	Loss: 185.500092 | Elapsed: 12.23s
01/28/2023 01:11:08 PM  [*] Sat Jan 28 13:11:08 2023: Train Epoch: 6 [44800/57094 (78%)]	Loss: 160.591705 | Elapsed: 12.44s
01/28/2023 01:11:21 PM  [*] Sat Jan 28 13:11:21 2023: Train Epoch: 6 [51200/57094 (90%)]	Loss: 177.317566 | Elapsed: 12.34s
01/28/2023 01:11:34 PM  [*] Sat Jan 28 13:11:34 2023:    6    | Tr.loss: 174.951723 | Elapsed:  112.82  s
01/28/2023 01:11:34 PM  [*] Started epoch: 7
01/28/2023 01:11:34 PM  [*] Sat Jan 28 13:11:34 2023: Train Epoch: 7 [  0  /57094 (0 %)]	Loss: 180.765594 | Elapsed: 0.14s
01/28/2023 01:11:47 PM  [*] Sat Jan 28 13:11:47 2023: Train Epoch: 7 [6400 /57094 (11%)]	Loss: 177.930145 | Elapsed: 12.61s
01/28/2023 01:11:59 PM  [*] Sat Jan 28 13:11:59 2023: Train Epoch: 7 [12800/57094 (22%)]	Loss: 150.035522 | Elapsed: 12.25s
01/28/2023 01:12:12 PM  [*] Sat Jan 28 13:12:12 2023: Train Epoch: 7 [19200/57094 (34%)]	Loss: 169.511459 | Elapsed: 12.44s
01/28/2023 01:12:25 PM  [*] Sat Jan 28 13:12:25 2023: Train Epoch: 7 [25600/57094 (45%)]	Loss: 162.930725 | Elapsed: 13.04s
01/28/2023 01:12:37 PM  [*] Sat Jan 28 13:12:37 2023: Train Epoch: 7 [32000/57094 (56%)]	Loss: 171.686096 | Elapsed: 12.44s
01/28/2023 01:12:50 PM  [*] Sat Jan 28 13:12:50 2023: Train Epoch: 7 [38400/57094 (67%)]	Loss: 180.088608 | Elapsed: 12.52s
01/28/2023 01:13:02 PM  [*] Sat Jan 28 13:13:02 2023: Train Epoch: 7 [44800/57094 (78%)]	Loss: 171.171677 | Elapsed: 12.39s
01/28/2023 01:13:15 PM  [*] Sat Jan 28 13:13:15 2023: Train Epoch: 7 [51200/57094 (90%)]	Loss: 200.763489 | Elapsed: 12.60s
01/28/2023 01:13:28 PM  [*] Sat Jan 28 13:13:28 2023:    7    | Tr.loss: 173.893721 | Elapsed:  114.06  s
01/28/2023 01:13:28 PM  [*] Started epoch: 8
01/28/2023 01:13:28 PM  [*] Sat Jan 28 13:13:28 2023: Train Epoch: 8 [  0  /57094 (0 %)]	Loss: 185.127441 | Elapsed: 0.25s
01/28/2023 01:13:41 PM  [*] Sat Jan 28 13:13:41 2023: Train Epoch: 8 [6400 /57094 (11%)]	Loss: 179.357574 | Elapsed: 12.77s
01/28/2023 01:13:54 PM  [*] Sat Jan 28 13:13:54 2023: Train Epoch: 8 [12800/57094 (22%)]	Loss: 183.997528 | Elapsed: 12.63s
01/28/2023 01:14:07 PM  [*] Sat Jan 28 13:14:07 2023: Train Epoch: 8 [19200/57094 (34%)]	Loss: 170.855225 | Elapsed: 12.84s
01/28/2023 01:14:19 PM  [*] Sat Jan 28 13:14:19 2023: Train Epoch: 8 [25600/57094 (45%)]	Loss: 149.005142 | Elapsed: 12.57s
01/28/2023 01:14:32 PM  [*] Sat Jan 28 13:14:32 2023: Train Epoch: 8 [32000/57094 (56%)]	Loss: 173.321671 | Elapsed: 12.84s
01/28/2023 01:14:45 PM  [*] Sat Jan 28 13:14:45 2023: Train Epoch: 8 [38400/57094 (67%)]	Loss: 172.839874 | Elapsed: 12.77s
01/28/2023 01:14:58 PM  [*] Sat Jan 28 13:14:58 2023: Train Epoch: 8 [44800/57094 (78%)]	Loss: 168.534393 | Elapsed: 12.69s
01/28/2023 01:15:10 PM  [*] Sat Jan 28 13:15:10 2023: Train Epoch: 8 [51200/57094 (90%)]	Loss: 164.556152 | Elapsed: 12.88s
01/28/2023 01:15:25 PM  [*] Sat Jan 28 13:15:25 2023:    8    | Tr.loss: 173.595918 | Elapsed:  116.27  s
01/28/2023 01:15:25 PM  [*] Started epoch: 9
01/28/2023 01:15:25 PM  [*] Sat Jan 28 13:15:25 2023: Train Epoch: 9 [  0  /57094 (0 %)]	Loss: 163.740524 | Elapsed: 0.22s
01/28/2023 01:15:38 PM  [*] Sat Jan 28 13:15:38 2023: Train Epoch: 9 [6400 /57094 (11%)]	Loss: 165.011932 | Elapsed: 12.87s
01/28/2023 01:15:50 PM  [*] Sat Jan 28 13:15:50 2023: Train Epoch: 9 [12800/57094 (22%)]	Loss: 181.012268 | Elapsed: 12.48s
01/28/2023 01:16:03 PM  [*] Sat Jan 28 13:16:03 2023: Train Epoch: 9 [19200/57094 (34%)]	Loss: 164.138000 | Elapsed: 12.66s
01/28/2023 01:16:15 PM  [*] Sat Jan 28 13:16:15 2023: Train Epoch: 9 [25600/57094 (45%)]	Loss: 160.067184 | Elapsed: 12.66s
01/28/2023 01:16:28 PM  [*] Sat Jan 28 13:16:28 2023: Train Epoch: 9 [32000/57094 (56%)]	Loss: 194.450546 | Elapsed: 12.59s
01/28/2023 01:16:41 PM  [*] Sat Jan 28 13:16:41 2023: Train Epoch: 9 [38400/57094 (67%)]	Loss: 159.291794 | Elapsed: 12.51s
01/28/2023 01:16:54 PM  [*] Sat Jan 28 13:16:54 2023: Train Epoch: 9 [44800/57094 (78%)]	Loss: 173.419128 | Elapsed: 13.40s
01/28/2023 01:17:07 PM  [*] Sat Jan 28 13:17:07 2023: Train Epoch: 9 [51200/57094 (90%)]	Loss: 176.166824 | Elapsed: 12.94s
01/28/2023 01:17:20 PM  [*] Sat Jan 28 13:17:20 2023:    9    | Tr.loss: 173.437207 | Elapsed:  115.85  s
01/28/2023 01:17:20 PM  [*] Started epoch: 10
01/28/2023 01:17:21 PM  [*] Sat Jan 28 13:17:21 2023: Train Epoch: 10 [  0  /57094 (0 %)]	Loss: 152.341354 | Elapsed: 0.21s
01/28/2023 01:17:34 PM  [*] Sat Jan 28 13:17:34 2023: Train Epoch: 10 [6400 /57094 (11%)]	Loss: 162.032867 | Elapsed: 13.22s
01/28/2023 01:17:47 PM  [*] Sat Jan 28 13:17:47 2023: Train Epoch: 10 [12800/57094 (22%)]	Loss: 187.091873 | Elapsed: 12.76s
01/28/2023 01:17:59 PM  [*] Sat Jan 28 13:17:59 2023: Train Epoch: 10 [19200/57094 (34%)]	Loss: 182.033234 | Elapsed: 12.73s
01/28/2023 01:18:12 PM  [*] Sat Jan 28 13:18:12 2023: Train Epoch: 10 [25600/57094 (45%)]	Loss: 159.684219 | Elapsed: 12.56s
01/28/2023 01:18:25 PM  [*] Sat Jan 28 13:18:25 2023: Train Epoch: 10 [32000/57094 (56%)]	Loss: 179.263962 | Elapsed: 12.72s
01/28/2023 01:18:37 PM  [*] Sat Jan 28 13:18:37 2023: Train Epoch: 10 [38400/57094 (67%)]	Loss: 166.557724 | Elapsed: 12.65s
01/28/2023 01:18:50 PM  [*] Sat Jan 28 13:18:50 2023: Train Epoch: 10 [44800/57094 (78%)]	Loss: 171.324783 | Elapsed: 12.72s
01/28/2023 01:19:03 PM  [*] Sat Jan 28 13:19:03 2023: Train Epoch: 10 [51200/57094 (90%)]	Loss: 180.680298 | Elapsed: 12.60s
01/28/2023 01:19:17 PM  [*] Sat Jan 28 13:19:17 2023:   10    | Tr.loss: 173.279781 | Elapsed:  116.23  s
01/28/2023 01:19:17 PM [!] Sat Jan 28 13:19:17 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\preTraining\training_files\1674908357-model.torch
		train time: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\preTraining\training_files\1674908357-trainTime.npy
		train losses: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\preTraining\training_files\1674908357-trainLosses.npy
		train AUC: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\preTraining\training_files\1674908357-auc.npy
01/28/2023 01:19:18 PM  [!] Training pretrained model on downstream task...
01/28/2023 01:19:18 PM  [*] Started epoch: 1
01/28/2023 01:19:19 PM  [*] Sat Jan 28 13:19:19 2023: Train Epoch: 1 [  0  /19032 (0 %)]	Loss: 3.105134 | Elapsed: 0.35s | FPR 0.0003 -> TPR 0.0250 & F1 0.0488
01/28/2023 01:19:28 PM  [*] Sat Jan 28 13:19:28 2023: Train Epoch: 1 [6400 /19032 (34%)]	Loss: 0.357684 | Elapsed: 9.31s | FPR 0.0003 -> TPR 0.4429 & F1 0.6139
01/28/2023 01:19:37 PM  [*] Sat Jan 28 13:19:37 2023: Train Epoch: 1 [12800/19032 (67%)]	Loss: 0.198856 | Elapsed: 9.20s | FPR 0.0003 -> TPR 0.7750 & F1 0.8732
01/28/2023 01:19:47 PM  [*] Sat Jan 28 13:19:47 2023:    1    | Tr.loss: 0.412970 | Elapsed:   28.28  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8759
01/28/2023 01:19:47 PM  [*] Started epoch: 2
01/28/2023 01:19:47 PM  [*] Sat Jan 28 13:19:47 2023: Train Epoch: 2 [  0  /19032 (0 %)]	Loss: 0.318404 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.6667 & F1 0.8000
01/28/2023 01:19:56 PM  [*] Sat Jan 28 13:19:56 2023: Train Epoch: 2 [6400 /19032 (34%)]	Loss: 0.222650 | Elapsed: 9.27s | FPR 0.0003 -> TPR 0.6901 & F1 0.8167
01/28/2023 01:20:05 PM  [*] Sat Jan 28 13:20:05 2023: Train Epoch: 2 [12800/19032 (67%)]	Loss: 0.291238 | Elapsed: 9.23s | FPR 0.0003 -> TPR 0.8235 & F1 0.9032
01/28/2023 01:20:15 PM  [*] Sat Jan 28 13:20:15 2023:    2    | Tr.loss: 0.261594 | Elapsed:   28.04  s | FPR 0.0003 -> TPR: 0.35 & F1: 0.52 | AUC: 0.9524
01/28/2023 01:20:15 PM  [*] Started epoch: 3
01/28/2023 01:20:15 PM  [*] Sat Jan 28 13:20:15 2023: Train Epoch: 3 [  0  /19032 (0 %)]	Loss: 0.216725 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.8049 & F1 0.8919
01/28/2023 01:20:24 PM  [*] Sat Jan 28 13:20:24 2023: Train Epoch: 3 [6400 /19032 (34%)]	Loss: 0.219454 | Elapsed: 9.23s | FPR 0.0003 -> TPR 0.8056 & F1 0.8923
01/28/2023 01:20:33 PM  [*] Sat Jan 28 13:20:33 2023: Train Epoch: 3 [12800/19032 (67%)]	Loss: 0.181471 | Elapsed: 9.19s | FPR 0.0003 -> TPR 0.7143 & F1 0.8333
01/28/2023 01:20:43 PM  [*] Sat Jan 28 13:20:43 2023:    3    | Tr.loss: 0.191624 | Elapsed:   27.88  s | FPR 0.0003 -> TPR: 0.50 & F1: 0.67 | AUC: 0.9746
01/28/2023 01:20:43 PM [!] Sat Jan 28 13:20:43 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_pretrained\training_files\1674908443-model.torch
		train time: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_pretrained\training_files\1674908443-trainTime.npy
		train losses: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_pretrained\training_files\1674908443-trainLosses.npy
		train AUC: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_pretrained\training_files\1674908443-auc.npy
		train F1s : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_pretrained\training_files\1674908443-trainF1s.npy
		train TPRs: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_pretrained\training_files\1674908443-trainTPRs.npy
01/28/2023 01:20:43 PM  [!] Training non_pretrained model on downstream task...
01/28/2023 01:20:44 PM  [*] Started epoch: 1
01/28/2023 01:20:44 PM  [*] Sat Jan 28 13:20:44 2023: Train Epoch: 1 [  0  /19032 (0 %)]	Loss: 1.561262 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0571 & F1 0.1081
01/28/2023 01:20:50 PM  [*] Sat Jan 28 13:20:50 2023: Train Epoch: 1 [6400 /19032 (34%)]	Loss: 0.461266 | Elapsed: 6.30s | FPR 0.0003 -> TPR 0.2817 & F1 0.4396
01/28/2023 01:20:56 PM  [*] Sat Jan 28 13:20:56 2023: Train Epoch: 1 [12800/19032 (67%)]	Loss: 0.406053 | Elapsed: 6.27s | FPR 0.0003 -> TPR 0.4571 & F1 0.6275
01/28/2023 01:21:03 PM  [*] Sat Jan 28 13:21:03 2023:    1    | Tr.loss: 0.431671 | Elapsed:   19.24  s | FPR 0.0003 -> TPR: 0.02 & F1: 0.04 | AUC: 0.8543
01/28/2023 01:21:03 PM  [*] Started epoch: 2
01/28/2023 01:21:03 PM  [*] Sat Jan 28 13:21:03 2023: Train Epoch: 2 [  0  /19032 (0 %)]	Loss: 0.207832 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.8571 & F1 0.9231
01/28/2023 01:21:09 PM  [*] Sat Jan 28 13:21:09 2023: Train Epoch: 2 [6400 /19032 (34%)]	Loss: 0.290567 | Elapsed: 6.31s | FPR 0.0003 -> TPR 0.5738 & F1 0.7292
01/28/2023 01:21:16 PM  [*] Sat Jan 28 13:21:16 2023: Train Epoch: 2 [12800/19032 (67%)]	Loss: 0.184354 | Elapsed: 6.34s | FPR 0.0003 -> TPR 0.7969 & F1 0.8870
01/28/2023 01:21:22 PM  [*] Sat Jan 28 13:21:22 2023:    2    | Tr.loss: 0.266267 | Elapsed:   19.39  s | FPR 0.0003 -> TPR: 0.32 & F1: 0.49 | AUC: 0.9486
01/28/2023 01:21:22 PM  [*] Started epoch: 3
01/28/2023 01:21:22 PM  [*] Sat Jan 28 13:21:22 2023: Train Epoch: 3 [  0  /19032 (0 %)]	Loss: 0.220716 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.6957 & F1 0.8205
01/28/2023 01:21:29 PM  [*] Sat Jan 28 13:21:29 2023: Train Epoch: 3 [6400 /19032 (34%)]	Loss: 0.225408 | Elapsed: 6.34s | FPR 0.0003 -> TPR 0.7391 & F1 0.8500
01/28/2023 01:21:35 PM  [*] Sat Jan 28 13:21:35 2023: Train Epoch: 3 [12800/19032 (67%)]	Loss: 0.201059 | Elapsed: 6.35s | FPR 0.0003 -> TPR 0.6833 & F1 0.8119
01/28/2023 01:21:42 PM  [*] Sat Jan 28 13:21:42 2023:    3    | Tr.loss: 0.192973 | Elapsed:   19.37  s | FPR 0.0003 -> TPR: 0.38 & F1: 0.55 | AUC: 0.9740
01/28/2023 01:21:42 PM [!] Sat Jan 28 13:21:42 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_non_pretrained\training_files\1674908502-model.torch
		train time: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_non_pretrained\training_files\1674908502-trainTime.npy
		train losses: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_non_pretrained\training_files\1674908502-trainLosses.npy
		train AUC: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_non_pretrained\training_files\1674908502-auc.npy
		train F1s : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_non_pretrained\training_files\1674908502-trainF1s.npy
		train TPRs: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_non_pretrained\training_files\1674908502-trainTPRs.npy
01/28/2023 01:21:42 PM  [!] Training full_data model on downstream task...
01/28/2023 01:21:43 PM  [*] Started epoch: 1
01/28/2023 01:21:43 PM  [*] Sat Jan 28 13:21:43 2023: Train Epoch: 1 [  0  /76126 (0 %)]	Loss: 1.826692 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0870 & F1 0.1600
01/28/2023 01:21:49 PM  [*] Sat Jan 28 13:21:49 2023: Train Epoch: 1 [6400 /76126 (8 %)]	Loss: 0.580017 | Elapsed: 6.35s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 01:21:55 PM  [*] Sat Jan 28 13:21:55 2023: Train Epoch: 1 [12800/76126 (17%)]	Loss: 0.384901 | Elapsed: 6.43s | FPR 0.0003 -> TPR 0.2571 & F1 0.4091
01/28/2023 01:22:02 PM  [*] Sat Jan 28 13:22:02 2023: Train Epoch: 1 [19200/76126 (25%)]	Loss: 0.400832 | Elapsed: 6.37s | FPR 0.0003 -> TPR 0.5156 & F1 0.6804
01/28/2023 01:22:08 PM  [*] Sat Jan 28 13:22:08 2023: Train Epoch: 1 [25600/76126 (34%)]	Loss: 0.342923 | Elapsed: 6.37s | FPR 0.0003 -> TPR 0.5763 & F1 0.7312
01/28/2023 01:22:15 PM  [*] Sat Jan 28 13:22:15 2023: Train Epoch: 1 [32000/76126 (42%)]	Loss: 0.211404 | Elapsed: 6.34s | FPR 0.0003 -> TPR 0.6234 & F1 0.7680
01/28/2023 01:22:21 PM  [*] Sat Jan 28 13:22:21 2023: Train Epoch: 1 [38400/76126 (50%)]	Loss: 0.286328 | Elapsed: 6.33s | FPR 0.0003 -> TPR 0.5333 & F1 0.6957
01/28/2023 01:22:27 PM  [*] Sat Jan 28 13:22:27 2023: Train Epoch: 1 [44800/76126 (59%)]	Loss: 0.309169 | Elapsed: 6.35s | FPR 0.0003 -> TPR 0.5538 & F1 0.7129
01/28/2023 01:22:34 PM  [*] Sat Jan 28 13:22:34 2023: Train Epoch: 1 [51200/76126 (67%)]	Loss: 0.131562 | Elapsed: 6.30s | FPR 0.0003 -> TPR 0.9062 & F1 0.9508
01/28/2023 01:22:40 PM  [*] Sat Jan 28 13:22:40 2023: Train Epoch: 1 [57600/76126 (76%)]	Loss: 0.212485 | Elapsed: 6.36s | FPR 0.0003 -> TPR 0.6471 & F1 0.7857
01/28/2023 01:22:46 PM [!] Learning rate: 2.5e-05
01/28/2023 01:22:46 PM  [*] Sat Jan 28 13:22:46 2023: Train Epoch: 1 [64000/76126 (84%)]	Loss: 0.238882 | Elapsed: 6.37s | FPR 0.0003 -> TPR 0.6923 & F1 0.8182
01/28/2023 01:22:53 PM  [*] Sat Jan 28 13:22:53 2023: Train Epoch: 1 [70400/76126 (92%)]	Loss: 0.215938 | Elapsed: 6.28s | FPR 0.0003 -> TPR 0.5873 & F1 0.7400
01/28/2023 01:23:00 PM  [*] Sat Jan 28 13:23:00 2023:    1    | Tr.loss: 0.297178 | Elapsed:   77.49  s | FPR 0.0003 -> TPR: 0.14 & F1: 0.24 | AUC: 0.9343
01/28/2023 01:23:00 PM  [*] Started epoch: 2
01/28/2023 01:23:00 PM  [*] Sat Jan 28 13:23:00 2023: Train Epoch: 2 [  0  /76126 (0 %)]	Loss: 0.190909 | Elapsed: 0.13s | FPR 0.0003 -> TPR 0.5682 & F1 0.7246
01/28/2023 01:23:07 PM  [*] Sat Jan 28 13:23:07 2023: Train Epoch: 2 [6400 /76126 (8 %)]	Loss: 0.141217 | Elapsed: 6.40s | FPR 0.0003 -> TPR 0.9275 & F1 0.9624
01/28/2023 01:23:13 PM  [*] Sat Jan 28 13:23:13 2023: Train Epoch: 2 [12800/76126 (17%)]	Loss: 0.202580 | Elapsed: 6.30s | FPR 0.0003 -> TPR 0.7941 & F1 0.8852
01/28/2023 01:23:19 PM  [*] Sat Jan 28 13:23:19 2023: Train Epoch: 2 [19200/76126 (25%)]	Loss: 0.136316 | Elapsed: 6.46s | FPR 0.0003 -> TPR 0.9403 & F1 0.9692
01/28/2023 01:23:26 PM  [*] Sat Jan 28 13:23:26 2023: Train Epoch: 2 [25600/76126 (34%)]	Loss: 0.237362 | Elapsed: 6.42s | FPR 0.0003 -> TPR 0.5758 & F1 0.7308
01/28/2023 01:23:32 PM  [*] Sat Jan 28 13:23:32 2023: Train Epoch: 2 [32000/76126 (42%)]	Loss: 0.087707 | Elapsed: 6.43s | FPR 0.0003 -> TPR 0.9385 & F1 0.9683
01/28/2023 01:23:39 PM  [*] Sat Jan 28 13:23:39 2023: Train Epoch: 2 [38400/76126 (50%)]	Loss: 0.202817 | Elapsed: 6.41s | FPR 0.0003 -> TPR 0.7465 & F1 0.8548
01/28/2023 01:23:45 PM  [*] Sat Jan 28 13:23:45 2023: Train Epoch: 2 [44800/76126 (59%)]	Loss: 0.214874 | Elapsed: 6.29s | FPR 0.0003 -> TPR 0.7761 & F1 0.8739
01/28/2023 01:23:51 PM  [*] Sat Jan 28 13:23:51 2023: Train Epoch: 2 [51200/76126 (67%)]	Loss: 0.122791 | Elapsed: 6.27s | FPR 0.0003 -> TPR 0.9189 & F1 0.9577
01/28/2023 01:23:52 PM [!] Learning rate: 2.5e-06
01/28/2023 01:23:58 PM  [*] Sat Jan 28 13:23:58 2023: Train Epoch: 2 [57600/76126 (76%)]	Loss: 0.174272 | Elapsed: 6.34s | FPR 0.0003 -> TPR 0.7568 & F1 0.8615
01/28/2023 01:24:04 PM  [*] Sat Jan 28 13:24:04 2023: Train Epoch: 2 [64000/76126 (84%)]	Loss: 0.109312 | Elapsed: 6.40s | FPR 0.0003 -> TPR 0.6769 & F1 0.8073
01/28/2023 01:24:10 PM  [*] Sat Jan 28 13:24:10 2023: Train Epoch: 2 [70400/76126 (92%)]	Loss: 0.186745 | Elapsed: 6.39s | FPR 0.0003 -> TPR 0.7632 & F1 0.8657
01/28/2023 01:24:18 PM  [*] Sat Jan 28 13:24:18 2023:    2    | Tr.loss: 0.168473 | Elapsed:   78.02  s | FPR 0.0003 -> TPR: 0.44 & F1: 0.61 | AUC: 0.9803
01/28/2023 01:24:18 PM  [*] Started epoch: 3
01/28/2023 01:24:18 PM  [*] Sat Jan 28 13:24:18 2023: Train Epoch: 3 [  0  /76126 (0 %)]	Loss: 0.136714 | Elapsed: 0.16s | FPR 0.0003 -> TPR 0.8750 & F1 0.9333
01/28/2023 01:24:25 PM  [*] Sat Jan 28 13:24:25 2023: Train Epoch: 3 [6400 /76126 (8 %)]	Loss: 0.103838 | Elapsed: 6.44s | FPR 0.0003 -> TPR 0.8169 & F1 0.8992
01/28/2023 01:24:31 PM  [*] Sat Jan 28 13:24:31 2023: Train Epoch: 3 [12800/76126 (17%)]	Loss: 0.254647 | Elapsed: 6.36s | FPR 0.0003 -> TPR 0.5352 & F1 0.6972
01/28/2023 01:24:37 PM  [*] Sat Jan 28 13:24:37 2023: Train Epoch: 3 [19200/76126 (25%)]	Loss: 0.087285 | Elapsed: 6.36s | FPR 0.0003 -> TPR 0.8657 & F1 0.9280
01/28/2023 01:24:44 PM  [*] Sat Jan 28 13:24:44 2023: Train Epoch: 3 [25600/76126 (34%)]	Loss: 0.110746 | Elapsed: 6.37s | FPR 0.0003 -> TPR 0.9697 & F1 0.9846
01/28/2023 01:24:50 PM  [*] Sat Jan 28 13:24:50 2023: Train Epoch: 3 [32000/76126 (42%)]	Loss: 0.170073 | Elapsed: 6.36s | FPR 0.0003 -> TPR 0.7391 & F1 0.8500
01/28/2023 01:24:57 PM  [*] Sat Jan 28 13:24:57 2023: Train Epoch: 3 [38400/76126 (50%)]	Loss: 0.142210 | Elapsed: 6.36s | FPR 0.0003 -> TPR 0.8154 & F1 0.8983
01/28/2023 01:24:58 PM [!] Learning rate: 2.5000000000000004e-07
01/28/2023 01:25:03 PM  [*] Sat Jan 28 13:25:03 2023: Train Epoch: 3 [44800/76126 (59%)]	Loss: 0.073733 | Elapsed: 6.36s | FPR 0.0003 -> TPR 0.8472 & F1 0.9173
01/28/2023 01:25:09 PM  [*] Sat Jan 28 13:25:09 2023: Train Epoch: 3 [51200/76126 (67%)]	Loss: 0.206113 | Elapsed: 6.42s | FPR 0.0003 -> TPR 0.5538 & F1 0.7129
01/28/2023 01:25:16 PM  [*] Sat Jan 28 13:25:16 2023: Train Epoch: 3 [57600/76126 (76%)]	Loss: 0.136743 | Elapsed: 6.34s | FPR 0.0003 -> TPR 0.7183 & F1 0.8361
01/28/2023 01:25:22 PM  [*] Sat Jan 28 13:25:22 2023: Train Epoch: 3 [64000/76126 (84%)]	Loss: 0.145058 | Elapsed: 6.30s | FPR 0.0003 -> TPR 0.8983 & F1 0.9464
01/28/2023 01:25:28 PM  [*] Sat Jan 28 13:25:28 2023: Train Epoch: 3 [70400/76126 (92%)]	Loss: 0.081825 | Elapsed: 6.31s | FPR 0.0003 -> TPR 1.0000 & F1 1.0000
01/28/2023 01:25:36 PM  [*] Sat Jan 28 13:25:36 2023:    3    | Tr.loss: 0.160545 | Elapsed:   77.73  s | FPR 0.0003 -> TPR: 0.45 & F1: 0.62 | AUC: 0.9821
01/28/2023 01:25:36 PM [!] Sat Jan 28 13:25:36 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_full_data\training_files\1674908736-model.torch
		train time: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_full_data\training_files\1674908736-trainTime.npy
		train losses: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_full_data\training_files\1674908736-trainLosses.npy
		train AUC: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_full_data\training_files\1674908736-auc.npy
		train F1s : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_full_data\training_files\1674908736-trainF1s.npy
		train TPRs: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107\downstreamTask_full_data\training_files\1674908736-trainTPRs.npy
01/28/2023 01:25:36 PM  [*] Evaluating pretrained model on test set...
01/28/2023 01:25:41 PM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0696 | F1: 0.1301
01/28/2023 01:25:41 PM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1046 | F1: 0.1894
01/28/2023 01:25:41 PM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.2555 | F1: 0.4067
01/28/2023 01:25:41 PM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3523 | F1: 0.5201
01/28/2023 01:25:41 PM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.4844 | F1: 0.6490
01/28/2023 01:25:41 PM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.5753 | F1: 0.7188
01/28/2023 01:25:41 PM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.7273 | F1: 0.8026
01/28/2023 01:25:41 PM  [*] Evaluating non_pretrained model on test set...
01/28/2023 01:25:47 PM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0772 | F1: 0.1434
01/28/2023 01:25:47 PM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1603 | F1: 0.2762
01/28/2023 01:25:47 PM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.2114 | F1: 0.3488
01/28/2023 01:25:47 PM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.2544 | F1: 0.4048
01/28/2023 01:25:47 PM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3077 | F1: 0.4675
01/28/2023 01:25:47 PM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4465 | F1: 0.6066
01/28/2023 01:25:47 PM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.7276 | F1: 0.8029
01/28/2023 01:25:47 PM  [*] Evaluating full_data model on test set...
01/28/2023 01:25:52 PM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0915 | F1: 0.1676
01/28/2023 01:25:52 PM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.2508 | F1: 0.4009
01/28/2023 01:25:52 PM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.3482 | F1: 0.5162
01/28/2023 01:25:52 PM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3871 | F1: 0.5571
01/28/2023 01:25:52 PM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.4348 | F1: 0.6025
01/28/2023 01:25:52 PM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.5506 | F1: 0.6987
01/28/2023 01:25:52 PM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.7994 | F1: 0.8485
01/28/2023 01:25:52 PM  [!] Finished pre-training evaluation over 3 splits! Saved metrics to:
	C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.75_1674904107/metrics_MaskedLanguageModel_nSplits_3_limit_None.json
01/28/2023 08:49:05 PM  [!] Starting Masked Language Model evaluation over 3 splits!
01/28/2023 08:49:06 PM  [!] Loaded data and vocab. X train size: (76126, 512), X test size: (17407, 512), vocab size: 50002
01/28/2023 08:49:06 PM  [!] Initiating Self-Supervised Learning Pretraining
     Language Modeling MaskedLanguageModel
     Model TransformerEncoderLM with config:
	{'vocabSize': 50002, 'maxLen': 512, 'dModel': 64, 'nHeads': 8, 'dHidden': 256, 'nLayers': 2, 'numClasses': 1, 'hiddenNeurons': [64], 'dropout': 0.3}

01/28/2023 08:49:06 PM  [!] Running pre-training split 1/3
01/28/2023 08:49:09 PM  [!] Pre-training model...
01/28/2023 08:49:10 PM  [*] Masking sequences...
01/28/2023 08:49:48 PM  [*] Started epoch: 1
01/28/2023 08:49:51 PM  [*] Sat Jan 28 20:49:51 2023: Train Epoch: 1 [  0  /60900 (0 %)]	Loss: 469.091492 | Elapsed: 2.44s
01/28/2023 08:50:02 PM  [*] Sat Jan 28 20:50:02 2023: Train Epoch: 1 [6400 /60900 (11%)]	Loss: 240.311493 | Elapsed: 11.83s
01/28/2023 08:50:15 PM  [*] Sat Jan 28 20:50:15 2023: Train Epoch: 1 [12800/60900 (21%)]	Loss: 208.109116 | Elapsed: 12.20s
01/28/2023 08:50:27 PM  [*] Sat Jan 28 20:50:27 2023: Train Epoch: 1 [19200/60900 (32%)]	Loss: 216.385132 | Elapsed: 12.22s
01/28/2023 08:50:39 PM  [*] Sat Jan 28 20:50:39 2023: Train Epoch: 1 [25600/60900 (42%)]	Loss: 216.906372 | Elapsed: 12.22s
01/28/2023 08:50:51 PM  [*] Sat Jan 28 20:50:51 2023: Train Epoch: 1 [32000/60900 (53%)]	Loss: 227.256714 | Elapsed: 12.27s
01/28/2023 08:51:04 PM  [*] Sat Jan 28 20:51:04 2023: Train Epoch: 1 [38400/60900 (63%)]	Loss: 188.191376 | Elapsed: 12.33s
01/28/2023 08:51:16 PM  [*] Sat Jan 28 20:51:16 2023: Train Epoch: 1 [44800/60900 (74%)]	Loss: 211.565796 | Elapsed: 12.38s
01/28/2023 08:51:29 PM  [*] Sat Jan 28 20:51:29 2023: Train Epoch: 1 [51200/60900 (84%)]	Loss: 179.027771 | Elapsed: 12.61s
01/28/2023 08:51:41 PM  [*] Sat Jan 28 20:51:41 2023: Train Epoch: 1 [57600/60900 (95%)]	Loss: 192.293289 | Elapsed: 12.46s
01/28/2023 08:51:49 PM  [*] Sat Jan 28 20:51:49 2023:    1    | Tr.loss: 208.109996 | Elapsed:  121.11  s
01/28/2023 08:51:49 PM  [*] Started epoch: 2
01/28/2023 08:51:49 PM  [*] Sat Jan 28 20:51:49 2023: Train Epoch: 2 [  0  /60900 (0 %)]	Loss: 195.270142 | Elapsed: 0.12s
01/28/2023 08:52:02 PM  [*] Sat Jan 28 20:52:02 2023: Train Epoch: 2 [6400 /60900 (11%)]	Loss: 189.820648 | Elapsed: 12.35s
01/28/2023 08:52:14 PM  [*] Sat Jan 28 20:52:14 2023: Train Epoch: 2 [12800/60900 (21%)]	Loss: 187.030502 | Elapsed: 12.29s
01/28/2023 08:52:26 PM  [*] Sat Jan 28 20:52:26 2023: Train Epoch: 2 [19200/60900 (32%)]	Loss: 196.225449 | Elapsed: 12.27s
01/28/2023 08:52:39 PM  [*] Sat Jan 28 20:52:39 2023: Train Epoch: 2 [25600/60900 (42%)]	Loss: 181.772034 | Elapsed: 12.28s
01/28/2023 08:52:51 PM  [*] Sat Jan 28 20:52:51 2023: Train Epoch: 2 [32000/60900 (53%)]	Loss: 211.198059 | Elapsed: 12.33s
01/28/2023 08:53:03 PM  [*] Sat Jan 28 20:53:03 2023: Train Epoch: 2 [38400/60900 (63%)]	Loss: 197.110931 | Elapsed: 12.23s
01/28/2023 08:53:15 PM  [*] Sat Jan 28 20:53:15 2023: Train Epoch: 2 [44800/60900 (74%)]	Loss: 190.048462 | Elapsed: 12.29s
01/28/2023 08:53:28 PM  [*] Sat Jan 28 20:53:28 2023: Train Epoch: 2 [51200/60900 (84%)]	Loss: 187.196930 | Elapsed: 12.32s
01/28/2023 08:53:40 PM  [*] Sat Jan 28 20:53:40 2023: Train Epoch: 2 [57600/60900 (95%)]	Loss: 195.892273 | Elapsed: 12.24s
01/28/2023 08:53:48 PM  [*] Sat Jan 28 20:53:48 2023:    2    | Tr.loss: 187.372663 | Elapsed:  118.55  s
01/28/2023 08:53:48 PM  [*] Started epoch: 3
01/28/2023 08:53:48 PM  [*] Sat Jan 28 20:53:48 2023: Train Epoch: 3 [  0  /60900 (0 %)]	Loss: 186.276321 | Elapsed: 0.13s
01/28/2023 08:54:00 PM  [*] Sat Jan 28 20:54:00 2023: Train Epoch: 3 [6400 /60900 (11%)]	Loss: 173.417297 | Elapsed: 12.40s
01/28/2023 08:54:13 PM  [*] Sat Jan 28 20:54:13 2023: Train Epoch: 3 [12800/60900 (21%)]	Loss: 171.723404 | Elapsed: 12.64s
01/28/2023 08:54:25 PM  [*] Sat Jan 28 20:54:25 2023: Train Epoch: 3 [19200/60900 (32%)]	Loss: 161.070694 | Elapsed: 12.27s
01/28/2023 08:54:38 PM  [*] Sat Jan 28 20:54:38 2023: Train Epoch: 3 [25600/60900 (42%)]	Loss: 182.869537 | Elapsed: 12.24s
01/28/2023 08:54:50 PM  [*] Sat Jan 28 20:54:50 2023: Train Epoch: 3 [32000/60900 (53%)]	Loss: 191.009338 | Elapsed: 12.22s
01/28/2023 08:55:02 PM  [*] Sat Jan 28 20:55:02 2023: Train Epoch: 3 [38400/60900 (63%)]	Loss: 192.998734 | Elapsed: 12.25s
01/28/2023 08:55:14 PM  [*] Sat Jan 28 20:55:14 2023: Train Epoch: 3 [44800/60900 (74%)]	Loss: 179.786407 | Elapsed: 12.31s
01/28/2023 08:55:27 PM  [*] Sat Jan 28 20:55:27 2023: Train Epoch: 3 [51200/60900 (84%)]	Loss: 198.028290 | Elapsed: 12.39s
01/28/2023 08:55:39 PM  [*] Sat Jan 28 20:55:39 2023: Train Epoch: 3 [57600/60900 (95%)]	Loss: 147.659546 | Elapsed: 12.35s
01/28/2023 08:55:47 PM  [*] Sat Jan 28 20:55:47 2023:    3    | Tr.loss: 182.375064 | Elapsed:  119.47  s
01/28/2023 08:55:47 PM  [*] Started epoch: 4
01/28/2023 08:55:47 PM  [*] Sat Jan 28 20:55:47 2023: Train Epoch: 4 [  0  /60900 (0 %)]	Loss: 184.838593 | Elapsed: 0.13s
01/28/2023 08:56:00 PM  [*] Sat Jan 28 20:56:00 2023: Train Epoch: 4 [6400 /60900 (11%)]	Loss: 195.980347 | Elapsed: 12.52s
01/28/2023 08:56:12 PM  [*] Sat Jan 28 20:56:12 2023: Train Epoch: 4 [12800/60900 (21%)]	Loss: 177.724396 | Elapsed: 12.25s
01/28/2023 08:56:25 PM  [*] Sat Jan 28 20:56:25 2023: Train Epoch: 4 [19200/60900 (32%)]	Loss: 189.582031 | Elapsed: 12.25s
01/28/2023 08:56:37 PM  [*] Sat Jan 28 20:56:37 2023: Train Epoch: 4 [25600/60900 (42%)]	Loss: 179.756805 | Elapsed: 12.27s
01/28/2023 08:56:49 PM  [*] Sat Jan 28 20:56:49 2023: Train Epoch: 4 [32000/60900 (53%)]	Loss: 178.603119 | Elapsed: 12.22s
01/28/2023 08:57:01 PM  [*] Sat Jan 28 20:57:01 2023: Train Epoch: 4 [38400/60900 (63%)]	Loss: 173.041931 | Elapsed: 12.29s
01/28/2023 08:57:14 PM  [*] Sat Jan 28 20:57:14 2023: Train Epoch: 4 [44800/60900 (74%)]	Loss: 168.397217 | Elapsed: 12.22s
01/28/2023 08:57:26 PM  [*] Sat Jan 28 20:57:26 2023: Train Epoch: 4 [51200/60900 (84%)]	Loss: 162.836578 | Elapsed: 12.22s
01/28/2023 08:57:38 PM  [*] Sat Jan 28 20:57:38 2023: Train Epoch: 4 [57600/60900 (95%)]	Loss: 199.898651 | Elapsed: 12.27s
01/28/2023 08:57:46 PM  [*] Sat Jan 28 20:57:46 2023:    4    | Tr.loss: 179.775187 | Elapsed:  118.52  s
01/28/2023 08:57:46 PM  [*] Started epoch: 5
01/28/2023 08:57:46 PM  [*] Sat Jan 28 20:57:46 2023: Train Epoch: 5 [  0  /60900 (0 %)]	Loss: 180.514435 | Elapsed: 0.13s
01/28/2023 08:57:58 PM  [*] Sat Jan 28 20:57:58 2023: Train Epoch: 5 [6400 /60900 (11%)]	Loss: 198.891266 | Elapsed: 12.29s
01/28/2023 08:58:11 PM  [*] Sat Jan 28 20:58:11 2023: Train Epoch: 5 [12800/60900 (21%)]	Loss: 160.997528 | Elapsed: 12.30s
01/28/2023 08:58:23 PM  [*] Sat Jan 28 20:58:23 2023: Train Epoch: 5 [19200/60900 (32%)]	Loss: 176.177505 | Elapsed: 12.34s
01/28/2023 08:58:35 PM  [*] Sat Jan 28 20:58:35 2023: Train Epoch: 5 [25600/60900 (42%)]	Loss: 175.327393 | Elapsed: 12.25s
01/28/2023 08:58:48 PM  [*] Sat Jan 28 20:58:48 2023: Train Epoch: 5 [32000/60900 (53%)]	Loss: 197.674377 | Elapsed: 12.31s
01/28/2023 08:59:00 PM  [*] Sat Jan 28 20:59:00 2023: Train Epoch: 5 [38400/60900 (63%)]	Loss: 191.540573 | Elapsed: 12.31s
01/28/2023 08:59:12 PM  [*] Sat Jan 28 20:59:12 2023: Train Epoch: 5 [44800/60900 (74%)]	Loss: 164.040741 | Elapsed: 12.57s
01/28/2023 08:59:25 PM  [*] Sat Jan 28 20:59:25 2023: Train Epoch: 5 [51200/60900 (84%)]	Loss: 166.148956 | Elapsed: 12.33s
01/28/2023 08:59:37 PM  [*] Sat Jan 28 20:59:37 2023: Train Epoch: 5 [57600/60900 (95%)]	Loss: 161.545715 | Elapsed: 12.23s
01/28/2023 08:59:45 PM  [*] Sat Jan 28 20:59:45 2023:    5    | Tr.loss: 178.153164 | Elapsed:  118.84  s
01/28/2023 08:59:45 PM  [*] Started epoch: 6
01/28/2023 08:59:45 PM  [*] Sat Jan 28 20:59:45 2023: Train Epoch: 6 [  0  /60900 (0 %)]	Loss: 192.007095 | Elapsed: 0.14s
01/28/2023 08:59:57 PM  [*] Sat Jan 28 20:59:57 2023: Train Epoch: 6 [6400 /60900 (11%)]	Loss: 179.278320 | Elapsed: 12.30s
01/28/2023 09:00:10 PM  [*] Sat Jan 28 21:00:10 2023: Train Epoch: 6 [12800/60900 (21%)]	Loss: 185.540237 | Elapsed: 12.40s
01/28/2023 09:00:14 PM [!] Learning rate: 2.5e-05
01/28/2023 09:00:22 PM  [*] Sat Jan 28 21:00:22 2023: Train Epoch: 6 [19200/60900 (32%)]	Loss: 151.136215 | Elapsed: 12.28s
01/28/2023 09:00:34 PM  [*] Sat Jan 28 21:00:34 2023: Train Epoch: 6 [25600/60900 (42%)]	Loss: 179.824738 | Elapsed: 12.37s
01/28/2023 09:00:46 PM  [*] Sat Jan 28 21:00:46 2023: Train Epoch: 6 [32000/60900 (53%)]	Loss: 183.892776 | Elapsed: 12.23s
01/28/2023 09:00:59 PM  [*] Sat Jan 28 21:00:59 2023: Train Epoch: 6 [38400/60900 (63%)]	Loss: 162.800171 | Elapsed: 12.28s
01/28/2023 09:01:11 PM  [*] Sat Jan 28 21:01:11 2023: Train Epoch: 6 [44800/60900 (74%)]	Loss: 185.376129 | Elapsed: 12.19s
01/28/2023 09:01:23 PM  [*] Sat Jan 28 21:01:23 2023: Train Epoch: 6 [51200/60900 (84%)]	Loss: 181.768631 | Elapsed: 12.23s
01/28/2023 09:01:36 PM  [*] Sat Jan 28 21:01:36 2023: Train Epoch: 6 [57600/60900 (95%)]	Loss: 173.004150 | Elapsed: 12.31s
01/28/2023 09:01:43 PM  [*] Sat Jan 28 21:01:43 2023:    6    | Tr.loss: 176.698859 | Elapsed:  118.61  s
01/28/2023 09:01:43 PM  [*] Started epoch: 7
01/28/2023 09:01:43 PM  [*] Sat Jan 28 21:01:43 2023: Train Epoch: 7 [  0  /60900 (0 %)]	Loss: 171.929871 | Elapsed: 0.13s
01/28/2023 09:01:56 PM  [*] Sat Jan 28 21:01:56 2023: Train Epoch: 7 [6400 /60900 (11%)]	Loss: 157.998840 | Elapsed: 12.31s
01/28/2023 09:02:08 PM  [*] Sat Jan 28 21:02:08 2023: Train Epoch: 7 [12800/60900 (21%)]	Loss: 181.831863 | Elapsed: 12.25s
01/28/2023 09:02:20 PM  [*] Sat Jan 28 21:02:20 2023: Train Epoch: 7 [19200/60900 (32%)]	Loss: 181.989136 | Elapsed: 12.23s
01/28/2023 09:02:33 PM  [*] Sat Jan 28 21:02:33 2023: Train Epoch: 7 [25600/60900 (42%)]	Loss: 162.812531 | Elapsed: 12.24s
01/28/2023 09:02:45 PM  [*] Sat Jan 28 21:02:45 2023: Train Epoch: 7 [32000/60900 (53%)]	Loss: 157.306610 | Elapsed: 12.18s
01/28/2023 09:02:57 PM  [*] Sat Jan 28 21:02:57 2023: Train Epoch: 7 [38400/60900 (63%)]	Loss: 168.243652 | Elapsed: 12.19s
01/28/2023 09:03:09 PM  [*] Sat Jan 28 21:03:09 2023: Train Epoch: 7 [44800/60900 (74%)]	Loss: 196.470169 | Elapsed: 12.27s
01/28/2023 09:03:21 PM  [*] Sat Jan 28 21:03:21 2023: Train Epoch: 7 [51200/60900 (84%)]	Loss: 176.855621 | Elapsed: 12.21s
01/28/2023 09:03:34 PM  [*] Sat Jan 28 21:03:34 2023: Train Epoch: 7 [57600/60900 (95%)]	Loss: 164.087769 | Elapsed: 12.26s
01/28/2023 09:03:42 PM  [*] Sat Jan 28 21:03:42 2023:    7    | Tr.loss: 176.099375 | Elapsed:  118.16  s
01/28/2023 09:03:42 PM  [*] Started epoch: 8
01/28/2023 09:03:42 PM  [*] Sat Jan 28 21:03:42 2023: Train Epoch: 8 [  0  /60900 (0 %)]	Loss: 175.139694 | Elapsed: 0.12s
01/28/2023 09:03:54 PM  [*] Sat Jan 28 21:03:54 2023: Train Epoch: 8 [6400 /60900 (11%)]	Loss: 195.567078 | Elapsed: 12.38s
01/28/2023 09:04:06 PM  [*] Sat Jan 28 21:04:06 2023: Train Epoch: 8 [12800/60900 (21%)]	Loss: 189.368546 | Elapsed: 12.26s
01/28/2023 09:04:19 PM  [*] Sat Jan 28 21:04:19 2023: Train Epoch: 8 [19200/60900 (32%)]	Loss: 173.597900 | Elapsed: 12.63s
01/28/2023 09:04:31 PM  [*] Sat Jan 28 21:04:31 2023: Train Epoch: 8 [25600/60900 (42%)]	Loss: 164.461624 | Elapsed: 12.35s
01/28/2023 09:04:44 PM  [*] Sat Jan 28 21:04:44 2023: Train Epoch: 8 [32000/60900 (53%)]	Loss: 161.948685 | Elapsed: 12.42s
01/28/2023 09:04:56 PM  [*] Sat Jan 28 21:04:56 2023: Train Epoch: 8 [38400/60900 (63%)]	Loss: 165.170624 | Elapsed: 12.62s
01/28/2023 09:05:09 PM  [*] Sat Jan 28 21:05:09 2023: Train Epoch: 8 [44800/60900 (74%)]	Loss: 180.379593 | Elapsed: 12.56s
01/28/2023 09:05:21 PM  [*] Sat Jan 28 21:05:21 2023: Train Epoch: 8 [51200/60900 (84%)]	Loss: 186.605927 | Elapsed: 12.43s
01/28/2023 09:05:34 PM  [*] Sat Jan 28 21:05:34 2023: Train Epoch: 8 [57600/60900 (95%)]	Loss: 158.253784 | Elapsed: 12.56s
01/28/2023 09:05:42 PM  [*] Sat Jan 28 21:05:42 2023:    8    | Tr.loss: 175.916624 | Elapsed:  120.54  s
01/28/2023 09:05:42 PM  [*] Started epoch: 9
01/28/2023 09:05:42 PM  [*] Sat Jan 28 21:05:42 2023: Train Epoch: 9 [  0  /60900 (0 %)]	Loss: 171.190826 | Elapsed: 0.13s
01/28/2023 09:05:55 PM  [*] Sat Jan 28 21:05:55 2023: Train Epoch: 9 [6400 /60900 (11%)]	Loss: 168.508606 | Elapsed: 12.76s
01/28/2023 09:06:08 PM  [*] Sat Jan 28 21:06:08 2023: Train Epoch: 9 [12800/60900 (21%)]	Loss: 185.570282 | Elapsed: 12.89s
01/28/2023 09:06:20 PM  [*] Sat Jan 28 21:06:20 2023: Train Epoch: 9 [19200/60900 (32%)]	Loss: 179.861877 | Elapsed: 12.44s
01/28/2023 09:06:33 PM  [*] Sat Jan 28 21:06:33 2023: Train Epoch: 9 [25600/60900 (42%)]	Loss: 181.226044 | Elapsed: 12.75s
01/28/2023 09:06:46 PM  [*] Sat Jan 28 21:06:46 2023: Train Epoch: 9 [32000/60900 (53%)]	Loss: 170.116486 | Elapsed: 12.71s
01/28/2023 09:06:58 PM  [*] Sat Jan 28 21:06:58 2023: Train Epoch: 9 [38400/60900 (63%)]	Loss: 179.395538 | Elapsed: 12.65s
01/28/2023 09:07:11 PM  [*] Sat Jan 28 21:07:11 2023: Train Epoch: 9 [44800/60900 (74%)]	Loss: 179.753433 | Elapsed: 12.40s
01/28/2023 09:07:23 PM  [*] Sat Jan 28 21:07:23 2023: Train Epoch: 9 [51200/60900 (84%)]	Loss: 153.392578 | Elapsed: 12.37s
01/28/2023 09:07:36 PM  [*] Sat Jan 28 21:07:36 2023: Train Epoch: 9 [57600/60900 (95%)]	Loss: 184.873077 | Elapsed: 12.61s
01/28/2023 09:07:45 PM  [*] Sat Jan 28 21:07:45 2023:    9    | Tr.loss: 175.719999 | Elapsed:  122.62  s
01/28/2023 09:07:45 PM  [*] Started epoch: 10
01/28/2023 09:07:45 PM  [*] Sat Jan 28 21:07:45 2023: Train Epoch: 10 [  0  /60900 (0 %)]	Loss: 168.596497 | Elapsed: 0.24s
01/28/2023 09:07:58 PM  [*] Sat Jan 28 21:07:58 2023: Train Epoch: 10 [6400 /60900 (11%)]	Loss: 184.618134 | Elapsed: 13.12s
01/28/2023 09:08:11 PM  [*] Sat Jan 28 21:08:11 2023: Train Epoch: 10 [12800/60900 (21%)]	Loss: 168.457718 | Elapsed: 12.82s
01/28/2023 09:08:24 PM  [*] Sat Jan 28 21:08:24 2023: Train Epoch: 10 [19200/60900 (32%)]	Loss: 163.301361 | Elapsed: 12.78s
01/28/2023 09:08:37 PM  [*] Sat Jan 28 21:08:37 2023: Train Epoch: 10 [25600/60900 (42%)]	Loss: 162.023987 | Elapsed: 13.11s
01/28/2023 09:08:49 PM  [*] Sat Jan 28 21:08:49 2023: Train Epoch: 10 [32000/60900 (53%)]	Loss: 177.981323 | Elapsed: 12.62s
01/28/2023 09:09:02 PM  [*] Sat Jan 28 21:09:02 2023: Train Epoch: 10 [38400/60900 (63%)]	Loss: 207.111313 | Elapsed: 12.45s
01/28/2023 09:09:14 PM  [*] Sat Jan 28 21:09:14 2023: Train Epoch: 10 [44800/60900 (74%)]	Loss: 202.456253 | Elapsed: 12.47s
01/28/2023 09:09:27 PM  [*] Sat Jan 28 21:09:27 2023: Train Epoch: 10 [51200/60900 (84%)]	Loss: 171.791397 | Elapsed: 12.64s
01/28/2023 09:09:40 PM  [*] Sat Jan 28 21:09:40 2023: Train Epoch: 10 [57600/60900 (95%)]	Loss: 180.226562 | Elapsed: 12.76s
01/28/2023 09:09:48 PM  [*] Sat Jan 28 21:09:48 2023:   10    | Tr.loss: 175.541420 | Elapsed:  123.44  s
01/28/2023 09:09:49 PM [!] Sat Jan 28 21:09:49 2023: Dumped results:
                model     : 1674936588-model.torch
		train time: 1674936588-trainTime.npy
		train losses: 1674936588-trainLosses.npy
		train AUC: 1674936588-auc.npy
01/28/2023 09:09:51 PM  [!] Training pretrained model on downstream task...
01/28/2023 09:09:51 PM  [*] Started epoch: 1
01/28/2023 09:09:51 PM  [*] Sat Jan 28 21:09:51 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 2.984851 | Elapsed: 0.41s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.2284
01/28/2023 09:10:00 PM  [*] Sat Jan 28 21:10:00 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.369415 | Elapsed: 9.23s | FPR 0.0003 -> TPR 0.0556 & F1 0.1053 | AUC 0.8755
01/28/2023 09:10:10 PM  [*] Sat Jan 28 21:10:10 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.390096 | Elapsed: 9.31s | FPR 0.0003 -> TPR 0.2727 & F1 0.4286 | AUC 0.8895
01/28/2023 09:10:14 PM  [*] Sat Jan 28 21:10:14 2023:    1    | Tr.loss: 0.485224 | Elapsed:   22.82  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8227
01/28/2023 09:10:14 PM  [*] Started epoch: 2
01/28/2023 09:10:14 PM  [*] Sat Jan 28 21:10:14 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.415376 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.3636 & F1 0.5333 | AUC 0.8466
01/28/2023 09:10:23 PM  [*] Sat Jan 28 21:10:23 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.304341 | Elapsed: 9.17s | FPR 0.0003 -> TPR 0.5968 & F1 0.7475 | AUC 0.9605
01/28/2023 09:10:32 PM  [*] Sat Jan 28 21:10:32 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.358845 | Elapsed: 9.20s | FPR 0.0003 -> TPR 0.3803 & F1 0.5510 | AUC 0.9043
01/28/2023 09:10:36 PM  [*] Sat Jan 28 21:10:36 2023:    2    | Tr.loss: 0.312856 | Elapsed:   22.41  s | FPR 0.0003 -> TPR: 0.19 & F1: 0.32 | AUC: 0.9275
01/28/2023 09:10:36 PM  [*] Started epoch: 3
01/28/2023 09:10:36 PM  [*] Sat Jan 28 21:10:36 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.269032 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.7045 & F1 0.8267 | AUC 0.9477
01/28/2023 09:10:45 PM  [*] Sat Jan 28 21:10:45 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.258447 | Elapsed: 9.28s | FPR 0.0003 -> TPR 0.4429 & F1 0.6139 | AUC 0.9500
01/28/2023 09:10:55 PM  [*] Sat Jan 28 21:10:55 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.190419 | Elapsed: 9.20s | FPR 0.0003 -> TPR 0.8116 & F1 0.8960 | AUC 0.9850
01/28/2023 09:10:58 PM  [*] Sat Jan 28 21:10:58 2023:    3    | Tr.loss: 0.224622 | Elapsed:   22.42  s | FPR 0.0003 -> TPR: 0.24 & F1: 0.38 | AUC: 0.9651
01/28/2023 09:10:59 PM [!] Sat Jan 28 21:10:59 2023: Dumped results:
                model     : 1674936658-model.torch
		train time: 1674936658-trainTime.npy
		train losses: 1674936658-trainLosses.npy
		train AUC: 1674936658-auc.npy
		train F1s : 1674936658-trainF1s.npy
		train TPRs: 1674936658-trainTPRs.npy
01/28/2023 09:10:59 PM  [!] Training non_pretrained model on downstream task...
01/28/2023 09:10:59 PM  [*] Started epoch: 1
01/28/2023 09:10:59 PM  [*] Sat Jan 28 21:10:59 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 1.498856 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0227 & F1 0.0444 | AUC 0.5545
01/28/2023 09:11:06 PM  [*] Sat Jan 28 21:11:06 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.406776 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.1286 & F1 0.2278 | AUC 0.7990
01/28/2023 09:11:12 PM  [*] Sat Jan 28 21:11:12 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.319919 | Elapsed: 6.28s | FPR 0.0003 -> TPR 0.6970 & F1 0.8214 | AUC 0.9358
01/28/2023 09:11:15 PM  [*] Sat Jan 28 21:11:15 2023:    1    | Tr.loss: 0.476109 | Elapsed:   15.21  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8235
01/28/2023 09:11:15 PM  [*] Started epoch: 2
01/28/2023 09:11:15 PM  [*] Sat Jan 28 21:11:15 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.289229 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.5600 & F1 0.7179 | AUC 0.9529
01/28/2023 09:11:21 PM  [*] Sat Jan 28 21:11:21 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.305056 | Elapsed: 6.29s | FPR 0.0003 -> TPR 0.5000 & F1 0.6667 | AUC 0.9380
01/28/2023 09:11:27 PM  [*] Sat Jan 28 21:11:27 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.260762 | Elapsed: 6.29s | FPR 0.0003 -> TPR 0.6250 & F1 0.7692 | AUC 0.9425
01/28/2023 09:11:30 PM  [*] Sat Jan 28 21:11:30 2023:    2    | Tr.loss: 0.305731 | Elapsed:   15.39  s | FPR 0.0003 -> TPR: 0.20 & F1: 0.33 | AUC: 0.9302
01/28/2023 09:11:30 PM  [*] Started epoch: 3
01/28/2023 09:11:30 PM  [*] Sat Jan 28 21:11:30 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.202179 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.8571 & F1 0.9231 | AUC 0.9816
01/28/2023 09:11:36 PM  [*] Sat Jan 28 21:11:36 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.168889 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.8611 & F1 0.9254 | AUC 0.9836
01/28/2023 09:11:43 PM  [*] Sat Jan 28 21:11:43 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.211778 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.8209 & F1 0.9016 | AUC 0.9765
01/28/2023 09:11:45 PM  [*] Sat Jan 28 21:11:45 2023:    3    | Tr.loss: 0.234873 | Elapsed:   15.24  s | FPR 0.0003 -> TPR: 0.36 & F1: 0.53 | AUC: 0.9607
01/28/2023 09:11:46 PM [!] Sat Jan 28 21:11:46 2023: Dumped results:
                model     : 1674936705-model.torch
		train time: 1674936705-trainTime.npy
		train losses: 1674936705-trainLosses.npy
		train AUC: 1674936705-auc.npy
		train F1s : 1674936705-trainF1s.npy
		train TPRs: 1674936705-trainTPRs.npy
01/28/2023 09:11:46 PM  [!] Training full_data model on downstream task...
01/28/2023 09:11:46 PM  [*] Started epoch: 1
01/28/2023 09:11:46 PM  [*] Sat Jan 28 21:11:46 2023: Train Epoch: 1 [  0  /76126 (0 %)]	Loss: 2.969193 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.3943
01/28/2023 09:11:53 PM  [*] Sat Jan 28 21:11:53 2023: Train Epoch: 1 [6400 /76126 (8 %)]	Loss: 0.435645 | Elapsed: 6.32s | FPR 0.0003 -> TPR 0.3448 & F1 0.5128 | AUC 0.8793
01/28/2023 09:11:59 PM  [*] Sat Jan 28 21:11:59 2023: Train Epoch: 1 [12800/76126 (17%)]	Loss: 0.450618 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.3333 & F1 0.5000 | AUC 0.8433
01/28/2023 09:12:05 PM  [*] Sat Jan 28 21:12:05 2023: Train Epoch: 1 [19200/76126 (25%)]	Loss: 0.288608 | Elapsed: 6.28s | FPR 0.0003 -> TPR 0.4394 & F1 0.6105 | AUC 0.9002
01/28/2023 09:12:12 PM  [*] Sat Jan 28 21:12:12 2023: Train Epoch: 1 [25600/76126 (34%)]	Loss: 0.396160 | Elapsed: 6.50s | FPR 0.0003 -> TPR 0.5968 & F1 0.7475 | AUC 0.9376
01/28/2023 09:12:18 PM  [*] Sat Jan 28 21:12:18 2023: Train Epoch: 1 [32000/76126 (42%)]	Loss: 0.181047 | Elapsed: 6.35s | FPR 0.0003 -> TPR 0.8143 & F1 0.8976 | AUC 0.9590
01/28/2023 09:12:24 PM  [*] Sat Jan 28 21:12:24 2023: Train Epoch: 1 [38400/76126 (50%)]	Loss: 0.321757 | Elapsed: 6.38s | FPR 0.0003 -> TPR 0.4923 & F1 0.6598 | AUC 0.9420
01/28/2023 09:12:31 PM  [*] Sat Jan 28 21:12:31 2023: Train Epoch: 1 [44800/76126 (59%)]	Loss: 0.191929 | Elapsed: 6.44s | FPR 0.0003 -> TPR 0.8889 & F1 0.9412 | AUC 0.9782
01/28/2023 09:12:37 PM  [*] Sat Jan 28 21:12:37 2023: Train Epoch: 1 [51200/76126 (67%)]	Loss: 0.339696 | Elapsed: 6.51s | FPR 0.0003 -> TPR 0.5667 & F1 0.7234 | AUC 0.9225
01/28/2023 09:12:44 PM  [*] Sat Jan 28 21:12:44 2023: Train Epoch: 1 [57600/76126 (76%)]	Loss: 0.177666 | Elapsed: 6.32s | FPR 0.0003 -> TPR 0.8235 & F1 0.9032 | AUC 0.9825
01/28/2023 09:12:50 PM [!] Learning rate: 2.5e-05
01/28/2023 09:12:50 PM  [*] Sat Jan 28 21:12:50 2023: Train Epoch: 1 [64000/76126 (84%)]	Loss: 0.149225 | Elapsed: 6.37s | FPR 0.0003 -> TPR 0.7656 & F1 0.8673 | AUC 0.9857
01/28/2023 09:12:57 PM  [*] Sat Jan 28 21:12:57 2023: Train Epoch: 1 [70400/76126 (92%)]	Loss: 0.125621 | Elapsed: 6.44s | FPR 0.0003 -> TPR 0.9565 & F1 0.9778 | AUC 0.9878
01/28/2023 09:13:04 PM  [*] Sat Jan 28 21:13:04 2023:    1    | Tr.loss: 0.300271 | Elapsed:   78.09  s | FPR 0.0003 -> TPR: 0.04 & F1: 0.07 | AUC: 0.9342
01/28/2023 09:13:04 PM  [*] Started epoch: 2
01/28/2023 09:13:04 PM  [*] Sat Jan 28 21:13:04 2023: Train Epoch: 2 [  0  /76126 (0 %)]	Loss: 0.167234 | Elapsed: 0.13s | FPR 0.0003 -> TPR 0.9070 & F1 0.9512 | AUC 0.9845
01/28/2023 09:13:11 PM  [*] Sat Jan 28 21:13:11 2023: Train Epoch: 2 [6400 /76126 (8 %)]	Loss: 0.287430 | Elapsed: 6.46s | FPR 0.0003 -> TPR 0.3158 & F1 0.4800 | AUC 0.9645
01/28/2023 09:13:17 PM  [*] Sat Jan 28 21:13:17 2023: Train Epoch: 2 [12800/76126 (17%)]	Loss: 0.152759 | Elapsed: 6.30s | FPR 0.0003 -> TPR 0.8594 & F1 0.9244 | AUC 0.9896
01/28/2023 09:13:24 PM  [*] Sat Jan 28 21:13:24 2023: Train Epoch: 2 [19200/76126 (25%)]	Loss: 0.110418 | Elapsed: 6.37s | FPR 0.0003 -> TPR 0.8788 & F1 0.9355 | AUC 0.9947
01/28/2023 09:13:30 PM  [*] Sat Jan 28 21:13:30 2023: Train Epoch: 2 [25600/76126 (34%)]	Loss: 0.080482 | Elapsed: 6.40s | FPR 0.0003 -> TPR 0.9697 & F1 0.9846 | AUC 0.9982
01/28/2023 09:13:36 PM  [*] Sat Jan 28 21:13:36 2023: Train Epoch: 2 [32000/76126 (42%)]	Loss: 0.179731 | Elapsed: 6.45s | FPR 0.0003 -> TPR 0.6769 & F1 0.8073 | AUC 0.9727
01/28/2023 09:13:43 PM  [*] Sat Jan 28 21:13:43 2023: Train Epoch: 2 [38400/76126 (50%)]	Loss: 0.152045 | Elapsed: 6.47s | FPR 0.0003 -> TPR 0.8413 & F1 0.9138 | AUC 0.9820
01/28/2023 09:13:49 PM  [*] Sat Jan 28 21:13:49 2023: Train Epoch: 2 [44800/76126 (59%)]	Loss: 0.148124 | Elapsed: 6.44s | FPR 0.0003 -> TPR 0.9231 & F1 0.9600 | AUC 0.9886
01/28/2023 09:13:56 PM  [*] Sat Jan 28 21:13:56 2023: Train Epoch: 2 [51200/76126 (67%)]	Loss: 0.149513 | Elapsed: 6.41s | FPR 0.0003 -> TPR 0.9000 & F1 0.9474 | AUC 0.9890
01/28/2023 09:13:56 PM [!] Learning rate: 2.5e-06
01/28/2023 09:14:02 PM  [*] Sat Jan 28 21:14:02 2023: Train Epoch: 2 [57600/76126 (76%)]	Loss: 0.173717 | Elapsed: 6.42s | FPR 0.0003 -> TPR 0.8308 & F1 0.9076 | AUC 0.9785
01/28/2023 09:14:09 PM  [*] Sat Jan 28 21:14:09 2023: Train Epoch: 2 [64000/76126 (84%)]	Loss: 0.088151 | Elapsed: 6.52s | FPR 0.0003 -> TPR 0.9857 & F1 0.9928 | AUC 0.9986
01/28/2023 09:14:15 PM  [*] Sat Jan 28 21:14:15 2023: Train Epoch: 2 [70400/76126 (92%)]	Loss: 0.156817 | Elapsed: 6.36s | FPR 0.0003 -> TPR 0.8056 & F1 0.8923 | AUC 0.9802
01/28/2023 09:14:23 PM  [*] Sat Jan 28 21:14:23 2023:    2    | Tr.loss: 0.164339 | Elapsed:   78.50  s | FPR 0.0003 -> TPR: 0.43 & F1: 0.60 | AUC: 0.9813
01/28/2023 09:14:23 PM  [*] Started epoch: 3
01/28/2023 09:14:23 PM  [*] Sat Jan 28 21:14:23 2023: Train Epoch: 3 [  0  /76126 (0 %)]	Loss: 0.126761 | Elapsed: 0.13s | FPR 0.0003 -> TPR 0.9792 & F1 0.9895 | AUC 0.9948
01/28/2023 09:14:29 PM  [*] Sat Jan 28 21:14:29 2023: Train Epoch: 3 [6400 /76126 (8 %)]	Loss: 0.127768 | Elapsed: 6.43s | FPR 0.0003 -> TPR 0.7059 & F1 0.8276 | AUC 0.9816
01/28/2023 09:14:36 PM  [*] Sat Jan 28 21:14:36 2023: Train Epoch: 3 [12800/76126 (17%)]	Loss: 0.119220 | Elapsed: 6.38s | FPR 0.0003 -> TPR 0.9016 & F1 0.9483 | AUC 0.9916
01/28/2023 09:14:42 PM  [*] Sat Jan 28 21:14:42 2023: Train Epoch: 3 [19200/76126 (25%)]	Loss: 0.182378 | Elapsed: 6.34s | FPR 0.0003 -> TPR 0.7887 & F1 0.8819 | AUC 0.9757
01/28/2023 09:14:49 PM  [*] Sat Jan 28 21:14:49 2023: Train Epoch: 3 [25600/76126 (34%)]	Loss: 0.135295 | Elapsed: 6.46s | FPR 0.0003 -> TPR 0.6567 & F1 0.7928 | AUC 0.9783
01/28/2023 09:14:55 PM  [*] Sat Jan 28 21:14:55 2023: Train Epoch: 3 [32000/76126 (42%)]	Loss: 0.056553 | Elapsed: 6.44s | FPR 0.0003 -> TPR 0.5970 & F1 0.7477 | AUC 0.9878
01/28/2023 09:15:01 PM  [*] Sat Jan 28 21:15:01 2023: Train Epoch: 3 [38400/76126 (50%)]	Loss: 0.150835 | Elapsed: 6.40s | FPR 0.0003 -> TPR 0.9032 & F1 0.9492 | AUC 0.9834
01/28/2023 09:15:03 PM [!] Learning rate: 2.5000000000000004e-07
01/28/2023 09:15:08 PM  [*] Sat Jan 28 21:15:08 2023: Train Epoch: 3 [44800/76126 (59%)]	Loss: 0.114990 | Elapsed: 6.33s | FPR 0.0003 -> TPR 0.9138 & F1 0.9550 | AUC 0.9893
01/28/2023 09:15:14 PM  [*] Sat Jan 28 21:15:14 2023: Train Epoch: 3 [51200/76126 (67%)]	Loss: 0.303236 | Elapsed: 6.43s | FPR 0.0003 -> TPR 0.6892 & F1 0.8160 | AUC 0.9381
01/28/2023 09:15:21 PM  [*] Sat Jan 28 21:15:21 2023: Train Epoch: 3 [57600/76126 (76%)]	Loss: 0.292520 | Elapsed: 6.36s | FPR 0.0003 -> TPR 0.8143 & F1 0.8976 | AUC 0.9729
01/28/2023 09:15:27 PM  [*] Sat Jan 28 21:15:27 2023: Train Epoch: 3 [64000/76126 (84%)]	Loss: 0.133719 | Elapsed: 6.44s | FPR 0.0003 -> TPR 0.9200 & F1 0.9583 | AUC 0.9904
01/28/2023 09:15:33 PM  [*] Sat Jan 28 21:15:33 2023: Train Epoch: 3 [70400/76126 (92%)]	Loss: 0.148210 | Elapsed: 6.34s | FPR 0.0003 -> TPR 0.7581 & F1 0.8624 | AUC 0.9762
01/28/2023 09:15:41 PM  [*] Sat Jan 28 21:15:41 2023:    3    | Tr.loss: 0.159174 | Elapsed:   78.23  s | FPR 0.0003 -> TPR: 0.46 & F1: 0.63 | AUC: 0.9824
01/28/2023 09:15:41 PM [!] Sat Jan 28 21:15:41 2023: Dumped results:
                model     : 1674936941-model.torch
		train time: 1674936941-trainTime.npy
		train losses: 1674936941-trainLosses.npy
		train AUC: 1674936941-auc.npy
		train F1s : 1674936941-trainF1s.npy
		train TPRs: 1674936941-trainTPRs.npy
01/28/2023 09:15:41 PM  [*] Evaluating pretrained model on test set...
01/28/2023 09:15:47 PM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0764 | F1: 0.1419
01/28/2023 09:15:47 PM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1067 | F1: 0.1927
01/28/2023 09:15:47 PM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.3393 | F1: 0.5063
01/28/2023 09:15:47 PM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3782 | F1: 0.5478
01/28/2023 09:15:47 PM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.4490 | F1: 0.6161
01/28/2023 09:15:47 PM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.5214 | F1: 0.6741
01/28/2023 09:15:47 PM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.7745 | F1: 0.8330
01/28/2023 09:15:47 PM  [*] Evaluating non_pretrained model on test set...
01/28/2023 09:15:52 PM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0489 | F1: 0.0933
01/28/2023 09:15:52 PM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.2364 | F1: 0.3824
01/28/2023 09:15:52 PM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.2941 | F1: 0.4542
01/28/2023 09:15:52 PM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3194 | F1: 0.4832
01/28/2023 09:15:52 PM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3489 | F1: 0.5141
01/28/2023 09:15:52 PM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4805 | F1: 0.6381
01/28/2023 09:15:52 PM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.6917 | F1: 0.7786
01/28/2023 09:15:52 PM  [*] Evaluating full_data model on test set...
01/28/2023 09:15:57 PM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0239 | F1: 0.0467
01/28/2023 09:15:57 PM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.2442 | F1: 0.3924
01/28/2023 09:15:57 PM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.2975 | F1: 0.4582
01/28/2023 09:15:57 PM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3944 | F1: 0.5647
01/28/2023 09:15:57 PM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.4804 | F1: 0.6453
01/28/2023 09:15:57 PM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.5580 | F1: 0.7048
01/28/2023 09:15:57 PM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.7942 | F1: 0.8452
01/28/2023 09:15:57 PM  [!] Running pre-training split 2/3
01/28/2023 09:16:00 PM  [!] Pre-training model...
01/28/2023 09:16:01 PM  [*] Masking sequences...
01/28/2023 09:16:22 PM  [*] Started epoch: 1
01/28/2023 09:16:22 PM  [*] Sat Jan 28 21:16:22 2023: Train Epoch: 1 [  0  /60900 (0 %)]	Loss: 435.446075 | Elapsed: 0.31s
01/28/2023 09:16:35 PM  [*] Sat Jan 28 21:16:35 2023: Train Epoch: 1 [6400 /60900 (11%)]	Loss: 226.045090 | Elapsed: 12.59s
01/28/2023 09:16:47 PM  [*] Sat Jan 28 21:16:47 2023: Train Epoch: 1 [12800/60900 (21%)]	Loss: 226.207672 | Elapsed: 12.79s
01/28/2023 09:17:00 PM  [*] Sat Jan 28 21:17:00 2023: Train Epoch: 1 [19200/60900 (32%)]	Loss: 216.042465 | Elapsed: 12.86s
01/28/2023 09:17:13 PM  [*] Sat Jan 28 21:17:13 2023: Train Epoch: 1 [25600/60900 (42%)]	Loss: 219.860199 | Elapsed: 12.89s
01/28/2023 09:17:26 PM  [*] Sat Jan 28 21:17:26 2023: Train Epoch: 1 [32000/60900 (53%)]	Loss: 194.978363 | Elapsed: 12.71s
01/28/2023 09:17:39 PM  [*] Sat Jan 28 21:17:39 2023: Train Epoch: 1 [38400/60900 (63%)]	Loss: 204.743317 | Elapsed: 12.86s
01/28/2023 09:17:51 PM  [*] Sat Jan 28 21:17:51 2023: Train Epoch: 1 [44800/60900 (74%)]	Loss: 224.135284 | Elapsed: 12.73s
01/28/2023 09:18:04 PM  [*] Sat Jan 28 21:18:04 2023: Train Epoch: 1 [51200/60900 (84%)]	Loss: 209.305237 | Elapsed: 12.89s
01/28/2023 09:18:17 PM  [*] Sat Jan 28 21:18:17 2023: Train Epoch: 1 [57600/60900 (95%)]	Loss: 198.402390 | Elapsed: 12.75s
01/28/2023 09:18:26 PM  [*] Sat Jan 28 21:18:26 2023:    1    | Tr.loss: 213.038528 | Elapsed:  123.88  s
01/28/2023 09:18:26 PM  [*] Started epoch: 2
01/28/2023 09:18:26 PM  [*] Sat Jan 28 21:18:26 2023: Train Epoch: 2 [  0  /60900 (0 %)]	Loss: 197.044983 | Elapsed: 0.14s
01/28/2023 09:18:39 PM  [*] Sat Jan 28 21:18:39 2023: Train Epoch: 2 [6400 /60900 (11%)]	Loss: 190.112427 | Elapsed: 13.00s
01/28/2023 09:18:52 PM  [*] Sat Jan 28 21:18:52 2023: Train Epoch: 2 [12800/60900 (21%)]	Loss: 208.764420 | Elapsed: 12.98s
01/28/2023 09:19:05 PM  [*] Sat Jan 28 21:19:05 2023: Train Epoch: 2 [19200/60900 (32%)]	Loss: 182.935120 | Elapsed: 12.96s
01/28/2023 09:19:18 PM  [*] Sat Jan 28 21:19:18 2023: Train Epoch: 2 [25600/60900 (42%)]	Loss: 172.260727 | Elapsed: 12.89s
01/28/2023 09:19:30 PM  [*] Sat Jan 28 21:19:30 2023: Train Epoch: 2 [32000/60900 (53%)]	Loss: 188.214539 | Elapsed: 12.74s
01/28/2023 09:19:43 PM  [*] Sat Jan 28 21:19:43 2023: Train Epoch: 2 [38400/60900 (63%)]	Loss: 187.897888 | Elapsed: 12.97s
01/28/2023 09:19:56 PM  [*] Sat Jan 28 21:19:56 2023: Train Epoch: 2 [44800/60900 (74%)]	Loss: 217.668091 | Elapsed: 12.82s
01/28/2023 09:20:09 PM  [*] Sat Jan 28 21:20:09 2023: Train Epoch: 2 [51200/60900 (84%)]	Loss: 190.243271 | Elapsed: 12.57s
01/28/2023 09:20:22 PM  [*] Sat Jan 28 21:20:22 2023: Train Epoch: 2 [57600/60900 (95%)]	Loss: 181.937042 | Elapsed: 13.09s
01/28/2023 09:20:30 PM  [*] Sat Jan 28 21:20:30 2023:    2    | Tr.loss: 193.056773 | Elapsed:  124.64  s
01/28/2023 09:20:30 PM  [*] Started epoch: 3
01/28/2023 09:20:30 PM  [*] Sat Jan 28 21:20:30 2023: Train Epoch: 3 [  0  /60900 (0 %)]	Loss: 172.750534 | Elapsed: 0.24s
01/28/2023 09:20:43 PM  [*] Sat Jan 28 21:20:43 2023: Train Epoch: 3 [6400 /60900 (11%)]	Loss: 171.911591 | Elapsed: 12.97s
01/28/2023 09:20:56 PM  [*] Sat Jan 28 21:20:56 2023: Train Epoch: 3 [12800/60900 (21%)]	Loss: 221.235062 | Elapsed: 13.04s
01/28/2023 09:21:10 PM  [*] Sat Jan 28 21:21:10 2023: Train Epoch: 3 [19200/60900 (32%)]	Loss: 163.035828 | Elapsed: 13.13s
01/28/2023 09:21:23 PM  [*] Sat Jan 28 21:21:23 2023: Train Epoch: 3 [25600/60900 (42%)]	Loss: 179.296234 | Elapsed: 13.00s
01/28/2023 09:21:36 PM  [*] Sat Jan 28 21:21:36 2023: Train Epoch: 3 [32000/60900 (53%)]	Loss: 167.987091 | Elapsed: 13.26s
01/28/2023 09:21:49 PM  [*] Sat Jan 28 21:21:49 2023: Train Epoch: 3 [38400/60900 (63%)]	Loss: 181.242218 | Elapsed: 13.29s
01/28/2023 09:22:02 PM  [*] Sat Jan 28 21:22:02 2023: Train Epoch: 3 [44800/60900 (74%)]	Loss: 190.202484 | Elapsed: 13.03s
01/28/2023 09:22:15 PM  [*] Sat Jan 28 21:22:15 2023: Train Epoch: 3 [51200/60900 (84%)]	Loss: 182.265228 | Elapsed: 12.85s
01/28/2023 09:22:28 PM  [*] Sat Jan 28 21:22:28 2023: Train Epoch: 3 [57600/60900 (95%)]	Loss: 192.415085 | Elapsed: 12.93s
01/28/2023 09:22:36 PM  [*] Sat Jan 28 21:22:36 2023:    3    | Tr.loss: 187.371175 | Elapsed:  126.06  s
01/28/2023 09:22:36 PM  [*] Started epoch: 4
01/28/2023 09:22:36 PM  [*] Sat Jan 28 21:22:36 2023: Train Epoch: 4 [  0  /60900 (0 %)]	Loss: 200.830414 | Elapsed: 0.14s
01/28/2023 09:22:49 PM  [*] Sat Jan 28 21:22:49 2023: Train Epoch: 4 [6400 /60900 (11%)]	Loss: 170.738922 | Elapsed: 13.06s
01/28/2023 09:23:02 PM  [*] Sat Jan 28 21:23:02 2023: Train Epoch: 4 [12800/60900 (21%)]	Loss: 207.954956 | Elapsed: 12.92s
01/28/2023 09:23:15 PM  [*] Sat Jan 28 21:23:15 2023: Train Epoch: 4 [19200/60900 (32%)]	Loss: 189.972778 | Elapsed: 12.84s
01/28/2023 09:23:29 PM  [*] Sat Jan 28 21:23:29 2023: Train Epoch: 4 [25600/60900 (42%)]	Loss: 178.284882 | Elapsed: 13.39s
01/28/2023 09:23:42 PM  [*] Sat Jan 28 21:23:42 2023: Train Epoch: 4 [32000/60900 (53%)]	Loss: 169.679901 | Elapsed: 13.45s
01/28/2023 09:23:56 PM  [*] Sat Jan 28 21:23:56 2023: Train Epoch: 4 [38400/60900 (63%)]	Loss: 186.066345 | Elapsed: 13.59s
01/28/2023 09:24:09 PM  [*] Sat Jan 28 21:24:09 2023: Train Epoch: 4 [44800/60900 (74%)]	Loss: 185.400955 | Elapsed: 13.21s
01/28/2023 09:24:22 PM  [*] Sat Jan 28 21:24:22 2023: Train Epoch: 4 [51200/60900 (84%)]	Loss: 196.632721 | Elapsed: 13.30s
01/28/2023 09:24:35 PM  [*] Sat Jan 28 21:24:35 2023: Train Epoch: 4 [57600/60900 (95%)]	Loss: 181.843506 | Elapsed: 13.09s
01/28/2023 09:24:44 PM  [*] Sat Jan 28 21:24:44 2023:    4    | Tr.loss: 184.630062 | Elapsed:  127.55  s
01/28/2023 09:24:44 PM  [*] Started epoch: 5
01/28/2023 09:24:44 PM  [*] Sat Jan 28 21:24:44 2023: Train Epoch: 5 [  0  /60900 (0 %)]	Loss: 196.601852 | Elapsed: 0.15s
01/28/2023 09:24:57 PM  [*] Sat Jan 28 21:24:57 2023: Train Epoch: 5 [6400 /60900 (11%)]	Loss: 177.201935 | Elapsed: 13.00s
01/28/2023 09:25:10 PM  [*] Sat Jan 28 21:25:10 2023: Train Epoch: 5 [12800/60900 (21%)]	Loss: 189.377975 | Elapsed: 12.92s
01/28/2023 09:25:23 PM  [*] Sat Jan 28 21:25:23 2023: Train Epoch: 5 [19200/60900 (32%)]	Loss: 174.877106 | Elapsed: 12.86s
01/28/2023 09:25:36 PM  [*] Sat Jan 28 21:25:36 2023: Train Epoch: 5 [25600/60900 (42%)]	Loss: 177.828949 | Elapsed: 13.04s
01/28/2023 09:25:49 PM  [*] Sat Jan 28 21:25:49 2023: Train Epoch: 5 [32000/60900 (53%)]	Loss: 182.573959 | Elapsed: 13.25s
01/28/2023 09:26:02 PM  [*] Sat Jan 28 21:26:02 2023: Train Epoch: 5 [38400/60900 (63%)]	Loss: 184.400467 | Elapsed: 12.69s
01/28/2023 09:26:14 PM  [*] Sat Jan 28 21:26:14 2023: Train Epoch: 5 [44800/60900 (74%)]	Loss: 211.996292 | Elapsed: 12.51s
01/28/2023 09:26:27 PM  [*] Sat Jan 28 21:26:27 2023: Train Epoch: 5 [51200/60900 (84%)]	Loss: 191.574982 | Elapsed: 12.76s
01/28/2023 09:26:40 PM  [*] Sat Jan 28 21:26:40 2023: Train Epoch: 5 [57600/60900 (95%)]	Loss: 173.640015 | Elapsed: 12.96s
01/28/2023 09:26:48 PM  [*] Sat Jan 28 21:26:48 2023:    5    | Tr.loss: 183.112465 | Elapsed:  124.40  s
01/28/2023 09:26:48 PM  [*] Started epoch: 6
01/28/2023 09:26:48 PM  [*] Sat Jan 28 21:26:48 2023: Train Epoch: 6 [  0  /60900 (0 %)]	Loss: 186.770874 | Elapsed: 0.22s
01/28/2023 09:27:02 PM  [*] Sat Jan 28 21:27:02 2023: Train Epoch: 6 [6400 /60900 (11%)]	Loss: 179.417664 | Elapsed: 13.27s
01/28/2023 09:27:15 PM  [*] Sat Jan 28 21:27:15 2023: Train Epoch: 6 [12800/60900 (21%)]	Loss: 167.893311 | Elapsed: 12.86s
01/28/2023 09:27:19 PM [!] Learning rate: 2.5e-05
01/28/2023 09:27:27 PM  [*] Sat Jan 28 21:27:27 2023: Train Epoch: 6 [19200/60900 (32%)]	Loss: 197.181107 | Elapsed: 12.72s
01/28/2023 09:27:40 PM  [*] Sat Jan 28 21:27:40 2023: Train Epoch: 6 [25600/60900 (42%)]	Loss: 177.638489 | Elapsed: 12.71s
01/28/2023 09:27:53 PM  [*] Sat Jan 28 21:27:53 2023: Train Epoch: 6 [32000/60900 (53%)]	Loss: 190.723175 | Elapsed: 12.79s
01/28/2023 09:28:06 PM  [*] Sat Jan 28 21:28:06 2023: Train Epoch: 6 [38400/60900 (63%)]	Loss: 161.630966 | Elapsed: 12.72s
01/28/2023 09:28:18 PM  [*] Sat Jan 28 21:28:18 2023: Train Epoch: 6 [44800/60900 (74%)]	Loss: 171.963730 | Elapsed: 12.73s
01/28/2023 09:28:31 PM  [*] Sat Jan 28 21:28:31 2023: Train Epoch: 6 [51200/60900 (84%)]	Loss: 162.283783 | Elapsed: 12.97s
01/28/2023 09:28:44 PM  [*] Sat Jan 28 21:28:44 2023: Train Epoch: 6 [57600/60900 (95%)]	Loss: 194.199097 | Elapsed: 12.89s
01/28/2023 09:28:52 PM  [*] Sat Jan 28 21:28:52 2023:    6    | Tr.loss: 181.559670 | Elapsed:  124.18  s
01/28/2023 09:28:52 PM  [*] Started epoch: 7
01/28/2023 09:28:53 PM  [*] Sat Jan 28 21:28:53 2023: Train Epoch: 7 [  0  /60900 (0 %)]	Loss: 181.405182 | Elapsed: 0.22s
01/28/2023 09:29:05 PM  [*] Sat Jan 28 21:29:05 2023: Train Epoch: 7 [6400 /60900 (11%)]	Loss: 185.539276 | Elapsed: 12.69s
01/28/2023 09:29:18 PM  [*] Sat Jan 28 21:29:18 2023: Train Epoch: 7 [12800/60900 (21%)]	Loss: 172.152008 | Elapsed: 12.67s
01/28/2023 09:29:31 PM  [*] Sat Jan 28 21:29:31 2023: Train Epoch: 7 [19200/60900 (32%)]	Loss: 195.890884 | Elapsed: 12.57s
01/28/2023 09:29:44 PM  [*] Sat Jan 28 21:29:44 2023: Train Epoch: 7 [25600/60900 (42%)]	Loss: 171.596069 | Elapsed: 13.00s
01/28/2023 09:29:56 PM  [*] Sat Jan 28 21:29:56 2023: Train Epoch: 7 [32000/60900 (53%)]	Loss: 179.014008 | Elapsed: 12.90s
01/28/2023 09:30:09 PM  [*] Sat Jan 28 21:30:09 2023: Train Epoch: 7 [38400/60900 (63%)]	Loss: 160.368835 | Elapsed: 12.93s
01/28/2023 09:30:22 PM  [*] Sat Jan 28 21:30:22 2023: Train Epoch: 7 [44800/60900 (74%)]	Loss: 177.063263 | Elapsed: 12.92s
01/28/2023 09:30:35 PM  [*] Sat Jan 28 21:30:35 2023: Train Epoch: 7 [51200/60900 (84%)]	Loss: 177.037628 | Elapsed: 12.79s
01/28/2023 09:30:48 PM  [*] Sat Jan 28 21:30:48 2023: Train Epoch: 7 [57600/60900 (95%)]	Loss: 176.513397 | Elapsed: 12.88s
01/28/2023 09:30:56 PM  [*] Sat Jan 28 21:30:56 2023:    7    | Tr.loss: 180.947477 | Elapsed:  123.77  s
01/28/2023 09:30:56 PM  [*] Started epoch: 8
01/28/2023 09:30:56 PM  [*] Sat Jan 28 21:30:56 2023: Train Epoch: 8 [  0  /60900 (0 %)]	Loss: 176.429611 | Elapsed: 0.21s
01/28/2023 09:31:09 PM  [*] Sat Jan 28 21:31:09 2023: Train Epoch: 8 [6400 /60900 (11%)]	Loss: 182.321228 | Elapsed: 12.81s
01/28/2023 09:31:22 PM  [*] Sat Jan 28 21:31:22 2023: Train Epoch: 8 [12800/60900 (21%)]	Loss: 174.280487 | Elapsed: 12.89s
01/28/2023 09:31:35 PM  [*] Sat Jan 28 21:31:35 2023: Train Epoch: 8 [19200/60900 (32%)]	Loss: 168.265289 | Elapsed: 12.74s
01/28/2023 09:31:48 PM  [*] Sat Jan 28 21:31:48 2023: Train Epoch: 8 [25600/60900 (42%)]	Loss: 186.477173 | Elapsed: 13.11s
01/28/2023 09:32:01 PM  [*] Sat Jan 28 21:32:01 2023: Train Epoch: 8 [32000/60900 (53%)]	Loss: 170.920105 | Elapsed: 12.70s
01/28/2023 09:32:14 PM  [*] Sat Jan 28 21:32:14 2023: Train Epoch: 8 [38400/60900 (63%)]	Loss: 174.834015 | Elapsed: 13.00s
01/28/2023 09:32:27 PM  [*] Sat Jan 28 21:32:27 2023: Train Epoch: 8 [44800/60900 (74%)]	Loss: 200.639709 | Elapsed: 13.30s
01/28/2023 09:32:40 PM  [*] Sat Jan 28 21:32:40 2023: Train Epoch: 8 [51200/60900 (84%)]	Loss: 197.934448 | Elapsed: 12.59s
01/28/2023 09:32:52 PM  [*] Sat Jan 28 21:32:52 2023: Train Epoch: 8 [57600/60900 (95%)]	Loss: 191.774658 | Elapsed: 12.86s
01/28/2023 09:33:00 PM  [*] Sat Jan 28 21:33:00 2023:    8    | Tr.loss: 180.831963 | Elapsed:  124.22  s
01/28/2023 09:33:00 PM  [*] Started epoch: 9
01/28/2023 09:33:01 PM  [*] Sat Jan 28 21:33:01 2023: Train Epoch: 9 [  0  /60900 (0 %)]	Loss: 166.102005 | Elapsed: 0.14s
01/28/2023 09:33:13 PM  [*] Sat Jan 28 21:33:13 2023: Train Epoch: 9 [6400 /60900 (11%)]	Loss: 191.563644 | Elapsed: 12.56s
01/28/2023 09:33:26 PM  [*] Sat Jan 28 21:33:26 2023: Train Epoch: 9 [12800/60900 (21%)]	Loss: 164.336395 | Elapsed: 12.66s
01/28/2023 09:33:38 PM  [*] Sat Jan 28 21:33:38 2023: Train Epoch: 9 [19200/60900 (32%)]	Loss: 187.348572 | Elapsed: 12.52s
01/28/2023 09:33:51 PM  [*] Sat Jan 28 21:33:51 2023: Train Epoch: 9 [25600/60900 (42%)]	Loss: 176.613159 | Elapsed: 12.76s
01/28/2023 09:34:04 PM  [*] Sat Jan 28 21:34:04 2023: Train Epoch: 9 [32000/60900 (53%)]	Loss: 187.314987 | Elapsed: 12.62s
01/28/2023 09:34:17 PM  [*] Sat Jan 28 21:34:17 2023: Train Epoch: 9 [38400/60900 (63%)]	Loss: 186.486816 | Elapsed: 12.87s
01/28/2023 09:34:29 PM  [*] Sat Jan 28 21:34:29 2023: Train Epoch: 9 [44800/60900 (74%)]	Loss: 158.826111 | Elapsed: 12.73s
01/28/2023 09:34:42 PM  [*] Sat Jan 28 21:34:42 2023: Train Epoch: 9 [51200/60900 (84%)]	Loss: 166.283905 | Elapsed: 12.92s
01/28/2023 09:34:55 PM  [*] Sat Jan 28 21:34:55 2023: Train Epoch: 9 [57600/60900 (95%)]	Loss: 179.684677 | Elapsed: 13.28s
01/28/2023 09:35:04 PM  [*] Sat Jan 28 21:35:04 2023:    9    | Tr.loss: 180.507286 | Elapsed:  123.63  s
01/28/2023 09:35:04 PM  [*] Started epoch: 10
01/28/2023 09:35:04 PM  [*] Sat Jan 28 21:35:04 2023: Train Epoch: 10 [  0  /60900 (0 %)]	Loss: 201.807129 | Elapsed: 0.21s
01/28/2023 09:35:18 PM  [*] Sat Jan 28 21:35:18 2023: Train Epoch: 10 [6400 /60900 (11%)]	Loss: 181.608154 | Elapsed: 13.29s
01/28/2023 09:35:31 PM  [*] Sat Jan 28 21:35:31 2023: Train Epoch: 10 [12800/60900 (21%)]	Loss: 165.181427 | Elapsed: 13.24s
01/28/2023 09:35:44 PM  [*] Sat Jan 28 21:35:44 2023: Train Epoch: 10 [19200/60900 (32%)]	Loss: 179.162247 | Elapsed: 13.14s
01/28/2023 09:35:57 PM  [*] Sat Jan 28 21:35:57 2023: Train Epoch: 10 [25600/60900 (42%)]	Loss: 156.918335 | Elapsed: 12.91s
01/28/2023 09:36:09 PM  [*] Sat Jan 28 21:36:09 2023: Train Epoch: 10 [32000/60900 (53%)]	Loss: 183.790466 | Elapsed: 12.59s
01/28/2023 09:36:22 PM  [*] Sat Jan 28 21:36:22 2023: Train Epoch: 10 [38400/60900 (63%)]	Loss: 170.033844 | Elapsed: 13.01s
01/28/2023 09:36:35 PM  [*] Sat Jan 28 21:36:35 2023: Train Epoch: 10 [44800/60900 (74%)]	Loss: 157.789642 | Elapsed: 12.91s
01/28/2023 09:36:48 PM  [*] Sat Jan 28 21:36:48 2023: Train Epoch: 10 [51200/60900 (84%)]	Loss: 179.507446 | Elapsed: 12.62s
01/28/2023 09:37:01 PM  [*] Sat Jan 28 21:37:01 2023: Train Epoch: 10 [57600/60900 (95%)]	Loss: 185.186996 | Elapsed: 12.61s
01/28/2023 09:37:09 PM  [*] Sat Jan 28 21:37:09 2023:   10    | Tr.loss: 180.390630 | Elapsed:  124.51  s
01/28/2023 09:37:09 PM [!] Sat Jan 28 21:37:09 2023: Dumped results:
                model     : 1674938229-model.torch
		train time: 1674938229-trainTime.npy
		train losses: 1674938229-trainLosses.npy
		train AUC: 1674938229-auc.npy
01/28/2023 09:37:11 PM  [!] Training pretrained model on downstream task...
01/28/2023 09:37:11 PM  [*] Started epoch: 1
01/28/2023 09:37:11 PM  [*] Sat Jan 28 21:37:11 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.062922 | Elapsed: 0.26s | FPR 0.0003 -> TPR 0.0465 & F1 0.0889 | AUC 0.5404
01/28/2023 09:37:20 PM  [*] Sat Jan 28 21:37:20 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.578361 | Elapsed: 9.17s | FPR 0.0003 -> TPR 0.1304 & F1 0.2308 | AUC 0.6744
01/28/2023 09:37:29 PM  [*] Sat Jan 28 21:37:29 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.509716 | Elapsed: 9.18s | FPR 0.0003 -> TPR 0.2812 & F1 0.4390 | AUC 0.7483
01/28/2023 09:37:33 PM  [*] Sat Jan 28 21:37:33 2023:    1    | Tr.loss: 0.644847 | Elapsed:   22.32  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7369
01/28/2023 09:37:33 PM  [*] Started epoch: 2
01/28/2023 09:37:33 PM  [*] Sat Jan 28 21:37:33 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.557335 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.2105 & F1 0.3478 | AUC 0.7753
01/28/2023 09:37:42 PM  [*] Sat Jan 28 21:37:42 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.421776 | Elapsed: 9.18s | FPR 0.0003 -> TPR 0.4697 & F1 0.6392 | AUC 0.8552
01/28/2023 09:37:51 PM  [*] Sat Jan 28 21:37:51 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.367794 | Elapsed: 9.11s | FPR 0.0003 -> TPR 0.5000 & F1 0.6667 | AUC 0.8909
01/28/2023 09:37:55 PM  [*] Sat Jan 28 21:37:55 2023:    2    | Tr.loss: 0.424410 | Elapsed:   22.19  s | FPR 0.0003 -> TPR: 0.13 & F1: 0.24 | AUC: 0.8492
01/28/2023 09:37:55 PM  [*] Started epoch: 3
01/28/2023 09:37:55 PM  [*] Sat Jan 28 21:37:55 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.335555 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.5385 & F1 0.7000 | AUC 0.9241
01/28/2023 09:38:04 PM  [*] Sat Jan 28 21:38:04 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.328431 | Elapsed: 9.14s | FPR 0.0003 -> TPR 0.5926 & F1 0.7442 | AUC 0.9163
01/28/2023 09:38:13 PM  [*] Sat Jan 28 21:38:13 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.309170 | Elapsed: 9.10s | FPR 0.0003 -> TPR 0.4928 & F1 0.6602 | AUC 0.8806
01/28/2023 09:38:17 PM  [*] Sat Jan 28 21:38:17 2023:    3    | Tr.loss: 0.343673 | Elapsed:   22.18  s | FPR 0.0003 -> TPR: 0.31 & F1: 0.47 | AUC: 0.9093
01/28/2023 09:38:18 PM [!] Sat Jan 28 21:38:18 2023: Dumped results:
                model     : 1674938297-model.torch
		train time: 1674938297-trainTime.npy
		train losses: 1674938297-trainLosses.npy
		train AUC: 1674938297-auc.npy
		train F1s : 1674938297-trainF1s.npy
		train TPRs: 1674938297-trainTPRs.npy
01/28/2023 09:38:18 PM  [!] Training non_pretrained model on downstream task...
01/28/2023 09:38:18 PM  [*] Started epoch: 1
01/28/2023 09:38:18 PM  [*] Sat Jan 28 21:38:18 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 2.133200 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0811 & F1 0.1500 | AUC 0.4054
01/28/2023 09:38:25 PM  [*] Sat Jan 28 21:38:25 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.567639 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.2647 & F1 0.4186 | AUC 0.8212
01/28/2023 09:38:31 PM  [*] Sat Jan 28 21:38:31 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.309581 | Elapsed: 6.30s | FPR 0.0003 -> TPR 0.4677 & F1 0.6374 | AUC 0.9410
01/28/2023 09:38:34 PM  [*] Sat Jan 28 21:38:34 2023:    1    | Tr.loss: 0.491987 | Elapsed:   15.33  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8152
01/28/2023 09:38:34 PM  [*] Started epoch: 2
01/28/2023 09:38:34 PM  [*] Sat Jan 28 21:38:34 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.367312 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.2927 & F1 0.4528 | AUC 0.8982
01/28/2023 09:38:40 PM  [*] Sat Jan 28 21:38:40 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.189756 | Elapsed: 6.27s | FPR 0.0003 -> TPR 0.7910 & F1 0.8833 | AUC 0.9742
01/28/2023 09:38:47 PM  [*] Sat Jan 28 21:38:47 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.317652 | Elapsed: 6.53s | FPR 0.0003 -> TPR 0.6866 & F1 0.8142 | AUC 0.9579
01/28/2023 09:38:49 PM  [*] Sat Jan 28 21:38:49 2023:    2    | Tr.loss: 0.306748 | Elapsed:   15.51  s | FPR 0.0003 -> TPR: 0.16 & F1: 0.27 | AUC: 0.9292
01/28/2023 09:38:49 PM  [*] Started epoch: 3
01/28/2023 09:38:49 PM  [*] Sat Jan 28 21:38:49 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.284904 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.8800 & F1 0.9362 | AUC 0.9543
01/28/2023 09:38:56 PM  [*] Sat Jan 28 21:38:56 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.177570 | Elapsed: 6.38s | FPR 0.0003 -> TPR 0.6923 & F1 0.8182 | AUC 0.9615
01/28/2023 09:39:02 PM  [*] Sat Jan 28 21:39:02 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.202186 | Elapsed: 6.44s | FPR 0.0003 -> TPR 0.7429 & F1 0.8525 | AUC 0.9767
01/28/2023 09:39:05 PM  [*] Sat Jan 28 21:39:05 2023:    3    | Tr.loss: 0.234159 | Elapsed:   15.76  s | FPR 0.0003 -> TPR: 0.21 & F1: 0.35 | AUC: 0.9610
01/28/2023 09:39:05 PM [!] Sat Jan 28 21:39:05 2023: Dumped results:
                model     : 1674938345-model.torch
		train time: 1674938345-trainTime.npy
		train losses: 1674938345-trainLosses.npy
		train AUC: 1674938345-auc.npy
		train F1s : 1674938345-trainF1s.npy
		train TPRs: 1674938345-trainTPRs.npy
01/28/2023 09:39:05 PM  [!] Training full_data model on downstream task...
01/28/2023 09:39:06 PM  [*] Started epoch: 1
01/28/2023 09:39:06 PM  [*] Sat Jan 28 21:39:06 2023: Train Epoch: 1 [  0  /76126 (0 %)]	Loss: 3.161469 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.1220 & F1 0.2174 | AUC 0.5567
01/28/2023 09:39:12 PM  [*] Sat Jan 28 21:39:12 2023: Train Epoch: 1 [6400 /76126 (8 %)]	Loss: 0.487289 | Elapsed: 6.26s | FPR 0.0003 -> TPR 0.1231 & F1 0.2192 | AUC 0.8136
01/28/2023 09:39:19 PM  [*] Sat Jan 28 21:39:19 2023: Train Epoch: 1 [12800/76126 (17%)]	Loss: 0.523151 | Elapsed: 6.31s | FPR 0.0003 -> TPR 0.2273 & F1 0.3704 | AUC 0.8503
01/28/2023 09:39:25 PM  [*] Sat Jan 28 21:39:25 2023: Train Epoch: 1 [19200/76126 (25%)]	Loss: 0.288013 | Elapsed: 6.36s | FPR 0.0003 -> TPR 0.4058 & F1 0.5773 | AUC 0.9411
01/28/2023 09:39:31 PM  [*] Sat Jan 28 21:39:31 2023: Train Epoch: 1 [25600/76126 (34%)]	Loss: 0.348213 | Elapsed: 6.40s | FPR 0.0003 -> TPR 0.5714 & F1 0.7273 | AUC 0.9105
01/28/2023 09:39:38 PM  [*] Sat Jan 28 21:39:38 2023: Train Epoch: 1 [32000/76126 (42%)]	Loss: 0.286006 | Elapsed: 6.40s | FPR 0.0003 -> TPR 0.7971 & F1 0.8871 | AUC 0.9635
01/28/2023 09:39:44 PM  [*] Sat Jan 28 21:39:44 2023: Train Epoch: 1 [38400/76126 (50%)]	Loss: 0.172775 | Elapsed: 6.48s | FPR 0.0003 -> TPR 0.8889 & F1 0.9412 | AUC 0.9797
01/28/2023 09:39:51 PM  [*] Sat Jan 28 21:39:51 2023: Train Epoch: 1 [44800/76126 (59%)]	Loss: 0.300421 | Elapsed: 6.54s | FPR 0.0003 -> TPR 0.6216 & F1 0.7667 | AUC 0.9210
01/28/2023 09:39:57 PM  [*] Sat Jan 28 21:39:57 2023: Train Epoch: 1 [51200/76126 (67%)]	Loss: 0.176093 | Elapsed: 6.40s | FPR 0.0003 -> TPR 0.6769 & F1 0.8073 | AUC 0.9503
01/28/2023 09:40:04 PM  [*] Sat Jan 28 21:40:04 2023: Train Epoch: 1 [57600/76126 (76%)]	Loss: 0.210779 | Elapsed: 6.35s | FPR 0.0003 -> TPR 0.7222 & F1 0.8387 | AUC 0.9812
01/28/2023 09:40:10 PM [!] Learning rate: 2.5e-05
01/28/2023 09:40:10 PM  [*] Sat Jan 28 21:40:10 2023: Train Epoch: 1 [64000/76126 (84%)]	Loss: 0.192673 | Elapsed: 6.30s | FPR 0.0003 -> TPR 0.7761 & F1 0.8739 | AUC 0.9846
01/28/2023 09:40:16 PM  [*] Sat Jan 28 21:40:16 2023: Train Epoch: 1 [70400/76126 (92%)]	Loss: 0.163394 | Elapsed: 6.31s | FPR 0.0003 -> TPR 0.7000 & F1 0.8235 | AUC 0.9852
01/28/2023 09:40:24 PM  [*] Sat Jan 28 21:40:24 2023:    1    | Tr.loss: 0.308021 | Elapsed:   77.72  s | FPR 0.0003 -> TPR: 0.03 & F1: 0.06 | AUC: 0.9310
01/28/2023 09:40:24 PM  [*] Started epoch: 2
01/28/2023 09:40:24 PM  [*] Sat Jan 28 21:40:24 2023: Train Epoch: 2 [  0  /76126 (0 %)]	Loss: 0.118615 | Elapsed: 0.13s | FPR 0.0003 -> TPR 0.9778 & F1 0.9888 | AUC 0.9988
01/28/2023 09:40:30 PM  [*] Sat Jan 28 21:40:30 2023: Train Epoch: 2 [6400 /76126 (8 %)]	Loss: 0.171349 | Elapsed: 6.27s | FPR 0.0003 -> TPR 0.7812 & F1 0.8772 | AUC 0.9770
01/28/2023 09:40:36 PM  [*] Sat Jan 28 21:40:36 2023: Train Epoch: 2 [12800/76126 (17%)]	Loss: 0.130008 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.7288 & F1 0.8431 | AUC 0.9789
01/28/2023 09:40:43 PM  [*] Sat Jan 28 21:40:43 2023: Train Epoch: 2 [19200/76126 (25%)]	Loss: 0.091963 | Elapsed: 6.30s | FPR 0.0003 -> TPR 0.8657 & F1 0.9280 | AUC 0.9806
01/28/2023 09:40:49 PM  [*] Sat Jan 28 21:40:49 2023: Train Epoch: 2 [25600/76126 (34%)]	Loss: 0.116615 | Elapsed: 6.55s | FPR 0.0003 -> TPR 0.8358 & F1 0.9106 | AUC 0.9914
01/28/2023 09:40:56 PM  [*] Sat Jan 28 21:40:56 2023: Train Epoch: 2 [32000/76126 (42%)]	Loss: 0.187408 | Elapsed: 6.56s | FPR 0.0003 -> TPR 0.8209 & F1 0.9016 | AUC 0.9697
01/28/2023 09:41:02 PM  [*] Sat Jan 28 21:41:02 2023: Train Epoch: 2 [38400/76126 (50%)]	Loss: 0.256367 | Elapsed: 6.46s | FPR 0.0003 -> TPR 0.5417 & F1 0.7027 | AUC 0.9598
01/28/2023 09:41:09 PM  [*] Sat Jan 28 21:41:09 2023: Train Epoch: 2 [44800/76126 (59%)]	Loss: 0.204237 | Elapsed: 6.46s | FPR 0.0003 -> TPR 0.7121 & F1 0.8319 | AUC 0.9719
01/28/2023 09:41:15 PM  [*] Sat Jan 28 21:41:15 2023: Train Epoch: 2 [51200/76126 (67%)]	Loss: 0.212382 | Elapsed: 6.39s | FPR 0.0003 -> TPR 0.6324 & F1 0.7748 | AUC 0.9619
01/28/2023 09:41:16 PM [!] Learning rate: 2.5e-06
01/28/2023 09:41:21 PM  [*] Sat Jan 28 21:41:21 2023: Train Epoch: 2 [57600/76126 (76%)]	Loss: 0.126669 | Elapsed: 6.26s | FPR 0.0003 -> TPR 0.9385 & F1 0.9683 | AUC 0.9916
01/28/2023 09:41:28 PM  [*] Sat Jan 28 21:41:28 2023: Train Epoch: 2 [64000/76126 (84%)]	Loss: 0.230066 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.7576 & F1 0.8621 | AUC 0.9728
01/28/2023 09:41:34 PM  [*] Sat Jan 28 21:41:34 2023: Train Epoch: 2 [70400/76126 (92%)]	Loss: 0.208423 | Elapsed: 6.29s | FPR 0.0003 -> TPR 0.7671 & F1 0.8682 | AUC 0.9797
01/28/2023 09:41:41 PM  [*] Sat Jan 28 21:41:41 2023:    2    | Tr.loss: 0.174885 | Elapsed:   77.63  s | FPR 0.0003 -> TPR: 0.39 & F1: 0.56 | AUC: 0.9786
01/28/2023 09:41:41 PM  [*] Started epoch: 3
01/28/2023 09:41:41 PM  [*] Sat Jan 28 21:41:41 2023: Train Epoch: 3 [  0  /76126 (0 %)]	Loss: 0.226718 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.7368 & F1 0.8485 | AUC 0.9787
01/28/2023 09:41:48 PM  [*] Sat Jan 28 21:41:48 2023: Train Epoch: 3 [6400 /76126 (8 %)]	Loss: 0.215551 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.8657 & F1 0.9280 | AUC 0.9774
01/28/2023 09:41:54 PM  [*] Sat Jan 28 21:41:54 2023: Train Epoch: 3 [12800/76126 (17%)]	Loss: 0.150625 | Elapsed: 6.28s | FPR 0.0003 -> TPR 0.7538 & F1 0.8596 | AUC 0.9789
01/28/2023 09:42:00 PM  [*] Sat Jan 28 21:42:00 2023: Train Epoch: 3 [19200/76126 (25%)]	Loss: 0.131267 | Elapsed: 6.30s | FPR 0.0003 -> TPR 0.8413 & F1 0.9138 | AUC 0.9833
01/28/2023 09:42:07 PM  [*] Sat Jan 28 21:42:07 2023: Train Epoch: 3 [25600/76126 (34%)]	Loss: 0.172095 | Elapsed: 6.35s | FPR 0.0003 -> TPR 0.9254 & F1 0.9612 | AUC 0.9796
01/28/2023 09:42:13 PM  [*] Sat Jan 28 21:42:13 2023: Train Epoch: 3 [32000/76126 (42%)]	Loss: 0.174379 | Elapsed: 6.39s | FPR 0.0003 -> TPR 0.5231 & F1 0.6869 | AUC 0.9719
01/28/2023 09:42:19 PM  [*] Sat Jan 28 21:42:19 2023: Train Epoch: 3 [38400/76126 (50%)]	Loss: 0.122983 | Elapsed: 6.37s | FPR 0.0003 -> TPR 0.8816 & F1 0.9371 | AUC 0.9885
01/28/2023 09:42:21 PM [!] Learning rate: 2.5000000000000004e-07
01/28/2023 09:42:26 PM  [*] Sat Jan 28 21:42:26 2023: Train Epoch: 3 [44800/76126 (59%)]	Loss: 0.113596 | Elapsed: 6.36s | FPR 0.0003 -> TPR 0.9219 & F1 0.9593 | AUC 0.9948
01/28/2023 09:42:32 PM  [*] Sat Jan 28 21:42:32 2023: Train Epoch: 3 [51200/76126 (67%)]	Loss: 0.253350 | Elapsed: 6.34s | FPR 0.0003 -> TPR 0.7534 & F1 0.8594 | AUC 0.9477
01/28/2023 09:42:38 PM  [*] Sat Jan 28 21:42:38 2023: Train Epoch: 3 [57600/76126 (76%)]	Loss: 0.150829 | Elapsed: 6.39s | FPR 0.0003 -> TPR 0.8732 & F1 0.9323 | AUC 0.9874
01/28/2023 09:42:45 PM  [*] Sat Jan 28 21:42:45 2023: Train Epoch: 3 [64000/76126 (84%)]	Loss: 0.132259 | Elapsed: 6.38s | FPR 0.0003 -> TPR 0.8154 & F1 0.8983 | AUC 0.9868
01/28/2023 09:42:51 PM  [*] Sat Jan 28 21:42:51 2023: Train Epoch: 3 [70400/76126 (92%)]	Loss: 0.146547 | Elapsed: 6.33s | FPR 0.0003 -> TPR 0.8358 & F1 0.9106 | AUC 0.9851
01/28/2023 09:42:59 PM  [*] Sat Jan 28 21:42:59 2023:    3    | Tr.loss: 0.165651 | Elapsed:   77.42  s | FPR 0.0003 -> TPR: 0.44 & F1: 0.61 | AUC: 0.9809
01/28/2023 09:42:59 PM [!] Sat Jan 28 21:42:59 2023: Dumped results:
                model     : 1674938579-model.torch
		train time: 1674938579-trainTime.npy
		train losses: 1674938579-trainLosses.npy
		train AUC: 1674938579-auc.npy
		train F1s : 1674938579-trainF1s.npy
		train TPRs: 1674938579-trainTPRs.npy
01/28/2023 09:42:59 PM  [*] Evaluating pretrained model on test set...
01/28/2023 09:43:04 PM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0314 | F1: 0.0608
01/28/2023 09:43:04 PM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1229 | F1: 0.2189
01/28/2023 09:43:04 PM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.2847 | F1: 0.4429
01/28/2023 09:43:04 PM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3647 | F1: 0.5334
01/28/2023 09:43:04 PM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.4040 | F1: 0.5721
01/28/2023 09:43:04 PM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.5157 | F1: 0.6692
01/28/2023 09:43:04 PM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.6451 | F1: 0.7458
01/28/2023 09:43:04 PM  [*] Evaluating non_pretrained model on test set...
01/28/2023 09:43:09 PM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.1145 | F1: 0.2055
01/28/2023 09:43:09 PM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1708 | F1: 0.2917
01/28/2023 09:43:09 PM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.2814 | F1: 0.4389
01/28/2023 09:43:09 PM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3088 | F1: 0.4710
01/28/2023 09:43:09 PM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3429 | F1: 0.5074
01/28/2023 09:43:09 PM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4763 | F1: 0.6343
01/28/2023 09:43:09 PM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.7308 | F1: 0.8050
01/28/2023 09:43:09 PM  [*] Evaluating full_data model on test set...
01/28/2023 09:43:14 PM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0145 | F1: 0.0285
01/28/2023 09:43:14 PM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.2258 | F1: 0.3683
01/28/2023 09:43:14 PM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.3435 | F1: 0.5110
01/28/2023 09:43:14 PM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3840 | F1: 0.5539
01/28/2023 09:43:14 PM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.4607 | F1: 0.6271
01/28/2023 09:43:14 PM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.5619 | F1: 0.7080
01/28/2023 09:43:14 PM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.7879 | F1: 0.8415
01/28/2023 09:43:14 PM  [!] Running pre-training split 3/3
01/28/2023 09:43:18 PM  [!] Pre-training model...
01/28/2023 09:43:18 PM  [*] Masking sequences...
01/28/2023 09:43:37 PM  [*] Started epoch: 1
01/28/2023 09:43:38 PM  [*] Sat Jan 28 21:43:38 2023: Train Epoch: 1 [  0  /60900 (0 %)]	Loss: 369.843292 | Elapsed: 0.82s
01/28/2023 09:43:50 PM  [*] Sat Jan 28 21:43:50 2023: Train Epoch: 1 [6400 /60900 (11%)]	Loss: 232.401871 | Elapsed: 12.45s
01/28/2023 09:44:03 PM  [*] Sat Jan 28 21:44:03 2023: Train Epoch: 1 [12800/60900 (21%)]	Loss: 229.757065 | Elapsed: 12.55s
01/28/2023 09:44:15 PM  [*] Sat Jan 28 21:44:15 2023: Train Epoch: 1 [19200/60900 (32%)]	Loss: 196.222885 | Elapsed: 12.51s
01/28/2023 09:44:28 PM  [*] Sat Jan 28 21:44:28 2023: Train Epoch: 1 [25600/60900 (42%)]	Loss: 186.666473 | Elapsed: 12.61s
01/28/2023 09:44:41 PM  [*] Sat Jan 28 21:44:41 2023: Train Epoch: 1 [32000/60900 (53%)]	Loss: 194.399185 | Elapsed: 12.74s
01/28/2023 09:44:53 PM  [*] Sat Jan 28 21:44:53 2023: Train Epoch: 1 [38400/60900 (63%)]	Loss: 201.010269 | Elapsed: 12.66s
01/28/2023 09:45:06 PM  [*] Sat Jan 28 21:45:06 2023: Train Epoch: 1 [44800/60900 (74%)]	Loss: 195.656738 | Elapsed: 12.67s
01/28/2023 09:45:19 PM  [*] Sat Jan 28 21:45:19 2023: Train Epoch: 1 [51200/60900 (84%)]	Loss: 183.991425 | Elapsed: 12.59s
01/28/2023 09:45:31 PM  [*] Sat Jan 28 21:45:31 2023: Train Epoch: 1 [57600/60900 (95%)]	Loss: 196.909775 | Elapsed: 12.75s
01/28/2023 09:45:40 PM  [*] Sat Jan 28 21:45:40 2023:    1    | Tr.loss: 206.677461 | Elapsed:  122.57  s
01/28/2023 09:45:40 PM  [*] Started epoch: 2
01/28/2023 09:45:40 PM  [*] Sat Jan 28 21:45:40 2023: Train Epoch: 2 [  0  /60900 (0 %)]	Loss: 181.114243 | Elapsed: 0.12s
01/28/2023 09:45:52 PM  [*] Sat Jan 28 21:45:52 2023: Train Epoch: 2 [6400 /60900 (11%)]	Loss: 173.956238 | Elapsed: 12.58s
01/28/2023 09:46:05 PM  [*] Sat Jan 28 21:46:05 2023: Train Epoch: 2 [12800/60900 (21%)]	Loss: 173.003662 | Elapsed: 12.70s
01/28/2023 09:46:18 PM  [*] Sat Jan 28 21:46:18 2023: Train Epoch: 2 [19200/60900 (32%)]	Loss: 189.898804 | Elapsed: 12.54s
01/28/2023 09:46:30 PM  [*] Sat Jan 28 21:46:30 2023: Train Epoch: 2 [25600/60900 (42%)]	Loss: 159.681625 | Elapsed: 12.66s
01/28/2023 09:46:43 PM  [*] Sat Jan 28 21:46:43 2023: Train Epoch: 2 [32000/60900 (53%)]	Loss: 188.961212 | Elapsed: 12.52s
01/28/2023 09:46:55 PM  [*] Sat Jan 28 21:46:55 2023: Train Epoch: 2 [38400/60900 (63%)]	Loss: 177.380814 | Elapsed: 12.58s
01/28/2023 09:47:08 PM  [*] Sat Jan 28 21:47:08 2023: Train Epoch: 2 [44800/60900 (74%)]	Loss: 192.349030 | Elapsed: 12.57s
01/28/2023 09:47:21 PM  [*] Sat Jan 28 21:47:21 2023: Train Epoch: 2 [51200/60900 (84%)]	Loss: 171.473206 | Elapsed: 12.63s
01/28/2023 09:47:33 PM  [*] Sat Jan 28 21:47:33 2023: Train Epoch: 2 [57600/60900 (95%)]	Loss: 167.911041 | Elapsed: 12.66s
01/28/2023 09:47:41 PM  [*] Sat Jan 28 21:47:41 2023:    2    | Tr.loss: 186.249473 | Elapsed:  121.34  s
01/28/2023 09:47:41 PM  [*] Started epoch: 3
01/28/2023 09:47:41 PM  [*] Sat Jan 28 21:47:41 2023: Train Epoch: 3 [  0  /60900 (0 %)]	Loss: 187.681671 | Elapsed: 0.15s
01/28/2023 09:47:54 PM  [*] Sat Jan 28 21:47:54 2023: Train Epoch: 3 [6400 /60900 (11%)]	Loss: 157.052094 | Elapsed: 12.58s
01/28/2023 09:48:06 PM  [*] Sat Jan 28 21:48:06 2023: Train Epoch: 3 [12800/60900 (21%)]	Loss: 172.923615 | Elapsed: 12.62s
01/28/2023 09:48:19 PM  [*] Sat Jan 28 21:48:19 2023: Train Epoch: 3 [19200/60900 (32%)]	Loss: 193.236649 | Elapsed: 12.55s
01/28/2023 09:48:31 PM  [*] Sat Jan 28 21:48:31 2023: Train Epoch: 3 [25600/60900 (42%)]	Loss: 166.271790 | Elapsed: 12.57s
01/28/2023 09:48:44 PM  [*] Sat Jan 28 21:48:44 2023: Train Epoch: 3 [32000/60900 (53%)]	Loss: 171.746368 | Elapsed: 12.66s
01/28/2023 09:48:57 PM  [*] Sat Jan 28 21:48:57 2023: Train Epoch: 3 [38400/60900 (63%)]	Loss: 195.907837 | Elapsed: 12.63s
01/28/2023 09:49:09 PM  [*] Sat Jan 28 21:49:09 2023: Train Epoch: 3 [44800/60900 (74%)]	Loss: 212.404877 | Elapsed: 12.60s
01/28/2023 09:49:22 PM  [*] Sat Jan 28 21:49:22 2023: Train Epoch: 3 [51200/60900 (84%)]	Loss: 199.470459 | Elapsed: 12.66s
01/28/2023 09:49:35 PM  [*] Sat Jan 28 21:49:35 2023: Train Epoch: 3 [57600/60900 (95%)]	Loss: 169.878922 | Elapsed: 12.62s
01/28/2023 09:49:43 PM  [*] Sat Jan 28 21:49:43 2023:    3    | Tr.loss: 181.263744 | Elapsed:  121.59  s
01/28/2023 09:49:43 PM  [*] Started epoch: 4
01/28/2023 09:49:43 PM  [*] Sat Jan 28 21:49:43 2023: Train Epoch: 4 [  0  /60900 (0 %)]	Loss: 165.194489 | Elapsed: 0.15s
01/28/2023 09:49:55 PM  [*] Sat Jan 28 21:49:55 2023: Train Epoch: 4 [6400 /60900 (11%)]	Loss: 187.192108 | Elapsed: 12.41s
01/28/2023 09:50:08 PM  [*] Sat Jan 28 21:50:08 2023: Train Epoch: 4 [12800/60900 (21%)]	Loss: 191.883087 | Elapsed: 12.47s
01/28/2023 09:50:20 PM  [*] Sat Jan 28 21:50:20 2023: Train Epoch: 4 [19200/60900 (32%)]	Loss: 169.230560 | Elapsed: 12.44s
01/28/2023 09:50:33 PM  [*] Sat Jan 28 21:50:33 2023: Train Epoch: 4 [25600/60900 (42%)]	Loss: 183.451385 | Elapsed: 12.52s
01/28/2023 09:50:45 PM  [*] Sat Jan 28 21:50:45 2023: Train Epoch: 4 [32000/60900 (53%)]	Loss: 173.981171 | Elapsed: 12.44s
01/28/2023 09:50:58 PM  [*] Sat Jan 28 21:50:58 2023: Train Epoch: 4 [38400/60900 (63%)]	Loss: 183.725021 | Elapsed: 12.60s
01/28/2023 09:51:10 PM  [*] Sat Jan 28 21:51:10 2023: Train Epoch: 4 [44800/60900 (74%)]	Loss: 166.119019 | Elapsed: 12.59s
01/28/2023 09:51:23 PM  [*] Sat Jan 28 21:51:23 2023: Train Epoch: 4 [51200/60900 (84%)]	Loss: 165.147095 | Elapsed: 12.50s
01/28/2023 09:51:35 PM  [*] Sat Jan 28 21:51:35 2023: Train Epoch: 4 [57600/60900 (95%)]	Loss: 164.379639 | Elapsed: 12.72s
01/28/2023 09:51:43 PM  [*] Sat Jan 28 21:51:43 2023:    4    | Tr.loss: 178.531181 | Elapsed:  120.83  s
01/28/2023 09:51:43 PM  [*] Started epoch: 5
01/28/2023 09:51:44 PM  [*] Sat Jan 28 21:51:44 2023: Train Epoch: 5 [  0  /60900 (0 %)]	Loss: 171.979706 | Elapsed: 0.14s
01/28/2023 09:51:56 PM  [*] Sat Jan 28 21:51:56 2023: Train Epoch: 5 [6400 /60900 (11%)]	Loss: 163.893188 | Elapsed: 12.52s
01/28/2023 09:52:09 PM  [*] Sat Jan 28 21:52:09 2023: Train Epoch: 5 [12800/60900 (21%)]	Loss: 188.959061 | Elapsed: 12.54s
01/28/2023 09:52:21 PM  [*] Sat Jan 28 21:52:21 2023: Train Epoch: 5 [19200/60900 (32%)]	Loss: 168.208282 | Elapsed: 12.55s
01/28/2023 09:52:34 PM  [*] Sat Jan 28 21:52:34 2023: Train Epoch: 5 [25600/60900 (42%)]	Loss: 195.818573 | Elapsed: 12.55s
01/28/2023 09:52:46 PM  [*] Sat Jan 28 21:52:46 2023: Train Epoch: 5 [32000/60900 (53%)]	Loss: 185.530624 | Elapsed: 12.57s
01/28/2023 09:52:59 PM  [*] Sat Jan 28 21:52:59 2023: Train Epoch: 5 [38400/60900 (63%)]	Loss: 168.204697 | Elapsed: 12.50s
01/28/2023 09:53:11 PM  [*] Sat Jan 28 21:53:11 2023: Train Epoch: 5 [44800/60900 (74%)]	Loss: 180.175049 | Elapsed: 12.56s
01/28/2023 09:53:24 PM  [*] Sat Jan 28 21:53:24 2023: Train Epoch: 5 [51200/60900 (84%)]	Loss: 192.849854 | Elapsed: 12.58s
01/28/2023 09:53:36 PM  [*] Sat Jan 28 21:53:36 2023: Train Epoch: 5 [57600/60900 (95%)]	Loss: 166.445541 | Elapsed: 12.54s
01/28/2023 09:53:44 PM  [*] Sat Jan 28 21:53:44 2023:    5    | Tr.loss: 176.583397 | Elapsed:  121.03  s
01/28/2023 09:53:44 PM  [*] Started epoch: 6
01/28/2023 09:53:45 PM  [*] Sat Jan 28 21:53:45 2023: Train Epoch: 6 [  0  /60900 (0 %)]	Loss: 193.972321 | Elapsed: 0.13s
01/28/2023 09:53:57 PM  [*] Sat Jan 28 21:53:57 2023: Train Epoch: 6 [6400 /60900 (11%)]	Loss: 183.965469 | Elapsed: 12.60s
01/28/2023 09:54:10 PM  [*] Sat Jan 28 21:54:10 2023: Train Epoch: 6 [12800/60900 (21%)]	Loss: 172.303558 | Elapsed: 12.48s
01/28/2023 09:54:14 PM [!] Learning rate: 2.5e-05
01/28/2023 09:54:22 PM  [*] Sat Jan 28 21:54:22 2023: Train Epoch: 6 [19200/60900 (32%)]	Loss: 189.673111 | Elapsed: 12.44s
01/28/2023 09:54:35 PM  [*] Sat Jan 28 21:54:35 2023: Train Epoch: 6 [25600/60900 (42%)]	Loss: 159.831802 | Elapsed: 12.48s
01/28/2023 09:54:47 PM  [*] Sat Jan 28 21:54:47 2023: Train Epoch: 6 [32000/60900 (53%)]	Loss: 168.003876 | Elapsed: 12.69s
01/28/2023 09:55:00 PM  [*] Sat Jan 28 21:55:00 2023: Train Epoch: 6 [38400/60900 (63%)]	Loss: 146.867676 | Elapsed: 12.73s
01/28/2023 09:55:12 PM  [*] Sat Jan 28 21:55:12 2023: Train Epoch: 6 [44800/60900 (74%)]	Loss: 167.384323 | Elapsed: 12.40s
01/28/2023 09:55:25 PM  [*] Sat Jan 28 21:55:25 2023: Train Epoch: 6 [51200/60900 (84%)]	Loss: 176.166824 | Elapsed: 12.47s
01/28/2023 09:55:37 PM  [*] Sat Jan 28 21:55:37 2023: Train Epoch: 6 [57600/60900 (95%)]	Loss: 186.415558 | Elapsed: 12.43s
01/28/2023 09:55:45 PM  [*] Sat Jan 28 21:55:45 2023:    6    | Tr.loss: 175.173063 | Elapsed:  120.82  s
01/28/2023 09:55:45 PM  [*] Started epoch: 7
01/28/2023 09:55:45 PM  [*] Sat Jan 28 21:55:45 2023: Train Epoch: 7 [  0  /60900 (0 %)]	Loss: 163.246582 | Elapsed: 0.14s
01/28/2023 09:55:58 PM  [*] Sat Jan 28 21:55:58 2023: Train Epoch: 7 [6400 /60900 (11%)]	Loss: 177.202820 | Elapsed: 12.51s
01/28/2023 09:56:10 PM  [*] Sat Jan 28 21:56:10 2023: Train Epoch: 7 [12800/60900 (21%)]	Loss: 185.380386 | Elapsed: 12.46s
01/28/2023 09:56:23 PM  [*] Sat Jan 28 21:56:23 2023: Train Epoch: 7 [19200/60900 (32%)]	Loss: 190.283371 | Elapsed: 12.67s
01/28/2023 09:56:35 PM  [*] Sat Jan 28 21:56:35 2023: Train Epoch: 7 [25600/60900 (42%)]	Loss: 163.339645 | Elapsed: 12.43s
01/28/2023 09:56:48 PM  [*] Sat Jan 28 21:56:48 2023: Train Epoch: 7 [32000/60900 (53%)]	Loss: 175.767548 | Elapsed: 12.44s
01/28/2023 09:57:00 PM  [*] Sat Jan 28 21:57:00 2023: Train Epoch: 7 [38400/60900 (63%)]	Loss: 172.159485 | Elapsed: 12.42s
01/28/2023 09:57:13 PM  [*] Sat Jan 28 21:57:13 2023: Train Epoch: 7 [44800/60900 (74%)]	Loss: 176.452515 | Elapsed: 12.44s
01/28/2023 09:57:25 PM  [*] Sat Jan 28 21:57:25 2023: Train Epoch: 7 [51200/60900 (84%)]	Loss: 186.035263 | Elapsed: 12.44s
01/28/2023 09:57:38 PM  [*] Sat Jan 28 21:57:38 2023: Train Epoch: 7 [57600/60900 (95%)]	Loss: 168.006516 | Elapsed: 12.44s
01/28/2023 09:57:46 PM  [*] Sat Jan 28 21:57:46 2023:    7    | Tr.loss: 174.465146 | Elapsed:  120.30  s
01/28/2023 09:57:46 PM  [*] Started epoch: 8
01/28/2023 09:57:46 PM  [*] Sat Jan 28 21:57:46 2023: Train Epoch: 8 [  0  /60900 (0 %)]	Loss: 187.088440 | Elapsed: 0.13s
01/28/2023 09:57:58 PM  [*] Sat Jan 28 21:57:58 2023: Train Epoch: 8 [6400 /60900 (11%)]	Loss: 168.511810 | Elapsed: 12.51s
01/28/2023 09:58:11 PM  [*] Sat Jan 28 21:58:11 2023: Train Epoch: 8 [12800/60900 (21%)]	Loss: 171.195801 | Elapsed: 12.46s
01/28/2023 09:58:23 PM  [*] Sat Jan 28 21:58:23 2023: Train Epoch: 8 [19200/60900 (32%)]	Loss: 161.843079 | Elapsed: 12.48s
01/28/2023 09:58:36 PM  [*] Sat Jan 28 21:58:36 2023: Train Epoch: 8 [25600/60900 (42%)]	Loss: 186.915833 | Elapsed: 12.43s
01/28/2023 09:58:48 PM  [*] Sat Jan 28 21:58:48 2023: Train Epoch: 8 [32000/60900 (53%)]	Loss: 165.053696 | Elapsed: 12.50s
01/28/2023 09:59:01 PM  [*] Sat Jan 28 21:59:01 2023: Train Epoch: 8 [38400/60900 (63%)]	Loss: 157.057098 | Elapsed: 12.50s
01/28/2023 09:59:14 PM  [*] Sat Jan 28 21:59:14 2023: Train Epoch: 8 [44800/60900 (74%)]	Loss: 164.756378 | Elapsed: 13.14s
01/28/2023 09:59:26 PM  [*] Sat Jan 28 21:59:26 2023: Train Epoch: 8 [51200/60900 (84%)]	Loss: 190.023254 | Elapsed: 12.69s
01/28/2023 09:59:39 PM  [*] Sat Jan 28 21:59:39 2023: Train Epoch: 8 [57600/60900 (95%)]	Loss: 180.877762 | Elapsed: 12.70s
01/28/2023 09:59:47 PM  [*] Sat Jan 28 21:59:47 2023:    8    | Tr.loss: 174.347023 | Elapsed:  121.90  s
01/28/2023 09:59:47 PM  [*] Started epoch: 9
01/28/2023 09:59:48 PM  [*] Sat Jan 28 21:59:48 2023: Train Epoch: 9 [  0  /60900 (0 %)]	Loss: 163.239594 | Elapsed: 0.14s
01/28/2023 10:00:01 PM  [*] Sat Jan 28 22:00:01 2023: Train Epoch: 9 [6400 /60900 (11%)]	Loss: 174.723450 | Elapsed: 13.31s
01/28/2023 10:00:14 PM  [*] Sat Jan 28 22:00:14 2023: Train Epoch: 9 [12800/60900 (21%)]	Loss: 194.747498 | Elapsed: 12.83s
01/28/2023 10:00:27 PM  [*] Sat Jan 28 22:00:27 2023: Train Epoch: 9 [19200/60900 (32%)]	Loss: 156.261032 | Elapsed: 12.92s
01/28/2023 10:00:40 PM  [*] Sat Jan 28 22:00:40 2023: Train Epoch: 9 [25600/60900 (42%)]	Loss: 178.088181 | Elapsed: 12.87s
01/28/2023 10:00:53 PM  [*] Sat Jan 28 22:00:53 2023: Train Epoch: 9 [32000/60900 (53%)]	Loss: 185.110611 | Elapsed: 13.02s
01/28/2023 10:01:05 PM  [*] Sat Jan 28 22:01:05 2023: Train Epoch: 9 [38400/60900 (63%)]	Loss: 173.010590 | Elapsed: 12.91s
01/28/2023 10:01:18 PM  [*] Sat Jan 28 22:01:18 2023: Train Epoch: 9 [44800/60900 (74%)]	Loss: 169.287231 | Elapsed: 13.00s
01/28/2023 10:01:31 PM  [*] Sat Jan 28 22:01:31 2023: Train Epoch: 9 [51200/60900 (84%)]	Loss: 199.334106 | Elapsed: 12.69s
01/28/2023 10:01:45 PM  [*] Sat Jan 28 22:01:45 2023: Train Epoch: 9 [57600/60900 (95%)]	Loss: 176.776550 | Elapsed: 13.41s
01/28/2023 10:01:53 PM  [*] Sat Jan 28 22:01:53 2023:    9    | Tr.loss: 174.121904 | Elapsed:  125.81  s
01/28/2023 10:01:53 PM  [*] Started epoch: 10
01/28/2023 10:01:53 PM  [*] Sat Jan 28 22:01:53 2023: Train Epoch: 10 [  0  /60900 (0 %)]	Loss: 173.941528 | Elapsed: 0.15s
01/28/2023 10:02:06 PM  [*] Sat Jan 28 22:02:06 2023: Train Epoch: 10 [6400 /60900 (11%)]	Loss: 178.070557 | Elapsed: 12.94s
01/28/2023 10:02:19 PM  [*] Sat Jan 28 22:02:19 2023: Train Epoch: 10 [12800/60900 (21%)]	Loss: 174.130753 | Elapsed: 12.68s
01/28/2023 10:02:32 PM  [*] Sat Jan 28 22:02:32 2023: Train Epoch: 10 [19200/60900 (32%)]	Loss: 174.328461 | Elapsed: 12.59s
01/28/2023 10:02:44 PM  [*] Sat Jan 28 22:02:44 2023: Train Epoch: 10 [25600/60900 (42%)]	Loss: 175.108643 | Elapsed: 12.66s
01/28/2023 10:02:57 PM  [*] Sat Jan 28 22:02:57 2023: Train Epoch: 10 [32000/60900 (53%)]	Loss: 176.277985 | Elapsed: 12.57s
01/28/2023 10:03:09 PM  [*] Sat Jan 28 22:03:09 2023: Train Epoch: 10 [38400/60900 (63%)]	Loss: 180.415512 | Elapsed: 12.64s
01/28/2023 10:03:22 PM  [*] Sat Jan 28 22:03:22 2023: Train Epoch: 10 [44800/60900 (74%)]	Loss: 145.873688 | Elapsed: 12.54s
01/28/2023 10:03:35 PM  [*] Sat Jan 28 22:03:35 2023: Train Epoch: 10 [51200/60900 (84%)]	Loss: 157.634735 | Elapsed: 12.57s
01/28/2023 10:03:47 PM  [*] Sat Jan 28 22:03:47 2023: Train Epoch: 10 [57600/60900 (95%)]	Loss: 172.327301 | Elapsed: 12.51s
01/28/2023 10:03:55 PM  [*] Sat Jan 28 22:03:55 2023:   10    | Tr.loss: 173.910366 | Elapsed:  121.97  s
01/28/2023 10:03:56 PM [!] Sat Jan 28 22:03:56 2023: Dumped results:
                model     : 1674939835-model.torch
		train time: 1674939835-trainTime.npy
		train losses: 1674939835-trainLosses.npy
		train AUC: 1674939835-auc.npy
01/28/2023 10:03:58 PM  [!] Training pretrained model on downstream task...
01/28/2023 10:03:58 PM  [*] Started epoch: 1
01/28/2023 10:03:58 PM  [*] Sat Jan 28 22:03:58 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 2.339759 | Elapsed: 0.23s | FPR 0.0003 -> TPR 0.1087 & F1 0.1961 | AUC 0.5809
01/28/2023 10:04:07 PM  [*] Sat Jan 28 22:04:07 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.314521 | Elapsed: 9.14s | FPR 0.0003 -> TPR 0.4179 & F1 0.5895 | AUC 0.8987
01/28/2023 10:04:16 PM  [*] Sat Jan 28 22:04:16 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.253809 | Elapsed: 9.14s | FPR 0.0003 -> TPR 0.4474 & F1 0.6182 | AUC 0.9353
01/28/2023 10:04:20 PM  [*] Sat Jan 28 22:04:20 2023:    1    | Tr.loss: 0.455593 | Elapsed:   22.21  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8499
01/28/2023 10:04:20 PM  [*] Started epoch: 2
01/28/2023 10:04:20 PM  [*] Sat Jan 28 22:04:20 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.251015 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.7250 & F1 0.8406 | AUC 0.9635
01/28/2023 10:04:29 PM  [*] Sat Jan 28 22:04:29 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.408645 | Elapsed: 9.08s | FPR 0.0003 -> TPR 0.6607 & F1 0.7957 | AUC 0.9233
01/28/2023 10:04:38 PM  [*] Sat Jan 28 22:04:38 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.207692 | Elapsed: 9.12s | FPR 0.0003 -> TPR 0.5135 & F1 0.6786 | AUC 0.9706
01/28/2023 10:04:42 PM  [*] Sat Jan 28 22:04:42 2023:    2    | Tr.loss: 0.273275 | Elapsed:   22.03  s | FPR 0.0003 -> TPR: 0.33 & F1: 0.50 | AUC: 0.9465
01/28/2023 10:04:42 PM  [*] Started epoch: 3
01/28/2023 10:04:42 PM  [*] Sat Jan 28 22:04:42 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.338387 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.3684 & F1 0.5385 | AUC 0.9286
01/28/2023 10:04:51 PM  [*] Sat Jan 28 22:04:51 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.204423 | Elapsed: 9.10s | FPR 0.0003 -> TPR 0.7143 & F1 0.8333 | AUC 0.9614
01/28/2023 10:05:00 PM  [*] Sat Jan 28 22:05:00 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.184078 | Elapsed: 9.09s | FPR 0.0003 -> TPR 0.8082 & F1 0.8939 | AUC 0.9723
01/28/2023 10:05:04 PM  [*] Sat Jan 28 22:05:04 2023:    3    | Tr.loss: 0.209343 | Elapsed:   22.03  s | FPR 0.0003 -> TPR: 0.40 & F1: 0.57 | AUC: 0.9688
01/28/2023 10:05:04 PM [!] Sat Jan 28 22:05:04 2023: Dumped results:
                model     : 1674939904-model.torch
		train time: 1674939904-trainTime.npy
		train losses: 1674939904-trainLosses.npy
		train AUC: 1674939904-auc.npy
		train F1s : 1674939904-trainF1s.npy
		train TPRs: 1674939904-trainTPRs.npy
01/28/2023 10:05:04 PM  [!] Training non_pretrained model on downstream task...
01/28/2023 10:05:05 PM  [*] Started epoch: 1
01/28/2023 10:05:05 PM  [*] Sat Jan 28 22:05:05 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 1.555653 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0930 & F1 0.1702 | AUC 0.5415
01/28/2023 10:05:11 PM  [*] Sat Jan 28 22:05:11 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.412162 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.3000 & F1 0.4615 | AUC 0.8614
01/28/2023 10:05:17 PM  [*] Sat Jan 28 22:05:17 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.426260 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.4194 & F1 0.5909 | AUC 0.9037
01/28/2023 10:05:20 PM  [*] Sat Jan 28 22:05:20 2023:    1    | Tr.loss: 0.473217 | Elapsed:   15.15  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.01 | AUC: 0.8314
01/28/2023 10:05:20 PM  [*] Started epoch: 2
01/28/2023 10:05:20 PM  [*] Sat Jan 28 22:05:20 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.420202 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.4865 & F1 0.6545 | AUC 0.8849
01/28/2023 10:05:26 PM  [*] Sat Jan 28 22:05:26 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.290618 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.6119 & F1 0.7593 | AUC 0.9484
01/28/2023 10:05:33 PM  [*] Sat Jan 28 22:05:33 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.226252 | Elapsed: 6.26s | FPR 0.0003 -> TPR 0.6066 & F1 0.7551 | AUC 0.9676
01/28/2023 10:05:35 PM  [*] Sat Jan 28 22:05:35 2023:    2    | Tr.loss: 0.294119 | Elapsed:   15.16  s | FPR 0.0003 -> TPR: 0.17 & F1: 0.29 | AUC: 0.9351
01/28/2023 10:05:35 PM  [*] Started epoch: 3
01/28/2023 10:05:35 PM  [*] Sat Jan 28 22:05:35 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.231544 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.8537 & F1 0.9211 | AUC 0.9703
01/28/2023 10:05:41 PM  [*] Sat Jan 28 22:05:41 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.195418 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.5156 & F1 0.6804 | AUC 0.9787
01/28/2023 10:05:48 PM  [*] Sat Jan 28 22:05:48 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.150361 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.8971 & F1 0.9457 | AUC 0.9885
01/28/2023 10:05:50 PM  [*] Sat Jan 28 22:05:50 2023:    3    | Tr.loss: 0.227635 | Elapsed:   15.19  s | FPR 0.0003 -> TPR: 0.29 & F1: 0.45 | AUC: 0.9634
01/28/2023 10:05:51 PM [!] Sat Jan 28 22:05:51 2023: Dumped results:
                model     : 1674939950-model.torch
		train time: 1674939950-trainTime.npy
		train losses: 1674939950-trainLosses.npy
		train AUC: 1674939950-auc.npy
		train F1s : 1674939950-trainF1s.npy
		train TPRs: 1674939950-trainTPRs.npy
01/28/2023 10:05:51 PM  [!] Training full_data model on downstream task...
01/28/2023 10:05:51 PM  [*] Started epoch: 1
01/28/2023 10:05:51 PM  [*] Sat Jan 28 22:05:51 2023: Train Epoch: 1 [  0  /76126 (0 %)]	Loss: 1.816764 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0435 & F1 0.0833 | AUC 0.3406
01/28/2023 10:05:58 PM  [*] Sat Jan 28 22:05:58 2023: Train Epoch: 1 [6400 /76126 (8 %)]	Loss: 0.562575 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.1857 & F1 0.3133 | AUC 0.7010
01/28/2023 10:06:04 PM  [*] Sat Jan 28 22:06:04 2023: Train Epoch: 1 [12800/76126 (17%)]	Loss: 0.349171 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.3000 & F1 0.4615 | AUC 0.8905
01/28/2023 10:06:10 PM  [*] Sat Jan 28 22:06:10 2023: Train Epoch: 1 [19200/76126 (25%)]	Loss: 0.292557 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.5938 & F1 0.7451 | AUC 0.9366
01/28/2023 10:06:16 PM  [*] Sat Jan 28 22:06:16 2023: Train Epoch: 1 [25600/76126 (34%)]	Loss: 0.380506 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.5763 & F1 0.7312 | AUC 0.9148
01/28/2023 10:06:22 PM  [*] Sat Jan 28 22:06:22 2023: Train Epoch: 1 [32000/76126 (42%)]	Loss: 0.240591 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.5974 & F1 0.7480 | AUC 0.9593
01/28/2023 10:06:29 PM  [*] Sat Jan 28 22:06:29 2023: Train Epoch: 1 [38400/76126 (50%)]	Loss: 0.194878 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.7067 & F1 0.8281 | AUC 0.9616
01/28/2023 10:06:35 PM  [*] Sat Jan 28 22:06:35 2023: Train Epoch: 1 [44800/76126 (59%)]	Loss: 0.222305 | Elapsed: 6.28s | FPR 0.0003 -> TPR 0.7385 & F1 0.8496 | AUC 0.9807
01/28/2023 10:06:41 PM  [*] Sat Jan 28 22:06:41 2023: Train Epoch: 1 [51200/76126 (67%)]	Loss: 0.134854 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.8750 & F1 0.9333 | AUC 0.9922
01/28/2023 10:06:47 PM  [*] Sat Jan 28 22:06:47 2023: Train Epoch: 1 [57600/76126 (76%)]	Loss: 0.177854 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.7500 & F1 0.8571 | AUC 0.9724
01/28/2023 10:06:54 PM [!] Learning rate: 2.5e-05
01/28/2023 10:06:54 PM  [*] Sat Jan 28 22:06:54 2023: Train Epoch: 1 [64000/76126 (84%)]	Loss: 0.263172 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.8154 & F1 0.8983 | AUC 0.9705
01/28/2023 10:07:00 PM  [*] Sat Jan 28 22:07:00 2023: Train Epoch: 1 [70400/76126 (92%)]	Loss: 0.185470 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.8571 & F1 0.9231 | AUC 0.9807
01/28/2023 10:07:07 PM  [*] Sat Jan 28 22:07:07 2023:    1    | Tr.loss: 0.291389 | Elapsed:   76.00  s | FPR 0.0003 -> TPR: 0.16 & F1: 0.28 | AUC: 0.9378
01/28/2023 10:07:07 PM  [*] Started epoch: 2
01/28/2023 10:07:07 PM  [*] Sat Jan 28 22:07:07 2023: Train Epoch: 2 [  0  /76126 (0 %)]	Loss: 0.193250 | Elapsed: 0.13s | FPR 0.0003 -> TPR 0.7955 & F1 0.8861 | AUC 0.9727
01/28/2023 10:07:14 PM  [*] Sat Jan 28 22:07:14 2023: Train Epoch: 2 [6400 /76126 (8 %)]	Loss: 0.125008 | Elapsed: 6.28s | FPR 0.0003 -> TPR 0.9420 & F1 0.9701 | AUC 0.9902
01/28/2023 10:07:20 PM  [*] Sat Jan 28 22:07:20 2023: Train Epoch: 2 [12800/76126 (17%)]	Loss: 0.156249 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.8529 & F1 0.9206 | AUC 0.9812
01/28/2023 10:07:26 PM  [*] Sat Jan 28 22:07:26 2023: Train Epoch: 2 [19200/76126 (25%)]	Loss: 0.152037 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.8806 & F1 0.9365 | AUC 0.9869
01/28/2023 10:07:32 PM  [*] Sat Jan 28 22:07:32 2023: Train Epoch: 2 [25600/76126 (34%)]	Loss: 0.282784 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.6970 & F1 0.8214 | AUC 0.9528
01/28/2023 10:07:39 PM  [*] Sat Jan 28 22:07:39 2023: Train Epoch: 2 [32000/76126 (42%)]	Loss: 0.116748 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.8923 & F1 0.9431 | AUC 0.9890
01/28/2023 10:07:45 PM  [*] Sat Jan 28 22:07:45 2023: Train Epoch: 2 [38400/76126 (50%)]	Loss: 0.187404 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.7746 & F1 0.8730 | AUC 0.9709
01/28/2023 10:07:51 PM  [*] Sat Jan 28 22:07:51 2023: Train Epoch: 2 [44800/76126 (59%)]	Loss: 0.142825 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.9254 & F1 0.9612 | AUC 0.9887
01/28/2023 10:07:57 PM  [*] Sat Jan 28 22:07:57 2023: Train Epoch: 2 [51200/76126 (67%)]	Loss: 0.210504 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.8649 & F1 0.9275 | AUC 0.9740
01/28/2023 10:07:58 PM [!] Learning rate: 2.5e-06
01/28/2023 10:08:03 PM  [*] Sat Jan 28 22:08:03 2023: Train Epoch: 2 [57600/76126 (76%)]	Loss: 0.198257 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.7432 & F1 0.8527 | AUC 0.9688
01/28/2023 10:08:10 PM  [*] Sat Jan 28 22:08:10 2023: Train Epoch: 2 [64000/76126 (84%)]	Loss: 0.152485 | Elapsed: 6.27s | FPR 0.0003 -> TPR 0.7231 & F1 0.8393 | AUC 0.9749
01/28/2023 10:08:16 PM  [*] Sat Jan 28 22:08:16 2023: Train Epoch: 2 [70400/76126 (92%)]	Loss: 0.190094 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.8947 & F1 0.9444 | AUC 0.9682
01/28/2023 10:08:23 PM  [*] Sat Jan 28 22:08:23 2023:    2    | Tr.loss: 0.163734 | Elapsed:   76.01  s | FPR 0.0003 -> TPR: 0.45 & F1: 0.62 | AUC: 0.9814
01/28/2023 10:08:23 PM  [*] Started epoch: 3
01/28/2023 10:08:23 PM  [*] Sat Jan 28 22:08:23 2023: Train Epoch: 3 [  0  /76126 (0 %)]	Loss: 0.125324 | Elapsed: 0.14s | FPR 0.0003 -> TPR 0.8750 & F1 0.9333 | AUC 0.9870
01/28/2023 10:08:30 PM  [*] Sat Jan 28 22:08:30 2023: Train Epoch: 3 [6400 /76126 (8 %)]	Loss: 0.135826 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.9014 & F1 0.9481 | AUC 0.9815
01/28/2023 10:08:36 PM  [*] Sat Jan 28 22:08:36 2023: Train Epoch: 3 [12800/76126 (17%)]	Loss: 0.233381 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.6338 & F1 0.7759 | AUC 0.9675
01/28/2023 10:08:42 PM  [*] Sat Jan 28 22:08:42 2023: Train Epoch: 3 [19200/76126 (25%)]	Loss: 0.155788 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.8806 & F1 0.9365 | AUC 0.9792
01/28/2023 10:08:48 PM  [*] Sat Jan 28 22:08:48 2023: Train Epoch: 3 [25600/76126 (34%)]	Loss: 0.115128 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.9545 & F1 0.9767 | AUC 0.9938
01/28/2023 10:08:55 PM  [*] Sat Jan 28 22:08:55 2023: Train Epoch: 3 [32000/76126 (42%)]	Loss: 0.182396 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.6232 & F1 0.7679 | AUC 0.9631
01/28/2023 10:09:01 PM  [*] Sat Jan 28 22:09:01 2023: Train Epoch: 3 [38400/76126 (50%)]	Loss: 0.104059 | Elapsed: 6.26s | FPR 0.0003 -> TPR 0.7077 & F1 0.8288 | AUC 0.9815
01/28/2023 10:09:02 PM [!] Learning rate: 2.5000000000000004e-07
01/28/2023 10:09:07 PM  [*] Sat Jan 28 22:09:07 2023: Train Epoch: 3 [44800/76126 (59%)]	Loss: 0.083452 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.9306 & F1 0.9640 | AUC 0.9950
01/28/2023 10:09:13 PM  [*] Sat Jan 28 22:09:13 2023: Train Epoch: 3 [51200/76126 (67%)]	Loss: 0.152697 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.8462 & F1 0.9167 | AUC 0.9807
01/28/2023 10:09:19 PM  [*] Sat Jan 28 22:09:19 2023: Train Epoch: 3 [57600/76126 (76%)]	Loss: 0.177295 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.5493 & F1 0.7091 | AUC 0.9723
01/28/2023 10:09:26 PM  [*] Sat Jan 28 22:09:26 2023: Train Epoch: 3 [64000/76126 (84%)]	Loss: 0.100933 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.9153 & F1 0.9558 | AUC 0.9917
01/28/2023 10:09:32 PM  [*] Sat Jan 28 22:09:32 2023: Train Epoch: 3 [70400/76126 (92%)]	Loss: 0.117579 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.8028 & F1 0.8906 | AUC 0.9879
01/28/2023 10:09:39 PM  [*] Sat Jan 28 22:09:39 2023:    3    | Tr.loss: 0.155716 | Elapsed:   75.94  s | FPR 0.0003 -> TPR: 0.47 & F1: 0.64 | AUC: 0.9832
01/28/2023 10:09:40 PM [!] Sat Jan 28 22:09:40 2023: Dumped results:
                model     : 1674940179-model.torch
		train time: 1674940179-trainTime.npy
		train losses: 1674940179-trainLosses.npy
		train AUC: 1674940179-auc.npy
		train F1s : 1674940179-trainF1s.npy
		train TPRs: 1674940179-trainTPRs.npy
01/28/2023 10:09:40 PM  [*] Evaluating pretrained model on test set...
01/28/2023 10:09:45 PM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.1229 | F1: 0.2190
01/28/2023 10:09:45 PM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1941 | F1: 0.3250
01/28/2023 10:09:45 PM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.2831 | F1: 0.4410
01/28/2023 10:09:45 PM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3538 | F1: 0.5217
01/28/2023 10:09:45 PM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3943 | F1: 0.5622
01/28/2023 10:09:45 PM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.5165 | F1: 0.6699
01/28/2023 10:09:45 PM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.7450 | F1: 0.8142
01/28/2023 10:09:45 PM  [*] Evaluating non_pretrained model on test set...
01/28/2023 10:09:50 PM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0614 | F1: 0.1156
01/28/2023 10:09:50 PM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1350 | F1: 0.2378
01/28/2023 10:09:50 PM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.2051 | F1: 0.3402
01/28/2023 10:09:50 PM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3065 | F1: 0.4683
01/28/2023 10:09:50 PM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3536 | F1: 0.5192
01/28/2023 10:09:50 PM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4342 | F1: 0.5949
01/28/2023 10:09:50 PM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.7360 | F1: 0.8083
01/28/2023 10:09:50 PM  [*] Evaluating full_data model on test set...
01/28/2023 10:09:55 PM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0757 | F1: 0.1408
01/28/2023 10:09:55 PM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.2658 | F1: 0.4199
01/28/2023 10:09:55 PM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.3469 | F1: 0.5148
01/28/2023 10:09:55 PM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3973 | F1: 0.5677
01/28/2023 10:09:55 PM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.4719 | F1: 0.6375
01/28/2023 10:09:55 PM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.5579 | F1: 0.7047
01/28/2023 10:09:55 PM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.7979 | F1: 0.8475
01/28/2023 10:09:55 PM  [!] Finished pre-training evaluation over 3 splits! Saved metrics to:
	C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.8_1674935345/metrics_MaskedLanguageModel_nSplits_3_limit_None.json
01/28/2023 10:09:55 PM  [!] Starting Masked Language Model evaluation over 3 splits!
01/28/2023 10:09:55 PM  [!] Loaded data and vocab. X train size: (76126, 512), X test size: (17407, 512), vocab size: 50002
01/28/2023 10:09:55 PM  [!] Initiating Self-Supervised Learning Pretraining
     Language Modeling MaskedLanguageModel
     Model TransformerEncoderLM with config:
	{'vocabSize': 50002, 'maxLen': 512, 'dModel': 64, 'nHeads': 8, 'dHidden': 256, 'nLayers': 2, 'numClasses': 1, 'hiddenNeurons': [64], 'dropout': 0.3}

01/28/2023 10:09:55 PM  [!] Running pre-training split 1/3
01/28/2023 10:09:58 PM  [!] Pre-training model...
01/28/2023 10:09:59 PM  [*] Masking sequences...
01/28/2023 10:10:19 PM  [*] Started epoch: 1
01/28/2023 10:10:20 PM  [*] Sat Jan 28 22:10:20 2023: Train Epoch: 1 [  0  /64707 (0 %)]	Loss: 459.655945 | Elapsed: 0.87s
01/28/2023 10:10:33 PM  [*] Sat Jan 28 22:10:33 2023: Train Epoch: 1 [6400 /64707 (10%)]	Loss: 236.449158 | Elapsed: 12.41s
01/28/2023 10:10:45 PM  [*] Sat Jan 28 22:10:45 2023: Train Epoch: 1 [12800/64707 (20%)]	Loss: 208.256454 | Elapsed: 12.51s
01/28/2023 10:10:58 PM  [*] Sat Jan 28 22:10:58 2023: Train Epoch: 1 [19200/64707 (30%)]	Loss: 217.448029 | Elapsed: 12.50s
01/28/2023 10:11:10 PM  [*] Sat Jan 28 22:11:10 2023: Train Epoch: 1 [25600/64707 (40%)]	Loss: 221.441864 | Elapsed: 12.56s
01/28/2023 10:11:23 PM  [*] Sat Jan 28 22:11:23 2023: Train Epoch: 1 [32000/64707 (49%)]	Loss: 192.531845 | Elapsed: 12.56s
01/28/2023 10:11:35 PM  [*] Sat Jan 28 22:11:35 2023: Train Epoch: 1 [38400/64707 (59%)]	Loss: 208.348770 | Elapsed: 12.66s
01/28/2023 10:11:48 PM  [*] Sat Jan 28 22:11:48 2023: Train Epoch: 1 [44800/64707 (69%)]	Loss: 216.618774 | Elapsed: 12.60s
01/28/2023 10:12:00 PM  [*] Sat Jan 28 22:12:00 2023: Train Epoch: 1 [51200/64707 (79%)]	Loss: 198.821106 | Elapsed: 12.56s
01/28/2023 10:12:13 PM  [*] Sat Jan 28 22:12:13 2023: Train Epoch: 1 [57600/64707 (89%)]	Loss: 222.726410 | Elapsed: 12.90s
01/28/2023 10:12:26 PM  [*] Sat Jan 28 22:12:26 2023: Train Epoch: 1 [64000/64707 (99%)]	Loss: 200.424561 | Elapsed: 12.85s
01/28/2023 10:12:29 PM  [*] Sat Jan 28 22:12:29 2023:    1    | Tr.loss: 207.858504 | Elapsed:  130.02  s
01/28/2023 10:12:29 PM  [*] Started epoch: 2
01/28/2023 10:12:29 PM  [*] Sat Jan 28 22:12:29 2023: Train Epoch: 2 [  0  /64707 (0 %)]	Loss: 193.118744 | Elapsed: 0.13s
01/28/2023 10:12:42 PM  [*] Sat Jan 28 22:12:42 2023: Train Epoch: 2 [6400 /64707 (10%)]	Loss: 175.726746 | Elapsed: 12.65s
01/28/2023 10:12:55 PM  [*] Sat Jan 28 22:12:55 2023: Train Epoch: 2 [12800/64707 (20%)]	Loss: 194.103851 | Elapsed: 12.57s
01/28/2023 10:13:07 PM  [*] Sat Jan 28 22:13:07 2023: Train Epoch: 2 [19200/64707 (30%)]	Loss: 233.026001 | Elapsed: 12.59s
01/28/2023 10:13:20 PM  [*] Sat Jan 28 22:13:20 2023: Train Epoch: 2 [25600/64707 (40%)]	Loss: 196.122543 | Elapsed: 12.58s
01/28/2023 10:13:32 PM  [*] Sat Jan 28 22:13:32 2023: Train Epoch: 2 [32000/64707 (49%)]	Loss: 176.843475 | Elapsed: 12.57s
01/28/2023 10:13:45 PM  [*] Sat Jan 28 22:13:45 2023: Train Epoch: 2 [38400/64707 (59%)]	Loss: 187.218353 | Elapsed: 12.54s
01/28/2023 10:13:57 PM  [*] Sat Jan 28 22:13:57 2023: Train Epoch: 2 [44800/64707 (69%)]	Loss: 160.101303 | Elapsed: 12.50s
01/28/2023 10:14:10 PM  [*] Sat Jan 28 22:14:10 2023: Train Epoch: 2 [51200/64707 (79%)]	Loss: 197.088242 | Elapsed: 12.72s
01/28/2023 10:14:23 PM  [*] Sat Jan 28 22:14:23 2023: Train Epoch: 2 [57600/64707 (89%)]	Loss: 182.604218 | Elapsed: 12.65s
01/28/2023 10:14:35 PM  [*] Sat Jan 28 22:14:35 2023: Train Epoch: 2 [64000/64707 (99%)]	Loss: 199.634003 | Elapsed: 12.57s
01/28/2023 10:14:38 PM  [*] Sat Jan 28 22:14:38 2023:    2    | Tr.loss: 188.782999 | Elapsed:  129.10  s
01/28/2023 10:14:38 PM  [*] Started epoch: 3
01/28/2023 10:14:38 PM  [*] Sat Jan 28 22:14:38 2023: Train Epoch: 3 [  0  /64707 (0 %)]	Loss: 199.563507 | Elapsed: 0.13s
01/28/2023 10:14:51 PM  [*] Sat Jan 28 22:14:51 2023: Train Epoch: 3 [6400 /64707 (10%)]	Loss: 177.927231 | Elapsed: 12.59s
01/28/2023 10:15:04 PM  [*] Sat Jan 28 22:15:04 2023: Train Epoch: 3 [12800/64707 (20%)]	Loss: 176.496399 | Elapsed: 12.59s
01/28/2023 10:15:16 PM  [*] Sat Jan 28 22:15:16 2023: Train Epoch: 3 [19200/64707 (30%)]	Loss: 162.421631 | Elapsed: 12.61s
01/28/2023 10:15:29 PM  [*] Sat Jan 28 22:15:29 2023: Train Epoch: 3 [25600/64707 (40%)]	Loss: 192.769516 | Elapsed: 12.49s
01/28/2023 10:15:41 PM  [*] Sat Jan 28 22:15:41 2023: Train Epoch: 3 [32000/64707 (49%)]	Loss: 186.847412 | Elapsed: 12.62s
01/28/2023 10:15:54 PM  [*] Sat Jan 28 22:15:54 2023: Train Epoch: 3 [38400/64707 (59%)]	Loss: 164.328125 | Elapsed: 12.54s
01/28/2023 10:16:07 PM  [*] Sat Jan 28 22:16:07 2023: Train Epoch: 3 [44800/64707 (69%)]	Loss: 192.987274 | Elapsed: 12.61s
01/28/2023 10:16:19 PM  [*] Sat Jan 28 22:16:19 2023: Train Epoch: 3 [51200/64707 (79%)]	Loss: 196.204712 | Elapsed: 12.56s
01/28/2023 10:16:32 PM  [*] Sat Jan 28 22:16:32 2023: Train Epoch: 3 [57600/64707 (89%)]	Loss: 180.251190 | Elapsed: 12.57s
01/28/2023 10:16:44 PM  [*] Sat Jan 28 22:16:44 2023: Train Epoch: 3 [64000/64707 (99%)]	Loss: 171.141632 | Elapsed: 12.62s
01/28/2023 10:16:47 PM  [*] Sat Jan 28 22:16:47 2023:    3    | Tr.loss: 183.981286 | Elapsed:  128.98  s
01/28/2023 10:16:47 PM  [*] Started epoch: 4
01/28/2023 10:16:48 PM  [*] Sat Jan 28 22:16:48 2023: Train Epoch: 4 [  0  /64707 (0 %)]	Loss: 193.215088 | Elapsed: 0.20s
01/28/2023 10:17:00 PM  [*] Sat Jan 28 22:17:00 2023: Train Epoch: 4 [6400 /64707 (10%)]	Loss: 192.374817 | Elapsed: 12.58s
01/28/2023 10:17:13 PM  [*] Sat Jan 28 22:17:13 2023: Train Epoch: 4 [12800/64707 (20%)]	Loss: 196.623260 | Elapsed: 12.54s
01/28/2023 10:17:25 PM  [*] Sat Jan 28 22:17:25 2023: Train Epoch: 4 [19200/64707 (30%)]	Loss: 184.199799 | Elapsed: 12.55s
01/28/2023 10:17:38 PM  [*] Sat Jan 28 22:17:38 2023: Train Epoch: 4 [25600/64707 (40%)]	Loss: 179.586380 | Elapsed: 12.51s
01/28/2023 10:17:50 PM  [*] Sat Jan 28 22:17:50 2023: Train Epoch: 4 [32000/64707 (49%)]	Loss: 169.940521 | Elapsed: 12.61s
01/28/2023 10:18:03 PM  [*] Sat Jan 28 22:18:03 2023: Train Epoch: 4 [38400/64707 (59%)]	Loss: 200.291901 | Elapsed: 12.46s
01/28/2023 10:18:15 PM  [*] Sat Jan 28 22:18:15 2023: Train Epoch: 4 [44800/64707 (69%)]	Loss: 170.938934 | Elapsed: 12.56s
01/28/2023 10:18:28 PM  [*] Sat Jan 28 22:18:28 2023: Train Epoch: 4 [51200/64707 (79%)]	Loss: 162.019897 | Elapsed: 12.47s
01/28/2023 10:18:40 PM  [*] Sat Jan 28 22:18:40 2023: Train Epoch: 4 [57600/64707 (89%)]	Loss: 194.266235 | Elapsed: 12.48s
01/28/2023 10:18:53 PM  [*] Sat Jan 28 22:18:53 2023: Train Epoch: 4 [64000/64707 (99%)]	Loss: 168.463486 | Elapsed: 12.52s
01/28/2023 10:18:56 PM  [*] Sat Jan 28 22:18:56 2023:    4    | Tr.loss: 181.503745 | Elapsed:  128.52  s
01/28/2023 10:18:56 PM  [*] Started epoch: 5
01/28/2023 10:18:56 PM  [*] Sat Jan 28 22:18:56 2023: Train Epoch: 5 [  0  /64707 (0 %)]	Loss: 173.819870 | Elapsed: 0.14s
01/28/2023 10:19:08 PM  [*] Sat Jan 28 22:19:08 2023: Train Epoch: 5 [6400 /64707 (10%)]	Loss: 194.206802 | Elapsed: 12.48s
01/28/2023 10:19:21 PM  [*] Sat Jan 28 22:19:21 2023: Train Epoch: 5 [12800/64707 (20%)]	Loss: 171.885529 | Elapsed: 12.45s
01/28/2023 10:19:33 PM  [*] Sat Jan 28 22:19:33 2023: Train Epoch: 5 [19200/64707 (30%)]	Loss: 162.795471 | Elapsed: 12.44s
01/28/2023 10:19:46 PM  [*] Sat Jan 28 22:19:46 2023: Train Epoch: 5 [25600/64707 (40%)]	Loss: 166.890076 | Elapsed: 12.48s
01/28/2023 10:19:58 PM  [*] Sat Jan 28 22:19:58 2023: Train Epoch: 5 [32000/64707 (49%)]	Loss: 197.603027 | Elapsed: 12.42s
01/28/2023 10:20:11 PM  [*] Sat Jan 28 22:20:11 2023: Train Epoch: 5 [38400/64707 (59%)]	Loss: 171.749023 | Elapsed: 12.43s
01/28/2023 10:20:23 PM  [*] Sat Jan 28 22:20:23 2023: Train Epoch: 5 [44800/64707 (69%)]	Loss: 185.773712 | Elapsed: 12.56s
01/28/2023 10:20:36 PM  [*] Sat Jan 28 22:20:36 2023: Train Epoch: 5 [51200/64707 (79%)]	Loss: 194.243164 | Elapsed: 12.48s
01/28/2023 10:20:48 PM  [*] Sat Jan 28 22:20:48 2023: Train Epoch: 5 [57600/64707 (89%)]	Loss: 197.026199 | Elapsed: 12.45s
01/28/2023 10:20:55 PM [!] Learning rate: 2.5e-05
01/28/2023 10:21:01 PM  [*] Sat Jan 28 22:21:01 2023: Train Epoch: 5 [64000/64707 (99%)]	Loss: 177.363312 | Elapsed: 12.46s
01/28/2023 10:21:04 PM  [*] Sat Jan 28 22:21:04 2023:    5    | Tr.loss: 179.782029 | Elapsed:  127.87  s
01/28/2023 10:21:04 PM  [*] Started epoch: 6
01/28/2023 10:21:04 PM  [*] Sat Jan 28 22:21:04 2023: Train Epoch: 6 [  0  /64707 (0 %)]	Loss: 170.203476 | Elapsed: 0.13s
01/28/2023 10:21:16 PM  [*] Sat Jan 28 22:21:16 2023: Train Epoch: 6 [6400 /64707 (10%)]	Loss: 160.927628 | Elapsed: 12.56s
01/28/2023 10:21:29 PM  [*] Sat Jan 28 22:21:29 2023: Train Epoch: 6 [12800/64707 (20%)]	Loss: 178.284271 | Elapsed: 12.59s
01/28/2023 10:21:41 PM  [*] Sat Jan 28 22:21:41 2023: Train Epoch: 6 [19200/64707 (30%)]	Loss: 188.961380 | Elapsed: 12.43s
01/28/2023 10:21:54 PM  [*] Sat Jan 28 22:21:54 2023: Train Epoch: 6 [25600/64707 (40%)]	Loss: 194.383545 | Elapsed: 12.44s
01/28/2023 10:22:06 PM  [*] Sat Jan 28 22:22:06 2023: Train Epoch: 6 [32000/64707 (49%)]	Loss: 153.572388 | Elapsed: 12.47s
01/28/2023 10:22:19 PM  [*] Sat Jan 28 22:22:19 2023: Train Epoch: 6 [38400/64707 (59%)]	Loss: 172.385986 | Elapsed: 12.45s
01/28/2023 10:22:31 PM  [*] Sat Jan 28 22:22:31 2023: Train Epoch: 6 [44800/64707 (69%)]	Loss: 187.414490 | Elapsed: 12.45s
01/28/2023 10:22:44 PM  [*] Sat Jan 28 22:22:44 2023: Train Epoch: 6 [51200/64707 (79%)]	Loss: 179.847931 | Elapsed: 12.43s
01/28/2023 10:22:56 PM  [*] Sat Jan 28 22:22:56 2023: Train Epoch: 6 [57600/64707 (89%)]	Loss: 157.137909 | Elapsed: 12.54s
01/28/2023 10:23:09 PM  [*] Sat Jan 28 22:23:09 2023: Train Epoch: 6 [64000/64707 (99%)]	Loss: 189.549271 | Elapsed: 12.49s
01/28/2023 10:23:12 PM  [*] Sat Jan 28 22:23:12 2023:    6    | Tr.loss: 178.329626 | Elapsed:  128.04  s
01/28/2023 10:23:12 PM  [*] Started epoch: 7
01/28/2023 10:23:12 PM  [*] Sat Jan 28 22:23:12 2023: Train Epoch: 7 [  0  /64707 (0 %)]	Loss: 182.081985 | Elapsed: 0.13s
01/28/2023 10:23:24 PM  [*] Sat Jan 28 22:23:24 2023: Train Epoch: 7 [6400 /64707 (10%)]	Loss: 154.095474 | Elapsed: 12.49s
01/28/2023 10:23:37 PM  [*] Sat Jan 28 22:23:37 2023: Train Epoch: 7 [12800/64707 (20%)]	Loss: 202.705261 | Elapsed: 12.41s
01/28/2023 10:23:49 PM  [*] Sat Jan 28 22:23:49 2023: Train Epoch: 7 [19200/64707 (30%)]	Loss: 191.368362 | Elapsed: 12.40s
01/28/2023 10:24:02 PM  [*] Sat Jan 28 22:24:02 2023: Train Epoch: 7 [25600/64707 (40%)]	Loss: 184.113678 | Elapsed: 12.41s
01/28/2023 10:24:14 PM  [*] Sat Jan 28 22:24:14 2023: Train Epoch: 7 [32000/64707 (49%)]	Loss: 177.230820 | Elapsed: 12.48s
01/28/2023 10:24:27 PM  [*] Sat Jan 28 22:24:27 2023: Train Epoch: 7 [38400/64707 (59%)]	Loss: 202.343567 | Elapsed: 12.49s
01/28/2023 10:24:39 PM  [*] Sat Jan 28 22:24:39 2023: Train Epoch: 7 [44800/64707 (69%)]	Loss: 179.554230 | Elapsed: 12.51s
01/28/2023 10:24:51 PM  [*] Sat Jan 28 22:24:51 2023: Train Epoch: 7 [51200/64707 (79%)]	Loss: 180.544189 | Elapsed: 12.40s
01/28/2023 10:25:04 PM  [*] Sat Jan 28 22:25:04 2023: Train Epoch: 7 [57600/64707 (89%)]	Loss: 186.652618 | Elapsed: 12.42s
01/28/2023 10:25:16 PM  [*] Sat Jan 28 22:25:16 2023: Train Epoch: 7 [64000/64707 (99%)]	Loss: 167.996262 | Elapsed: 12.46s
01/28/2023 10:25:19 PM  [*] Sat Jan 28 22:25:19 2023:    7    | Tr.loss: 177.994021 | Elapsed:  127.62  s
01/28/2023 10:25:19 PM  [*] Started epoch: 8
01/28/2023 10:25:19 PM  [*] Sat Jan 28 22:25:19 2023: Train Epoch: 8 [  0  /64707 (0 %)]	Loss: 176.578125 | Elapsed: 0.13s
01/28/2023 10:25:32 PM  [*] Sat Jan 28 22:25:32 2023: Train Epoch: 8 [6400 /64707 (10%)]	Loss: 173.816559 | Elapsed: 12.49s
01/28/2023 10:25:44 PM  [*] Sat Jan 28 22:25:44 2023: Train Epoch: 8 [12800/64707 (20%)]	Loss: 173.932281 | Elapsed: 12.46s
01/28/2023 10:25:57 PM  [*] Sat Jan 28 22:25:57 2023: Train Epoch: 8 [19200/64707 (30%)]	Loss: 180.256546 | Elapsed: 12.38s
01/28/2023 10:26:09 PM  [*] Sat Jan 28 22:26:09 2023: Train Epoch: 8 [25600/64707 (40%)]	Loss: 194.421051 | Elapsed: 12.41s
01/28/2023 10:26:22 PM  [*] Sat Jan 28 22:26:22 2023: Train Epoch: 8 [32000/64707 (49%)]	Loss: 174.724594 | Elapsed: 12.50s
01/28/2023 10:26:34 PM  [*] Sat Jan 28 22:26:34 2023: Train Epoch: 8 [38400/64707 (59%)]	Loss: 172.552261 | Elapsed: 12.40s
01/28/2023 10:26:46 PM  [*] Sat Jan 28 22:26:46 2023: Train Epoch: 8 [44800/64707 (69%)]	Loss: 180.984833 | Elapsed: 12.35s
01/28/2023 10:26:59 PM  [*] Sat Jan 28 22:26:59 2023: Train Epoch: 8 [51200/64707 (79%)]	Loss: 189.147949 | Elapsed: 12.48s
01/28/2023 10:27:11 PM  [*] Sat Jan 28 22:27:11 2023: Train Epoch: 8 [57600/64707 (89%)]	Loss: 165.141586 | Elapsed: 12.42s
01/28/2023 10:27:24 PM  [*] Sat Jan 28 22:27:24 2023: Train Epoch: 8 [64000/64707 (99%)]	Loss: 173.685455 | Elapsed: 12.43s
01/28/2023 10:27:27 PM  [*] Sat Jan 28 22:27:27 2023:    8    | Tr.loss: 177.851612 | Elapsed:  127.52  s
01/28/2023 10:27:27 PM  [*] Started epoch: 9
01/28/2023 10:27:27 PM  [*] Sat Jan 28 22:27:27 2023: Train Epoch: 9 [  0  /64707 (0 %)]	Loss: 178.329269 | Elapsed: 0.15s
01/28/2023 10:27:40 PM  [*] Sat Jan 28 22:27:40 2023: Train Epoch: 9 [6400 /64707 (10%)]	Loss: 204.070251 | Elapsed: 12.58s
01/28/2023 10:27:52 PM  [*] Sat Jan 28 22:27:52 2023: Train Epoch: 9 [12800/64707 (20%)]	Loss: 180.337250 | Elapsed: 12.36s
01/28/2023 10:28:04 PM  [*] Sat Jan 28 22:28:04 2023: Train Epoch: 9 [19200/64707 (30%)]	Loss: 176.316910 | Elapsed: 12.40s
01/28/2023 10:28:17 PM  [*] Sat Jan 28 22:28:17 2023: Train Epoch: 9 [25600/64707 (40%)]	Loss: 170.320068 | Elapsed: 12.50s
01/28/2023 10:28:29 PM  [*] Sat Jan 28 22:28:29 2023: Train Epoch: 9 [32000/64707 (49%)]	Loss: 174.908020 | Elapsed: 12.46s
01/28/2023 10:28:42 PM  [*] Sat Jan 28 22:28:42 2023: Train Epoch: 9 [38400/64707 (59%)]	Loss: 172.953430 | Elapsed: 12.36s
01/28/2023 10:28:54 PM  [*] Sat Jan 28 22:28:54 2023: Train Epoch: 9 [44800/64707 (69%)]	Loss: 172.396515 | Elapsed: 12.43s
01/28/2023 10:29:07 PM  [*] Sat Jan 28 22:29:07 2023: Train Epoch: 9 [51200/64707 (79%)]	Loss: 182.772339 | Elapsed: 12.41s
01/28/2023 10:29:19 PM  [*] Sat Jan 28 22:29:19 2023: Train Epoch: 9 [57600/64707 (89%)]	Loss: 175.275482 | Elapsed: 12.49s
01/28/2023 10:29:32 PM  [*] Sat Jan 28 22:29:32 2023: Train Epoch: 9 [64000/64707 (99%)]	Loss: 174.126862 | Elapsed: 12.54s
01/28/2023 10:29:35 PM  [*] Sat Jan 28 22:29:35 2023:    9    | Tr.loss: 177.604805 | Elapsed:  127.73  s
01/28/2023 10:29:35 PM  [*] Started epoch: 10
01/28/2023 10:29:35 PM  [*] Sat Jan 28 22:29:35 2023: Train Epoch: 10 [  0  /64707 (0 %)]	Loss: 168.149048 | Elapsed: 0.21s
01/28/2023 10:29:47 PM  [*] Sat Jan 28 22:29:47 2023: Train Epoch: 10 [6400 /64707 (10%)]	Loss: 182.808121 | Elapsed: 12.56s
01/28/2023 10:30:00 PM  [*] Sat Jan 28 22:30:00 2023: Train Epoch: 10 [12800/64707 (20%)]	Loss: 169.750519 | Elapsed: 12.44s
01/28/2023 10:30:12 PM  [*] Sat Jan 28 22:30:12 2023: Train Epoch: 10 [19200/64707 (30%)]	Loss: 170.484512 | Elapsed: 12.37s
01/28/2023 10:30:25 PM  [*] Sat Jan 28 22:30:25 2023: Train Epoch: 10 [25600/64707 (40%)]	Loss: 157.229523 | Elapsed: 12.46s
01/28/2023 10:30:37 PM  [*] Sat Jan 28 22:30:37 2023: Train Epoch: 10 [32000/64707 (49%)]	Loss: 171.165039 | Elapsed: 12.41s
01/28/2023 10:30:50 PM  [*] Sat Jan 28 22:30:50 2023: Train Epoch: 10 [38400/64707 (59%)]	Loss: 191.553772 | Elapsed: 12.52s
01/28/2023 10:31:02 PM  [*] Sat Jan 28 22:31:02 2023: Train Epoch: 10 [44800/64707 (69%)]	Loss: 170.749954 | Elapsed: 12.41s
01/28/2023 10:31:14 PM  [*] Sat Jan 28 22:31:14 2023: Train Epoch: 10 [51200/64707 (79%)]	Loss: 169.120148 | Elapsed: 12.45s
01/28/2023 10:31:26 PM [!] Learning rate: 2.5e-06
01/28/2023 10:31:27 PM  [*] Sat Jan 28 22:31:27 2023: Train Epoch: 10 [57600/64707 (89%)]	Loss: 186.645905 | Elapsed: 12.45s
01/28/2023 10:31:39 PM  [*] Sat Jan 28 22:31:39 2023: Train Epoch: 10 [64000/64707 (99%)]	Loss: 175.252777 | Elapsed: 12.54s
01/28/2023 10:31:43 PM  [*] Sat Jan 28 22:31:43 2023:   10    | Tr.loss: 177.382492 | Elapsed:  127.89  s
01/28/2023 10:31:43 PM [!] Sat Jan 28 22:31:43 2023: Dumped results:
                model     : 1674941503-model.torch
		train time: 1674941503-trainTime.npy
		train losses: 1674941503-trainLosses.npy
		train AUC: 1674941503-auc.npy
01/28/2023 10:31:45 PM  [!] Training pretrained model on downstream task...
01/28/2023 10:31:45 PM  [*] Started epoch: 1
01/28/2023 10:31:46 PM  [*] Sat Jan 28 22:31:46 2023: Train Epoch: 1 [  0  /11419 (0 %)]	Loss: 1.529521 | Elapsed: 0.22s | FPR 0.0003 -> TPR 0.2292 & F1 0.3729 | AUC 0.5768
01/28/2023 10:31:55 PM  [*] Sat Jan 28 22:31:55 2023: Train Epoch: 1 [6400 /11419 (56%)]	Loss: 0.687940 | Elapsed: 9.12s | FPR 0.0003 -> TPR 0.1452 & F1 0.2535 | AUC 0.7640
01/28/2023 10:32:02 PM  [*] Sat Jan 28 22:32:02 2023:    1    | Tr.loss: 0.481402 | Elapsed:   16.67  s | FPR 0.0003 -> TPR: 0.03 & F1: 0.07 | AUC: 0.8230
01/28/2023 10:32:02 PM  [*] Started epoch: 2
01/28/2023 10:32:02 PM  [*] Sat Jan 28 22:32:02 2023: Train Epoch: 2 [  0  /11419 (0 %)]	Loss: 0.516922 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.1429 & F1 0.2500 | AUC 0.8301
01/28/2023 10:32:11 PM  [*] Sat Jan 28 22:32:11 2023: Train Epoch: 2 [6400 /11419 (56%)]	Loss: 0.360410 | Elapsed: 9.06s | FPR 0.0003 -> TPR 0.5000 & F1 0.6667 | AUC 0.8721
01/28/2023 10:32:18 PM  [*] Sat Jan 28 22:32:18 2023:    2    | Tr.loss: 0.343420 | Elapsed:   16.51  s | FPR 0.0003 -> TPR: 0.25 & F1: 0.40 | AUC: 0.9064
01/28/2023 10:32:18 PM  [*] Started epoch: 3
01/28/2023 10:32:19 PM  [*] Sat Jan 28 22:32:19 2023: Train Epoch: 3 [  0  /11419 (0 %)]	Loss: 0.334957 | Elapsed: 0.11s | FPR 0.0003 -> TPR 0.7750 & F1 0.8732 | AUC 0.9245
01/28/2023 10:32:28 PM  [*] Sat Jan 28 22:32:28 2023: Train Epoch: 3 [6400 /11419 (56%)]	Loss: 0.276408 | Elapsed: 9.07s | FPR 0.0003 -> TPR 0.7571 & F1 0.8618 | AUC 0.9581
01/28/2023 10:32:35 PM  [*] Sat Jan 28 22:32:35 2023:    3    | Tr.loss: 0.264092 | Elapsed:   16.47  s | FPR 0.0003 -> TPR: 0.35 & F1: 0.52 | AUC: 0.9489
01/28/2023 10:32:35 PM [!] Sat Jan 28 22:32:35 2023: Dumped results:
                model     : 1674941555-model.torch
		train time: 1674941555-trainTime.npy
		train losses: 1674941555-trainLosses.npy
		train AUC: 1674941555-auc.npy
		train F1s : 1674941555-trainF1s.npy
		train TPRs: 1674941555-trainTPRs.npy
01/28/2023 10:32:35 PM  [!] Training non_pretrained model on downstream task...
01/28/2023 10:32:36 PM  [*] Started epoch: 1
01/28/2023 10:32:36 PM  [*] Sat Jan 28 22:32:36 2023: Train Epoch: 1 [  0  /11419 (0 %)]	Loss: 1.649267 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.4781
01/28/2023 10:32:42 PM  [*] Sat Jan 28 22:32:42 2023: Train Epoch: 1 [6400 /11419 (56%)]	Loss: 0.407078 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.0694 & F1 0.1299 | AUC 0.8299
01/28/2023 10:32:47 PM  [*] Sat Jan 28 22:32:47 2023:    1    | Tr.loss: 0.511420 | Elapsed:   11.37  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8005
01/28/2023 10:32:47 PM  [*] Started epoch: 2
01/28/2023 10:32:47 PM  [*] Sat Jan 28 22:32:47 2023: Train Epoch: 2 [  0  /11419 (0 %)]	Loss: 0.254858 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.8125 & F1 0.8966 | AUC 0.9596
01/28/2023 10:32:53 PM  [*] Sat Jan 28 22:32:53 2023: Train Epoch: 2 [6400 /11419 (56%)]	Loss: 0.307054 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.6176 & F1 0.7636 | AUC 0.9265
01/28/2023 10:32:59 PM  [*] Sat Jan 28 22:32:59 2023:    2    | Tr.loss: 0.334831 | Elapsed:   11.37  s | FPR 0.0003 -> TPR: 0.09 & F1: 0.17 | AUC: 0.9118
01/28/2023 10:32:59 PM  [*] Started epoch: 3
01/28/2023 10:32:59 PM  [*] Sat Jan 28 22:32:59 2023: Train Epoch: 3 [  0  /11419 (0 %)]	Loss: 0.203040 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.7143 & F1 0.8333 | AUC 0.9483
01/28/2023 10:33:05 PM  [*] Sat Jan 28 22:33:05 2023: Train Epoch: 3 [6400 /11419 (56%)]	Loss: 0.395185 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.5571 & F1 0.7156 | AUC 0.9224
01/28/2023 10:33:10 PM  [*] Sat Jan 28 22:33:10 2023:    3    | Tr.loss: 0.267803 | Elapsed:   11.31  s | FPR 0.0003 -> TPR: 0.25 & F1: 0.40 | AUC: 0.9468
01/28/2023 10:33:10 PM [!] Sat Jan 28 22:33:10 2023: Dumped results:
                model     : 1674941590-model.torch
		train time: 1674941590-trainTime.npy
		train losses: 1674941590-trainLosses.npy
		train AUC: 1674941590-auc.npy
		train F1s : 1674941590-trainF1s.npy
		train TPRs: 1674941590-trainTPRs.npy
01/28/2023 10:33:10 PM  [!] Training full_data model on downstream task...
01/28/2023 10:33:11 PM  [*] Started epoch: 1
01/28/2023 10:33:11 PM  [*] Sat Jan 28 22:33:11 2023: Train Epoch: 1 [  0  /76126 (0 %)]	Loss: 2.252913 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.1250 & F1 0.2222 | AUC 0.5635
01/28/2023 10:33:17 PM  [*] Sat Jan 28 22:33:17 2023: Train Epoch: 1 [6400 /76126 (8 %)]	Loss: 0.505211 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.3621 & F1 0.5316 | AUC 0.8309
01/28/2023 10:33:23 PM  [*] Sat Jan 28 22:33:23 2023: Train Epoch: 1 [12800/76126 (17%)]	Loss: 0.519155 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.1250 & F1 0.2222 | AUC 0.8140
01/28/2023 10:33:30 PM  [*] Sat Jan 28 22:33:30 2023: Train Epoch: 1 [19200/76126 (25%)]	Loss: 0.255034 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.3788 & F1 0.5495 | AUC 0.9327
01/28/2023 10:33:36 PM  [*] Sat Jan 28 22:33:36 2023: Train Epoch: 1 [25600/76126 (34%)]	Loss: 0.379101 | Elapsed: 6.26s | FPR 0.0003 -> TPR 0.4677 & F1 0.6374 | AUC 0.8969
01/28/2023 10:33:42 PM  [*] Sat Jan 28 22:33:42 2023: Train Epoch: 1 [32000/76126 (42%)]	Loss: 0.226662 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.6429 & F1 0.7826 | AUC 0.9529
01/28/2023 10:33:48 PM  [*] Sat Jan 28 22:33:48 2023: Train Epoch: 1 [38400/76126 (50%)]	Loss: 0.193803 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.8000 & F1 0.8889 | AUC 0.9684
01/28/2023 10:33:54 PM  [*] Sat Jan 28 22:33:54 2023: Train Epoch: 1 [44800/76126 (59%)]	Loss: 0.217372 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.5139 & F1 0.6789 | AUC 0.9593
01/28/2023 10:34:01 PM  [*] Sat Jan 28 22:34:01 2023: Train Epoch: 1 [51200/76126 (67%)]	Loss: 0.307162 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.6500 & F1 0.7879 | AUC 0.9392
01/28/2023 10:34:07 PM  [*] Sat Jan 28 22:34:07 2023: Train Epoch: 1 [57600/76126 (76%)]	Loss: 0.118679 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.8824 & F1 0.9375 | AUC 0.9949
01/28/2023 10:34:13 PM [!] Learning rate: 2.5e-05
01/28/2023 10:34:13 PM  [*] Sat Jan 28 22:34:13 2023: Train Epoch: 1 [64000/76126 (84%)]	Loss: 0.137389 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.9375 & F1 0.9677 | AUC 0.9926
01/28/2023 10:34:19 PM  [*] Sat Jan 28 22:34:19 2023: Train Epoch: 1 [70400/76126 (92%)]	Loss: 0.152232 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.7971 & F1 0.8871 | AUC 0.9766
01/28/2023 10:34:27 PM  [*] Sat Jan 28 22:34:27 2023:    1    | Tr.loss: 0.302331 | Elapsed:   75.83  s | FPR 0.0003 -> TPR: 0.04 & F1: 0.08 | AUC: 0.9328
01/28/2023 10:34:27 PM  [*] Started epoch: 2
01/28/2023 10:34:27 PM  [*] Sat Jan 28 22:34:27 2023: Train Epoch: 2 [  0  /76126 (0 %)]	Loss: 0.113642 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.9302 & F1 0.9639 | AUC 0.9956
01/28/2023 10:34:33 PM  [*] Sat Jan 28 22:34:33 2023: Train Epoch: 2 [6400 /76126 (8 %)]	Loss: 0.257118 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.2105 & F1 0.3478 | AUC 0.9657
01/28/2023 10:34:39 PM  [*] Sat Jan 28 22:34:39 2023: Train Epoch: 2 [12800/76126 (17%)]	Loss: 0.204550 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.8125 & F1 0.8966 | AUC 0.9822
01/28/2023 10:34:45 PM  [*] Sat Jan 28 22:34:45 2023: Train Epoch: 2 [19200/76126 (25%)]	Loss: 0.150334 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.8939 & F1 0.9440 | AUC 0.9947
01/28/2023 10:34:52 PM  [*] Sat Jan 28 22:34:52 2023: Train Epoch: 2 [25600/76126 (34%)]	Loss: 0.100678 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.9394 & F1 0.9688 | AUC 0.9938
01/28/2023 10:34:58 PM  [*] Sat Jan 28 22:34:58 2023: Train Epoch: 2 [32000/76126 (42%)]	Loss: 0.210668 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.7077 & F1 0.8288 | AUC 0.9754
01/28/2023 10:35:04 PM  [*] Sat Jan 28 22:35:04 2023: Train Epoch: 2 [38400/76126 (50%)]	Loss: 0.147609 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.7619 & F1 0.8649 | AUC 0.9880
01/28/2023 10:35:10 PM  [*] Sat Jan 28 22:35:10 2023: Train Epoch: 2 [44800/76126 (59%)]	Loss: 0.171121 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.9231 & F1 0.9600 | AUC 0.9855
01/28/2023 10:35:16 PM  [*] Sat Jan 28 22:35:16 2023: Train Epoch: 2 [51200/76126 (67%)]	Loss: 0.138323 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.9286 & F1 0.9630 | AUC 0.9905
01/28/2023 10:35:17 PM [!] Learning rate: 2.5e-06
01/28/2023 10:35:23 PM  [*] Sat Jan 28 22:35:23 2023: Train Epoch: 2 [57600/76126 (76%)]	Loss: 0.120827 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.8923 & F1 0.9431 | AUC 0.9877
01/28/2023 10:35:29 PM  [*] Sat Jan 28 22:35:29 2023: Train Epoch: 2 [64000/76126 (84%)]	Loss: 0.108283 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.9286 & F1 0.9630 | AUC 0.9938
01/28/2023 10:35:35 PM  [*] Sat Jan 28 22:35:35 2023: Train Epoch: 2 [70400/76126 (92%)]	Loss: 0.174038 | Elapsed: 6.29s | FPR 0.0003 -> TPR 0.7639 & F1 0.8661 | AUC 0.9747
01/28/2023 10:35:43 PM  [*] Sat Jan 28 22:35:43 2023:    2    | Tr.loss: 0.166153 | Elapsed:   75.91  s | FPR 0.0003 -> TPR: 0.46 & F1: 0.63 | AUC: 0.9809
01/28/2023 10:35:43 PM  [*] Started epoch: 3
01/28/2023 10:35:43 PM  [*] Sat Jan 28 22:35:43 2023: Train Epoch: 3 [  0  /76126 (0 %)]	Loss: 0.154341 | Elapsed: 0.13s | FPR 0.0003 -> TPR 0.8750 & F1 0.9333 | AUC 0.9857
01/28/2023 10:35:49 PM  [*] Sat Jan 28 22:35:49 2023: Train Epoch: 3 [6400 /76126 (8 %)]	Loss: 0.181085 | Elapsed: 6.28s | FPR 0.0003 -> TPR 0.6618 & F1 0.7965 | AUC 0.9793
01/28/2023 10:35:55 PM  [*] Sat Jan 28 22:35:55 2023: Train Epoch: 3 [12800/76126 (17%)]	Loss: 0.148112 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.7705 & F1 0.8704 | AUC 0.9895
01/28/2023 10:36:01 PM  [*] Sat Jan 28 22:36:01 2023: Train Epoch: 3 [19200/76126 (25%)]	Loss: 0.135007 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.9296 & F1 0.9635 | AUC 0.9937
01/28/2023 10:36:08 PM  [*] Sat Jan 28 22:36:08 2023: Train Epoch: 3 [25600/76126 (34%)]	Loss: 0.124221 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.7313 & F1 0.8448 | AUC 0.9778
01/28/2023 10:36:14 PM  [*] Sat Jan 28 22:36:14 2023: Train Epoch: 3 [32000/76126 (42%)]	Loss: 0.086847 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.6119 & F1 0.7593 | AUC 0.9851
01/28/2023 10:36:20 PM  [*] Sat Jan 28 22:36:20 2023: Train Epoch: 3 [38400/76126 (50%)]	Loss: 0.177273 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.8548 & F1 0.9217 | AUC 0.9839
01/28/2023 10:36:21 PM [!] Learning rate: 2.5000000000000004e-07
01/28/2023 10:36:26 PM  [*] Sat Jan 28 22:36:26 2023: Train Epoch: 3 [44800/76126 (59%)]	Loss: 0.113439 | Elapsed: 6.26s | FPR 0.0003 -> TPR 0.9310 & F1 0.9643 | AUC 0.9947
01/28/2023 10:36:33 PM  [*] Sat Jan 28 22:36:33 2023: Train Epoch: 3 [51200/76126 (67%)]	Loss: 0.291068 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.5405 & F1 0.7018 | AUC 0.9506
01/28/2023 10:36:39 PM  [*] Sat Jan 28 22:36:39 2023: Train Epoch: 3 [57600/76126 (76%)]	Loss: 0.170850 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.8571 & F1 0.9231 | AUC 0.9829
01/28/2023 10:36:45 PM  [*] Sat Jan 28 22:36:45 2023: Train Epoch: 3 [64000/76126 (84%)]	Loss: 0.168299 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.9067 & F1 0.9510 | AUC 0.9883
01/28/2023 10:36:51 PM  [*] Sat Jan 28 22:36:51 2023: Train Epoch: 3 [70400/76126 (92%)]	Loss: 0.201812 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.6613 & F1 0.7961 | AUC 0.9605
01/28/2023 10:36:59 PM  [*] Sat Jan 28 22:36:59 2023:    3    | Tr.loss: 0.159010 | Elapsed:   76.02  s | FPR 0.0003 -> TPR: 0.44 & F1: 0.61 | AUC: 0.9825
01/28/2023 10:36:59 PM [!] Sat Jan 28 22:36:59 2023: Dumped results:
                model     : 1674941819-model.torch
		train time: 1674941819-trainTime.npy
		train losses: 1674941819-trainLosses.npy
		train AUC: 1674941819-auc.npy
		train F1s : 1674941819-trainF1s.npy
		train TPRs: 1674941819-trainTPRs.npy
01/28/2023 10:36:59 PM  [*] Evaluating pretrained model on test set...
01/28/2023 10:37:04 PM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.1026 | F1: 0.1861
01/28/2023 10:37:04 PM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.2340 | F1: 0.3791
01/28/2023 10:37:04 PM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.3746 | F1: 0.5447
01/28/2023 10:37:04 PM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.4060 | F1: 0.5765
01/28/2023 10:37:04 PM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.4612 | F1: 0.6276
01/28/2023 10:37:04 PM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.5100 | F1: 0.6643
01/28/2023 10:37:04 PM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.6656 | F1: 0.7605
01/28/2023 10:37:04 PM  [*] Evaluating non_pretrained model on test set...
01/28/2023 10:37:09 PM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0296 | F1: 0.0574
01/28/2023 10:37:09 PM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1552 | F1: 0.2686
01/28/2023 10:37:09 PM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.2401 | F1: 0.3870
01/28/2023 10:37:09 PM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3143 | F1: 0.4773
01/28/2023 10:37:09 PM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3573 | F1: 0.5232
01/28/2023 10:37:09 PM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4466 | F1: 0.6067
01/28/2023 10:37:09 PM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.6551 | F1: 0.7529
01/28/2023 10:37:09 PM  [*] Evaluating full_data model on test set...
01/28/2023 10:37:14 PM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0007 | F1: 0.0015
01/28/2023 10:37:14 PM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.2411 | F1: 0.3885
01/28/2023 10:37:14 PM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.3029 | F1: 0.4646
01/28/2023 10:37:14 PM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3829 | F1: 0.5527
01/28/2023 10:37:14 PM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.4845 | F1: 0.6490
01/28/2023 10:37:14 PM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.5940 | F1: 0.7335
01/28/2023 10:37:14 PM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.7939 | F1: 0.8451
01/28/2023 10:37:14 PM  [!] Running pre-training split 2/3
01/28/2023 10:37:17 PM  [!] Pre-training model...
01/28/2023 10:37:18 PM  [*] Masking sequences...
01/28/2023 10:37:38 PM  [*] Started epoch: 1
01/28/2023 10:37:39 PM  [*] Sat Jan 28 22:37:39 2023: Train Epoch: 1 [  0  /64707 (0 %)]	Loss: 398.586914 | Elapsed: 0.83s
01/28/2023 10:37:51 PM  [*] Sat Jan 28 22:37:51 2023: Train Epoch: 1 [6400 /64707 (10%)]	Loss: 223.885941 | Elapsed: 12.29s
01/28/2023 10:38:03 PM  [*] Sat Jan 28 22:38:03 2023: Train Epoch: 1 [12800/64707 (20%)]	Loss: 229.465637 | Elapsed: 12.35s
01/28/2023 10:38:16 PM  [*] Sat Jan 28 22:38:16 2023: Train Epoch: 1 [19200/64707 (30%)]	Loss: 211.662567 | Elapsed: 12.40s
01/28/2023 10:38:28 PM  [*] Sat Jan 28 22:38:28 2023: Train Epoch: 1 [25600/64707 (40%)]	Loss: 196.309341 | Elapsed: 12.43s
01/28/2023 10:38:41 PM  [*] Sat Jan 28 22:38:41 2023: Train Epoch: 1 [32000/64707 (49%)]	Loss: 195.058777 | Elapsed: 12.39s
01/28/2023 10:38:53 PM  [*] Sat Jan 28 22:38:53 2023: Train Epoch: 1 [38400/64707 (59%)]	Loss: 187.007889 | Elapsed: 12.39s
01/28/2023 10:39:05 PM  [*] Sat Jan 28 22:39:05 2023: Train Epoch: 1 [44800/64707 (69%)]	Loss: 225.357666 | Elapsed: 12.43s
01/28/2023 10:39:18 PM  [*] Sat Jan 28 22:39:18 2023: Train Epoch: 1 [51200/64707 (79%)]	Loss: 174.284302 | Elapsed: 12.44s
01/28/2023 10:39:30 PM  [*] Sat Jan 28 22:39:30 2023: Train Epoch: 1 [57600/64707 (89%)]	Loss: 177.607819 | Elapsed: 12.43s
01/28/2023 10:39:43 PM  [*] Sat Jan 28 22:39:43 2023: Train Epoch: 1 [64000/64707 (99%)]	Loss: 195.076721 | Elapsed: 12.50s
01/28/2023 10:39:46 PM  [*] Sat Jan 28 22:39:46 2023:    1    | Tr.loss: 212.388201 | Elapsed:  128.00  s
01/28/2023 10:39:46 PM  [*] Started epoch: 2
01/28/2023 10:39:46 PM  [*] Sat Jan 28 22:39:46 2023: Train Epoch: 2 [  0  /64707 (0 %)]	Loss: 189.203308 | Elapsed: 0.13s
01/28/2023 10:39:58 PM  [*] Sat Jan 28 22:39:58 2023: Train Epoch: 2 [6400 /64707 (10%)]	Loss: 179.889130 | Elapsed: 12.44s
01/28/2023 10:40:11 PM  [*] Sat Jan 28 22:40:11 2023: Train Epoch: 2 [12800/64707 (20%)]	Loss: 189.035065 | Elapsed: 12.48s
01/28/2023 10:40:23 PM  [*] Sat Jan 28 22:40:23 2023: Train Epoch: 2 [19200/64707 (30%)]	Loss: 177.811081 | Elapsed: 12.41s
01/28/2023 10:40:36 PM  [*] Sat Jan 28 22:40:36 2023: Train Epoch: 2 [25600/64707 (40%)]	Loss: 177.875534 | Elapsed: 12.44s
01/28/2023 10:40:48 PM  [*] Sat Jan 28 22:40:48 2023: Train Epoch: 2 [32000/64707 (49%)]	Loss: 199.696762 | Elapsed: 12.36s
01/28/2023 10:41:01 PM  [*] Sat Jan 28 22:41:01 2023: Train Epoch: 2 [38400/64707 (59%)]	Loss: 184.364578 | Elapsed: 12.48s
01/28/2023 10:41:13 PM  [*] Sat Jan 28 22:41:13 2023: Train Epoch: 2 [44800/64707 (69%)]	Loss: 214.442352 | Elapsed: 12.40s
01/28/2023 10:41:25 PM  [*] Sat Jan 28 22:41:25 2023: Train Epoch: 2 [51200/64707 (79%)]	Loss: 182.753326 | Elapsed: 12.46s
01/28/2023 10:41:38 PM  [*] Sat Jan 28 22:41:38 2023: Train Epoch: 2 [57600/64707 (89%)]	Loss: 195.062256 | Elapsed: 12.44s
01/28/2023 10:41:50 PM  [*] Sat Jan 28 22:41:50 2023: Train Epoch: 2 [64000/64707 (99%)]	Loss: 210.601837 | Elapsed: 12.37s
01/28/2023 10:41:53 PM  [*] Sat Jan 28 22:41:53 2023:    2    | Tr.loss: 193.182892 | Elapsed:  127.32  s
01/28/2023 10:41:53 PM  [*] Started epoch: 3
01/28/2023 10:41:53 PM  [*] Sat Jan 28 22:41:53 2023: Train Epoch: 3 [  0  /64707 (0 %)]	Loss: 195.606003 | Elapsed: 0.14s
01/28/2023 10:42:06 PM  [*] Sat Jan 28 22:42:06 2023: Train Epoch: 3 [6400 /64707 (10%)]	Loss: 189.763565 | Elapsed: 12.28s
01/28/2023 10:42:18 PM  [*] Sat Jan 28 22:42:18 2023: Train Epoch: 3 [12800/64707 (20%)]	Loss: 190.858704 | Elapsed: 12.23s
01/28/2023 10:42:30 PM  [*] Sat Jan 28 22:42:30 2023: Train Epoch: 3 [19200/64707 (30%)]	Loss: 206.703156 | Elapsed: 12.34s
01/28/2023 10:42:42 PM  [*] Sat Jan 28 22:42:42 2023: Train Epoch: 3 [25600/64707 (40%)]	Loss: 187.282578 | Elapsed: 12.21s
01/28/2023 10:42:55 PM  [*] Sat Jan 28 22:42:55 2023: Train Epoch: 3 [32000/64707 (49%)]	Loss: 213.842682 | Elapsed: 12.20s
01/28/2023 10:43:07 PM  [*] Sat Jan 28 22:43:07 2023: Train Epoch: 3 [38400/64707 (59%)]	Loss: 178.227875 | Elapsed: 12.20s
01/28/2023 10:43:19 PM  [*] Sat Jan 28 22:43:19 2023: Train Epoch: 3 [44800/64707 (69%)]	Loss: 182.665375 | Elapsed: 12.22s
01/28/2023 10:43:31 PM  [*] Sat Jan 28 22:43:31 2023: Train Epoch: 3 [51200/64707 (79%)]	Loss: 211.798050 | Elapsed: 12.25s
01/28/2023 10:43:44 PM  [*] Sat Jan 28 22:43:44 2023: Train Epoch: 3 [57600/64707 (89%)]	Loss: 169.099457 | Elapsed: 12.24s
01/28/2023 10:43:56 PM  [*] Sat Jan 28 22:43:56 2023: Train Epoch: 3 [64000/64707 (99%)]	Loss: 190.760925 | Elapsed: 12.20s
01/28/2023 10:43:59 PM  [*] Sat Jan 28 22:43:59 2023:    3    | Tr.loss: 187.580605 | Elapsed:  125.42  s
01/28/2023 10:43:59 PM  [*] Started epoch: 4
01/28/2023 10:43:59 PM  [*] Sat Jan 28 22:43:59 2023: Train Epoch: 4 [  0  /64707 (0 %)]	Loss: 157.795837 | Elapsed: 0.13s
01/28/2023 10:44:11 PM  [*] Sat Jan 28 22:44:11 2023: Train Epoch: 4 [6400 /64707 (10%)]	Loss: 184.537506 | Elapsed: 12.29s
01/28/2023 10:44:23 PM  [*] Sat Jan 28 22:44:23 2023: Train Epoch: 4 [12800/64707 (20%)]	Loss: 176.521744 | Elapsed: 12.23s
01/28/2023 10:44:36 PM  [*] Sat Jan 28 22:44:36 2023: Train Epoch: 4 [19200/64707 (30%)]	Loss: 189.833649 | Elapsed: 12.25s
01/28/2023 10:44:48 PM  [*] Sat Jan 28 22:44:48 2023: Train Epoch: 4 [25600/64707 (40%)]	Loss: 174.803680 | Elapsed: 12.20s
01/28/2023 10:45:00 PM  [*] Sat Jan 28 22:45:00 2023: Train Epoch: 4 [32000/64707 (49%)]	Loss: 210.833359 | Elapsed: 12.29s
01/28/2023 10:45:12 PM  [*] Sat Jan 28 22:45:12 2023: Train Epoch: 4 [38400/64707 (59%)]	Loss: 181.125305 | Elapsed: 12.21s
01/28/2023 10:45:24 PM  [*] Sat Jan 28 22:45:24 2023: Train Epoch: 4 [44800/64707 (69%)]	Loss: 173.881287 | Elapsed: 12.21s
01/28/2023 10:45:37 PM  [*] Sat Jan 28 22:45:37 2023: Train Epoch: 4 [51200/64707 (79%)]	Loss: 193.020050 | Elapsed: 12.22s
01/28/2023 10:45:49 PM  [*] Sat Jan 28 22:45:49 2023: Train Epoch: 4 [57600/64707 (89%)]	Loss: 196.172272 | Elapsed: 12.21s
01/28/2023 10:46:01 PM  [*] Sat Jan 28 22:46:01 2023: Train Epoch: 4 [64000/64707 (99%)]	Loss: 201.888474 | Elapsed: 12.19s
01/28/2023 10:46:04 PM  [*] Sat Jan 28 22:46:04 2023:    4    | Tr.loss: 184.883629 | Elapsed:  125.41  s
01/28/2023 10:46:04 PM  [*] Started epoch: 5
01/28/2023 10:46:04 PM  [*] Sat Jan 28 22:46:04 2023: Train Epoch: 5 [  0  /64707 (0 %)]	Loss: 179.886520 | Elapsed: 0.13s
01/28/2023 10:46:16 PM  [*] Sat Jan 28 22:46:16 2023: Train Epoch: 5 [6400 /64707 (10%)]	Loss: 170.365356 | Elapsed: 12.30s
01/28/2023 10:46:29 PM  [*] Sat Jan 28 22:46:29 2023: Train Epoch: 5 [12800/64707 (20%)]	Loss: 195.876831 | Elapsed: 12.28s
01/28/2023 10:46:41 PM  [*] Sat Jan 28 22:46:41 2023: Train Epoch: 5 [19200/64707 (30%)]	Loss: 176.800964 | Elapsed: 12.29s
01/28/2023 10:46:53 PM  [*] Sat Jan 28 22:46:53 2023: Train Epoch: 5 [25600/64707 (40%)]	Loss: 186.621948 | Elapsed: 12.25s
01/28/2023 10:47:05 PM  [*] Sat Jan 28 22:47:05 2023: Train Epoch: 5 [32000/64707 (49%)]	Loss: 172.524246 | Elapsed: 12.19s
01/28/2023 10:47:18 PM  [*] Sat Jan 28 22:47:18 2023: Train Epoch: 5 [38400/64707 (59%)]	Loss: 194.004959 | Elapsed: 12.22s
01/28/2023 10:47:30 PM  [*] Sat Jan 28 22:47:30 2023: Train Epoch: 5 [44800/64707 (69%)]	Loss: 182.560883 | Elapsed: 12.31s
01/28/2023 10:47:42 PM  [*] Sat Jan 28 22:47:42 2023: Train Epoch: 5 [51200/64707 (79%)]	Loss: 195.220306 | Elapsed: 12.18s
01/28/2023 10:47:54 PM  [*] Sat Jan 28 22:47:54 2023: Train Epoch: 5 [57600/64707 (89%)]	Loss: 190.199753 | Elapsed: 12.21s
01/28/2023 10:48:01 PM [!] Learning rate: 2.5e-05
01/28/2023 10:48:07 PM  [*] Sat Jan 28 22:48:07 2023: Train Epoch: 5 [64000/64707 (99%)]	Loss: 186.518570 | Elapsed: 12.22s
01/28/2023 10:48:10 PM  [*] Sat Jan 28 22:48:10 2023:    5    | Tr.loss: 183.228567 | Elapsed:  125.57  s
01/28/2023 10:48:10 PM  [*] Started epoch: 6
01/28/2023 10:48:10 PM  [*] Sat Jan 28 22:48:10 2023: Train Epoch: 6 [  0  /64707 (0 %)]	Loss: 184.418732 | Elapsed: 0.14s
01/28/2023 10:48:22 PM  [*] Sat Jan 28 22:48:22 2023: Train Epoch: 6 [6400 /64707 (10%)]	Loss: 185.416016 | Elapsed: 12.30s
01/28/2023 10:48:34 PM  [*] Sat Jan 28 22:48:34 2023: Train Epoch: 6 [12800/64707 (20%)]	Loss: 160.055832 | Elapsed: 12.24s
01/28/2023 10:48:47 PM  [*] Sat Jan 28 22:48:47 2023: Train Epoch: 6 [19200/64707 (30%)]	Loss: 194.253876 | Elapsed: 12.24s
01/28/2023 10:48:59 PM  [*] Sat Jan 28 22:48:59 2023: Train Epoch: 6 [25600/64707 (40%)]	Loss: 171.711411 | Elapsed: 12.21s
01/28/2023 10:49:11 PM  [*] Sat Jan 28 22:49:11 2023: Train Epoch: 6 [32000/64707 (49%)]	Loss: 163.607513 | Elapsed: 12.22s
01/28/2023 10:49:23 PM  [*] Sat Jan 28 22:49:23 2023: Train Epoch: 6 [38400/64707 (59%)]	Loss: 178.828400 | Elapsed: 12.31s
01/28/2023 10:49:36 PM  [*] Sat Jan 28 22:49:36 2023: Train Epoch: 6 [44800/64707 (69%)]	Loss: 190.940750 | Elapsed: 12.27s
01/28/2023 10:49:48 PM  [*] Sat Jan 28 22:49:48 2023: Train Epoch: 6 [51200/64707 (79%)]	Loss: 176.303543 | Elapsed: 12.22s
01/28/2023 10:50:00 PM  [*] Sat Jan 28 22:50:00 2023: Train Epoch: 6 [57600/64707 (89%)]	Loss: 185.374634 | Elapsed: 12.35s
01/28/2023 10:50:12 PM  [*] Sat Jan 28 22:50:12 2023: Train Epoch: 6 [64000/64707 (99%)]	Loss: 205.527893 | Elapsed: 12.23s
01/28/2023 10:50:15 PM  [*] Sat Jan 28 22:50:15 2023:    6    | Tr.loss: 181.597208 | Elapsed:  125.68  s
01/28/2023 10:50:15 PM  [*] Started epoch: 7
01/28/2023 10:50:15 PM  [*] Sat Jan 28 22:50:15 2023: Train Epoch: 7 [  0  /64707 (0 %)]	Loss: 164.940750 | Elapsed: 0.13s
01/28/2023 10:50:28 PM  [*] Sat Jan 28 22:50:28 2023: Train Epoch: 7 [6400 /64707 (10%)]	Loss: 163.861053 | Elapsed: 12.30s
01/28/2023 10:50:40 PM  [*] Sat Jan 28 22:50:40 2023: Train Epoch: 7 [12800/64707 (20%)]	Loss: 162.931259 | Elapsed: 12.25s
01/28/2023 10:50:52 PM  [*] Sat Jan 28 22:50:52 2023: Train Epoch: 7 [19200/64707 (30%)]	Loss: 166.442947 | Elapsed: 12.20s
01/28/2023 10:51:04 PM  [*] Sat Jan 28 22:51:04 2023: Train Epoch: 7 [25600/64707 (40%)]	Loss: 191.371140 | Elapsed: 12.23s
01/28/2023 10:51:17 PM  [*] Sat Jan 28 22:51:17 2023: Train Epoch: 7 [32000/64707 (49%)]	Loss: 185.037415 | Elapsed: 12.23s
01/28/2023 10:51:29 PM  [*] Sat Jan 28 22:51:29 2023: Train Epoch: 7 [38400/64707 (59%)]	Loss: 204.322067 | Elapsed: 12.27s
01/28/2023 10:51:41 PM  [*] Sat Jan 28 22:51:41 2023: Train Epoch: 7 [44800/64707 (69%)]	Loss: 178.477005 | Elapsed: 12.33s
01/28/2023 10:51:53 PM  [*] Sat Jan 28 22:51:53 2023: Train Epoch: 7 [51200/64707 (79%)]	Loss: 202.877625 | Elapsed: 12.22s
01/28/2023 10:52:06 PM  [*] Sat Jan 28 22:52:06 2023: Train Epoch: 7 [57600/64707 (89%)]	Loss: 189.069427 | Elapsed: 12.23s
01/28/2023 10:52:18 PM  [*] Sat Jan 28 22:52:18 2023: Train Epoch: 7 [64000/64707 (99%)]	Loss: 166.662262 | Elapsed: 12.31s
01/28/2023 10:52:21 PM  [*] Sat Jan 28 22:52:21 2023:    7    | Tr.loss: 181.413254 | Elapsed:  125.69  s
01/28/2023 10:52:21 PM  [*] Started epoch: 8
01/28/2023 10:52:21 PM  [*] Sat Jan 28 22:52:21 2023: Train Epoch: 8 [  0  /64707 (0 %)]	Loss: 198.264725 | Elapsed: 0.13s
01/28/2023 10:52:33 PM  [*] Sat Jan 28 22:52:33 2023: Train Epoch: 8 [6400 /64707 (10%)]	Loss: 179.304047 | Elapsed: 12.35s
01/28/2023 10:52:46 PM  [*] Sat Jan 28 22:52:46 2023: Train Epoch: 8 [12800/64707 (20%)]	Loss: 188.357208 | Elapsed: 12.32s
01/28/2023 10:52:58 PM  [*] Sat Jan 28 22:52:58 2023: Train Epoch: 8 [19200/64707 (30%)]	Loss: 190.407440 | Elapsed: 12.42s
01/28/2023 10:53:11 PM  [*] Sat Jan 28 22:53:11 2023: Train Epoch: 8 [25600/64707 (40%)]	Loss: 193.801514 | Elapsed: 12.50s
01/28/2023 10:53:23 PM  [*] Sat Jan 28 22:53:23 2023: Train Epoch: 8 [32000/64707 (49%)]	Loss: 162.956955 | Elapsed: 12.39s
01/28/2023 10:53:35 PM  [*] Sat Jan 28 22:53:35 2023: Train Epoch: 8 [38400/64707 (59%)]	Loss: 189.241440 | Elapsed: 12.29s
01/28/2023 10:53:48 PM  [*] Sat Jan 28 22:53:48 2023: Train Epoch: 8 [44800/64707 (69%)]	Loss: 188.605835 | Elapsed: 12.24s
01/28/2023 10:54:00 PM  [*] Sat Jan 28 22:54:00 2023: Train Epoch: 8 [51200/64707 (79%)]	Loss: 194.561310 | Elapsed: 12.27s
01/28/2023 10:54:12 PM  [*] Sat Jan 28 22:54:12 2023: Train Epoch: 8 [57600/64707 (89%)]	Loss: 188.695374 | Elapsed: 12.24s
01/28/2023 10:54:24 PM  [*] Sat Jan 28 22:54:24 2023: Train Epoch: 8 [64000/64707 (99%)]	Loss: 160.278320 | Elapsed: 12.28s
01/28/2023 10:54:27 PM  [*] Sat Jan 28 22:54:27 2023:    8    | Tr.loss: 181.211410 | Elapsed:  126.33  s
01/28/2023 10:54:27 PM  [*] Started epoch: 9
01/28/2023 10:54:27 PM  [*] Sat Jan 28 22:54:27 2023: Train Epoch: 9 [  0  /64707 (0 %)]	Loss: 162.927917 | Elapsed: 0.12s
01/28/2023 10:54:40 PM  [*] Sat Jan 28 22:54:40 2023: Train Epoch: 9 [6400 /64707 (10%)]	Loss: 196.314575 | Elapsed: 12.27s
01/28/2023 10:54:52 PM  [*] Sat Jan 28 22:54:52 2023: Train Epoch: 9 [12800/64707 (20%)]	Loss: 184.805908 | Elapsed: 12.21s
01/28/2023 10:55:04 PM  [*] Sat Jan 28 22:55:04 2023: Train Epoch: 9 [19200/64707 (30%)]	Loss: 196.698517 | Elapsed: 12.25s
01/28/2023 10:55:16 PM  [*] Sat Jan 28 22:55:16 2023: Train Epoch: 9 [25600/64707 (40%)]	Loss: 176.238419 | Elapsed: 12.31s
01/28/2023 10:55:29 PM  [*] Sat Jan 28 22:55:29 2023: Train Epoch: 9 [32000/64707 (49%)]	Loss: 156.438721 | Elapsed: 12.21s
01/28/2023 10:55:41 PM  [*] Sat Jan 28 22:55:41 2023: Train Epoch: 9 [38400/64707 (59%)]	Loss: 191.926422 | Elapsed: 12.27s
01/28/2023 10:55:53 PM  [*] Sat Jan 28 22:55:53 2023: Train Epoch: 9 [44800/64707 (69%)]	Loss: 183.352966 | Elapsed: 12.21s
01/28/2023 10:56:05 PM  [*] Sat Jan 28 22:56:05 2023: Train Epoch: 9 [51200/64707 (79%)]	Loss: 195.884979 | Elapsed: 12.26s
01/28/2023 10:56:18 PM  [*] Sat Jan 28 22:56:18 2023: Train Epoch: 9 [57600/64707 (89%)]	Loss: 172.849747 | Elapsed: 12.24s
01/28/2023 10:56:30 PM  [*] Sat Jan 28 22:56:30 2023: Train Epoch: 9 [64000/64707 (99%)]	Loss: 185.333038 | Elapsed: 12.23s
01/28/2023 10:56:33 PM  [*] Sat Jan 28 22:56:33 2023:    9    | Tr.loss: 181.102807 | Elapsed:  125.64  s
01/28/2023 10:56:33 PM  [*] Started epoch: 10
01/28/2023 10:56:33 PM  [*] Sat Jan 28 22:56:33 2023: Train Epoch: 10 [  0  /64707 (0 %)]	Loss: 171.282593 | Elapsed: 0.13s
01/28/2023 10:56:45 PM  [*] Sat Jan 28 22:56:45 2023: Train Epoch: 10 [6400 /64707 (10%)]	Loss: 184.985840 | Elapsed: 12.27s
01/28/2023 10:56:58 PM  [*] Sat Jan 28 22:56:58 2023: Train Epoch: 10 [12800/64707 (20%)]	Loss: 210.514023 | Elapsed: 12.21s
01/28/2023 10:57:10 PM  [*] Sat Jan 28 22:57:10 2023: Train Epoch: 10 [19200/64707 (30%)]	Loss: 174.596741 | Elapsed: 12.22s
01/28/2023 10:57:22 PM  [*] Sat Jan 28 22:57:22 2023: Train Epoch: 10 [25600/64707 (40%)]	Loss: 186.243927 | Elapsed: 12.26s
01/28/2023 10:57:34 PM  [*] Sat Jan 28 22:57:34 2023: Train Epoch: 10 [32000/64707 (49%)]	Loss: 177.040436 | Elapsed: 12.26s
01/28/2023 10:57:47 PM  [*] Sat Jan 28 22:57:47 2023: Train Epoch: 10 [38400/64707 (59%)]	Loss: 166.462753 | Elapsed: 12.32s
01/28/2023 10:57:59 PM  [*] Sat Jan 28 22:57:59 2023: Train Epoch: 10 [44800/64707 (69%)]	Loss: 196.144394 | Elapsed: 12.23s
01/28/2023 10:58:11 PM  [*] Sat Jan 28 22:58:11 2023: Train Epoch: 10 [51200/64707 (79%)]	Loss: 183.517242 | Elapsed: 12.19s
01/28/2023 10:58:22 PM [!] Learning rate: 2.5e-06
01/28/2023 10:58:23 PM  [*] Sat Jan 28 22:58:23 2023: Train Epoch: 10 [57600/64707 (89%)]	Loss: 180.949234 | Elapsed: 12.23s
01/28/2023 10:58:35 PM  [*] Sat Jan 28 22:58:35 2023: Train Epoch: 10 [64000/64707 (99%)]	Loss: 199.028305 | Elapsed: 12.24s
01/28/2023 10:58:38 PM  [*] Sat Jan 28 22:58:38 2023:   10    | Tr.loss: 180.875381 | Elapsed:  125.49  s
01/28/2023 10:58:39 PM [!] Sat Jan 28 22:58:39 2023: Dumped results:
                model     : 1674943118-model.torch
		train time: 1674943118-trainTime.npy
		train losses: 1674943118-trainLosses.npy
		train AUC: 1674943118-auc.npy
01/28/2023 10:58:41 PM  [!] Training pretrained model on downstream task...
01/28/2023 10:58:41 PM  [*] Started epoch: 1
01/28/2023 10:58:41 PM  [*] Sat Jan 28 22:58:41 2023: Train Epoch: 1 [  0  /11419 (0 %)]	Loss: 1.044902 | Elapsed: 0.42s | FPR 0.0003 -> TPR 0.2558 & F1 0.4074 | AUC 0.6932
01/28/2023 10:58:50 PM  [*] Sat Jan 28 22:58:50 2023: Train Epoch: 1 [6400 /11419 (56%)]	Loss: 0.535126 | Elapsed: 9.07s | FPR 0.0003 -> TPR 0.2714 & F1 0.4270 | AUC 0.8048
01/28/2023 10:58:58 PM  [*] Sat Jan 28 22:58:58 2023:    1    | Tr.loss: 0.496441 | Elapsed:   16.76  s | FPR 0.0003 -> TPR: 0.01 & F1: 0.01 | AUC: 0.8111
01/28/2023 10:58:58 PM  [*] Started epoch: 2
01/28/2023 10:58:58 PM  [*] Sat Jan 28 22:58:58 2023: Train Epoch: 2 [  0  /11419 (0 %)]	Loss: 0.473103 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.3256 & F1 0.4912 | AUC 0.8278
01/28/2023 10:59:07 PM  [*] Sat Jan 28 22:59:07 2023: Train Epoch: 2 [6400 /11419 (56%)]	Loss: 0.375705 | Elapsed: 9.05s | FPR 0.0003 -> TPR 0.5167 & F1 0.6813 | AUC 0.9104
01/28/2023 10:59:14 PM  [*] Sat Jan 28 22:59:14 2023:    2    | Tr.loss: 0.374341 | Elapsed:   16.47  s | FPR 0.0003 -> TPR: 0.29 & F1: 0.45 | AUC: 0.8935
01/28/2023 10:59:14 PM  [*] Started epoch: 3
01/28/2023 10:59:14 PM  [*] Sat Jan 28 22:59:14 2023: Train Epoch: 3 [  0  /11419 (0 %)]	Loss: 0.230023 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.8108 & F1 0.8955 | AUC 0.9690
01/28/2023 10:59:23 PM  [*] Sat Jan 28 22:59:23 2023: Train Epoch: 3 [6400 /11419 (56%)]	Loss: 0.312250 | Elapsed: 9.04s | FPR 0.0003 -> TPR 0.6119 & F1 0.7593 | AUC 0.9426
01/28/2023 10:59:30 PM  [*] Sat Jan 28 22:59:30 2023:    3    | Tr.loss: 0.284569 | Elapsed:   16.40  s | FPR 0.0003 -> TPR: 0.39 & F1: 0.56 | AUC: 0.9424
01/28/2023 10:59:31 PM [!] Sat Jan 28 22:59:31 2023: Dumped results:
                model     : 1674943170-model.torch
		train time: 1674943170-trainTime.npy
		train losses: 1674943170-trainLosses.npy
		train AUC: 1674943170-auc.npy
		train F1s : 1674943170-trainF1s.npy
		train TPRs: 1674943170-trainTPRs.npy
01/28/2023 10:59:31 PM  [!] Training non_pretrained model on downstream task...
01/28/2023 10:59:31 PM  [*] Started epoch: 1
01/28/2023 10:59:31 PM  [*] Sat Jan 28 22:59:31 2023: Train Epoch: 1 [  0  /11419 (0 %)]	Loss: 1.564770 | Elapsed: 0.05s | FPR 0.0003 -> TPR 0.0698 & F1 0.1304 | AUC 0.4751
01/28/2023 10:59:38 PM  [*] Sat Jan 28 22:59:38 2023: Train Epoch: 1 [6400 /11419 (56%)]	Loss: 0.457841 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.3485 & F1 0.5169 | AUC 0.8739
01/28/2023 10:59:43 PM  [*] Sat Jan 28 22:59:43 2023:    1    | Tr.loss: 0.515138 | Elapsed:   11.32  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.01 | AUC: 0.7948
01/28/2023 10:59:43 PM  [*] Started epoch: 2
01/28/2023 10:59:43 PM  [*] Sat Jan 28 22:59:43 2023: Train Epoch: 2 [  0  /11419 (0 %)]	Loss: 0.356873 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.4118 & F1 0.5833 | AUC 0.9324
01/28/2023 10:59:49 PM  [*] Sat Jan 28 22:59:49 2023: Train Epoch: 2 [6400 /11419 (56%)]	Loss: 0.369954 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.2400 & F1 0.3871 | AUC 0.8581
01/28/2023 10:59:54 PM  [*] Sat Jan 28 22:59:54 2023:    2    | Tr.loss: 0.339438 | Elapsed:   11.34  s | FPR 0.0003 -> TPR: 0.14 & F1: 0.25 | AUC: 0.9103
01/28/2023 10:59:54 PM  [*] Started epoch: 3
01/28/2023 10:59:54 PM  [*] Sat Jan 28 22:59:54 2023: Train Epoch: 3 [  0  /11419 (0 %)]	Loss: 0.312633 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.6250 & F1 0.7692 | AUC 0.9344
01/28/2023 11:00:00 PM  [*] Sat Jan 28 23:00:00 2023: Train Epoch: 3 [6400 /11419 (56%)]	Loss: 0.310136 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.6441 & F1 0.7835 | AUC 0.9533
01/28/2023 11:00:05 PM  [*] Sat Jan 28 23:00:05 2023:    3    | Tr.loss: 0.271930 | Elapsed:   11.27  s | FPR 0.0003 -> TPR: 0.29 & F1: 0.44 | AUC: 0.9462
01/28/2023 11:00:06 PM [!] Sat Jan 28 23:00:06 2023: Dumped results:
                model     : 1674943205-model.torch
		train time: 1674943205-trainTime.npy
		train losses: 1674943205-trainLosses.npy
		train AUC: 1674943205-auc.npy
		train F1s : 1674943205-trainF1s.npy
		train TPRs: 1674943205-trainTPRs.npy
01/28/2023 11:00:06 PM  [!] Training full_data model on downstream task...
01/28/2023 11:00:06 PM  [*] Started epoch: 1
01/28/2023 11:00:06 PM  [*] Sat Jan 28 23:00:06 2023: Train Epoch: 1 [  0  /76126 (0 %)]	Loss: 2.994689 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.1463 & F1 0.2553 | AUC 0.5567
01/28/2023 11:00:12 PM  [*] Sat Jan 28 23:00:12 2023: Train Epoch: 1 [6400 /76126 (8 %)]	Loss: 0.436574 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.2923 & F1 0.4524 | AUC 0.8053
01/28/2023 11:00:18 PM  [*] Sat Jan 28 23:00:18 2023: Train Epoch: 1 [12800/76126 (17%)]	Loss: 0.449568 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.2727 & F1 0.4286 | AUC 0.8708
01/28/2023 11:00:25 PM  [*] Sat Jan 28 23:00:25 2023: Train Epoch: 1 [19200/76126 (25%)]	Loss: 0.346264 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.5072 & F1 0.6731 | AUC 0.9378
01/28/2023 11:00:31 PM  [*] Sat Jan 28 23:00:31 2023: Train Epoch: 1 [25600/76126 (34%)]	Loss: 0.398632 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.1714 & F1 0.2927 | AUC 0.8852
01/28/2023 11:00:37 PM  [*] Sat Jan 28 23:00:37 2023: Train Epoch: 1 [32000/76126 (42%)]	Loss: 0.319701 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.6087 & F1 0.7568 | AUC 0.9490
01/28/2023 11:00:43 PM  [*] Sat Jan 28 23:00:43 2023: Train Epoch: 1 [38400/76126 (50%)]	Loss: 0.202046 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.5000 & F1 0.6667 | AUC 0.9549
01/28/2023 11:00:50 PM  [*] Sat Jan 28 23:00:50 2023: Train Epoch: 1 [44800/76126 (59%)]	Loss: 0.293786 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.7027 & F1 0.8254 | AUC 0.9205
01/28/2023 11:00:56 PM  [*] Sat Jan 28 23:00:56 2023: Train Epoch: 1 [51200/76126 (67%)]	Loss: 0.249232 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.6923 & F1 0.8182 | AUC 0.9459
01/28/2023 11:01:02 PM  [*] Sat Jan 28 23:01:02 2023: Train Epoch: 1 [57600/76126 (76%)]	Loss: 0.211509 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.7500 & F1 0.8571 | AUC 0.9757
01/28/2023 11:01:08 PM [!] Learning rate: 2.5e-05
01/28/2023 11:01:08 PM  [*] Sat Jan 28 23:01:08 2023: Train Epoch: 1 [64000/76126 (84%)]	Loss: 0.164382 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.5373 & F1 0.6990 | AUC 0.9742
01/28/2023 11:01:14 PM  [*] Sat Jan 28 23:01:14 2023: Train Epoch: 1 [70400/76126 (92%)]	Loss: 0.179841 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.8143 & F1 0.8976 | AUC 0.9800
01/28/2023 11:01:21 PM  [*] Sat Jan 28 23:01:21 2023:    1    | Tr.loss: 0.306196 | Elapsed:   75.47  s | FPR 0.0003 -> TPR: 0.05 & F1: 0.10 | AUC: 0.9318
01/28/2023 11:01:21 PM  [*] Started epoch: 2
01/28/2023 11:01:22 PM  [*] Sat Jan 28 23:01:22 2023: Train Epoch: 2 [  0  /76126 (0 %)]	Loss: 0.137789 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.9556 & F1 0.9773 | AUC 0.9871
01/28/2023 11:01:28 PM  [*] Sat Jan 28 23:01:28 2023: Train Epoch: 2 [6400 /76126 (8 %)]	Loss: 0.123815 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.8750 & F1 0.9333 | AUC 0.9870
01/28/2023 11:01:34 PM  [*] Sat Jan 28 23:01:34 2023: Train Epoch: 2 [12800/76126 (17%)]	Loss: 0.135759 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.6780 & F1 0.8081 | AUC 0.9706
01/28/2023 11:01:40 PM  [*] Sat Jan 28 23:01:40 2023: Train Epoch: 2 [19200/76126 (25%)]	Loss: 0.148340 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.7463 & F1 0.8547 | AUC 0.9697
01/28/2023 11:01:46 PM  [*] Sat Jan 28 23:01:46 2023: Train Epoch: 2 [25600/76126 (34%)]	Loss: 0.114740 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.9104 & F1 0.9531 | AUC 0.9941
01/28/2023 11:01:53 PM  [*] Sat Jan 28 23:01:53 2023: Train Epoch: 2 [32000/76126 (42%)]	Loss: 0.122948 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.8358 & F1 0.9106 | AUC 0.9815
01/28/2023 11:01:59 PM  [*] Sat Jan 28 23:01:59 2023: Train Epoch: 2 [38400/76126 (50%)]	Loss: 0.187524 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.8472 & F1 0.9173 | AUC 0.9802
01/28/2023 11:02:05 PM  [*] Sat Jan 28 23:02:05 2023: Train Epoch: 2 [44800/76126 (59%)]	Loss: 0.242177 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.7273 & F1 0.8421 | AUC 0.9639
01/28/2023 11:02:11 PM  [*] Sat Jan 28 23:02:11 2023: Train Epoch: 2 [51200/76126 (67%)]	Loss: 0.170710 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.8382 & F1 0.9120 | AUC 0.9775
01/28/2023 11:02:12 PM [!] Learning rate: 2.5e-06
01/28/2023 11:02:17 PM  [*] Sat Jan 28 23:02:17 2023: Train Epoch: 2 [57600/76126 (76%)]	Loss: 0.181158 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.7846 & F1 0.8793 | AUC 0.9785
01/28/2023 11:02:24 PM  [*] Sat Jan 28 23:02:24 2023: Train Epoch: 2 [64000/76126 (84%)]	Loss: 0.253978 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.8485 & F1 0.9180 | AUC 0.9684
01/28/2023 11:02:30 PM  [*] Sat Jan 28 23:02:30 2023: Train Epoch: 2 [70400/76126 (92%)]	Loss: 0.170367 | Elapsed: 6.27s | FPR 0.0003 -> TPR 0.7808 & F1 0.8769 | AUC 0.9848
01/28/2023 11:02:37 PM  [*] Sat Jan 28 23:02:37 2023:    2    | Tr.loss: 0.174488 | Elapsed:   75.72  s | FPR 0.0003 -> TPR: 0.41 & F1: 0.58 | AUC: 0.9788
01/28/2023 11:02:37 PM  [*] Started epoch: 3
01/28/2023 11:02:37 PM  [*] Sat Jan 28 23:02:37 2023: Train Epoch: 3 [  0  /76126 (0 %)]	Loss: 0.256505 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.6316 & F1 0.7742 | AUC 0.9595
01/28/2023 11:02:43 PM  [*] Sat Jan 28 23:02:43 2023: Train Epoch: 3 [6400 /76126 (8 %)]	Loss: 0.316274 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.7015 & F1 0.8246 | AUC 0.9729
01/28/2023 11:02:50 PM  [*] Sat Jan 28 23:02:50 2023: Train Epoch: 3 [12800/76126 (17%)]	Loss: 0.123161 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.7692 & F1 0.8696 | AUC 0.9855
01/28/2023 11:02:56 PM  [*] Sat Jan 28 23:02:56 2023: Train Epoch: 3 [19200/76126 (25%)]	Loss: 0.148600 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.9206 & F1 0.9587 | AUC 0.9888
01/28/2023 11:03:02 PM  [*] Sat Jan 28 23:03:02 2023: Train Epoch: 3 [25600/76126 (34%)]	Loss: 0.125748 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.9254 & F1 0.9612 | AUC 0.9833
01/28/2023 11:03:08 PM  [*] Sat Jan 28 23:03:08 2023: Train Epoch: 3 [32000/76126 (42%)]	Loss: 0.184230 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.8000 & F1 0.8889 | AUC 0.9701
01/28/2023 11:03:14 PM  [*] Sat Jan 28 23:03:14 2023: Train Epoch: 3 [38400/76126 (50%)]	Loss: 0.114553 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.9211 & F1 0.9589 | AUC 0.9890
01/28/2023 11:03:16 PM [!] Learning rate: 2.5000000000000004e-07
01/28/2023 11:03:21 PM  [*] Sat Jan 28 23:03:21 2023: Train Epoch: 3 [44800/76126 (59%)]	Loss: 0.124720 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.8594 & F1 0.9244 | AUC 0.9900
01/28/2023 11:03:27 PM  [*] Sat Jan 28 23:03:27 2023: Train Epoch: 3 [51200/76126 (67%)]	Loss: 0.275490 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.8219 & F1 0.9023 | AUC 0.9559
01/28/2023 11:03:33 PM  [*] Sat Jan 28 23:03:33 2023: Train Epoch: 3 [57600/76126 (76%)]	Loss: 0.181144 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.8310 & F1 0.9077 | AUC 0.9772
01/28/2023 11:03:39 PM  [*] Sat Jan 28 23:03:39 2023: Train Epoch: 3 [64000/76126 (84%)]	Loss: 0.170756 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.7846 & F1 0.8793 | AUC 0.9767
01/28/2023 11:03:45 PM  [*] Sat Jan 28 23:03:45 2023: Train Epoch: 3 [70400/76126 (92%)]	Loss: 0.166030 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.8507 & F1 0.9194 | AUC 0.9869
01/28/2023 11:03:53 PM  [*] Sat Jan 28 23:03:53 2023:    3    | Tr.loss: 0.167766 | Elapsed:   75.45  s | FPR 0.0003 -> TPR: 0.45 & F1: 0.62 | AUC: 0.9804
01/28/2023 11:03:53 PM [!] Sat Jan 28 23:03:53 2023: Dumped results:
                model     : 1674943433-model.torch
		train time: 1674943433-trainTime.npy
		train losses: 1674943433-trainLosses.npy
		train AUC: 1674943433-auc.npy
		train F1s : 1674943433-trainF1s.npy
		train TPRs: 1674943433-trainTPRs.npy
01/28/2023 11:03:53 PM  [*] Evaluating pretrained model on test set...
01/28/2023 11:03:58 PM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0535 | F1: 0.1016
01/28/2023 11:03:58 PM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1671 | F1: 0.2863
01/28/2023 11:03:58 PM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.3259 | F1: 0.4912
01/28/2023 11:03:58 PM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3589 | F1: 0.5273
01/28/2023 11:03:58 PM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3737 | F1: 0.5408
01/28/2023 11:03:58 PM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.5096 | F1: 0.6639
01/28/2023 11:03:58 PM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.7149 | F1: 0.7943
01/28/2023 11:03:58 PM  [*] Evaluating non_pretrained model on test set...
01/28/2023 11:04:03 PM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.1320 | F1: 0.2332
01/28/2023 11:04:03 PM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1519 | F1: 0.2636
01/28/2023 11:04:03 PM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.2364 | F1: 0.3822
01/28/2023 11:04:03 PM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.2669 | F1: 0.4205
01/28/2023 11:04:03 PM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3072 | F1: 0.4671
01/28/2023 11:04:03 PM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4311 | F1: 0.5920
01/28/2023 11:04:03 PM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.7289 | F1: 0.8037
01/28/2023 11:04:03 PM  [*] Evaluating full_data model on test set...
01/28/2023 11:04:08 PM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0155 | F1: 0.0306
01/28/2023 11:04:08 PM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.2686 | F1: 0.4234
01/28/2023 11:04:08 PM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.3354 | F1: 0.5020
01/28/2023 11:04:08 PM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3648 | F1: 0.5336
01/28/2023 11:04:08 PM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.4285 | F1: 0.5964
01/28/2023 11:04:08 PM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.5569 | F1: 0.7039
01/28/2023 11:04:08 PM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.7968 | F1: 0.8468
01/28/2023 11:04:08 PM  [!] Running pre-training split 3/3
01/28/2023 11:04:11 PM  [!] Pre-training model...
01/28/2023 11:04:11 PM  [*] Masking sequences...
01/28/2023 11:04:30 PM  [*] Started epoch: 1
01/28/2023 11:04:31 PM  [*] Sat Jan 28 23:04:31 2023: Train Epoch: 1 [  0  /64707 (0 %)]	Loss: 389.239258 | Elapsed: 0.81s
01/28/2023 11:04:43 PM  [*] Sat Jan 28 23:04:43 2023: Train Epoch: 1 [6400 /64707 (10%)]	Loss: 244.266174 | Elapsed: 12.19s
01/28/2023 11:04:56 PM  [*] Sat Jan 28 23:04:56 2023: Train Epoch: 1 [12800/64707 (20%)]	Loss: 212.813278 | Elapsed: 12.24s
01/28/2023 11:05:08 PM  [*] Sat Jan 28 23:05:08 2023: Train Epoch: 1 [19200/64707 (30%)]	Loss: 204.698578 | Elapsed: 12.32s
01/28/2023 11:05:20 PM  [*] Sat Jan 28 23:05:20 2023: Train Epoch: 1 [25600/64707 (40%)]	Loss: 208.449249 | Elapsed: 12.22s
01/28/2023 11:05:32 PM  [*] Sat Jan 28 23:05:32 2023: Train Epoch: 1 [32000/64707 (49%)]	Loss: 192.897095 | Elapsed: 12.19s
01/28/2023 11:05:45 PM  [*] Sat Jan 28 23:05:45 2023: Train Epoch: 1 [38400/64707 (59%)]	Loss: 202.163025 | Elapsed: 12.32s
01/28/2023 11:05:57 PM  [*] Sat Jan 28 23:05:57 2023: Train Epoch: 1 [44800/64707 (69%)]	Loss: 173.970978 | Elapsed: 12.19s
01/28/2023 11:06:09 PM  [*] Sat Jan 28 23:06:09 2023: Train Epoch: 1 [51200/64707 (79%)]	Loss: 184.773499 | Elapsed: 12.23s
01/28/2023 11:06:21 PM  [*] Sat Jan 28 23:06:21 2023: Train Epoch: 1 [57600/64707 (89%)]	Loss: 201.242310 | Elapsed: 12.22s
01/28/2023 11:06:34 PM  [*] Sat Jan 28 23:06:34 2023: Train Epoch: 1 [64000/64707 (99%)]	Loss: 208.086578 | Elapsed: 12.27s
01/28/2023 11:06:37 PM  [*] Sat Jan 28 23:06:37 2023:    1    | Tr.loss: 207.056253 | Elapsed:  126.19  s
01/28/2023 11:06:37 PM  [*] Started epoch: 2
01/28/2023 11:06:37 PM  [*] Sat Jan 28 23:06:37 2023: Train Epoch: 2 [  0  /64707 (0 %)]	Loss: 177.734802 | Elapsed: 0.13s
01/28/2023 11:06:49 PM  [*] Sat Jan 28 23:06:49 2023: Train Epoch: 2 [6400 /64707 (10%)]	Loss: 200.513046 | Elapsed: 12.38s
01/28/2023 11:07:01 PM  [*] Sat Jan 28 23:07:01 2023: Train Epoch: 2 [12800/64707 (20%)]	Loss: 174.538345 | Elapsed: 12.27s
01/28/2023 11:07:14 PM  [*] Sat Jan 28 23:07:14 2023: Train Epoch: 2 [19200/64707 (30%)]	Loss: 172.001984 | Elapsed: 12.31s
01/28/2023 11:07:26 PM  [*] Sat Jan 28 23:07:26 2023: Train Epoch: 2 [25600/64707 (40%)]	Loss: 183.176025 | Elapsed: 12.27s
01/28/2023 11:07:38 PM  [*] Sat Jan 28 23:07:38 2023: Train Epoch: 2 [32000/64707 (49%)]	Loss: 195.164154 | Elapsed: 12.27s
01/28/2023 11:07:50 PM  [*] Sat Jan 28 23:07:50 2023: Train Epoch: 2 [38400/64707 (59%)]	Loss: 196.884949 | Elapsed: 12.24s
01/28/2023 11:08:03 PM  [*] Sat Jan 28 23:08:03 2023: Train Epoch: 2 [44800/64707 (69%)]	Loss: 203.223419 | Elapsed: 12.22s
01/28/2023 11:08:15 PM  [*] Sat Jan 28 23:08:15 2023: Train Epoch: 2 [51200/64707 (79%)]	Loss: 155.931808 | Elapsed: 12.26s
01/28/2023 11:08:27 PM  [*] Sat Jan 28 23:08:27 2023: Train Epoch: 2 [57600/64707 (89%)]	Loss: 202.474289 | Elapsed: 12.29s
01/28/2023 11:08:40 PM  [*] Sat Jan 28 23:08:40 2023: Train Epoch: 2 [64000/64707 (99%)]	Loss: 196.915314 | Elapsed: 12.31s
01/28/2023 11:08:43 PM  [*] Sat Jan 28 23:08:43 2023:    2    | Tr.loss: 187.248865 | Elapsed:  125.94  s
01/28/2023 11:08:43 PM  [*] Started epoch: 3
01/28/2023 11:08:43 PM  [*] Sat Jan 28 23:08:43 2023: Train Epoch: 3 [  0  /64707 (0 %)]	Loss: 193.687347 | Elapsed: 0.13s
01/28/2023 11:08:55 PM  [*] Sat Jan 28 23:08:55 2023: Train Epoch: 3 [6400 /64707 (10%)]	Loss: 180.275436 | Elapsed: 12.35s
01/28/2023 11:09:07 PM  [*] Sat Jan 28 23:09:07 2023: Train Epoch: 3 [12800/64707 (20%)]	Loss: 166.162140 | Elapsed: 12.27s
01/28/2023 11:09:20 PM  [*] Sat Jan 28 23:09:20 2023: Train Epoch: 3 [19200/64707 (30%)]	Loss: 202.710205 | Elapsed: 12.32s
01/28/2023 11:09:32 PM  [*] Sat Jan 28 23:09:32 2023: Train Epoch: 3 [25600/64707 (40%)]	Loss: 175.347900 | Elapsed: 12.30s
01/28/2023 11:09:44 PM  [*] Sat Jan 28 23:09:44 2023: Train Epoch: 3 [32000/64707 (49%)]	Loss: 215.631958 | Elapsed: 12.30s
01/28/2023 11:09:57 PM  [*] Sat Jan 28 23:09:57 2023: Train Epoch: 3 [38400/64707 (59%)]	Loss: 188.802277 | Elapsed: 12.31s
01/28/2023 11:10:09 PM  [*] Sat Jan 28 23:10:09 2023: Train Epoch: 3 [44800/64707 (69%)]	Loss: 179.310303 | Elapsed: 12.30s
01/28/2023 11:10:21 PM  [*] Sat Jan 28 23:10:21 2023: Train Epoch: 3 [51200/64707 (79%)]	Loss: 193.887924 | Elapsed: 12.19s
01/28/2023 11:10:33 PM  [*] Sat Jan 28 23:10:33 2023: Train Epoch: 3 [57600/64707 (89%)]	Loss: 186.012177 | Elapsed: 12.21s
01/28/2023 11:10:46 PM  [*] Sat Jan 28 23:10:46 2023: Train Epoch: 3 [64000/64707 (99%)]	Loss: 204.414948 | Elapsed: 12.35s
01/28/2023 11:10:49 PM  [*] Sat Jan 28 23:10:49 2023:    3    | Tr.loss: 182.753279 | Elapsed:  126.02  s
01/28/2023 11:10:49 PM  [*] Started epoch: 4
01/28/2023 11:10:49 PM  [*] Sat Jan 28 23:10:49 2023: Train Epoch: 4 [  0  /64707 (0 %)]	Loss: 185.148148 | Elapsed: 0.13s
01/28/2023 11:11:01 PM  [*] Sat Jan 28 23:11:01 2023: Train Epoch: 4 [6400 /64707 (10%)]	Loss: 167.481750 | Elapsed: 12.27s
01/28/2023 11:11:13 PM  [*] Sat Jan 28 23:11:13 2023: Train Epoch: 4 [12800/64707 (20%)]	Loss: 191.975479 | Elapsed: 12.25s
01/28/2023 11:11:25 PM  [*] Sat Jan 28 23:11:25 2023: Train Epoch: 4 [19200/64707 (30%)]	Loss: 166.779480 | Elapsed: 12.23s
01/28/2023 11:11:38 PM  [*] Sat Jan 28 23:11:38 2023: Train Epoch: 4 [25600/64707 (40%)]	Loss: 182.963638 | Elapsed: 12.33s
01/28/2023 11:11:50 PM  [*] Sat Jan 28 23:11:50 2023: Train Epoch: 4 [32000/64707 (49%)]	Loss: 195.551361 | Elapsed: 12.32s
01/28/2023 11:12:02 PM  [*] Sat Jan 28 23:12:02 2023: Train Epoch: 4 [38400/64707 (59%)]	Loss: 165.414810 | Elapsed: 12.24s
01/28/2023 11:12:15 PM  [*] Sat Jan 28 23:12:15 2023: Train Epoch: 4 [44800/64707 (69%)]	Loss: 222.487091 | Elapsed: 12.23s
01/28/2023 11:12:27 PM  [*] Sat Jan 28 23:12:27 2023: Train Epoch: 4 [51200/64707 (79%)]	Loss: 181.562500 | Elapsed: 12.25s
01/28/2023 11:12:39 PM  [*] Sat Jan 28 23:12:39 2023: Train Epoch: 4 [57600/64707 (89%)]	Loss: 163.573715 | Elapsed: 12.19s
01/28/2023 11:12:51 PM  [*] Sat Jan 28 23:12:51 2023: Train Epoch: 4 [64000/64707 (99%)]	Loss: 185.214783 | Elapsed: 12.30s
01/28/2023 11:12:54 PM  [*] Sat Jan 28 23:12:54 2023:    4    | Tr.loss: 180.186686 | Elapsed:  125.64  s
01/28/2023 11:12:54 PM  [*] Started epoch: 5
01/28/2023 11:12:54 PM  [*] Sat Jan 28 23:12:54 2023: Train Epoch: 5 [  0  /64707 (0 %)]	Loss: 176.851959 | Elapsed: 0.15s
01/28/2023 11:13:07 PM  [*] Sat Jan 28 23:13:07 2023: Train Epoch: 5 [6400 /64707 (10%)]	Loss: 170.525787 | Elapsed: 12.25s
01/28/2023 11:13:19 PM  [*] Sat Jan 28 23:13:19 2023: Train Epoch: 5 [12800/64707 (20%)]	Loss: 175.373199 | Elapsed: 12.24s
01/28/2023 11:13:31 PM  [*] Sat Jan 28 23:13:31 2023: Train Epoch: 5 [19200/64707 (30%)]	Loss: 187.544479 | Elapsed: 12.25s
01/28/2023 11:13:43 PM  [*] Sat Jan 28 23:13:43 2023: Train Epoch: 5 [25600/64707 (40%)]	Loss: 188.527023 | Elapsed: 12.22s
01/28/2023 11:13:56 PM  [*] Sat Jan 28 23:13:56 2023: Train Epoch: 5 [32000/64707 (49%)]	Loss: 174.549683 | Elapsed: 12.26s
01/28/2023 11:14:08 PM  [*] Sat Jan 28 23:14:08 2023: Train Epoch: 5 [38400/64707 (59%)]	Loss: 168.508942 | Elapsed: 12.24s
01/28/2023 11:14:20 PM  [*] Sat Jan 28 23:14:20 2023: Train Epoch: 5 [44800/64707 (69%)]	Loss: 185.581116 | Elapsed: 12.29s
01/28/2023 11:14:32 PM  [*] Sat Jan 28 23:14:32 2023: Train Epoch: 5 [51200/64707 (79%)]	Loss: 187.703644 | Elapsed: 12.30s
01/28/2023 11:14:45 PM  [*] Sat Jan 28 23:14:45 2023: Train Epoch: 5 [57600/64707 (89%)]	Loss: 174.641510 | Elapsed: 12.27s
01/28/2023 11:14:51 PM [!] Learning rate: 2.5e-05
01/28/2023 11:14:57 PM  [*] Sat Jan 28 23:14:57 2023: Train Epoch: 5 [64000/64707 (99%)]	Loss: 168.811661 | Elapsed: 12.24s
01/28/2023 11:15:00 PM  [*] Sat Jan 28 23:15:00 2023:    5    | Tr.loss: 178.492641 | Elapsed:  125.66  s
01/28/2023 11:15:00 PM  [*] Started epoch: 6
01/28/2023 11:15:00 PM  [*] Sat Jan 28 23:15:00 2023: Train Epoch: 6 [  0  /64707 (0 %)]	Loss: 196.359940 | Elapsed: 0.15s
01/28/2023 11:15:12 PM  [*] Sat Jan 28 23:15:12 2023: Train Epoch: 6 [6400 /64707 (10%)]	Loss: 185.327225 | Elapsed: 12.26s
01/28/2023 11:15:24 PM  [*] Sat Jan 28 23:15:24 2023: Train Epoch: 6 [12800/64707 (20%)]	Loss: 179.180603 | Elapsed: 12.23s
01/28/2023 11:15:37 PM  [*] Sat Jan 28 23:15:37 2023: Train Epoch: 6 [19200/64707 (30%)]	Loss: 194.905670 | Elapsed: 12.26s
01/28/2023 11:15:49 PM  [*] Sat Jan 28 23:15:49 2023: Train Epoch: 6 [25600/64707 (40%)]	Loss: 189.181183 | Elapsed: 12.23s
01/28/2023 11:16:01 PM  [*] Sat Jan 28 23:16:01 2023: Train Epoch: 6 [32000/64707 (49%)]	Loss: 166.850861 | Elapsed: 12.26s
01/28/2023 11:16:14 PM  [*] Sat Jan 28 23:16:14 2023: Train Epoch: 6 [38400/64707 (59%)]	Loss: 177.146500 | Elapsed: 12.27s
01/28/2023 11:16:26 PM  [*] Sat Jan 28 23:16:26 2023: Train Epoch: 6 [44800/64707 (69%)]	Loss: 178.935913 | Elapsed: 12.19s
01/28/2023 11:16:38 PM  [*] Sat Jan 28 23:16:38 2023: Train Epoch: 6 [51200/64707 (79%)]	Loss: 182.674835 | Elapsed: 12.25s
01/28/2023 11:16:50 PM  [*] Sat Jan 28 23:16:50 2023: Train Epoch: 6 [57600/64707 (89%)]	Loss: 165.427353 | Elapsed: 12.38s
01/28/2023 11:17:03 PM  [*] Sat Jan 28 23:17:03 2023: Train Epoch: 6 [64000/64707 (99%)]	Loss: 175.954941 | Elapsed: 12.23s
01/28/2023 11:17:06 PM  [*] Sat Jan 28 23:17:06 2023:    6    | Tr.loss: 177.003750 | Elapsed:  125.68  s
01/28/2023 11:17:06 PM  [*] Started epoch: 7
01/28/2023 11:17:06 PM  [*] Sat Jan 28 23:17:06 2023: Train Epoch: 7 [  0  /64707 (0 %)]	Loss: 183.061005 | Elapsed: 0.14s
01/28/2023 11:17:18 PM  [*] Sat Jan 28 23:17:18 2023: Train Epoch: 7 [6400 /64707 (10%)]	Loss: 163.671371 | Elapsed: 12.26s
01/28/2023 11:17:30 PM  [*] Sat Jan 28 23:17:30 2023: Train Epoch: 7 [12800/64707 (20%)]	Loss: 161.136688 | Elapsed: 12.23s
01/28/2023 11:17:42 PM  [*] Sat Jan 28 23:17:42 2023: Train Epoch: 7 [19200/64707 (30%)]	Loss: 175.301163 | Elapsed: 12.30s
01/28/2023 11:17:55 PM  [*] Sat Jan 28 23:17:55 2023: Train Epoch: 7 [25600/64707 (40%)]	Loss: 173.140884 | Elapsed: 12.27s
01/28/2023 11:18:07 PM  [*] Sat Jan 28 23:18:07 2023: Train Epoch: 7 [32000/64707 (49%)]	Loss: 161.188293 | Elapsed: 12.21s
01/28/2023 11:18:19 PM  [*] Sat Jan 28 23:18:19 2023: Train Epoch: 7 [38400/64707 (59%)]	Loss: 170.457855 | Elapsed: 12.29s
01/28/2023 11:18:32 PM  [*] Sat Jan 28 23:18:32 2023: Train Epoch: 7 [44800/64707 (69%)]	Loss: 156.788483 | Elapsed: 12.28s
01/28/2023 11:18:44 PM  [*] Sat Jan 28 23:18:44 2023: Train Epoch: 7 [51200/64707 (79%)]	Loss: 174.445831 | Elapsed: 12.29s
01/28/2023 11:18:56 PM  [*] Sat Jan 28 23:18:56 2023: Train Epoch: 7 [57600/64707 (89%)]	Loss: 192.919479 | Elapsed: 12.26s
01/28/2023 11:19:08 PM  [*] Sat Jan 28 23:19:08 2023: Train Epoch: 7 [64000/64707 (99%)]	Loss: 177.056412 | Elapsed: 12.21s
01/28/2023 11:19:11 PM  [*] Sat Jan 28 23:19:11 2023:    7    | Tr.loss: 176.757809 | Elapsed:  125.69  s
01/28/2023 11:19:11 PM  [*] Started epoch: 8
01/28/2023 11:19:11 PM  [*] Sat Jan 28 23:19:11 2023: Train Epoch: 8 [  0  /64707 (0 %)]	Loss: 188.315231 | Elapsed: 0.14s
01/28/2023 11:19:24 PM  [*] Sat Jan 28 23:19:24 2023: Train Epoch: 8 [6400 /64707 (10%)]	Loss: 183.827835 | Elapsed: 12.25s
01/28/2023 11:19:36 PM  [*] Sat Jan 28 23:19:36 2023: Train Epoch: 8 [12800/64707 (20%)]	Loss: 183.127243 | Elapsed: 12.29s
01/28/2023 11:19:48 PM  [*] Sat Jan 28 23:19:48 2023: Train Epoch: 8 [19200/64707 (30%)]	Loss: 156.956757 | Elapsed: 12.25s
01/28/2023 11:20:00 PM  [*] Sat Jan 28 23:20:00 2023: Train Epoch: 8 [25600/64707 (40%)]	Loss: 174.756897 | Elapsed: 12.26s
01/28/2023 11:20:13 PM  [*] Sat Jan 28 23:20:13 2023: Train Epoch: 8 [32000/64707 (49%)]	Loss: 148.235840 | Elapsed: 12.21s
01/28/2023 11:20:25 PM  [*] Sat Jan 28 23:20:25 2023: Train Epoch: 8 [38400/64707 (59%)]	Loss: 160.535858 | Elapsed: 12.17s
01/28/2023 11:20:37 PM  [*] Sat Jan 28 23:20:37 2023: Train Epoch: 8 [44800/64707 (69%)]	Loss: 195.494385 | Elapsed: 12.26s
01/28/2023 11:20:49 PM  [*] Sat Jan 28 23:20:49 2023: Train Epoch: 8 [51200/64707 (79%)]	Loss: 172.809753 | Elapsed: 12.26s
01/28/2023 11:21:02 PM  [*] Sat Jan 28 23:21:02 2023: Train Epoch: 8 [57600/64707 (89%)]	Loss: 199.165619 | Elapsed: 12.32s
01/28/2023 11:21:14 PM  [*] Sat Jan 28 23:21:14 2023: Train Epoch: 8 [64000/64707 (99%)]	Loss: 171.216766 | Elapsed: 12.31s
01/28/2023 11:21:17 PM  [*] Sat Jan 28 23:21:17 2023:    8    | Tr.loss: 176.610316 | Elapsed:  125.61  s
01/28/2023 11:21:17 PM  [*] Started epoch: 9
01/28/2023 11:21:17 PM  [*] Sat Jan 28 23:21:17 2023: Train Epoch: 9 [  0  /64707 (0 %)]	Loss: 173.662109 | Elapsed: 0.12s
01/28/2023 11:21:29 PM  [*] Sat Jan 28 23:21:29 2023: Train Epoch: 9 [6400 /64707 (10%)]	Loss: 176.744415 | Elapsed: 12.32s
01/28/2023 11:21:42 PM  [*] Sat Jan 28 23:21:42 2023: Train Epoch: 9 [12800/64707 (20%)]	Loss: 173.045593 | Elapsed: 12.25s
01/28/2023 11:21:54 PM  [*] Sat Jan 28 23:21:54 2023: Train Epoch: 9 [19200/64707 (30%)]	Loss: 156.015884 | Elapsed: 12.23s
01/28/2023 11:22:06 PM  [*] Sat Jan 28 23:22:06 2023: Train Epoch: 9 [25600/64707 (40%)]	Loss: 153.632660 | Elapsed: 12.39s
01/28/2023 11:22:18 PM  [*] Sat Jan 28 23:22:18 2023: Train Epoch: 9 [32000/64707 (49%)]	Loss: 171.321747 | Elapsed: 12.25s
01/28/2023 11:22:31 PM  [*] Sat Jan 28 23:22:31 2023: Train Epoch: 9 [38400/64707 (59%)]	Loss: 156.555603 | Elapsed: 12.20s
01/28/2023 11:22:43 PM  [*] Sat Jan 28 23:22:43 2023: Train Epoch: 9 [44800/64707 (69%)]	Loss: 166.437347 | Elapsed: 12.22s
01/28/2023 11:22:55 PM  [*] Sat Jan 28 23:22:55 2023: Train Epoch: 9 [51200/64707 (79%)]	Loss: 198.705475 | Elapsed: 12.32s
01/28/2023 11:23:07 PM  [*] Sat Jan 28 23:23:07 2023: Train Epoch: 9 [57600/64707 (89%)]	Loss: 186.218597 | Elapsed: 12.19s
01/28/2023 11:23:20 PM  [*] Sat Jan 28 23:23:20 2023: Train Epoch: 9 [64000/64707 (99%)]	Loss: 165.094177 | Elapsed: 12.42s
01/28/2023 11:23:23 PM  [*] Sat Jan 28 23:23:23 2023:    9    | Tr.loss: 176.479825 | Elapsed:  126.02  s
01/28/2023 11:23:23 PM  [*] Started epoch: 10
01/28/2023 11:23:23 PM  [*] Sat Jan 28 23:23:23 2023: Train Epoch: 10 [  0  /64707 (0 %)]	Loss: 182.508911 | Elapsed: 0.14s
01/28/2023 11:23:35 PM  [*] Sat Jan 28 23:23:35 2023: Train Epoch: 10 [6400 /64707 (10%)]	Loss: 188.818298 | Elapsed: 12.44s
01/28/2023 11:23:48 PM  [*] Sat Jan 28 23:23:48 2023: Train Epoch: 10 [12800/64707 (20%)]	Loss: 159.482727 | Elapsed: 12.81s
01/28/2023 11:24:01 PM  [*] Sat Jan 28 23:24:01 2023: Train Epoch: 10 [19200/64707 (30%)]	Loss: 176.853729 | Elapsed: 12.80s
01/28/2023 11:24:14 PM  [*] Sat Jan 28 23:24:14 2023: Train Epoch: 10 [25600/64707 (40%)]	Loss: 171.884766 | Elapsed: 12.77s
01/28/2023 11:24:26 PM  [*] Sat Jan 28 23:24:26 2023: Train Epoch: 10 [32000/64707 (49%)]	Loss: 208.102814 | Elapsed: 12.26s
01/28/2023 11:24:38 PM  [*] Sat Jan 28 23:24:38 2023: Train Epoch: 10 [38400/64707 (59%)]	Loss: 176.289917 | Elapsed: 12.27s
01/28/2023 11:24:51 PM  [*] Sat Jan 28 23:24:51 2023: Train Epoch: 10 [44800/64707 (69%)]	Loss: 158.006882 | Elapsed: 12.30s
01/28/2023 11:25:03 PM  [*] Sat Jan 28 23:25:03 2023: Train Epoch: 10 [51200/64707 (79%)]	Loss: 172.825195 | Elapsed: 12.31s
01/28/2023 11:25:14 PM [!] Learning rate: 2.5e-06
01/28/2023 11:25:15 PM  [*] Sat Jan 28 23:25:15 2023: Train Epoch: 10 [57600/64707 (89%)]	Loss: 155.812042 | Elapsed: 12.20s
01/28/2023 11:25:27 PM  [*] Sat Jan 28 23:25:27 2023: Train Epoch: 10 [64000/64707 (99%)]	Loss: 139.684128 | Elapsed: 12.35s
01/28/2023 11:25:30 PM  [*] Sat Jan 28 23:25:30 2023:   10    | Tr.loss: 176.066387 | Elapsed:  127.57  s
01/28/2023 11:25:31 PM [!] Sat Jan 28 23:25:31 2023: Dumped results:
                model     : 1674944730-model.torch
		train time: 1674944730-trainTime.npy
		train losses: 1674944730-trainLosses.npy
		train AUC: 1674944730-auc.npy
01/28/2023 11:25:33 PM  [!] Training pretrained model on downstream task...
01/28/2023 11:25:33 PM  [*] Started epoch: 1
01/28/2023 11:25:33 PM  [*] Sat Jan 28 23:25:33 2023: Train Epoch: 1 [  0  /11419 (0 %)]	Loss: 3.407917 | Elapsed: 0.40s | FPR 0.0003 -> TPR 0.0652 & F1 0.1224 | AUC 0.5906
01/28/2023 11:25:42 PM  [*] Sat Jan 28 23:25:42 2023: Train Epoch: 1 [6400 /11419 (56%)]	Loss: 0.547792 | Elapsed: 9.11s | FPR 0.0003 -> TPR 0.1231 & F1 0.2192 | AUC 0.7376
01/28/2023 11:25:50 PM  [*] Sat Jan 28 23:25:50 2023:    1    | Tr.loss: 0.621927 | Elapsed:   16.78  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7454
01/28/2023 11:25:50 PM  [*] Started epoch: 2
01/28/2023 11:25:50 PM  [*] Sat Jan 28 23:25:50 2023: Train Epoch: 2 [  0  /11419 (0 %)]	Loss: 0.508083 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.3500 & F1 0.5185 | AUC 0.7333
01/28/2023 11:25:59 PM  [*] Sat Jan 28 23:25:59 2023: Train Epoch: 2 [6400 /11419 (56%)]	Loss: 0.330886 | Elapsed: 9.05s | FPR 0.0003 -> TPR 0.4925 & F1 0.6600 | AUC 0.8673
01/28/2023 11:26:06 PM  [*] Sat Jan 28 23:26:06 2023:    2    | Tr.loss: 0.440929 | Elapsed:   16.50  s | FPR 0.0003 -> TPR: 0.11 & F1: 0.20 | AUC: 0.8134
01/28/2023 11:26:06 PM  [*] Started epoch: 3
01/28/2023 11:26:06 PM  [*] Sat Jan 28 23:26:06 2023: Train Epoch: 3 [  0  /11419 (0 %)]	Loss: 0.416445 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.4583 & F1 0.6286 | AUC 0.8743
01/28/2023 11:26:15 PM  [*] Sat Jan 28 23:26:15 2023: Train Epoch: 3 [6400 /11419 (56%)]	Loss: 0.391207 | Elapsed: 9.06s | FPR 0.0003 -> TPR 0.3971 & F1 0.5684 | AUC 0.8784
01/28/2023 11:26:22 PM  [*] Sat Jan 28 23:26:22 2023:    3    | Tr.loss: 0.389939 | Elapsed:   16.43  s | FPR 0.0003 -> TPR: 0.20 & F1: 0.34 | AUC: 0.8636
01/28/2023 11:26:23 PM [!] Sat Jan 28 23:26:23 2023: Dumped results:
                model     : 1674944782-model.torch
		train time: 1674944782-trainTime.npy
		train losses: 1674944782-trainLosses.npy
		train AUC: 1674944782-auc.npy
		train F1s : 1674944782-trainF1s.npy
		train TPRs: 1674944782-trainTPRs.npy
01/28/2023 11:26:23 PM  [!] Training non_pretrained model on downstream task...
01/28/2023 11:26:23 PM  [*] Started epoch: 1
01/28/2023 11:26:23 PM  [*] Sat Jan 28 23:26:23 2023: Train Epoch: 1 [  0  /11419 (0 %)]	Loss: 1.396236 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0833 & F1 0.1538 | AUC 0.6172
01/28/2023 11:26:30 PM  [*] Sat Jan 28 23:26:30 2023: Train Epoch: 1 [6400 /11419 (56%)]	Loss: 0.512621 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.3065 & F1 0.4691 | AUC 0.8086
01/28/2023 11:26:35 PM  [*] Sat Jan 28 23:26:35 2023:    1    | Tr.loss: 0.516115 | Elapsed:   11.30  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7947
01/28/2023 11:26:35 PM  [*] Started epoch: 2
01/28/2023 11:26:35 PM  [*] Sat Jan 28 23:26:35 2023: Train Epoch: 2 [  0  /11419 (0 %)]	Loss: 0.256019 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.4565 & F1 0.6269 | AUC 0.9553
01/28/2023 11:26:41 PM  [*] Sat Jan 28 23:26:41 2023: Train Epoch: 2 [6400 /11419 (56%)]	Loss: 0.309268 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.5625 & F1 0.7200 | AUC 0.9184
01/28/2023 11:26:46 PM  [*] Sat Jan 28 23:26:46 2023:    2    | Tr.loss: 0.330730 | Elapsed:   11.31  s | FPR 0.0003 -> TPR: 0.18 & F1: 0.31 | AUC: 0.9150
01/28/2023 11:26:46 PM  [*] Started epoch: 3
01/28/2023 11:26:46 PM  [*] Sat Jan 28 23:26:46 2023: Train Epoch: 3 [  0  /11419 (0 %)]	Loss: 0.248806 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.7826 & F1 0.8780 | AUC 0.9529
01/28/2023 11:26:52 PM  [*] Sat Jan 28 23:26:52 2023: Train Epoch: 3 [6400 /11419 (56%)]	Loss: 0.231164 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.4783 & F1 0.6471 | AUC 0.9654
01/28/2023 11:26:57 PM  [*] Sat Jan 28 23:26:57 2023:    3    | Tr.loss: 0.257372 | Elapsed:   11.26  s | FPR 0.0003 -> TPR: 0.35 & F1: 0.52 | AUC: 0.9520
01/28/2023 11:26:58 PM [!] Sat Jan 28 23:26:58 2023: Dumped results:
                model     : 1674944817-model.torch
		train time: 1674944817-trainTime.npy
		train losses: 1674944817-trainLosses.npy
		train AUC: 1674944817-auc.npy
		train F1s : 1674944817-trainF1s.npy
		train TPRs: 1674944817-trainTPRs.npy
01/28/2023 11:26:58 PM  [!] Training full_data model on downstream task...
01/28/2023 11:26:58 PM  [*] Started epoch: 1
01/28/2023 11:26:58 PM  [*] Sat Jan 28 23:26:58 2023: Train Epoch: 1 [  0  /76126 (0 %)]	Loss: 1.614541 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0870 & F1 0.1600 | AUC 0.5604
01/28/2023 11:27:04 PM  [*] Sat Jan 28 23:27:04 2023: Train Epoch: 1 [6400 /76126 (8 %)]	Loss: 0.457298 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.2429 & F1 0.3908 | AUC 0.7933
01/28/2023 11:27:10 PM  [*] Sat Jan 28 23:27:10 2023: Train Epoch: 1 [12800/76126 (17%)]	Loss: 0.456277 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.1571 & F1 0.2716 | AUC 0.8614
01/28/2023 11:27:17 PM  [*] Sat Jan 28 23:27:17 2023: Train Epoch: 1 [19200/76126 (25%)]	Loss: 0.414396 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.5000 & F1 0.6667 | AUC 0.8841
01/28/2023 11:27:23 PM  [*] Sat Jan 28 23:27:23 2023: Train Epoch: 1 [25600/76126 (34%)]	Loss: 0.370916 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.5593 & F1 0.7174 | AUC 0.9153
01/28/2023 11:27:29 PM  [*] Sat Jan 28 23:27:29 2023: Train Epoch: 1 [32000/76126 (42%)]	Loss: 0.239871 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.7662 & F1 0.8676 | AUC 0.9582
01/28/2023 11:27:35 PM  [*] Sat Jan 28 23:27:35 2023: Train Epoch: 1 [38400/76126 (50%)]	Loss: 0.209342 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.8267 & F1 0.9051 | AUC 0.9627
01/28/2023 11:27:42 PM  [*] Sat Jan 28 23:27:42 2023: Train Epoch: 1 [44800/76126 (59%)]	Loss: 0.227092 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.6308 & F1 0.7736 | AUC 0.9727
01/28/2023 11:27:48 PM  [*] Sat Jan 28 23:27:48 2023: Train Epoch: 1 [51200/76126 (67%)]	Loss: 0.161606 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.8750 & F1 0.9333 | AUC 0.9792
01/28/2023 11:27:54 PM  [*] Sat Jan 28 23:27:54 2023: Train Epoch: 1 [57600/76126 (76%)]	Loss: 0.157214 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.8529 & F1 0.9206 | AUC 0.9793
01/28/2023 11:28:00 PM [!] Learning rate: 2.5e-05
01/28/2023 11:28:00 PM  [*] Sat Jan 28 23:28:00 2023: Train Epoch: 1 [64000/76126 (84%)]	Loss: 0.245203 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.8000 & F1 0.8889 | AUC 0.9710
01/28/2023 11:28:06 PM  [*] Sat Jan 28 23:28:06 2023: Train Epoch: 1 [70400/76126 (92%)]	Loss: 0.201695 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.7302 & F1 0.8440 | AUC 0.9794
01/28/2023 11:28:14 PM  [*] Sat Jan 28 23:28:14 2023:    1    | Tr.loss: 0.288132 | Elapsed:   75.60  s | FPR 0.0003 -> TPR: 0.11 & F1: 0.20 | AUC: 0.9385
01/28/2023 11:28:14 PM  [*] Started epoch: 2
01/28/2023 11:28:14 PM  [*] Sat Jan 28 23:28:14 2023: Train Epoch: 2 [  0  /76126 (0 %)]	Loss: 0.158428 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.8864 & F1 0.9398 | AUC 0.9841
01/28/2023 11:28:20 PM  [*] Sat Jan 28 23:28:20 2023: Train Epoch: 2 [6400 /76126 (8 %)]	Loss: 0.154888 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.9420 & F1 0.9701 | AUC 0.9897
01/28/2023 11:28:26 PM  [*] Sat Jan 28 23:28:26 2023: Train Epoch: 2 [12800/76126 (17%)]	Loss: 0.121094 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.9118 & F1 0.9538 | AUC 0.9940
01/28/2023 11:28:32 PM  [*] Sat Jan 28 23:28:32 2023: Train Epoch: 2 [19200/76126 (25%)]	Loss: 0.150931 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.7761 & F1 0.8739 | AUC 0.9824
01/28/2023 11:28:38 PM  [*] Sat Jan 28 23:28:38 2023: Train Epoch: 2 [25600/76126 (34%)]	Loss: 0.167315 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.8636 & F1 0.9268 | AUC 0.9840
01/28/2023 11:28:45 PM  [*] Sat Jan 28 23:28:45 2023: Train Epoch: 2 [32000/76126 (42%)]	Loss: 0.056092 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.9692 & F1 0.9844 | AUC 0.9969
01/28/2023 11:28:51 PM  [*] Sat Jan 28 23:28:51 2023: Train Epoch: 2 [38400/76126 (50%)]	Loss: 0.185566 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.8451 & F1 0.9160 | AUC 0.9801
01/28/2023 11:28:57 PM  [*] Sat Jan 28 23:28:57 2023: Train Epoch: 2 [44800/76126 (59%)]	Loss: 0.180832 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.7910 & F1 0.8833 | AUC 0.9864
01/28/2023 11:29:03 PM  [*] Sat Jan 28 23:29:03 2023: Train Epoch: 2 [51200/76126 (67%)]	Loss: 0.134029 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.7973 & F1 0.8872 | AUC 0.9823
01/28/2023 11:29:04 PM [!] Learning rate: 2.5e-06
01/28/2023 11:29:09 PM  [*] Sat Jan 28 23:29:09 2023: Train Epoch: 2 [57600/76126 (76%)]	Loss: 0.195438 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.7027 & F1 0.8254 | AUC 0.9688
01/28/2023 11:29:16 PM  [*] Sat Jan 28 23:29:16 2023: Train Epoch: 2 [64000/76126 (84%)]	Loss: 0.077735 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.8923 & F1 0.9431 | AUC 0.9938
01/28/2023 11:29:22 PM  [*] Sat Jan 28 23:29:22 2023: Train Epoch: 2 [70400/76126 (92%)]	Loss: 0.174848 | Elapsed: 6.28s | FPR 0.0003 -> TPR 0.8421 & F1 0.9143 | AUC 0.9797
01/28/2023 11:29:29 PM  [*] Sat Jan 28 23:29:29 2023:    2    | Tr.loss: 0.159760 | Elapsed:   75.66  s | FPR 0.0003 -> TPR: 0.48 & F1: 0.65 | AUC: 0.9822
01/28/2023 11:29:29 PM  [*] Started epoch: 3
01/28/2023 11:29:29 PM  [*] Sat Jan 28 23:29:29 2023: Train Epoch: 3 [  0  /76126 (0 %)]	Loss: 0.158312 | Elapsed: 0.13s | FPR 0.0003 -> TPR 0.7917 & F1 0.8837 | AUC 0.9844
01/28/2023 11:29:36 PM  [*] Sat Jan 28 23:29:36 2023: Train Epoch: 3 [6400 /76126 (8 %)]	Loss: 0.126275 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.9014 & F1 0.9481 | AUC 0.9864
01/28/2023 11:29:42 PM  [*] Sat Jan 28 23:29:42 2023: Train Epoch: 3 [12800/76126 (17%)]	Loss: 0.185045 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.8310 & F1 0.9077 | AUC 0.9820
01/28/2023 11:29:48 PM  [*] Sat Jan 28 23:29:48 2023: Train Epoch: 3 [19200/76126 (25%)]	Loss: 0.114708 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.9403 & F1 0.9692 | AUC 0.9928
01/28/2023 11:29:54 PM  [*] Sat Jan 28 23:29:54 2023: Train Epoch: 3 [25600/76126 (34%)]	Loss: 0.147920 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.9091 & F1 0.9524 | AUC 0.9938
01/28/2023 11:30:01 PM  [*] Sat Jan 28 23:30:01 2023: Train Epoch: 3 [32000/76126 (42%)]	Loss: 0.174713 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.7681 & F1 0.8689 | AUC 0.9771
01/28/2023 11:30:07 PM  [*] Sat Jan 28 23:30:07 2023: Train Epoch: 3 [38400/76126 (50%)]	Loss: 0.147288 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.8000 & F1 0.8889 | AUC 0.9798
01/28/2023 11:30:08 PM [!] Learning rate: 2.5000000000000004e-07
01/28/2023 11:30:13 PM  [*] Sat Jan 28 23:30:13 2023: Train Epoch: 3 [44800/76126 (59%)]	Loss: 0.121819 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.8333 & F1 0.9091 | AUC 0.9836
01/28/2023 11:30:19 PM  [*] Sat Jan 28 23:30:19 2023: Train Epoch: 3 [51200/76126 (67%)]	Loss: 0.173070 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.7692 & F1 0.8696 | AUC 0.9749
01/28/2023 11:30:25 PM  [*] Sat Jan 28 23:30:25 2023: Train Epoch: 3 [57600/76126 (76%)]	Loss: 0.118174 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.8028 & F1 0.8906 | AUC 0.9864
01/28/2023 11:30:32 PM  [*] Sat Jan 28 23:30:32 2023: Train Epoch: 3 [64000/76126 (84%)]	Loss: 0.182845 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.7458 & F1 0.8544 | AUC 0.9864
01/28/2023 11:30:38 PM  [*] Sat Jan 28 23:30:38 2023: Train Epoch: 3 [70400/76126 (92%)]	Loss: 0.132771 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.8592 & F1 0.9242 | AUC 0.9830
01/28/2023 11:30:45 PM  [*] Sat Jan 28 23:30:45 2023:    3    | Tr.loss: 0.153333 | Elapsed:   75.68  s | FPR 0.0003 -> TPR: 0.52 & F1: 0.68 | AUC: 0.9837
01/28/2023 11:30:45 PM [!] Sat Jan 28 23:30:45 2023: Dumped results:
                model     : 1674945045-model.torch
		train time: 1674945045-trainTime.npy
		train losses: 1674945045-trainLosses.npy
		train AUC: 1674945045-auc.npy
		train F1s : 1674945045-trainF1s.npy
		train TPRs: 1674945045-trainTPRs.npy
01/28/2023 11:30:45 PM  [*] Evaluating pretrained model on test set...
01/28/2023 11:30:50 PM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.1045 | F1: 0.1893
01/28/2023 11:30:50 PM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1909 | F1: 0.3205
01/28/2023 11:30:50 PM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.2481 | F1: 0.3973
01/28/2023 11:30:50 PM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3216 | F1: 0.4857
01/28/2023 11:30:50 PM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3533 | F1: 0.5189
01/28/2023 11:30:50 PM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.3896 | F1: 0.5507
01/28/2023 11:30:50 PM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.6048 | F1: 0.7158
01/28/2023 11:30:50 PM  [*] Evaluating non_pretrained model on test set...
01/28/2023 11:30:55 PM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0560 | F1: 0.1061
01/28/2023 11:30:55 PM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.0905 | F1: 0.1660
01/28/2023 11:30:55 PM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.1954 | F1: 0.3266
01/28/2023 11:30:55 PM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3047 | F1: 0.4662
01/28/2023 11:30:55 PM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3654 | F1: 0.5319
01/28/2023 11:30:55 PM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4594 | F1: 0.6188
01/28/2023 11:30:55 PM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.6452 | F1: 0.7458
01/28/2023 11:30:55 PM  [*] Evaluating full_data model on test set...
01/28/2023 11:31:00 PM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.1037 | F1: 0.1879
01/28/2023 11:31:00 PM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.2542 | F1: 0.4053
01/28/2023 11:31:00 PM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.3557 | F1: 0.5245
01/28/2023 11:31:00 PM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3872 | F1: 0.5572
01/28/2023 11:31:00 PM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.4335 | F1: 0.6013
01/28/2023 11:31:00 PM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.5584 | F1: 0.7051
01/28/2023 11:31:00 PM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.8379 | F1: 0.8715
01/28/2023 11:31:00 PM  [!] Finished pre-training evaluation over 3 splits! Saved metrics to:
	C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.85_1674940195/metrics_MaskedLanguageModel_nSplits_3_limit_None.json
01/28/2023 11:31:01 PM  [!] Starting Masked Language Model evaluation over 3 splits!
01/28/2023 11:31:01 PM  [!] Loaded data and vocab. X train size: (76126, 512), X test size: (17407, 512), vocab size: 50002
01/28/2023 11:31:01 PM  [!] Initiating Self-Supervised Learning Pretraining
     Language Modeling MaskedLanguageModel
     Model TransformerEncoderLM with config:
	{'vocabSize': 50002, 'maxLen': 512, 'dModel': 64, 'nHeads': 8, 'dHidden': 256, 'nLayers': 2, 'numClasses': 1, 'hiddenNeurons': [64], 'dropout': 0.3}

01/28/2023 11:31:01 PM  [!] Running pre-training split 1/3
01/28/2023 11:31:04 PM  [!] Pre-training model...
01/28/2023 11:31:04 PM  [*] Masking sequences...
01/28/2023 11:31:24 PM  [*] Started epoch: 1
01/28/2023 11:31:25 PM  [*] Sat Jan 28 23:31:25 2023: Train Epoch: 1 [  0  /68513 (0 %)]	Loss: 434.996368 | Elapsed: 0.84s
01/28/2023 11:31:37 PM  [*] Sat Jan 28 23:31:37 2023: Train Epoch: 1 [6400 /68513 (9 %)]	Loss: 223.762207 | Elapsed: 12.18s
01/28/2023 11:31:49 PM  [*] Sat Jan 28 23:31:49 2023: Train Epoch: 1 [12800/68513 (19%)]	Loss: 203.997772 | Elapsed: 12.24s
01/28/2023 11:32:02 PM  [*] Sat Jan 28 23:32:02 2023: Train Epoch: 1 [19200/68513 (28%)]	Loss: 200.701874 | Elapsed: 12.20s
01/28/2023 11:32:14 PM  [*] Sat Jan 28 23:32:14 2023: Train Epoch: 1 [25600/68513 (37%)]	Loss: 193.131577 | Elapsed: 12.25s
01/28/2023 11:32:26 PM  [*] Sat Jan 28 23:32:26 2023: Train Epoch: 1 [32000/68513 (47%)]	Loss: 204.474030 | Elapsed: 12.19s
01/28/2023 11:32:38 PM  [*] Sat Jan 28 23:32:38 2023: Train Epoch: 1 [38400/68513 (56%)]	Loss: 218.147461 | Elapsed: 12.24s
01/28/2023 11:32:50 PM  [*] Sat Jan 28 23:32:50 2023: Train Epoch: 1 [44800/68513 (65%)]	Loss: 193.563721 | Elapsed: 12.21s
01/28/2023 11:33:03 PM  [*] Sat Jan 28 23:33:03 2023: Train Epoch: 1 [51200/68513 (75%)]	Loss: 183.640717 | Elapsed: 12.21s
01/28/2023 11:33:15 PM  [*] Sat Jan 28 23:33:15 2023: Train Epoch: 1 [57600/68513 (84%)]	Loss: 170.132294 | Elapsed: 12.18s
01/28/2023 11:33:27 PM  [*] Sat Jan 28 23:33:27 2023: Train Epoch: 1 [64000/68513 (93%)]	Loss: 218.767548 | Elapsed: 12.36s
01/28/2023 11:33:39 PM  [*] Sat Jan 28 23:33:39 2023:    1    | Tr.loss: 205.657684 | Elapsed:  135.00  s
01/28/2023 11:33:39 PM  [*] Started epoch: 2
01/28/2023 11:33:39 PM  [*] Sat Jan 28 23:33:39 2023: Train Epoch: 2 [  0  /68513 (0 %)]	Loss: 195.689880 | Elapsed: 0.13s
01/28/2023 11:33:52 PM  [*] Sat Jan 28 23:33:52 2023: Train Epoch: 2 [6400 /68513 (9 %)]	Loss: 163.003113 | Elapsed: 12.35s
01/28/2023 11:34:04 PM  [*] Sat Jan 28 23:34:04 2023: Train Epoch: 2 [12800/68513 (19%)]	Loss: 190.265823 | Elapsed: 12.19s
01/28/2023 11:34:16 PM  [*] Sat Jan 28 23:34:16 2023: Train Epoch: 2 [19200/68513 (28%)]	Loss: 177.255035 | Elapsed: 12.26s
01/28/2023 11:34:28 PM  [*] Sat Jan 28 23:34:28 2023: Train Epoch: 2 [25600/68513 (37%)]	Loss: 163.561981 | Elapsed: 12.20s
01/28/2023 11:34:40 PM  [*] Sat Jan 28 23:34:40 2023: Train Epoch: 2 [32000/68513 (47%)]	Loss: 198.199097 | Elapsed: 12.19s
01/28/2023 11:34:53 PM  [*] Sat Jan 28 23:34:53 2023: Train Epoch: 2 [38400/68513 (56%)]	Loss: 196.840851 | Elapsed: 12.23s
01/28/2023 11:35:05 PM  [*] Sat Jan 28 23:35:05 2023: Train Epoch: 2 [44800/68513 (65%)]	Loss: 181.803207 | Elapsed: 12.23s
01/28/2023 11:35:17 PM  [*] Sat Jan 28 23:35:17 2023: Train Epoch: 2 [51200/68513 (75%)]	Loss: 178.553604 | Elapsed: 12.24s
01/28/2023 11:35:29 PM  [*] Sat Jan 28 23:35:29 2023: Train Epoch: 2 [57600/68513 (84%)]	Loss: 175.386932 | Elapsed: 12.27s
01/28/2023 11:35:42 PM  [*] Sat Jan 28 23:35:42 2023: Train Epoch: 2 [64000/68513 (93%)]	Loss: 161.267136 | Elapsed: 12.22s
01/28/2023 11:35:52 PM  [*] Sat Jan 28 23:35:52 2023:    2    | Tr.loss: 186.148035 | Elapsed:  132.85  s
01/28/2023 11:35:52 PM  [*] Started epoch: 3
01/28/2023 11:35:52 PM  [*] Sat Jan 28 23:35:52 2023: Train Epoch: 3 [  0  /68513 (0 %)]	Loss: 174.959900 | Elapsed: 0.20s
01/28/2023 11:36:04 PM  [*] Sat Jan 28 23:36:04 2023: Train Epoch: 3 [6400 /68513 (9 %)]	Loss: 174.841522 | Elapsed: 12.31s
01/28/2023 11:36:17 PM  [*] Sat Jan 28 23:36:17 2023: Train Epoch: 3 [12800/68513 (19%)]	Loss: 194.802399 | Elapsed: 12.22s
01/28/2023 11:36:29 PM  [*] Sat Jan 28 23:36:29 2023: Train Epoch: 3 [19200/68513 (28%)]	Loss: 191.259155 | Elapsed: 12.27s
01/28/2023 11:36:41 PM  [*] Sat Jan 28 23:36:41 2023: Train Epoch: 3 [25600/68513 (37%)]	Loss: 195.399216 | Elapsed: 12.19s
01/28/2023 11:36:53 PM  [*] Sat Jan 28 23:36:53 2023: Train Epoch: 3 [32000/68513 (47%)]	Loss: 199.075119 | Elapsed: 12.30s
01/28/2023 11:37:06 PM  [*] Sat Jan 28 23:37:06 2023: Train Epoch: 3 [38400/68513 (56%)]	Loss: 186.734055 | Elapsed: 12.20s
01/28/2023 11:37:18 PM  [*] Sat Jan 28 23:37:18 2023: Train Epoch: 3 [44800/68513 (65%)]	Loss: 200.723541 | Elapsed: 12.23s
01/28/2023 11:37:30 PM  [*] Sat Jan 28 23:37:30 2023: Train Epoch: 3 [51200/68513 (75%)]	Loss: 182.520599 | Elapsed: 12.18s
01/28/2023 11:37:42 PM  [*] Sat Jan 28 23:37:42 2023: Train Epoch: 3 [57600/68513 (84%)]	Loss: 172.606384 | Elapsed: 12.24s
01/28/2023 11:37:55 PM  [*] Sat Jan 28 23:37:55 2023: Train Epoch: 3 [64000/68513 (93%)]	Loss: 192.623260 | Elapsed: 12.24s
01/28/2023 11:38:05 PM  [*] Sat Jan 28 23:38:05 2023:    3    | Tr.loss: 181.640258 | Elapsed:  132.84  s
01/28/2023 11:38:05 PM  [*] Started epoch: 4
01/28/2023 11:38:05 PM  [*] Sat Jan 28 23:38:05 2023: Train Epoch: 4 [  0  /68513 (0 %)]	Loss: 168.309082 | Elapsed: 0.15s
01/28/2023 11:38:17 PM  [*] Sat Jan 28 23:38:17 2023: Train Epoch: 4 [6400 /68513 (9 %)]	Loss: 195.292297 | Elapsed: 12.29s
01/28/2023 11:38:29 PM  [*] Sat Jan 28 23:38:29 2023: Train Epoch: 4 [12800/68513 (19%)]	Loss: 151.935516 | Elapsed: 12.20s
01/28/2023 11:38:42 PM  [*] Sat Jan 28 23:38:42 2023: Train Epoch: 4 [19200/68513 (28%)]	Loss: 175.170212 | Elapsed: 12.23s
01/28/2023 11:38:54 PM  [*] Sat Jan 28 23:38:54 2023: Train Epoch: 4 [25600/68513 (37%)]	Loss: 156.823013 | Elapsed: 12.32s
01/28/2023 11:39:06 PM  [*] Sat Jan 28 23:39:06 2023: Train Epoch: 4 [32000/68513 (47%)]	Loss: 163.718903 | Elapsed: 12.22s
01/28/2023 11:39:18 PM  [*] Sat Jan 28 23:39:18 2023: Train Epoch: 4 [38400/68513 (56%)]	Loss: 183.818726 | Elapsed: 12.18s
01/28/2023 11:39:31 PM  [*] Sat Jan 28 23:39:31 2023: Train Epoch: 4 [44800/68513 (65%)]	Loss: 165.850433 | Elapsed: 12.21s
01/28/2023 11:39:43 PM  [*] Sat Jan 28 23:39:43 2023: Train Epoch: 4 [51200/68513 (75%)]	Loss: 169.362427 | Elapsed: 12.18s
01/28/2023 11:39:55 PM  [*] Sat Jan 28 23:39:55 2023: Train Epoch: 4 [57600/68513 (84%)]	Loss: 174.019318 | Elapsed: 12.23s
01/28/2023 11:40:07 PM  [*] Sat Jan 28 23:40:07 2023: Train Epoch: 4 [64000/68513 (93%)]	Loss: 187.197021 | Elapsed: 12.22s
01/28/2023 11:40:17 PM  [*] Sat Jan 28 23:40:17 2023:    4    | Tr.loss: 179.245361 | Elapsed:  132.55  s
01/28/2023 11:40:17 PM  [*] Started epoch: 5
01/28/2023 11:40:17 PM  [*] Sat Jan 28 23:40:17 2023: Train Epoch: 5 [  0  /68513 (0 %)]	Loss: 180.308319 | Elapsed: 0.13s
01/28/2023 11:40:30 PM  [*] Sat Jan 28 23:40:30 2023: Train Epoch: 5 [6400 /68513 (9 %)]	Loss: 166.632111 | Elapsed: 12.28s
01/28/2023 11:40:42 PM  [*] Sat Jan 28 23:40:42 2023: Train Epoch: 5 [12800/68513 (19%)]	Loss: 200.843079 | Elapsed: 12.17s
01/28/2023 11:40:54 PM  [*] Sat Jan 28 23:40:54 2023: Train Epoch: 5 [19200/68513 (28%)]	Loss: 177.593872 | Elapsed: 12.22s
01/28/2023 11:41:06 PM  [*] Sat Jan 28 23:41:06 2023: Train Epoch: 5 [25600/68513 (37%)]	Loss: 172.763977 | Elapsed: 12.26s
01/28/2023 11:41:19 PM  [*] Sat Jan 28 23:41:19 2023: Train Epoch: 5 [32000/68513 (47%)]	Loss: 183.788879 | Elapsed: 12.23s
01/28/2023 11:41:31 PM  [*] Sat Jan 28 23:41:31 2023: Train Epoch: 5 [38400/68513 (56%)]	Loss: 188.173828 | Elapsed: 12.29s
01/28/2023 11:41:43 PM  [*] Sat Jan 28 23:41:43 2023: Train Epoch: 5 [44800/68513 (65%)]	Loss: 179.484772 | Elapsed: 12.23s
01/28/2023 11:41:45 PM [!] Learning rate: 2.5e-05
01/28/2023 11:41:55 PM  [*] Sat Jan 28 23:41:55 2023: Train Epoch: 5 [51200/68513 (75%)]	Loss: 166.531815 | Elapsed: 12.24s
01/28/2023 11:42:08 PM  [*] Sat Jan 28 23:42:08 2023: Train Epoch: 5 [57600/68513 (84%)]	Loss: 167.392822 | Elapsed: 12.19s
01/28/2023 11:42:20 PM  [*] Sat Jan 28 23:42:20 2023: Train Epoch: 5 [64000/68513 (93%)]	Loss: 181.303955 | Elapsed: 12.25s
01/28/2023 11:42:30 PM  [*] Sat Jan 28 23:42:30 2023:    5    | Tr.loss: 177.706404 | Elapsed:  132.73  s
01/28/2023 11:42:30 PM  [*] Started epoch: 6
01/28/2023 11:42:30 PM  [*] Sat Jan 28 23:42:30 2023: Train Epoch: 6 [  0  /68513 (0 %)]	Loss: 186.262619 | Elapsed: 0.14s
01/28/2023 11:42:42 PM  [*] Sat Jan 28 23:42:42 2023: Train Epoch: 6 [6400 /68513 (9 %)]	Loss: 183.261749 | Elapsed: 12.30s
01/28/2023 11:42:55 PM  [*] Sat Jan 28 23:42:55 2023: Train Epoch: 6 [12800/68513 (19%)]	Loss: 172.933838 | Elapsed: 12.30s
01/28/2023 11:43:07 PM  [*] Sat Jan 28 23:43:07 2023: Train Epoch: 6 [19200/68513 (28%)]	Loss: 177.340714 | Elapsed: 12.21s
01/28/2023 11:43:19 PM  [*] Sat Jan 28 23:43:19 2023: Train Epoch: 6 [25600/68513 (37%)]	Loss: 193.140060 | Elapsed: 12.19s
01/28/2023 11:43:31 PM  [*] Sat Jan 28 23:43:31 2023: Train Epoch: 6 [32000/68513 (47%)]	Loss: 189.598602 | Elapsed: 12.18s
01/28/2023 11:43:44 PM  [*] Sat Jan 28 23:43:44 2023: Train Epoch: 6 [38400/68513 (56%)]	Loss: 178.777023 | Elapsed: 12.26s
01/28/2023 11:43:56 PM  [*] Sat Jan 28 23:43:56 2023: Train Epoch: 6 [44800/68513 (65%)]	Loss: 165.974670 | Elapsed: 12.25s
01/28/2023 11:44:08 PM  [*] Sat Jan 28 23:44:08 2023: Train Epoch: 6 [51200/68513 (75%)]	Loss: 183.319626 | Elapsed: 12.20s
01/28/2023 11:44:20 PM  [*] Sat Jan 28 23:44:20 2023: Train Epoch: 6 [57600/68513 (84%)]	Loss: 168.612701 | Elapsed: 12.21s
01/28/2023 11:44:33 PM  [*] Sat Jan 28 23:44:33 2023: Train Epoch: 6 [64000/68513 (93%)]	Loss: 157.459122 | Elapsed: 12.21s
01/28/2023 11:44:43 PM  [*] Sat Jan 28 23:44:43 2023:    6    | Tr.loss: 176.538688 | Elapsed:  132.79  s
01/28/2023 11:44:43 PM  [*] Started epoch: 7
01/28/2023 11:44:43 PM  [*] Sat Jan 28 23:44:43 2023: Train Epoch: 7 [  0  /68513 (0 %)]	Loss: 186.712784 | Elapsed: 0.20s
01/28/2023 11:44:55 PM  [*] Sat Jan 28 23:44:55 2023: Train Epoch: 7 [6400 /68513 (9 %)]	Loss: 179.321732 | Elapsed: 12.26s
01/28/2023 11:45:08 PM  [*] Sat Jan 28 23:45:08 2023: Train Epoch: 7 [12800/68513 (19%)]	Loss: 205.565521 | Elapsed: 12.22s
01/28/2023 11:45:20 PM  [*] Sat Jan 28 23:45:20 2023: Train Epoch: 7 [19200/68513 (28%)]	Loss: 182.746002 | Elapsed: 12.20s
01/28/2023 11:45:32 PM  [*] Sat Jan 28 23:45:32 2023: Train Epoch: 7 [25600/68513 (37%)]	Loss: 172.555542 | Elapsed: 12.23s
01/28/2023 11:45:44 PM  [*] Sat Jan 28 23:45:44 2023: Train Epoch: 7 [32000/68513 (47%)]	Loss: 168.983368 | Elapsed: 12.21s
01/28/2023 11:45:56 PM  [*] Sat Jan 28 23:45:56 2023: Train Epoch: 7 [38400/68513 (56%)]	Loss: 174.294373 | Elapsed: 12.27s
01/28/2023 11:46:09 PM  [*] Sat Jan 28 23:46:09 2023: Train Epoch: 7 [44800/68513 (65%)]	Loss: 181.961990 | Elapsed: 12.29s
01/28/2023 11:46:21 PM  [*] Sat Jan 28 23:46:21 2023: Train Epoch: 7 [51200/68513 (75%)]	Loss: 163.061096 | Elapsed: 12.22s
01/28/2023 11:46:33 PM  [*] Sat Jan 28 23:46:33 2023: Train Epoch: 7 [57600/68513 (84%)]	Loss: 176.107422 | Elapsed: 12.21s
01/28/2023 11:46:45 PM  [*] Sat Jan 28 23:46:45 2023: Train Epoch: 7 [64000/68513 (93%)]	Loss: 181.458389 | Elapsed: 12.21s
01/28/2023 11:46:56 PM  [*] Sat Jan 28 23:46:56 2023:    7    | Tr.loss: 176.182949 | Elapsed:  132.73  s
01/28/2023 11:46:56 PM  [*] Started epoch: 8
01/28/2023 11:46:56 PM  [*] Sat Jan 28 23:46:56 2023: Train Epoch: 8 [  0  /68513 (0 %)]	Loss: 153.622452 | Elapsed: 0.13s
01/28/2023 11:47:08 PM  [*] Sat Jan 28 23:47:08 2023: Train Epoch: 8 [6400 /68513 (9 %)]	Loss: 188.725159 | Elapsed: 12.34s
01/28/2023 11:47:20 PM  [*] Sat Jan 28 23:47:20 2023: Train Epoch: 8 [12800/68513 (19%)]	Loss: 184.463852 | Elapsed: 12.18s
01/28/2023 11:47:32 PM  [*] Sat Jan 28 23:47:32 2023: Train Epoch: 8 [19200/68513 (28%)]	Loss: 180.601486 | Elapsed: 12.18s
01/28/2023 11:47:45 PM  [*] Sat Jan 28 23:47:45 2023: Train Epoch: 8 [25600/68513 (37%)]	Loss: 170.907898 | Elapsed: 12.21s
01/28/2023 11:47:57 PM  [*] Sat Jan 28 23:47:57 2023: Train Epoch: 8 [32000/68513 (47%)]	Loss: 183.496536 | Elapsed: 12.19s
01/28/2023 11:48:09 PM  [*] Sat Jan 28 23:48:09 2023: Train Epoch: 8 [38400/68513 (56%)]	Loss: 180.909286 | Elapsed: 12.24s
01/28/2023 11:48:21 PM  [*] Sat Jan 28 23:48:21 2023: Train Epoch: 8 [44800/68513 (65%)]	Loss: 154.527390 | Elapsed: 12.20s
01/28/2023 11:48:33 PM  [*] Sat Jan 28 23:48:33 2023: Train Epoch: 8 [51200/68513 (75%)]	Loss: 172.533691 | Elapsed: 12.21s
01/28/2023 11:48:46 PM  [*] Sat Jan 28 23:48:46 2023: Train Epoch: 8 [57600/68513 (84%)]	Loss: 166.187057 | Elapsed: 12.30s
01/28/2023 11:48:58 PM  [*] Sat Jan 28 23:48:58 2023: Train Epoch: 8 [64000/68513 (93%)]	Loss: 188.772949 | Elapsed: 12.26s
01/28/2023 11:49:08 PM  [*] Sat Jan 28 23:49:08 2023:    8    | Tr.loss: 176.096773 | Elapsed:  132.61  s
01/28/2023 11:49:08 PM  [*] Started epoch: 9
01/28/2023 11:49:08 PM  [*] Sat Jan 28 23:49:08 2023: Train Epoch: 9 [  0  /68513 (0 %)]	Loss: 175.377945 | Elapsed: 0.14s
01/28/2023 11:49:21 PM  [*] Sat Jan 28 23:49:21 2023: Train Epoch: 9 [6400 /68513 (9 %)]	Loss: 159.878326 | Elapsed: 12.28s
01/28/2023 11:49:33 PM  [*] Sat Jan 28 23:49:33 2023: Train Epoch: 9 [12800/68513 (19%)]	Loss: 178.398712 | Elapsed: 12.18s
01/28/2023 11:49:45 PM  [*] Sat Jan 28 23:49:45 2023: Train Epoch: 9 [19200/68513 (28%)]	Loss: 161.802261 | Elapsed: 12.21s
01/28/2023 11:49:57 PM  [*] Sat Jan 28 23:49:57 2023: Train Epoch: 9 [25600/68513 (37%)]	Loss: 190.066254 | Elapsed: 12.20s
01/28/2023 11:50:09 PM  [*] Sat Jan 28 23:50:09 2023: Train Epoch: 9 [32000/68513 (47%)]	Loss: 162.011932 | Elapsed: 12.21s
01/28/2023 11:50:22 PM  [*] Sat Jan 28 23:50:22 2023: Train Epoch: 9 [38400/68513 (56%)]	Loss: 182.631409 | Elapsed: 12.19s
01/28/2023 11:50:34 PM  [*] Sat Jan 28 23:50:34 2023: Train Epoch: 9 [44800/68513 (65%)]	Loss: 177.516129 | Elapsed: 12.21s
01/28/2023 11:50:46 PM  [*] Sat Jan 28 23:50:46 2023: Train Epoch: 9 [51200/68513 (75%)]	Loss: 178.625259 | Elapsed: 12.20s
01/28/2023 11:50:58 PM  [*] Sat Jan 28 23:50:58 2023: Train Epoch: 9 [57600/68513 (84%)]	Loss: 179.092972 | Elapsed: 12.17s
01/28/2023 11:51:10 PM  [*] Sat Jan 28 23:51:10 2023: Train Epoch: 9 [64000/68513 (93%)]	Loss: 178.586487 | Elapsed: 12.24s
01/28/2023 11:51:21 PM  [*] Sat Jan 28 23:51:21 2023:    9    | Tr.loss: 175.792850 | Elapsed:  132.41  s
01/28/2023 11:51:21 PM  [*] Started epoch: 10
01/28/2023 11:51:21 PM  [*] Sat Jan 28 23:51:21 2023: Train Epoch: 10 [  0  /68513 (0 %)]	Loss: 179.971298 | Elapsed: 0.14s
01/28/2023 11:51:33 PM  [*] Sat Jan 28 23:51:33 2023: Train Epoch: 10 [6400 /68513 (9 %)]	Loss: 189.881165 | Elapsed: 12.41s
01/28/2023 11:51:45 PM  [*] Sat Jan 28 23:51:45 2023: Train Epoch: 10 [12800/68513 (19%)]	Loss: 175.001404 | Elapsed: 12.30s
01/28/2023 11:51:58 PM  [*] Sat Jan 28 23:51:58 2023: Train Epoch: 10 [19200/68513 (28%)]	Loss: 138.720200 | Elapsed: 12.22s
01/28/2023 11:52:05 PM [!] Learning rate: 2.5e-06
01/28/2023 11:52:10 PM  [*] Sat Jan 28 23:52:10 2023: Train Epoch: 10 [25600/68513 (37%)]	Loss: 179.365646 | Elapsed: 12.25s
01/28/2023 11:52:22 PM  [*] Sat Jan 28 23:52:22 2023: Train Epoch: 10 [32000/68513 (47%)]	Loss: 176.669205 | Elapsed: 12.18s
01/28/2023 11:52:34 PM  [*] Sat Jan 28 23:52:34 2023: Train Epoch: 10 [38400/68513 (56%)]	Loss: 177.656006 | Elapsed: 12.19s
01/28/2023 11:52:47 PM  [*] Sat Jan 28 23:52:47 2023: Train Epoch: 10 [44800/68513 (65%)]	Loss: 182.916718 | Elapsed: 12.22s
01/28/2023 11:52:59 PM  [*] Sat Jan 28 23:52:59 2023: Train Epoch: 10 [51200/68513 (75%)]	Loss: 195.505051 | Elapsed: 12.18s
01/28/2023 11:53:11 PM  [*] Sat Jan 28 23:53:11 2023: Train Epoch: 10 [57600/68513 (84%)]	Loss: 178.352112 | Elapsed: 12.25s
01/28/2023 11:53:23 PM  [*] Sat Jan 28 23:53:23 2023: Train Epoch: 10 [64000/68513 (93%)]	Loss: 183.604950 | Elapsed: 12.30s
01/28/2023 11:53:34 PM  [*] Sat Jan 28 23:53:34 2023:   10    | Tr.loss: 175.700533 | Elapsed:  132.93  s
01/28/2023 11:53:34 PM [!] Sat Jan 28 23:53:34 2023: Dumped results:
                model     : 1674946414-model.torch
		train time: 1674946414-trainTime.npy
		train losses: 1674946414-trainLosses.npy
		train AUC: 1674946414-auc.npy
01/28/2023 11:53:36 PM  [!] Training pretrained model on downstream task...
01/28/2023 11:53:36 PM  [*] Started epoch: 1
01/28/2023 11:53:36 PM  [*] Sat Jan 28 23:53:36 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 4.187222 | Elapsed: 0.34s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.3919
01/28/2023 11:53:46 PM  [*] Sat Jan 28 23:53:46 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.437163 | Elapsed: 9.08s | FPR 0.0003 -> TPR 0.3729 & F1 0.5432 | AUC 0.8276
01/28/2023 11:53:47 PM  [*] Sat Jan 28 23:53:47 2023:    1    | Tr.loss: 0.564639 | Elapsed:   11.29  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7838
01/28/2023 11:53:47 PM  [*] Started epoch: 2
01/28/2023 11:53:48 PM  [*] Sat Jan 28 23:53:48 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.326159 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.5778 & F1 0.7324 | AUC 0.8936
01/28/2023 11:53:57 PM  [*] Sat Jan 28 23:53:57 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.364499 | Elapsed: 9.07s | FPR 0.0003 -> TPR 0.5753 & F1 0.7304 | AUC 0.8899
01/28/2023 11:53:58 PM  [*] Sat Jan 28 23:53:58 2023:    2    | Tr.loss: 0.370045 | Elapsed:   11.02  s | FPR 0.0003 -> TPR: 0.19 & F1: 0.32 | AUC: 0.8881
01/28/2023 11:53:58 PM  [*] Started epoch: 3
01/28/2023 11:53:59 PM  [*] Sat Jan 28 23:53:59 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.335447 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.6486 & F1 0.7869 | AUC 0.9289
01/28/2023 11:54:08 PM  [*] Sat Jan 28 23:54:08 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.324400 | Elapsed: 9.18s | FPR 0.0003 -> TPR 0.4000 & F1 0.5714 | AUC 0.9450
01/28/2023 11:54:10 PM  [*] Sat Jan 28 23:54:10 2023:    3    | Tr.loss: 0.319643 | Elapsed:   11.11  s | FPR 0.0003 -> TPR: 0.22 & F1: 0.36 | AUC: 0.9237
01/28/2023 11:54:10 PM [!] Sat Jan 28 23:54:10 2023: Dumped results:
                model     : 1674946450-model.torch
		train time: 1674946450-trainTime.npy
		train losses: 1674946450-trainLosses.npy
		train AUC: 1674946450-auc.npy
		train F1s : 1674946450-trainF1s.npy
		train TPRs: 1674946450-trainTPRs.npy
01/28/2023 11:54:10 PM  [!] Training non_pretrained model on downstream task...
01/28/2023 11:54:10 PM  [*] Started epoch: 1
01/28/2023 11:54:11 PM  [*] Sat Jan 28 23:54:11 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 1.328727 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.5616
01/28/2023 11:54:17 PM  [*] Sat Jan 28 23:54:17 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.456991 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.3200 & F1 0.4848 | AUC 0.8293
01/28/2023 11:54:18 PM  [*] Sat Jan 28 23:54:18 2023:    1    | Tr.loss: 0.566867 | Elapsed:   7.64   s | FPR 0.0003 -> TPR: 0.01 & F1: 0.01 | AUC: 0.7571
01/28/2023 11:54:18 PM  [*] Started epoch: 2
01/28/2023 11:54:18 PM  [*] Sat Jan 28 23:54:18 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.362621 | Elapsed: 0.05s | FPR 0.0003 -> TPR 0.3617 & F1 0.5312 | AUC 0.8736
01/28/2023 11:54:24 PM  [*] Sat Jan 28 23:54:24 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.346329 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.4179 & F1 0.5895 | AUC 0.9331
01/28/2023 11:54:26 PM  [*] Sat Jan 28 23:54:26 2023:    2    | Tr.loss: 0.368298 | Elapsed:   7.52   s | FPR 0.0003 -> TPR: 0.02 & F1: 0.04 | AUC: 0.8918
01/28/2023 11:54:26 PM  [*] Started epoch: 3
01/28/2023 11:54:26 PM  [*] Sat Jan 28 23:54:26 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.210238 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.7021 & F1 0.8250 | AUC 0.9625
01/28/2023 11:54:32 PM  [*] Sat Jan 28 23:54:32 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.388752 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.3385 & F1 0.5057 | AUC 0.8664
01/28/2023 11:54:33 PM  [*] Sat Jan 28 23:54:33 2023:    3    | Tr.loss: 0.309000 | Elapsed:   7.56   s | FPR 0.0003 -> TPR: 0.15 & F1: 0.26 | AUC: 0.9266
01/28/2023 11:54:34 PM [!] Sat Jan 28 23:54:34 2023: Dumped results:
                model     : 1674946473-model.torch
		train time: 1674946473-trainTime.npy
		train losses: 1674946473-trainLosses.npy
		train AUC: 1674946473-auc.npy
		train F1s : 1674946473-trainF1s.npy
		train TPRs: 1674946473-trainTPRs.npy
01/28/2023 11:54:34 PM  [!] Training full_data model on downstream task...
01/28/2023 11:54:34 PM  [*] Started epoch: 1
01/28/2023 11:54:34 PM  [*] Sat Jan 28 23:54:34 2023: Train Epoch: 1 [  0  /76126 (0 %)]	Loss: 3.001303 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.4865
01/28/2023 11:54:40 PM  [*] Sat Jan 28 23:54:40 2023: Train Epoch: 1 [6400 /76126 (8 %)]	Loss: 0.550072 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.2241 & F1 0.3662 | AUC 0.8670
01/28/2023 11:54:47 PM  [*] Sat Jan 28 23:54:47 2023: Train Epoch: 1 [12800/76126 (17%)]	Loss: 0.417323 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.3889 & F1 0.5600 | AUC 0.8626
01/28/2023 11:54:53 PM  [*] Sat Jan 28 23:54:53 2023: Train Epoch: 1 [19200/76126 (25%)]	Loss: 0.310976 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.4242 & F1 0.5957 | AUC 0.9220
01/28/2023 11:54:59 PM  [*] Sat Jan 28 23:54:59 2023: Train Epoch: 1 [25600/76126 (34%)]	Loss: 0.378531 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.6774 & F1 0.8077 | AUC 0.9278
01/28/2023 11:55:05 PM  [*] Sat Jan 28 23:55:05 2023: Train Epoch: 1 [32000/76126 (42%)]	Loss: 0.218794 | Elapsed: 6.27s | FPR 0.0003 -> TPR 0.4571 & F1 0.6275 | AUC 0.9371
01/28/2023 11:55:11 PM  [*] Sat Jan 28 23:55:11 2023: Train Epoch: 1 [38400/76126 (50%)]	Loss: 0.236832 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.5385 & F1 0.7000 | AUC 0.9604
01/28/2023 11:55:18 PM  [*] Sat Jan 28 23:55:18 2023: Train Epoch: 1 [44800/76126 (59%)]	Loss: 0.243930 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.6806 & F1 0.8099 | AUC 0.9583
01/28/2023 11:55:24 PM  [*] Sat Jan 28 23:55:24 2023: Train Epoch: 1 [51200/76126 (67%)]	Loss: 0.327051 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.5500 & F1 0.7097 | AUC 0.9396
01/28/2023 11:55:30 PM  [*] Sat Jan 28 23:55:30 2023: Train Epoch: 1 [57600/76126 (76%)]	Loss: 0.126488 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.7647 & F1 0.8667 | AUC 0.9890
01/28/2023 11:55:36 PM [!] Learning rate: 2.5e-05
01/28/2023 11:55:36 PM  [*] Sat Jan 28 23:55:36 2023: Train Epoch: 1 [64000/76126 (84%)]	Loss: 0.107890 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.9531 & F1 0.9760 | AUC 0.9978
01/28/2023 11:55:42 PM  [*] Sat Jan 28 23:55:42 2023: Train Epoch: 1 [70400/76126 (92%)]	Loss: 0.109490 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.9130 & F1 0.9545 | AUC 0.9850
01/28/2023 11:55:50 PM  [*] Sat Jan 28 23:55:50 2023:    1    | Tr.loss: 0.297385 | Elapsed:   75.69  s | FPR 0.0003 -> TPR: 0.04 & F1: 0.08 | AUC: 0.9354
01/28/2023 11:55:50 PM  [*] Started epoch: 2
01/28/2023 11:55:50 PM  [*] Sat Jan 28 23:55:50 2023: Train Epoch: 2 [  0  /76126 (0 %)]	Loss: 0.193237 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.5349 & F1 0.6970 | AUC 0.9745
01/28/2023 11:55:56 PM  [*] Sat Jan 28 23:55:56 2023: Train Epoch: 2 [6400 /76126 (8 %)]	Loss: 0.338650 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.2632 & F1 0.4167 | AUC 0.9576
01/28/2023 11:56:02 PM  [*] Sat Jan 28 23:56:02 2023: Train Epoch: 2 [12800/76126 (17%)]	Loss: 0.179032 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.8906 & F1 0.9421 | AUC 0.9865
01/28/2023 11:56:09 PM  [*] Sat Jan 28 23:56:09 2023: Train Epoch: 2 [19200/76126 (25%)]	Loss: 0.163053 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.9091 & F1 0.9524 | AUC 0.9889
01/28/2023 11:56:15 PM  [*] Sat Jan 28 23:56:15 2023: Train Epoch: 2 [25600/76126 (34%)]	Loss: 0.073320 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.9394 & F1 0.9688 | AUC 0.9938
01/28/2023 11:56:21 PM  [*] Sat Jan 28 23:56:21 2023: Train Epoch: 2 [32000/76126 (42%)]	Loss: 0.203087 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.7846 & F1 0.8793 | AUC 0.9811
01/28/2023 11:56:27 PM  [*] Sat Jan 28 23:56:27 2023: Train Epoch: 2 [38400/76126 (50%)]	Loss: 0.142576 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.8889 & F1 0.9412 | AUC 0.9901
01/28/2023 11:56:33 PM  [*] Sat Jan 28 23:56:33 2023: Train Epoch: 2 [44800/76126 (59%)]	Loss: 0.081407 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.9692 & F1 0.9844 | AUC 0.9978
01/28/2023 11:56:40 PM  [*] Sat Jan 28 23:56:40 2023: Train Epoch: 2 [51200/76126 (67%)]	Loss: 0.131500 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.9714 & F1 0.9855 | AUC 0.9952
01/28/2023 11:56:40 PM [!] Learning rate: 2.5e-06
01/28/2023 11:56:46 PM  [*] Sat Jan 28 23:56:46 2023: Train Epoch: 2 [57600/76126 (76%)]	Loss: 0.154268 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.8308 & F1 0.9076 | AUC 0.9767
01/28/2023 11:56:52 PM  [*] Sat Jan 28 23:56:52 2023: Train Epoch: 2 [64000/76126 (84%)]	Loss: 0.115350 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.8429 & F1 0.9147 | AUC 0.9919
01/28/2023 11:56:58 PM  [*] Sat Jan 28 23:56:58 2023: Train Epoch: 2 [70400/76126 (92%)]	Loss: 0.200882 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.9028 & F1 0.9489 | AUC 0.9737
01/28/2023 11:57:06 PM  [*] Sat Jan 28 23:57:06 2023:    2    | Tr.loss: 0.166641 | Elapsed:   75.75  s | FPR 0.0003 -> TPR: 0.46 & F1: 0.63 | AUC: 0.9807
01/28/2023 11:57:06 PM  [*] Started epoch: 3
01/28/2023 11:57:06 PM  [*] Sat Jan 28 23:57:06 2023: Train Epoch: 3 [  0  /76126 (0 %)]	Loss: 0.206707 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.8958 & F1 0.9451 | AUC 0.9766
01/28/2023 11:57:12 PM  [*] Sat Jan 28 23:57:12 2023: Train Epoch: 3 [6400 /76126 (8 %)]	Loss: 0.137826 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.8088 & F1 0.8943 | AUC 0.9871
01/28/2023 11:57:18 PM  [*] Sat Jan 28 23:57:18 2023: Train Epoch: 3 [12800/76126 (17%)]	Loss: 0.123182 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.9016 & F1 0.9483 | AUC 0.9945
01/28/2023 11:57:24 PM  [*] Sat Jan 28 23:57:24 2023: Train Epoch: 3 [19200/76126 (25%)]	Loss: 0.088212 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.9718 & F1 0.9857 | AUC 0.9956
01/28/2023 11:57:31 PM  [*] Sat Jan 28 23:57:31 2023: Train Epoch: 3 [25600/76126 (34%)]	Loss: 0.131057 | Elapsed: 6.33s | FPR 0.0003 -> TPR 0.7612 & F1 0.8644 | AUC 0.9851
01/28/2023 11:57:37 PM  [*] Sat Jan 28 23:57:37 2023: Train Epoch: 3 [32000/76126 (42%)]	Loss: 0.087073 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.6716 & F1 0.8036 | AUC 0.9869
01/28/2023 11:57:43 PM  [*] Sat Jan 28 23:57:43 2023: Train Epoch: 3 [38400/76126 (50%)]	Loss: 0.175497 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.7903 & F1 0.8829 | AUC 0.9784
01/28/2023 11:57:44 PM [!] Learning rate: 2.5000000000000004e-07
01/28/2023 11:57:49 PM  [*] Sat Jan 28 23:57:49 2023: Train Epoch: 3 [44800/76126 (59%)]	Loss: 0.130162 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.8966 & F1 0.9455 | AUC 0.9906
01/28/2023 11:57:56 PM  [*] Sat Jan 28 23:57:56 2023: Train Epoch: 3 [51200/76126 (67%)]	Loss: 0.277644 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.7162 & F1 0.8346 | AUC 0.9423
01/28/2023 11:58:02 PM  [*] Sat Jan 28 23:58:02 2023: Train Epoch: 3 [57600/76126 (76%)]	Loss: 0.246943 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.7714 & F1 0.8710 | AUC 0.9776
01/28/2023 11:58:08 PM  [*] Sat Jan 28 23:58:08 2023: Train Epoch: 3 [64000/76126 (84%)]	Loss: 0.138830 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.8800 & F1 0.9362 | AUC 0.9899
01/28/2023 11:58:14 PM  [*] Sat Jan 28 23:58:14 2023: Train Epoch: 3 [70400/76126 (92%)]	Loss: 0.130548 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.7581 & F1 0.8624 | AUC 0.9784
01/28/2023 11:58:21 PM  [*] Sat Jan 28 23:58:21 2023:    3    | Tr.loss: 0.157921 | Elapsed:   75.94  s | FPR 0.0003 -> TPR: 0.54 & F1: 0.70 | AUC: 0.9829
01/28/2023 11:58:22 PM [!] Sat Jan 28 23:58:22 2023: Dumped results:
                model     : 1674946701-model.torch
		train time: 1674946701-trainTime.npy
		train losses: 1674946701-trainLosses.npy
		train AUC: 1674946701-auc.npy
		train F1s : 1674946701-trainF1s.npy
		train TPRs: 1674946701-trainTPRs.npy
01/28/2023 11:58:22 PM  [*] Evaluating pretrained model on test set...
01/28/2023 11:58:27 PM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0423 | F1: 0.0812
01/28/2023 11:58:27 PM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1983 | F1: 0.3310
01/28/2023 11:58:27 PM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.2552 | F1: 0.4064
01/28/2023 11:58:27 PM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.2912 | F1: 0.4501
01/28/2023 11:58:27 PM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3547 | F1: 0.5204
01/28/2023 11:58:27 PM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4400 | F1: 0.6005
01/28/2023 11:58:27 PM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.5886 | F1: 0.7034
01/28/2023 11:58:27 PM  [*] Evaluating non_pretrained model on test set...
01/28/2023 11:58:32 PM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0158 | F1: 0.0312
01/28/2023 11:58:32 PM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1867 | F1: 0.3147
01/28/2023 11:58:32 PM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.2329 | F1: 0.3776
01/28/2023 11:58:32 PM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.2934 | F1: 0.4529
01/28/2023 11:58:32 PM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3748 | F1: 0.5419
01/28/2023 11:58:32 PM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4288 | F1: 0.5897
01/28/2023 11:58:32 PM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.6211 | F1: 0.7280
01/28/2023 11:58:32 PM  [*] Evaluating full_data model on test set...
01/28/2023 11:58:37 PM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0301 | F1: 0.0584
01/28/2023 11:58:37 PM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.2401 | F1: 0.3872
01/28/2023 11:58:37 PM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.3121 | F1: 0.4755
01/28/2023 11:58:37 PM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.4038 | F1: 0.5743
01/28/2023 11:58:37 PM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.4936 | F1: 0.6572
01/28/2023 11:58:37 PM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.5807 | F1: 0.7230
01/28/2023 11:58:37 PM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.8031 | F1: 0.8507
01/28/2023 11:58:37 PM  [!] Running pre-training split 2/3
01/28/2023 11:58:40 PM  [!] Pre-training model...
01/28/2023 11:58:41 PM  [*] Masking sequences...
01/28/2023 11:59:02 PM  [*] Started epoch: 1
01/28/2023 11:59:02 PM  [*] Sat Jan 28 23:59:02 2023: Train Epoch: 1 [  0  /68513 (0 %)]	Loss: 426.142456 | Elapsed: 0.32s
01/28/2023 11:59:15 PM  [*] Sat Jan 28 23:59:15 2023: Train Epoch: 1 [6400 /68513 (9 %)]	Loss: 222.375992 | Elapsed: 12.30s
01/28/2023 11:59:27 PM  [*] Sat Jan 28 23:59:27 2023: Train Epoch: 1 [12800/68513 (19%)]	Loss: 234.760498 | Elapsed: 12.38s
01/28/2023 11:59:39 PM  [*] Sat Jan 28 23:59:39 2023: Train Epoch: 1 [19200/68513 (28%)]	Loss: 208.961716 | Elapsed: 12.44s
01/28/2023 11:59:52 PM  [*] Sat Jan 28 23:59:52 2023: Train Epoch: 1 [25600/68513 (37%)]	Loss: 195.170380 | Elapsed: 12.32s
01/29/2023 12:00:04 AM  [*] Sun Jan 29 00:00:04 2023: Train Epoch: 1 [32000/68513 (47%)]	Loss: 203.325256 | Elapsed: 12.70s
01/29/2023 12:00:17 AM  [*] Sun Jan 29 00:00:17 2023: Train Epoch: 1 [38400/68513 (56%)]	Loss: 212.967499 | Elapsed: 12.79s
01/29/2023 12:00:30 AM  [*] Sun Jan 29 00:00:30 2023: Train Epoch: 1 [44800/68513 (65%)]	Loss: 219.125732 | Elapsed: 12.42s
01/29/2023 12:00:42 AM  [*] Sun Jan 29 00:00:42 2023: Train Epoch: 1 [51200/68513 (75%)]	Loss: 205.828064 | Elapsed: 12.38s
01/29/2023 12:00:54 AM  [*] Sun Jan 29 00:00:54 2023: Train Epoch: 1 [57600/68513 (84%)]	Loss: 212.322235 | Elapsed: 12.41s
01/29/2023 12:01:07 AM  [*] Sun Jan 29 00:01:07 2023: Train Epoch: 1 [64000/68513 (93%)]	Loss: 182.187347 | Elapsed: 12.48s
01/29/2023 12:01:18 AM  [*] Sun Jan 29 00:01:18 2023:    1    | Tr.loss: 210.807206 | Elapsed:  136.32  s
01/29/2023 12:01:18 AM  [*] Started epoch: 2
01/29/2023 12:01:18 AM  [*] Sun Jan 29 00:01:18 2023: Train Epoch: 2 [  0  /68513 (0 %)]	Loss: 182.567398 | Elapsed: 0.20s
01/29/2023 12:01:31 AM  [*] Sun Jan 29 00:01:31 2023: Train Epoch: 2 [6400 /68513 (9 %)]	Loss: 206.629456 | Elapsed: 12.58s
01/29/2023 12:01:44 AM  [*] Sun Jan 29 00:01:44 2023: Train Epoch: 2 [12800/68513 (19%)]	Loss: 205.952911 | Elapsed: 12.46s
01/29/2023 12:01:56 AM  [*] Sun Jan 29 00:01:56 2023: Train Epoch: 2 [19200/68513 (28%)]	Loss: 179.675385 | Elapsed: 12.40s
01/29/2023 12:02:08 AM  [*] Sun Jan 29 00:02:08 2023: Train Epoch: 2 [25600/68513 (37%)]	Loss: 185.040527 | Elapsed: 12.54s
01/29/2023 12:02:21 AM  [*] Sun Jan 29 00:02:21 2023: Train Epoch: 2 [32000/68513 (47%)]	Loss: 194.799561 | Elapsed: 12.47s
01/29/2023 12:02:33 AM  [*] Sun Jan 29 00:02:33 2023: Train Epoch: 2 [38400/68513 (56%)]	Loss: 209.361694 | Elapsed: 12.41s
01/29/2023 12:02:46 AM  [*] Sun Jan 29 00:02:46 2023: Train Epoch: 2 [44800/68513 (65%)]	Loss: 199.856186 | Elapsed: 12.41s
01/29/2023 12:02:58 AM  [*] Sun Jan 29 00:02:58 2023: Train Epoch: 2 [51200/68513 (75%)]	Loss: 179.662018 | Elapsed: 12.43s
01/29/2023 12:03:11 AM  [*] Sun Jan 29 00:03:11 2023: Train Epoch: 2 [57600/68513 (84%)]	Loss: 191.362000 | Elapsed: 12.45s
01/29/2023 12:03:23 AM  [*] Sun Jan 29 00:03:23 2023: Train Epoch: 2 [64000/68513 (93%)]	Loss: 201.698242 | Elapsed: 12.47s
01/29/2023 12:03:33 AM  [*] Sun Jan 29 00:03:33 2023:    2    | Tr.loss: 191.438018 | Elapsed:  135.18  s
01/29/2023 12:03:33 AM  [*] Started epoch: 3
01/29/2023 12:03:34 AM  [*] Sun Jan 29 00:03:34 2023: Train Epoch: 3 [  0  /68513 (0 %)]	Loss: 199.480499 | Elapsed: 0.20s
01/29/2023 12:03:46 AM  [*] Sun Jan 29 00:03:46 2023: Train Epoch: 3 [6400 /68513 (9 %)]	Loss: 182.974228 | Elapsed: 12.52s
01/29/2023 12:03:59 AM  [*] Sun Jan 29 00:03:59 2023: Train Epoch: 3 [12800/68513 (19%)]	Loss: 173.570862 | Elapsed: 12.47s
01/29/2023 12:04:11 AM  [*] Sun Jan 29 00:04:11 2023: Train Epoch: 3 [19200/68513 (28%)]	Loss: 200.646057 | Elapsed: 12.56s
01/29/2023 12:04:24 AM  [*] Sun Jan 29 00:04:24 2023: Train Epoch: 3 [25600/68513 (37%)]	Loss: 197.310303 | Elapsed: 12.38s
01/29/2023 12:04:36 AM  [*] Sun Jan 29 00:04:36 2023: Train Epoch: 3 [32000/68513 (47%)]	Loss: 190.751434 | Elapsed: 12.50s
01/29/2023 12:04:49 AM  [*] Sun Jan 29 00:04:49 2023: Train Epoch: 3 [38400/68513 (56%)]	Loss: 176.788467 | Elapsed: 12.43s
01/29/2023 12:05:01 AM  [*] Sun Jan 29 00:05:01 2023: Train Epoch: 3 [44800/68513 (65%)]	Loss: 208.895325 | Elapsed: 12.39s
01/29/2023 12:05:13 AM  [*] Sun Jan 29 00:05:13 2023: Train Epoch: 3 [51200/68513 (75%)]	Loss: 185.294495 | Elapsed: 12.45s
01/29/2023 12:05:26 AM  [*] Sun Jan 29 00:05:26 2023: Train Epoch: 3 [57600/68513 (84%)]	Loss: 197.704010 | Elapsed: 12.44s
01/29/2023 12:05:38 AM  [*] Sun Jan 29 00:05:38 2023: Train Epoch: 3 [64000/68513 (93%)]	Loss: 184.123413 | Elapsed: 12.42s
01/29/2023 12:05:49 AM  [*] Sun Jan 29 00:05:49 2023:    3    | Tr.loss: 185.856612 | Elapsed:  135.44  s
01/29/2023 12:05:49 AM  [*] Started epoch: 4
01/29/2023 12:05:49 AM  [*] Sun Jan 29 00:05:49 2023: Train Epoch: 4 [  0  /68513 (0 %)]	Loss: 174.817352 | Elapsed: 0.20s
01/29/2023 12:06:02 AM  [*] Sun Jan 29 00:06:02 2023: Train Epoch: 4 [6400 /68513 (9 %)]	Loss: 186.860657 | Elapsed: 12.50s
01/29/2023 12:06:14 AM  [*] Sun Jan 29 00:06:14 2023: Train Epoch: 4 [12800/68513 (19%)]	Loss: 186.821960 | Elapsed: 12.54s
01/29/2023 12:06:27 AM  [*] Sun Jan 29 00:06:27 2023: Train Epoch: 4 [19200/68513 (28%)]	Loss: 184.914398 | Elapsed: 12.45s
01/29/2023 12:06:39 AM  [*] Sun Jan 29 00:06:39 2023: Train Epoch: 4 [25600/68513 (37%)]	Loss: 174.516266 | Elapsed: 12.44s
01/29/2023 12:06:51 AM  [*] Sun Jan 29 00:06:51 2023: Train Epoch: 4 [32000/68513 (47%)]	Loss: 157.780670 | Elapsed: 12.39s
01/29/2023 12:07:04 AM  [*] Sun Jan 29 00:07:04 2023: Train Epoch: 4 [38400/68513 (56%)]	Loss: 192.315491 | Elapsed: 12.46s
01/29/2023 12:07:16 AM  [*] Sun Jan 29 00:07:16 2023: Train Epoch: 4 [44800/68513 (65%)]	Loss: 204.797150 | Elapsed: 12.37s
01/29/2023 12:07:29 AM  [*] Sun Jan 29 00:07:29 2023: Train Epoch: 4 [51200/68513 (75%)]	Loss: 189.369614 | Elapsed: 12.41s
01/29/2023 12:07:41 AM  [*] Sun Jan 29 00:07:41 2023: Train Epoch: 4 [57600/68513 (84%)]	Loss: 194.725052 | Elapsed: 12.44s
01/29/2023 12:07:54 AM  [*] Sun Jan 29 00:07:54 2023: Train Epoch: 4 [64000/68513 (93%)]	Loss: 208.132996 | Elapsed: 12.47s
01/29/2023 12:08:04 AM  [*] Sun Jan 29 00:08:04 2023:    4    | Tr.loss: 183.485674 | Elapsed:  135.13  s
01/29/2023 12:08:04 AM  [*] Started epoch: 5
01/29/2023 12:08:04 AM  [*] Sun Jan 29 00:08:04 2023: Train Epoch: 5 [  0  /68513 (0 %)]	Loss: 204.757111 | Elapsed: 0.19s
01/29/2023 12:08:17 AM  [*] Sun Jan 29 00:08:17 2023: Train Epoch: 5 [6400 /68513 (9 %)]	Loss: 196.829224 | Elapsed: 12.57s
01/29/2023 12:08:29 AM  [*] Sun Jan 29 00:08:29 2023: Train Epoch: 5 [12800/68513 (19%)]	Loss: 168.894119 | Elapsed: 12.39s
01/29/2023 12:08:42 AM  [*] Sun Jan 29 00:08:42 2023: Train Epoch: 5 [19200/68513 (28%)]	Loss: 202.323334 | Elapsed: 12.46s
01/29/2023 12:08:54 AM  [*] Sun Jan 29 00:08:54 2023: Train Epoch: 5 [25600/68513 (37%)]	Loss: 176.518936 | Elapsed: 12.39s
01/29/2023 12:09:07 AM  [*] Sun Jan 29 00:09:07 2023: Train Epoch: 5 [32000/68513 (47%)]	Loss: 175.016144 | Elapsed: 12.48s
01/29/2023 12:09:19 AM  [*] Sun Jan 29 00:09:19 2023: Train Epoch: 5 [38400/68513 (56%)]	Loss: 196.988998 | Elapsed: 12.42s
01/29/2023 12:09:31 AM  [*] Sun Jan 29 00:09:31 2023: Train Epoch: 5 [44800/68513 (65%)]	Loss: 177.778381 | Elapsed: 12.47s
01/29/2023 12:09:33 AM [!] Learning rate: 2.5e-05
01/29/2023 12:09:44 AM  [*] Sun Jan 29 00:09:44 2023: Train Epoch: 5 [51200/68513 (75%)]	Loss: 162.711426 | Elapsed: 12.39s
01/29/2023 12:09:56 AM  [*] Sun Jan 29 00:09:56 2023: Train Epoch: 5 [57600/68513 (84%)]	Loss: 179.811676 | Elapsed: 12.44s
01/29/2023 12:10:09 AM  [*] Sun Jan 29 00:10:09 2023: Train Epoch: 5 [64000/68513 (93%)]	Loss: 177.041428 | Elapsed: 12.46s
01/29/2023 12:10:19 AM  [*] Sun Jan 29 00:10:19 2023:    5    | Tr.loss: 181.730292 | Elapsed:  135.18  s
01/29/2023 12:10:19 AM  [*] Started epoch: 6
01/29/2023 12:10:19 AM  [*] Sun Jan 29 00:10:19 2023: Train Epoch: 6 [  0  /68513 (0 %)]	Loss: 176.234436 | Elapsed: 0.20s
01/29/2023 12:10:32 AM  [*] Sun Jan 29 00:10:32 2023: Train Epoch: 6 [6400 /68513 (9 %)]	Loss: 160.958038 | Elapsed: 12.58s
01/29/2023 12:10:44 AM  [*] Sun Jan 29 00:10:44 2023: Train Epoch: 6 [12800/68513 (19%)]	Loss: 182.307190 | Elapsed: 12.41s
01/29/2023 12:10:57 AM  [*] Sun Jan 29 00:10:57 2023: Train Epoch: 6 [19200/68513 (28%)]	Loss: 172.073212 | Elapsed: 12.39s
01/29/2023 12:11:09 AM  [*] Sun Jan 29 00:11:09 2023: Train Epoch: 6 [25600/68513 (37%)]	Loss: 201.754990 | Elapsed: 12.43s
01/29/2023 12:11:22 AM  [*] Sun Jan 29 00:11:22 2023: Train Epoch: 6 [32000/68513 (47%)]	Loss: 167.135147 | Elapsed: 12.41s
01/29/2023 12:11:34 AM  [*] Sun Jan 29 00:11:34 2023: Train Epoch: 6 [38400/68513 (56%)]	Loss: 193.703827 | Elapsed: 12.58s
01/29/2023 12:11:47 AM  [*] Sun Jan 29 00:11:47 2023: Train Epoch: 6 [44800/68513 (65%)]	Loss: 192.215240 | Elapsed: 12.42s
01/29/2023 12:11:59 AM  [*] Sun Jan 29 00:11:59 2023: Train Epoch: 6 [51200/68513 (75%)]	Loss: 165.558228 | Elapsed: 12.41s
01/29/2023 12:12:12 AM  [*] Sun Jan 29 00:12:12 2023: Train Epoch: 6 [57600/68513 (84%)]	Loss: 184.726791 | Elapsed: 12.47s
01/29/2023 12:12:24 AM  [*] Sun Jan 29 00:12:24 2023: Train Epoch: 6 [64000/68513 (93%)]	Loss: 195.751282 | Elapsed: 12.41s
01/29/2023 12:12:34 AM  [*] Sun Jan 29 00:12:34 2023:    6    | Tr.loss: 180.460615 | Elapsed:  135.17  s
01/29/2023 12:12:34 AM  [*] Started epoch: 7
01/29/2023 12:12:35 AM  [*] Sun Jan 29 00:12:35 2023: Train Epoch: 7 [  0  /68513 (0 %)]	Loss: 172.966125 | Elapsed: 0.14s
01/29/2023 12:12:47 AM  [*] Sun Jan 29 00:12:47 2023: Train Epoch: 7 [6400 /68513 (9 %)]	Loss: 178.944092 | Elapsed: 12.51s
01/29/2023 12:12:59 AM  [*] Sun Jan 29 00:12:59 2023: Train Epoch: 7 [12800/68513 (19%)]	Loss: 186.347778 | Elapsed: 12.42s
01/29/2023 12:13:12 AM  [*] Sun Jan 29 00:13:12 2023: Train Epoch: 7 [19200/68513 (28%)]	Loss: 152.805328 | Elapsed: 12.53s
01/29/2023 12:13:24 AM  [*] Sun Jan 29 00:13:24 2023: Train Epoch: 7 [25600/68513 (37%)]	Loss: 178.421936 | Elapsed: 12.44s
01/29/2023 12:13:37 AM  [*] Sun Jan 29 00:13:37 2023: Train Epoch: 7 [32000/68513 (47%)]	Loss: 164.060760 | Elapsed: 12.46s
01/29/2023 12:13:49 AM  [*] Sun Jan 29 00:13:49 2023: Train Epoch: 7 [38400/68513 (56%)]	Loss: 186.679657 | Elapsed: 12.35s
01/29/2023 12:14:02 AM  [*] Sun Jan 29 00:14:02 2023: Train Epoch: 7 [44800/68513 (65%)]	Loss: 169.291077 | Elapsed: 12.54s
01/29/2023 12:14:14 AM  [*] Sun Jan 29 00:14:14 2023: Train Epoch: 7 [51200/68513 (75%)]	Loss: 180.721313 | Elapsed: 12.45s
01/29/2023 12:14:27 AM  [*] Sun Jan 29 00:14:27 2023: Train Epoch: 7 [57600/68513 (84%)]	Loss: 178.103149 | Elapsed: 12.41s
01/29/2023 12:14:39 AM  [*] Sun Jan 29 00:14:39 2023: Train Epoch: 7 [64000/68513 (93%)]	Loss: 194.101135 | Elapsed: 12.52s
01/29/2023 12:14:50 AM  [*] Sun Jan 29 00:14:50 2023:    7    | Tr.loss: 180.206405 | Elapsed:  135.24  s
01/29/2023 12:14:50 AM  [*] Started epoch: 8
01/29/2023 12:14:50 AM  [*] Sun Jan 29 00:14:50 2023: Train Epoch: 8 [  0  /68513 (0 %)]	Loss: 183.584808 | Elapsed: 0.22s
01/29/2023 12:15:02 AM  [*] Sun Jan 29 00:15:02 2023: Train Epoch: 8 [6400 /68513 (9 %)]	Loss: 181.668625 | Elapsed: 12.57s
01/29/2023 12:15:15 AM  [*] Sun Jan 29 00:15:15 2023: Train Epoch: 8 [12800/68513 (19%)]	Loss: 188.799667 | Elapsed: 12.43s
01/29/2023 12:15:27 AM  [*] Sun Jan 29 00:15:27 2023: Train Epoch: 8 [19200/68513 (28%)]	Loss: 191.975647 | Elapsed: 12.42s
01/29/2023 12:15:40 AM  [*] Sun Jan 29 00:15:40 2023: Train Epoch: 8 [25600/68513 (37%)]	Loss: 184.405609 | Elapsed: 12.43s
01/29/2023 12:15:52 AM  [*] Sun Jan 29 00:15:52 2023: Train Epoch: 8 [32000/68513 (47%)]	Loss: 182.568024 | Elapsed: 12.40s
01/29/2023 12:16:05 AM  [*] Sun Jan 29 00:16:05 2023: Train Epoch: 8 [38400/68513 (56%)]	Loss: 180.334045 | Elapsed: 12.43s
01/29/2023 12:16:17 AM  [*] Sun Jan 29 00:16:17 2023: Train Epoch: 8 [44800/68513 (65%)]	Loss: 195.833817 | Elapsed: 12.58s
01/29/2023 12:16:30 AM  [*] Sun Jan 29 00:16:30 2023: Train Epoch: 8 [51200/68513 (75%)]	Loss: 184.442047 | Elapsed: 12.41s
01/29/2023 12:16:42 AM  [*] Sun Jan 29 00:16:42 2023: Train Epoch: 8 [57600/68513 (84%)]	Loss: 166.857086 | Elapsed: 12.43s
01/29/2023 12:16:54 AM  [*] Sun Jan 29 00:16:54 2023: Train Epoch: 8 [64000/68513 (93%)]	Loss: 162.156982 | Elapsed: 12.36s
01/29/2023 12:17:05 AM  [*] Sun Jan 29 00:17:05 2023:    8    | Tr.loss: 179.958996 | Elapsed:  135.13  s
01/29/2023 12:17:05 AM  [*] Started epoch: 9
01/29/2023 12:17:05 AM  [*] Sun Jan 29 00:17:05 2023: Train Epoch: 9 [  0  /68513 (0 %)]	Loss: 179.078217 | Elapsed: 0.14s
01/29/2023 12:17:18 AM  [*] Sun Jan 29 00:17:18 2023: Train Epoch: 9 [6400 /68513 (9 %)]	Loss: 153.775787 | Elapsed: 12.62s
01/29/2023 12:17:30 AM  [*] Sun Jan 29 00:17:30 2023: Train Epoch: 9 [12800/68513 (19%)]	Loss: 199.707092 | Elapsed: 12.46s
01/29/2023 12:17:42 AM  [*] Sun Jan 29 00:17:42 2023: Train Epoch: 9 [19200/68513 (28%)]	Loss: 160.052704 | Elapsed: 12.44s
01/29/2023 12:17:55 AM  [*] Sun Jan 29 00:17:55 2023: Train Epoch: 9 [25600/68513 (37%)]	Loss: 177.446045 | Elapsed: 12.43s
01/29/2023 12:18:07 AM  [*] Sun Jan 29 00:18:07 2023: Train Epoch: 9 [32000/68513 (47%)]	Loss: 176.530670 | Elapsed: 12.53s
01/29/2023 12:18:20 AM  [*] Sun Jan 29 00:18:20 2023: Train Epoch: 9 [38400/68513 (56%)]	Loss: 170.314407 | Elapsed: 12.45s
01/29/2023 12:18:32 AM  [*] Sun Jan 29 00:18:32 2023: Train Epoch: 9 [44800/68513 (65%)]	Loss: 169.557205 | Elapsed: 12.41s
01/29/2023 12:18:45 AM  [*] Sun Jan 29 00:18:45 2023: Train Epoch: 9 [51200/68513 (75%)]	Loss: 176.021347 | Elapsed: 12.49s
01/29/2023 12:18:57 AM  [*] Sun Jan 29 00:18:57 2023: Train Epoch: 9 [57600/68513 (84%)]	Loss: 172.638245 | Elapsed: 12.49s
01/29/2023 12:19:10 AM  [*] Sun Jan 29 00:19:10 2023: Train Epoch: 9 [64000/68513 (93%)]	Loss: 178.372467 | Elapsed: 12.35s
01/29/2023 12:19:20 AM  [*] Sun Jan 29 00:19:20 2023:    9    | Tr.loss: 179.722912 | Elapsed:  135.41  s
01/29/2023 12:19:20 AM  [*] Started epoch: 10
01/29/2023 12:19:20 AM  [*] Sun Jan 29 00:19:20 2023: Train Epoch: 10 [  0  /68513 (0 %)]	Loss: 178.679413 | Elapsed: 0.22s
01/29/2023 12:19:33 AM  [*] Sun Jan 29 00:19:33 2023: Train Epoch: 10 [6400 /68513 (9 %)]	Loss: 167.835327 | Elapsed: 12.47s
01/29/2023 12:19:45 AM  [*] Sun Jan 29 00:19:45 2023: Train Epoch: 10 [12800/68513 (19%)]	Loss: 173.444550 | Elapsed: 12.47s
01/29/2023 12:19:58 AM  [*] Sun Jan 29 00:19:58 2023: Train Epoch: 10 [19200/68513 (28%)]	Loss: 195.759094 | Elapsed: 12.40s
01/29/2023 12:20:05 AM [!] Learning rate: 2.5e-06
01/29/2023 12:20:10 AM  [*] Sun Jan 29 00:20:10 2023: Train Epoch: 10 [25600/68513 (37%)]	Loss: 177.707123 | Elapsed: 12.45s
01/29/2023 12:20:23 AM  [*] Sun Jan 29 00:20:23 2023: Train Epoch: 10 [32000/68513 (47%)]	Loss: 167.340698 | Elapsed: 12.47s
01/29/2023 12:20:35 AM  [*] Sun Jan 29 00:20:35 2023: Train Epoch: 10 [38400/68513 (56%)]	Loss: 177.026428 | Elapsed: 12.46s
01/29/2023 12:20:48 AM  [*] Sun Jan 29 00:20:48 2023: Train Epoch: 10 [44800/68513 (65%)]	Loss: 167.971222 | Elapsed: 12.39s
01/29/2023 12:21:00 AM  [*] Sun Jan 29 00:21:00 2023: Train Epoch: 10 [51200/68513 (75%)]	Loss: 177.990173 | Elapsed: 12.37s
01/29/2023 12:21:12 AM  [*] Sun Jan 29 00:21:12 2023: Train Epoch: 10 [57600/68513 (84%)]	Loss: 193.135178 | Elapsed: 12.42s
01/29/2023 12:21:25 AM  [*] Sun Jan 29 00:21:25 2023: Train Epoch: 10 [64000/68513 (93%)]	Loss: 174.638184 | Elapsed: 12.43s
01/29/2023 12:21:35 AM  [*] Sun Jan 29 00:21:35 2023:   10    | Tr.loss: 179.585131 | Elapsed:  135.17  s
01/29/2023 12:21:36 AM [!] Sun Jan 29 00:21:36 2023: Dumped results:
                model     : 1674948095-model.torch
		train time: 1674948095-trainTime.npy
		train losses: 1674948095-trainLosses.npy
		train AUC: 1674948095-auc.npy
01/29/2023 12:21:38 AM  [!] Training pretrained model on downstream task...
01/29/2023 12:21:38 AM  [*] Started epoch: 1
01/29/2023 12:21:38 AM  [*] Sun Jan 29 00:21:38 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 3.938900 | Elapsed: 0.28s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.5990
01/29/2023 12:21:48 AM  [*] Sun Jan 29 00:21:48 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.665585 | Elapsed: 9.14s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.6406
01/29/2023 12:21:49 AM  [*] Sun Jan 29 00:21:49 2023:    1    | Tr.loss: 0.860277 | Elapsed:   11.26  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.6471
01/29/2023 12:21:49 AM  [*] Started epoch: 2
01/29/2023 12:21:50 AM  [*] Sun Jan 29 00:21:50 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.604510 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.7292
01/29/2023 12:21:59 AM  [*] Sun Jan 29 00:21:59 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.666575 | Elapsed: 9.05s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.6690
01/29/2023 12:22:00 AM  [*] Sun Jan 29 00:22:00 2023:    2    | Tr.loss: 0.649877 | Elapsed:   10.96  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.6877
01/29/2023 12:22:00 AM  [*] Started epoch: 3
01/29/2023 12:22:00 AM  [*] Sun Jan 29 00:22:00 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.688265 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.6630
01/29/2023 12:22:10 AM  [*] Sun Jan 29 00:22:10 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.666659 | Elapsed: 9.06s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.6983
01/29/2023 12:22:11 AM  [*] Sun Jan 29 00:22:11 2023:    3    | Tr.loss: 0.637054 | Elapsed:   10.95  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7026
01/29/2023 12:22:12 AM [!] Sun Jan 29 00:22:12 2023: Dumped results:
                model     : 1674948131-model.torch
		train time: 1674948131-trainTime.npy
		train losses: 1674948131-trainLosses.npy
		train AUC: 1674948131-auc.npy
		train F1s : 1674948131-trainF1s.npy
		train TPRs: 1674948131-trainTPRs.npy
01/29/2023 12:22:12 AM  [!] Training non_pretrained model on downstream task...
01/29/2023 12:22:12 AM  [*] Started epoch: 1
01/29/2023 12:22:12 AM  [*] Sun Jan 29 00:22:12 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 1.649454 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.1395 & F1 0.2449 | AUC 0.4773
01/29/2023 12:22:18 AM  [*] Sun Jan 29 00:22:18 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.379700 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.6716 & F1 0.8036 | AUC 0.9059
01/29/2023 12:22:20 AM  [*] Sun Jan 29 00:22:20 2023:    1    | Tr.loss: 0.568362 | Elapsed:   7.61   s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7603
01/29/2023 12:22:20 AM  [*] Started epoch: 2
01/29/2023 12:22:20 AM  [*] Sun Jan 29 00:22:20 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.465589 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.3095 & F1 0.4727 | AUC 0.8344
01/29/2023 12:22:26 AM  [*] Sun Jan 29 00:22:26 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.250793 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.6567 & F1 0.7928 | AUC 0.9349
01/29/2023 12:22:27 AM  [*] Sun Jan 29 00:22:27 2023:    2    | Tr.loss: 0.363168 | Elapsed:   7.56   s | FPR 0.0003 -> TPR: 0.10 & F1: 0.19 | AUC: 0.8941
01/29/2023 12:22:27 AM  [*] Started epoch: 3
01/29/2023 12:22:27 AM  [*] Sun Jan 29 00:22:27 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.294257 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.3864 & F1 0.5574 | AUC 0.9216
01/29/2023 12:22:34 AM  [*] Sun Jan 29 00:22:34 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.315461 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.6000 & F1 0.7500 | AUC 0.9333
01/29/2023 12:22:35 AM  [*] Sun Jan 29 00:22:35 2023:    3    | Tr.loss: 0.308443 | Elapsed:   7.52   s | FPR 0.0003 -> TPR: 0.17 & F1: 0.30 | AUC: 0.9268
01/29/2023 12:22:35 AM [!] Sun Jan 29 00:22:35 2023: Dumped results:
                model     : 1674948155-model.torch
		train time: 1674948155-trainTime.npy
		train losses: 1674948155-trainLosses.npy
		train AUC: 1674948155-auc.npy
		train F1s : 1674948155-trainF1s.npy
		train TPRs: 1674948155-trainTPRs.npy
01/29/2023 12:22:35 AM  [!] Training full_data model on downstream task...
01/29/2023 12:22:36 AM  [*] Started epoch: 1
01/29/2023 12:22:36 AM  [*] Sun Jan 29 00:22:36 2023: Train Epoch: 1 [  0  /76126 (0 %)]	Loss: 2.995098 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.5779
01/29/2023 12:22:42 AM  [*] Sun Jan 29 00:22:42 2023: Train Epoch: 1 [6400 /76126 (8 %)]	Loss: 0.419045 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.2615 & F1 0.4146 | AUC 0.8233
01/29/2023 12:22:48 AM  [*] Sun Jan 29 00:22:48 2023: Train Epoch: 1 [12800/76126 (17%)]	Loss: 0.418503 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.4697 & F1 0.6392 | AUC 0.8801
01/29/2023 12:22:54 AM  [*] Sun Jan 29 00:22:54 2023: Train Epoch: 1 [19200/76126 (25%)]	Loss: 0.347131 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.4493 & F1 0.6200 | AUC 0.9046
01/29/2023 12:23:01 AM  [*] Sun Jan 29 00:23:01 2023: Train Epoch: 1 [25600/76126 (34%)]	Loss: 0.388016 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.5429 & F1 0.7037 | AUC 0.9181
01/29/2023 12:23:07 AM  [*] Sun Jan 29 00:23:07 2023: Train Epoch: 1 [32000/76126 (42%)]	Loss: 0.269175 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.7101 & F1 0.8305 | AUC 0.9659
01/29/2023 12:23:13 AM  [*] Sun Jan 29 00:23:13 2023: Train Epoch: 1 [38400/76126 (50%)]	Loss: 0.136085 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.9028 & F1 0.9489 | AUC 0.9921
01/29/2023 12:23:19 AM  [*] Sun Jan 29 00:23:19 2023: Train Epoch: 1 [44800/76126 (59%)]	Loss: 0.319530 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.5811 & F1 0.7350 | AUC 0.9070
01/29/2023 12:23:26 AM  [*] Sun Jan 29 00:23:26 2023: Train Epoch: 1 [51200/76126 (67%)]	Loss: 0.272191 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.6154 & F1 0.7619 | AUC 0.9380
01/29/2023 12:23:32 AM  [*] Sun Jan 29 00:23:32 2023: Train Epoch: 1 [57600/76126 (76%)]	Loss: 0.250230 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.8333 & F1 0.9091 | AUC 0.9712
01/29/2023 12:23:38 AM [!] Learning rate: 2.5e-05
01/29/2023 12:23:38 AM  [*] Sun Jan 29 00:23:38 2023: Train Epoch: 1 [64000/76126 (84%)]	Loss: 0.182323 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.6866 & F1 0.8142 | AUC 0.9711
01/29/2023 12:23:44 AM  [*] Sun Jan 29 00:23:44 2023: Train Epoch: 1 [70400/76126 (92%)]	Loss: 0.173176 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.8714 & F1 0.9313 | AUC 0.9871
01/29/2023 12:23:51 AM  [*] Sun Jan 29 00:23:51 2023:    1    | Tr.loss: 0.298763 | Elapsed:   75.59  s | FPR 0.0003 -> TPR: 0.05 & F1: 0.09 | AUC: 0.9349
01/29/2023 12:23:51 AM  [*] Started epoch: 2
01/29/2023 12:23:51 AM  [*] Sun Jan 29 00:23:51 2023: Train Epoch: 2 [  0  /76126 (0 %)]	Loss: 0.153976 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.8444 & F1 0.9157 | AUC 0.9860
01/29/2023 12:23:58 AM  [*] Sun Jan 29 00:23:58 2023: Train Epoch: 2 [6400 /76126 (8 %)]	Loss: 0.141833 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.8906 & F1 0.9421 | AUC 0.9844
01/29/2023 12:24:04 AM  [*] Sun Jan 29 00:24:04 2023: Train Epoch: 2 [12800/76126 (17%)]	Loss: 0.163462 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.5593 & F1 0.7174 | AUC 0.9802
01/29/2023 12:24:10 AM  [*] Sun Jan 29 00:24:10 2023: Train Epoch: 2 [19200/76126 (25%)]	Loss: 0.135446 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.8806 & F1 0.9365 | AUC 0.9833
01/29/2023 12:24:16 AM  [*] Sun Jan 29 00:24:16 2023: Train Epoch: 2 [25600/76126 (34%)]	Loss: 0.116973 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.8955 & F1 0.9449 | AUC 0.9905
01/29/2023 12:24:22 AM  [*] Sun Jan 29 00:24:22 2023: Train Epoch: 2 [32000/76126 (42%)]	Loss: 0.191197 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.7910 & F1 0.8833 | AUC 0.9692
01/29/2023 12:24:29 AM  [*] Sun Jan 29 00:24:29 2023: Train Epoch: 2 [38400/76126 (50%)]	Loss: 0.208463 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.6389 & F1 0.7797 | AUC 0.9697
01/29/2023 12:24:35 AM  [*] Sun Jan 29 00:24:35 2023: Train Epoch: 2 [44800/76126 (59%)]	Loss: 0.198712 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.7727 & F1 0.8718 | AUC 0.9693
01/29/2023 12:24:41 AM  [*] Sun Jan 29 00:24:41 2023: Train Epoch: 2 [51200/76126 (67%)]	Loss: 0.115539 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.9118 & F1 0.9538 | AUC 0.9816
01/29/2023 12:24:42 AM [!] Learning rate: 2.5e-06
01/29/2023 12:24:47 AM  [*] Sun Jan 29 00:24:47 2023: Train Epoch: 2 [57600/76126 (76%)]	Loss: 0.176680 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.7077 & F1 0.8288 | AUC 0.9767
01/29/2023 12:24:54 AM  [*] Sun Jan 29 00:24:54 2023: Train Epoch: 2 [64000/76126 (84%)]	Loss: 0.190496 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.8333 & F1 0.9091 | AUC 0.9710
01/29/2023 12:25:00 AM  [*] Sun Jan 29 00:25:00 2023: Train Epoch: 2 [70400/76126 (92%)]	Loss: 0.180123 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.8493 & F1 0.9185 | AUC 0.9797
01/29/2023 12:25:07 AM  [*] Sun Jan 29 00:25:07 2023:    2    | Tr.loss: 0.170765 | Elapsed:   75.63  s | FPR 0.0003 -> TPR: 0.45 & F1: 0.62 | AUC: 0.9796
01/29/2023 12:25:07 AM  [*] Started epoch: 3
01/29/2023 12:25:07 AM  [*] Sun Jan 29 00:25:07 2023: Train Epoch: 3 [  0  /76126 (0 %)]	Loss: 0.119972 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.9737 & F1 0.9867 | AUC 0.9980
01/29/2023 12:25:13 AM  [*] Sun Jan 29 00:25:13 2023: Train Epoch: 3 [6400 /76126 (8 %)]	Loss: 0.239930 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.7015 & F1 0.8246 | AUC 0.9796
01/29/2023 12:25:20 AM  [*] Sun Jan 29 00:25:20 2023: Train Epoch: 3 [12800/76126 (17%)]	Loss: 0.111225 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.8308 & F1 0.9076 | AUC 0.9807
01/29/2023 12:25:26 AM  [*] Sun Jan 29 00:25:26 2023: Train Epoch: 3 [19200/76126 (25%)]	Loss: 0.122563 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.8254 & F1 0.9043 | AUC 0.9888
01/29/2023 12:25:32 AM  [*] Sun Jan 29 00:25:32 2023: Train Epoch: 3 [25600/76126 (34%)]	Loss: 0.136066 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.9403 & F1 0.9692 | AUC 0.9891
01/29/2023 12:25:38 AM  [*] Sun Jan 29 00:25:38 2023: Train Epoch: 3 [32000/76126 (42%)]	Loss: 0.189016 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.8462 & F1 0.9167 | AUC 0.9688
01/29/2023 12:25:44 AM  [*] Sun Jan 29 00:25:44 2023: Train Epoch: 3 [38400/76126 (50%)]	Loss: 0.119953 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.8947 & F1 0.9444 | AUC 0.9923
01/29/2023 12:25:46 AM [!] Learning rate: 2.5000000000000004e-07
01/29/2023 12:25:51 AM  [*] Sun Jan 29 00:25:51 2023: Train Epoch: 3 [44800/76126 (59%)]	Loss: 0.129925 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.8281 & F1 0.9060 | AUC 0.9844
01/29/2023 12:25:57 AM  [*] Sun Jan 29 00:25:57 2023: Train Epoch: 3 [51200/76126 (67%)]	Loss: 0.174678 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.6027 & F1 0.7521 | AUC 0.9630
01/29/2023 12:26:03 AM  [*] Sun Jan 29 00:26:03 2023: Train Epoch: 3 [57600/76126 (76%)]	Loss: 0.115373 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.8451 & F1 0.9160 | AUC 0.9874
01/29/2023 12:26:09 AM  [*] Sun Jan 29 00:26:09 2023: Train Epoch: 3 [64000/76126 (84%)]	Loss: 0.129939 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.7846 & F1 0.8793 | AUC 0.9815
01/29/2023 12:26:15 AM  [*] Sun Jan 29 00:26:15 2023: Train Epoch: 3 [70400/76126 (92%)]	Loss: 0.179643 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.6716 & F1 0.8036 | AUC 0.9765
01/29/2023 12:26:23 AM  [*] Sun Jan 29 00:26:23 2023:    3    | Tr.loss: 0.164100 | Elapsed:   75.85  s | FPR 0.0003 -> TPR: 0.47 & F1: 0.64 | AUC: 0.9812
01/29/2023 12:26:23 AM [!] Sun Jan 29 00:26:23 2023: Dumped results:
                model     : 1674948383-model.torch
		train time: 1674948383-trainTime.npy
		train losses: 1674948383-trainLosses.npy
		train AUC: 1674948383-auc.npy
		train F1s : 1674948383-trainF1s.npy
		train TPRs: 1674948383-trainTPRs.npy
01/29/2023 12:26:23 AM  [*] Evaluating pretrained model on test set...
01/29/2023 12:26:28 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0000 | F1: 0.0000
01/29/2023 12:26:28 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.0000 | F1: 0.0000
01/29/2023 12:26:28 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.0000 | F1: 0.0000
01/29/2023 12:26:28 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.0000 | F1: 0.0000
01/29/2023 12:26:28 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.0000 | F1: 0.0000
01/29/2023 12:26:28 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.0000 | F1: 0.0000
01/29/2023 12:26:28 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.0000 | F1: 0.0000
01/29/2023 12:26:28 AM  [*] Evaluating non_pretrained model on test set...
01/29/2023 12:26:33 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0302 | F1: 0.0586
01/29/2023 12:26:33 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1182 | F1: 0.2113
01/29/2023 12:26:33 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.2475 | F1: 0.3965
01/29/2023 12:26:33 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.2843 | F1: 0.4418
01/29/2023 12:26:33 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3624 | F1: 0.5287
01/29/2023 12:26:33 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4558 | F1: 0.6154
01/29/2023 12:26:33 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.6285 | F1: 0.7336
01/29/2023 12:26:33 AM  [*] Evaluating full_data model on test set...
01/29/2023 12:26:38 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0442 | F1: 0.0847
01/29/2023 12:26:38 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.2339 | F1: 0.3790
01/29/2023 12:26:38 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.3455 | F1: 0.5133
01/29/2023 12:26:38 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3940 | F1: 0.5643
01/29/2023 12:26:38 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.4628 | F1: 0.6291
01/29/2023 12:26:38 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.5691 | F1: 0.7138
01/29/2023 12:26:38 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.7902 | F1: 0.8427
01/29/2023 12:26:38 AM  [!] Running pre-training split 3/3
01/29/2023 12:26:42 AM  [!] Pre-training model...
01/29/2023 12:26:42 AM  [*] Masking sequences...
01/29/2023 12:27:03 AM  [*] Started epoch: 1
01/29/2023 12:27:04 AM  [*] Sun Jan 29 00:27:04 2023: Train Epoch: 1 [  0  /68513 (0 %)]	Loss: 418.918243 | Elapsed: 0.83s
01/29/2023 12:27:16 AM  [*] Sun Jan 29 00:27:16 2023: Train Epoch: 1 [6400 /68513 (9 %)]	Loss: 220.005676 | Elapsed: 12.29s
01/29/2023 12:27:29 AM  [*] Sun Jan 29 00:27:29 2023: Train Epoch: 1 [12800/68513 (19%)]	Loss: 213.146118 | Elapsed: 12.40s
01/29/2023 12:27:41 AM  [*] Sun Jan 29 00:27:41 2023: Train Epoch: 1 [19200/68513 (28%)]	Loss: 209.642151 | Elapsed: 12.35s
01/29/2023 12:27:54 AM  [*] Sun Jan 29 00:27:54 2023: Train Epoch: 1 [25600/68513 (37%)]	Loss: 197.909058 | Elapsed: 12.43s
01/29/2023 12:28:06 AM  [*] Sun Jan 29 00:28:06 2023: Train Epoch: 1 [32000/68513 (47%)]	Loss: 196.447571 | Elapsed: 12.42s
01/29/2023 12:28:18 AM  [*] Sun Jan 29 00:28:18 2023: Train Epoch: 1 [38400/68513 (56%)]	Loss: 186.461670 | Elapsed: 12.45s
01/29/2023 12:28:31 AM  [*] Sun Jan 29 00:28:31 2023: Train Epoch: 1 [44800/68513 (65%)]	Loss: 186.477264 | Elapsed: 12.34s
01/29/2023 12:28:43 AM  [*] Sun Jan 29 00:28:43 2023: Train Epoch: 1 [51200/68513 (75%)]	Loss: 191.342545 | Elapsed: 12.42s
01/29/2023 12:28:56 AM  [*] Sun Jan 29 00:28:56 2023: Train Epoch: 1 [57600/68513 (84%)]	Loss: 184.630249 | Elapsed: 12.44s
01/29/2023 12:29:08 AM  [*] Sun Jan 29 00:29:08 2023: Train Epoch: 1 [64000/68513 (93%)]	Loss: 201.718414 | Elapsed: 12.42s
01/29/2023 12:29:20 AM  [*] Sun Jan 29 00:29:20 2023:    1    | Tr.loss: 208.106258 | Elapsed:  136.28  s
01/29/2023 12:29:20 AM  [*] Started epoch: 2
01/29/2023 12:29:20 AM  [*] Sun Jan 29 00:29:20 2023: Train Epoch: 2 [  0  /68513 (0 %)]	Loss: 187.072464 | Elapsed: 0.21s
01/29/2023 12:29:32 AM  [*] Sun Jan 29 00:29:32 2023: Train Epoch: 2 [6400 /68513 (9 %)]	Loss: 209.245575 | Elapsed: 12.45s
01/29/2023 12:29:45 AM  [*] Sun Jan 29 00:29:45 2023: Train Epoch: 2 [12800/68513 (19%)]	Loss: 190.846619 | Elapsed: 12.48s
01/29/2023 12:29:57 AM  [*] Sun Jan 29 00:29:57 2023: Train Epoch: 2 [19200/68513 (28%)]	Loss: 173.045502 | Elapsed: 12.47s
01/29/2023 12:30:10 AM  [*] Sun Jan 29 00:30:10 2023: Train Epoch: 2 [25600/68513 (37%)]	Loss: 175.603394 | Elapsed: 12.50s
01/29/2023 12:30:22 AM  [*] Sun Jan 29 00:30:22 2023: Train Epoch: 2 [32000/68513 (47%)]	Loss: 202.923676 | Elapsed: 12.47s
01/29/2023 12:30:35 AM  [*] Sun Jan 29 00:30:35 2023: Train Epoch: 2 [38400/68513 (56%)]	Loss: 175.022552 | Elapsed: 12.44s
01/29/2023 12:30:47 AM  [*] Sun Jan 29 00:30:47 2023: Train Epoch: 2 [44800/68513 (65%)]	Loss: 180.729691 | Elapsed: 12.39s
01/29/2023 12:30:59 AM  [*] Sun Jan 29 00:30:59 2023: Train Epoch: 2 [51200/68513 (75%)]	Loss: 190.670395 | Elapsed: 12.46s
01/29/2023 12:31:12 AM  [*] Sun Jan 29 00:31:12 2023: Train Epoch: 2 [57600/68513 (84%)]	Loss: 180.454132 | Elapsed: 12.39s
01/29/2023 12:31:24 AM  [*] Sun Jan 29 00:31:24 2023: Train Epoch: 2 [64000/68513 (93%)]	Loss: 171.984406 | Elapsed: 12.50s
01/29/2023 12:31:35 AM  [*] Sun Jan 29 00:31:35 2023:    2    | Tr.loss: 188.933279 | Elapsed:  135.36  s
01/29/2023 12:31:35 AM  [*] Started epoch: 3
01/29/2023 12:31:35 AM  [*] Sun Jan 29 00:31:35 2023: Train Epoch: 3 [  0  /68513 (0 %)]	Loss: 170.386993 | Elapsed: 0.22s
01/29/2023 12:31:48 AM  [*] Sun Jan 29 00:31:48 2023: Train Epoch: 3 [6400 /68513 (9 %)]	Loss: 181.263474 | Elapsed: 12.48s
01/29/2023 12:32:00 AM  [*] Sun Jan 29 00:32:00 2023: Train Epoch: 3 [12800/68513 (19%)]	Loss: 210.189209 | Elapsed: 12.38s
01/29/2023 12:32:13 AM  [*] Sun Jan 29 00:32:13 2023: Train Epoch: 3 [19200/68513 (28%)]	Loss: 210.123169 | Elapsed: 12.57s
01/29/2023 12:32:25 AM  [*] Sun Jan 29 00:32:25 2023: Train Epoch: 3 [25600/68513 (37%)]	Loss: 188.300552 | Elapsed: 12.48s
01/29/2023 12:32:37 AM  [*] Sun Jan 29 00:32:37 2023: Train Epoch: 3 [32000/68513 (47%)]	Loss: 198.845764 | Elapsed: 12.41s
01/29/2023 12:32:50 AM  [*] Sun Jan 29 00:32:50 2023: Train Epoch: 3 [38400/68513 (56%)]	Loss: 157.185211 | Elapsed: 12.46s
01/29/2023 12:33:02 AM  [*] Sun Jan 29 00:33:02 2023: Train Epoch: 3 [44800/68513 (65%)]	Loss: 192.404068 | Elapsed: 12.41s
01/29/2023 12:33:15 AM  [*] Sun Jan 29 00:33:15 2023: Train Epoch: 3 [51200/68513 (75%)]	Loss: 167.856705 | Elapsed: 12.32s
01/29/2023 12:33:27 AM  [*] Sun Jan 29 00:33:27 2023: Train Epoch: 3 [57600/68513 (84%)]	Loss: 188.860413 | Elapsed: 12.43s
01/29/2023 12:33:40 AM  [*] Sun Jan 29 00:33:40 2023: Train Epoch: 3 [64000/68513 (93%)]	Loss: 183.374390 | Elapsed: 12.45s
01/29/2023 12:33:50 AM  [*] Sun Jan 29 00:33:50 2023:    3    | Tr.loss: 183.641424 | Elapsed:  135.11  s
01/29/2023 12:33:50 AM  [*] Started epoch: 4
01/29/2023 12:33:50 AM  [*] Sun Jan 29 00:33:50 2023: Train Epoch: 4 [  0  /68513 (0 %)]	Loss: 154.093628 | Elapsed: 0.14s
01/29/2023 12:34:03 AM  [*] Sun Jan 29 00:34:03 2023: Train Epoch: 4 [6400 /68513 (9 %)]	Loss: 173.198669 | Elapsed: 12.54s
01/29/2023 12:34:15 AM  [*] Sun Jan 29 00:34:15 2023: Train Epoch: 4 [12800/68513 (19%)]	Loss: 176.311142 | Elapsed: 12.41s
01/29/2023 12:34:28 AM  [*] Sun Jan 29 00:34:28 2023: Train Epoch: 4 [19200/68513 (28%)]	Loss: 189.457611 | Elapsed: 12.37s
01/29/2023 12:34:40 AM  [*] Sun Jan 29 00:34:40 2023: Train Epoch: 4 [25600/68513 (37%)]	Loss: 172.329819 | Elapsed: 12.51s
01/29/2023 12:34:52 AM  [*] Sun Jan 29 00:34:52 2023: Train Epoch: 4 [32000/68513 (47%)]	Loss: 182.879822 | Elapsed: 12.44s
01/29/2023 12:35:05 AM  [*] Sun Jan 29 00:35:05 2023: Train Epoch: 4 [38400/68513 (56%)]	Loss: 182.019806 | Elapsed: 12.40s
01/29/2023 12:35:17 AM  [*] Sun Jan 29 00:35:17 2023: Train Epoch: 4 [44800/68513 (65%)]	Loss: 183.119858 | Elapsed: 12.42s
01/29/2023 12:35:30 AM  [*] Sun Jan 29 00:35:30 2023: Train Epoch: 4 [51200/68513 (75%)]	Loss: 171.759995 | Elapsed: 12.47s
01/29/2023 12:35:42 AM  [*] Sun Jan 29 00:35:42 2023: Train Epoch: 4 [57600/68513 (84%)]	Loss: 184.388092 | Elapsed: 12.38s
01/29/2023 12:35:55 AM  [*] Sun Jan 29 00:35:55 2023: Train Epoch: 4 [64000/68513 (93%)]	Loss: 190.190948 | Elapsed: 12.43s
01/29/2023 12:36:05 AM  [*] Sun Jan 29 00:36:05 2023:    4    | Tr.loss: 180.886375 | Elapsed:  134.98  s
01/29/2023 12:36:05 AM  [*] Started epoch: 5
01/29/2023 12:36:05 AM  [*] Sun Jan 29 00:36:05 2023: Train Epoch: 5 [  0  /68513 (0 %)]	Loss: 171.364243 | Elapsed: 0.18s
01/29/2023 12:36:18 AM  [*] Sun Jan 29 00:36:18 2023: Train Epoch: 5 [6400 /68513 (9 %)]	Loss: 176.040359 | Elapsed: 12.53s
01/29/2023 12:36:30 AM  [*] Sun Jan 29 00:36:30 2023: Train Epoch: 5 [12800/68513 (19%)]	Loss: 187.522491 | Elapsed: 12.44s
01/29/2023 12:36:42 AM  [*] Sun Jan 29 00:36:42 2023: Train Epoch: 5 [19200/68513 (28%)]	Loss: 181.521484 | Elapsed: 12.34s
01/29/2023 12:36:55 AM  [*] Sun Jan 29 00:36:55 2023: Train Epoch: 5 [25600/68513 (37%)]	Loss: 179.662689 | Elapsed: 12.37s
01/29/2023 12:37:07 AM  [*] Sun Jan 29 00:37:07 2023: Train Epoch: 5 [32000/68513 (47%)]	Loss: 167.699768 | Elapsed: 12.49s
01/29/2023 12:37:20 AM  [*] Sun Jan 29 00:37:20 2023: Train Epoch: 5 [38400/68513 (56%)]	Loss: 141.696411 | Elapsed: 12.43s
01/29/2023 12:37:32 AM  [*] Sun Jan 29 00:37:32 2023: Train Epoch: 5 [44800/68513 (65%)]	Loss: 180.867493 | Elapsed: 12.50s
01/29/2023 12:37:34 AM [!] Learning rate: 2.5e-05
01/29/2023 12:37:45 AM  [*] Sun Jan 29 00:37:45 2023: Train Epoch: 5 [51200/68513 (75%)]	Loss: 161.333801 | Elapsed: 12.39s
01/29/2023 12:37:57 AM  [*] Sun Jan 29 00:37:57 2023: Train Epoch: 5 [57600/68513 (84%)]	Loss: 170.313904 | Elapsed: 12.36s
01/29/2023 12:38:09 AM  [*] Sun Jan 29 00:38:09 2023: Train Epoch: 5 [64000/68513 (93%)]	Loss: 173.157196 | Elapsed: 12.40s
01/29/2023 12:38:20 AM  [*] Sun Jan 29 00:38:20 2023:    5    | Tr.loss: 179.233321 | Elapsed:  134.89  s
01/29/2023 12:38:20 AM  [*] Started epoch: 6
01/29/2023 12:38:20 AM  [*] Sun Jan 29 00:38:20 2023: Train Epoch: 6 [  0  /68513 (0 %)]	Loss: 189.022247 | Elapsed: 0.13s
01/29/2023 12:38:33 AM  [*] Sun Jan 29 00:38:33 2023: Train Epoch: 6 [6400 /68513 (9 %)]	Loss: 171.479889 | Elapsed: 12.52s
01/29/2023 12:38:45 AM  [*] Sun Jan 29 00:38:45 2023: Train Epoch: 6 [12800/68513 (19%)]	Loss: 184.645584 | Elapsed: 12.39s
01/29/2023 12:38:57 AM  [*] Sun Jan 29 00:38:57 2023: Train Epoch: 6 [19200/68513 (28%)]	Loss: 163.268005 | Elapsed: 12.38s
01/29/2023 12:39:10 AM  [*] Sun Jan 29 00:39:10 2023: Train Epoch: 6 [25600/68513 (37%)]	Loss: 183.405457 | Elapsed: 12.43s
01/29/2023 12:39:22 AM  [*] Sun Jan 29 00:39:22 2023: Train Epoch: 6 [32000/68513 (47%)]	Loss: 194.996216 | Elapsed: 12.41s
01/29/2023 12:39:35 AM  [*] Sun Jan 29 00:39:35 2023: Train Epoch: 6 [38400/68513 (56%)]	Loss: 195.573425 | Elapsed: 12.52s
01/29/2023 12:39:47 AM  [*] Sun Jan 29 00:39:47 2023: Train Epoch: 6 [44800/68513 (65%)]	Loss: 177.861694 | Elapsed: 12.32s
01/29/2023 12:39:59 AM  [*] Sun Jan 29 00:39:59 2023: Train Epoch: 6 [51200/68513 (75%)]	Loss: 171.911621 | Elapsed: 12.41s
01/29/2023 12:40:12 AM  [*] Sun Jan 29 00:40:12 2023: Train Epoch: 6 [57600/68513 (84%)]	Loss: 177.622253 | Elapsed: 12.41s
01/29/2023 12:40:24 AM  [*] Sun Jan 29 00:40:24 2023: Train Epoch: 6 [64000/68513 (93%)]	Loss: 172.222702 | Elapsed: 12.34s
01/29/2023 12:40:35 AM  [*] Sun Jan 29 00:40:35 2023:    6    | Tr.loss: 177.973081 | Elapsed:  134.78  s
01/29/2023 12:40:35 AM  [*] Started epoch: 7
01/29/2023 12:40:35 AM  [*] Sun Jan 29 00:40:35 2023: Train Epoch: 7 [  0  /68513 (0 %)]	Loss: 176.189865 | Elapsed: 0.14s
01/29/2023 12:40:47 AM  [*] Sun Jan 29 00:40:47 2023: Train Epoch: 7 [6400 /68513 (9 %)]	Loss: 186.141479 | Elapsed: 12.50s
01/29/2023 12:41:00 AM  [*] Sun Jan 29 00:41:00 2023: Train Epoch: 7 [12800/68513 (19%)]	Loss: 185.032806 | Elapsed: 12.47s
01/29/2023 12:41:12 AM  [*] Sun Jan 29 00:41:12 2023: Train Epoch: 7 [19200/68513 (28%)]	Loss: 183.270889 | Elapsed: 12.42s
01/29/2023 12:41:25 AM  [*] Sun Jan 29 00:41:25 2023: Train Epoch: 7 [25600/68513 (37%)]	Loss: 192.655228 | Elapsed: 12.40s
01/29/2023 12:41:37 AM  [*] Sun Jan 29 00:41:37 2023: Train Epoch: 7 [32000/68513 (47%)]	Loss: 160.673737 | Elapsed: 12.57s
01/29/2023 12:41:50 AM  [*] Sun Jan 29 00:41:50 2023: Train Epoch: 7 [38400/68513 (56%)]	Loss: 171.564560 | Elapsed: 12.42s
01/29/2023 12:42:02 AM  [*] Sun Jan 29 00:42:02 2023: Train Epoch: 7 [44800/68513 (65%)]	Loss: 175.617401 | Elapsed: 12.44s
01/29/2023 12:42:14 AM  [*] Sun Jan 29 00:42:14 2023: Train Epoch: 7 [51200/68513 (75%)]	Loss: 173.484940 | Elapsed: 12.40s
01/29/2023 12:42:27 AM  [*] Sun Jan 29 00:42:27 2023: Train Epoch: 7 [57600/68513 (84%)]	Loss: 161.306427 | Elapsed: 12.43s
01/29/2023 12:42:39 AM  [*] Sun Jan 29 00:42:39 2023: Train Epoch: 7 [64000/68513 (93%)]	Loss: 171.858978 | Elapsed: 12.42s
01/29/2023 12:42:50 AM  [*] Sun Jan 29 00:42:50 2023:    7    | Tr.loss: 177.682145 | Elapsed:  135.08  s
01/29/2023 12:42:50 AM  [*] Started epoch: 8
01/29/2023 12:42:50 AM  [*] Sun Jan 29 00:42:50 2023: Train Epoch: 8 [  0  /68513 (0 %)]	Loss: 163.622437 | Elapsed: 0.14s
01/29/2023 12:43:02 AM  [*] Sun Jan 29 00:43:02 2023: Train Epoch: 8 [6400 /68513 (9 %)]	Loss: 172.013016 | Elapsed: 12.51s
01/29/2023 12:43:15 AM  [*] Sun Jan 29 00:43:15 2023: Train Epoch: 8 [12800/68513 (19%)]	Loss: 176.061905 | Elapsed: 12.42s
01/29/2023 12:43:27 AM  [*] Sun Jan 29 00:43:27 2023: Train Epoch: 8 [19200/68513 (28%)]	Loss: 188.620850 | Elapsed: 12.45s
01/29/2023 12:43:40 AM  [*] Sun Jan 29 00:43:40 2023: Train Epoch: 8 [25600/68513 (37%)]	Loss: 211.089630 | Elapsed: 12.36s
01/29/2023 12:43:52 AM  [*] Sun Jan 29 00:43:52 2023: Train Epoch: 8 [32000/68513 (47%)]	Loss: 191.427094 | Elapsed: 12.49s
01/29/2023 12:44:05 AM  [*] Sun Jan 29 00:44:05 2023: Train Epoch: 8 [38400/68513 (56%)]	Loss: 157.050690 | Elapsed: 12.43s
01/29/2023 12:44:17 AM  [*] Sun Jan 29 00:44:17 2023: Train Epoch: 8 [44800/68513 (65%)]	Loss: 165.073410 | Elapsed: 12.42s
01/29/2023 12:44:29 AM  [*] Sun Jan 29 00:44:29 2023: Train Epoch: 8 [51200/68513 (75%)]	Loss: 174.254349 | Elapsed: 12.43s
01/29/2023 12:44:42 AM  [*] Sun Jan 29 00:44:42 2023: Train Epoch: 8 [57600/68513 (84%)]	Loss: 177.289413 | Elapsed: 12.47s
01/29/2023 12:44:54 AM  [*] Sun Jan 29 00:44:54 2023: Train Epoch: 8 [64000/68513 (93%)]	Loss: 184.820953 | Elapsed: 12.41s
01/29/2023 12:45:05 AM  [*] Sun Jan 29 00:45:05 2023:    8    | Tr.loss: 177.532975 | Elapsed:  135.03  s
01/29/2023 12:45:05 AM  [*] Started epoch: 9
01/29/2023 12:45:05 AM  [*] Sun Jan 29 00:45:05 2023: Train Epoch: 9 [  0  /68513 (0 %)]	Loss: 173.179016 | Elapsed: 0.14s
01/29/2023 12:45:17 AM  [*] Sun Jan 29 00:45:17 2023: Train Epoch: 9 [6400 /68513 (9 %)]	Loss: 178.885239 | Elapsed: 12.51s
01/29/2023 12:45:30 AM  [*] Sun Jan 29 00:45:30 2023: Train Epoch: 9 [12800/68513 (19%)]	Loss: 218.426392 | Elapsed: 12.47s
01/29/2023 12:45:42 AM  [*] Sun Jan 29 00:45:42 2023: Train Epoch: 9 [19200/68513 (28%)]	Loss: 173.990997 | Elapsed: 12.38s
01/29/2023 12:45:55 AM  [*] Sun Jan 29 00:45:55 2023: Train Epoch: 9 [25600/68513 (37%)]	Loss: 188.887238 | Elapsed: 12.41s
01/29/2023 12:46:07 AM  [*] Sun Jan 29 00:46:07 2023: Train Epoch: 9 [32000/68513 (47%)]	Loss: 185.512634 | Elapsed: 12.38s
01/29/2023 12:46:20 AM  [*] Sun Jan 29 00:46:20 2023: Train Epoch: 9 [38400/68513 (56%)]	Loss: 189.948853 | Elapsed: 12.43s
01/29/2023 12:46:32 AM  [*] Sun Jan 29 00:46:32 2023: Train Epoch: 9 [44800/68513 (65%)]	Loss: 151.594727 | Elapsed: 12.45s
01/29/2023 12:46:44 AM  [*] Sun Jan 29 00:46:44 2023: Train Epoch: 9 [51200/68513 (75%)]	Loss: 172.718658 | Elapsed: 12.45s
01/29/2023 12:46:57 AM  [*] Sun Jan 29 00:46:57 2023: Train Epoch: 9 [57600/68513 (84%)]	Loss: 176.076370 | Elapsed: 12.41s
01/29/2023 12:47:09 AM  [*] Sun Jan 29 00:47:09 2023: Train Epoch: 9 [64000/68513 (93%)]	Loss: 170.816254 | Elapsed: 12.45s
01/29/2023 12:47:20 AM  [*] Sun Jan 29 00:47:20 2023:    9    | Tr.loss: 177.371185 | Elapsed:  135.02  s
01/29/2023 12:47:20 AM  [*] Started epoch: 10
01/29/2023 12:47:20 AM  [*] Sun Jan 29 00:47:20 2023: Train Epoch: 10 [  0  /68513 (0 %)]	Loss: 190.933365 | Elapsed: 0.21s
01/29/2023 12:47:33 AM  [*] Sun Jan 29 00:47:33 2023: Train Epoch: 10 [6400 /68513 (9 %)]	Loss: 152.505615 | Elapsed: 12.57s
01/29/2023 12:47:45 AM  [*] Sun Jan 29 00:47:45 2023: Train Epoch: 10 [12800/68513 (19%)]	Loss: 183.544037 | Elapsed: 12.42s
01/29/2023 12:47:57 AM  [*] Sun Jan 29 00:47:57 2023: Train Epoch: 10 [19200/68513 (28%)]	Loss: 173.681580 | Elapsed: 12.38s
01/29/2023 12:48:05 AM [!] Learning rate: 2.5e-06
01/29/2023 12:48:10 AM  [*] Sun Jan 29 00:48:10 2023: Train Epoch: 10 [25600/68513 (37%)]	Loss: 186.747269 | Elapsed: 12.44s
01/29/2023 12:48:22 AM  [*] Sun Jan 29 00:48:22 2023: Train Epoch: 10 [32000/68513 (47%)]	Loss: 168.148773 | Elapsed: 12.41s
01/29/2023 12:48:35 AM  [*] Sun Jan 29 00:48:35 2023: Train Epoch: 10 [38400/68513 (56%)]	Loss: 175.137817 | Elapsed: 12.40s
01/29/2023 12:48:47 AM  [*] Sun Jan 29 00:48:47 2023: Train Epoch: 10 [44800/68513 (65%)]	Loss: 169.303101 | Elapsed: 12.36s
01/29/2023 12:48:59 AM  [*] Sun Jan 29 00:48:59 2023: Train Epoch: 10 [51200/68513 (75%)]	Loss: 190.678299 | Elapsed: 12.39s
01/29/2023 12:49:12 AM  [*] Sun Jan 29 00:49:12 2023: Train Epoch: 10 [57600/68513 (84%)]	Loss: 211.118851 | Elapsed: 12.41s
01/29/2023 12:49:24 AM  [*] Sun Jan 29 00:49:24 2023: Train Epoch: 10 [64000/68513 (93%)]	Loss: 185.598328 | Elapsed: 12.44s
01/29/2023 12:49:35 AM  [*] Sun Jan 29 00:49:35 2023:   10    | Tr.loss: 177.168959 | Elapsed:  134.93  s
01/29/2023 12:49:35 AM [!] Sun Jan 29 00:49:35 2023: Dumped results:
                model     : 1674949775-model.torch
		train time: 1674949775-trainTime.npy
		train losses: 1674949775-trainLosses.npy
		train AUC: 1674949775-auc.npy
01/29/2023 12:49:37 AM  [!] Training pretrained model on downstream task...
01/29/2023 12:49:37 AM  [*] Started epoch: 1
01/29/2023 12:49:38 AM  [*] Sun Jan 29 00:49:38 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 3.819301 | Elapsed: 0.26s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.3860
01/29/2023 12:49:47 AM  [*] Sun Jan 29 00:49:47 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.523158 | Elapsed: 9.15s | FPR 0.0003 -> TPR 0.1452 & F1 0.2535 | AUC 0.7604
01/29/2023 12:49:49 AM  [*] Sun Jan 29 00:49:49 2023:    1    | Tr.loss: 0.670020 | Elapsed:   11.25  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7217
01/29/2023 12:49:49 AM  [*] Started epoch: 2
01/29/2023 12:49:49 AM  [*] Sun Jan 29 00:49:49 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.415943 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.2093 & F1 0.3462 | AUC 0.8654
01/29/2023 12:49:58 AM  [*] Sun Jan 29 00:49:58 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.428021 | Elapsed: 9.05s | FPR 0.0003 -> TPR 0.3485 & F1 0.5169 | AUC 0.8607
01/29/2023 12:50:00 AM  [*] Sun Jan 29 00:50:00 2023:    2    | Tr.loss: 0.434907 | Elapsed:   10.96  s | FPR 0.0003 -> TPR: 0.10 & F1: 0.18 | AUC: 0.8372
01/29/2023 12:50:00 AM  [*] Started epoch: 3
01/29/2023 12:50:00 AM  [*] Sun Jan 29 00:50:00 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.437018 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.3415 & F1 0.5091 | AUC 0.8362
01/29/2023 12:50:09 AM  [*] Sun Jan 29 00:50:09 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.276343 | Elapsed: 9.06s | FPR 0.0003 -> TPR 0.4789 & F1 0.6476 | AUC 0.9169
01/29/2023 12:50:11 AM  [*] Sun Jan 29 00:50:11 2023:    3    | Tr.loss: 0.370996 | Elapsed:   10.96  s | FPR 0.0003 -> TPR: 0.17 & F1: 0.30 | AUC: 0.8854
01/29/2023 12:50:11 AM [!] Sun Jan 29 00:50:11 2023: Dumped results:
                model     : 1674949811-model.torch
		train time: 1674949811-trainTime.npy
		train losses: 1674949811-trainLosses.npy
		train AUC: 1674949811-auc.npy
		train F1s : 1674949811-trainF1s.npy
		train TPRs: 1674949811-trainTPRs.npy
01/29/2023 12:50:11 AM  [!] Training non_pretrained model on downstream task...
01/29/2023 12:50:11 AM  [*] Started epoch: 1
01/29/2023 12:50:12 AM  [*] Sun Jan 29 00:50:12 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 1.660060 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0217 & F1 0.0426 | AUC 0.4952
01/29/2023 12:50:18 AM  [*] Sun Jan 29 00:50:18 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.462867 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.2241 & F1 0.3662 | AUC 0.8190
01/29/2023 12:50:19 AM  [*] Sun Jan 29 00:50:19 2023:    1    | Tr.loss: 0.573448 | Elapsed:   7.59   s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7577
01/29/2023 12:50:19 AM  [*] Started epoch: 2
01/29/2023 12:50:19 AM  [*] Sun Jan 29 00:50:19 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.334461 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.3409 & F1 0.5085 | AUC 0.8886
01/29/2023 12:50:25 AM  [*] Sun Jan 29 00:50:25 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.357148 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.5000 & F1 0.6667 | AUC 0.9138
01/29/2023 12:50:27 AM  [*] Sun Jan 29 00:50:27 2023:    2    | Tr.loss: 0.365703 | Elapsed:   7.55   s | FPR 0.0003 -> TPR: 0.01 & F1: 0.02 | AUC: 0.8952
01/29/2023 12:50:27 AM  [*] Started epoch: 3
01/29/2023 12:50:27 AM  [*] Sun Jan 29 00:50:27 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.285527 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.7674 & F1 0.8684 | AUC 0.9435
01/29/2023 12:50:33 AM  [*] Sun Jan 29 00:50:33 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.365293 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.2286 & F1 0.3721 | AUC 0.9138
01/29/2023 12:50:34 AM  [*] Sun Jan 29 00:50:34 2023:    3    | Tr.loss: 0.304080 | Elapsed:   7.54   s | FPR 0.0003 -> TPR: 0.03 & F1: 0.05 | AUC: 0.9307
01/29/2023 12:50:35 AM [!] Sun Jan 29 00:50:35 2023: Dumped results:
                model     : 1674949834-model.torch
		train time: 1674949834-trainTime.npy
		train losses: 1674949834-trainLosses.npy
		train AUC: 1674949834-auc.npy
		train F1s : 1674949834-trainF1s.npy
		train TPRs: 1674949834-trainTPRs.npy
01/29/2023 12:50:35 AM  [!] Training full_data model on downstream task...
01/29/2023 12:50:35 AM  [*] Started epoch: 1
01/29/2023 12:50:35 AM  [*] Sun Jan 29 00:50:35 2023: Train Epoch: 1 [  0  /76126 (0 %)]	Loss: 1.909763 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.4094
01/29/2023 12:50:41 AM  [*] Sun Jan 29 00:50:41 2023: Train Epoch: 1 [6400 /76126 (8 %)]	Loss: 0.634502 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.0714 & F1 0.1333 | AUC 0.6752
01/29/2023 12:50:47 AM  [*] Sun Jan 29 00:50:47 2023: Train Epoch: 1 [12800/76126 (17%)]	Loss: 0.413366 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.3429 & F1 0.5106 | AUC 0.8790
01/29/2023 12:50:54 AM  [*] Sun Jan 29 00:50:54 2023: Train Epoch: 1 [19200/76126 (25%)]	Loss: 0.353227 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.5781 & F1 0.7327 | AUC 0.9314
01/29/2023 12:51:00 AM  [*] Sun Jan 29 00:51:00 2023: Train Epoch: 1 [25600/76126 (34%)]	Loss: 0.355642 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.4068 & F1 0.5783 | AUC 0.9194
01/29/2023 12:51:06 AM  [*] Sun Jan 29 00:51:06 2023: Train Epoch: 1 [32000/76126 (42%)]	Loss: 0.230815 | Elapsed: 6.26s | FPR 0.0003 -> TPR 0.6753 & F1 0.8062 | AUC 0.9430
01/29/2023 12:51:12 AM  [*] Sun Jan 29 00:51:12 2023: Train Epoch: 1 [38400/76126 (50%)]	Loss: 0.212971 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.6800 & F1 0.8095 | AUC 0.9531
01/29/2023 12:51:19 AM  [*] Sun Jan 29 00:51:19 2023: Train Epoch: 1 [44800/76126 (59%)]	Loss: 0.287461 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.7692 & F1 0.8696 | AUC 0.9578
01/29/2023 12:51:25 AM  [*] Sun Jan 29 00:51:25 2023: Train Epoch: 1 [51200/76126 (67%)]	Loss: 0.080961 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.8750 & F1 0.9333 | AUC 0.9878
01/29/2023 12:51:31 AM  [*] Sun Jan 29 00:51:31 2023: Train Epoch: 1 [57600/76126 (76%)]	Loss: 0.185073 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.6029 & F1 0.7523 | AUC 0.9665
01/29/2023 12:51:37 AM [!] Learning rate: 2.5e-05
01/29/2023 12:51:37 AM  [*] Sun Jan 29 00:51:37 2023: Train Epoch: 1 [64000/76126 (84%)]	Loss: 0.199222 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.5538 & F1 0.7129 | AUC 0.9745
01/29/2023 12:51:43 AM  [*] Sun Jan 29 00:51:43 2023: Train Epoch: 1 [70400/76126 (92%)]	Loss: 0.214345 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.8571 & F1 0.9231 | AUC 0.9764
01/29/2023 12:51:51 AM  [*] Sun Jan 29 00:51:51 2023:    1    | Tr.loss: 0.289208 | Elapsed:   75.80  s | FPR 0.0003 -> TPR: 0.13 & F1: 0.23 | AUC: 0.9385
01/29/2023 12:51:51 AM  [*] Started epoch: 2
01/29/2023 12:51:51 AM  [*] Sun Jan 29 00:51:51 2023: Train Epoch: 2 [  0  /76126 (0 %)]	Loss: 0.131230 | Elapsed: 0.12s | FPR 0.0003 -> TPR 0.9545 & F1 0.9767 | AUC 0.9909
01/29/2023 12:51:57 AM  [*] Sun Jan 29 00:51:57 2023: Train Epoch: 2 [6400 /76126 (8 %)]	Loss: 0.190399 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.8696 & F1 0.9302 | AUC 0.9808
01/29/2023 12:52:03 AM  [*] Sun Jan 29 00:52:03 2023: Train Epoch: 2 [12800/76126 (17%)]	Loss: 0.134756 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.9559 & F1 0.9774 | AUC 0.9899
01/29/2023 12:52:10 AM  [*] Sun Jan 29 00:52:10 2023: Train Epoch: 2 [19200/76126 (25%)]	Loss: 0.168881 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.8358 & F1 0.9106 | AUC 0.9846
01/29/2023 12:52:16 AM  [*] Sun Jan 29 00:52:16 2023: Train Epoch: 2 [25600/76126 (34%)]	Loss: 0.217600 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.6364 & F1 0.7778 | AUC 0.9724
01/29/2023 12:52:22 AM  [*] Sun Jan 29 00:52:22 2023: Train Epoch: 2 [32000/76126 (42%)]	Loss: 0.091446 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.9231 & F1 0.9600 | AUC 0.9916
01/29/2023 12:52:28 AM  [*] Sun Jan 29 00:52:28 2023: Train Epoch: 2 [38400/76126 (50%)]	Loss: 0.173735 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.8451 & F1 0.9160 | AUC 0.9762
01/29/2023 12:52:34 AM  [*] Sun Jan 29 00:52:34 2023: Train Epoch: 2 [44800/76126 (59%)]	Loss: 0.190088 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.8657 & F1 0.9280 | AUC 0.9833
01/29/2023 12:52:41 AM  [*] Sun Jan 29 00:52:41 2023: Train Epoch: 2 [51200/76126 (67%)]	Loss: 0.158126 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.7432 & F1 0.8527 | AUC 0.9797
01/29/2023 12:52:41 AM [!] Learning rate: 2.5e-06
01/29/2023 12:52:47 AM  [*] Sun Jan 29 00:52:47 2023: Train Epoch: 2 [57600/76126 (76%)]	Loss: 0.187176 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.8919 & F1 0.9429 | AUC 0.9860
01/29/2023 12:52:53 AM  [*] Sun Jan 29 00:52:53 2023: Train Epoch: 2 [64000/76126 (84%)]	Loss: 0.099036 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.8462 & F1 0.9167 | AUC 0.9921
01/29/2023 12:52:59 AM  [*] Sun Jan 29 00:52:59 2023: Train Epoch: 2 [70400/76126 (92%)]	Loss: 0.171224 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.9079 & F1 0.9517 | AUC 0.9830
01/29/2023 12:53:07 AM  [*] Sun Jan 29 00:53:07 2023:    2    | Tr.loss: 0.158810 | Elapsed:   75.82  s | FPR 0.0003 -> TPR: 0.49 & F1: 0.66 | AUC: 0.9825
01/29/2023 12:53:07 AM  [*] Started epoch: 3
01/29/2023 12:53:07 AM  [*] Sun Jan 29 00:53:07 2023: Train Epoch: 3 [  0  /76126 (0 %)]	Loss: 0.142351 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.8750 & F1 0.9333 | AUC 0.9844
01/29/2023 12:53:13 AM  [*] Sun Jan 29 00:53:13 2023: Train Epoch: 3 [6400 /76126 (8 %)]	Loss: 0.164218 | Elapsed: 6.27s | FPR 0.0003 -> TPR 0.8732 & F1 0.9323 | AUC 0.9820
01/29/2023 12:53:19 AM  [*] Sun Jan 29 00:53:19 2023: Train Epoch: 3 [12800/76126 (17%)]	Loss: 0.311580 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.3944 & F1 0.5657 | AUC 0.9553
01/29/2023 12:53:25 AM  [*] Sun Jan 29 00:53:25 2023: Train Epoch: 3 [19200/76126 (25%)]	Loss: 0.138861 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.8806 & F1 0.9365 | AUC 0.9896
01/29/2023 12:53:32 AM  [*] Sun Jan 29 00:53:32 2023: Train Epoch: 3 [25600/76126 (34%)]	Loss: 0.168100 | Elapsed: 6.29s | FPR 0.0003 -> TPR 0.9394 & F1 0.9688 | AUC 0.9898
01/29/2023 12:53:38 AM  [*] Sun Jan 29 00:53:38 2023: Train Epoch: 3 [32000/76126 (42%)]	Loss: 0.149881 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.4928 & F1 0.6602 | AUC 0.9696
01/29/2023 12:53:44 AM  [*] Sun Jan 29 00:53:44 2023: Train Epoch: 3 [38400/76126 (50%)]	Loss: 0.060887 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.8923 & F1 0.9431 | AUC 0.9947
01/29/2023 12:53:45 AM [!] Learning rate: 2.5000000000000004e-07
01/29/2023 12:53:50 AM  [*] Sun Jan 29 00:53:50 2023: Train Epoch: 3 [44800/76126 (59%)]	Loss: 0.099124 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.9306 & F1 0.9640 | AUC 0.9896
01/29/2023 12:53:57 AM  [*] Sun Jan 29 00:53:57 2023: Train Epoch: 3 [51200/76126 (67%)]	Loss: 0.145515 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.8154 & F1 0.8983 | AUC 0.9771
01/29/2023 12:54:03 AM  [*] Sun Jan 29 00:54:03 2023: Train Epoch: 3 [57600/76126 (76%)]	Loss: 0.093662 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.7465 & F1 0.8548 | AUC 0.9849
01/29/2023 12:54:09 AM  [*] Sun Jan 29 00:54:09 2023: Train Epoch: 3 [64000/76126 (84%)]	Loss: 0.116348 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.9492 & F1 0.9739 | AUC 0.9946
01/29/2023 12:54:15 AM  [*] Sun Jan 29 00:54:15 2023: Train Epoch: 3 [70400/76126 (92%)]	Loss: 0.155677 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.8732 & F1 0.9323 | AUC 0.9845
01/29/2023 12:54:22 AM  [*] Sun Jan 29 00:54:22 2023:    3    | Tr.loss: 0.154017 | Elapsed:   75.74  s | FPR 0.0003 -> TPR: 0.55 & F1: 0.71 | AUC: 0.9836
01/29/2023 12:54:23 AM [!] Sun Jan 29 00:54:23 2023: Dumped results:
                model     : 1674950062-model.torch
		train time: 1674950062-trainTime.npy
		train losses: 1674950062-trainLosses.npy
		train AUC: 1674950062-auc.npy
		train F1s : 1674950062-trainF1s.npy
		train TPRs: 1674950062-trainTPRs.npy
01/29/2023 12:54:23 AM  [*] Evaluating pretrained model on test set...
01/29/2023 12:54:28 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.1044 | F1: 0.1891
01/29/2023 12:54:28 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1554 | F1: 0.2689
01/29/2023 12:54:28 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.2039 | F1: 0.3385
01/29/2023 12:54:28 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.2830 | F1: 0.4403
01/29/2023 12:54:28 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3870 | F1: 0.5546
01/29/2023 12:54:28 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4679 | F1: 0.6267
01/29/2023 12:54:28 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.6128 | F1: 0.7219
01/29/2023 12:54:28 AM  [*] Evaluating non_pretrained model on test set...
01/29/2023 12:54:33 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0224 | F1: 0.0439
01/29/2023 12:54:33 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1296 | F1: 0.2295
01/29/2023 12:54:33 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.2397 | F1: 0.3865
01/29/2023 12:54:33 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.2993 | F1: 0.4598
01/29/2023 12:54:33 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3431 | F1: 0.5077
01/29/2023 12:54:33 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4021 | F1: 0.5633
01/29/2023 12:54:33 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.5412 | F1: 0.6656
01/29/2023 12:54:33 AM  [*] Evaluating full_data model on test set...
01/29/2023 12:54:38 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0835 | F1: 0.1541
01/29/2023 12:54:38 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.2753 | F1: 0.4317
01/29/2023 12:54:38 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.3411 | F1: 0.5083
01/29/2023 12:54:38 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3910 | F1: 0.5612
01/29/2023 12:54:38 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.4485 | F1: 0.6156
01/29/2023 12:54:38 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.5725 | F1: 0.7165
01/29/2023 12:54:38 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.8368 | F1: 0.8708
01/29/2023 12:54:38 AM  [!] Finished pre-training evaluation over 3 splits! Saved metrics to:
	C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.9_1674945061/metrics_MaskedLanguageModel_nSplits_3_limit_None.json
01/29/2023 12:54:38 AM  [!] Starting Masked Language Model evaluation over 3 splits!
01/29/2023 12:54:38 AM  [!] Loaded data and vocab. X train size: (76126, 512), X test size: (17407, 512), vocab size: 50002
01/29/2023 12:54:38 AM  [!] Initiating Self-Supervised Learning Pretraining
     Language Modeling MaskedLanguageModel
     Model TransformerEncoderLM with config:
	{'vocabSize': 50002, 'maxLen': 512, 'dModel': 64, 'nHeads': 8, 'dHidden': 256, 'nLayers': 2, 'numClasses': 1, 'hiddenNeurons': [64], 'dropout': 0.3}

01/29/2023 12:54:38 AM  [!] Running pre-training split 1/3
01/29/2023 12:54:41 AM  [!] Pre-training model...
01/29/2023 12:54:41 AM  [*] Masking sequences...
01/29/2023 12:55:03 AM  [*] Started epoch: 1
01/29/2023 12:55:04 AM  [*] Sun Jan 29 00:55:04 2023: Train Epoch: 1 [  0  /72319 (0 %)]	Loss: 410.899231 | Elapsed: 0.40s
01/29/2023 12:55:16 AM  [*] Sun Jan 29 00:55:16 2023: Train Epoch: 1 [6400 /72319 (9 %)]	Loss: 231.098328 | Elapsed: 12.25s
01/29/2023 12:55:28 AM  [*] Sun Jan 29 00:55:28 2023: Train Epoch: 1 [12800/72319 (18%)]	Loss: 223.758896 | Elapsed: 12.19s
01/29/2023 12:55:40 AM  [*] Sun Jan 29 00:55:40 2023: Train Epoch: 1 [19200/72319 (27%)]	Loss: 208.352615 | Elapsed: 12.29s
01/29/2023 12:55:52 AM  [*] Sun Jan 29 00:55:52 2023: Train Epoch: 1 [25600/72319 (35%)]	Loss: 193.450546 | Elapsed: 12.18s
01/29/2023 12:56:05 AM  [*] Sun Jan 29 00:56:05 2023: Train Epoch: 1 [32000/72319 (44%)]	Loss: 171.801636 | Elapsed: 12.20s
01/29/2023 12:56:17 AM  [*] Sun Jan 29 00:56:17 2023: Train Epoch: 1 [38400/72319 (53%)]	Loss: 200.628845 | Elapsed: 12.17s
01/29/2023 12:56:29 AM  [*] Sun Jan 29 00:56:29 2023: Train Epoch: 1 [44800/72319 (62%)]	Loss: 179.932678 | Elapsed: 12.21s
01/29/2023 12:56:41 AM  [*] Sun Jan 29 00:56:41 2023: Train Epoch: 1 [51200/72319 (71%)]	Loss: 200.272125 | Elapsed: 12.21s
01/29/2023 12:56:53 AM  [*] Sun Jan 29 00:56:53 2023: Train Epoch: 1 [57600/72319 (80%)]	Loss: 207.619904 | Elapsed: 12.21s
01/29/2023 12:57:06 AM  [*] Sun Jan 29 00:57:06 2023: Train Epoch: 1 [64000/72319 (88%)]	Loss: 187.369263 | Elapsed: 12.75s
01/29/2023 12:57:24 AM  [*] Sun Jan 29 00:57:24 2023: Train Epoch: 1 [70400/72319 (97%)]	Loss: 180.897766 | Elapsed: 17.82s
01/29/2023 12:57:31 AM  [*] Sun Jan 29 00:57:31 2023:    1    | Tr.loss: 204.851059 | Elapsed:  147.79  s
01/29/2023 12:57:31 AM  [*] Started epoch: 2
01/29/2023 12:57:31 AM  [*] Sun Jan 29 00:57:31 2023: Train Epoch: 2 [  0  /72319 (0 %)]	Loss: 189.201477 | Elapsed: 0.20s
01/29/2023 12:57:44 AM  [*] Sun Jan 29 00:57:44 2023: Train Epoch: 2 [6400 /72319 (9 %)]	Loss: 193.387131 | Elapsed: 12.43s
01/29/2023 12:57:56 AM  [*] Sun Jan 29 00:57:56 2023: Train Epoch: 2 [12800/72319 (18%)]	Loss: 187.014496 | Elapsed: 12.30s
01/29/2023 12:58:08 AM  [*] Sun Jan 29 00:58:08 2023: Train Epoch: 2 [19200/72319 (27%)]	Loss: 177.533691 | Elapsed: 12.29s
01/29/2023 12:58:20 AM  [*] Sun Jan 29 00:58:20 2023: Train Epoch: 2 [25600/72319 (35%)]	Loss: 158.873444 | Elapsed: 12.28s
01/29/2023 12:58:33 AM  [*] Sun Jan 29 00:58:33 2023: Train Epoch: 2 [32000/72319 (44%)]	Loss: 184.316650 | Elapsed: 12.24s
01/29/2023 12:58:45 AM  [*] Sun Jan 29 00:58:45 2023: Train Epoch: 2 [38400/72319 (53%)]	Loss: 180.567657 | Elapsed: 12.23s
01/29/2023 12:58:57 AM  [*] Sun Jan 29 00:58:57 2023: Train Epoch: 2 [44800/72319 (62%)]	Loss: 170.472931 | Elapsed: 12.21s
01/29/2023 12:59:09 AM  [*] Sun Jan 29 00:59:09 2023: Train Epoch: 2 [51200/72319 (71%)]	Loss: 142.736099 | Elapsed: 12.34s
01/29/2023 12:59:22 AM  [*] Sun Jan 29 00:59:22 2023: Train Epoch: 2 [57600/72319 (80%)]	Loss: 165.338074 | Elapsed: 12.27s
01/29/2023 12:59:34 AM  [*] Sun Jan 29 00:59:34 2023: Train Epoch: 2 [64000/72319 (88%)]	Loss: 213.449005 | Elapsed: 12.26s
01/29/2023 12:59:46 AM  [*] Sun Jan 29 00:59:46 2023: Train Epoch: 2 [70400/72319 (97%)]	Loss: 155.235153 | Elapsed: 12.29s
01/29/2023 12:59:52 AM  [*] Sun Jan 29 00:59:52 2023:    2    | Tr.loss: 184.762004 | Elapsed:  140.94  s
01/29/2023 12:59:52 AM  [*] Started epoch: 3
01/29/2023 12:59:52 AM  [*] Sun Jan 29 00:59:52 2023: Train Epoch: 3 [  0  /72319 (0 %)]	Loss: 174.914612 | Elapsed: 0.23s
01/29/2023 01:00:04 AM  [*] Sun Jan 29 01:00:04 2023: Train Epoch: 3 [6400 /72319 (9 %)]	Loss: 177.111343 | Elapsed: 12.32s
01/29/2023 01:00:17 AM  [*] Sun Jan 29 01:00:17 2023: Train Epoch: 3 [12800/72319 (18%)]	Loss: 184.513000 | Elapsed: 12.32s
01/29/2023 01:00:29 AM  [*] Sun Jan 29 01:00:29 2023: Train Epoch: 3 [19200/72319 (27%)]	Loss: 195.678711 | Elapsed: 12.21s
01/29/2023 01:00:41 AM  [*] Sun Jan 29 01:00:41 2023: Train Epoch: 3 [25600/72319 (35%)]	Loss: 158.380920 | Elapsed: 12.21s
01/29/2023 01:00:53 AM  [*] Sun Jan 29 01:00:53 2023: Train Epoch: 3 [32000/72319 (44%)]	Loss: 196.349396 | Elapsed: 12.20s
01/29/2023 01:01:06 AM  [*] Sun Jan 29 01:01:06 2023: Train Epoch: 3 [38400/72319 (53%)]	Loss: 192.938370 | Elapsed: 12.18s
01/29/2023 01:01:18 AM  [*] Sun Jan 29 01:01:18 2023: Train Epoch: 3 [44800/72319 (62%)]	Loss: 178.729538 | Elapsed: 12.27s
01/29/2023 01:01:30 AM  [*] Sun Jan 29 01:01:30 2023: Train Epoch: 3 [51200/72319 (71%)]	Loss: 196.143799 | Elapsed: 12.32s
01/29/2023 01:01:42 AM  [*] Sun Jan 29 01:01:42 2023: Train Epoch: 3 [57600/72319 (80%)]	Loss: 185.864838 | Elapsed: 12.21s
01/29/2023 01:01:55 AM  [*] Sun Jan 29 01:01:55 2023: Train Epoch: 3 [64000/72319 (88%)]	Loss: 189.157318 | Elapsed: 12.21s
01/29/2023 01:02:07 AM  [*] Sun Jan 29 01:02:07 2023: Train Epoch: 3 [70400/72319 (97%)]	Loss: 164.739105 | Elapsed: 12.20s
01/29/2023 01:02:12 AM  [*] Sun Jan 29 01:02:12 2023:    3    | Tr.loss: 180.489713 | Elapsed:  140.37  s
01/29/2023 01:02:12 AM  [*] Started epoch: 4
01/29/2023 01:02:12 AM  [*] Sun Jan 29 01:02:12 2023: Train Epoch: 4 [  0  /72319 (0 %)]	Loss: 199.404037 | Elapsed: 0.21s
01/29/2023 01:02:25 AM  [*] Sun Jan 29 01:02:25 2023: Train Epoch: 4 [6400 /72319 (9 %)]	Loss: 161.827286 | Elapsed: 12.31s
01/29/2023 01:02:37 AM  [*] Sun Jan 29 01:02:37 2023: Train Epoch: 4 [12800/72319 (18%)]	Loss: 183.328476 | Elapsed: 12.34s
01/29/2023 01:02:49 AM  [*] Sun Jan 29 01:02:49 2023: Train Epoch: 4 [19200/72319 (27%)]	Loss: 184.035889 | Elapsed: 12.21s
01/29/2023 01:03:02 AM  [*] Sun Jan 29 01:03:02 2023: Train Epoch: 4 [25600/72319 (35%)]	Loss: 172.112000 | Elapsed: 12.20s
01/29/2023 01:03:14 AM  [*] Sun Jan 29 01:03:14 2023: Train Epoch: 4 [32000/72319 (44%)]	Loss: 166.508362 | Elapsed: 12.22s
01/29/2023 01:03:26 AM  [*] Sun Jan 29 01:03:26 2023: Train Epoch: 4 [38400/72319 (53%)]	Loss: 174.958145 | Elapsed: 12.20s
01/29/2023 01:03:38 AM  [*] Sun Jan 29 01:03:38 2023: Train Epoch: 4 [44800/72319 (62%)]	Loss: 188.518280 | Elapsed: 12.22s
01/29/2023 01:03:50 AM  [*] Sun Jan 29 01:03:50 2023: Train Epoch: 4 [51200/72319 (71%)]	Loss: 178.488632 | Elapsed: 12.20s
01/29/2023 01:04:03 AM  [*] Sun Jan 29 01:04:03 2023: Train Epoch: 4 [57600/72319 (80%)]	Loss: 166.580933 | Elapsed: 12.20s
01/29/2023 01:04:15 AM  [*] Sun Jan 29 01:04:15 2023: Train Epoch: 4 [64000/72319 (88%)]	Loss: 193.880493 | Elapsed: 12.23s
01/29/2023 01:04:27 AM  [*] Sun Jan 29 01:04:27 2023: Train Epoch: 4 [70400/72319 (97%)]	Loss: 169.880554 | Elapsed: 12.20s
01/29/2023 01:04:32 AM  [*] Sun Jan 29 01:04:32 2023:    4    | Tr.loss: 178.121531 | Elapsed:  140.20  s
01/29/2023 01:04:32 AM  [*] Started epoch: 5
01/29/2023 01:04:33 AM  [*] Sun Jan 29 01:04:33 2023: Train Epoch: 5 [  0  /72319 (0 %)]	Loss: 166.696686 | Elapsed: 0.21s
01/29/2023 01:04:45 AM  [*] Sun Jan 29 01:04:45 2023: Train Epoch: 5 [6400 /72319 (9 %)]	Loss: 175.508972 | Elapsed: 12.30s
01/29/2023 01:04:57 AM  [*] Sun Jan 29 01:04:57 2023: Train Epoch: 5 [12800/72319 (18%)]	Loss: 173.571991 | Elapsed: 12.25s
01/29/2023 01:05:09 AM  [*] Sun Jan 29 01:05:09 2023: Train Epoch: 5 [19200/72319 (27%)]	Loss: 179.770874 | Elapsed: 12.20s
01/29/2023 01:05:22 AM  [*] Sun Jan 29 01:05:22 2023: Train Epoch: 5 [25600/72319 (35%)]	Loss: 183.847107 | Elapsed: 12.20s
01/29/2023 01:05:31 AM [!] Learning rate: 2.5e-05
01/29/2023 01:05:34 AM  [*] Sun Jan 29 01:05:34 2023: Train Epoch: 5 [32000/72319 (44%)]	Loss: 174.270004 | Elapsed: 12.24s
01/29/2023 01:05:46 AM  [*] Sun Jan 29 01:05:46 2023: Train Epoch: 5 [38400/72319 (53%)]	Loss: 174.627777 | Elapsed: 12.23s
01/29/2023 01:05:58 AM  [*] Sun Jan 29 01:05:58 2023: Train Epoch: 5 [44800/72319 (62%)]	Loss: 169.080933 | Elapsed: 12.18s
01/29/2023 01:06:10 AM  [*] Sun Jan 29 01:06:10 2023: Train Epoch: 5 [51200/72319 (71%)]	Loss: 180.997406 | Elapsed: 12.18s
01/29/2023 01:06:23 AM  [*] Sun Jan 29 01:06:23 2023: Train Epoch: 5 [57600/72319 (80%)]	Loss: 170.111542 | Elapsed: 12.20s
01/29/2023 01:06:35 AM  [*] Sun Jan 29 01:06:35 2023: Train Epoch: 5 [64000/72319 (88%)]	Loss: 191.528351 | Elapsed: 12.20s
01/29/2023 01:06:47 AM  [*] Sun Jan 29 01:06:47 2023: Train Epoch: 5 [70400/72319 (97%)]	Loss: 175.340118 | Elapsed: 12.29s
01/29/2023 01:06:53 AM  [*] Sun Jan 29 01:06:53 2023:    5    | Tr.loss: 176.481205 | Elapsed:  140.16  s
01/29/2023 01:06:53 AM  [*] Started epoch: 6
01/29/2023 01:06:53 AM  [*] Sun Jan 29 01:06:53 2023: Train Epoch: 6 [  0  /72319 (0 %)]	Loss: 175.080765 | Elapsed: 0.23s
01/29/2023 01:07:05 AM  [*] Sun Jan 29 01:07:05 2023: Train Epoch: 6 [6400 /72319 (9 %)]	Loss: 187.017166 | Elapsed: 12.30s
01/29/2023 01:07:17 AM  [*] Sun Jan 29 01:07:17 2023: Train Epoch: 6 [12800/72319 (18%)]	Loss: 173.993469 | Elapsed: 12.26s
01/29/2023 01:07:30 AM  [*] Sun Jan 29 01:07:30 2023: Train Epoch: 6 [19200/72319 (27%)]	Loss: 179.667480 | Elapsed: 12.23s
01/29/2023 01:07:42 AM  [*] Sun Jan 29 01:07:42 2023: Train Epoch: 6 [25600/72319 (35%)]	Loss: 170.610214 | Elapsed: 12.21s
01/29/2023 01:07:54 AM  [*] Sun Jan 29 01:07:54 2023: Train Epoch: 6 [32000/72319 (44%)]	Loss: 170.444244 | Elapsed: 12.27s
01/29/2023 01:08:06 AM  [*] Sun Jan 29 01:08:06 2023: Train Epoch: 6 [38400/72319 (53%)]	Loss: 154.377426 | Elapsed: 12.18s
01/29/2023 01:08:19 AM  [*] Sun Jan 29 01:08:19 2023: Train Epoch: 6 [44800/72319 (62%)]	Loss: 166.159088 | Elapsed: 12.20s
01/29/2023 01:08:31 AM  [*] Sun Jan 29 01:08:31 2023: Train Epoch: 6 [51200/72319 (71%)]	Loss: 173.183929 | Elapsed: 12.19s
01/29/2023 01:08:43 AM  [*] Sun Jan 29 01:08:43 2023: Train Epoch: 6 [57600/72319 (80%)]	Loss: 184.111755 | Elapsed: 12.24s
01/29/2023 01:08:55 AM  [*] Sun Jan 29 01:08:55 2023: Train Epoch: 6 [64000/72319 (88%)]	Loss: 187.669586 | Elapsed: 12.17s
01/29/2023 01:09:08 AM  [*] Sun Jan 29 01:09:08 2023: Train Epoch: 6 [70400/72319 (97%)]	Loss: 172.338852 | Elapsed: 12.38s
01/29/2023 01:09:13 AM  [*] Sun Jan 29 01:09:13 2023:    6    | Tr.loss: 175.726539 | Elapsed:  140.62  s
01/29/2023 01:09:13 AM  [*] Started epoch: 7
01/29/2023 01:09:13 AM  [*] Sun Jan 29 01:09:13 2023: Train Epoch: 7 [  0  /72319 (0 %)]	Loss: 205.655365 | Elapsed: 0.22s
01/29/2023 01:09:26 AM  [*] Sun Jan 29 01:09:26 2023: Train Epoch: 7 [6400 /72319 (9 %)]	Loss: 181.210815 | Elapsed: 12.60s
01/29/2023 01:09:39 AM  [*] Sun Jan 29 01:09:39 2023: Train Epoch: 7 [12800/72319 (18%)]	Loss: 173.586578 | Elapsed: 12.58s
01/29/2023 01:09:51 AM  [*] Sun Jan 29 01:09:51 2023: Train Epoch: 7 [19200/72319 (27%)]	Loss: 166.378174 | Elapsed: 12.64s
01/29/2023 01:10:04 AM  [*] Sun Jan 29 01:10:04 2023: Train Epoch: 7 [25600/72319 (35%)]	Loss: 177.693466 | Elapsed: 12.31s
01/29/2023 01:10:16 AM  [*] Sun Jan 29 01:10:16 2023: Train Epoch: 7 [32000/72319 (44%)]	Loss: 176.522186 | Elapsed: 12.67s
01/29/2023 01:10:29 AM  [*] Sun Jan 29 01:10:29 2023: Train Epoch: 7 [38400/72319 (53%)]	Loss: 166.404205 | Elapsed: 12.50s
01/29/2023 01:10:41 AM  [*] Sun Jan 29 01:10:41 2023: Train Epoch: 7 [44800/72319 (62%)]	Loss: 187.440506 | Elapsed: 12.62s
01/29/2023 01:10:54 AM  [*] Sun Jan 29 01:10:54 2023: Train Epoch: 7 [51200/72319 (71%)]	Loss: 172.126572 | Elapsed: 12.42s
01/29/2023 01:11:06 AM  [*] Sun Jan 29 01:11:06 2023: Train Epoch: 7 [57600/72319 (80%)]	Loss: 165.754120 | Elapsed: 12.38s
01/29/2023 01:11:19 AM  [*] Sun Jan 29 01:11:19 2023: Train Epoch: 7 [64000/72319 (88%)]	Loss: 158.630432 | Elapsed: 12.47s
01/29/2023 01:11:31 AM  [*] Sun Jan 29 01:11:31 2023: Train Epoch: 7 [70400/72319 (97%)]	Loss: 164.935303 | Elapsed: 12.69s
01/29/2023 01:11:37 AM  [*] Sun Jan 29 01:11:37 2023:    7    | Tr.loss: 175.392919 | Elapsed:  143.98  s
01/29/2023 01:11:37 AM  [*] Started epoch: 8
01/29/2023 01:11:37 AM  [*] Sun Jan 29 01:11:37 2023: Train Epoch: 8 [  0  /72319 (0 %)]	Loss: 177.113708 | Elapsed: 0.23s
01/29/2023 01:11:50 AM  [*] Sun Jan 29 01:11:50 2023: Train Epoch: 8 [6400 /72319 (9 %)]	Loss: 163.740448 | Elapsed: 12.53s
01/29/2023 01:12:03 AM  [*] Sun Jan 29 01:12:03 2023: Train Epoch: 8 [12800/72319 (18%)]	Loss: 173.632034 | Elapsed: 12.59s
01/29/2023 01:12:15 AM  [*] Sun Jan 29 01:12:15 2023: Train Epoch: 8 [19200/72319 (27%)]	Loss: 176.954041 | Elapsed: 12.64s
01/29/2023 01:12:28 AM  [*] Sun Jan 29 01:12:28 2023: Train Epoch: 8 [25600/72319 (35%)]	Loss: 189.322250 | Elapsed: 12.56s
01/29/2023 01:12:40 AM  [*] Sun Jan 29 01:12:40 2023: Train Epoch: 8 [32000/72319 (44%)]	Loss: 193.730469 | Elapsed: 12.45s
01/29/2023 01:12:52 AM  [*] Sun Jan 29 01:12:52 2023: Train Epoch: 8 [38400/72319 (53%)]	Loss: 180.015564 | Elapsed: 12.22s
01/29/2023 01:13:05 AM  [*] Sun Jan 29 01:13:05 2023: Train Epoch: 8 [44800/72319 (62%)]	Loss: 157.147095 | Elapsed: 12.19s
01/29/2023 01:13:17 AM  [*] Sun Jan 29 01:13:17 2023: Train Epoch: 8 [51200/72319 (71%)]	Loss: 165.489914 | Elapsed: 12.20s
01/29/2023 01:13:29 AM  [*] Sun Jan 29 01:13:29 2023: Train Epoch: 8 [57600/72319 (80%)]	Loss: 163.616470 | Elapsed: 12.18s
01/29/2023 01:13:41 AM  [*] Sun Jan 29 01:13:41 2023: Train Epoch: 8 [64000/72319 (88%)]	Loss: 186.282715 | Elapsed: 12.21s
01/29/2023 01:13:53 AM  [*] Sun Jan 29 01:13:53 2023: Train Epoch: 8 [70400/72319 (97%)]	Loss: 188.646332 | Elapsed: 12.20s
01/29/2023 01:13:59 AM  [*] Sun Jan 29 01:13:59 2023:    8    | Tr.loss: 175.205637 | Elapsed:  141.77  s
01/29/2023 01:13:59 AM  [*] Started epoch: 9
01/29/2023 01:13:59 AM  [*] Sun Jan 29 01:13:59 2023: Train Epoch: 9 [  0  /72319 (0 %)]	Loss: 198.152222 | Elapsed: 0.21s
01/29/2023 01:14:12 AM  [*] Sun Jan 29 01:14:12 2023: Train Epoch: 9 [6400 /72319 (9 %)]	Loss: 171.994507 | Elapsed: 12.32s
01/29/2023 01:14:24 AM  [*] Sun Jan 29 01:14:24 2023: Train Epoch: 9 [12800/72319 (18%)]	Loss: 174.258545 | Elapsed: 12.20s
01/29/2023 01:14:36 AM  [*] Sun Jan 29 01:14:36 2023: Train Epoch: 9 [19200/72319 (27%)]	Loss: 183.582336 | Elapsed: 12.20s
01/29/2023 01:14:48 AM  [*] Sun Jan 29 01:14:48 2023: Train Epoch: 9 [25600/72319 (35%)]	Loss: 176.897980 | Elapsed: 12.31s
01/29/2023 01:15:00 AM  [*] Sun Jan 29 01:15:00 2023: Train Epoch: 9 [32000/72319 (44%)]	Loss: 190.785980 | Elapsed: 12.17s
01/29/2023 01:15:13 AM  [*] Sun Jan 29 01:15:13 2023: Train Epoch: 9 [38400/72319 (53%)]	Loss: 170.853012 | Elapsed: 12.21s
01/29/2023 01:15:25 AM  [*] Sun Jan 29 01:15:25 2023: Train Epoch: 9 [44800/72319 (62%)]	Loss: 167.147949 | Elapsed: 12.18s
01/29/2023 01:15:37 AM  [*] Sun Jan 29 01:15:37 2023: Train Epoch: 9 [51200/72319 (71%)]	Loss: 166.228226 | Elapsed: 12.17s
01/29/2023 01:15:49 AM  [*] Sun Jan 29 01:15:49 2023: Train Epoch: 9 [57600/72319 (80%)]	Loss: 169.623962 | Elapsed: 12.24s
01/29/2023 01:15:56 AM [!] Learning rate: 2.5e-06
01/29/2023 01:16:01 AM  [*] Sun Jan 29 01:16:01 2023: Train Epoch: 9 [64000/72319 (88%)]	Loss: 171.565140 | Elapsed: 12.21s
01/29/2023 01:16:14 AM  [*] Sun Jan 29 01:16:14 2023: Train Epoch: 9 [70400/72319 (97%)]	Loss: 199.311340 | Elapsed: 12.19s
01/29/2023 01:16:19 AM  [*] Sun Jan 29 01:16:19 2023:    9    | Tr.loss: 175.042085 | Elapsed:  140.15  s
01/29/2023 01:16:19 AM  [*] Started epoch: 10
01/29/2023 01:16:19 AM  [*] Sun Jan 29 01:16:19 2023: Train Epoch: 10 [  0  /72319 (0 %)]	Loss: 173.699341 | Elapsed: 0.22s
01/29/2023 01:16:32 AM  [*] Sun Jan 29 01:16:32 2023: Train Epoch: 10 [6400 /72319 (9 %)]	Loss: 195.772629 | Elapsed: 12.28s
01/29/2023 01:16:44 AM  [*] Sun Jan 29 01:16:44 2023: Train Epoch: 10 [12800/72319 (18%)]	Loss: 184.561340 | Elapsed: 12.20s
01/29/2023 01:16:56 AM  [*] Sun Jan 29 01:16:56 2023: Train Epoch: 10 [19200/72319 (27%)]	Loss: 175.916626 | Elapsed: 12.20s
01/29/2023 01:17:08 AM  [*] Sun Jan 29 01:17:08 2023: Train Epoch: 10 [25600/72319 (35%)]	Loss: 185.111786 | Elapsed: 12.19s
01/29/2023 01:17:21 AM  [*] Sun Jan 29 01:17:21 2023: Train Epoch: 10 [32000/72319 (44%)]	Loss: 204.885956 | Elapsed: 12.28s
01/29/2023 01:17:33 AM  [*] Sun Jan 29 01:17:33 2023: Train Epoch: 10 [38400/72319 (53%)]	Loss: 187.795273 | Elapsed: 12.19s
01/29/2023 01:17:45 AM  [*] Sun Jan 29 01:17:45 2023: Train Epoch: 10 [44800/72319 (62%)]	Loss: 173.241302 | Elapsed: 12.22s
01/29/2023 01:17:57 AM  [*] Sun Jan 29 01:17:57 2023: Train Epoch: 10 [51200/72319 (71%)]	Loss: 173.351501 | Elapsed: 12.24s
01/29/2023 01:18:09 AM  [*] Sun Jan 29 01:18:09 2023: Train Epoch: 10 [57600/72319 (80%)]	Loss: 173.182648 | Elapsed: 12.21s
01/29/2023 01:18:22 AM  [*] Sun Jan 29 01:18:22 2023: Train Epoch: 10 [64000/72319 (88%)]	Loss: 174.585785 | Elapsed: 12.21s
01/29/2023 01:18:34 AM  [*] Sun Jan 29 01:18:34 2023: Train Epoch: 10 [70400/72319 (97%)]	Loss: 175.328217 | Elapsed: 12.24s
01/29/2023 01:18:39 AM  [*] Sun Jan 29 01:18:39 2023:   10    | Tr.loss: 174.876944 | Elapsed:  140.13  s
01/29/2023 01:18:40 AM [!] Sun Jan 29 01:18:40 2023: Dumped results:
                model     : 1674951519-model.torch
		train time: 1674951519-trainTime.npy
		train losses: 1674951519-trainLosses.npy
		train AUC: 1674951519-auc.npy
01/29/2023 01:18:42 AM  [!] Training pretrained model on downstream task...
01/29/2023 01:18:42 AM  [*] Started epoch: 1
01/29/2023 01:18:42 AM  [*] Sun Jan 29 01:18:42 2023: Train Epoch: 1 [  0  /3807  (0 %)]	Loss: 2.377938 | Elapsed: 0.31s | FPR 0.0003 -> TPR 0.0769 & F1 0.1429 | AUC 0.6154
01/29/2023 01:18:48 AM  [*] Sun Jan 29 01:18:48 2023:    1    | Tr.loss: 0.767733 | Elapsed:   5.75   s | FPR 0.0003 -> TPR: 0.00 & F1: 0.01 | AUC: 0.7246
01/29/2023 01:18:48 AM  [*] Started epoch: 2
01/29/2023 01:18:48 AM  [*] Sun Jan 29 01:18:48 2023: Train Epoch: 2 [  0  /3807  (0 %)]	Loss: 0.518175 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.3333 & F1 0.5000 | AUC 0.8031
01/29/2023 01:18:53 AM  [*] Sun Jan 29 01:18:53 2023:    2    | Tr.loss: 0.438794 | Elapsed:   5.49   s | FPR 0.0003 -> TPR: 0.05 & F1: 0.10 | AUC: 0.8307
01/29/2023 01:18:53 AM  [*] Started epoch: 3
01/29/2023 01:18:54 AM  [*] Sun Jan 29 01:18:54 2023: Train Epoch: 3 [  0  /3807  (0 %)]	Loss: 0.411544 | Elapsed: 0.11s | FPR 0.0003 -> TPR 0.2917 & F1 0.4516 | AUC 0.8060
01/29/2023 01:18:59 AM  [*] Sun Jan 29 01:18:59 2023:    3    | Tr.loss: 0.398087 | Elapsed:   5.49   s | FPR 0.0003 -> TPR: 0.10 & F1: 0.17 | AUC: 0.8681
01/29/2023 01:18:59 AM [!] Sun Jan 29 01:18:59 2023: Dumped results:
                model     : 1674951539-model.torch
		train time: 1674951539-trainTime.npy
		train losses: 1674951539-trainLosses.npy
		train AUC: 1674951539-auc.npy
		train F1s : 1674951539-trainF1s.npy
		train TPRs: 1674951539-trainTPRs.npy
01/29/2023 01:18:59 AM  [!] Training non_pretrained model on downstream task...
01/29/2023 01:19:00 AM  [*] Started epoch: 1
01/29/2023 01:19:00 AM  [*] Sun Jan 29 01:19:00 2023: Train Epoch: 1 [  0  /3807  (0 %)]	Loss: 1.182025 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.1250 & F1 0.2222 | AUC 0.6583
01/29/2023 01:19:03 AM  [*] Sun Jan 29 01:19:03 2023:    1    | Tr.loss: 0.738189 | Elapsed:   3.77   s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.6774
01/29/2023 01:19:03 AM  [*] Started epoch: 2
01/29/2023 01:19:04 AM  [*] Sun Jan 29 01:19:04 2023: Train Epoch: 2 [  0  /3807  (0 %)]	Loss: 0.428572 | Elapsed: 0.05s | FPR 0.0003 -> TPR 0.2340 & F1 0.3793 | AUC 0.8173
01/29/2023 01:19:07 AM  [*] Sun Jan 29 01:19:07 2023:    2    | Tr.loss: 0.439482 | Elapsed:   3.74   s | FPR 0.0003 -> TPR: 0.07 & F1: 0.13 | AUC: 0.8371
01/29/2023 01:19:07 AM  [*] Started epoch: 3
01/29/2023 01:19:07 AM  [*] Sun Jan 29 01:19:07 2023: Train Epoch: 3 [  0  /3807  (0 %)]	Loss: 0.649084 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.3824 & F1 0.5532 | AUC 0.8559
01/29/2023 01:19:11 AM  [*] Sun Jan 29 01:19:11 2023:    3    | Tr.loss: 0.378700 | Elapsed:   3.81   s | FPR 0.0003 -> TPR: 0.18 & F1: 0.30 | AUC: 0.8817
01/29/2023 01:19:11 AM [!] Sun Jan 29 01:19:11 2023: Dumped results:
                model     : 1674951551-model.torch
		train time: 1674951551-trainTime.npy
		train losses: 1674951551-trainLosses.npy
		train AUC: 1674951551-auc.npy
		train F1s : 1674951551-trainF1s.npy
		train TPRs: 1674951551-trainTPRs.npy
01/29/2023 01:19:11 AM  [!] Training full_data model on downstream task...
01/29/2023 01:19:12 AM  [*] Started epoch: 1
01/29/2023 01:19:12 AM  [*] Sun Jan 29 01:19:12 2023: Train Epoch: 1 [  0  /76126 (0 %)]	Loss: 3.729117 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.2729
01/29/2023 01:19:18 AM  [*] Sun Jan 29 01:19:18 2023: Train Epoch: 1 [6400 /76126 (8 %)]	Loss: 0.530891 | Elapsed: 6.15s | FPR 0.0003 -> TPR 0.1724 & F1 0.2941 | AUC 0.8888
01/29/2023 01:19:24 AM  [*] Sun Jan 29 01:19:24 2023: Train Epoch: 1 [12800/76126 (17%)]	Loss: 0.412222 | Elapsed: 6.14s | FPR 0.0003 -> TPR 0.2500 & F1 0.4000 | AUC 0.8507
01/29/2023 01:19:30 AM  [*] Sun Jan 29 01:19:30 2023: Train Epoch: 1 [19200/76126 (25%)]	Loss: 0.345540 | Elapsed: 6.14s | FPR 0.0003 -> TPR 0.2424 & F1 0.3902 | AUC 0.9180
01/29/2023 01:19:37 AM  [*] Sun Jan 29 01:19:37 2023: Train Epoch: 1 [25600/76126 (34%)]	Loss: 0.322323 | Elapsed: 6.14s | FPR 0.0003 -> TPR 0.5161 & F1 0.6809 | AUC 0.9376
01/29/2023 01:19:43 AM  [*] Sun Jan 29 01:19:43 2023: Train Epoch: 1 [32000/76126 (42%)]	Loss: 0.153325 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.6714 & F1 0.8034 | AUC 0.9624
01/29/2023 01:19:49 AM  [*] Sun Jan 29 01:19:49 2023: Train Epoch: 1 [38400/76126 (50%)]	Loss: 0.226762 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.8308 & F1 0.9076 | AUC 0.9727
01/29/2023 01:19:55 AM  [*] Sun Jan 29 01:19:55 2023: Train Epoch: 1 [44800/76126 (59%)]	Loss: 0.234883 | Elapsed: 6.16s | FPR 0.0003 -> TPR 0.8194 & F1 0.9008 | AUC 0.9762
01/29/2023 01:20:01 AM  [*] Sun Jan 29 01:20:01 2023: Train Epoch: 1 [51200/76126 (67%)]	Loss: 0.260997 | Elapsed: 6.16s | FPR 0.0003 -> TPR 0.4833 & F1 0.6517 | AUC 0.9446
01/29/2023 01:20:07 AM  [*] Sun Jan 29 01:20:07 2023: Train Epoch: 1 [57600/76126 (76%)]	Loss: 0.152148 | Elapsed: 6.15s | FPR 0.0003 -> TPR 0.9118 & F1 0.9538 | AUC 0.9844
01/29/2023 01:20:14 AM [!] Learning rate: 2.5e-05
01/29/2023 01:20:14 AM  [*] Sun Jan 29 01:20:14 2023: Train Epoch: 1 [64000/76126 (84%)]	Loss: 0.138899 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.8906 & F1 0.9421 | AUC 0.9913
01/29/2023 01:20:20 AM  [*] Sun Jan 29 01:20:20 2023: Train Epoch: 1 [70400/76126 (92%)]	Loss: 0.148337 | Elapsed: 6.16s | FPR 0.0003 -> TPR 0.8116 & F1 0.8960 | AUC 0.9813
01/29/2023 01:20:27 AM  [*] Sun Jan 29 01:20:27 2023:    1    | Tr.loss: 0.296979 | Elapsed:   75.10  s | FPR 0.0003 -> TPR: 0.01 & F1: 0.03 | AUC: 0.9355
01/29/2023 01:20:27 AM  [*] Started epoch: 2
01/29/2023 01:20:27 AM  [*] Sun Jan 29 01:20:27 2023: Train Epoch: 2 [  0  /76126 (0 %)]	Loss: 0.152774 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.8605 & F1 0.9250 | AUC 0.9856
01/29/2023 01:20:33 AM  [*] Sun Jan 29 01:20:33 2023: Train Epoch: 2 [6400 /76126 (8 %)]	Loss: 0.249721 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.3860 & F1 0.5570 | AUC 0.9714
01/29/2023 01:20:40 AM  [*] Sun Jan 29 01:20:40 2023: Train Epoch: 2 [12800/76126 (17%)]	Loss: 0.177581 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.7656 & F1 0.8673 | AUC 0.9887
01/29/2023 01:20:46 AM  [*] Sun Jan 29 01:20:46 2023: Train Epoch: 2 [19200/76126 (25%)]	Loss: 0.107415 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.9545 & F1 0.9767 | AUC 0.9982
01/29/2023 01:20:52 AM  [*] Sun Jan 29 01:20:52 2023: Train Epoch: 2 [25600/76126 (34%)]	Loss: 0.073527 | Elapsed: 6.15s | FPR 0.0003 -> TPR 0.7576 & F1 0.8621 | AUC 0.9866
01/29/2023 01:20:58 AM  [*] Sun Jan 29 01:20:58 2023: Train Epoch: 2 [32000/76126 (42%)]	Loss: 0.185807 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.8923 & F1 0.9431 | AUC 0.9833
01/29/2023 01:21:04 AM  [*] Sun Jan 29 01:21:04 2023: Train Epoch: 2 [38400/76126 (50%)]	Loss: 0.197816 | Elapsed: 6.15s | FPR 0.0003 -> TPR 0.7460 & F1 0.8545 | AUC 0.9708
01/29/2023 01:21:10 AM  [*] Sun Jan 29 01:21:10 2023: Train Epoch: 2 [44800/76126 (59%)]	Loss: 0.166726 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.9231 & F1 0.9600 | AUC 0.9820
01/29/2023 01:21:17 AM  [*] Sun Jan 29 01:21:17 2023: Train Epoch: 2 [51200/76126 (67%)]	Loss: 0.094238 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.9571 & F1 0.9781 | AUC 0.9971
01/29/2023 01:21:17 AM [!] Learning rate: 2.5e-06
01/29/2023 01:21:23 AM  [*] Sun Jan 29 01:21:23 2023: Train Epoch: 2 [57600/76126 (76%)]	Loss: 0.152957 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.8769 & F1 0.9344 | AUC 0.9820
01/29/2023 01:21:29 AM  [*] Sun Jan 29 01:21:29 2023: Train Epoch: 2 [64000/76126 (84%)]	Loss: 0.079026 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.9857 & F1 0.9928 | AUC 0.9995
01/29/2023 01:21:35 AM  [*] Sun Jan 29 01:21:35 2023: Train Epoch: 2 [70400/76126 (92%)]	Loss: 0.191068 | Elapsed: 6.16s | FPR 0.0003 -> TPR 0.7639 & F1 0.8661 | AUC 0.9737
01/29/2023 01:21:42 AM  [*] Sun Jan 29 01:21:42 2023:    2    | Tr.loss: 0.160504 | Elapsed:   75.33  s | FPR 0.0003 -> TPR: 0.47 & F1: 0.64 | AUC: 0.9823
01/29/2023 01:21:42 AM  [*] Started epoch: 3
01/29/2023 01:21:42 AM  [*] Sun Jan 29 01:21:42 2023: Train Epoch: 3 [  0  /76126 (0 %)]	Loss: 0.196629 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.9167 & F1 0.9565 | AUC 0.9818
01/29/2023 01:21:49 AM  [*] Sun Jan 29 01:21:49 2023: Train Epoch: 3 [6400 /76126 (8 %)]	Loss: 0.136174 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.7941 & F1 0.8852 | AUC 0.9858
01/29/2023 01:21:55 AM  [*] Sun Jan 29 01:21:55 2023: Train Epoch: 3 [12800/76126 (17%)]	Loss: 0.091023 | Elapsed: 6.15s | FPR 0.0003 -> TPR 0.8525 & F1 0.9204 | AUC 0.9920
01/29/2023 01:22:01 AM  [*] Sun Jan 29 01:22:01 2023: Train Epoch: 3 [19200/76126 (25%)]	Loss: 0.095963 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.9296 & F1 0.9635 | AUC 0.9932
01/29/2023 01:22:07 AM  [*] Sun Jan 29 01:22:07 2023: Train Epoch: 3 [25600/76126 (34%)]	Loss: 0.201426 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.6567 & F1 0.7928 | AUC 0.9706
01/29/2023 01:22:13 AM  [*] Sun Jan 29 01:22:13 2023: Train Epoch: 3 [32000/76126 (42%)]	Loss: 0.118304 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.8358 & F1 0.9106 | AUC 0.9873
01/29/2023 01:22:20 AM  [*] Sun Jan 29 01:22:20 2023: Train Epoch: 3 [38400/76126 (50%)]	Loss: 0.171650 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.8871 & F1 0.9402 | AUC 0.9834
01/29/2023 01:22:21 AM [!] Learning rate: 2.5000000000000004e-07
01/29/2023 01:22:26 AM  [*] Sun Jan 29 01:22:26 2023: Train Epoch: 3 [44800/76126 (59%)]	Loss: 0.130007 | Elapsed: 6.16s | FPR 0.0003 -> TPR 0.9483 & F1 0.9735 | AUC 0.9910
01/29/2023 01:22:32 AM  [*] Sun Jan 29 01:22:32 2023: Train Epoch: 3 [51200/76126 (67%)]	Loss: 0.268579 | Elapsed: 6.15s | FPR 0.0003 -> TPR 0.5270 & F1 0.6903 | AUC 0.9465
01/29/2023 01:22:38 AM  [*] Sun Jan 29 01:22:38 2023: Train Epoch: 3 [57600/76126 (76%)]	Loss: 0.256727 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.8000 & F1 0.8889 | AUC 0.9757
01/29/2023 01:22:44 AM  [*] Sun Jan 29 01:22:44 2023: Train Epoch: 3 [64000/76126 (84%)]	Loss: 0.182735 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.9333 & F1 0.9655 | AUC 0.9888
01/29/2023 01:22:51 AM  [*] Sun Jan 29 01:22:51 2023: Train Epoch: 3 [70400/76126 (92%)]	Loss: 0.115846 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.7903 & F1 0.8829 | AUC 0.9817
01/29/2023 01:22:58 AM  [*] Sun Jan 29 01:22:58 2023:    3    | Tr.loss: 0.156993 | Elapsed:   75.37  s | FPR 0.0003 -> TPR: 0.50 & F1: 0.67 | AUC: 0.9829
01/29/2023 01:22:58 AM [!] Sun Jan 29 01:22:58 2023: Dumped results:
                model     : 1674951778-model.torch
		train time: 1674951778-trainTime.npy
		train losses: 1674951778-trainLosses.npy
		train AUC: 1674951778-auc.npy
		train F1s : 1674951778-trainF1s.npy
		train TPRs: 1674951778-trainTPRs.npy
01/29/2023 01:22:58 AM  [*] Evaluating pretrained model on test set...
01/29/2023 01:23:03 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0725 | F1: 0.1353
01/29/2023 01:23:03 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.0824 | F1: 0.1523
01/29/2023 01:23:03 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.1061 | F1: 0.1918
01/29/2023 01:23:03 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.1323 | F1: 0.2332
01/29/2023 01:23:03 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.2601 | F1: 0.4101
01/29/2023 01:23:03 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4234 | F1: 0.5844
01/29/2023 01:23:03 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.5078 | F1: 0.6376
01/29/2023 01:23:03 AM  [*] Evaluating non_pretrained model on test set...
01/29/2023 01:23:08 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0397 | F1: 0.0763
01/29/2023 01:23:08 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.0984 | F1: 0.1791
01/29/2023 01:23:08 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.1355 | F1: 0.2385
01/29/2023 01:23:08 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.1782 | F1: 0.3019
01/29/2023 01:23:08 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.2909 | F1: 0.4477
01/29/2023 01:23:08 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.3984 | F1: 0.5596
01/29/2023 01:23:08 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.5400 | F1: 0.6646
01/29/2023 01:23:08 AM  [*] Evaluating full_data model on test set...
01/29/2023 01:23:13 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0171 | F1: 0.0337
01/29/2023 01:23:13 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.2737 | F1: 0.4298
01/29/2023 01:23:13 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.3167 | F1: 0.4807
01/29/2023 01:23:13 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3882 | F1: 0.5582
01/29/2023 01:23:13 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.5074 | F1: 0.6695
01/29/2023 01:23:13 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.6049 | F1: 0.7420
01/29/2023 01:23:13 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.7973 | F1: 0.8472
01/29/2023 01:23:13 AM  [!] Running pre-training split 2/3
01/29/2023 01:23:16 AM  [!] Pre-training model...
01/29/2023 01:23:17 AM  [*] Masking sequences...
01/29/2023 01:23:38 AM  [*] Started epoch: 1
01/29/2023 01:23:38 AM  [*] Sun Jan 29 01:23:38 2023: Train Epoch: 1 [  0  /72319 (0 %)]	Loss: 427.502747 | Elapsed: 0.48s
01/29/2023 01:23:50 AM  [*] Sun Jan 29 01:23:50 2023: Train Epoch: 1 [6400 /72319 (9 %)]	Loss: 231.491547 | Elapsed: 12.22s
01/29/2023 01:24:03 AM  [*] Sun Jan 29 01:24:03 2023: Train Epoch: 1 [12800/72319 (18%)]	Loss: 218.609100 | Elapsed: 12.19s
01/29/2023 01:24:15 AM  [*] Sun Jan 29 01:24:15 2023: Train Epoch: 1 [19200/72319 (27%)]	Loss: 213.891312 | Elapsed: 12.24s
01/29/2023 01:24:27 AM  [*] Sun Jan 29 01:24:27 2023: Train Epoch: 1 [25600/72319 (35%)]	Loss: 222.717438 | Elapsed: 12.30s
01/29/2023 01:24:39 AM  [*] Sun Jan 29 01:24:39 2023: Train Epoch: 1 [32000/72319 (44%)]	Loss: 232.935104 | Elapsed: 12.24s
01/29/2023 01:24:52 AM  [*] Sun Jan 29 01:24:52 2023: Train Epoch: 1 [38400/72319 (53%)]	Loss: 198.501251 | Elapsed: 12.25s
01/29/2023 01:25:04 AM  [*] Sun Jan 29 01:25:04 2023: Train Epoch: 1 [44800/72319 (62%)]	Loss: 175.649658 | Elapsed: 12.21s
01/29/2023 01:25:16 AM  [*] Sun Jan 29 01:25:16 2023: Train Epoch: 1 [51200/72319 (71%)]	Loss: 188.974289 | Elapsed: 12.22s
01/29/2023 01:25:28 AM  [*] Sun Jan 29 01:25:28 2023: Train Epoch: 1 [57600/72319 (80%)]	Loss: 203.395966 | Elapsed: 12.26s
01/29/2023 01:25:41 AM  [*] Sun Jan 29 01:25:41 2023: Train Epoch: 1 [64000/72319 (88%)]	Loss: 178.844788 | Elapsed: 12.25s
01/29/2023 01:25:53 AM  [*] Sun Jan 29 01:25:53 2023: Train Epoch: 1 [70400/72319 (97%)]	Loss: 206.958786 | Elapsed: 12.76s
01/29/2023 01:26:04 AM  [*] Sun Jan 29 01:26:04 2023:    1    | Tr.loss: 207.032804 | Elapsed:  145.96  s
01/29/2023 01:26:04 AM  [*] Started epoch: 2
01/29/2023 01:26:04 AM  [*] Sun Jan 29 01:26:04 2023: Train Epoch: 2 [  0  /72319 (0 %)]	Loss: 168.135284 | Elapsed: 0.21s
01/29/2023 01:26:16 AM  [*] Sun Jan 29 01:26:16 2023: Train Epoch: 2 [6400 /72319 (9 %)]	Loss: 179.295502 | Elapsed: 12.34s
01/29/2023 01:26:29 AM  [*] Sun Jan 29 01:26:29 2023: Train Epoch: 2 [12800/72319 (18%)]	Loss: 176.522797 | Elapsed: 12.35s
01/29/2023 01:26:41 AM  [*] Sun Jan 29 01:26:41 2023: Train Epoch: 2 [19200/72319 (27%)]	Loss: 177.783203 | Elapsed: 12.28s
01/29/2023 01:26:53 AM  [*] Sun Jan 29 01:26:53 2023: Train Epoch: 2 [25600/72319 (35%)]	Loss: 169.311615 | Elapsed: 12.32s
01/29/2023 01:27:05 AM  [*] Sun Jan 29 01:27:05 2023: Train Epoch: 2 [32000/72319 (44%)]	Loss: 179.720764 | Elapsed: 12.28s
01/29/2023 01:27:18 AM  [*] Sun Jan 29 01:27:18 2023: Train Epoch: 2 [38400/72319 (53%)]	Loss: 188.670944 | Elapsed: 12.27s
01/29/2023 01:27:30 AM  [*] Sun Jan 29 01:27:30 2023: Train Epoch: 2 [44800/72319 (62%)]	Loss: 173.285934 | Elapsed: 12.34s
01/29/2023 01:27:42 AM  [*] Sun Jan 29 01:27:42 2023: Train Epoch: 2 [51200/72319 (71%)]	Loss: 172.951080 | Elapsed: 12.31s
01/29/2023 01:27:55 AM  [*] Sun Jan 29 01:27:55 2023: Train Epoch: 2 [57600/72319 (80%)]	Loss: 179.330429 | Elapsed: 12.38s
01/29/2023 01:28:07 AM  [*] Sun Jan 29 01:28:07 2023: Train Epoch: 2 [64000/72319 (88%)]	Loss: 182.625610 | Elapsed: 12.39s
01/29/2023 01:28:20 AM  [*] Sun Jan 29 01:28:20 2023: Train Epoch: 2 [70400/72319 (97%)]	Loss: 182.780319 | Elapsed: 12.43s
01/29/2023 01:28:25 AM  [*] Sun Jan 29 01:28:25 2023:    2    | Tr.loss: 186.701416 | Elapsed:  141.44  s
01/29/2023 01:28:25 AM  [*] Started epoch: 3
01/29/2023 01:28:25 AM  [*] Sun Jan 29 01:28:25 2023: Train Epoch: 3 [  0  /72319 (0 %)]	Loss: 178.975769 | Elapsed: 0.19s
01/29/2023 01:28:38 AM  [*] Sun Jan 29 01:28:38 2023: Train Epoch: 3 [6400 /72319 (9 %)]	Loss: 175.210876 | Elapsed: 12.38s
01/29/2023 01:28:50 AM  [*] Sun Jan 29 01:28:50 2023: Train Epoch: 3 [12800/72319 (18%)]	Loss: 182.910248 | Elapsed: 12.40s
01/29/2023 01:29:02 AM  [*] Sun Jan 29 01:29:02 2023: Train Epoch: 3 [19200/72319 (27%)]	Loss: 176.374878 | Elapsed: 12.29s
01/29/2023 01:29:15 AM  [*] Sun Jan 29 01:29:15 2023: Train Epoch: 3 [25600/72319 (35%)]	Loss: 185.901428 | Elapsed: 12.33s
01/29/2023 01:29:27 AM  [*] Sun Jan 29 01:29:27 2023: Train Epoch: 3 [32000/72319 (44%)]	Loss: 189.434006 | Elapsed: 12.24s
01/29/2023 01:29:39 AM  [*] Sun Jan 29 01:29:39 2023: Train Epoch: 3 [38400/72319 (53%)]	Loss: 187.141144 | Elapsed: 12.33s
01/29/2023 01:29:52 AM  [*] Sun Jan 29 01:29:52 2023: Train Epoch: 3 [44800/72319 (62%)]	Loss: 184.680908 | Elapsed: 12.35s
01/29/2023 01:30:04 AM  [*] Sun Jan 29 01:30:04 2023: Train Epoch: 3 [51200/72319 (71%)]	Loss: 169.308105 | Elapsed: 12.31s
01/29/2023 01:30:16 AM  [*] Sun Jan 29 01:30:16 2023: Train Epoch: 3 [57600/72319 (80%)]	Loss: 185.139481 | Elapsed: 12.38s
01/29/2023 01:30:29 AM  [*] Sun Jan 29 01:30:29 2023: Train Epoch: 3 [64000/72319 (88%)]	Loss: 169.289093 | Elapsed: 12.29s
01/29/2023 01:30:41 AM  [*] Sun Jan 29 01:30:41 2023: Train Epoch: 3 [70400/72319 (97%)]	Loss: 185.979553 | Elapsed: 12.33s
01/29/2023 01:30:46 AM  [*] Sun Jan 29 01:30:46 2023:    3    | Tr.loss: 181.968411 | Elapsed:  141.35  s
01/29/2023 01:30:46 AM  [*] Started epoch: 4
01/29/2023 01:30:47 AM  [*] Sun Jan 29 01:30:47 2023: Train Epoch: 4 [  0  /72319 (0 %)]	Loss: 171.062531 | Elapsed: 0.22s
01/29/2023 01:30:59 AM  [*] Sun Jan 29 01:30:59 2023: Train Epoch: 4 [6400 /72319 (9 %)]	Loss: 200.758575 | Elapsed: 12.32s
01/29/2023 01:31:11 AM  [*] Sun Jan 29 01:31:11 2023: Train Epoch: 4 [12800/72319 (18%)]	Loss: 179.618988 | Elapsed: 12.36s
01/29/2023 01:31:24 AM  [*] Sun Jan 29 01:31:24 2023: Train Epoch: 4 [19200/72319 (27%)]	Loss: 182.553162 | Elapsed: 12.33s
01/29/2023 01:31:36 AM  [*] Sun Jan 29 01:31:36 2023: Train Epoch: 4 [25600/72319 (35%)]	Loss: 177.497253 | Elapsed: 12.32s
01/29/2023 01:31:48 AM  [*] Sun Jan 29 01:31:48 2023: Train Epoch: 4 [32000/72319 (44%)]	Loss: 166.286469 | Elapsed: 12.27s
01/29/2023 01:32:01 AM  [*] Sun Jan 29 01:32:01 2023: Train Epoch: 4 [38400/72319 (53%)]	Loss: 174.846588 | Elapsed: 12.28s
01/29/2023 01:32:13 AM  [*] Sun Jan 29 01:32:13 2023: Train Epoch: 4 [44800/72319 (62%)]	Loss: 175.753937 | Elapsed: 12.24s
01/29/2023 01:32:25 AM  [*] Sun Jan 29 01:32:25 2023: Train Epoch: 4 [51200/72319 (71%)]	Loss: 164.041138 | Elapsed: 12.27s
01/29/2023 01:32:37 AM  [*] Sun Jan 29 01:32:37 2023: Train Epoch: 4 [57600/72319 (80%)]	Loss: 185.191498 | Elapsed: 12.21s
01/29/2023 01:32:50 AM  [*] Sun Jan 29 01:32:50 2023: Train Epoch: 4 [64000/72319 (88%)]	Loss: 209.604584 | Elapsed: 12.26s
01/29/2023 01:33:02 AM  [*] Sun Jan 29 01:33:02 2023: Train Epoch: 4 [70400/72319 (97%)]	Loss: 167.938690 | Elapsed: 12.26s
01/29/2023 01:33:07 AM  [*] Sun Jan 29 01:33:07 2023:    4    | Tr.loss: 179.427564 | Elapsed:  140.91  s
01/29/2023 01:33:07 AM  [*] Started epoch: 5
01/29/2023 01:33:08 AM  [*] Sun Jan 29 01:33:08 2023: Train Epoch: 5 [  0  /72319 (0 %)]	Loss: 169.961990 | Elapsed: 0.20s
01/29/2023 01:33:20 AM  [*] Sun Jan 29 01:33:20 2023: Train Epoch: 5 [6400 /72319 (9 %)]	Loss: 159.725311 | Elapsed: 12.31s
01/29/2023 01:33:32 AM  [*] Sun Jan 29 01:33:32 2023: Train Epoch: 5 [12800/72319 (18%)]	Loss: 193.882019 | Elapsed: 12.35s
01/29/2023 01:33:44 AM  [*] Sun Jan 29 01:33:44 2023: Train Epoch: 5 [19200/72319 (27%)]	Loss: 180.208344 | Elapsed: 12.21s
01/29/2023 01:33:57 AM  [*] Sun Jan 29 01:33:57 2023: Train Epoch: 5 [25600/72319 (35%)]	Loss: 183.029724 | Elapsed: 12.27s
01/29/2023 01:34:06 AM [!] Learning rate: 2.5e-05
01/29/2023 01:34:09 AM  [*] Sun Jan 29 01:34:09 2023: Train Epoch: 5 [32000/72319 (44%)]	Loss: 174.414246 | Elapsed: 12.24s
01/29/2023 01:34:21 AM  [*] Sun Jan 29 01:34:21 2023: Train Epoch: 5 [38400/72319 (53%)]	Loss: 181.687180 | Elapsed: 12.22s
01/29/2023 01:34:33 AM  [*] Sun Jan 29 01:34:33 2023: Train Epoch: 5 [44800/72319 (62%)]	Loss: 189.494354 | Elapsed: 12.22s
01/29/2023 01:34:46 AM  [*] Sun Jan 29 01:34:46 2023: Train Epoch: 5 [51200/72319 (71%)]	Loss: 156.885727 | Elapsed: 12.23s
01/29/2023 01:34:58 AM  [*] Sun Jan 29 01:34:58 2023: Train Epoch: 5 [57600/72319 (80%)]	Loss: 167.861694 | Elapsed: 12.30s
01/29/2023 01:35:10 AM  [*] Sun Jan 29 01:35:10 2023: Train Epoch: 5 [64000/72319 (88%)]	Loss: 161.136749 | Elapsed: 12.23s
01/29/2023 01:35:22 AM  [*] Sun Jan 29 01:35:22 2023: Train Epoch: 5 [70400/72319 (97%)]	Loss: 202.577515 | Elapsed: 12.27s
01/29/2023 01:35:28 AM  [*] Sun Jan 29 01:35:28 2023:    5    | Tr.loss: 177.724659 | Elapsed:  140.51  s
01/29/2023 01:35:28 AM  [*] Started epoch: 6
01/29/2023 01:35:28 AM  [*] Sun Jan 29 01:35:28 2023: Train Epoch: 6 [  0  /72319 (0 %)]	Loss: 185.474991 | Elapsed: 0.21s
01/29/2023 01:35:40 AM  [*] Sun Jan 29 01:35:40 2023: Train Epoch: 6 [6400 /72319 (9 %)]	Loss: 171.289032 | Elapsed: 12.34s
01/29/2023 01:35:53 AM  [*] Sun Jan 29 01:35:53 2023: Train Epoch: 6 [12800/72319 (18%)]	Loss: 176.403809 | Elapsed: 12.21s
01/29/2023 01:36:05 AM  [*] Sun Jan 29 01:36:05 2023: Train Epoch: 6 [19200/72319 (27%)]	Loss: 158.344360 | Elapsed: 12.29s
01/29/2023 01:36:17 AM  [*] Sun Jan 29 01:36:17 2023: Train Epoch: 6 [25600/72319 (35%)]	Loss: 156.531464 | Elapsed: 12.24s
01/29/2023 01:36:29 AM  [*] Sun Jan 29 01:36:29 2023: Train Epoch: 6 [32000/72319 (44%)]	Loss: 200.367661 | Elapsed: 12.26s
01/29/2023 01:36:42 AM  [*] Sun Jan 29 01:36:42 2023: Train Epoch: 6 [38400/72319 (53%)]	Loss: 174.353271 | Elapsed: 12.23s
01/29/2023 01:36:54 AM  [*] Sun Jan 29 01:36:54 2023: Train Epoch: 6 [44800/72319 (62%)]	Loss: 184.572449 | Elapsed: 12.26s
01/29/2023 01:37:06 AM  [*] Sun Jan 29 01:37:06 2023: Train Epoch: 6 [51200/72319 (71%)]	Loss: 167.760437 | Elapsed: 12.23s
01/29/2023 01:37:18 AM  [*] Sun Jan 29 01:37:18 2023: Train Epoch: 6 [57600/72319 (80%)]	Loss: 170.318298 | Elapsed: 12.22s
01/29/2023 01:37:31 AM  [*] Sun Jan 29 01:37:31 2023: Train Epoch: 6 [64000/72319 (88%)]	Loss: 151.608658 | Elapsed: 12.21s
01/29/2023 01:37:43 AM  [*] Sun Jan 29 01:37:43 2023: Train Epoch: 6 [70400/72319 (97%)]	Loss: 188.756760 | Elapsed: 12.26s
01/29/2023 01:37:48 AM  [*] Sun Jan 29 01:37:48 2023:    6    | Tr.loss: 176.810573 | Elapsed:  140.49  s
01/29/2023 01:37:48 AM  [*] Started epoch: 7
01/29/2023 01:37:49 AM  [*] Sun Jan 29 01:37:49 2023: Train Epoch: 7 [  0  /72319 (0 %)]	Loss: 168.694519 | Elapsed: 0.22s
01/29/2023 01:38:01 AM  [*] Sun Jan 29 01:38:01 2023: Train Epoch: 7 [6400 /72319 (9 %)]	Loss: 176.820435 | Elapsed: 12.29s
01/29/2023 01:38:13 AM  [*] Sun Jan 29 01:38:13 2023: Train Epoch: 7 [12800/72319 (18%)]	Loss: 164.264297 | Elapsed: 12.26s
01/29/2023 01:38:25 AM  [*] Sun Jan 29 01:38:25 2023: Train Epoch: 7 [19200/72319 (27%)]	Loss: 179.351624 | Elapsed: 12.29s
01/29/2023 01:38:38 AM  [*] Sun Jan 29 01:38:38 2023: Train Epoch: 7 [25600/72319 (35%)]	Loss: 181.883179 | Elapsed: 12.23s
01/29/2023 01:38:50 AM  [*] Sun Jan 29 01:38:50 2023: Train Epoch: 7 [32000/72319 (44%)]	Loss: 181.825821 | Elapsed: 12.22s
01/29/2023 01:39:02 AM  [*] Sun Jan 29 01:39:02 2023: Train Epoch: 7 [38400/72319 (53%)]	Loss: 172.589294 | Elapsed: 12.25s
01/29/2023 01:39:14 AM  [*] Sun Jan 29 01:39:14 2023: Train Epoch: 7 [44800/72319 (62%)]	Loss: 188.047180 | Elapsed: 12.23s
01/29/2023 01:39:27 AM  [*] Sun Jan 29 01:39:27 2023: Train Epoch: 7 [51200/72319 (71%)]	Loss: 185.378784 | Elapsed: 12.24s
01/29/2023 01:39:39 AM  [*] Sun Jan 29 01:39:39 2023: Train Epoch: 7 [57600/72319 (80%)]	Loss: 176.511292 | Elapsed: 12.24s
01/29/2023 01:39:51 AM  [*] Sun Jan 29 01:39:51 2023: Train Epoch: 7 [64000/72319 (88%)]	Loss: 165.500916 | Elapsed: 12.23s
01/29/2023 01:40:03 AM  [*] Sun Jan 29 01:40:03 2023: Train Epoch: 7 [70400/72319 (97%)]	Loss: 207.657104 | Elapsed: 12.35s
01/29/2023 01:40:09 AM  [*] Sun Jan 29 01:40:09 2023:    7    | Tr.loss: 176.590828 | Elapsed:  140.47  s
01/29/2023 01:40:09 AM  [*] Started epoch: 8
01/29/2023 01:40:09 AM  [*] Sun Jan 29 01:40:09 2023: Train Epoch: 8 [  0  /72319 (0 %)]	Loss: 166.892899 | Elapsed: 0.20s
01/29/2023 01:40:21 AM  [*] Sun Jan 29 01:40:21 2023: Train Epoch: 8 [6400 /72319 (9 %)]	Loss: 178.740753 | Elapsed: 12.30s
01/29/2023 01:40:34 AM  [*] Sun Jan 29 01:40:34 2023: Train Epoch: 8 [12800/72319 (18%)]	Loss: 159.553345 | Elapsed: 12.27s
01/29/2023 01:40:46 AM  [*] Sun Jan 29 01:40:46 2023: Train Epoch: 8 [19200/72319 (27%)]	Loss: 160.198212 | Elapsed: 12.31s
01/29/2023 01:40:58 AM  [*] Sun Jan 29 01:40:58 2023: Train Epoch: 8 [25600/72319 (35%)]	Loss: 184.921722 | Elapsed: 12.24s
01/29/2023 01:41:10 AM  [*] Sun Jan 29 01:41:10 2023: Train Epoch: 8 [32000/72319 (44%)]	Loss: 190.348633 | Elapsed: 12.19s
01/29/2023 01:41:23 AM  [*] Sun Jan 29 01:41:23 2023: Train Epoch: 8 [38400/72319 (53%)]	Loss: 177.227295 | Elapsed: 12.24s
01/29/2023 01:41:35 AM  [*] Sun Jan 29 01:41:35 2023: Train Epoch: 8 [44800/72319 (62%)]	Loss: 182.711182 | Elapsed: 12.29s
01/29/2023 01:41:47 AM  [*] Sun Jan 29 01:41:47 2023: Train Epoch: 8 [51200/72319 (71%)]	Loss: 177.918579 | Elapsed: 12.25s
01/29/2023 01:41:59 AM  [*] Sun Jan 29 01:41:59 2023: Train Epoch: 8 [57600/72319 (80%)]	Loss: 175.255325 | Elapsed: 12.23s
01/29/2023 01:42:12 AM  [*] Sun Jan 29 01:42:12 2023: Train Epoch: 8 [64000/72319 (88%)]	Loss: 161.877579 | Elapsed: 12.21s
01/29/2023 01:42:24 AM  [*] Sun Jan 29 01:42:24 2023: Train Epoch: 8 [70400/72319 (97%)]	Loss: 163.311600 | Elapsed: 12.28s
01/29/2023 01:42:29 AM  [*] Sun Jan 29 01:42:29 2023:    8    | Tr.loss: 176.402383 | Elapsed:  140.40  s
01/29/2023 01:42:29 AM  [*] Started epoch: 9
01/29/2023 01:42:29 AM  [*] Sun Jan 29 01:42:29 2023: Train Epoch: 9 [  0  /72319 (0 %)]	Loss: 175.044312 | Elapsed: 0.17s
01/29/2023 01:42:42 AM  [*] Sun Jan 29 01:42:42 2023: Train Epoch: 9 [6400 /72319 (9 %)]	Loss: 179.975327 | Elapsed: 12.32s
01/29/2023 01:42:54 AM  [*] Sun Jan 29 01:42:54 2023: Train Epoch: 9 [12800/72319 (18%)]	Loss: 165.347443 | Elapsed: 12.29s
01/29/2023 01:43:06 AM  [*] Sun Jan 29 01:43:06 2023: Train Epoch: 9 [19200/72319 (27%)]	Loss: 165.197784 | Elapsed: 12.31s
01/29/2023 01:43:19 AM  [*] Sun Jan 29 01:43:19 2023: Train Epoch: 9 [25600/72319 (35%)]	Loss: 173.025024 | Elapsed: 12.27s
01/29/2023 01:43:31 AM  [*] Sun Jan 29 01:43:31 2023: Train Epoch: 9 [32000/72319 (44%)]	Loss: 174.745331 | Elapsed: 12.24s
01/29/2023 01:43:43 AM  [*] Sun Jan 29 01:43:43 2023: Train Epoch: 9 [38400/72319 (53%)]	Loss: 167.401321 | Elapsed: 12.23s
01/29/2023 01:43:55 AM  [*] Sun Jan 29 01:43:55 2023: Train Epoch: 9 [44800/72319 (62%)]	Loss: 179.228409 | Elapsed: 12.23s
01/29/2023 01:44:08 AM  [*] Sun Jan 29 01:44:08 2023: Train Epoch: 9 [51200/72319 (71%)]	Loss: 199.137207 | Elapsed: 12.28s
01/29/2023 01:44:20 AM  [*] Sun Jan 29 01:44:20 2023: Train Epoch: 9 [57600/72319 (80%)]	Loss: 183.549301 | Elapsed: 12.29s
01/29/2023 01:44:27 AM [!] Learning rate: 2.5e-06
01/29/2023 01:44:32 AM  [*] Sun Jan 29 01:44:32 2023: Train Epoch: 9 [64000/72319 (88%)]	Loss: 176.892761 | Elapsed: 12.27s
01/29/2023 01:44:44 AM  [*] Sun Jan 29 01:44:44 2023: Train Epoch: 9 [70400/72319 (97%)]	Loss: 148.029251 | Elapsed: 12.24s
01/29/2023 01:44:50 AM  [*] Sun Jan 29 01:44:50 2023:    9    | Tr.loss: 176.123322 | Elapsed:  140.64  s
01/29/2023 01:44:50 AM  [*] Started epoch: 10
01/29/2023 01:44:50 AM  [*] Sun Jan 29 01:44:50 2023: Train Epoch: 10 [  0  /72319 (0 %)]	Loss: 180.895203 | Elapsed: 0.15s
01/29/2023 01:45:02 AM  [*] Sun Jan 29 01:45:02 2023: Train Epoch: 10 [6400 /72319 (9 %)]	Loss: 176.661316 | Elapsed: 12.33s
01/29/2023 01:45:15 AM  [*] Sun Jan 29 01:45:15 2023: Train Epoch: 10 [12800/72319 (18%)]	Loss: 191.164368 | Elapsed: 12.24s
01/29/2023 01:45:27 AM  [*] Sun Jan 29 01:45:27 2023: Train Epoch: 10 [19200/72319 (27%)]	Loss: 182.316055 | Elapsed: 12.32s
01/29/2023 01:45:39 AM  [*] Sun Jan 29 01:45:39 2023: Train Epoch: 10 [25600/72319 (35%)]	Loss: 170.104034 | Elapsed: 12.18s
01/29/2023 01:45:51 AM  [*] Sun Jan 29 01:45:51 2023: Train Epoch: 10 [32000/72319 (44%)]	Loss: 185.909149 | Elapsed: 12.23s
01/29/2023 01:46:04 AM  [*] Sun Jan 29 01:46:04 2023: Train Epoch: 10 [38400/72319 (53%)]	Loss: 192.602829 | Elapsed: 12.25s
01/29/2023 01:46:16 AM  [*] Sun Jan 29 01:46:16 2023: Train Epoch: 10 [44800/72319 (62%)]	Loss: 186.864899 | Elapsed: 12.20s
01/29/2023 01:46:28 AM  [*] Sun Jan 29 01:46:28 2023: Train Epoch: 10 [51200/72319 (71%)]	Loss: 178.784973 | Elapsed: 12.21s
01/29/2023 01:46:40 AM  [*] Sun Jan 29 01:46:40 2023: Train Epoch: 10 [57600/72319 (80%)]	Loss: 174.472656 | Elapsed: 12.25s
01/29/2023 01:46:53 AM  [*] Sun Jan 29 01:46:53 2023: Train Epoch: 10 [64000/72319 (88%)]	Loss: 201.266327 | Elapsed: 12.31s
01/29/2023 01:47:05 AM  [*] Sun Jan 29 01:47:05 2023: Train Epoch: 10 [70400/72319 (97%)]	Loss: 190.390442 | Elapsed: 12.29s
01/29/2023 01:47:10 AM  [*] Sun Jan 29 01:47:10 2023:   10    | Tr.loss: 176.107099 | Elapsed:  140.48  s
01/29/2023 01:47:11 AM [!] Sun Jan 29 01:47:11 2023: Dumped results:
                model     : 1674953230-model.torch
		train time: 1674953230-trainTime.npy
		train losses: 1674953230-trainLosses.npy
		train AUC: 1674953230-auc.npy
01/29/2023 01:47:13 AM  [!] Training pretrained model on downstream task...
01/29/2023 01:47:13 AM  [*] Started epoch: 1
01/29/2023 01:47:13 AM  [*] Sun Jan 29 01:47:13 2023: Train Epoch: 1 [  0  /3807  (0 %)]	Loss: 2.491504 | Elapsed: 0.33s | FPR 0.0003 -> TPR 0.0213 & F1 0.0417 | AUC 0.4093
01/29/2023 01:47:19 AM  [*] Sun Jan 29 01:47:19 2023:    1    | Tr.loss: 0.737403 | Elapsed:   5.75   s | FPR 0.0003 -> TPR: 0.01 & F1: 0.02 | AUC: 0.7082
01/29/2023 01:47:19 AM  [*] Started epoch: 2
01/29/2023 01:47:19 AM  [*] Sun Jan 29 01:47:19 2023: Train Epoch: 2 [  0  /3807  (0 %)]	Loss: 0.469189 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.3250 & F1 0.4906 | AUC 0.8271
01/29/2023 01:47:24 AM  [*] Sun Jan 29 01:47:24 2023:    2    | Tr.loss: 0.478170 | Elapsed:   5.47   s | FPR 0.0003 -> TPR: 0.03 & F1: 0.07 | AUC: 0.7967
01/29/2023 01:47:24 AM  [*] Started epoch: 3
01/29/2023 01:47:24 AM  [*] Sun Jan 29 01:47:24 2023: Train Epoch: 3 [  0  /3807  (0 %)]	Loss: 0.509448 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.3125 & F1 0.4762 | AUC 0.7676
01/29/2023 01:47:30 AM  [*] Sun Jan 29 01:47:30 2023:    3    | Tr.loss: 0.436683 | Elapsed:   5.53   s | FPR 0.0003 -> TPR: 0.14 & F1: 0.25 | AUC: 0.8354
01/29/2023 01:47:30 AM [!] Sun Jan 29 01:47:30 2023: Dumped results:
                model     : 1674953250-model.torch
		train time: 1674953250-trainTime.npy
		train losses: 1674953250-trainLosses.npy
		train AUC: 1674953250-auc.npy
		train F1s : 1674953250-trainF1s.npy
		train TPRs: 1674953250-trainTPRs.npy
01/29/2023 01:47:30 AM  [!] Training non_pretrained model on downstream task...
01/29/2023 01:47:31 AM  [*] Started epoch: 1
01/29/2023 01:47:31 AM  [*] Sun Jan 29 01:47:31 2023: Train Epoch: 1 [  0  /3807  (0 %)]	Loss: 1.745771 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.4889
01/29/2023 01:47:34 AM  [*] Sun Jan 29 01:47:34 2023:    1    | Tr.loss: 0.657328 | Elapsed:   3.76   s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.6946
01/29/2023 01:47:34 AM  [*] Started epoch: 2
01/29/2023 01:47:35 AM  [*] Sun Jan 29 01:47:35 2023: Train Epoch: 2 [  0  /3807  (0 %)]	Loss: 0.452741 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.2500 & F1 0.4000 | AUC 0.8406
01/29/2023 01:47:38 AM  [*] Sun Jan 29 01:47:38 2023:    2    | Tr.loss: 0.414976 | Elapsed:   3.75   s | FPR 0.0003 -> TPR: 0.05 & F1: 0.09 | AUC: 0.8552
01/29/2023 01:47:38 AM  [*] Started epoch: 3
01/29/2023 01:47:38 AM  [*] Sun Jan 29 01:47:38 2023: Train Epoch: 3 [  0  /3807  (0 %)]	Loss: 0.438485 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.4545 & F1 0.6250 | AUC 0.8352
01/29/2023 01:47:42 AM  [*] Sun Jan 29 01:47:42 2023:    3    | Tr.loss: 0.360270 | Elapsed:   3.76   s | FPR 0.0003 -> TPR: 0.10 & F1: 0.18 | AUC: 0.8943
01/29/2023 01:47:42 AM [!] Sun Jan 29 01:47:42 2023: Dumped results:
                model     : 1674953262-model.torch
		train time: 1674953262-trainTime.npy
		train losses: 1674953262-trainLosses.npy
		train AUC: 1674953262-auc.npy
		train F1s : 1674953262-trainF1s.npy
		train TPRs: 1674953262-trainTPRs.npy
01/29/2023 01:47:42 AM  [!] Training full_data model on downstream task...
01/29/2023 01:47:43 AM  [*] Started epoch: 1
01/29/2023 01:47:43 AM  [*] Sun Jan 29 01:47:43 2023: Train Epoch: 1 [  0  /76126 (0 %)]	Loss: 3.254930 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0488 & F1 0.0930 | AUC 0.5133
01/29/2023 01:47:49 AM  [*] Sun Jan 29 01:47:49 2023: Train Epoch: 1 [6400 /76126 (8 %)]	Loss: 0.402304 | Elapsed: 6.16s | FPR 0.0003 -> TPR 0.2308 & F1 0.3750 | AUC 0.8747
01/29/2023 01:47:55 AM  [*] Sun Jan 29 01:47:55 2023: Train Epoch: 1 [12800/76126 (17%)]	Loss: 0.486372 | Elapsed: 6.16s | FPR 0.0003 -> TPR 0.2121 & F1 0.3500 | AUC 0.8650
01/29/2023 01:48:01 AM  [*] Sun Jan 29 01:48:01 2023: Train Epoch: 1 [19200/76126 (25%)]	Loss: 0.302288 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.6087 & F1 0.7568 | AUC 0.9378
01/29/2023 01:48:08 AM  [*] Sun Jan 29 01:48:08 2023: Train Epoch: 1 [25600/76126 (34%)]	Loss: 0.373221 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.6714 & F1 0.8034 | AUC 0.9171
01/29/2023 01:48:14 AM  [*] Sun Jan 29 01:48:14 2023: Train Epoch: 1 [32000/76126 (42%)]	Loss: 0.323897 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.7101 & F1 0.8305 | AUC 0.9551
01/29/2023 01:48:20 AM  [*] Sun Jan 29 01:48:20 2023: Train Epoch: 1 [38400/76126 (50%)]	Loss: 0.177386 | Elapsed: 6.16s | FPR 0.0003 -> TPR 0.5139 & F1 0.6789 | AUC 0.9628
01/29/2023 01:48:26 AM  [*] Sun Jan 29 01:48:26 2023: Train Epoch: 1 [44800/76126 (59%)]	Loss: 0.292173 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.6622 & F1 0.7967 | AUC 0.9059
01/29/2023 01:48:32 AM  [*] Sun Jan 29 01:48:32 2023: Train Epoch: 1 [51200/76126 (67%)]	Loss: 0.222622 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.6615 & F1 0.7963 | AUC 0.9521
01/29/2023 01:48:39 AM  [*] Sun Jan 29 01:48:39 2023: Train Epoch: 1 [57600/76126 (76%)]	Loss: 0.216224 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.7639 & F1 0.8661 | AUC 0.9692
01/29/2023 01:48:45 AM [!] Learning rate: 2.5e-05
01/29/2023 01:48:45 AM  [*] Sun Jan 29 01:48:45 2023: Train Epoch: 1 [64000/76126 (84%)]	Loss: 0.201792 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.5224 & F1 0.6863 | AUC 0.9683
01/29/2023 01:48:51 AM  [*] Sun Jan 29 01:48:51 2023: Train Epoch: 1 [70400/76126 (92%)]	Loss: 0.156308 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.8714 & F1 0.9313 | AUC 0.9900
01/29/2023 01:48:58 AM  [*] Sun Jan 29 01:48:58 2023:    1    | Tr.loss: 0.304178 | Elapsed:   75.37  s | FPR 0.0003 -> TPR: 0.03 & F1: 0.06 | AUC: 0.9332
01/29/2023 01:48:58 AM  [*] Started epoch: 2
01/29/2023 01:48:58 AM  [*] Sun Jan 29 01:48:58 2023: Train Epoch: 2 [  0  /76126 (0 %)]	Loss: 0.132294 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.9556 & F1 0.9773 | AUC 0.9953
01/29/2023 01:49:05 AM  [*] Sun Jan 29 01:49:05 2023: Train Epoch: 2 [6400 /76126 (8 %)]	Loss: 0.084393 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.9531 & F1 0.9760 | AUC 0.9974
01/29/2023 01:49:11 AM  [*] Sun Jan 29 01:49:11 2023: Train Epoch: 2 [12800/76126 (17%)]	Loss: 0.110989 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.8136 & F1 0.8972 | AUC 0.9847
01/29/2023 01:49:17 AM  [*] Sun Jan 29 01:49:17 2023: Train Epoch: 2 [19200/76126 (25%)]	Loss: 0.118885 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.6716 & F1 0.8036 | AUC 0.9787
01/29/2023 01:49:23 AM  [*] Sun Jan 29 01:49:23 2023: Train Epoch: 2 [25600/76126 (34%)]	Loss: 0.134901 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.9701 & F1 0.9848 | AUC 0.9941
01/29/2023 01:49:29 AM  [*] Sun Jan 29 01:49:29 2023: Train Epoch: 2 [32000/76126 (42%)]	Loss: 0.171770 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.7612 & F1 0.8644 | AUC 0.9769
01/29/2023 01:49:36 AM  [*] Sun Jan 29 01:49:36 2023: Train Epoch: 2 [38400/76126 (50%)]	Loss: 0.160362 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.7917 & F1 0.8837 | AUC 0.9792
01/29/2023 01:49:42 AM  [*] Sun Jan 29 01:49:42 2023: Train Epoch: 2 [44800/76126 (59%)]	Loss: 0.178696 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.4545 & F1 0.6250 | AUC 0.9617
01/29/2023 01:49:48 AM  [*] Sun Jan 29 01:49:48 2023: Train Epoch: 2 [51200/76126 (67%)]	Loss: 0.181444 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.7941 & F1 0.8852 | AUC 0.9655
01/29/2023 01:49:48 AM [!] Learning rate: 2.5e-06
01/29/2023 01:49:54 AM  [*] Sun Jan 29 01:49:54 2023: Train Epoch: 2 [57600/76126 (76%)]	Loss: 0.158822 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.8769 & F1 0.9344 | AUC 0.9899
01/29/2023 01:50:00 AM  [*] Sun Jan 29 01:50:00 2023: Train Epoch: 2 [64000/76126 (84%)]	Loss: 0.203951 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.8030 & F1 0.8908 | AUC 0.9688
01/29/2023 01:50:06 AM  [*] Sun Jan 29 01:50:06 2023: Train Epoch: 2 [70400/76126 (92%)]	Loss: 0.204313 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.8082 & F1 0.8939 | AUC 0.9848
01/29/2023 01:50:14 AM  [*] Sun Jan 29 01:50:14 2023:    2    | Tr.loss: 0.171692 | Elapsed:   75.46  s | FPR 0.0003 -> TPR: 0.44 & F1: 0.61 | AUC: 0.9795
01/29/2023 01:50:14 AM  [*] Started epoch: 3
01/29/2023 01:50:14 AM  [*] Sun Jan 29 01:50:14 2023: Train Epoch: 3 [  0  /76126 (0 %)]	Loss: 0.258791 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.5000 & F1 0.6667 | AUC 0.9615
01/29/2023 01:50:20 AM  [*] Sun Jan 29 01:50:20 2023: Train Epoch: 3 [6400 /76126 (8 %)]	Loss: 0.218296 | Elapsed: 6.16s | FPR 0.0003 -> TPR 0.8507 & F1 0.9194 | AUC 0.9828
01/29/2023 01:50:26 AM  [*] Sun Jan 29 01:50:26 2023: Train Epoch: 3 [12800/76126 (17%)]	Loss: 0.097779 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.8308 & F1 0.9076 | AUC 0.9912
01/29/2023 01:50:32 AM  [*] Sun Jan 29 01:50:32 2023: Train Epoch: 3 [19200/76126 (25%)]	Loss: 0.161669 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.6984 & F1 0.8224 | AUC 0.9798
01/29/2023 01:50:39 AM  [*] Sun Jan 29 01:50:39 2023: Train Epoch: 3 [25600/76126 (34%)]	Loss: 0.146561 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.8657 & F1 0.9280 | AUC 0.9896
01/29/2023 01:50:45 AM  [*] Sun Jan 29 01:50:45 2023: Train Epoch: 3 [32000/76126 (42%)]	Loss: 0.184196 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.6462 & F1 0.7850 | AUC 0.9692
01/29/2023 01:50:51 AM  [*] Sun Jan 29 01:50:51 2023: Train Epoch: 3 [38400/76126 (50%)]	Loss: 0.085063 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.9737 & F1 0.9867 | AUC 0.9973
01/29/2023 01:50:52 AM [!] Learning rate: 2.5000000000000004e-07
01/29/2023 01:50:57 AM  [*] Sun Jan 29 01:50:57 2023: Train Epoch: 3 [44800/76126 (59%)]	Loss: 0.114214 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.9375 & F1 0.9677 | AUC 0.9922
01/29/2023 01:51:03 AM  [*] Sun Jan 29 01:51:03 2023: Train Epoch: 3 [51200/76126 (67%)]	Loss: 0.133559 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.7534 & F1 0.8594 | AUC 0.9827
01/29/2023 01:51:10 AM  [*] Sun Jan 29 01:51:10 2023: Train Epoch: 3 [57600/76126 (76%)]	Loss: 0.132731 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.9014 & F1 0.9481 | AUC 0.9874
01/29/2023 01:51:16 AM  [*] Sun Jan 29 01:51:16 2023: Train Epoch: 3 [64000/76126 (84%)]	Loss: 0.098443 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.8308 & F1 0.9076 | AUC 0.9903
01/29/2023 01:51:22 AM  [*] Sun Jan 29 01:51:22 2023: Train Epoch: 3 [70400/76126 (92%)]	Loss: 0.165825 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.7910 & F1 0.8833 | AUC 0.9751
01/29/2023 01:51:29 AM  [*] Sun Jan 29 01:51:29 2023:    3    | Tr.loss: 0.164444 | Elapsed:   75.73  s | FPR 0.0003 -> TPR: 0.46 & F1: 0.63 | AUC: 0.9813
01/29/2023 01:51:30 AM [!] Sun Jan 29 01:51:30 2023: Dumped results:
                model     : 1674953489-model.torch
		train time: 1674953489-trainTime.npy
		train losses: 1674953489-trainLosses.npy
		train AUC: 1674953489-auc.npy
		train F1s : 1674953489-trainF1s.npy
		train TPRs: 1674953489-trainTPRs.npy
01/29/2023 01:51:30 AM  [*] Evaluating pretrained model on test set...
01/29/2023 01:51:35 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0641 | F1: 0.1205
01/29/2023 01:51:35 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.0909 | F1: 0.1667
01/29/2023 01:51:35 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.1021 | F1: 0.1851
01/29/2023 01:51:35 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.1397 | F1: 0.2447
01/29/2023 01:51:35 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.2357 | F1: 0.3788
01/29/2023 01:51:35 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.3384 | F1: 0.4962
01/29/2023 01:51:35 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.4802 | F1: 0.6136
01/29/2023 01:51:35 AM  [*] Evaluating non_pretrained model on test set...
01/29/2023 01:51:40 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0591 | F1: 0.1117
01/29/2023 01:51:40 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1002 | F1: 0.1821
01/29/2023 01:51:40 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.1384 | F1: 0.2429
01/29/2023 01:51:40 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.1869 | F1: 0.3142
01/29/2023 01:51:40 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.2666 | F1: 0.4182
01/29/2023 01:51:40 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.3773 | F1: 0.5379
01/29/2023 01:51:40 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.5535 | F1: 0.6756
01/29/2023 01:51:40 AM  [*] Evaluating full_data model on test set...
01/29/2023 01:51:45 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0249 | F1: 0.0486
01/29/2023 01:51:45 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.2662 | F1: 0.4204
01/29/2023 01:51:45 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.3276 | F1: 0.4932
01/29/2023 01:51:45 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3623 | F1: 0.5309
01/29/2023 01:51:45 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.4276 | F1: 0.5955
01/29/2023 01:51:45 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.5655 | F1: 0.7108
01/29/2023 01:51:45 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.7968 | F1: 0.8468
01/29/2023 01:51:45 AM  [!] Running pre-training split 3/3
01/29/2023 01:51:48 AM  [!] Pre-training model...
01/29/2023 01:51:49 AM  [*] Masking sequences...
01/29/2023 01:52:11 AM  [*] Started epoch: 1
01/29/2023 01:52:12 AM  [*] Sun Jan 29 01:52:12 2023: Train Epoch: 1 [  0  /72319 (0 %)]	Loss: 426.813843 | Elapsed: 0.34s
01/29/2023 01:52:24 AM  [*] Sun Jan 29 01:52:24 2023: Train Epoch: 1 [6400 /72319 (9 %)]	Loss: 205.061371 | Elapsed: 12.33s
01/29/2023 01:52:36 AM  [*] Sun Jan 29 01:52:36 2023: Train Epoch: 1 [12800/72319 (18%)]	Loss: 206.318344 | Elapsed: 12.35s
01/29/2023 01:52:49 AM  [*] Sun Jan 29 01:52:49 2023: Train Epoch: 1 [19200/72319 (27%)]	Loss: 219.658203 | Elapsed: 12.47s
01/29/2023 01:53:02 AM  [*] Sun Jan 29 01:53:02 2023: Train Epoch: 1 [25600/72319 (35%)]	Loss: 189.560638 | Elapsed: 12.72s
01/29/2023 01:53:14 AM  [*] Sun Jan 29 01:53:14 2023: Train Epoch: 1 [32000/72319 (44%)]	Loss: 179.981522 | Elapsed: 12.60s
01/29/2023 01:53:27 AM  [*] Sun Jan 29 01:53:27 2023: Train Epoch: 1 [38400/72319 (53%)]	Loss: 193.980347 | Elapsed: 12.43s
01/29/2023 01:53:39 AM  [*] Sun Jan 29 01:53:39 2023: Train Epoch: 1 [44800/72319 (62%)]	Loss: 198.521072 | Elapsed: 12.41s
01/29/2023 01:53:51 AM  [*] Sun Jan 29 01:53:51 2023: Train Epoch: 1 [51200/72319 (71%)]	Loss: 191.412262 | Elapsed: 12.36s
01/29/2023 01:54:04 AM  [*] Sun Jan 29 01:54:04 2023: Train Epoch: 1 [57600/72319 (80%)]	Loss: 211.587830 | Elapsed: 12.55s
01/29/2023 01:54:16 AM  [*] Sun Jan 29 01:54:16 2023: Train Epoch: 1 [64000/72319 (88%)]	Loss: 160.047043 | Elapsed: 12.41s
01/29/2023 01:54:34 AM  [*] Sun Jan 29 01:54:34 2023: Train Epoch: 1 [70400/72319 (97%)]	Loss: 166.929138 | Elapsed: 17.59s
01/29/2023 01:54:41 AM  [*] Sun Jan 29 01:54:41 2023:    1    | Tr.loss: 206.557779 | Elapsed:  149.99  s
01/29/2023 01:54:41 AM  [*] Started epoch: 2
01/29/2023 01:54:42 AM  [*] Sun Jan 29 01:54:42 2023: Train Epoch: 2 [  0  /72319 (0 %)]	Loss: 179.967865 | Elapsed: 0.20s
01/29/2023 01:54:54 AM  [*] Sun Jan 29 01:54:54 2023: Train Epoch: 2 [6400 /72319 (9 %)]	Loss: 173.775085 | Elapsed: 12.67s
01/29/2023 01:55:07 AM  [*] Sun Jan 29 01:55:07 2023: Train Epoch: 2 [12800/72319 (18%)]	Loss: 215.082489 | Elapsed: 12.52s
01/29/2023 01:55:19 AM  [*] Sun Jan 29 01:55:19 2023: Train Epoch: 2 [19200/72319 (27%)]	Loss: 186.248016 | Elapsed: 12.47s
01/29/2023 01:55:32 AM  [*] Sun Jan 29 01:55:32 2023: Train Epoch: 2 [25600/72319 (35%)]	Loss: 180.445740 | Elapsed: 12.47s
01/29/2023 01:55:44 AM  [*] Sun Jan 29 01:55:44 2023: Train Epoch: 2 [32000/72319 (44%)]	Loss: 180.435898 | Elapsed: 12.49s
01/29/2023 01:55:57 AM  [*] Sun Jan 29 01:55:57 2023: Train Epoch: 2 [38400/72319 (53%)]	Loss: 194.226044 | Elapsed: 12.51s
01/29/2023 01:56:09 AM  [*] Sun Jan 29 01:56:09 2023: Train Epoch: 2 [44800/72319 (62%)]	Loss: 174.628494 | Elapsed: 12.56s
01/29/2023 01:56:22 AM  [*] Sun Jan 29 01:56:22 2023: Train Epoch: 2 [51200/72319 (71%)]	Loss: 186.066040 | Elapsed: 12.49s
01/29/2023 01:56:34 AM  [*] Sun Jan 29 01:56:34 2023: Train Epoch: 2 [57600/72319 (80%)]	Loss: 198.392944 | Elapsed: 12.53s
01/29/2023 01:56:47 AM  [*] Sun Jan 29 01:56:47 2023: Train Epoch: 2 [64000/72319 (88%)]	Loss: 170.265091 | Elapsed: 12.54s
01/29/2023 01:57:00 AM  [*] Sun Jan 29 01:57:00 2023: Train Epoch: 2 [70400/72319 (97%)]	Loss: 192.948029 | Elapsed: 12.60s
01/29/2023 01:57:05 AM  [*] Sun Jan 29 01:57:05 2023:    2    | Tr.loss: 186.903062 | Elapsed:  143.66  s
01/29/2023 01:57:05 AM  [*] Started epoch: 3
01/29/2023 01:57:05 AM  [*] Sun Jan 29 01:57:05 2023: Train Epoch: 3 [  0  /72319 (0 %)]	Loss: 191.641846 | Elapsed: 0.21s
01/29/2023 01:57:18 AM  [*] Sun Jan 29 01:57:18 2023: Train Epoch: 3 [6400 /72319 (9 %)]	Loss: 164.861511 | Elapsed: 12.58s
01/29/2023 01:57:31 AM  [*] Sun Jan 29 01:57:31 2023: Train Epoch: 3 [12800/72319 (18%)]	Loss: 182.057129 | Elapsed: 12.61s
01/29/2023 01:57:43 AM  [*] Sun Jan 29 01:57:43 2023: Train Epoch: 3 [19200/72319 (27%)]	Loss: 216.314255 | Elapsed: 12.51s
01/29/2023 01:57:56 AM  [*] Sun Jan 29 01:57:56 2023: Train Epoch: 3 [25600/72319 (35%)]	Loss: 157.554810 | Elapsed: 12.51s
01/29/2023 01:58:08 AM  [*] Sun Jan 29 01:58:08 2023: Train Epoch: 3 [32000/72319 (44%)]	Loss: 189.962372 | Elapsed: 12.52s
01/29/2023 01:58:21 AM  [*] Sun Jan 29 01:58:21 2023: Train Epoch: 3 [38400/72319 (53%)]	Loss: 178.564911 | Elapsed: 12.51s
01/29/2023 01:58:33 AM  [*] Sun Jan 29 01:58:33 2023: Train Epoch: 3 [44800/72319 (62%)]	Loss: 179.553711 | Elapsed: 12.43s
01/29/2023 01:58:45 AM  [*] Sun Jan 29 01:58:45 2023: Train Epoch: 3 [51200/72319 (71%)]	Loss: 154.627014 | Elapsed: 12.50s
01/29/2023 01:58:58 AM  [*] Sun Jan 29 01:58:58 2023: Train Epoch: 3 [57600/72319 (80%)]	Loss: 185.726562 | Elapsed: 12.48s
01/29/2023 01:59:11 AM  [*] Sun Jan 29 01:59:11 2023: Train Epoch: 3 [64000/72319 (88%)]	Loss: 162.477753 | Elapsed: 12.54s
01/29/2023 01:59:23 AM  [*] Sun Jan 29 01:59:23 2023: Train Epoch: 3 [70400/72319 (97%)]	Loss: 177.989426 | Elapsed: 12.54s
01/29/2023 01:59:29 AM  [*] Sun Jan 29 01:59:29 2023:    3    | Tr.loss: 182.003909 | Elapsed:  143.54  s
01/29/2023 01:59:29 AM  [*] Started epoch: 4
01/29/2023 01:59:29 AM  [*] Sun Jan 29 01:59:29 2023: Train Epoch: 4 [  0  /72319 (0 %)]	Loss: 184.783234 | Elapsed: 0.24s
01/29/2023 01:59:41 AM  [*] Sun Jan 29 01:59:41 2023: Train Epoch: 4 [6400 /72319 (9 %)]	Loss: 178.684982 | Elapsed: 12.53s
01/29/2023 01:59:54 AM  [*] Sun Jan 29 01:59:54 2023: Train Epoch: 4 [12800/72319 (18%)]	Loss: 182.043610 | Elapsed: 12.46s
01/29/2023 02:00:06 AM  [*] Sun Jan 29 02:00:06 2023: Train Epoch: 4 [19200/72319 (27%)]	Loss: 186.950851 | Elapsed: 12.52s
01/29/2023 02:00:19 AM  [*] Sun Jan 29 02:00:19 2023: Train Epoch: 4 [25600/72319 (35%)]	Loss: 196.720459 | Elapsed: 12.35s
01/29/2023 02:00:31 AM  [*] Sun Jan 29 02:00:31 2023: Train Epoch: 4 [32000/72319 (44%)]	Loss: 183.688171 | Elapsed: 12.42s
01/29/2023 02:00:44 AM  [*] Sun Jan 29 02:00:44 2023: Train Epoch: 4 [38400/72319 (53%)]	Loss: 174.363281 | Elapsed: 12.41s
01/29/2023 02:00:56 AM  [*] Sun Jan 29 02:00:56 2023: Train Epoch: 4 [44800/72319 (62%)]	Loss: 174.356995 | Elapsed: 12.38s
01/29/2023 02:01:08 AM  [*] Sun Jan 29 02:01:08 2023: Train Epoch: 4 [51200/72319 (71%)]	Loss: 161.303497 | Elapsed: 12.38s
01/29/2023 02:01:21 AM  [*] Sun Jan 29 02:01:21 2023: Train Epoch: 4 [57600/72319 (80%)]	Loss: 184.313156 | Elapsed: 12.42s
01/29/2023 02:01:33 AM  [*] Sun Jan 29 02:01:33 2023: Train Epoch: 4 [64000/72319 (88%)]	Loss: 194.020081 | Elapsed: 12.64s
01/29/2023 02:01:46 AM  [*] Sun Jan 29 02:01:46 2023: Train Epoch: 4 [70400/72319 (97%)]	Loss: 169.979523 | Elapsed: 12.84s
01/29/2023 02:01:53 AM  [*] Sun Jan 29 02:01:53 2023:    4    | Tr.loss: 179.379139 | Elapsed:  143.90  s
01/29/2023 02:01:53 AM  [*] Started epoch: 5
01/29/2023 02:01:53 AM  [*] Sun Jan 29 02:01:53 2023: Train Epoch: 5 [  0  /72319 (0 %)]	Loss: 176.558716 | Elapsed: 0.23s
01/29/2023 02:02:05 AM  [*] Sun Jan 29 02:02:05 2023: Train Epoch: 5 [6400 /72319 (9 %)]	Loss: 165.185181 | Elapsed: 12.63s
01/29/2023 02:02:18 AM  [*] Sun Jan 29 02:02:18 2023: Train Epoch: 5 [12800/72319 (18%)]	Loss: 165.897156 | Elapsed: 12.47s
01/29/2023 02:02:30 AM  [*] Sun Jan 29 02:02:30 2023: Train Epoch: 5 [19200/72319 (27%)]	Loss: 188.407562 | Elapsed: 12.40s
01/29/2023 02:02:43 AM  [*] Sun Jan 29 02:02:43 2023: Train Epoch: 5 [25600/72319 (35%)]	Loss: 162.939651 | Elapsed: 12.37s
01/29/2023 02:02:52 AM [!] Learning rate: 2.5e-05
01/29/2023 02:02:55 AM  [*] Sun Jan 29 02:02:55 2023: Train Epoch: 5 [32000/72319 (44%)]	Loss: 184.913940 | Elapsed: 12.43s
01/29/2023 02:03:07 AM  [*] Sun Jan 29 02:03:07 2023: Train Epoch: 5 [38400/72319 (53%)]	Loss: 193.282471 | Elapsed: 12.37s
01/29/2023 02:03:20 AM  [*] Sun Jan 29 02:03:20 2023: Train Epoch: 5 [44800/72319 (62%)]	Loss: 180.402557 | Elapsed: 12.37s
01/29/2023 02:03:32 AM  [*] Sun Jan 29 02:03:32 2023: Train Epoch: 5 [51200/72319 (71%)]	Loss: 167.971405 | Elapsed: 12.38s
01/29/2023 02:03:45 AM  [*] Sun Jan 29 02:03:45 2023: Train Epoch: 5 [57600/72319 (80%)]	Loss: 163.611969 | Elapsed: 12.44s
01/29/2023 02:03:57 AM  [*] Sun Jan 29 02:03:57 2023: Train Epoch: 5 [64000/72319 (88%)]	Loss: 159.929214 | Elapsed: 12.36s
01/29/2023 02:04:10 AM  [*] Sun Jan 29 02:04:10 2023: Train Epoch: 5 [70400/72319 (97%)]	Loss: 179.649017 | Elapsed: 12.51s
01/29/2023 02:04:15 AM  [*] Sun Jan 29 02:04:15 2023:    5    | Tr.loss: 177.546306 | Elapsed:  142.60  s
01/29/2023 02:04:15 AM  [*] Started epoch: 6
01/29/2023 02:04:15 AM  [*] Sun Jan 29 02:04:15 2023: Train Epoch: 6 [  0  /72319 (0 %)]	Loss: 215.397705 | Elapsed: 0.25s
01/29/2023 02:04:28 AM  [*] Sun Jan 29 02:04:28 2023: Train Epoch: 6 [6400 /72319 (9 %)]	Loss: 162.371063 | Elapsed: 12.52s
01/29/2023 02:04:40 AM  [*] Sun Jan 29 02:04:40 2023: Train Epoch: 6 [12800/72319 (18%)]	Loss: 162.383926 | Elapsed: 12.41s
01/29/2023 02:04:53 AM  [*] Sun Jan 29 02:04:53 2023: Train Epoch: 6 [19200/72319 (27%)]	Loss: 175.977905 | Elapsed: 12.54s
01/29/2023 02:05:05 AM  [*] Sun Jan 29 02:05:05 2023: Train Epoch: 6 [25600/72319 (35%)]	Loss: 173.570190 | Elapsed: 12.43s
01/29/2023 02:05:18 AM  [*] Sun Jan 29 02:05:18 2023: Train Epoch: 6 [32000/72319 (44%)]	Loss: 174.468857 | Elapsed: 12.44s
01/29/2023 02:05:30 AM  [*] Sun Jan 29 02:05:30 2023: Train Epoch: 6 [38400/72319 (53%)]	Loss: 177.093018 | Elapsed: 12.40s
01/29/2023 02:05:43 AM  [*] Sun Jan 29 02:05:43 2023: Train Epoch: 6 [44800/72319 (62%)]	Loss: 179.474411 | Elapsed: 12.42s
01/29/2023 02:05:55 AM  [*] Sun Jan 29 02:05:55 2023: Train Epoch: 6 [51200/72319 (71%)]	Loss: 158.803619 | Elapsed: 12.38s
01/29/2023 02:06:07 AM  [*] Sun Jan 29 02:06:07 2023: Train Epoch: 6 [57600/72319 (80%)]	Loss: 167.679611 | Elapsed: 12.43s
01/29/2023 02:06:20 AM  [*] Sun Jan 29 02:06:20 2023: Train Epoch: 6 [64000/72319 (88%)]	Loss: 174.615265 | Elapsed: 12.46s
01/29/2023 02:06:32 AM  [*] Sun Jan 29 02:06:32 2023: Train Epoch: 6 [70400/72319 (97%)]	Loss: 181.531342 | Elapsed: 12.43s
01/29/2023 02:06:38 AM  [*] Sun Jan 29 02:06:38 2023:    6    | Tr.loss: 176.691330 | Elapsed:  142.79  s
01/29/2023 02:06:38 AM  [*] Started epoch: 7
01/29/2023 02:06:38 AM  [*] Sun Jan 29 02:06:38 2023: Train Epoch: 7 [  0  /72319 (0 %)]	Loss: 178.950500 | Elapsed: 0.19s
01/29/2023 02:06:51 AM  [*] Sun Jan 29 02:06:51 2023: Train Epoch: 7 [6400 /72319 (9 %)]	Loss: 165.271835 | Elapsed: 12.58s
01/29/2023 02:07:03 AM  [*] Sun Jan 29 02:07:03 2023: Train Epoch: 7 [12800/72319 (18%)]	Loss: 170.569641 | Elapsed: 12.46s
01/29/2023 02:07:16 AM  [*] Sun Jan 29 02:07:16 2023: Train Epoch: 7 [19200/72319 (27%)]	Loss: 172.531006 | Elapsed: 12.56s
01/29/2023 02:07:28 AM  [*] Sun Jan 29 02:07:28 2023: Train Epoch: 7 [25600/72319 (35%)]	Loss: 181.391846 | Elapsed: 12.42s
01/29/2023 02:07:41 AM  [*] Sun Jan 29 02:07:41 2023: Train Epoch: 7 [32000/72319 (44%)]	Loss: 170.211731 | Elapsed: 12.37s
01/29/2023 02:07:53 AM  [*] Sun Jan 29 02:07:53 2023: Train Epoch: 7 [38400/72319 (53%)]	Loss: 163.546722 | Elapsed: 12.41s
01/29/2023 02:08:05 AM  [*] Sun Jan 29 02:08:05 2023: Train Epoch: 7 [44800/72319 (62%)]	Loss: 176.336365 | Elapsed: 12.41s
01/29/2023 02:08:18 AM  [*] Sun Jan 29 02:08:18 2023: Train Epoch: 7 [51200/72319 (71%)]	Loss: 178.140198 | Elapsed: 12.44s
01/29/2023 02:08:30 AM  [*] Sun Jan 29 02:08:30 2023: Train Epoch: 7 [57600/72319 (80%)]	Loss: 183.472260 | Elapsed: 12.44s
01/29/2023 02:08:43 AM  [*] Sun Jan 29 02:08:43 2023: Train Epoch: 7 [64000/72319 (88%)]	Loss: 177.494370 | Elapsed: 12.43s
01/29/2023 02:08:55 AM  [*] Sun Jan 29 02:08:55 2023: Train Epoch: 7 [70400/72319 (97%)]	Loss: 168.494247 | Elapsed: 12.51s
01/29/2023 02:09:01 AM  [*] Sun Jan 29 02:09:01 2023:    7    | Tr.loss: 176.488170 | Elapsed:  142.88  s
01/29/2023 02:09:01 AM  [*] Started epoch: 8
01/29/2023 02:09:01 AM  [*] Sun Jan 29 02:09:01 2023: Train Epoch: 8 [  0  /72319 (0 %)]	Loss: 177.945358 | Elapsed: 0.24s
01/29/2023 02:09:14 AM  [*] Sun Jan 29 02:09:14 2023: Train Epoch: 8 [6400 /72319 (9 %)]	Loss: 170.635223 | Elapsed: 12.59s
01/29/2023 02:09:26 AM  [*] Sun Jan 29 02:09:26 2023: Train Epoch: 8 [12800/72319 (18%)]	Loss: 173.886490 | Elapsed: 12.47s
01/29/2023 02:09:39 AM  [*] Sun Jan 29 02:09:39 2023: Train Epoch: 8 [19200/72319 (27%)]	Loss: 202.149094 | Elapsed: 12.55s
01/29/2023 02:09:51 AM  [*] Sun Jan 29 02:09:51 2023: Train Epoch: 8 [25600/72319 (35%)]	Loss: 190.364731 | Elapsed: 12.47s
01/29/2023 02:10:04 AM  [*] Sun Jan 29 02:10:04 2023: Train Epoch: 8 [32000/72319 (44%)]	Loss: 187.133209 | Elapsed: 12.46s
01/29/2023 02:10:16 AM  [*] Sun Jan 29 02:10:16 2023: Train Epoch: 8 [38400/72319 (53%)]	Loss: 187.476959 | Elapsed: 12.45s
01/29/2023 02:10:29 AM  [*] Sun Jan 29 02:10:29 2023: Train Epoch: 8 [44800/72319 (62%)]	Loss: 175.182907 | Elapsed: 12.52s
01/29/2023 02:10:41 AM  [*] Sun Jan 29 02:10:41 2023: Train Epoch: 8 [51200/72319 (71%)]	Loss: 170.755493 | Elapsed: 12.39s
01/29/2023 02:10:53 AM  [*] Sun Jan 29 02:10:53 2023: Train Epoch: 8 [57600/72319 (80%)]	Loss: 189.454865 | Elapsed: 12.48s
01/29/2023 02:11:06 AM  [*] Sun Jan 29 02:11:06 2023: Train Epoch: 8 [64000/72319 (88%)]	Loss: 178.825302 | Elapsed: 12.37s
01/29/2023 02:11:18 AM  [*] Sun Jan 29 02:11:18 2023: Train Epoch: 8 [70400/72319 (97%)]	Loss: 195.370117 | Elapsed: 12.43s
01/29/2023 02:11:24 AM  [*] Sun Jan 29 02:11:24 2023:    8    | Tr.loss: 176.216575 | Elapsed:  143.11  s
01/29/2023 02:11:24 AM  [*] Started epoch: 9
01/29/2023 02:11:24 AM  [*] Sun Jan 29 02:11:24 2023: Train Epoch: 9 [  0  /72319 (0 %)]	Loss: 182.734604 | Elapsed: 0.25s
01/29/2023 02:11:37 AM  [*] Sun Jan 29 02:11:37 2023: Train Epoch: 9 [6400 /72319 (9 %)]	Loss: 168.678558 | Elapsed: 12.61s
01/29/2023 02:11:49 AM  [*] Sun Jan 29 02:11:49 2023: Train Epoch: 9 [12800/72319 (18%)]	Loss: 176.092957 | Elapsed: 12.45s
01/29/2023 02:12:02 AM  [*] Sun Jan 29 02:12:02 2023: Train Epoch: 9 [19200/72319 (27%)]	Loss: 189.149597 | Elapsed: 12.46s
01/29/2023 02:12:14 AM  [*] Sun Jan 29 02:12:14 2023: Train Epoch: 9 [25600/72319 (35%)]	Loss: 171.583725 | Elapsed: 12.47s
01/29/2023 02:12:27 AM  [*] Sun Jan 29 02:12:27 2023: Train Epoch: 9 [32000/72319 (44%)]	Loss: 189.219330 | Elapsed: 12.41s
01/29/2023 02:12:39 AM  [*] Sun Jan 29 02:12:39 2023: Train Epoch: 9 [38400/72319 (53%)]	Loss: 181.307831 | Elapsed: 12.44s
01/29/2023 02:12:51 AM  [*] Sun Jan 29 02:12:51 2023: Train Epoch: 9 [44800/72319 (62%)]	Loss: 190.739105 | Elapsed: 12.44s
01/29/2023 02:13:04 AM  [*] Sun Jan 29 02:13:04 2023: Train Epoch: 9 [51200/72319 (71%)]	Loss: 186.839142 | Elapsed: 12.44s
01/29/2023 02:13:16 AM  [*] Sun Jan 29 02:13:16 2023: Train Epoch: 9 [57600/72319 (80%)]	Loss: 178.528900 | Elapsed: 12.43s
01/29/2023 02:13:24 AM [!] Learning rate: 2.5e-06
01/29/2023 02:13:29 AM  [*] Sun Jan 29 02:13:29 2023: Train Epoch: 9 [64000/72319 (88%)]	Loss: 188.439011 | Elapsed: 12.46s
01/29/2023 02:13:41 AM  [*] Sun Jan 29 02:13:41 2023: Train Epoch: 9 [70400/72319 (97%)]	Loss: 167.360718 | Elapsed: 12.46s
01/29/2023 02:13:47 AM  [*] Sun Jan 29 02:13:47 2023:    9    | Tr.loss: 176.024174 | Elapsed:  143.04  s
01/29/2023 02:13:47 AM  [*] Started epoch: 10
01/29/2023 02:13:47 AM  [*] Sun Jan 29 02:13:47 2023: Train Epoch: 10 [  0  /72319 (0 %)]	Loss: 157.672668 | Elapsed: 0.24s
01/29/2023 02:14:00 AM  [*] Sun Jan 29 02:14:00 2023: Train Epoch: 10 [6400 /72319 (9 %)]	Loss: 208.275055 | Elapsed: 12.53s
01/29/2023 02:14:12 AM  [*] Sun Jan 29 02:14:12 2023: Train Epoch: 10 [12800/72319 (18%)]	Loss: 164.624588 | Elapsed: 12.46s
01/29/2023 02:14:25 AM  [*] Sun Jan 29 02:14:25 2023: Train Epoch: 10 [19200/72319 (27%)]	Loss: 180.036530 | Elapsed: 12.47s
01/29/2023 02:14:37 AM  [*] Sun Jan 29 02:14:37 2023: Train Epoch: 10 [25600/72319 (35%)]	Loss: 166.296997 | Elapsed: 12.42s
01/29/2023 02:14:49 AM  [*] Sun Jan 29 02:14:49 2023: Train Epoch: 10 [32000/72319 (44%)]	Loss: 186.995728 | Elapsed: 12.37s
01/29/2023 02:15:02 AM  [*] Sun Jan 29 02:15:02 2023: Train Epoch: 10 [38400/72319 (53%)]	Loss: 194.899628 | Elapsed: 12.42s
01/29/2023 02:15:14 AM  [*] Sun Jan 29 02:15:14 2023: Train Epoch: 10 [44800/72319 (62%)]	Loss: 171.056793 | Elapsed: 12.44s
01/29/2023 02:15:27 AM  [*] Sun Jan 29 02:15:27 2023: Train Epoch: 10 [51200/72319 (71%)]	Loss: 168.338837 | Elapsed: 12.38s
01/29/2023 02:15:39 AM  [*] Sun Jan 29 02:15:39 2023: Train Epoch: 10 [57600/72319 (80%)]	Loss: 179.842758 | Elapsed: 12.37s
01/29/2023 02:15:51 AM  [*] Sun Jan 29 02:15:51 2023: Train Epoch: 10 [64000/72319 (88%)]	Loss: 192.026550 | Elapsed: 12.40s
01/29/2023 02:16:04 AM  [*] Sun Jan 29 02:16:04 2023: Train Epoch: 10 [70400/72319 (97%)]	Loss: 174.469070 | Elapsed: 12.39s
01/29/2023 02:16:10 AM  [*] Sun Jan 29 02:16:10 2023:   10    | Tr.loss: 175.820248 | Elapsed:  142.57  s
01/29/2023 02:16:10 AM [!] Sun Jan 29 02:16:10 2023: Dumped results:
                model     : 1674954970-model.torch
		train time: 1674954970-trainTime.npy
		train losses: 1674954970-trainLosses.npy
		train AUC: 1674954970-auc.npy
01/29/2023 02:16:13 AM  [!] Training pretrained model on downstream task...
01/29/2023 02:16:13 AM  [*] Started epoch: 1
01/29/2023 02:16:13 AM  [*] Sun Jan 29 02:16:13 2023: Train Epoch: 1 [  0  /3807  (0 %)]	Loss: 3.818436 | Elapsed: 0.25s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.3086
01/29/2023 02:16:19 AM  [*] Sun Jan 29 02:16:19 2023:    1    | Tr.loss: 0.865517 | Elapsed:   5.72   s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.6534
01/29/2023 02:16:19 AM  [*] Started epoch: 2
01/29/2023 02:16:19 AM  [*] Sun Jan 29 02:16:19 2023: Train Epoch: 2 [  0  /3807  (0 %)]	Loss: 0.740081 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.1163 & F1 0.2083 | AUC 0.5903
01/29/2023 02:16:24 AM  [*] Sun Jan 29 02:16:24 2023:    2    | Tr.loss: 0.510835 | Elapsed:   5.52   s | FPR 0.0003 -> TPR: 0.06 & F1: 0.10 | AUC: 0.7373
01/29/2023 02:16:24 AM  [*] Started epoch: 3
01/29/2023 02:16:24 AM  [*] Sun Jan 29 02:16:24 2023: Train Epoch: 3 [  0  /3807  (0 %)]	Loss: 0.472311 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.3000 & F1 0.4615 | AUC 0.6814
01/29/2023 02:16:30 AM  [*] Sun Jan 29 02:16:30 2023:    3    | Tr.loss: 0.482143 | Elapsed:   5.57   s | FPR 0.0003 -> TPR: 0.08 & F1: 0.14 | AUC: 0.7652
01/29/2023 02:16:30 AM [!] Sun Jan 29 02:16:30 2023: Dumped results:
                model     : 1674954990-model.torch
		train time: 1674954990-trainTime.npy
		train losses: 1674954990-trainLosses.npy
		train AUC: 1674954990-auc.npy
		train F1s : 1674954990-trainF1s.npy
		train TPRs: 1674954990-trainTPRs.npy
01/29/2023 02:16:30 AM  [!] Training non_pretrained model on downstream task...
01/29/2023 02:16:31 AM  [*] Started epoch: 1
01/29/2023 02:16:31 AM  [*] Sun Jan 29 02:16:31 2023: Train Epoch: 1 [  0  /3807  (0 %)]	Loss: 2.213147 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0227 & F1 0.0444 | AUC 0.4477
01/29/2023 02:16:34 AM  [*] Sun Jan 29 02:16:34 2023:    1    | Tr.loss: 0.714047 | Elapsed:   3.79   s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.6660
01/29/2023 02:16:34 AM  [*] Started epoch: 2
01/29/2023 02:16:35 AM  [*] Sun Jan 29 02:16:35 2023: Train Epoch: 2 [  0  /3807  (0 %)]	Loss: 0.437015 | Elapsed: 0.05s | FPR 0.0003 -> TPR 0.5641 & F1 0.7213 | AUC 0.8728
01/29/2023 02:16:38 AM  [*] Sun Jan 29 02:16:38 2023:    2    | Tr.loss: 0.444893 | Elapsed:   3.76   s | FPR 0.0003 -> TPR: 0.09 & F1: 0.16 | AUC: 0.8354
01/29/2023 02:16:38 AM  [*] Started epoch: 3
01/29/2023 02:16:38 AM  [*] Sun Jan 29 02:16:38 2023: Train Epoch: 3 [  0  /3807  (0 %)]	Loss: 0.353461 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.4419 & F1 0.6129 | AUC 0.9158
01/29/2023 02:16:42 AM  [*] Sun Jan 29 02:16:42 2023:    3    | Tr.loss: 0.376795 | Elapsed:   3.76   s | FPR 0.0003 -> TPR: 0.00 & F1: 0.01 | AUC: 0.8870
01/29/2023 02:16:42 AM [!] Sun Jan 29 02:16:42 2023: Dumped results:
                model     : 1674955002-model.torch
		train time: 1674955002-trainTime.npy
		train losses: 1674955002-trainLosses.npy
		train AUC: 1674955002-auc.npy
		train F1s : 1674955002-trainF1s.npy
		train TPRs: 1674955002-trainTPRs.npy
01/29/2023 02:16:42 AM  [!] Training full_data model on downstream task...
01/29/2023 02:16:43 AM  [*] Started epoch: 1
01/29/2023 02:16:43 AM  [*] Sun Jan 29 02:16:43 2023: Train Epoch: 1 [  0  /76126 (0 %)]	Loss: 1.584947 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.1522 & F1 0.2642 | AUC 0.5761
01/29/2023 02:16:49 AM  [*] Sun Jan 29 02:16:49 2023: Train Epoch: 1 [6400 /76126 (8 %)]	Loss: 0.480208 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.3429 & F1 0.5106 | AUC 0.6857
01/29/2023 02:16:55 AM  [*] Sun Jan 29 02:16:55 2023: Train Epoch: 1 [12800/76126 (17%)]	Loss: 0.447667 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.5143 & F1 0.6792 | AUC 0.8243
01/29/2023 02:17:02 AM  [*] Sun Jan 29 02:17:02 2023: Train Epoch: 1 [19200/76126 (25%)]	Loss: 0.326929 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.5781 & F1 0.7327 | AUC 0.9440
01/29/2023 02:17:08 AM  [*] Sun Jan 29 02:17:08 2023: Train Epoch: 1 [25600/76126 (34%)]	Loss: 0.360975 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.5593 & F1 0.7174 | AUC 0.9157
01/29/2023 02:17:14 AM  [*] Sun Jan 29 02:17:14 2023: Train Epoch: 1 [32000/76126 (42%)]	Loss: 0.258695 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.7143 & F1 0.8333 | AUC 0.9560
01/29/2023 02:17:20 AM  [*] Sun Jan 29 02:17:20 2023: Train Epoch: 1 [38400/76126 (50%)]	Loss: 0.231835 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.7733 & F1 0.8722 | AUC 0.9552
01/29/2023 02:17:27 AM  [*] Sun Jan 29 02:17:27 2023: Train Epoch: 1 [44800/76126 (59%)]	Loss: 0.218821 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.7846 & F1 0.8793 | AUC 0.9789
01/29/2023 02:17:33 AM  [*] Sun Jan 29 02:17:33 2023: Train Epoch: 1 [51200/76126 (67%)]	Loss: 0.155447 | Elapsed: 6.27s | FPR 0.0003 -> TPR 0.7656 & F1 0.8673 | AUC 0.9783
01/29/2023 02:17:39 AM  [*] Sun Jan 29 02:17:39 2023: Train Epoch: 1 [57600/76126 (76%)]	Loss: 0.211934 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.7794 & F1 0.8760 | AUC 0.9747
01/29/2023 02:17:45 AM [!] Learning rate: 2.5e-05
01/29/2023 02:17:45 AM  [*] Sun Jan 29 02:17:45 2023: Train Epoch: 1 [64000/76126 (84%)]	Loss: 0.225370 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.7692 & F1 0.8696 | AUC 0.9719
01/29/2023 02:17:51 AM  [*] Sun Jan 29 02:17:51 2023: Train Epoch: 1 [70400/76126 (92%)]	Loss: 0.157287 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.9365 & F1 0.9672 | AUC 0.9936
01/29/2023 02:17:59 AM  [*] Sun Jan 29 02:17:59 2023:    1    | Tr.loss: 0.295982 | Elapsed:   75.96  s | FPR 0.0003 -> TPR: 0.16 & F1: 0.28 | AUC: 0.9348
01/29/2023 02:17:59 AM  [*] Started epoch: 2
01/29/2023 02:17:59 AM  [*] Sun Jan 29 02:17:59 2023: Train Epoch: 2 [  0  /76126 (0 %)]	Loss: 0.202793 | Elapsed: 0.12s | FPR 0.0003 -> TPR 0.7955 & F1 0.8861 | AUC 0.9716
01/29/2023 02:18:05 AM  [*] Sun Jan 29 02:18:05 2023: Train Epoch: 2 [6400 /76126 (8 %)]	Loss: 0.157151 | Elapsed: 6.27s | FPR 0.0003 -> TPR 0.9130 & F1 0.9545 | AUC 0.9776
01/29/2023 02:18:11 AM  [*] Sun Jan 29 02:18:11 2023: Train Epoch: 2 [12800/76126 (17%)]	Loss: 0.218624 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.8088 & F1 0.8943 | AUC 0.9697
01/29/2023 02:18:18 AM  [*] Sun Jan 29 02:18:18 2023: Train Epoch: 2 [19200/76126 (25%)]	Loss: 0.249252 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.8657 & F1 0.9280 | AUC 0.9778
01/29/2023 02:18:24 AM  [*] Sun Jan 29 02:18:24 2023: Train Epoch: 2 [25600/76126 (34%)]	Loss: 0.262040 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.7727 & F1 0.8718 | AUC 0.9617
01/29/2023 02:18:30 AM  [*] Sun Jan 29 02:18:30 2023: Train Epoch: 2 [32000/76126 (42%)]	Loss: 0.106595 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.8923 & F1 0.9431 | AUC 0.9859
01/29/2023 02:18:36 AM  [*] Sun Jan 29 02:18:36 2023: Train Epoch: 2 [38400/76126 (50%)]	Loss: 0.148655 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.7746 & F1 0.8730 | AUC 0.9801
01/29/2023 02:18:43 AM  [*] Sun Jan 29 02:18:43 2023: Train Epoch: 2 [44800/76126 (59%)]	Loss: 0.180587 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.8806 & F1 0.9365 | AUC 0.9869
01/29/2023 02:18:49 AM  [*] Sun Jan 29 02:18:49 2023: Train Epoch: 2 [51200/76126 (67%)]	Loss: 0.138894 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.8784 & F1 0.9353 | AUC 0.9844
01/29/2023 02:18:49 AM [!] Learning rate: 2.5e-06
01/29/2023 02:18:55 AM  [*] Sun Jan 29 02:18:55 2023: Train Epoch: 2 [57600/76126 (76%)]	Loss: 0.136130 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.9054 & F1 0.9504 | AUC 0.9875
01/29/2023 02:19:01 AM  [*] Sun Jan 29 02:19:01 2023: Train Epoch: 2 [64000/76126 (84%)]	Loss: 0.115061 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.8000 & F1 0.8889 | AUC 0.9855
01/29/2023 02:19:07 AM  [*] Sun Jan 29 02:19:07 2023: Train Epoch: 2 [70400/76126 (92%)]	Loss: 0.145163 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.9605 & F1 0.9799 | AUC 0.9907
01/29/2023 02:19:15 AM  [*] Sun Jan 29 02:19:15 2023:    2    | Tr.loss: 0.167877 | Elapsed:   76.07  s | FPR 0.0003 -> TPR: 0.48 & F1: 0.65 | AUC: 0.9805
01/29/2023 02:19:15 AM  [*] Started epoch: 3
01/29/2023 02:19:15 AM  [*] Sun Jan 29 02:19:15 2023: Train Epoch: 3 [  0  /76126 (0 %)]	Loss: 0.174313 | Elapsed: 0.12s | FPR 0.0003 -> TPR 0.8750 & F1 0.9333 | AUC 0.9818
01/29/2023 02:19:21 AM  [*] Sun Jan 29 02:19:21 2023: Train Epoch: 3 [6400 /76126 (8 %)]	Loss: 0.171284 | Elapsed: 6.32s | FPR 0.0003 -> TPR 0.9155 & F1 0.9559 | AUC 0.9845
01/29/2023 02:19:28 AM  [*] Sun Jan 29 02:19:28 2023: Train Epoch: 3 [12800/76126 (17%)]	Loss: 0.331268 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.7183 & F1 0.8361 | AUC 0.9563
01/29/2023 02:19:34 AM  [*] Sun Jan 29 02:19:34 2023: Train Epoch: 3 [19200/76126 (25%)]	Loss: 0.110739 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.8955 & F1 0.9449 | AUC 0.9891
01/29/2023 02:19:40 AM  [*] Sun Jan 29 02:19:40 2023: Train Epoch: 3 [25600/76126 (34%)]	Loss: 0.170423 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.8939 & F1 0.9440 | AUC 0.9933
01/29/2023 02:19:46 AM  [*] Sun Jan 29 02:19:46 2023: Train Epoch: 3 [32000/76126 (42%)]	Loss: 0.215693 | Elapsed: 6.27s | FPR 0.0003 -> TPR 0.6522 & F1 0.7895 | AUC 0.9645
01/29/2023 02:19:53 AM  [*] Sun Jan 29 02:19:53 2023: Train Epoch: 3 [38400/76126 (50%)]	Loss: 0.091517 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.8000 & F1 0.8889 | AUC 0.9908
01/29/2023 02:19:54 AM [!] Learning rate: 2.5000000000000004e-07
01/29/2023 02:19:59 AM  [*] Sun Jan 29 02:19:59 2023: Train Epoch: 3 [44800/76126 (59%)]	Loss: 0.071978 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.9444 & F1 0.9714 | AUC 0.9926
01/29/2023 02:20:05 AM  [*] Sun Jan 29 02:20:05 2023: Train Epoch: 3 [51200/76126 (67%)]	Loss: 0.156781 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.8154 & F1 0.8983 | AUC 0.9780
01/29/2023 02:20:11 AM  [*] Sun Jan 29 02:20:11 2023: Train Epoch: 3 [57600/76126 (76%)]	Loss: 0.146846 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.8732 & F1 0.9323 | AUC 0.9849
01/29/2023 02:20:17 AM  [*] Sun Jan 29 02:20:17 2023: Train Epoch: 3 [64000/76126 (84%)]	Loss: 0.157249 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.7966 & F1 0.8868 | AUC 0.9884
01/29/2023 02:20:24 AM  [*] Sun Jan 29 02:20:24 2023: Train Epoch: 3 [70400/76126 (92%)]	Loss: 0.187939 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.7183 & F1 0.8361 | AUC 0.9767
01/29/2023 02:20:31 AM  [*] Sun Jan 29 02:20:31 2023:    3    | Tr.loss: 0.161471 | Elapsed:   76.15  s | FPR 0.0003 -> TPR: 0.51 & F1: 0.67 | AUC: 0.9819
01/29/2023 02:20:31 AM [!] Sun Jan 29 02:20:31 2023: Dumped results:
                model     : 1674955231-model.torch
		train time: 1674955231-trainTime.npy
		train losses: 1674955231-trainLosses.npy
		train AUC: 1674955231-auc.npy
		train F1s : 1674955231-trainF1s.npy
		train TPRs: 1674955231-trainTPRs.npy
01/29/2023 02:20:31 AM  [*] Evaluating pretrained model on test set...
01/29/2023 02:20:37 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0031 | F1: 0.0061
01/29/2023 02:20:37 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.0911 | F1: 0.1670
01/29/2023 02:20:37 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.1149 | F1: 0.2059
01/29/2023 02:20:37 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.1439 | F1: 0.2510
01/29/2023 02:20:37 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.2149 | F1: 0.3514
01/29/2023 02:20:37 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.2970 | F1: 0.4492
01/29/2023 02:20:37 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.4837 | F1: 0.6167
01/29/2023 02:20:37 AM  [*] Evaluating non_pretrained model on test set...
01/29/2023 02:20:42 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0256 | F1: 0.0500
01/29/2023 02:20:42 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1316 | F1: 0.2325
01/29/2023 02:20:42 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.1647 | F1: 0.2827
01/29/2023 02:20:42 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.2114 | F1: 0.3483
01/29/2023 02:20:42 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.2704 | F1: 0.4229
01/29/2023 02:20:42 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.3599 | F1: 0.5196
01/29/2023 02:20:42 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.5102 | F1: 0.6396
01/29/2023 02:20:42 AM  [*] Evaluating full_data model on test set...
01/29/2023 02:20:47 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.1335 | F1: 0.2355
01/29/2023 02:20:47 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.2752 | F1: 0.4316
01/29/2023 02:20:47 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.3698 | F1: 0.5396
01/29/2023 02:20:47 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3850 | F1: 0.5549
01/29/2023 02:20:47 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.4207 | F1: 0.5887
01/29/2023 02:20:47 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.5356 | F1: 0.6862
01/29/2023 02:20:47 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.8093 | F1: 0.8544
01/29/2023 02:20:47 AM  [!] Finished pre-training evaluation over 3 splits! Saved metrics to:
	C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.95_1674950078/metrics_MaskedLanguageModel_nSplits_3_limit_None.json
01/29/2023 02:20:47 AM  [!] Starting Masked Language Model evaluation over 3 splits!
01/29/2023 02:20:47 AM  [!] Loaded data and vocab. X train size: (76126, 512), X test size: (17407, 512), vocab size: 50002
01/29/2023 02:20:47 AM  [!] Initiating Self-Supervised Learning Pretraining
     Language Modeling MaskedLanguageModel
     Model TransformerEncoderLM with config:
	{'vocabSize': 50002, 'maxLen': 512, 'dModel': 64, 'nHeads': 8, 'dHidden': 256, 'nLayers': 2, 'numClasses': 1, 'hiddenNeurons': [64], 'dropout': 0.3}

01/29/2023 02:20:47 AM  [!] Running pre-training split 1/3
01/29/2023 02:20:50 AM  [!] Pre-training model...
01/29/2023 02:20:50 AM  [*] Masking sequences...
01/29/2023 02:21:13 AM  [*] Started epoch: 1
01/29/2023 02:21:14 AM  [*] Sun Jan 29 02:21:14 2023: Train Epoch: 1 [  0  /73842 (0 %)]	Loss: 399.803955 | Elapsed: 0.39s
01/29/2023 02:21:26 AM  [*] Sun Jan 29 02:21:26 2023: Train Epoch: 1 [6400 /73842 (9 %)]	Loss: 261.936554 | Elapsed: 12.32s
01/29/2023 02:21:39 AM  [*] Sun Jan 29 02:21:39 2023: Train Epoch: 1 [12800/73842 (17%)]	Loss: 212.806427 | Elapsed: 12.40s
01/29/2023 02:21:51 AM  [*] Sun Jan 29 02:21:51 2023: Train Epoch: 1 [19200/73842 (26%)]	Loss: 208.074387 | Elapsed: 12.38s
01/29/2023 02:22:03 AM  [*] Sun Jan 29 02:22:03 2023: Train Epoch: 1 [25600/73842 (35%)]	Loss: 212.899017 | Elapsed: 12.40s
01/29/2023 02:22:16 AM  [*] Sun Jan 29 02:22:16 2023: Train Epoch: 1 [32000/73842 (43%)]	Loss: 220.882812 | Elapsed: 12.41s
01/29/2023 02:22:28 AM  [*] Sun Jan 29 02:22:28 2023: Train Epoch: 1 [38400/73842 (52%)]	Loss: 207.718643 | Elapsed: 12.39s
01/29/2023 02:22:40 AM  [*] Sun Jan 29 02:22:40 2023: Train Epoch: 1 [44800/73842 (61%)]	Loss: 207.841461 | Elapsed: 12.38s
01/29/2023 02:22:53 AM  [*] Sun Jan 29 02:22:53 2023: Train Epoch: 1 [51200/73842 (69%)]	Loss: 212.332184 | Elapsed: 12.34s
01/29/2023 02:23:05 AM  [*] Sun Jan 29 02:23:05 2023: Train Epoch: 1 [57600/73842 (78%)]	Loss: 214.439865 | Elapsed: 12.38s
01/29/2023 02:23:18 AM  [*] Sun Jan 29 02:23:18 2023: Train Epoch: 1 [64000/73842 (87%)]	Loss: 181.284012 | Elapsed: 12.46s
01/29/2023 02:23:36 AM  [*] Sun Jan 29 02:23:36 2023: Train Epoch: 1 [70400/73842 (95%)]	Loss: 177.346649 | Elapsed: 18.01s
01/29/2023 02:23:47 AM  [*] Sun Jan 29 02:23:47 2023:    1    | Tr.loss: 204.871474 | Elapsed:  153.66  s
01/29/2023 02:23:47 AM  [*] Started epoch: 2
01/29/2023 02:23:47 AM  [*] Sun Jan 29 02:23:47 2023: Train Epoch: 2 [  0  /73842 (0 %)]	Loss: 194.752975 | Elapsed: 0.21s
01/29/2023 02:24:00 AM  [*] Sun Jan 29 02:24:00 2023: Train Epoch: 2 [6400 /73842 (9 %)]	Loss: 172.705811 | Elapsed: 12.50s
01/29/2023 02:24:12 AM  [*] Sun Jan 29 02:24:12 2023: Train Epoch: 2 [12800/73842 (17%)]	Loss: 188.900604 | Elapsed: 12.52s
01/29/2023 02:24:25 AM  [*] Sun Jan 29 02:24:25 2023: Train Epoch: 2 [19200/73842 (26%)]	Loss: 204.571564 | Elapsed: 12.48s
01/29/2023 02:24:37 AM  [*] Sun Jan 29 02:24:37 2023: Train Epoch: 2 [25600/73842 (35%)]	Loss: 175.839172 | Elapsed: 12.48s
01/29/2023 02:24:50 AM  [*] Sun Jan 29 02:24:50 2023: Train Epoch: 2 [32000/73842 (43%)]	Loss: 190.531998 | Elapsed: 12.45s
01/29/2023 02:25:02 AM  [*] Sun Jan 29 02:25:02 2023: Train Epoch: 2 [38400/73842 (52%)]	Loss: 190.860901 | Elapsed: 12.45s
01/29/2023 02:25:15 AM  [*] Sun Jan 29 02:25:15 2023: Train Epoch: 2 [44800/73842 (61%)]	Loss: 205.640778 | Elapsed: 12.43s
01/29/2023 02:25:27 AM  [*] Sun Jan 29 02:25:27 2023: Train Epoch: 2 [51200/73842 (69%)]	Loss: 187.991776 | Elapsed: 12.49s
01/29/2023 02:25:40 AM  [*] Sun Jan 29 02:25:40 2023: Train Epoch: 2 [57600/73842 (78%)]	Loss: 184.869431 | Elapsed: 12.48s
01/29/2023 02:25:52 AM  [*] Sun Jan 29 02:25:52 2023: Train Epoch: 2 [64000/73842 (87%)]	Loss: 172.736389 | Elapsed: 12.46s
01/29/2023 02:26:04 AM  [*] Sun Jan 29 02:26:04 2023: Train Epoch: 2 [70400/73842 (95%)]	Loss: 194.342773 | Elapsed: 12.46s
01/29/2023 02:26:13 AM  [*] Sun Jan 29 02:26:13 2023:    2    | Tr.loss: 184.765150 | Elapsed:  146.07  s
01/29/2023 02:26:13 AM  [*] Started epoch: 3
01/29/2023 02:26:13 AM  [*] Sun Jan 29 02:26:13 2023: Train Epoch: 3 [  0  /73842 (0 %)]	Loss: 172.370407 | Elapsed: 0.22s
01/29/2023 02:26:26 AM  [*] Sun Jan 29 02:26:26 2023: Train Epoch: 3 [6400 /73842 (9 %)]	Loss: 180.175674 | Elapsed: 12.46s
01/29/2023 02:26:38 AM  [*] Sun Jan 29 02:26:38 2023: Train Epoch: 3 [12800/73842 (17%)]	Loss: 173.641388 | Elapsed: 12.61s
01/29/2023 02:26:51 AM  [*] Sun Jan 29 02:26:51 2023: Train Epoch: 3 [19200/73842 (26%)]	Loss: 173.353836 | Elapsed: 12.47s
01/29/2023 02:27:03 AM  [*] Sun Jan 29 02:27:03 2023: Train Epoch: 3 [25600/73842 (35%)]	Loss: 173.539825 | Elapsed: 12.40s
01/29/2023 02:27:16 AM  [*] Sun Jan 29 02:27:16 2023: Train Epoch: 3 [32000/73842 (43%)]	Loss: 185.031464 | Elapsed: 12.46s
01/29/2023 02:27:28 AM  [*] Sun Jan 29 02:27:28 2023: Train Epoch: 3 [38400/73842 (52%)]	Loss: 204.879028 | Elapsed: 12.49s
01/29/2023 02:27:41 AM  [*] Sun Jan 29 02:27:41 2023: Train Epoch: 3 [44800/73842 (61%)]	Loss: 188.256897 | Elapsed: 12.37s
01/29/2023 02:27:53 AM  [*] Sun Jan 29 02:27:53 2023: Train Epoch: 3 [51200/73842 (69%)]	Loss: 178.099274 | Elapsed: 12.46s
01/29/2023 02:28:06 AM  [*] Sun Jan 29 02:28:06 2023: Train Epoch: 3 [57600/73842 (78%)]	Loss: 159.055298 | Elapsed: 12.45s
01/29/2023 02:28:18 AM  [*] Sun Jan 29 02:28:18 2023: Train Epoch: 3 [64000/73842 (87%)]	Loss: 162.187927 | Elapsed: 12.41s
01/29/2023 02:28:30 AM  [*] Sun Jan 29 02:28:30 2023: Train Epoch: 3 [70400/73842 (95%)]	Loss: 173.474380 | Elapsed: 12.51s
01/29/2023 02:28:39 AM  [*] Sun Jan 29 02:28:39 2023:    3    | Tr.loss: 179.659496 | Elapsed:  145.91  s
01/29/2023 02:28:39 AM  [*] Started epoch: 4
01/29/2023 02:28:39 AM  [*] Sun Jan 29 02:28:39 2023: Train Epoch: 4 [  0  /73842 (0 %)]	Loss: 159.707458 | Elapsed: 0.22s
01/29/2023 02:28:52 AM  [*] Sun Jan 29 02:28:52 2023: Train Epoch: 4 [6400 /73842 (9 %)]	Loss: 177.841919 | Elapsed: 12.46s
01/29/2023 02:29:04 AM  [*] Sun Jan 29 02:29:04 2023: Train Epoch: 4 [12800/73842 (17%)]	Loss: 170.244904 | Elapsed: 12.54s
01/29/2023 02:29:18 AM  [*] Sun Jan 29 02:29:18 2023: Train Epoch: 4 [19200/73842 (26%)]	Loss: 175.663040 | Elapsed: 13.67s
01/29/2023 02:29:34 AM  [*] Sun Jan 29 02:29:34 2023: Train Epoch: 4 [25600/73842 (35%)]	Loss: 180.038269 | Elapsed: 16.37s
01/29/2023 02:29:51 AM  [*] Sun Jan 29 02:29:51 2023: Train Epoch: 4 [32000/73842 (43%)]	Loss: 171.925461 | Elapsed: 16.28s
01/29/2023 02:30:07 AM  [*] Sun Jan 29 02:30:07 2023: Train Epoch: 4 [38400/73842 (52%)]	Loss: 181.260864 | Elapsed: 16.21s
01/29/2023 02:30:23 AM  [*] Sun Jan 29 02:30:23 2023: Train Epoch: 4 [44800/73842 (61%)]	Loss: 181.052277 | Elapsed: 16.18s
01/29/2023 02:30:39 AM  [*] Sun Jan 29 02:30:39 2023: Train Epoch: 4 [51200/73842 (69%)]	Loss: 181.445099 | Elapsed: 16.46s
01/29/2023 02:30:56 AM  [*] Sun Jan 29 02:30:56 2023: Train Epoch: 4 [57600/73842 (78%)]	Loss: 206.704071 | Elapsed: 16.45s
01/29/2023 02:31:12 AM  [*] Sun Jan 29 02:31:12 2023: Train Epoch: 4 [64000/73842 (87%)]	Loss: 181.493835 | Elapsed: 16.28s
01/29/2023 02:31:29 AM  [*] Sun Jan 29 02:31:29 2023: Train Epoch: 4 [70400/73842 (95%)]	Loss: 167.072693 | Elapsed: 16.52s
01/29/2023 02:31:39 AM  [*] Sun Jan 29 02:31:39 2023:    4    | Tr.loss: 177.029893 | Elapsed:  180.35  s
01/29/2023 02:31:39 AM  [*] Started epoch: 5
01/29/2023 02:31:40 AM  [*] Sun Jan 29 02:31:40 2023: Train Epoch: 5 [  0  /73842 (0 %)]	Loss: 186.246887 | Elapsed: 0.22s
01/29/2023 02:31:52 AM  [*] Sun Jan 29 02:31:52 2023: Train Epoch: 5 [6400 /73842 (9 %)]	Loss: 182.493011 | Elapsed: 12.44s
01/29/2023 02:32:05 AM  [*] Sun Jan 29 02:32:05 2023: Train Epoch: 5 [12800/73842 (17%)]	Loss: 174.225189 | Elapsed: 12.47s
01/29/2023 02:32:17 AM  [*] Sun Jan 29 02:32:17 2023: Train Epoch: 5 [19200/73842 (26%)]	Loss: 188.936249 | Elapsed: 12.43s
01/29/2023 02:32:30 AM [!] Learning rate: 2.5e-05
01/29/2023 02:32:33 AM  [*] Sun Jan 29 02:32:33 2023: Train Epoch: 5 [25600/73842 (35%)]	Loss: 159.790710 | Elapsed: 15.80s
01/29/2023 02:32:49 AM  [*] Sun Jan 29 02:32:49 2023: Train Epoch: 5 [32000/73842 (43%)]	Loss: 154.569000 | Elapsed: 16.20s
01/29/2023 02:33:05 AM  [*] Sun Jan 29 02:33:05 2023: Train Epoch: 5 [38400/73842 (52%)]	Loss: 179.950714 | Elapsed: 16.29s
01/29/2023 02:33:22 AM  [*] Sun Jan 29 02:33:22 2023: Train Epoch: 5 [44800/73842 (61%)]	Loss: 193.278549 | Elapsed: 16.65s
01/29/2023 02:33:38 AM  [*] Sun Jan 29 02:33:38 2023: Train Epoch: 5 [51200/73842 (69%)]	Loss: 186.772705 | Elapsed: 16.41s
01/29/2023 02:33:55 AM  [*] Sun Jan 29 02:33:55 2023: Train Epoch: 5 [57600/73842 (78%)]	Loss: 177.370071 | Elapsed: 16.25s
01/29/2023 02:34:11 AM  [*] Sun Jan 29 02:34:11 2023: Train Epoch: 5 [64000/73842 (87%)]	Loss: 173.158630 | Elapsed: 16.33s
01/29/2023 02:34:27 AM  [*] Sun Jan 29 02:34:27 2023: Train Epoch: 5 [70400/73842 (95%)]	Loss: 161.333801 | Elapsed: 16.48s
01/29/2023 02:34:38 AM  [*] Sun Jan 29 02:34:38 2023:    5    | Tr.loss: 175.248813 | Elapsed:  178.60  s
01/29/2023 02:34:38 AM  [*] Started epoch: 6
01/29/2023 02:34:38 AM  [*] Sun Jan 29 02:34:38 2023: Train Epoch: 6 [  0  /73842 (0 %)]	Loss: 189.542694 | Elapsed: 0.21s
01/29/2023 02:34:51 AM  [*] Sun Jan 29 02:34:51 2023: Train Epoch: 6 [6400 /73842 (9 %)]	Loss: 169.997620 | Elapsed: 12.50s
01/29/2023 02:35:03 AM  [*] Sun Jan 29 02:35:03 2023: Train Epoch: 6 [12800/73842 (17%)]	Loss: 179.888809 | Elapsed: 12.41s
01/29/2023 02:35:15 AM  [*] Sun Jan 29 02:35:15 2023: Train Epoch: 6 [19200/73842 (26%)]	Loss: 168.037109 | Elapsed: 12.35s
01/29/2023 02:35:30 AM  [*] Sun Jan 29 02:35:30 2023: Train Epoch: 6 [25600/73842 (35%)]	Loss: 184.888580 | Elapsed: 14.23s
01/29/2023 02:35:46 AM  [*] Sun Jan 29 02:35:46 2023: Train Epoch: 6 [32000/73842 (43%)]	Loss: 149.276550 | Elapsed: 16.43s
01/29/2023 02:36:02 AM  [*] Sun Jan 29 02:36:02 2023: Train Epoch: 6 [38400/73842 (52%)]	Loss: 171.774857 | Elapsed: 16.28s
01/29/2023 02:36:19 AM  [*] Sun Jan 29 02:36:19 2023: Train Epoch: 6 [44800/73842 (61%)]	Loss: 187.494965 | Elapsed: 16.43s
01/29/2023 02:36:35 AM  [*] Sun Jan 29 02:36:35 2023: Train Epoch: 6 [51200/73842 (69%)]	Loss: 164.093079 | Elapsed: 16.38s
01/29/2023 02:36:52 AM  [*] Sun Jan 29 02:36:52 2023: Train Epoch: 6 [57600/73842 (78%)]	Loss: 177.684387 | Elapsed: 16.41s
01/29/2023 02:37:08 AM  [*] Sun Jan 29 02:37:08 2023: Train Epoch: 6 [64000/73842 (87%)]	Loss: 175.528839 | Elapsed: 16.46s
01/29/2023 02:37:25 AM  [*] Sun Jan 29 02:37:25 2023: Train Epoch: 6 [70400/73842 (95%)]	Loss: 167.037491 | Elapsed: 16.45s
01/29/2023 02:37:35 AM  [*] Sun Jan 29 02:37:35 2023:    6    | Tr.loss: 174.510811 | Elapsed:  177.21  s
01/29/2023 02:37:35 AM  [*] Started epoch: 7
01/29/2023 02:37:35 AM  [*] Sun Jan 29 02:37:35 2023: Train Epoch: 7 [  0  /73842 (0 %)]	Loss: 190.019287 | Elapsed: 0.21s
01/29/2023 02:37:48 AM  [*] Sun Jan 29 02:37:48 2023: Train Epoch: 7 [6400 /73842 (9 %)]	Loss: 193.671021 | Elapsed: 12.54s
01/29/2023 02:38:00 AM  [*] Sun Jan 29 02:38:00 2023: Train Epoch: 7 [12800/73842 (17%)]	Loss: 161.343597 | Elapsed: 12.53s
01/29/2023 02:38:13 AM  [*] Sun Jan 29 02:38:13 2023: Train Epoch: 7 [19200/73842 (26%)]	Loss: 162.670349 | Elapsed: 12.34s
01/29/2023 02:38:25 AM  [*] Sun Jan 29 02:38:25 2023: Train Epoch: 7 [25600/73842 (35%)]	Loss: 184.692307 | Elapsed: 12.47s
01/29/2023 02:38:42 AM  [*] Sun Jan 29 02:38:42 2023: Train Epoch: 7 [32000/73842 (43%)]	Loss: 167.155914 | Elapsed: 16.26s
01/29/2023 02:38:58 AM  [*] Sun Jan 29 02:38:58 2023: Train Epoch: 7 [38400/73842 (52%)]	Loss: 189.249680 | Elapsed: 16.11s
01/29/2023 02:39:14 AM  [*] Sun Jan 29 02:39:14 2023: Train Epoch: 7 [44800/73842 (61%)]	Loss: 181.466476 | Elapsed: 16.29s
01/29/2023 02:39:31 AM  [*] Sun Jan 29 02:39:31 2023: Train Epoch: 7 [51200/73842 (69%)]	Loss: 169.227112 | Elapsed: 16.57s
01/29/2023 02:39:47 AM  [*] Sun Jan 29 02:39:47 2023: Train Epoch: 7 [57600/73842 (78%)]	Loss: 195.784470 | Elapsed: 16.33s
01/29/2023 02:40:03 AM  [*] Sun Jan 29 02:40:03 2023: Train Epoch: 7 [64000/73842 (87%)]	Loss: 183.785446 | Elapsed: 16.52s
01/29/2023 02:40:20 AM  [*] Sun Jan 29 02:40:20 2023: Train Epoch: 7 [70400/73842 (95%)]	Loss: 196.957764 | Elapsed: 16.41s
01/29/2023 02:40:30 AM  [*] Sun Jan 29 02:40:30 2023:    7    | Tr.loss: 174.226309 | Elapsed:  175.19  s
01/29/2023 02:40:30 AM  [*] Started epoch: 8
01/29/2023 02:40:31 AM  [*] Sun Jan 29 02:40:31 2023: Train Epoch: 8 [  0  /73842 (0 %)]	Loss: 182.387329 | Elapsed: 0.27s
01/29/2023 02:40:43 AM  [*] Sun Jan 29 02:40:43 2023: Train Epoch: 8 [6400 /73842 (9 %)]	Loss: 175.058334 | Elapsed: 12.40s
01/29/2023 02:40:56 AM  [*] Sun Jan 29 02:40:56 2023: Train Epoch: 8 [12800/73842 (17%)]	Loss: 171.873703 | Elapsed: 12.51s
01/29/2023 02:41:08 AM  [*] Sun Jan 29 02:41:08 2023: Train Epoch: 8 [19200/73842 (26%)]	Loss: 160.049240 | Elapsed: 12.37s
01/29/2023 02:41:20 AM  [*] Sun Jan 29 02:41:20 2023: Train Epoch: 8 [25600/73842 (35%)]	Loss: 173.106842 | Elapsed: 12.35s
01/29/2023 02:41:33 AM  [*] Sun Jan 29 02:41:33 2023: Train Epoch: 8 [32000/73842 (43%)]	Loss: 154.789520 | Elapsed: 12.52s
01/29/2023 02:41:45 AM  [*] Sun Jan 29 02:41:45 2023: Train Epoch: 8 [38400/73842 (52%)]	Loss: 175.141495 | Elapsed: 12.42s
01/29/2023 02:41:58 AM  [*] Sun Jan 29 02:41:58 2023: Train Epoch: 8 [44800/73842 (61%)]	Loss: 165.878662 | Elapsed: 12.34s
01/29/2023 02:42:10 AM  [*] Sun Jan 29 02:42:10 2023: Train Epoch: 8 [51200/73842 (69%)]	Loss: 156.290329 | Elapsed: 12.41s
01/29/2023 02:42:22 AM  [*] Sun Jan 29 02:42:22 2023: Train Epoch: 8 [57600/73842 (78%)]	Loss: 185.621689 | Elapsed: 12.35s
01/29/2023 02:42:35 AM  [*] Sun Jan 29 02:42:35 2023: Train Epoch: 8 [64000/73842 (87%)]	Loss: 174.251465 | Elapsed: 12.39s
01/29/2023 02:42:47 AM  [*] Sun Jan 29 02:42:47 2023: Train Epoch: 8 [70400/73842 (95%)]	Loss: 174.639694 | Elapsed: 12.43s
01/29/2023 02:42:56 AM  [*] Sun Jan 29 02:42:56 2023:    8    | Tr.loss: 174.032907 | Elapsed:  145.42  s
01/29/2023 02:42:56 AM  [*] Started epoch: 9
01/29/2023 02:42:56 AM  [*] Sun Jan 29 02:42:56 2023: Train Epoch: 9 [  0  /73842 (0 %)]	Loss: 173.781174 | Elapsed: 0.22s
01/29/2023 02:43:09 AM  [*] Sun Jan 29 02:43:09 2023: Train Epoch: 9 [6400 /73842 (9 %)]	Loss: 159.606934 | Elapsed: 12.60s
01/29/2023 02:43:21 AM  [*] Sun Jan 29 02:43:21 2023: Train Epoch: 9 [12800/73842 (17%)]	Loss: 182.031998 | Elapsed: 12.51s
01/29/2023 02:43:34 AM  [*] Sun Jan 29 02:43:34 2023: Train Epoch: 9 [19200/73842 (26%)]	Loss: 159.866699 | Elapsed: 12.41s
01/29/2023 02:43:46 AM  [*] Sun Jan 29 02:43:46 2023: Train Epoch: 9 [25600/73842 (35%)]	Loss: 187.330627 | Elapsed: 12.42s
01/29/2023 02:43:58 AM  [*] Sun Jan 29 02:43:58 2023: Train Epoch: 9 [32000/73842 (43%)]	Loss: 175.738144 | Elapsed: 12.36s
01/29/2023 02:44:11 AM  [*] Sun Jan 29 02:44:11 2023: Train Epoch: 9 [38400/73842 (52%)]	Loss: 180.295502 | Elapsed: 12.38s
01/29/2023 02:44:23 AM  [*] Sun Jan 29 02:44:23 2023: Train Epoch: 9 [44800/73842 (61%)]	Loss: 190.307800 | Elapsed: 12.39s
01/29/2023 02:44:31 AM [!] Learning rate: 2.5e-06
01/29/2023 02:44:36 AM  [*] Sun Jan 29 02:44:36 2023: Train Epoch: 9 [51200/73842 (69%)]	Loss: 173.336670 | Elapsed: 12.52s
01/29/2023 02:44:48 AM  [*] Sun Jan 29 02:44:48 2023: Train Epoch: 9 [57600/73842 (78%)]	Loss: 170.395096 | Elapsed: 12.43s
01/29/2023 02:45:00 AM  [*] Sun Jan 29 02:45:00 2023: Train Epoch: 9 [64000/73842 (87%)]	Loss: 174.417969 | Elapsed: 12.37s
01/29/2023 02:45:13 AM  [*] Sun Jan 29 02:45:13 2023: Train Epoch: 9 [70400/73842 (95%)]	Loss: 183.046112 | Elapsed: 12.48s
01/29/2023 02:45:21 AM  [*] Sun Jan 29 02:45:21 2023:    9    | Tr.loss: 173.859429 | Elapsed:  145.65  s
01/29/2023 02:45:21 AM  [*] Started epoch: 10
01/29/2023 02:45:22 AM  [*] Sun Jan 29 02:45:22 2023: Train Epoch: 10 [  0  /73842 (0 %)]	Loss: 172.351242 | Elapsed: 0.23s
01/29/2023 02:45:34 AM  [*] Sun Jan 29 02:45:34 2023: Train Epoch: 10 [6400 /73842 (9 %)]	Loss: 169.580215 | Elapsed: 12.47s
01/29/2023 02:45:47 AM  [*] Sun Jan 29 02:45:47 2023: Train Epoch: 10 [12800/73842 (17%)]	Loss: 167.948242 | Elapsed: 12.55s
01/29/2023 02:45:59 AM  [*] Sun Jan 29 02:45:59 2023: Train Epoch: 10 [19200/73842 (26%)]	Loss: 155.737625 | Elapsed: 12.39s
01/29/2023 02:46:11 AM  [*] Sun Jan 29 02:46:11 2023: Train Epoch: 10 [25600/73842 (35%)]	Loss: 172.767334 | Elapsed: 12.42s
01/29/2023 02:46:24 AM  [*] Sun Jan 29 02:46:24 2023: Train Epoch: 10 [32000/73842 (43%)]	Loss: 169.124725 | Elapsed: 12.39s
01/29/2023 02:46:36 AM  [*] Sun Jan 29 02:46:36 2023: Train Epoch: 10 [38400/73842 (52%)]	Loss: 165.269501 | Elapsed: 12.38s
01/29/2023 02:46:49 AM  [*] Sun Jan 29 02:46:49 2023: Train Epoch: 10 [44800/73842 (61%)]	Loss: 156.965073 | Elapsed: 12.43s
01/29/2023 02:47:01 AM  [*] Sun Jan 29 02:47:01 2023: Train Epoch: 10 [51200/73842 (69%)]	Loss: 168.524612 | Elapsed: 12.47s
01/29/2023 02:47:14 AM  [*] Sun Jan 29 02:47:14 2023: Train Epoch: 10 [57600/73842 (78%)]	Loss: 183.316055 | Elapsed: 12.48s
01/29/2023 02:47:26 AM  [*] Sun Jan 29 02:47:26 2023: Train Epoch: 10 [64000/73842 (87%)]	Loss: 182.788666 | Elapsed: 12.42s
01/29/2023 02:47:39 AM  [*] Sun Jan 29 02:47:39 2023: Train Epoch: 10 [70400/73842 (95%)]	Loss: 164.334183 | Elapsed: 12.46s
01/29/2023 02:47:47 AM  [*] Sun Jan 29 02:47:47 2023:   10    | Tr.loss: 173.657870 | Elapsed:  145.79  s
01/29/2023 02:47:48 AM [!] Sun Jan 29 02:47:48 2023: Dumped results:
                model     : 1674956867-model.torch
		train time: 1674956867-trainTime.npy
		train losses: 1674956867-trainLosses.npy
		train AUC: 1674956867-auc.npy
01/29/2023 02:47:50 AM  [!] Training pretrained model on downstream task...
01/29/2023 02:47:51 AM  [*] Started epoch: 1
01/29/2023 02:47:51 AM  [*] Sun Jan 29 02:47:51 2023: Train Epoch: 1 [  0  /2284  (0 %)]	Loss: 4.008593 | Elapsed: 0.31s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.3138
01/29/2023 02:47:54 AM  [*] Sun Jan 29 02:47:54 2023:    1    | Tr.loss: 0.993834 | Elapsed:   3.55   s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.6254
01/29/2023 02:47:54 AM  [*] Started epoch: 2
01/29/2023 02:47:54 AM  [*] Sun Jan 29 02:47:54 2023: Train Epoch: 2 [  0  /2284  (0 %)]	Loss: 0.538976 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.2727 & F1 0.4286 | AUC 0.7733
01/29/2023 02:47:57 AM  [*] Sun Jan 29 02:47:57 2023:    2    | Tr.loss: 0.478289 | Elapsed:   3.39   s | FPR 0.0003 -> TPR: 0.10 & F1: 0.18 | AUC: 0.7964
01/29/2023 02:47:57 AM  [*] Started epoch: 3
01/29/2023 02:47:58 AM  [*] Sun Jan 29 02:47:58 2023: Train Epoch: 3 [  0  /2284  (0 %)]	Loss: 0.417305 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.2791 & F1 0.4364 | AUC 0.8505
01/29/2023 02:48:01 AM  [*] Sun Jan 29 02:48:01 2023:    3    | Tr.loss: 0.429893 | Elapsed:   3.31   s | FPR 0.0003 -> TPR: 0.13 & F1: 0.23 | AUC: 0.8441
01/29/2023 02:48:01 AM [!] Sun Jan 29 02:48:01 2023: Dumped results:
                model     : 1674956881-model.torch
		train time: 1674956881-trainTime.npy
		train losses: 1674956881-trainLosses.npy
		train AUC: 1674956881-auc.npy
		train F1s : 1674956881-trainF1s.npy
		train TPRs: 1674956881-trainTPRs.npy
01/29/2023 02:48:01 AM  [!] Training non_pretrained model on downstream task...
01/29/2023 02:48:02 AM  [*] Started epoch: 1
01/29/2023 02:48:02 AM  [*] Sun Jan 29 02:48:02 2023: Train Epoch: 1 [  0  /2284  (0 %)]	Loss: 1.759533 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0227 & F1 0.0444 | AUC 0.4318
01/29/2023 02:48:04 AM  [*] Sun Jan 29 02:48:04 2023:    1    | Tr.loss: 0.798605 | Elapsed:   2.29   s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.6419
01/29/2023 02:48:04 AM  [*] Started epoch: 2
01/29/2023 02:48:04 AM  [*] Sun Jan 29 02:48:04 2023: Train Epoch: 2 [  0  /2284  (0 %)]	Loss: 0.556607 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.1277 & F1 0.2264 | AUC 0.6721
01/29/2023 02:48:06 AM  [*] Sun Jan 29 02:48:06 2023:    2    | Tr.loss: 0.482310 | Elapsed:   2.27   s | FPR 0.0003 -> TPR: 0.04 & F1: 0.07 | AUC: 0.8045
01/29/2023 02:48:06 AM  [*] Started epoch: 3
01/29/2023 02:48:06 AM  [*] Sun Jan 29 02:48:06 2023: Train Epoch: 3 [  0  /2284  (0 %)]	Loss: 0.351018 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.4583 & F1 0.6286 | AUC 0.8984
01/29/2023 02:48:08 AM  [*] Sun Jan 29 02:48:08 2023:    3    | Tr.loss: 0.420884 | Elapsed:   2.28   s | FPR 0.0003 -> TPR: 0.17 & F1: 0.29 | AUC: 0.8537
01/29/2023 02:48:09 AM [!] Sun Jan 29 02:48:09 2023: Dumped results:
                model     : 1674956888-model.torch
		train time: 1674956888-trainTime.npy
		train losses: 1674956888-trainLosses.npy
		train AUC: 1674956888-auc.npy
		train F1s : 1674956888-trainF1s.npy
		train TPRs: 1674956888-trainTPRs.npy
01/29/2023 02:48:09 AM  [!] Training full_data model on downstream task...
01/29/2023 02:48:09 AM  [*] Started epoch: 1
01/29/2023 02:48:09 AM  [*] Sun Jan 29 02:48:09 2023: Train Epoch: 1 [  0  /76126 (0 %)]	Loss: 3.316394 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.0500 & F1 0.0952 | AUC 0.4703
01/29/2023 02:48:16 AM  [*] Sun Jan 29 02:48:16 2023: Train Epoch: 1 [6400 /76126 (8 %)]	Loss: 0.552670 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.2241 & F1 0.3662 | AUC 0.8641
01/29/2023 02:48:22 AM  [*] Sun Jan 29 02:48:22 2023: Train Epoch: 1 [12800/76126 (17%)]	Loss: 0.384788 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.4306 & F1 0.6019 | AUC 0.9028
01/29/2023 02:48:28 AM  [*] Sun Jan 29 02:48:28 2023: Train Epoch: 1 [19200/76126 (25%)]	Loss: 0.275183 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.5758 & F1 0.7308 | AUC 0.9242
01/29/2023 02:48:34 AM  [*] Sun Jan 29 02:48:34 2023: Train Epoch: 1 [25600/76126 (34%)]	Loss: 0.383568 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.5806 & F1 0.7347 | AUC 0.9126
01/29/2023 02:48:40 AM  [*] Sun Jan 29 02:48:40 2023: Train Epoch: 1 [32000/76126 (42%)]	Loss: 0.189747 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.7286 & F1 0.8430 | AUC 0.9619
01/29/2023 02:48:47 AM  [*] Sun Jan 29 02:48:47 2023: Train Epoch: 1 [38400/76126 (50%)]	Loss: 0.317215 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.4462 & F1 0.6170 | AUC 0.9354
01/29/2023 02:48:53 AM  [*] Sun Jan 29 02:48:53 2023: Train Epoch: 1 [44800/76126 (59%)]	Loss: 0.239427 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.6806 & F1 0.8099 | AUC 0.9658
01/29/2023 02:48:59 AM  [*] Sun Jan 29 02:48:59 2023: Train Epoch: 1 [51200/76126 (67%)]	Loss: 0.297570 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.4667 & F1 0.6364 | AUC 0.9442
01/29/2023 02:49:05 AM  [*] Sun Jan 29 02:49:05 2023: Train Epoch: 1 [57600/76126 (76%)]	Loss: 0.148003 | Elapsed: 6.26s | FPR 0.0003 -> TPR 0.8235 & F1 0.9032 | AUC 0.9881
01/29/2023 02:49:11 AM [!] Learning rate: 2.5e-05
01/29/2023 02:49:12 AM  [*] Sun Jan 29 02:49:12 2023: Train Epoch: 1 [64000/76126 (84%)]	Loss: 0.124205 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.8281 & F1 0.9060 | AUC 0.9905
01/29/2023 02:49:18 AM  [*] Sun Jan 29 02:49:18 2023: Train Epoch: 1 [70400/76126 (92%)]	Loss: 0.153918 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.8261 & F1 0.9048 | AUC 0.9696
01/29/2023 02:49:25 AM  [*] Sun Jan 29 02:49:25 2023:    1    | Tr.loss: 0.303157 | Elapsed:   75.67  s | FPR 0.0003 -> TPR: 0.02 & F1: 0.05 | AUC: 0.9333
01/29/2023 02:49:25 AM  [*] Started epoch: 2
01/29/2023 02:49:25 AM  [*] Sun Jan 29 02:49:25 2023: Train Epoch: 2 [  0  /76126 (0 %)]	Loss: 0.167764 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.8372 & F1 0.9114 | AUC 0.9856
01/29/2023 02:49:31 AM  [*] Sun Jan 29 02:49:31 2023: Train Epoch: 2 [6400 /76126 (8 %)]	Loss: 0.308098 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.4386 & F1 0.6098 | AUC 0.9649
01/29/2023 02:49:38 AM  [*] Sun Jan 29 02:49:38 2023: Train Epoch: 2 [12800/76126 (17%)]	Loss: 0.145911 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.9531 & F1 0.9760 | AUC 0.9961
01/29/2023 02:49:44 AM  [*] Sun Jan 29 02:49:44 2023: Train Epoch: 2 [19200/76126 (25%)]	Loss: 0.135821 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.9242 & F1 0.9606 | AUC 0.9955
01/29/2023 02:49:50 AM  [*] Sun Jan 29 02:49:50 2023: Train Epoch: 2 [25600/76126 (34%)]	Loss: 0.072661 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.9848 & F1 0.9924 | AUC 0.9982
01/29/2023 02:49:56 AM  [*] Sun Jan 29 02:49:56 2023: Train Epoch: 2 [32000/76126 (42%)]	Loss: 0.134133 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.9231 & F1 0.9600 | AUC 0.9864
01/29/2023 02:50:02 AM  [*] Sun Jan 29 02:50:02 2023: Train Epoch: 2 [38400/76126 (50%)]	Loss: 0.152265 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.9206 & F1 0.9587 | AUC 0.9820
01/29/2023 02:50:09 AM  [*] Sun Jan 29 02:50:09 2023: Train Epoch: 2 [44800/76126 (59%)]	Loss: 0.163286 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.9385 & F1 0.9683 | AUC 0.9851
01/29/2023 02:50:15 AM  [*] Sun Jan 29 02:50:15 2023: Train Epoch: 2 [51200/76126 (67%)]	Loss: 0.151762 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.9571 & F1 0.9781 | AUC 0.9919
01/29/2023 02:50:15 AM [!] Learning rate: 2.5e-06
01/29/2023 02:50:21 AM  [*] Sun Jan 29 02:50:21 2023: Train Epoch: 2 [57600/76126 (76%)]	Loss: 0.142154 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.8615 & F1 0.9256 | AUC 0.9877
01/29/2023 02:50:27 AM  [*] Sun Jan 29 02:50:27 2023: Train Epoch: 2 [64000/76126 (84%)]	Loss: 0.120333 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.9571 & F1 0.9781 | AUC 0.9933
01/29/2023 02:50:33 AM  [*] Sun Jan 29 02:50:33 2023: Train Epoch: 2 [70400/76126 (92%)]	Loss: 0.244850 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.7500 & F1 0.8571 | AUC 0.9563
01/29/2023 02:50:41 AM  [*] Sun Jan 29 02:50:41 2023:    2    | Tr.loss: 0.168686 | Elapsed:   75.74  s | FPR 0.0003 -> TPR: 0.46 & F1: 0.63 | AUC: 0.9803
01/29/2023 02:50:41 AM  [*] Started epoch: 3
01/29/2023 02:50:41 AM  [*] Sun Jan 29 02:50:41 2023: Train Epoch: 3 [  0  /76126 (0 %)]	Loss: 0.161221 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.9375 & F1 0.9677 | AUC 0.9857
01/29/2023 02:50:47 AM  [*] Sun Jan 29 02:50:47 2023: Train Epoch: 3 [6400 /76126 (8 %)]	Loss: 0.111533 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.6618 & F1 0.7965 | AUC 0.9881
01/29/2023 02:50:53 AM  [*] Sun Jan 29 02:50:53 2023: Train Epoch: 3 [12800/76126 (17%)]	Loss: 0.129815 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.8852 & F1 0.9391 | AUC 0.9933
01/29/2023 02:51:00 AM  [*] Sun Jan 29 02:51:00 2023: Train Epoch: 3 [19200/76126 (25%)]	Loss: 0.128940 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.9437 & F1 0.9710 | AUC 0.9898
01/29/2023 02:51:06 AM  [*] Sun Jan 29 02:51:06 2023: Train Epoch: 3 [25600/76126 (34%)]	Loss: 0.142068 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.6866 & F1 0.8142 | AUC 0.9819
01/29/2023 02:51:12 AM  [*] Sun Jan 29 02:51:12 2023: Train Epoch: 3 [32000/76126 (42%)]	Loss: 0.105281 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.5075 & F1 0.6733 | AUC 0.9806
01/29/2023 02:51:18 AM  [*] Sun Jan 29 02:51:18 2023: Train Epoch: 3 [38400/76126 (50%)]	Loss: 0.186184 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.8226 & F1 0.9027 | AUC 0.9817
01/29/2023 02:51:19 AM [!] Learning rate: 2.5000000000000004e-07
01/29/2023 02:51:24 AM  [*] Sun Jan 29 02:51:24 2023: Train Epoch: 3 [44800/76126 (59%)]	Loss: 0.150945 | Elapsed: 6.26s | FPR 0.0003 -> TPR 0.9828 & F1 0.9913 | AUC 0.9889
01/29/2023 02:51:31 AM  [*] Sun Jan 29 02:51:31 2023: Train Epoch: 3 [51200/76126 (67%)]	Loss: 0.171365 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.7838 & F1 0.8788 | AUC 0.9771
01/29/2023 02:51:37 AM  [*] Sun Jan 29 02:51:37 2023: Train Epoch: 3 [57600/76126 (76%)]	Loss: 0.311266 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.6286 & F1 0.7719 | AUC 0.9581
01/29/2023 02:51:43 AM  [*] Sun Jan 29 02:51:43 2023: Train Epoch: 3 [64000/76126 (84%)]	Loss: 0.114179 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.9333 & F1 0.9655 | AUC 0.9952
01/29/2023 02:51:49 AM  [*] Sun Jan 29 02:51:49 2023: Train Epoch: 3 [70400/76126 (92%)]	Loss: 0.143270 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.8548 & F1 0.9217 | AUC 0.9737
01/29/2023 02:51:56 AM  [*] Sun Jan 29 02:51:56 2023:    3    | Tr.loss: 0.161690 | Elapsed:   75.69  s | FPR 0.0003 -> TPR: 0.51 & F1: 0.68 | AUC: 0.9819
01/29/2023 02:51:57 AM [!] Sun Jan 29 02:51:57 2023: Dumped results:
                model     : 1674957116-model.torch
		train time: 1674957116-trainTime.npy
		train losses: 1674957116-trainLosses.npy
		train AUC: 1674957116-auc.npy
		train F1s : 1674957116-trainF1s.npy
		train TPRs: 1674957116-trainTPRs.npy
01/29/2023 02:51:57 AM  [*] Evaluating pretrained model on test set...
01/29/2023 02:52:02 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0654 | F1: 0.1228
01/29/2023 02:52:02 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.0798 | F1: 0.1477
01/29/2023 02:52:02 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.0994 | F1: 0.1807
01/29/2023 02:52:02 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.1724 | F1: 0.2935
01/29/2023 02:52:02 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.2623 | F1: 0.4128
01/29/2023 02:52:02 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.3964 | F1: 0.5575
01/29/2023 02:52:02 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.5479 | F1: 0.6712
01/29/2023 02:52:02 AM  [*] Evaluating non_pretrained model on test set...
01/29/2023 02:52:07 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0211 | F1: 0.0412
01/29/2023 02:52:07 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.0761 | F1: 0.1415
01/29/2023 02:52:07 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.1067 | F1: 0.1926
01/29/2023 02:52:07 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.1691 | F1: 0.2886
01/29/2023 02:52:07 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.2580 | F1: 0.4074
01/29/2023 02:52:07 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.3336 | F1: 0.4909
01/29/2023 02:52:07 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.4872 | F1: 0.6197
01/29/2023 02:52:07 AM  [*] Evaluating full_data model on test set...
01/29/2023 02:52:12 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0131 | F1: 0.0258
01/29/2023 02:52:12 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1963 | F1: 0.3281
01/29/2023 02:52:12 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.3189 | F1: 0.4833
01/29/2023 02:52:12 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3687 | F1: 0.5378
01/29/2023 02:52:12 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.4683 | F1: 0.6342
01/29/2023 02:52:12 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.5757 | F1: 0.7190
01/29/2023 02:52:12 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.7968 | F1: 0.8468
01/29/2023 02:52:12 AM  [!] Running pre-training split 2/3
01/29/2023 02:52:15 AM  [!] Pre-training model...
01/29/2023 02:52:15 AM  [*] Masking sequences...
01/29/2023 02:52:37 AM  [*] Started epoch: 1
01/29/2023 02:52:37 AM  [*] Sun Jan 29 02:52:37 2023: Train Epoch: 1 [  0  /73842 (0 %)]	Loss: 378.542267 | Elapsed: 0.37s
01/29/2023 02:52:49 AM  [*] Sun Jan 29 02:52:49 2023: Train Epoch: 1 [6400 /73842 (9 %)]	Loss: 223.251205 | Elapsed: 12.13s
01/29/2023 02:53:02 AM  [*] Sun Jan 29 02:53:02 2023: Train Epoch: 1 [12800/73842 (17%)]	Loss: 212.635040 | Elapsed: 12.20s
01/29/2023 02:53:14 AM  [*] Sun Jan 29 02:53:14 2023: Train Epoch: 1 [19200/73842 (26%)]	Loss: 202.181427 | Elapsed: 12.24s
01/29/2023 02:53:26 AM  [*] Sun Jan 29 02:53:26 2023: Train Epoch: 1 [25600/73842 (35%)]	Loss: 189.758698 | Elapsed: 12.25s
01/29/2023 02:53:38 AM  [*] Sun Jan 29 02:53:38 2023: Train Epoch: 1 [32000/73842 (43%)]	Loss: 202.244354 | Elapsed: 12.25s
01/29/2023 02:53:51 AM  [*] Sun Jan 29 02:53:51 2023: Train Epoch: 1 [38400/73842 (52%)]	Loss: 237.480408 | Elapsed: 12.23s
01/29/2023 02:54:03 AM  [*] Sun Jan 29 02:54:03 2023: Train Epoch: 1 [44800/73842 (61%)]	Loss: 199.911713 | Elapsed: 12.30s
01/29/2023 02:54:15 AM  [*] Sun Jan 29 02:54:15 2023: Train Epoch: 1 [51200/73842 (69%)]	Loss: 193.582672 | Elapsed: 12.68s
01/29/2023 02:54:28 AM  [*] Sun Jan 29 02:54:28 2023: Train Epoch: 1 [57600/73842 (78%)]	Loss: 199.891449 | Elapsed: 12.66s
01/29/2023 02:54:41 AM  [*] Sun Jan 29 02:54:41 2023: Train Epoch: 1 [64000/73842 (87%)]	Loss: 191.100159 | Elapsed: 12.50s
01/29/2023 02:55:00 AM  [*] Sun Jan 29 02:55:00 2023: Train Epoch: 1 [70400/73842 (95%)]	Loss: 179.170441 | Elapsed: 18.95s
01/29/2023 02:55:11 AM  [*] Sun Jan 29 02:55:11 2023:    1    | Tr.loss: 207.629161 | Elapsed:  154.62  s
01/29/2023 02:55:11 AM  [*] Started epoch: 2
01/29/2023 02:55:12 AM  [*] Sun Jan 29 02:55:12 2023: Train Epoch: 2 [  0  /73842 (0 %)]	Loss: 200.416260 | Elapsed: 0.22s
01/29/2023 02:55:24 AM  [*] Sun Jan 29 02:55:24 2023: Train Epoch: 2 [6400 /73842 (9 %)]	Loss: 196.265869 | Elapsed: 12.55s
01/29/2023 02:55:37 AM  [*] Sun Jan 29 02:55:37 2023: Train Epoch: 2 [12800/73842 (17%)]	Loss: 180.464905 | Elapsed: 12.67s
01/29/2023 02:55:50 AM  [*] Sun Jan 29 02:55:50 2023: Train Epoch: 2 [19200/73842 (26%)]	Loss: 206.340637 | Elapsed: 12.59s
01/29/2023 02:56:02 AM  [*] Sun Jan 29 02:56:02 2023: Train Epoch: 2 [25600/73842 (35%)]	Loss: 184.002625 | Elapsed: 12.59s
01/29/2023 02:56:14 AM  [*] Sun Jan 29 02:56:14 2023: Train Epoch: 2 [32000/73842 (43%)]	Loss: 177.229813 | Elapsed: 12.31s
01/29/2023 02:56:27 AM  [*] Sun Jan 29 02:56:27 2023: Train Epoch: 2 [38400/73842 (52%)]	Loss: 190.801193 | Elapsed: 12.24s
01/29/2023 02:56:39 AM  [*] Sun Jan 29 02:56:39 2023: Train Epoch: 2 [44800/73842 (61%)]	Loss: 184.034363 | Elapsed: 12.31s
01/29/2023 02:56:51 AM  [*] Sun Jan 29 02:56:51 2023: Train Epoch: 2 [51200/73842 (69%)]	Loss: 194.051254 | Elapsed: 12.23s
01/29/2023 02:57:03 AM  [*] Sun Jan 29 02:57:03 2023: Train Epoch: 2 [57600/73842 (78%)]	Loss: 170.038177 | Elapsed: 12.26s
01/29/2023 02:57:16 AM  [*] Sun Jan 29 02:57:16 2023: Train Epoch: 2 [64000/73842 (87%)]	Loss: 180.097229 | Elapsed: 12.27s
01/29/2023 02:57:28 AM  [*] Sun Jan 29 02:57:28 2023: Train Epoch: 2 [70400/73842 (95%)]	Loss: 211.044067 | Elapsed: 12.29s
01/29/2023 02:57:36 AM  [*] Sun Jan 29 02:57:36 2023:    2    | Tr.loss: 187.957041 | Elapsed:  144.95  s
01/29/2023 02:57:36 AM  [*] Started epoch: 3
01/29/2023 02:57:37 AM  [*] Sun Jan 29 02:57:37 2023: Train Epoch: 3 [  0  /73842 (0 %)]	Loss: 178.050995 | Elapsed: 0.20s
01/29/2023 02:57:49 AM  [*] Sun Jan 29 02:57:49 2023: Train Epoch: 3 [6400 /73842 (9 %)]	Loss: 161.887161 | Elapsed: 12.26s
01/29/2023 02:58:01 AM  [*] Sun Jan 29 02:58:01 2023: Train Epoch: 3 [12800/73842 (17%)]	Loss: 176.846573 | Elapsed: 12.30s
01/29/2023 02:58:13 AM  [*] Sun Jan 29 02:58:13 2023: Train Epoch: 3 [19200/73842 (26%)]	Loss: 198.591461 | Elapsed: 12.21s
01/29/2023 02:58:26 AM  [*] Sun Jan 29 02:58:26 2023: Train Epoch: 3 [25600/73842 (35%)]	Loss: 167.902008 | Elapsed: 12.24s
01/29/2023 02:58:38 AM  [*] Sun Jan 29 02:58:38 2023: Train Epoch: 3 [32000/73842 (43%)]	Loss: 188.848267 | Elapsed: 12.26s
01/29/2023 02:58:50 AM  [*] Sun Jan 29 02:58:50 2023: Train Epoch: 3 [38400/73842 (52%)]	Loss: 177.843842 | Elapsed: 12.23s
01/29/2023 02:59:02 AM  [*] Sun Jan 29 02:59:02 2023: Train Epoch: 3 [44800/73842 (61%)]	Loss: 168.403214 | Elapsed: 12.19s
01/29/2023 02:59:15 AM  [*] Sun Jan 29 02:59:15 2023: Train Epoch: 3 [51200/73842 (69%)]	Loss: 175.401855 | Elapsed: 12.23s
01/29/2023 02:59:27 AM  [*] Sun Jan 29 02:59:27 2023: Train Epoch: 3 [57600/73842 (78%)]	Loss: 187.773956 | Elapsed: 12.18s
01/29/2023 02:59:39 AM  [*] Sun Jan 29 02:59:39 2023: Train Epoch: 3 [64000/73842 (87%)]	Loss: 176.312164 | Elapsed: 12.24s
01/29/2023 02:59:51 AM  [*] Sun Jan 29 02:59:51 2023: Train Epoch: 3 [70400/73842 (95%)]	Loss: 174.856094 | Elapsed: 12.22s
01/29/2023 03:00:00 AM  [*] Sun Jan 29 03:00:00 2023:    3    | Tr.loss: 182.764915 | Elapsed:  143.16  s
01/29/2023 03:00:00 AM  [*] Started epoch: 4
01/29/2023 03:00:00 AM  [*] Sun Jan 29 03:00:00 2023: Train Epoch: 4 [  0  /73842 (0 %)]	Loss: 180.395554 | Elapsed: 0.23s
01/29/2023 03:00:12 AM  [*] Sun Jan 29 03:00:12 2023: Train Epoch: 4 [6400 /73842 (9 %)]	Loss: 177.875244 | Elapsed: 12.25s
01/29/2023 03:00:24 AM  [*] Sun Jan 29 03:00:24 2023: Train Epoch: 4 [12800/73842 (17%)]	Loss: 185.550873 | Elapsed: 12.27s
01/29/2023 03:00:37 AM  [*] Sun Jan 29 03:00:37 2023: Train Epoch: 4 [19200/73842 (26%)]	Loss: 183.005676 | Elapsed: 12.25s
01/29/2023 03:00:49 AM  [*] Sun Jan 29 03:00:49 2023: Train Epoch: 4 [25600/73842 (35%)]	Loss: 193.482681 | Elapsed: 12.21s
01/29/2023 03:01:01 AM  [*] Sun Jan 29 03:01:01 2023: Train Epoch: 4 [32000/73842 (43%)]	Loss: 187.644012 | Elapsed: 12.23s
01/29/2023 03:01:13 AM  [*] Sun Jan 29 03:01:13 2023: Train Epoch: 4 [38400/73842 (52%)]	Loss: 178.838715 | Elapsed: 12.22s
01/29/2023 03:01:25 AM  [*] Sun Jan 29 03:01:25 2023: Train Epoch: 4 [44800/73842 (61%)]	Loss: 177.475433 | Elapsed: 12.18s
01/29/2023 03:01:38 AM  [*] Sun Jan 29 03:01:38 2023: Train Epoch: 4 [51200/73842 (69%)]	Loss: 186.387192 | Elapsed: 12.37s
01/29/2023 03:01:50 AM  [*] Sun Jan 29 03:01:50 2023: Train Epoch: 4 [57600/73842 (78%)]	Loss: 178.043579 | Elapsed: 12.22s
01/29/2023 03:02:02 AM  [*] Sun Jan 29 03:02:02 2023: Train Epoch: 4 [64000/73842 (87%)]	Loss: 193.985657 | Elapsed: 12.23s
01/29/2023 03:02:15 AM  [*] Sun Jan 29 03:02:15 2023: Train Epoch: 4 [70400/73842 (95%)]	Loss: 193.342987 | Elapsed: 12.27s
01/29/2023 03:02:23 AM  [*] Sun Jan 29 03:02:23 2023:    4    | Tr.loss: 180.071182 | Elapsed:  143.11  s
01/29/2023 03:02:23 AM  [*] Started epoch: 5
01/29/2023 03:02:23 AM  [*] Sun Jan 29 03:02:23 2023: Train Epoch: 5 [  0  /73842 (0 %)]	Loss: 176.603241 | Elapsed: 0.13s
01/29/2023 03:02:35 AM  [*] Sun Jan 29 03:02:35 2023: Train Epoch: 5 [6400 /73842 (9 %)]	Loss: 186.550705 | Elapsed: 12.29s
01/29/2023 03:02:47 AM  [*] Sun Jan 29 03:02:47 2023: Train Epoch: 5 [12800/73842 (17%)]	Loss: 172.250275 | Elapsed: 12.32s
01/29/2023 03:03:00 AM  [*] Sun Jan 29 03:03:00 2023: Train Epoch: 5 [19200/73842 (26%)]	Loss: 171.521088 | Elapsed: 12.19s
01/29/2023 03:03:10 AM [!] Learning rate: 2.5e-05
01/29/2023 03:03:12 AM  [*] Sun Jan 29 03:03:12 2023: Train Epoch: 5 [25600/73842 (35%)]	Loss: 210.927032 | Elapsed: 12.19s
01/29/2023 03:03:24 AM  [*] Sun Jan 29 03:03:24 2023: Train Epoch: 5 [32000/73842 (43%)]	Loss: 174.875702 | Elapsed: 12.18s
01/29/2023 03:03:36 AM  [*] Sun Jan 29 03:03:36 2023: Train Epoch: 5 [38400/73842 (52%)]	Loss: 187.318481 | Elapsed: 12.19s
01/29/2023 03:03:48 AM  [*] Sun Jan 29 03:03:48 2023: Train Epoch: 5 [44800/73842 (61%)]	Loss: 184.156433 | Elapsed: 12.21s
01/29/2023 03:04:01 AM  [*] Sun Jan 29 03:04:01 2023: Train Epoch: 5 [51200/73842 (69%)]	Loss: 185.996063 | Elapsed: 12.18s
01/29/2023 03:04:13 AM  [*] Sun Jan 29 03:04:13 2023: Train Epoch: 5 [57600/73842 (78%)]	Loss: 187.672516 | Elapsed: 12.20s
01/29/2023 03:04:25 AM  [*] Sun Jan 29 03:04:25 2023: Train Epoch: 5 [64000/73842 (87%)]	Loss: 170.231583 | Elapsed: 12.21s
01/29/2023 03:04:37 AM  [*] Sun Jan 29 03:04:37 2023: Train Epoch: 5 [70400/73842 (95%)]	Loss: 188.439545 | Elapsed: 12.33s
01/29/2023 03:04:46 AM  [*] Sun Jan 29 03:04:46 2023:    5    | Tr.loss: 178.315855 | Elapsed:  142.84  s
01/29/2023 03:04:46 AM  [*] Started epoch: 6
01/29/2023 03:04:46 AM  [*] Sun Jan 29 03:04:46 2023: Train Epoch: 6 [  0  /73842 (0 %)]	Loss: 171.859894 | Elapsed: 0.16s
01/29/2023 03:04:58 AM  [*] Sun Jan 29 03:04:58 2023: Train Epoch: 6 [6400 /73842 (9 %)]	Loss: 183.741974 | Elapsed: 12.24s
01/29/2023 03:05:10 AM  [*] Sun Jan 29 03:05:10 2023: Train Epoch: 6 [12800/73842 (17%)]	Loss: 165.135132 | Elapsed: 12.25s
01/29/2023 03:05:22 AM  [*] Sun Jan 29 03:05:22 2023: Train Epoch: 6 [19200/73842 (26%)]	Loss: 170.809067 | Elapsed: 12.17s
01/29/2023 03:05:35 AM  [*] Sun Jan 29 03:05:35 2023: Train Epoch: 6 [25600/73842 (35%)]	Loss: 179.803772 | Elapsed: 12.21s
01/29/2023 03:05:47 AM  [*] Sun Jan 29 03:05:47 2023: Train Epoch: 6 [32000/73842 (43%)]	Loss: 195.528870 | Elapsed: 12.20s
01/29/2023 03:05:59 AM  [*] Sun Jan 29 03:05:59 2023: Train Epoch: 6 [38400/73842 (52%)]	Loss: 177.204544 | Elapsed: 12.20s
01/29/2023 03:06:11 AM  [*] Sun Jan 29 03:06:11 2023: Train Epoch: 6 [44800/73842 (61%)]	Loss: 173.644897 | Elapsed: 12.18s
01/29/2023 03:06:23 AM  [*] Sun Jan 29 03:06:23 2023: Train Epoch: 6 [51200/73842 (69%)]	Loss: 198.438141 | Elapsed: 12.29s
01/29/2023 03:06:36 AM  [*] Sun Jan 29 03:06:36 2023: Train Epoch: 6 [57600/73842 (78%)]	Loss: 203.444016 | Elapsed: 12.46s
01/29/2023 03:06:48 AM  [*] Sun Jan 29 03:06:48 2023: Train Epoch: 6 [64000/73842 (87%)]	Loss: 194.107056 | Elapsed: 12.58s
01/29/2023 03:07:01 AM  [*] Sun Jan 29 03:07:01 2023: Train Epoch: 6 [70400/73842 (95%)]	Loss: 181.152283 | Elapsed: 12.51s
01/29/2023 03:07:09 AM  [*] Sun Jan 29 03:07:09 2023:    6    | Tr.loss: 177.630849 | Elapsed:  143.78  s
01/29/2023 03:07:09 AM  [*] Started epoch: 7
01/29/2023 03:07:10 AM  [*] Sun Jan 29 03:07:10 2023: Train Epoch: 7 [  0  /73842 (0 %)]	Loss: 180.329437 | Elapsed: 0.21s
01/29/2023 03:07:22 AM  [*] Sun Jan 29 03:07:22 2023: Train Epoch: 7 [6400 /73842 (9 %)]	Loss: 204.468277 | Elapsed: 12.56s
01/29/2023 03:07:35 AM  [*] Sun Jan 29 03:07:35 2023: Train Epoch: 7 [12800/73842 (17%)]	Loss: 171.152252 | Elapsed: 12.59s
01/29/2023 03:07:47 AM  [*] Sun Jan 29 03:07:47 2023: Train Epoch: 7 [19200/73842 (26%)]	Loss: 196.686737 | Elapsed: 12.56s
01/29/2023 03:08:00 AM  [*] Sun Jan 29 03:08:00 2023: Train Epoch: 7 [25600/73842 (35%)]	Loss: 200.121948 | Elapsed: 12.45s
01/29/2023 03:08:12 AM  [*] Sun Jan 29 03:08:12 2023: Train Epoch: 7 [32000/73842 (43%)]	Loss: 173.001404 | Elapsed: 12.21s
01/29/2023 03:08:24 AM  [*] Sun Jan 29 03:08:24 2023: Train Epoch: 7 [38400/73842 (52%)]	Loss: 173.130035 | Elapsed: 12.22s
01/29/2023 03:08:36 AM  [*] Sun Jan 29 03:08:36 2023: Train Epoch: 7 [44800/73842 (61%)]	Loss: 170.852127 | Elapsed: 12.22s
01/29/2023 03:08:49 AM  [*] Sun Jan 29 03:08:49 2023: Train Epoch: 7 [51200/73842 (69%)]	Loss: 176.796616 | Elapsed: 12.22s
01/29/2023 03:09:01 AM  [*] Sun Jan 29 03:09:01 2023: Train Epoch: 7 [57600/73842 (78%)]	Loss: 175.953262 | Elapsed: 12.23s
01/29/2023 03:09:13 AM  [*] Sun Jan 29 03:09:13 2023: Train Epoch: 7 [64000/73842 (87%)]	Loss: 177.242340 | Elapsed: 12.21s
01/29/2023 03:09:25 AM  [*] Sun Jan 29 03:09:25 2023: Train Epoch: 7 [70400/73842 (95%)]	Loss: 177.011627 | Elapsed: 12.29s
01/29/2023 03:09:34 AM  [*] Sun Jan 29 03:09:34 2023:    7    | Tr.loss: 177.318009 | Elapsed:  144.32  s
01/29/2023 03:09:34 AM  [*] Started epoch: 8
01/29/2023 03:09:34 AM  [*] Sun Jan 29 03:09:34 2023: Train Epoch: 8 [  0  /73842 (0 %)]	Loss: 207.970398 | Elapsed: 0.20s
01/29/2023 03:09:46 AM  [*] Sun Jan 29 03:09:46 2023: Train Epoch: 8 [6400 /73842 (9 %)]	Loss: 184.343658 | Elapsed: 12.30s
01/29/2023 03:09:58 AM  [*] Sun Jan 29 03:09:58 2023: Train Epoch: 8 [12800/73842 (17%)]	Loss: 185.476059 | Elapsed: 12.29s
01/29/2023 03:10:11 AM  [*] Sun Jan 29 03:10:11 2023: Train Epoch: 8 [19200/73842 (26%)]	Loss: 169.858322 | Elapsed: 12.22s
01/29/2023 03:10:23 AM  [*] Sun Jan 29 03:10:23 2023: Train Epoch: 8 [25600/73842 (35%)]	Loss: 156.100845 | Elapsed: 12.20s
01/29/2023 03:10:35 AM  [*] Sun Jan 29 03:10:35 2023: Train Epoch: 8 [32000/73842 (43%)]	Loss: 181.905304 | Elapsed: 12.20s
01/29/2023 03:10:47 AM  [*] Sun Jan 29 03:10:47 2023: Train Epoch: 8 [38400/73842 (52%)]	Loss: 169.578369 | Elapsed: 12.21s
01/29/2023 03:10:59 AM  [*] Sun Jan 29 03:10:59 2023: Train Epoch: 8 [44800/73842 (61%)]	Loss: 164.120270 | Elapsed: 12.23s
01/29/2023 03:11:12 AM  [*] Sun Jan 29 03:11:12 2023: Train Epoch: 8 [51200/73842 (69%)]	Loss: 190.109924 | Elapsed: 12.19s
01/29/2023 03:11:24 AM  [*] Sun Jan 29 03:11:24 2023: Train Epoch: 8 [57600/73842 (78%)]	Loss: 170.419632 | Elapsed: 12.19s
01/29/2023 03:11:36 AM  [*] Sun Jan 29 03:11:36 2023: Train Epoch: 8 [64000/73842 (87%)]	Loss: 181.747299 | Elapsed: 12.29s
01/29/2023 03:11:48 AM  [*] Sun Jan 29 03:11:48 2023: Train Epoch: 8 [70400/73842 (95%)]	Loss: 184.373184 | Elapsed: 12.27s
01/29/2023 03:11:57 AM  [*] Sun Jan 29 03:11:57 2023:    8    | Tr.loss: 177.088538 | Elapsed:  143.11  s
01/29/2023 03:11:57 AM  [*] Started epoch: 9
01/29/2023 03:11:57 AM  [*] Sun Jan 29 03:11:57 2023: Train Epoch: 9 [  0  /73842 (0 %)]	Loss: 181.937286 | Elapsed: 0.21s
01/29/2023 03:12:09 AM  [*] Sun Jan 29 03:12:09 2023: Train Epoch: 9 [6400 /73842 (9 %)]	Loss: 177.520660 | Elapsed: 12.29s
01/29/2023 03:12:21 AM  [*] Sun Jan 29 03:12:21 2023: Train Epoch: 9 [12800/73842 (17%)]	Loss: 199.797943 | Elapsed: 12.23s
01/29/2023 03:12:34 AM  [*] Sun Jan 29 03:12:34 2023: Train Epoch: 9 [19200/73842 (26%)]	Loss: 173.706528 | Elapsed: 12.19s
01/29/2023 03:12:46 AM  [*] Sun Jan 29 03:12:46 2023: Train Epoch: 9 [25600/73842 (35%)]	Loss: 170.061401 | Elapsed: 12.21s
01/29/2023 03:12:58 AM  [*] Sun Jan 29 03:12:58 2023: Train Epoch: 9 [32000/73842 (43%)]	Loss: 164.087296 | Elapsed: 12.20s
01/29/2023 03:13:10 AM  [*] Sun Jan 29 03:13:10 2023: Train Epoch: 9 [38400/73842 (52%)]	Loss: 178.461227 | Elapsed: 12.18s
01/29/2023 03:13:22 AM  [*] Sun Jan 29 03:13:22 2023: Train Epoch: 9 [44800/73842 (61%)]	Loss: 199.100128 | Elapsed: 12.19s
01/29/2023 03:13:31 AM [!] Learning rate: 2.5e-06
01/29/2023 03:13:35 AM  [*] Sun Jan 29 03:13:35 2023: Train Epoch: 9 [51200/73842 (69%)]	Loss: 176.058884 | Elapsed: 12.19s
01/29/2023 03:13:47 AM  [*] Sun Jan 29 03:13:47 2023: Train Epoch: 9 [57600/73842 (78%)]	Loss: 186.344208 | Elapsed: 12.23s
01/29/2023 03:13:59 AM  [*] Sun Jan 29 03:13:59 2023: Train Epoch: 9 [64000/73842 (87%)]	Loss: 196.252258 | Elapsed: 12.20s
01/29/2023 03:14:11 AM  [*] Sun Jan 29 03:14:11 2023: Train Epoch: 9 [70400/73842 (95%)]	Loss: 168.560181 | Elapsed: 12.22s
01/29/2023 03:14:20 AM  [*] Sun Jan 29 03:14:20 2023:    9    | Tr.loss: 176.900551 | Elapsed:  142.94  s
01/29/2023 03:14:20 AM  [*] Started epoch: 10
01/29/2023 03:14:20 AM  [*] Sun Jan 29 03:14:20 2023: Train Epoch: 10 [  0  /73842 (0 %)]	Loss: 182.225647 | Elapsed: 0.21s
01/29/2023 03:14:32 AM  [*] Sun Jan 29 03:14:32 2023: Train Epoch: 10 [6400 /73842 (9 %)]	Loss: 173.127151 | Elapsed: 12.23s
01/29/2023 03:14:44 AM  [*] Sun Jan 29 03:14:44 2023: Train Epoch: 10 [12800/73842 (17%)]	Loss: 173.175323 | Elapsed: 12.31s
01/29/2023 03:14:57 AM  [*] Sun Jan 29 03:14:57 2023: Train Epoch: 10 [19200/73842 (26%)]	Loss: 152.579651 | Elapsed: 12.19s
01/29/2023 03:15:09 AM  [*] Sun Jan 29 03:15:09 2023: Train Epoch: 10 [25600/73842 (35%)]	Loss: 168.134445 | Elapsed: 12.21s
01/29/2023 03:15:21 AM  [*] Sun Jan 29 03:15:21 2023: Train Epoch: 10 [32000/73842 (43%)]	Loss: 179.731445 | Elapsed: 12.21s
01/29/2023 03:15:33 AM  [*] Sun Jan 29 03:15:33 2023: Train Epoch: 10 [38400/73842 (52%)]	Loss: 184.574081 | Elapsed: 12.18s
01/29/2023 03:15:45 AM  [*] Sun Jan 29 03:15:45 2023: Train Epoch: 10 [44800/73842 (61%)]	Loss: 178.714310 | Elapsed: 12.25s
01/29/2023 03:15:58 AM  [*] Sun Jan 29 03:15:58 2023: Train Epoch: 10 [51200/73842 (69%)]	Loss: 179.075211 | Elapsed: 12.20s
01/29/2023 03:16:10 AM  [*] Sun Jan 29 03:16:10 2023: Train Epoch: 10 [57600/73842 (78%)]	Loss: 199.677979 | Elapsed: 12.19s
01/29/2023 03:16:22 AM  [*] Sun Jan 29 03:16:22 2023: Train Epoch: 10 [64000/73842 (87%)]	Loss: 162.079575 | Elapsed: 12.22s
01/29/2023 03:16:34 AM  [*] Sun Jan 29 03:16:34 2023: Train Epoch: 10 [70400/73842 (95%)]	Loss: 166.937119 | Elapsed: 12.21s
01/29/2023 03:16:43 AM  [*] Sun Jan 29 03:16:43 2023:   10    | Tr.loss: 176.706692 | Elapsed:  142.93  s
01/29/2023 03:16:43 AM [!] Sun Jan 29 03:16:43 2023: Dumped results:
                model     : 1674958603-model.torch
		train time: 1674958603-trainTime.npy
		train losses: 1674958603-trainLosses.npy
		train AUC: 1674958603-auc.npy
01/29/2023 03:16:45 AM  [!] Training pretrained model on downstream task...
01/29/2023 03:16:45 AM  [*] Started epoch: 1
01/29/2023 03:16:46 AM  [*] Sun Jan 29 03:16:46 2023: Train Epoch: 1 [  0  /2284  (0 %)]	Loss: 0.800891 | Elapsed: 0.25s | FPR 0.0003 -> TPR 0.4906 & F1 0.6582 | AUC 0.8027
01/29/2023 03:16:49 AM  [*] Sun Jan 29 03:16:49 2023:    1    | Tr.loss: 0.675619 | Elapsed:   3.49   s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7633
01/29/2023 03:16:49 AM  [*] Started epoch: 2
01/29/2023 03:16:49 AM  [*] Sun Jan 29 03:16:49 2023: Train Epoch: 2 [  0  /2284  (0 %)]	Loss: 0.522226 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.3182 & F1 0.4828 | AUC 0.7398
01/29/2023 03:16:52 AM  [*] Sun Jan 29 03:16:52 2023:    2    | Tr.loss: 0.446579 | Elapsed:   3.36   s | FPR 0.0003 -> TPR: 0.04 & F1: 0.07 | AUC: 0.8333
01/29/2023 03:16:52 AM  [*] Started epoch: 3
01/29/2023 03:16:52 AM  [*] Sun Jan 29 03:16:52 2023: Train Epoch: 3 [  0  /2284  (0 %)]	Loss: 0.432073 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.5714 & F1 0.7273 | AUC 0.8761
01/29/2023 03:16:55 AM  [*] Sun Jan 29 03:16:55 2023:    3    | Tr.loss: 0.409170 | Elapsed:   3.29   s | FPR 0.0003 -> TPR: 0.01 & F1: 0.02 | AUC: 0.8605
01/29/2023 03:16:56 AM [!] Sun Jan 29 03:16:56 2023: Dumped results:
                model     : 1674958615-model.torch
		train time: 1674958615-trainTime.npy
		train losses: 1674958615-trainLosses.npy
		train AUC: 1674958615-auc.npy
		train F1s : 1674958615-trainF1s.npy
		train TPRs: 1674958615-trainTPRs.npy
01/29/2023 03:16:56 AM  [!] Training non_pretrained model on downstream task...
01/29/2023 03:16:56 AM  [*] Started epoch: 1
01/29/2023 03:16:56 AM  [*] Sun Jan 29 03:16:56 2023: Train Epoch: 1 [  0  /2284  (0 %)]	Loss: 1.646458 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0465 & F1 0.0889 | AUC 0.4906
01/29/2023 03:16:59 AM  [*] Sun Jan 29 03:16:59 2023:    1    | Tr.loss: 0.858145 | Elapsed:   2.27   s | FPR 0.0003 -> TPR: 0.01 & F1: 0.02 | AUC: 0.6558
01/29/2023 03:16:59 AM  [*] Started epoch: 2
01/29/2023 03:16:59 AM  [*] Sun Jan 29 03:16:59 2023: Train Epoch: 2 [  0  /2284  (0 %)]	Loss: 0.407694 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.1064 & F1 0.1923 | AUC 0.8348
01/29/2023 03:17:01 AM  [*] Sun Jan 29 03:17:01 2023:    2    | Tr.loss: 0.459662 | Elapsed:   2.26   s | FPR 0.0003 -> TPR: 0.06 & F1: 0.11 | AUC: 0.8151
01/29/2023 03:17:01 AM  [*] Started epoch: 3
01/29/2023 03:17:01 AM  [*] Sun Jan 29 03:17:01 2023: Train Epoch: 3 [  0  /2284  (0 %)]	Loss: 0.376497 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.1628 & F1 0.2800 | AUC 0.9014
01/29/2023 03:17:03 AM  [*] Sun Jan 29 03:17:03 2023:    3    | Tr.loss: 0.417958 | Elapsed:   2.26   s | FPR 0.0003 -> TPR: 0.03 & F1: 0.05 | AUC: 0.8510
01/29/2023 03:17:04 AM [!] Sun Jan 29 03:17:04 2023: Dumped results:
                model     : 1674958623-model.torch
		train time: 1674958623-trainTime.npy
		train losses: 1674958623-trainLosses.npy
		train AUC: 1674958623-auc.npy
		train F1s : 1674958623-trainF1s.npy
		train TPRs: 1674958623-trainTPRs.npy
01/29/2023 03:17:04 AM  [!] Training full_data model on downstream task...
01/29/2023 03:17:04 AM  [*] Started epoch: 1
01/29/2023 03:17:04 AM  [*] Sun Jan 29 03:17:04 2023: Train Epoch: 1 [  0  /76126 (0 %)]	Loss: 3.404727 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.5875
01/29/2023 03:17:10 AM  [*] Sun Jan 29 03:17:10 2023: Train Epoch: 1 [6400 /76126 (8 %)]	Loss: 0.377201 | Elapsed: 6.16s | FPR 0.0003 -> TPR 0.2308 & F1 0.3750 | AUC 0.8286
01/29/2023 03:17:16 AM  [*] Sun Jan 29 03:17:16 2023: Train Epoch: 1 [12800/76126 (17%)]	Loss: 0.529732 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.1515 & F1 0.2632 | AUC 0.8369
01/29/2023 03:17:23 AM  [*] Sun Jan 29 03:17:23 2023: Train Epoch: 1 [19200/76126 (25%)]	Loss: 0.275825 | Elapsed: 6.16s | FPR 0.0003 -> TPR 0.6522 & F1 0.7895 | AUC 0.9537
01/29/2023 03:17:29 AM  [*] Sun Jan 29 03:17:29 2023: Train Epoch: 1 [25600/76126 (34%)]	Loss: 0.461939 | Elapsed: 6.15s | FPR 0.0003 -> TPR 0.5571 & F1 0.7156 | AUC 0.8824
01/29/2023 03:17:35 AM  [*] Sun Jan 29 03:17:35 2023: Train Epoch: 1 [32000/76126 (42%)]	Loss: 0.366069 | Elapsed: 6.16s | FPR 0.0003 -> TPR 0.7391 & F1 0.8500 | AUC 0.9439
01/29/2023 03:17:41 AM  [*] Sun Jan 29 03:17:41 2023: Train Epoch: 1 [38400/76126 (50%)]	Loss: 0.173099 | Elapsed: 6.16s | FPR 0.0003 -> TPR 0.7778 & F1 0.8750 | AUC 0.9826
01/29/2023 03:17:47 AM  [*] Sun Jan 29 03:17:47 2023: Train Epoch: 1 [44800/76126 (59%)]	Loss: 0.338969 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.5135 & F1 0.6786 | AUC 0.9064
01/29/2023 03:17:53 AM  [*] Sun Jan 29 03:17:53 2023: Train Epoch: 1 [51200/76126 (67%)]	Loss: 0.235076 | Elapsed: 6.16s | FPR 0.0003 -> TPR 0.6615 & F1 0.7963 | AUC 0.9275
01/29/2023 03:18:00 AM  [*] Sun Jan 29 03:18:00 2023: Train Epoch: 1 [57600/76126 (76%)]	Loss: 0.150463 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.9444 & F1 0.9714 | AUC 0.9866
01/29/2023 03:18:06 AM [!] Learning rate: 2.5e-05
01/29/2023 03:18:06 AM  [*] Sun Jan 29 03:18:06 2023: Train Epoch: 1 [64000/76126 (84%)]	Loss: 0.246960 | Elapsed: 6.16s | FPR 0.0003 -> TPR 0.5672 & F1 0.7238 | AUC 0.9584
01/29/2023 03:18:12 AM  [*] Sun Jan 29 03:18:12 2023: Train Epoch: 1 [70400/76126 (92%)]	Loss: 0.198346 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.8571 & F1 0.9231 | AUC 0.9833
01/29/2023 03:18:19 AM  [*] Sun Jan 29 03:18:19 2023:    1    | Tr.loss: 0.306531 | Elapsed:   75.19  s | FPR 0.0003 -> TPR: 0.02 & F1: 0.05 | AUC: 0.9321
01/29/2023 03:18:19 AM  [*] Started epoch: 2
01/29/2023 03:18:19 AM  [*] Sun Jan 29 03:18:19 2023: Train Epoch: 2 [  0  /76126 (0 %)]	Loss: 0.097736 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.9778 & F1 0.9888 | AUC 0.9953
01/29/2023 03:18:25 AM  [*] Sun Jan 29 03:18:25 2023: Train Epoch: 2 [6400 /76126 (8 %)]	Loss: 0.107594 | Elapsed: 6.16s | FPR 0.0003 -> TPR 0.8438 & F1 0.9153 | AUC 0.9891
01/29/2023 03:18:32 AM  [*] Sun Jan 29 03:18:32 2023: Train Epoch: 2 [12800/76126 (17%)]	Loss: 0.118159 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.6610 & F1 0.7959 | AUC 0.9764
01/29/2023 03:18:38 AM  [*] Sun Jan 29 03:18:38 2023: Train Epoch: 2 [19200/76126 (25%)]	Loss: 0.141913 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.6269 & F1 0.7706 | AUC 0.9656
01/29/2023 03:18:44 AM  [*] Sun Jan 29 03:18:44 2023: Train Epoch: 2 [25600/76126 (34%)]	Loss: 0.098999 | Elapsed: 6.16s | FPR 0.0003 -> TPR 0.9552 & F1 0.9771 | AUC 0.9982
01/29/2023 03:18:50 AM  [*] Sun Jan 29 03:18:50 2023: Train Epoch: 2 [32000/76126 (42%)]	Loss: 0.134785 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.7612 & F1 0.8644 | AUC 0.9792
01/29/2023 03:18:56 AM  [*] Sun Jan 29 03:18:56 2023: Train Epoch: 2 [38400/76126 (50%)]	Loss: 0.278092 | Elapsed: 6.15s | FPR 0.0003 -> TPR 0.6111 & F1 0.7586 | AUC 0.9568
01/29/2023 03:19:02 AM  [*] Sun Jan 29 03:19:02 2023: Train Epoch: 2 [44800/76126 (59%)]	Loss: 0.147183 | Elapsed: 6.15s | FPR 0.0003 -> TPR 0.6818 & F1 0.8108 | AUC 0.9728
01/29/2023 03:19:09 AM  [*] Sun Jan 29 03:19:09 2023: Train Epoch: 2 [51200/76126 (67%)]	Loss: 0.158372 | Elapsed: 6.15s | FPR 0.0003 -> TPR 0.7647 & F1 0.8667 | AUC 0.9706
01/29/2023 03:19:09 AM [!] Learning rate: 2.5e-06
01/29/2023 03:19:15 AM  [*] Sun Jan 29 03:19:15 2023: Train Epoch: 2 [57600/76126 (76%)]	Loss: 0.171873 | Elapsed: 6.15s | FPR 0.0003 -> TPR 0.6615 & F1 0.7963 | AUC 0.9842
01/29/2023 03:19:21 AM  [*] Sun Jan 29 03:19:21 2023: Train Epoch: 2 [64000/76126 (84%)]	Loss: 0.185094 | Elapsed: 6.16s | FPR 0.0003 -> TPR 0.8939 & F1 0.9440 | AUC 0.9799
01/29/2023 03:19:27 AM  [*] Sun Jan 29 03:19:27 2023: Train Epoch: 2 [70400/76126 (92%)]	Loss: 0.138979 | Elapsed: 6.16s | FPR 0.0003 -> TPR 0.8904 & F1 0.9420 | AUC 0.9929
01/29/2023 03:19:35 AM  [*] Sun Jan 29 03:19:35 2023:    2    | Tr.loss: 0.173275 | Elapsed:   75.38  s | FPR 0.0003 -> TPR: 0.49 & F1: 0.66 | AUC: 0.9790
01/29/2023 03:19:35 AM  [*] Started epoch: 3
01/29/2023 03:19:35 AM  [*] Sun Jan 29 03:19:35 2023: Train Epoch: 3 [  0  /76126 (0 %)]	Loss: 0.386034 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.5000 & F1 0.6667 | AUC 0.9251
01/29/2023 03:19:41 AM  [*] Sun Jan 29 03:19:41 2023: Train Epoch: 3 [6400 /76126 (8 %)]	Loss: 0.218682 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.6716 & F1 0.8036 | AUC 0.9815
01/29/2023 03:19:47 AM  [*] Sun Jan 29 03:19:47 2023: Train Epoch: 3 [12800/76126 (17%)]	Loss: 0.103900 | Elapsed: 6.16s | FPR 0.0003 -> TPR 0.8308 & F1 0.9076 | AUC 0.9873
01/29/2023 03:19:53 AM  [*] Sun Jan 29 03:19:53 2023: Train Epoch: 3 [19200/76126 (25%)]	Loss: 0.124909 | Elapsed: 6.15s | FPR 0.0003 -> TPR 0.9048 & F1 0.9500 | AUC 0.9888
01/29/2023 03:19:59 AM  [*] Sun Jan 29 03:19:59 2023: Train Epoch: 3 [25600/76126 (34%)]	Loss: 0.142533 | Elapsed: 6.16s | FPR 0.0003 -> TPR 0.9104 & F1 0.9531 | AUC 0.9837
01/29/2023 03:20:06 AM  [*] Sun Jan 29 03:20:06 2023: Train Epoch: 3 [32000/76126 (42%)]	Loss: 0.146824 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.7077 & F1 0.8288 | AUC 0.9670
01/29/2023 03:20:12 AM  [*] Sun Jan 29 03:20:12 2023: Train Epoch: 3 [38400/76126 (50%)]	Loss: 0.132498 | Elapsed: 6.15s | FPR 0.0003 -> TPR 0.9342 & F1 0.9660 | AUC 0.9846
01/29/2023 03:20:13 AM [!] Learning rate: 2.5000000000000004e-07
01/29/2023 03:20:18 AM  [*] Sun Jan 29 03:20:18 2023: Train Epoch: 3 [44800/76126 (59%)]	Loss: 0.107544 | Elapsed: 6.27s | FPR 0.0003 -> TPR 0.9375 & F1 0.9677 | AUC 0.9905
01/29/2023 03:20:24 AM  [*] Sun Jan 29 03:20:24 2023: Train Epoch: 3 [51200/76126 (67%)]	Loss: 0.217288 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.7260 & F1 0.8413 | AUC 0.9630
01/29/2023 03:20:30 AM  [*] Sun Jan 29 03:20:30 2023: Train Epoch: 3 [57600/76126 (76%)]	Loss: 0.115830 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.8732 & F1 0.9323 | AUC 0.9908
01/29/2023 03:20:37 AM  [*] Sun Jan 29 03:20:37 2023: Train Epoch: 3 [64000/76126 (84%)]	Loss: 0.121763 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.9077 & F1 0.9516 | AUC 0.9890
01/29/2023 03:20:43 AM  [*] Sun Jan 29 03:20:43 2023: Train Epoch: 3 [70400/76126 (92%)]	Loss: 0.164420 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.6716 & F1 0.8036 | AUC 0.9774
01/29/2023 03:20:50 AM  [*] Sun Jan 29 03:20:50 2023:    3    | Tr.loss: 0.165682 | Elapsed:   75.60  s | FPR 0.0003 -> TPR: 0.44 & F1: 0.61 | AUC: 0.9809
01/29/2023 03:20:51 AM [!] Sun Jan 29 03:20:51 2023: Dumped results:
                model     : 1674958850-model.torch
		train time: 1674958850-trainTime.npy
		train losses: 1674958850-trainLosses.npy
		train AUC: 1674958850-auc.npy
		train F1s : 1674958850-trainF1s.npy
		train TPRs: 1674958850-trainTPRs.npy
01/29/2023 03:20:51 AM  [*] Evaluating pretrained model on test set...
01/29/2023 03:20:56 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0004 | F1: 0.0009
01/29/2023 03:20:56 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.0011 | F1: 0.0021
01/29/2023 03:20:56 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.0021 | F1: 0.0042
01/29/2023 03:20:56 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.0037 | F1: 0.0074
01/29/2023 03:20:56 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.0095 | F1: 0.0186
01/29/2023 03:20:56 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.2649 | F1: 0.4106
01/29/2023 03:20:56 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.5088 | F1: 0.6384
01/29/2023 03:20:56 AM  [*] Evaluating non_pretrained model on test set...
01/29/2023 03:21:01 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0233 | F1: 0.0455
01/29/2023 03:21:01 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.0573 | F1: 0.1084
01/29/2023 03:21:01 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.0962 | F1: 0.1755
01/29/2023 03:21:01 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.1557 | F1: 0.2688
01/29/2023 03:21:01 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.2304 | F1: 0.3719
01/29/2023 03:21:01 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.3300 | F1: 0.4869
01/29/2023 03:21:01 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.4618 | F1: 0.5970
01/29/2023 03:21:01 AM  [*] Evaluating full_data model on test set...
01/29/2023 03:21:06 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0414 | F1: 0.0795
01/29/2023 03:21:06 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.2510 | F1: 0.4012
01/29/2023 03:21:06 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.3368 | F1: 0.5036
01/29/2023 03:21:06 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3603 | F1: 0.5288
01/29/2023 03:21:06 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.4448 | F1: 0.6121
01/29/2023 03:21:06 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.5728 | F1: 0.7167
01/29/2023 03:21:06 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.7994 | F1: 0.8485
01/29/2023 03:21:06 AM  [!] Running pre-training split 3/3
01/29/2023 03:21:09 AM  [!] Pre-training model...
01/29/2023 03:21:09 AM  [*] Masking sequences...
01/29/2023 03:21:32 AM  [*] Started epoch: 1
01/29/2023 03:21:33 AM  [*] Sun Jan 29 03:21:33 2023: Train Epoch: 1 [  0  /73842 (0 %)]	Loss: 411.861694 | Elapsed: 0.33s
01/29/2023 03:21:45 AM  [*] Sun Jan 29 03:21:45 2023: Train Epoch: 1 [6400 /73842 (9 %)]	Loss: 240.235703 | Elapsed: 12.28s
01/29/2023 03:21:57 AM  [*] Sun Jan 29 03:21:57 2023: Train Epoch: 1 [12800/73842 (17%)]	Loss: 195.159195 | Elapsed: 12.35s
01/29/2023 03:22:10 AM  [*] Sun Jan 29 03:22:10 2023: Train Epoch: 1 [19200/73842 (26%)]	Loss: 179.963409 | Elapsed: 12.44s
01/29/2023 03:22:22 AM  [*] Sun Jan 29 03:22:22 2023: Train Epoch: 1 [25600/73842 (35%)]	Loss: 210.535828 | Elapsed: 12.42s
01/29/2023 03:22:35 AM  [*] Sun Jan 29 03:22:35 2023: Train Epoch: 1 [32000/73842 (43%)]	Loss: 195.629425 | Elapsed: 12.39s
01/29/2023 03:22:47 AM  [*] Sun Jan 29 03:22:47 2023: Train Epoch: 1 [38400/73842 (52%)]	Loss: 220.958496 | Elapsed: 12.39s
01/29/2023 03:22:59 AM  [*] Sun Jan 29 03:22:59 2023: Train Epoch: 1 [44800/73842 (61%)]	Loss: 191.539749 | Elapsed: 12.40s
01/29/2023 03:23:12 AM  [*] Sun Jan 29 03:23:12 2023: Train Epoch: 1 [51200/73842 (69%)]	Loss: 200.980316 | Elapsed: 12.37s
01/29/2023 03:23:24 AM  [*] Sun Jan 29 03:23:24 2023: Train Epoch: 1 [57600/73842 (78%)]	Loss: 178.957306 | Elapsed: 12.47s
01/29/2023 03:23:37 AM  [*] Sun Jan 29 03:23:37 2023: Train Epoch: 1 [64000/73842 (87%)]	Loss: 202.880463 | Elapsed: 12.42s
01/29/2023 03:23:50 AM  [*] Sun Jan 29 03:23:50 2023: Train Epoch: 1 [70400/73842 (95%)]	Loss: 179.024567 | Elapsed: 12.91s
01/29/2023 03:24:09 AM  [*] Sun Jan 29 03:24:09 2023:    1    | Tr.loss: 203.453822 | Elapsed:  156.79  s
01/29/2023 03:24:09 AM  [*] Started epoch: 2
01/29/2023 03:24:09 AM  [*] Sun Jan 29 03:24:09 2023: Train Epoch: 2 [  0  /73842 (0 %)]	Loss: 159.205841 | Elapsed: 0.20s
01/29/2023 03:24:22 AM  [*] Sun Jan 29 03:24:22 2023: Train Epoch: 2 [6400 /73842 (9 %)]	Loss: 189.708069 | Elapsed: 12.43s
01/29/2023 03:24:34 AM  [*] Sun Jan 29 03:24:34 2023: Train Epoch: 2 [12800/73842 (17%)]	Loss: 171.488480 | Elapsed: 12.51s
01/29/2023 03:24:47 AM  [*] Sun Jan 29 03:24:47 2023: Train Epoch: 2 [19200/73842 (26%)]	Loss: 176.893036 | Elapsed: 12.48s
01/29/2023 03:24:59 AM  [*] Sun Jan 29 03:24:59 2023: Train Epoch: 2 [25600/73842 (35%)]	Loss: 201.198181 | Elapsed: 12.47s
01/29/2023 03:25:12 AM  [*] Sun Jan 29 03:25:12 2023: Train Epoch: 2 [32000/73842 (43%)]	Loss: 194.965637 | Elapsed: 12.47s
01/29/2023 03:25:24 AM  [*] Sun Jan 29 03:25:24 2023: Train Epoch: 2 [38400/73842 (52%)]	Loss: 166.495819 | Elapsed: 12.45s
01/29/2023 03:25:37 AM  [*] Sun Jan 29 03:25:37 2023: Train Epoch: 2 [44800/73842 (61%)]	Loss: 185.081818 | Elapsed: 12.46s
01/29/2023 03:25:49 AM  [*] Sun Jan 29 03:25:49 2023: Train Epoch: 2 [51200/73842 (69%)]	Loss: 163.739227 | Elapsed: 12.48s
01/29/2023 03:26:02 AM  [*] Sun Jan 29 03:26:02 2023: Train Epoch: 2 [57600/73842 (78%)]	Loss: 187.444061 | Elapsed: 12.50s
01/29/2023 03:26:14 AM  [*] Sun Jan 29 03:26:14 2023: Train Epoch: 2 [64000/73842 (87%)]	Loss: 174.618683 | Elapsed: 12.49s
01/29/2023 03:26:27 AM  [*] Sun Jan 29 03:26:27 2023: Train Epoch: 2 [70400/73842 (95%)]	Loss: 187.158005 | Elapsed: 12.45s
01/29/2023 03:26:37 AM  [*] Sun Jan 29 03:26:37 2023:    2    | Tr.loss: 184.253291 | Elapsed:  147.45  s
01/29/2023 03:26:37 AM  [*] Started epoch: 3
01/29/2023 03:26:37 AM  [*] Sun Jan 29 03:26:37 2023: Train Epoch: 3 [  0  /73842 (0 %)]	Loss: 197.922501 | Elapsed: 0.23s
01/29/2023 03:26:49 AM  [*] Sun Jan 29 03:26:49 2023: Train Epoch: 3 [6400 /73842 (9 %)]	Loss: 180.137390 | Elapsed: 12.43s
01/29/2023 03:27:02 AM  [*] Sun Jan 29 03:27:02 2023: Train Epoch: 3 [12800/73842 (17%)]	Loss: 195.003479 | Elapsed: 12.52s
01/29/2023 03:27:14 AM  [*] Sun Jan 29 03:27:14 2023: Train Epoch: 3 [19200/73842 (26%)]	Loss: 177.615631 | Elapsed: 12.44s
01/29/2023 03:27:27 AM  [*] Sun Jan 29 03:27:27 2023: Train Epoch: 3 [25600/73842 (35%)]	Loss: 173.192963 | Elapsed: 12.39s
01/29/2023 03:27:39 AM  [*] Sun Jan 29 03:27:39 2023: Train Epoch: 3 [32000/73842 (43%)]	Loss: 191.456497 | Elapsed: 12.38s
01/29/2023 03:27:51 AM  [*] Sun Jan 29 03:27:51 2023: Train Epoch: 3 [38400/73842 (52%)]	Loss: 155.111847 | Elapsed: 12.43s
01/29/2023 03:28:04 AM  [*] Sun Jan 29 03:28:04 2023: Train Epoch: 3 [44800/73842 (61%)]	Loss: 185.942566 | Elapsed: 12.41s
01/29/2023 03:28:16 AM  [*] Sun Jan 29 03:28:16 2023: Train Epoch: 3 [51200/73842 (69%)]	Loss: 177.686615 | Elapsed: 12.44s
01/29/2023 03:28:29 AM  [*] Sun Jan 29 03:28:29 2023: Train Epoch: 3 [57600/73842 (78%)]	Loss: 174.698105 | Elapsed: 12.43s
01/29/2023 03:28:41 AM  [*] Sun Jan 29 03:28:41 2023: Train Epoch: 3 [64000/73842 (87%)]	Loss: 199.301086 | Elapsed: 12.42s
01/29/2023 03:28:54 AM  [*] Sun Jan 29 03:28:54 2023: Train Epoch: 3 [70400/73842 (95%)]	Loss: 174.442566 | Elapsed: 12.44s
01/29/2023 03:29:02 AM  [*] Sun Jan 29 03:29:02 2023:    3    | Tr.loss: 180.159013 | Elapsed:  145.43  s
01/29/2023 03:29:02 AM  [*] Started epoch: 4
01/29/2023 03:29:02 AM  [*] Sun Jan 29 03:29:02 2023: Train Epoch: 4 [  0  /73842 (0 %)]	Loss: 171.802277 | Elapsed: 0.21s
01/29/2023 03:29:15 AM  [*] Sun Jan 29 03:29:15 2023: Train Epoch: 4 [6400 /73842 (9 %)]	Loss: 184.093903 | Elapsed: 12.47s
01/29/2023 03:29:27 AM  [*] Sun Jan 29 03:29:27 2023: Train Epoch: 4 [12800/73842 (17%)]	Loss: 190.385803 | Elapsed: 12.52s
01/29/2023 03:29:40 AM  [*] Sun Jan 29 03:29:40 2023: Train Epoch: 4 [19200/73842 (26%)]	Loss: 165.000397 | Elapsed: 12.46s
01/29/2023 03:29:52 AM  [*] Sun Jan 29 03:29:52 2023: Train Epoch: 4 [25600/73842 (35%)]	Loss: 189.932037 | Elapsed: 12.56s
01/29/2023 03:30:05 AM  [*] Sun Jan 29 03:30:05 2023: Train Epoch: 4 [32000/73842 (43%)]	Loss: 167.441803 | Elapsed: 12.36s
01/29/2023 03:30:17 AM  [*] Sun Jan 29 03:30:17 2023: Train Epoch: 4 [38400/73842 (52%)]	Loss: 183.436340 | Elapsed: 12.39s
01/29/2023 03:30:29 AM  [*] Sun Jan 29 03:30:29 2023: Train Epoch: 4 [44800/73842 (61%)]	Loss: 180.267334 | Elapsed: 12.40s
01/29/2023 03:30:42 AM  [*] Sun Jan 29 03:30:42 2023: Train Epoch: 4 [51200/73842 (69%)]	Loss: 181.099808 | Elapsed: 12.42s
01/29/2023 03:30:54 AM  [*] Sun Jan 29 03:30:54 2023: Train Epoch: 4 [57600/73842 (78%)]	Loss: 181.237549 | Elapsed: 12.41s
01/29/2023 03:31:07 AM  [*] Sun Jan 29 03:31:07 2023: Train Epoch: 4 [64000/73842 (87%)]	Loss: 176.285248 | Elapsed: 12.38s
01/29/2023 03:31:19 AM  [*] Sun Jan 29 03:31:19 2023: Train Epoch: 4 [70400/73842 (95%)]	Loss: 160.585938 | Elapsed: 12.39s
01/29/2023 03:31:28 AM  [*] Sun Jan 29 03:31:28 2023:    4    | Tr.loss: 177.911848 | Elapsed:  145.61  s
01/29/2023 03:31:28 AM  [*] Started epoch: 5
01/29/2023 03:31:28 AM  [*] Sun Jan 29 03:31:28 2023: Train Epoch: 5 [  0  /73842 (0 %)]	Loss: 193.394501 | Elapsed: 0.23s
01/29/2023 03:31:40 AM  [*] Sun Jan 29 03:31:40 2023: Train Epoch: 5 [6400 /73842 (9 %)]	Loss: 199.999207 | Elapsed: 12.50s
01/29/2023 03:31:53 AM  [*] Sun Jan 29 03:31:53 2023: Train Epoch: 5 [12800/73842 (17%)]	Loss: 175.215790 | Elapsed: 12.44s
01/29/2023 03:32:05 AM  [*] Sun Jan 29 03:32:05 2023: Train Epoch: 5 [19200/73842 (26%)]	Loss: 183.688263 | Elapsed: 12.42s
01/29/2023 03:32:16 AM [!] Learning rate: 2.5e-05
01/29/2023 03:32:18 AM  [*] Sun Jan 29 03:32:18 2023: Train Epoch: 5 [25600/73842 (35%)]	Loss: 173.840515 | Elapsed: 12.42s
01/29/2023 03:32:30 AM  [*] Sun Jan 29 03:32:30 2023: Train Epoch: 5 [32000/73842 (43%)]	Loss: 181.026123 | Elapsed: 12.42s
01/29/2023 03:32:43 AM  [*] Sun Jan 29 03:32:43 2023: Train Epoch: 5 [38400/73842 (52%)]	Loss: 135.646011 | Elapsed: 12.42s
01/29/2023 03:32:55 AM  [*] Sun Jan 29 03:32:55 2023: Train Epoch: 5 [44800/73842 (61%)]	Loss: 163.730011 | Elapsed: 12.40s
01/29/2023 03:33:07 AM  [*] Sun Jan 29 03:33:07 2023: Train Epoch: 5 [51200/73842 (69%)]	Loss: 159.056854 | Elapsed: 12.42s
01/29/2023 03:33:20 AM  [*] Sun Jan 29 03:33:20 2023: Train Epoch: 5 [57600/73842 (78%)]	Loss: 181.298386 | Elapsed: 12.44s
01/29/2023 03:33:32 AM  [*] Sun Jan 29 03:33:32 2023: Train Epoch: 5 [64000/73842 (87%)]	Loss: 156.273880 | Elapsed: 12.36s
01/29/2023 03:33:45 AM  [*] Sun Jan 29 03:33:45 2023: Train Epoch: 5 [70400/73842 (95%)]	Loss: 183.566040 | Elapsed: 12.48s
01/29/2023 03:33:53 AM  [*] Sun Jan 29 03:33:53 2023:    5    | Tr.loss: 176.321082 | Elapsed:  145.59  s
01/29/2023 03:33:53 AM  [*] Started epoch: 6
01/29/2023 03:33:53 AM  [*] Sun Jan 29 03:33:53 2023: Train Epoch: 6 [  0  /73842 (0 %)]	Loss: 167.522705 | Elapsed: 0.21s
01/29/2023 03:34:06 AM  [*] Sun Jan 29 03:34:06 2023: Train Epoch: 6 [6400 /73842 (9 %)]	Loss: 185.297760 | Elapsed: 12.51s
01/29/2023 03:34:18 AM  [*] Sun Jan 29 03:34:18 2023: Train Epoch: 6 [12800/73842 (17%)]	Loss: 173.722961 | Elapsed: 12.46s
01/29/2023 03:34:31 AM  [*] Sun Jan 29 03:34:31 2023: Train Epoch: 6 [19200/73842 (26%)]	Loss: 164.453232 | Elapsed: 12.40s
01/29/2023 03:34:43 AM  [*] Sun Jan 29 03:34:43 2023: Train Epoch: 6 [25600/73842 (35%)]	Loss: 163.092987 | Elapsed: 12.42s
01/29/2023 03:34:56 AM  [*] Sun Jan 29 03:34:56 2023: Train Epoch: 6 [32000/73842 (43%)]	Loss: 172.010040 | Elapsed: 12.42s
01/29/2023 03:35:08 AM  [*] Sun Jan 29 03:35:08 2023: Train Epoch: 6 [38400/73842 (52%)]	Loss: 185.759979 | Elapsed: 12.42s
01/29/2023 03:35:21 AM  [*] Sun Jan 29 03:35:21 2023: Train Epoch: 6 [44800/73842 (61%)]	Loss: 170.474426 | Elapsed: 12.40s
01/29/2023 03:35:33 AM  [*] Sun Jan 29 03:35:33 2023: Train Epoch: 6 [51200/73842 (69%)]	Loss: 184.442322 | Elapsed: 12.38s
01/29/2023 03:35:45 AM  [*] Sun Jan 29 03:35:45 2023: Train Epoch: 6 [57600/73842 (78%)]	Loss: 192.358444 | Elapsed: 12.39s
01/29/2023 03:35:58 AM  [*] Sun Jan 29 03:35:58 2023: Train Epoch: 6 [64000/73842 (87%)]	Loss: 179.623932 | Elapsed: 12.43s
01/29/2023 03:36:10 AM  [*] Sun Jan 29 03:36:10 2023: Train Epoch: 6 [70400/73842 (95%)]	Loss: 193.629364 | Elapsed: 12.49s
01/29/2023 03:36:19 AM  [*] Sun Jan 29 03:36:19 2023:    6    | Tr.loss: 175.644897 | Elapsed:  145.62  s
01/29/2023 03:36:19 AM  [*] Started epoch: 7
01/29/2023 03:36:19 AM  [*] Sun Jan 29 03:36:19 2023: Train Epoch: 7 [  0  /73842 (0 %)]	Loss: 180.524124 | Elapsed: 0.23s
01/29/2023 03:36:32 AM  [*] Sun Jan 29 03:36:32 2023: Train Epoch: 7 [6400 /73842 (9 %)]	Loss: 150.913757 | Elapsed: 12.44s
01/29/2023 03:36:44 AM  [*] Sun Jan 29 03:36:44 2023: Train Epoch: 7 [12800/73842 (17%)]	Loss: 173.277771 | Elapsed: 12.44s
01/29/2023 03:36:56 AM  [*] Sun Jan 29 03:36:56 2023: Train Epoch: 7 [19200/73842 (26%)]	Loss: 169.184036 | Elapsed: 12.41s
01/29/2023 03:37:09 AM  [*] Sun Jan 29 03:37:09 2023: Train Epoch: 7 [25600/73842 (35%)]	Loss: 182.626404 | Elapsed: 12.41s
01/29/2023 03:37:21 AM  [*] Sun Jan 29 03:37:21 2023: Train Epoch: 7 [32000/73842 (43%)]	Loss: 203.137421 | Elapsed: 12.39s
01/29/2023 03:37:34 AM  [*] Sun Jan 29 03:37:34 2023: Train Epoch: 7 [38400/73842 (52%)]	Loss: 182.212463 | Elapsed: 12.39s
01/29/2023 03:37:46 AM  [*] Sun Jan 29 03:37:46 2023: Train Epoch: 7 [44800/73842 (61%)]	Loss: 197.836273 | Elapsed: 12.38s
01/29/2023 03:37:58 AM  [*] Sun Jan 29 03:37:58 2023: Train Epoch: 7 [51200/73842 (69%)]	Loss: 194.292114 | Elapsed: 12.42s
01/29/2023 03:38:11 AM  [*] Sun Jan 29 03:38:11 2023: Train Epoch: 7 [57600/73842 (78%)]	Loss: 168.529144 | Elapsed: 12.38s
01/29/2023 03:38:23 AM  [*] Sun Jan 29 03:38:23 2023: Train Epoch: 7 [64000/73842 (87%)]	Loss: 176.901184 | Elapsed: 12.38s
01/29/2023 03:38:36 AM  [*] Sun Jan 29 03:38:36 2023: Train Epoch: 7 [70400/73842 (95%)]	Loss: 173.174500 | Elapsed: 12.47s
01/29/2023 03:38:44 AM  [*] Sun Jan 29 03:38:44 2023:    7    | Tr.loss: 175.358436 | Elapsed:  145.40  s
01/29/2023 03:38:44 AM  [*] Started epoch: 8
01/29/2023 03:38:45 AM  [*] Sun Jan 29 03:38:45 2023: Train Epoch: 8 [  0  /73842 (0 %)]	Loss: 155.470398 | Elapsed: 0.25s
01/29/2023 03:38:57 AM  [*] Sun Jan 29 03:38:57 2023: Train Epoch: 8 [6400 /73842 (9 %)]	Loss: 169.851288 | Elapsed: 12.53s
01/29/2023 03:39:10 AM  [*] Sun Jan 29 03:39:10 2023: Train Epoch: 8 [12800/73842 (17%)]	Loss: 188.525574 | Elapsed: 12.50s
01/29/2023 03:39:22 AM  [*] Sun Jan 29 03:39:22 2023: Train Epoch: 8 [19200/73842 (26%)]	Loss: 191.570496 | Elapsed: 12.48s
01/29/2023 03:39:35 AM  [*] Sun Jan 29 03:39:35 2023: Train Epoch: 8 [25600/73842 (35%)]	Loss: 172.255554 | Elapsed: 12.66s
01/29/2023 03:39:47 AM  [*] Sun Jan 29 03:39:47 2023: Train Epoch: 8 [32000/73842 (43%)]	Loss: 195.290588 | Elapsed: 12.67s
01/29/2023 03:40:00 AM  [*] Sun Jan 29 03:40:00 2023: Train Epoch: 8 [38400/73842 (52%)]	Loss: 205.382950 | Elapsed: 12.44s
01/29/2023 03:40:12 AM  [*] Sun Jan 29 03:40:12 2023: Train Epoch: 8 [44800/73842 (61%)]	Loss: 162.151245 | Elapsed: 12.37s
01/29/2023 03:40:25 AM  [*] Sun Jan 29 03:40:25 2023: Train Epoch: 8 [51200/73842 (69%)]	Loss: 150.609268 | Elapsed: 12.39s
01/29/2023 03:40:37 AM  [*] Sun Jan 29 03:40:37 2023: Train Epoch: 8 [57600/73842 (78%)]	Loss: 164.541916 | Elapsed: 12.41s
01/29/2023 03:40:49 AM  [*] Sun Jan 29 03:40:49 2023: Train Epoch: 8 [64000/73842 (87%)]	Loss: 175.282104 | Elapsed: 12.44s
01/29/2023 03:41:02 AM  [*] Sun Jan 29 03:41:02 2023: Train Epoch: 8 [70400/73842 (95%)]	Loss: 185.256882 | Elapsed: 12.49s
01/29/2023 03:41:11 AM  [*] Sun Jan 29 03:41:11 2023:    8    | Tr.loss: 175.166079 | Elapsed:  146.26  s
01/29/2023 03:41:11 AM  [*] Started epoch: 9
01/29/2023 03:41:11 AM  [*] Sun Jan 29 03:41:11 2023: Train Epoch: 9 [  0  /73842 (0 %)]	Loss: 169.169525 | Elapsed: 0.21s
01/29/2023 03:41:23 AM  [*] Sun Jan 29 03:41:23 2023: Train Epoch: 9 [6400 /73842 (9 %)]	Loss: 185.071304 | Elapsed: 12.48s
01/29/2023 03:41:36 AM  [*] Sun Jan 29 03:41:36 2023: Train Epoch: 9 [12800/73842 (17%)]	Loss: 187.144592 | Elapsed: 12.61s
01/29/2023 03:41:48 AM  [*] Sun Jan 29 03:41:48 2023: Train Epoch: 9 [19200/73842 (26%)]	Loss: 172.532150 | Elapsed: 12.35s
01/29/2023 03:42:01 AM  [*] Sun Jan 29 03:42:01 2023: Train Epoch: 9 [25600/73842 (35%)]	Loss: 156.210632 | Elapsed: 12.40s
01/29/2023 03:42:13 AM  [*] Sun Jan 29 03:42:13 2023: Train Epoch: 9 [32000/73842 (43%)]	Loss: 158.780518 | Elapsed: 12.37s
01/29/2023 03:42:25 AM  [*] Sun Jan 29 03:42:25 2023: Train Epoch: 9 [38400/73842 (52%)]	Loss: 172.567322 | Elapsed: 12.35s
01/29/2023 03:42:38 AM  [*] Sun Jan 29 03:42:38 2023: Train Epoch: 9 [44800/73842 (61%)]	Loss: 194.431808 | Elapsed: 12.40s
01/29/2023 03:42:46 AM [!] Learning rate: 2.5e-06
01/29/2023 03:42:50 AM  [*] Sun Jan 29 03:42:50 2023: Train Epoch: 9 [51200/73842 (69%)]	Loss: 178.529236 | Elapsed: 12.37s
01/29/2023 03:43:03 AM  [*] Sun Jan 29 03:43:03 2023: Train Epoch: 9 [57600/73842 (78%)]	Loss: 165.584076 | Elapsed: 12.45s
01/29/2023 03:43:15 AM  [*] Sun Jan 29 03:43:15 2023: Train Epoch: 9 [64000/73842 (87%)]	Loss: 169.184158 | Elapsed: 12.44s
01/29/2023 03:43:27 AM  [*] Sun Jan 29 03:43:27 2023: Train Epoch: 9 [70400/73842 (95%)]	Loss: 184.067352 | Elapsed: 12.41s
01/29/2023 03:43:36 AM  [*] Sun Jan 29 03:43:36 2023:    9    | Tr.loss: 174.937178 | Elapsed:  145.57  s
01/29/2023 03:43:36 AM  [*] Started epoch: 10
01/29/2023 03:43:36 AM  [*] Sun Jan 29 03:43:36 2023: Train Epoch: 10 [  0  /73842 (0 %)]	Loss: 165.870300 | Elapsed: 0.27s
01/29/2023 03:43:49 AM  [*] Sun Jan 29 03:43:49 2023: Train Epoch: 10 [6400 /73842 (9 %)]	Loss: 158.752151 | Elapsed: 12.54s
01/29/2023 03:44:01 AM  [*] Sun Jan 29 03:44:01 2023: Train Epoch: 10 [12800/73842 (17%)]	Loss: 164.947388 | Elapsed: 12.51s
01/29/2023 03:44:14 AM  [*] Sun Jan 29 03:44:14 2023: Train Epoch: 10 [19200/73842 (26%)]	Loss: 186.672958 | Elapsed: 12.44s
01/29/2023 03:44:26 AM  [*] Sun Jan 29 03:44:26 2023: Train Epoch: 10 [25600/73842 (35%)]	Loss: 191.864471 | Elapsed: 12.32s
01/29/2023 03:44:39 AM  [*] Sun Jan 29 03:44:39 2023: Train Epoch: 10 [32000/73842 (43%)]	Loss: 162.221832 | Elapsed: 12.37s
01/29/2023 03:44:51 AM  [*] Sun Jan 29 03:44:51 2023: Train Epoch: 10 [38400/73842 (52%)]	Loss: 172.155487 | Elapsed: 12.35s
01/29/2023 03:45:03 AM  [*] Sun Jan 29 03:45:03 2023: Train Epoch: 10 [44800/73842 (61%)]	Loss: 167.033310 | Elapsed: 12.45s
01/29/2023 03:45:16 AM  [*] Sun Jan 29 03:45:16 2023: Train Epoch: 10 [51200/73842 (69%)]	Loss: 171.216522 | Elapsed: 12.38s
01/29/2023 03:45:28 AM  [*] Sun Jan 29 03:45:28 2023: Train Epoch: 10 [57600/73842 (78%)]	Loss: 202.030304 | Elapsed: 12.34s
01/29/2023 03:45:40 AM  [*] Sun Jan 29 03:45:40 2023: Train Epoch: 10 [64000/73842 (87%)]	Loss: 189.190216 | Elapsed: 12.36s
01/29/2023 03:45:53 AM  [*] Sun Jan 29 03:45:53 2023: Train Epoch: 10 [70400/73842 (95%)]	Loss: 184.861908 | Elapsed: 12.38s
01/29/2023 03:46:01 AM  [*] Sun Jan 29 03:46:01 2023:   10    | Tr.loss: 174.754779 | Elapsed:  145.33  s
01/29/2023 03:46:02 AM [!] Sun Jan 29 03:46:02 2023: Dumped results:
                model     : 1674960361-model.torch
		train time: 1674960361-trainTime.npy
		train losses: 1674960361-trainLosses.npy
		train AUC: 1674960361-auc.npy
01/29/2023 03:46:05 AM  [!] Training pretrained model on downstream task...
01/29/2023 03:46:05 AM  [*] Started epoch: 1
01/29/2023 03:46:05 AM  [*] Sun Jan 29 03:46:05 2023: Train Epoch: 1 [  0  /2284  (0 %)]	Loss: 1.565853 | Elapsed: 0.31s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.7818
01/29/2023 03:46:08 AM  [*] Sun Jan 29 03:46:08 2023:    1    | Tr.loss: 0.744470 | Elapsed:   3.56   s | FPR 0.0003 -> TPR: 0.01 & F1: 0.01 | AUC: 0.6982
01/29/2023 03:46:08 AM  [*] Started epoch: 2
01/29/2023 03:46:08 AM  [*] Sun Jan 29 03:46:08 2023: Train Epoch: 2 [  0  /2284  (0 %)]	Loss: 0.460838 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.2439 & F1 0.3922 | AUC 0.8097
01/29/2023 03:46:12 AM  [*] Sun Jan 29 03:46:12 2023:    2    | Tr.loss: 0.471496 | Elapsed:   3.39   s | FPR 0.0003 -> TPR: 0.04 & F1: 0.08 | AUC: 0.7974
01/29/2023 03:46:12 AM  [*] Started epoch: 3
01/29/2023 03:46:12 AM  [*] Sun Jan 29 03:46:12 2023: Train Epoch: 3 [  0  /2284  (0 %)]	Loss: 0.411919 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.3256 & F1 0.4912 | AUC 0.8450
01/29/2023 03:46:15 AM  [*] Sun Jan 29 03:46:15 2023:    3    | Tr.loss: 0.434064 | Elapsed:   3.33   s | FPR 0.0003 -> TPR: 0.08 & F1: 0.14 | AUC: 0.8293
01/29/2023 03:46:15 AM [!] Sun Jan 29 03:46:15 2023: Dumped results:
                model     : 1674960375-model.torch
		train time: 1674960375-trainTime.npy
		train losses: 1674960375-trainLosses.npy
		train AUC: 1674960375-auc.npy
		train F1s : 1674960375-trainF1s.npy
		train TPRs: 1674960375-trainTPRs.npy
01/29/2023 03:46:15 AM  [!] Training non_pretrained model on downstream task...
01/29/2023 03:46:16 AM  [*] Started epoch: 1
01/29/2023 03:46:16 AM  [*] Sun Jan 29 03:46:16 2023: Train Epoch: 1 [  0  /2284  (0 %)]	Loss: 1.930223 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.4596
01/29/2023 03:46:18 AM  [*] Sun Jan 29 03:46:18 2023:    1    | Tr.loss: 0.782723 | Elapsed:   2.28   s | FPR 0.0003 -> TPR: 0.00 & F1: 0.01 | AUC: 0.6442
01/29/2023 03:46:18 AM  [*] Started epoch: 2
01/29/2023 03:46:18 AM  [*] Sun Jan 29 03:46:18 2023: Train Epoch: 2 [  0  /2284  (0 %)]	Loss: 0.644118 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0488 & F1 0.0930 | AUC 0.6575
01/29/2023 03:46:20 AM  [*] Sun Jan 29 03:46:20 2023:    2    | Tr.loss: 0.484622 | Elapsed:   2.27   s | FPR 0.0003 -> TPR: 0.08 & F1: 0.14 | AUC: 0.7961
01/29/2023 03:46:20 AM  [*] Started epoch: 3
01/29/2023 03:46:20 AM  [*] Sun Jan 29 03:46:20 2023: Train Epoch: 3 [  0  /2284  (0 %)]	Loss: 0.413270 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.2157 & F1 0.3548 | AUC 0.7979
01/29/2023 03:46:23 AM  [*] Sun Jan 29 03:46:23 2023:    3    | Tr.loss: 0.438822 | Elapsed:   2.28   s | FPR 0.0003 -> TPR: 0.03 & F1: 0.06 | AUC: 0.8384
01/29/2023 03:46:23 AM [!] Sun Jan 29 03:46:23 2023: Dumped results:
                model     : 1674960383-model.torch
		train time: 1674960383-trainTime.npy
		train losses: 1674960383-trainLosses.npy
		train AUC: 1674960383-auc.npy
		train F1s : 1674960383-trainF1s.npy
		train TPRs: 1674960383-trainTPRs.npy
01/29/2023 03:46:23 AM  [!] Training full_data model on downstream task...
01/29/2023 03:46:24 AM  [*] Started epoch: 1
01/29/2023 03:46:24 AM  [*] Sun Jan 29 03:46:24 2023: Train Epoch: 1 [  0  /76126 (0 %)]	Loss: 2.291869 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0217 & F1 0.0426 | AUC 0.3116
01/29/2023 03:46:30 AM  [*] Sun Jan 29 03:46:30 2023: Train Epoch: 1 [6400 /76126 (8 %)]	Loss: 0.487123 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.1857 & F1 0.3133 | AUC 0.7924
01/29/2023 03:46:36 AM  [*] Sun Jan 29 03:46:36 2023: Train Epoch: 1 [12800/76126 (17%)]	Loss: 0.424863 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.4000 & F1 0.5714 | AUC 0.8671
01/29/2023 03:46:42 AM  [*] Sun Jan 29 03:46:42 2023: Train Epoch: 1 [19200/76126 (25%)]	Loss: 0.344498 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.2344 & F1 0.3797 | AUC 0.9340
01/29/2023 03:46:48 AM  [*] Sun Jan 29 03:46:48 2023: Train Epoch: 1 [25600/76126 (34%)]	Loss: 0.332358 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.6271 & F1 0.7708 | AUC 0.9248
01/29/2023 03:46:55 AM  [*] Sun Jan 29 03:46:55 2023: Train Epoch: 1 [32000/76126 (42%)]	Loss: 0.224775 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.8052 & F1 0.8921 | AUC 0.9667
01/29/2023 03:47:01 AM  [*] Sun Jan 29 03:47:01 2023: Train Epoch: 1 [38400/76126 (50%)]	Loss: 0.214257 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.8000 & F1 0.8889 | AUC 0.9675
01/29/2023 03:47:07 AM  [*] Sun Jan 29 03:47:07 2023: Train Epoch: 1 [44800/76126 (59%)]	Loss: 0.245353 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.7385 & F1 0.8496 | AUC 0.9662
01/29/2023 03:47:13 AM  [*] Sun Jan 29 03:47:13 2023: Train Epoch: 1 [51200/76126 (67%)]	Loss: 0.103687 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.7969 & F1 0.8870 | AUC 0.9848
01/29/2023 03:47:20 AM  [*] Sun Jan 29 03:47:20 2023: Train Epoch: 1 [57600/76126 (76%)]	Loss: 0.161805 | Elapsed: 6.26s | FPR 0.0003 -> TPR 0.7647 & F1 0.8667 | AUC 0.9761
01/29/2023 03:47:26 AM [!] Learning rate: 2.5e-05
01/29/2023 03:47:26 AM  [*] Sun Jan 29 03:47:26 2023: Train Epoch: 1 [64000/76126 (84%)]	Loss: 0.243982 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.7538 & F1 0.8596 | AUC 0.9697
01/29/2023 03:47:32 AM  [*] Sun Jan 29 03:47:32 2023: Train Epoch: 1 [70400/76126 (92%)]	Loss: 0.245846 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.8730 & F1 0.9322 | AUC 0.9743
01/29/2023 03:47:39 AM  [*] Sun Jan 29 03:47:39 2023:    1    | Tr.loss: 0.288771 | Elapsed:   75.68  s | FPR 0.0003 -> TPR: 0.14 & F1: 0.24 | AUC: 0.9389
01/29/2023 03:47:39 AM  [*] Started epoch: 2
01/29/2023 03:47:39 AM  [*] Sun Jan 29 03:47:39 2023: Train Epoch: 2 [  0  /76126 (0 %)]	Loss: 0.183022 | Elapsed: 0.13s | FPR 0.0003 -> TPR 0.7955 & F1 0.8861 | AUC 0.9773
01/29/2023 03:47:46 AM  [*] Sun Jan 29 03:47:46 2023: Train Epoch: 2 [6400 /76126 (8 %)]	Loss: 0.185940 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.7971 & F1 0.8871 | AUC 0.9748
01/29/2023 03:47:52 AM  [*] Sun Jan 29 03:47:52 2023: Train Epoch: 2 [12800/76126 (17%)]	Loss: 0.276577 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.7500 & F1 0.8571 | AUC 0.9692
01/29/2023 03:47:58 AM  [*] Sun Jan 29 03:47:58 2023: Train Epoch: 2 [19200/76126 (25%)]	Loss: 0.137545 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.8955 & F1 0.9449 | AUC 0.9860
01/29/2023 03:48:04 AM  [*] Sun Jan 29 03:48:04 2023: Train Epoch: 2 [25600/76126 (34%)]	Loss: 0.181559 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.9091 & F1 0.9524 | AUC 0.9835
01/29/2023 03:48:10 AM  [*] Sun Jan 29 03:48:10 2023: Train Epoch: 2 [32000/76126 (42%)]	Loss: 0.154483 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.8308 & F1 0.9076 | AUC 0.9868
01/29/2023 03:48:17 AM  [*] Sun Jan 29 03:48:17 2023: Train Epoch: 2 [38400/76126 (50%)]	Loss: 0.144470 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.7324 & F1 0.8455 | AUC 0.9825
01/29/2023 03:48:23 AM  [*] Sun Jan 29 03:48:23 2023: Train Epoch: 2 [44800/76126 (59%)]	Loss: 0.190072 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.9254 & F1 0.9612 | AUC 0.9878
01/29/2023 03:48:29 AM  [*] Sun Jan 29 03:48:29 2023: Train Epoch: 2 [51200/76126 (67%)]	Loss: 0.197565 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.7973 & F1 0.8872 | AUC 0.9808
01/29/2023 03:48:30 AM [!] Learning rate: 2.5e-06
01/29/2023 03:48:35 AM  [*] Sun Jan 29 03:48:35 2023: Train Epoch: 2 [57600/76126 (76%)]	Loss: 0.249870 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.7297 & F1 0.8437 | AUC 0.9636
01/29/2023 03:48:42 AM  [*] Sun Jan 29 03:48:42 2023: Train Epoch: 2 [64000/76126 (84%)]	Loss: 0.130677 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.7846 & F1 0.8793 | AUC 0.9776
01/29/2023 03:48:48 AM  [*] Sun Jan 29 03:48:48 2023: Train Epoch: 2 [70400/76126 (92%)]	Loss: 0.159836 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.8553 & F1 0.9220 | AUC 0.9857
01/29/2023 03:48:55 AM  [*] Sun Jan 29 03:48:55 2023:    2    | Tr.loss: 0.160612 | Elapsed:   75.77  s | FPR 0.0003 -> TPR: 0.45 & F1: 0.62 | AUC: 0.9821
01/29/2023 03:48:55 AM  [*] Started epoch: 3
01/29/2023 03:48:55 AM  [*] Sun Jan 29 03:48:55 2023: Train Epoch: 3 [  0  /76126 (0 %)]	Loss: 0.142285 | Elapsed: 0.12s | FPR 0.0003 -> TPR 0.8333 & F1 0.9091 | AUC 0.9857
01/29/2023 03:49:01 AM  [*] Sun Jan 29 03:49:01 2023: Train Epoch: 3 [6400 /76126 (8 %)]	Loss: 0.141655 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.8732 & F1 0.9323 | AUC 0.9869
01/29/2023 03:49:08 AM  [*] Sun Jan 29 03:49:08 2023: Train Epoch: 3 [12800/76126 (17%)]	Loss: 0.246945 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.6197 & F1 0.7652 | AUC 0.9743
01/29/2023 03:49:14 AM  [*] Sun Jan 29 03:49:14 2023: Train Epoch: 3 [19200/76126 (25%)]	Loss: 0.121533 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.9701 & F1 0.9848 | AUC 0.9928
01/29/2023 03:49:20 AM  [*] Sun Jan 29 03:49:20 2023: Train Epoch: 3 [25600/76126 (34%)]	Loss: 0.084282 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.9697 & F1 0.9846 | AUC 0.9987
01/29/2023 03:49:26 AM  [*] Sun Jan 29 03:49:26 2023: Train Epoch: 3 [32000/76126 (42%)]	Loss: 0.193153 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.3913 & F1 0.5625 | AUC 0.9570
01/29/2023 03:49:32 AM  [*] Sun Jan 29 03:49:32 2023: Train Epoch: 3 [38400/76126 (50%)]	Loss: 0.111784 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.9692 & F1 0.9844 | AUC 0.9974
01/29/2023 03:49:34 AM [!] Learning rate: 2.5000000000000004e-07
01/29/2023 03:49:39 AM  [*] Sun Jan 29 03:49:39 2023: Train Epoch: 3 [44800/76126 (59%)]	Loss: 0.094666 | Elapsed: 6.26s | FPR 0.0003 -> TPR 0.9583 & F1 0.9787 | AUC 0.9975
01/29/2023 03:49:45 AM  [*] Sun Jan 29 03:49:45 2023: Train Epoch: 3 [51200/76126 (67%)]	Loss: 0.160476 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.8308 & F1 0.9076 | AUC 0.9793
01/29/2023 03:49:51 AM  [*] Sun Jan 29 03:49:51 2023: Train Epoch: 3 [57600/76126 (76%)]	Loss: 0.160284 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.6620 & F1 0.7966 | AUC 0.9811
01/29/2023 03:49:57 AM  [*] Sun Jan 29 03:49:57 2023: Train Epoch: 3 [64000/76126 (84%)]	Loss: 0.114060 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.8644 & F1 0.9273 | AUC 0.9938
01/29/2023 03:50:04 AM  [*] Sun Jan 29 03:50:04 2023: Train Epoch: 3 [70400/76126 (92%)]	Loss: 0.116885 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.8873 & F1 0.9403 | AUC 0.9942
01/29/2023 03:50:11 AM  [*] Sun Jan 29 03:50:11 2023:    3    | Tr.loss: 0.152375 | Elapsed:   75.84  s | FPR 0.0003 -> TPR: 0.50 & F1: 0.67 | AUC: 0.9839
01/29/2023 03:50:11 AM [!] Sun Jan 29 03:50:11 2023: Dumped results:
                model     : 1674960611-model.torch
		train time: 1674960611-trainTime.npy
		train losses: 1674960611-trainLosses.npy
		train AUC: 1674960611-auc.npy
		train F1s : 1674960611-trainF1s.npy
		train TPRs: 1674960611-trainTPRs.npy
01/29/2023 03:50:11 AM  [*] Evaluating pretrained model on test set...
01/29/2023 03:50:16 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0296 | F1: 0.0574
01/29/2023 03:50:16 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1245 | F1: 0.2214
01/29/2023 03:50:16 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.1476 | F1: 0.2571
01/29/2023 03:50:16 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.1632 | F1: 0.2801
01/29/2023 03:50:16 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.2267 | F1: 0.3671
01/29/2023 03:50:16 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.3475 | F1: 0.5063
01/29/2023 03:50:16 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.4602 | F1: 0.5956
01/29/2023 03:50:16 AM  [*] Evaluating non_pretrained model on test set...
01/29/2023 03:50:21 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0236 | F1: 0.0461
01/29/2023 03:50:21 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.0449 | F1: 0.0859
01/29/2023 03:50:21 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.0999 | F1: 0.1814
01/29/2023 03:50:21 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.1494 | F1: 0.2594
01/29/2023 03:50:21 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.2155 | F1: 0.3521
01/29/2023 03:50:21 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.3113 | F1: 0.4657
01/29/2023 03:50:21 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.4413 | F1: 0.5784
01/29/2023 03:50:21 AM  [*] Evaluating full_data model on test set...
01/29/2023 03:50:26 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.1245 | F1: 0.2215
01/29/2023 03:50:26 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.2579 | F1: 0.4100
01/29/2023 03:50:26 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.3439 | F1: 0.5115
01/29/2023 03:50:26 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3918 | F1: 0.5620
01/29/2023 03:50:26 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.4446 | F1: 0.6120
01/29/2023 03:50:26 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.5767 | F1: 0.7199
01/29/2023 03:50:26 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.8019 | F1: 0.8499
01/29/2023 03:50:26 AM  [!] Finished pre-training evaluation over 3 splits! Saved metrics to:
	C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\uSize_0.97_1674955247/metrics_MaskedLanguageModel_nSplits_3_limit_None.json
