01/27/2023 10:36:35 PM  [!] Starting Masked Language Model evaluation over 3 splits!
01/27/2023 10:36:35 PM  [!] Loaded data and vocab. X train size: (76126, 512), X test size: (17407, 512), vocab size: 50002
01/27/2023 10:36:35 PM  [!] Initiating Self-Supervised Learning Pretraining
     Language Modeling MaskedLanguageModel
     Model TransformerEncoderLM with config:
	{'vocabSize': 50002, 'maxLen': 512, 'dModel': 64, 'nHeads': 8, 'dHidden': 256, 'nLayers': 2, 'numClasses': 1, 'hiddenNeurons': [64], 'dropout': 0.3}

01/27/2023 10:36:35 PM  [!] Running pre-training split 1/3
01/27/2023 10:36:38 PM  [!] Pre-training model...
01/27/2023 10:36:39 PM  [*] Masking sequences...
01/27/2023 10:36:57 PM  [*] Started epoch: 1
01/27/2023 10:37:00 PM  [*] Fri Jan 27 22:37:00 2023: Train Epoch: 1 [  0  /60900 (0 %)]	Loss: 469.091492 | Elapsed: 2.73s
01/27/2023 10:37:12 PM  [*] Fri Jan 27 22:37:12 2023: Train Epoch: 1 [6400 /60900 (11%)]	Loss: 240.311493 | Elapsed: 12.05s
01/27/2023 10:37:24 PM  [*] Fri Jan 27 22:37:24 2023: Train Epoch: 1 [12800/60900 (21%)]	Loss: 208.109116 | Elapsed: 12.19s
01/27/2023 10:37:37 PM  [*] Fri Jan 27 22:37:37 2023: Train Epoch: 1 [19200/60900 (32%)]	Loss: 216.385132 | Elapsed: 12.32s
01/27/2023 10:37:49 PM  [*] Fri Jan 27 22:37:49 2023: Train Epoch: 1 [25600/60900 (42%)]	Loss: 216.906372 | Elapsed: 12.33s
01/27/2023 10:38:01 PM  [*] Fri Jan 27 22:38:01 2023: Train Epoch: 1 [32000/60900 (53%)]	Loss: 227.256714 | Elapsed: 12.52s
01/27/2023 10:38:14 PM  [*] Fri Jan 27 22:38:14 2023: Train Epoch: 1 [38400/60900 (63%)]	Loss: 188.191376 | Elapsed: 12.67s
01/27/2023 10:38:27 PM  [*] Fri Jan 27 22:38:27 2023: Train Epoch: 1 [44800/60900 (74%)]	Loss: 211.565796 | Elapsed: 12.99s
01/27/2023 10:38:40 PM  [*] Fri Jan 27 22:38:40 2023: Train Epoch: 1 [51200/60900 (84%)]	Loss: 179.027771 | Elapsed: 12.91s
01/27/2023 10:38:53 PM  [*] Fri Jan 27 22:38:53 2023: Train Epoch: 1 [57600/60900 (95%)]	Loss: 192.293289 | Elapsed: 12.91s
01/27/2023 10:39:02 PM  [*] Fri Jan 27 22:39:02 2023:    1    | Tr.loss: 208.109996 | Elapsed:  124.55  s
01/27/2023 10:39:02 PM [!] Fri Jan 27 22:39:02 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_1_1674855542-model.torch
01/27/2023 10:39:02 PM  [*] Started epoch: 2
01/27/2023 10:39:03 PM  [*] Fri Jan 27 22:39:03 2023: Train Epoch: 2 [  0  /60900 (0 %)]	Loss: 195.270142 | Elapsed: 0.18s
01/27/2023 10:39:15 PM  [*] Fri Jan 27 22:39:15 2023: Train Epoch: 2 [6400 /60900 (11%)]	Loss: 189.820648 | Elapsed: 12.64s
01/27/2023 10:39:28 PM  [*] Fri Jan 27 22:39:28 2023: Train Epoch: 2 [12800/60900 (21%)]	Loss: 187.030502 | Elapsed: 12.57s
01/27/2023 10:39:40 PM  [*] Fri Jan 27 22:39:40 2023: Train Epoch: 2 [19200/60900 (32%)]	Loss: 196.225449 | Elapsed: 12.70s
01/27/2023 10:39:53 PM  [*] Fri Jan 27 22:39:53 2023: Train Epoch: 2 [25600/60900 (42%)]	Loss: 181.772034 | Elapsed: 12.59s
01/27/2023 10:40:06 PM  [*] Fri Jan 27 22:40:06 2023: Train Epoch: 2 [32000/60900 (53%)]	Loss: 211.198059 | Elapsed: 12.84s
01/27/2023 10:40:19 PM  [*] Fri Jan 27 22:40:19 2023: Train Epoch: 2 [38400/60900 (63%)]	Loss: 197.110931 | Elapsed: 12.61s
01/27/2023 10:40:31 PM  [*] Fri Jan 27 22:40:31 2023: Train Epoch: 2 [44800/60900 (74%)]	Loss: 190.048462 | Elapsed: 12.57s
01/27/2023 10:40:44 PM  [*] Fri Jan 27 22:40:44 2023: Train Epoch: 2 [51200/60900 (84%)]	Loss: 187.196930 | Elapsed: 12.61s
01/27/2023 10:40:56 PM  [*] Fri Jan 27 22:40:56 2023: Train Epoch: 2 [57600/60900 (95%)]	Loss: 195.892273 | Elapsed: 12.59s
01/27/2023 10:41:05 PM  [*] Fri Jan 27 22:41:05 2023:    2    | Tr.loss: 187.372663 | Elapsed:  122.10  s
01/27/2023 10:41:05 PM [!] Fri Jan 27 22:41:05 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_2_1674855665-model.torch
01/27/2023 10:41:05 PM  [*] Started epoch: 3
01/27/2023 10:41:05 PM  [*] Fri Jan 27 22:41:05 2023: Train Epoch: 3 [  0  /60900 (0 %)]	Loss: 186.276321 | Elapsed: 0.19s
01/27/2023 10:41:18 PM  [*] Fri Jan 27 22:41:18 2023: Train Epoch: 3 [6400 /60900 (11%)]	Loss: 173.417297 | Elapsed: 12.51s
01/27/2023 10:41:30 PM  [*] Fri Jan 27 22:41:30 2023: Train Epoch: 3 [12800/60900 (21%)]	Loss: 171.723404 | Elapsed: 12.53s
01/27/2023 10:41:43 PM  [*] Fri Jan 27 22:41:43 2023: Train Epoch: 3 [19200/60900 (32%)]	Loss: 161.070694 | Elapsed: 12.51s
01/27/2023 10:41:56 PM  [*] Fri Jan 27 22:41:56 2023: Train Epoch: 3 [25600/60900 (42%)]	Loss: 182.869537 | Elapsed: 12.65s
01/27/2023 10:42:08 PM  [*] Fri Jan 27 22:42:08 2023: Train Epoch: 3 [32000/60900 (53%)]	Loss: 191.009338 | Elapsed: 12.41s
01/27/2023 10:42:20 PM  [*] Fri Jan 27 22:42:20 2023: Train Epoch: 3 [38400/60900 (63%)]	Loss: 192.998734 | Elapsed: 12.54s
01/27/2023 10:42:33 PM  [*] Fri Jan 27 22:42:33 2023: Train Epoch: 3 [44800/60900 (74%)]	Loss: 179.786407 | Elapsed: 12.53s
01/27/2023 10:42:46 PM  [*] Fri Jan 27 22:42:46 2023: Train Epoch: 3 [51200/60900 (84%)]	Loss: 198.028290 | Elapsed: 12.54s
01/27/2023 10:42:58 PM  [*] Fri Jan 27 22:42:58 2023: Train Epoch: 3 [57600/60900 (95%)]	Loss: 147.659546 | Elapsed: 12.58s
01/27/2023 10:43:06 PM  [*] Fri Jan 27 22:43:06 2023:    3    | Tr.loss: 182.375064 | Elapsed:  121.18  s
01/27/2023 10:43:07 PM [!] Fri Jan 27 22:43:07 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_3_1674855786-model.torch
01/27/2023 10:43:07 PM  [*] Started epoch: 4
01/27/2023 10:43:07 PM  [*] Fri Jan 27 22:43:07 2023: Train Epoch: 4 [  0  /60900 (0 %)]	Loss: 184.838593 | Elapsed: 0.20s
01/27/2023 10:43:20 PM  [*] Fri Jan 27 22:43:20 2023: Train Epoch: 4 [6400 /60900 (11%)]	Loss: 195.980347 | Elapsed: 12.52s
01/27/2023 10:43:32 PM  [*] Fri Jan 27 22:43:32 2023: Train Epoch: 4 [12800/60900 (21%)]	Loss: 177.724396 | Elapsed: 12.48s
01/27/2023 10:43:45 PM  [*] Fri Jan 27 22:43:45 2023: Train Epoch: 4 [19200/60900 (32%)]	Loss: 189.582031 | Elapsed: 12.56s
01/27/2023 10:43:57 PM  [*] Fri Jan 27 22:43:57 2023: Train Epoch: 4 [25600/60900 (42%)]	Loss: 179.756805 | Elapsed: 12.47s
01/27/2023 10:44:10 PM  [*] Fri Jan 27 22:44:10 2023: Train Epoch: 4 [32000/60900 (53%)]	Loss: 178.603119 | Elapsed: 12.52s
01/27/2023 10:44:22 PM  [*] Fri Jan 27 22:44:22 2023: Train Epoch: 4 [38400/60900 (63%)]	Loss: 173.041931 | Elapsed: 12.61s
01/27/2023 10:44:35 PM  [*] Fri Jan 27 22:44:35 2023: Train Epoch: 4 [44800/60900 (74%)]	Loss: 168.397217 | Elapsed: 12.47s
01/27/2023 10:44:47 PM  [*] Fri Jan 27 22:44:47 2023: Train Epoch: 4 [51200/60900 (84%)]	Loss: 162.836578 | Elapsed: 12.73s
01/27/2023 10:45:00 PM  [*] Fri Jan 27 22:45:00 2023: Train Epoch: 4 [57600/60900 (95%)]	Loss: 199.898651 | Elapsed: 12.76s
01/27/2023 10:45:09 PM  [*] Fri Jan 27 22:45:09 2023:    4    | Tr.loss: 179.775187 | Elapsed:  121.82  s
01/27/2023 10:45:09 PM [!] Fri Jan 27 22:45:09 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_4_1674855909-model.torch
01/27/2023 10:45:09 PM  [*] Started epoch: 5
01/27/2023 10:45:09 PM  [*] Fri Jan 27 22:45:09 2023: Train Epoch: 5 [  0  /60900 (0 %)]	Loss: 180.514435 | Elapsed: 0.24s
01/27/2023 10:45:22 PM  [*] Fri Jan 27 22:45:22 2023: Train Epoch: 5 [6400 /60900 (11%)]	Loss: 198.891266 | Elapsed: 12.66s
01/27/2023 10:45:35 PM  [*] Fri Jan 27 22:45:35 2023: Train Epoch: 5 [12800/60900 (21%)]	Loss: 160.997528 | Elapsed: 12.62s
01/27/2023 10:45:47 PM  [*] Fri Jan 27 22:45:47 2023: Train Epoch: 5 [19200/60900 (32%)]	Loss: 176.177505 | Elapsed: 12.57s
01/27/2023 10:46:00 PM  [*] Fri Jan 27 22:46:00 2023: Train Epoch: 5 [25600/60900 (42%)]	Loss: 175.327393 | Elapsed: 12.55s
01/27/2023 10:46:12 PM  [*] Fri Jan 27 22:46:12 2023: Train Epoch: 5 [32000/60900 (53%)]	Loss: 197.674377 | Elapsed: 12.58s
01/27/2023 10:46:25 PM  [*] Fri Jan 27 22:46:25 2023: Train Epoch: 5 [38400/60900 (63%)]	Loss: 191.540573 | Elapsed: 12.46s
01/27/2023 10:46:37 PM  [*] Fri Jan 27 22:46:37 2023: Train Epoch: 5 [44800/60900 (74%)]	Loss: 164.040741 | Elapsed: 12.54s
01/27/2023 10:46:50 PM  [*] Fri Jan 27 22:46:50 2023: Train Epoch: 5 [51200/60900 (84%)]	Loss: 166.148956 | Elapsed: 12.43s
01/27/2023 10:47:02 PM  [*] Fri Jan 27 22:47:02 2023: Train Epoch: 5 [57600/60900 (95%)]	Loss: 161.545715 | Elapsed: 12.47s
01/27/2023 10:47:10 PM  [*] Fri Jan 27 22:47:10 2023:    5    | Tr.loss: 178.153164 | Elapsed:  121.23  s
01/27/2023 10:47:11 PM [!] Fri Jan 27 22:47:11 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_5_1674856030-model.torch
01/27/2023 10:47:11 PM  [*] Started epoch: 6
01/27/2023 10:47:11 PM  [*] Fri Jan 27 22:47:11 2023: Train Epoch: 6 [  0  /60900 (0 %)]	Loss: 192.007095 | Elapsed: 0.20s
01/27/2023 10:47:24 PM  [*] Fri Jan 27 22:47:24 2023: Train Epoch: 6 [6400 /60900 (11%)]	Loss: 179.278320 | Elapsed: 12.48s
01/27/2023 10:47:36 PM  [*] Fri Jan 27 22:47:36 2023: Train Epoch: 6 [12800/60900 (21%)]	Loss: 185.540237 | Elapsed: 12.50s
01/27/2023 10:47:49 PM  [*] Fri Jan 27 22:47:49 2023: Train Epoch: 6 [19200/60900 (32%)]	Loss: 151.507584 | Elapsed: 12.57s
01/27/2023 10:48:01 PM  [*] Fri Jan 27 22:48:01 2023: Train Epoch: 6 [25600/60900 (42%)]	Loss: 179.824341 | Elapsed: 12.52s
01/27/2023 10:48:14 PM  [*] Fri Jan 27 22:48:14 2023: Train Epoch: 6 [32000/60900 (53%)]	Loss: 184.340546 | Elapsed: 12.52s
01/27/2023 10:48:26 PM  [*] Fri Jan 27 22:48:26 2023: Train Epoch: 6 [38400/60900 (63%)]	Loss: 163.476944 | Elapsed: 12.64s
01/27/2023 10:48:39 PM  [*] Fri Jan 27 22:48:39 2023: Train Epoch: 6 [44800/60900 (74%)]	Loss: 185.515640 | Elapsed: 12.57s
01/27/2023 10:48:51 PM  [*] Fri Jan 27 22:48:51 2023: Train Epoch: 6 [51200/60900 (84%)]	Loss: 182.011414 | Elapsed: 12.47s
01/27/2023 10:49:04 PM  [*] Fri Jan 27 22:49:04 2023: Train Epoch: 6 [57600/60900 (95%)]	Loss: 173.341827 | Elapsed: 12.58s
01/27/2023 10:49:12 PM  [*] Fri Jan 27 22:49:12 2023:    6    | Tr.loss: 176.881489 | Elapsed:  121.26  s
01/27/2023 10:49:13 PM [!] Fri Jan 27 22:49:13 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_6_1674856152-model.torch
01/27/2023 10:49:13 PM  [*] Started epoch: 7
01/27/2023 10:49:13 PM  [*] Fri Jan 27 22:49:13 2023: Train Epoch: 7 [  0  /60900 (0 %)]	Loss: 172.252319 | Elapsed: 0.19s
01/27/2023 10:49:25 PM  [*] Fri Jan 27 22:49:25 2023: Train Epoch: 7 [6400 /60900 (11%)]	Loss: 157.685181 | Elapsed: 12.53s
01/27/2023 10:49:38 PM  [*] Fri Jan 27 22:49:38 2023: Train Epoch: 7 [12800/60900 (21%)]	Loss: 181.381073 | Elapsed: 12.51s
01/27/2023 10:49:51 PM  [*] Fri Jan 27 22:49:51 2023: Train Epoch: 7 [19200/60900 (32%)]	Loss: 181.623703 | Elapsed: 12.59s
01/27/2023 10:50:03 PM  [*] Fri Jan 27 22:50:03 2023: Train Epoch: 7 [25600/60900 (42%)]	Loss: 163.938721 | Elapsed: 12.44s
01/27/2023 10:50:16 PM  [*] Fri Jan 27 22:50:16 2023: Train Epoch: 7 [32000/60900 (53%)]	Loss: 156.887177 | Elapsed: 12.50s
01/27/2023 10:50:28 PM  [*] Fri Jan 27 22:50:28 2023: Train Epoch: 7 [38400/60900 (63%)]	Loss: 168.346985 | Elapsed: 12.56s
01/27/2023 10:50:41 PM  [*] Fri Jan 27 22:50:41 2023: Train Epoch: 7 [44800/60900 (74%)]	Loss: 196.010498 | Elapsed: 12.57s
01/27/2023 10:50:53 PM  [*] Fri Jan 27 22:50:53 2023: Train Epoch: 7 [51200/60900 (84%)]	Loss: 176.780457 | Elapsed: 12.41s
01/27/2023 10:51:06 PM  [*] Fri Jan 27 22:51:06 2023: Train Epoch: 7 [57600/60900 (95%)]	Loss: 164.001297 | Elapsed: 12.45s
01/27/2023 10:51:14 PM  [*] Fri Jan 27 22:51:14 2023:    7    | Tr.loss: 175.960670 | Elapsed:  120.81  s
01/27/2023 10:51:14 PM [!] Fri Jan 27 22:51:14 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_7_1674856274-model.torch
01/27/2023 10:51:14 PM  [*] Started epoch: 8
01/27/2023 10:51:14 PM  [*] Fri Jan 27 22:51:14 2023: Train Epoch: 8 [  0  /60900 (0 %)]	Loss: 174.066559 | Elapsed: 0.33s
01/27/2023 10:51:27 PM  [*] Fri Jan 27 22:51:27 2023: Train Epoch: 8 [6400 /60900 (11%)]	Loss: 194.596085 | Elapsed: 12.51s
01/27/2023 10:51:39 PM  [*] Fri Jan 27 22:51:39 2023: Train Epoch: 8 [12800/60900 (21%)]	Loss: 189.175171 | Elapsed: 12.46s
01/27/2023 10:51:52 PM  [*] Fri Jan 27 22:51:52 2023: Train Epoch: 8 [19200/60900 (32%)]	Loss: 173.189224 | Elapsed: 12.55s
01/27/2023 10:52:04 PM  [*] Fri Jan 27 22:52:04 2023: Train Epoch: 8 [25600/60900 (42%)]	Loss: 163.531876 | Elapsed: 12.44s
01/27/2023 10:52:17 PM  [*] Fri Jan 27 22:52:17 2023: Train Epoch: 8 [32000/60900 (53%)]	Loss: 161.542404 | Elapsed: 12.45s
01/27/2023 10:52:29 PM  [*] Fri Jan 27 22:52:29 2023: Train Epoch: 8 [38400/60900 (63%)]	Loss: 164.757202 | Elapsed: 12.46s
01/27/2023 10:52:42 PM  [*] Fri Jan 27 22:52:42 2023: Train Epoch: 8 [44800/60900 (74%)]	Loss: 179.164917 | Elapsed: 12.45s
01/27/2023 10:52:54 PM  [*] Fri Jan 27 22:52:54 2023: Train Epoch: 8 [51200/60900 (84%)]	Loss: 185.738098 | Elapsed: 12.45s
01/27/2023 10:53:07 PM  [*] Fri Jan 27 22:53:07 2023: Train Epoch: 8 [57600/60900 (95%)]	Loss: 156.983521 | Elapsed: 12.43s
01/27/2023 10:53:15 PM  [*] Fri Jan 27 22:53:15 2023:    8    | Tr.loss: 175.222393 | Elapsed:  120.69  s
01/27/2023 10:53:15 PM [!] Fri Jan 27 22:53:15 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_8_1674856395-model.torch
01/27/2023 10:53:15 PM  [*] Started epoch: 9
01/27/2023 10:53:16 PM  [*] Fri Jan 27 22:53:16 2023: Train Epoch: 9 [  0  /60900 (0 %)]	Loss: 170.826691 | Elapsed: 0.32s
01/27/2023 10:53:28 PM  [*] Fri Jan 27 22:53:28 2023: Train Epoch: 9 [6400 /60900 (11%)]	Loss: 167.671326 | Elapsed: 12.83s
01/27/2023 10:53:41 PM  [*] Fri Jan 27 22:53:41 2023: Train Epoch: 9 [12800/60900 (21%)]	Loss: 184.106415 | Elapsed: 12.71s
01/27/2023 10:53:54 PM  [*] Fri Jan 27 22:53:54 2023: Train Epoch: 9 [19200/60900 (32%)]	Loss: 178.352509 | Elapsed: 12.48s
01/27/2023 10:54:06 PM  [*] Fri Jan 27 22:54:06 2023: Train Epoch: 9 [25600/60900 (42%)]	Loss: 179.331848 | Elapsed: 12.46s
01/27/2023 10:54:19 PM  [*] Fri Jan 27 22:54:19 2023: Train Epoch: 9 [32000/60900 (53%)]	Loss: 168.632950 | Elapsed: 12.52s
01/27/2023 10:54:31 PM  [*] Fri Jan 27 22:54:31 2023: Train Epoch: 9 [38400/60900 (63%)]	Loss: 178.184143 | Elapsed: 12.50s
01/27/2023 10:54:44 PM  [*] Fri Jan 27 22:54:44 2023: Train Epoch: 9 [44800/60900 (74%)]	Loss: 177.422195 | Elapsed: 12.46s
01/27/2023 10:54:56 PM  [*] Fri Jan 27 22:54:56 2023: Train Epoch: 9 [51200/60900 (84%)]	Loss: 152.412231 | Elapsed: 12.40s
01/27/2023 10:55:09 PM  [*] Fri Jan 27 22:55:09 2023: Train Epoch: 9 [57600/60900 (95%)]	Loss: 183.555145 | Elapsed: 12.50s
01/27/2023 10:55:17 PM  [*] Fri Jan 27 22:55:17 2023:    9    | Tr.loss: 174.491904 | Elapsed:  121.48  s
01/27/2023 10:55:17 PM [!] Fri Jan 27 22:55:17 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_9_1674856517-model.torch
01/27/2023 10:55:17 PM  [*] Started epoch: 10
01/27/2023 10:55:18 PM  [*] Fri Jan 27 22:55:18 2023: Train Epoch: 10 [  0  /60900 (0 %)]	Loss: 167.323166 | Elapsed: 0.22s
01/27/2023 10:55:30 PM  [*] Fri Jan 27 22:55:30 2023: Train Epoch: 10 [6400 /60900 (11%)]	Loss: 182.483215 | Elapsed: 12.69s
01/27/2023 10:55:43 PM  [*] Fri Jan 27 22:55:43 2023: Train Epoch: 10 [12800/60900 (21%)]	Loss: 167.012558 | Elapsed: 12.49s
01/27/2023 10:55:55 PM  [*] Fri Jan 27 22:55:55 2023: Train Epoch: 10 [19200/60900 (32%)]	Loss: 160.691986 | Elapsed: 12.53s
01/27/2023 10:56:08 PM  [*] Fri Jan 27 22:56:08 2023: Train Epoch: 10 [25600/60900 (42%)]	Loss: 159.363663 | Elapsed: 12.53s
01/27/2023 10:56:20 PM  [*] Fri Jan 27 22:56:20 2023: Train Epoch: 10 [32000/60900 (53%)]	Loss: 176.336380 | Elapsed: 12.57s
01/27/2023 10:56:33 PM  [*] Fri Jan 27 22:56:33 2023: Train Epoch: 10 [38400/60900 (63%)]	Loss: 205.891327 | Elapsed: 12.49s
01/27/2023 10:56:45 PM  [*] Fri Jan 27 22:56:45 2023: Train Epoch: 10 [44800/60900 (74%)]	Loss: 200.874878 | Elapsed: 12.50s
01/27/2023 10:56:58 PM  [*] Fri Jan 27 22:56:58 2023: Train Epoch: 10 [51200/60900 (84%)]	Loss: 170.298645 | Elapsed: 12.38s
01/27/2023 10:57:10 PM  [*] Fri Jan 27 22:57:10 2023: Train Epoch: 10 [57600/60900 (95%)]	Loss: 178.181854 | Elapsed: 12.56s
01/27/2023 10:57:19 PM  [*] Fri Jan 27 22:57:19 2023:   10    | Tr.loss: 173.879151 | Elapsed:  121.14  s
01/27/2023 10:57:19 PM [!] Fri Jan 27 22:57:19 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_10_1674856639-model.torch
01/27/2023 10:57:19 PM  [*] Started epoch: 11
01/27/2023 10:57:19 PM  [*] Fri Jan 27 22:57:19 2023: Train Epoch: 11 [  0  /60900 (0 %)]	Loss: 173.358032 | Elapsed: 0.24s
01/27/2023 10:57:32 PM  [*] Fri Jan 27 22:57:32 2023: Train Epoch: 11 [6400 /60900 (11%)]	Loss: 174.162048 | Elapsed: 12.63s
01/27/2023 10:57:44 PM  [*] Fri Jan 27 22:57:44 2023: Train Epoch: 11 [12800/60900 (21%)]	Loss: 168.146072 | Elapsed: 12.46s
01/27/2023 10:57:57 PM  [*] Fri Jan 27 22:57:57 2023: Train Epoch: 11 [19200/60900 (32%)]	Loss: 184.688812 | Elapsed: 12.47s
01/27/2023 10:58:09 PM  [*] Fri Jan 27 22:58:09 2023: Train Epoch: 11 [25600/60900 (42%)]	Loss: 182.328934 | Elapsed: 12.54s
01/27/2023 10:58:19 PM [!] Learning rate: 2.5e-05
01/27/2023 10:58:22 PM  [*] Fri Jan 27 22:58:22 2023: Train Epoch: 11 [32000/60900 (53%)]	Loss: 164.965347 | Elapsed: 12.54s
01/27/2023 10:58:34 PM  [*] Fri Jan 27 22:58:34 2023: Train Epoch: 11 [38400/60900 (63%)]	Loss: 193.734558 | Elapsed: 12.42s
01/27/2023 10:58:47 PM  [*] Fri Jan 27 22:58:47 2023: Train Epoch: 11 [44800/60900 (74%)]	Loss: 197.237839 | Elapsed: 12.51s
01/27/2023 10:58:59 PM  [*] Fri Jan 27 22:58:59 2023: Train Epoch: 11 [51200/60900 (84%)]	Loss: 177.261658 | Elapsed: 12.41s
01/27/2023 10:59:12 PM  [*] Fri Jan 27 22:59:12 2023: Train Epoch: 11 [57600/60900 (95%)]	Loss: 186.913864 | Elapsed: 12.47s
01/27/2023 10:59:20 PM  [*] Fri Jan 27 22:59:20 2023:   11    | Tr.loss: 173.312927 | Elapsed:  120.86  s
01/27/2023 10:59:20 PM [!] Fri Jan 27 22:59:20 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_11_1674856760-model.torch
01/27/2023 10:59:20 PM  [*] Started epoch: 12
01/27/2023 10:59:21 PM  [*] Fri Jan 27 22:59:21 2023: Train Epoch: 12 [  0  /60900 (0 %)]	Loss: 179.969696 | Elapsed: 0.18s
01/27/2023 10:59:33 PM  [*] Fri Jan 27 22:59:33 2023: Train Epoch: 12 [6400 /60900 (11%)]	Loss: 172.128693 | Elapsed: 12.56s
01/27/2023 10:59:46 PM  [*] Fri Jan 27 22:59:46 2023: Train Epoch: 12 [12800/60900 (21%)]	Loss: 167.563309 | Elapsed: 12.56s
01/27/2023 10:59:58 PM  [*] Fri Jan 27 22:59:58 2023: Train Epoch: 12 [19200/60900 (32%)]	Loss: 154.394623 | Elapsed: 12.52s
01/27/2023 11:00:11 PM  [*] Fri Jan 27 23:00:11 2023: Train Epoch: 12 [25600/60900 (42%)]	Loss: 170.585693 | Elapsed: 12.55s
01/27/2023 11:00:23 PM  [*] Fri Jan 27 23:00:23 2023: Train Epoch: 12 [32000/60900 (53%)]	Loss: 182.185181 | Elapsed: 12.46s
01/27/2023 11:00:36 PM  [*] Fri Jan 27 23:00:36 2023: Train Epoch: 12 [38400/60900 (63%)]	Loss: 166.018234 | Elapsed: 12.66s
01/27/2023 11:00:48 PM  [*] Fri Jan 27 23:00:48 2023: Train Epoch: 12 [44800/60900 (74%)]	Loss: 181.263306 | Elapsed: 12.46s
01/27/2023 11:01:01 PM  [*] Fri Jan 27 23:01:01 2023: Train Epoch: 12 [51200/60900 (84%)]	Loss: 193.060806 | Elapsed: 12.48s
01/27/2023 11:01:13 PM  [*] Fri Jan 27 23:01:13 2023: Train Epoch: 12 [57600/60900 (95%)]	Loss: 156.378387 | Elapsed: 12.39s
01/27/2023 11:01:21 PM  [*] Fri Jan 27 23:01:21 2023:   12    | Tr.loss: 172.635653 | Elapsed:  121.04  s
01/27/2023 11:01:22 PM [!] Fri Jan 27 23:01:22 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_12_1674856881-model.torch
01/27/2023 11:01:22 PM  [*] Started epoch: 13
01/27/2023 11:01:22 PM  [*] Fri Jan 27 23:01:22 2023: Train Epoch: 13 [  0  /60900 (0 %)]	Loss: 152.304794 | Elapsed: 0.21s
01/27/2023 11:01:35 PM  [*] Fri Jan 27 23:01:35 2023: Train Epoch: 13 [6400 /60900 (11%)]	Loss: 158.331192 | Elapsed: 12.56s
01/27/2023 11:01:47 PM  [*] Fri Jan 27 23:01:47 2023: Train Epoch: 13 [12800/60900 (21%)]	Loss: 181.503540 | Elapsed: 12.45s
01/27/2023 11:02:00 PM  [*] Fri Jan 27 23:02:00 2023: Train Epoch: 13 [19200/60900 (32%)]	Loss: 185.201340 | Elapsed: 12.47s
01/27/2023 11:02:12 PM  [*] Fri Jan 27 23:02:12 2023: Train Epoch: 13 [25600/60900 (42%)]	Loss: 153.748459 | Elapsed: 12.62s
01/27/2023 11:02:25 PM  [*] Fri Jan 27 23:02:25 2023: Train Epoch: 13 [32000/60900 (53%)]	Loss: 169.826965 | Elapsed: 12.56s
01/27/2023 11:02:37 PM  [*] Fri Jan 27 23:02:37 2023: Train Epoch: 13 [38400/60900 (63%)]	Loss: 178.518875 | Elapsed: 12.50s
01/27/2023 11:02:50 PM  [*] Fri Jan 27 23:02:50 2023: Train Epoch: 13 [44800/60900 (74%)]	Loss: 154.129013 | Elapsed: 12.50s
01/27/2023 11:03:02 PM  [*] Fri Jan 27 23:03:02 2023: Train Epoch: 13 [51200/60900 (84%)]	Loss: 185.790009 | Elapsed: 12.55s
01/27/2023 11:03:15 PM  [*] Fri Jan 27 23:03:15 2023: Train Epoch: 13 [57600/60900 (95%)]	Loss: 164.817322 | Elapsed: 12.49s
01/27/2023 11:03:23 PM  [*] Fri Jan 27 23:03:23 2023:   13    | Tr.loss: 172.412951 | Elapsed:  121.25  s
01/27/2023 11:03:24 PM [!] Fri Jan 27 23:03:24 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_13_1674857003-model.torch
01/27/2023 11:03:24 PM  [*] Started epoch: 14
01/27/2023 11:03:24 PM  [*] Fri Jan 27 23:03:24 2023: Train Epoch: 14 [  0  /60900 (0 %)]	Loss: 191.008667 | Elapsed: 0.26s
01/27/2023 11:03:37 PM  [*] Fri Jan 27 23:03:37 2023: Train Epoch: 14 [6400 /60900 (11%)]	Loss: 179.963623 | Elapsed: 12.59s
01/27/2023 11:03:49 PM  [*] Fri Jan 27 23:03:49 2023: Train Epoch: 14 [12800/60900 (21%)]	Loss: 165.451172 | Elapsed: 12.57s
01/27/2023 11:04:02 PM  [*] Fri Jan 27 23:04:02 2023: Train Epoch: 14 [19200/60900 (32%)]	Loss: 178.730209 | Elapsed: 12.58s
01/27/2023 11:04:14 PM  [*] Fri Jan 27 23:04:14 2023: Train Epoch: 14 [25600/60900 (42%)]	Loss: 174.248535 | Elapsed: 12.46s
01/27/2023 11:04:27 PM  [*] Fri Jan 27 23:04:27 2023: Train Epoch: 14 [32000/60900 (53%)]	Loss: 166.864685 | Elapsed: 12.52s
01/27/2023 11:04:39 PM  [*] Fri Jan 27 23:04:39 2023: Train Epoch: 14 [38400/60900 (63%)]	Loss: 170.731323 | Elapsed: 12.42s
01/27/2023 11:04:52 PM  [*] Fri Jan 27 23:04:52 2023: Train Epoch: 14 [44800/60900 (74%)]	Loss: 182.188736 | Elapsed: 12.51s
01/27/2023 11:05:04 PM  [*] Fri Jan 27 23:05:04 2023: Train Epoch: 14 [51200/60900 (84%)]	Loss: 164.678986 | Elapsed: 12.46s
01/27/2023 11:05:17 PM  [*] Fri Jan 27 23:05:17 2023: Train Epoch: 14 [57600/60900 (95%)]	Loss: 155.409866 | Elapsed: 12.56s
01/27/2023 11:05:25 PM  [*] Fri Jan 27 23:05:25 2023:   14    | Tr.loss: 172.341249 | Elapsed:  121.20  s
01/27/2023 11:05:26 PM [!] Fri Jan 27 23:05:26 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_14_1674857125-model.torch
01/27/2023 11:05:26 PM  [*] Started epoch: 15
01/27/2023 11:05:26 PM  [*] Fri Jan 27 23:05:26 2023: Train Epoch: 15 [  0  /60900 (0 %)]	Loss: 175.561890 | Elapsed: 0.27s
01/27/2023 11:05:38 PM  [*] Fri Jan 27 23:05:38 2023: Train Epoch: 15 [6400 /60900 (11%)]	Loss: 165.936798 | Elapsed: 12.55s
01/27/2023 11:05:51 PM  [*] Fri Jan 27 23:05:51 2023: Train Epoch: 15 [12800/60900 (21%)]	Loss: 178.957275 | Elapsed: 12.45s
01/27/2023 11:06:04 PM  [*] Fri Jan 27 23:06:04 2023: Train Epoch: 15 [19200/60900 (32%)]	Loss: 175.807678 | Elapsed: 12.74s
01/27/2023 11:06:16 PM  [*] Fri Jan 27 23:06:16 2023: Train Epoch: 15 [25600/60900 (42%)]	Loss: 175.945389 | Elapsed: 12.43s
01/27/2023 11:06:28 PM  [*] Fri Jan 27 23:06:28 2023: Train Epoch: 15 [32000/60900 (53%)]	Loss: 206.471573 | Elapsed: 12.47s
01/27/2023 11:06:41 PM  [*] Fri Jan 27 23:06:41 2023: Train Epoch: 15 [38400/60900 (63%)]	Loss: 177.639496 | Elapsed: 12.38s
01/27/2023 11:06:53 PM  [*] Fri Jan 27 23:06:53 2023: Train Epoch: 15 [44800/60900 (74%)]	Loss: 188.512207 | Elapsed: 12.39s
01/27/2023 11:07:06 PM  [*] Fri Jan 27 23:07:06 2023: Train Epoch: 15 [51200/60900 (84%)]	Loss: 175.139404 | Elapsed: 12.44s
01/27/2023 11:07:18 PM  [*] Fri Jan 27 23:07:18 2023: Train Epoch: 15 [57600/60900 (95%)]	Loss: 184.479431 | Elapsed: 12.49s
01/27/2023 11:07:26 PM  [*] Fri Jan 27 23:07:26 2023:   15    | Tr.loss: 172.263590 | Elapsed:  120.81  s
01/27/2023 11:07:27 PM [!] Fri Jan 27 23:07:27 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_15_1674857246-model.torch
01/27/2023 11:07:27 PM  [*] Started epoch: 16
01/27/2023 11:07:27 PM  [*] Fri Jan 27 23:07:27 2023: Train Epoch: 16 [  0  /60900 (0 %)]	Loss: 163.515213 | Elapsed: 0.32s
01/27/2023 11:07:40 PM  [*] Fri Jan 27 23:07:40 2023: Train Epoch: 16 [6400 /60900 (11%)]	Loss: 166.084503 | Elapsed: 12.50s
01/27/2023 11:07:52 PM  [*] Fri Jan 27 23:07:52 2023: Train Epoch: 16 [12800/60900 (21%)]	Loss: 180.797531 | Elapsed: 12.44s
01/27/2023 11:08:05 PM  [*] Fri Jan 27 23:08:05 2023: Train Epoch: 16 [19200/60900 (32%)]	Loss: 166.304077 | Elapsed: 12.64s
01/27/2023 11:08:17 PM  [*] Fri Jan 27 23:08:17 2023: Train Epoch: 16 [25600/60900 (42%)]	Loss: 169.000854 | Elapsed: 12.49s
01/27/2023 11:08:30 PM  [*] Fri Jan 27 23:08:30 2023: Train Epoch: 16 [32000/60900 (53%)]	Loss: 166.533615 | Elapsed: 12.66s
01/27/2023 11:08:43 PM  [*] Fri Jan 27 23:08:43 2023: Train Epoch: 16 [38400/60900 (63%)]	Loss: 186.114807 | Elapsed: 12.53s
01/27/2023 11:08:55 PM  [*] Fri Jan 27 23:08:55 2023: Train Epoch: 16 [44800/60900 (74%)]	Loss: 169.314499 | Elapsed: 12.47s
01/27/2023 11:09:07 PM  [*] Fri Jan 27 23:09:07 2023: Train Epoch: 16 [51200/60900 (84%)]	Loss: 163.675446 | Elapsed: 12.44s
01/27/2023 11:09:20 PM  [*] Fri Jan 27 23:09:20 2023: Train Epoch: 16 [57600/60900 (95%)]	Loss: 170.483505 | Elapsed: 12.47s
01/27/2023 11:09:28 PM  [*] Fri Jan 27 23:09:28 2023:   16    | Tr.loss: 172.156829 | Elapsed:  121.07  s
01/27/2023 11:09:29 PM [!] Fri Jan 27 23:09:29 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_16_1674857368-model.torch
01/27/2023 11:09:29 PM  [*] Started epoch: 17
01/27/2023 11:09:29 PM  [*] Fri Jan 27 23:09:29 2023: Train Epoch: 17 [  0  /60900 (0 %)]	Loss: 151.294174 | Elapsed: 0.24s
01/27/2023 11:09:41 PM  [*] Fri Jan 27 23:09:41 2023: Train Epoch: 17 [6400 /60900 (11%)]	Loss: 154.012543 | Elapsed: 12.55s
01/27/2023 11:09:54 PM  [*] Fri Jan 27 23:09:54 2023: Train Epoch: 17 [12800/60900 (21%)]	Loss: 160.293304 | Elapsed: 12.45s
01/27/2023 11:10:06 PM  [*] Fri Jan 27 23:10:06 2023: Train Epoch: 17 [19200/60900 (32%)]	Loss: 171.658142 | Elapsed: 12.47s
01/27/2023 11:10:19 PM  [*] Fri Jan 27 23:10:19 2023: Train Epoch: 17 [25600/60900 (42%)]	Loss: 172.736694 | Elapsed: 12.45s
01/27/2023 11:10:31 PM  [*] Fri Jan 27 23:10:31 2023: Train Epoch: 17 [32000/60900 (53%)]	Loss: 182.515488 | Elapsed: 12.54s
01/27/2023 11:10:44 PM  [*] Fri Jan 27 23:10:44 2023: Train Epoch: 17 [38400/60900 (63%)]	Loss: 171.893921 | Elapsed: 12.47s
01/27/2023 11:10:56 PM  [*] Fri Jan 27 23:10:56 2023: Train Epoch: 17 [44800/60900 (74%)]	Loss: 160.250381 | Elapsed: 12.55s
01/27/2023 11:11:09 PM  [*] Fri Jan 27 23:11:09 2023: Train Epoch: 17 [51200/60900 (84%)]	Loss: 163.067535 | Elapsed: 12.59s
01/27/2023 11:11:21 PM  [*] Fri Jan 27 23:11:21 2023: Train Epoch: 17 [57600/60900 (95%)]	Loss: 184.705460 | Elapsed: 12.44s
01/27/2023 11:11:30 PM  [*] Fri Jan 27 23:11:30 2023:   17    | Tr.loss: 172.065488 | Elapsed:  120.98  s
01/27/2023 11:11:30 PM [!] Fri Jan 27 23:11:30 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_17_1674857490-model.torch
01/27/2023 11:11:30 PM  [*] Started epoch: 18
01/27/2023 11:11:30 PM  [*] Fri Jan 27 23:11:30 2023: Train Epoch: 18 [  0  /60900 (0 %)]	Loss: 175.749481 | Elapsed: 0.25s
01/27/2023 11:11:43 PM  [*] Fri Jan 27 23:11:43 2023: Train Epoch: 18 [6400 /60900 (11%)]	Loss: 193.156891 | Elapsed: 12.56s
01/27/2023 11:11:55 PM  [*] Fri Jan 27 23:11:55 2023: Train Epoch: 18 [12800/60900 (21%)]	Loss: 199.335312 | Elapsed: 12.49s
01/27/2023 11:12:08 PM  [*] Fri Jan 27 23:12:08 2023: Train Epoch: 18 [19200/60900 (32%)]	Loss: 172.981415 | Elapsed: 12.44s
01/27/2023 11:12:20 PM  [*] Fri Jan 27 23:12:20 2023: Train Epoch: 18 [25600/60900 (42%)]	Loss: 167.408386 | Elapsed: 12.50s
01/27/2023 11:12:33 PM  [*] Fri Jan 27 23:12:33 2023: Train Epoch: 18 [32000/60900 (53%)]	Loss: 179.190659 | Elapsed: 12.44s
01/27/2023 11:12:45 PM  [*] Fri Jan 27 23:12:45 2023: Train Epoch: 18 [38400/60900 (63%)]	Loss: 169.805237 | Elapsed: 12.51s
01/27/2023 11:12:58 PM  [*] Fri Jan 27 23:12:58 2023: Train Epoch: 18 [44800/60900 (74%)]	Loss: 180.588943 | Elapsed: 12.39s
01/27/2023 11:13:10 PM  [*] Fri Jan 27 23:13:10 2023: Train Epoch: 18 [51200/60900 (84%)]	Loss: 173.816376 | Elapsed: 12.44s
01/27/2023 11:13:23 PM  [*] Fri Jan 27 23:13:23 2023: Train Epoch: 18 [57600/60900 (95%)]	Loss: 177.087769 | Elapsed: 12.47s
01/27/2023 11:13:31 PM  [*] Fri Jan 27 23:13:31 2023:   18    | Tr.loss: 171.995014 | Elapsed:  120.69  s
01/27/2023 11:13:31 PM [!] Fri Jan 27 23:13:31 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_18_1674857611-model.torch
01/27/2023 11:13:31 PM  [*] Started epoch: 19
01/27/2023 11:13:31 PM  [*] Fri Jan 27 23:13:31 2023: Train Epoch: 19 [  0  /60900 (0 %)]	Loss: 175.332230 | Elapsed: 0.21s
01/27/2023 11:13:44 PM  [*] Fri Jan 27 23:13:44 2023: Train Epoch: 19 [6400 /60900 (11%)]	Loss: 181.119034 | Elapsed: 12.63s
01/27/2023 11:13:57 PM  [*] Fri Jan 27 23:13:57 2023: Train Epoch: 19 [12800/60900 (21%)]	Loss: 175.289551 | Elapsed: 12.59s
01/27/2023 11:14:09 PM  [*] Fri Jan 27 23:14:09 2023: Train Epoch: 19 [19200/60900 (32%)]	Loss: 174.430801 | Elapsed: 12.50s
01/27/2023 11:14:22 PM  [*] Fri Jan 27 23:14:22 2023: Train Epoch: 19 [25600/60900 (42%)]	Loss: 175.389832 | Elapsed: 12.51s
01/27/2023 11:14:34 PM  [*] Fri Jan 27 23:14:34 2023: Train Epoch: 19 [32000/60900 (53%)]	Loss: 188.979187 | Elapsed: 12.52s
01/27/2023 11:14:47 PM  [*] Fri Jan 27 23:14:47 2023: Train Epoch: 19 [38400/60900 (63%)]	Loss: 197.751129 | Elapsed: 12.50s
01/27/2023 11:14:59 PM  [*] Fri Jan 27 23:14:59 2023: Train Epoch: 19 [44800/60900 (74%)]	Loss: 167.120972 | Elapsed: 12.47s
01/27/2023 11:15:12 PM  [*] Fri Jan 27 23:15:12 2023: Train Epoch: 19 [51200/60900 (84%)]	Loss: 181.599274 | Elapsed: 12.55s
01/27/2023 11:15:24 PM  [*] Fri Jan 27 23:15:24 2023: Train Epoch: 19 [57600/60900 (95%)]	Loss: 184.505783 | Elapsed: 12.56s
01/27/2023 11:15:32 PM  [*] Fri Jan 27 23:15:32 2023:   19    | Tr.loss: 171.991547 | Elapsed:  121.24  s
01/27/2023 11:15:33 PM [!] Fri Jan 27 23:15:33 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_19_1674857732-model.torch
01/27/2023 11:15:33 PM  [*] Started epoch: 20
01/27/2023 11:15:33 PM  [*] Fri Jan 27 23:15:33 2023: Train Epoch: 20 [  0  /60900 (0 %)]	Loss: 180.485764 | Elapsed: 0.23s
01/27/2023 11:15:46 PM  [*] Fri Jan 27 23:15:46 2023: Train Epoch: 20 [6400 /60900 (11%)]	Loss: 182.172684 | Elapsed: 12.49s
01/27/2023 11:15:58 PM  [*] Fri Jan 27 23:15:58 2023: Train Epoch: 20 [12800/60900 (21%)]	Loss: 183.040955 | Elapsed: 12.47s
01/27/2023 11:16:11 PM  [*] Fri Jan 27 23:16:11 2023: Train Epoch: 20 [19200/60900 (32%)]	Loss: 181.037964 | Elapsed: 12.61s
01/27/2023 11:16:23 PM  [*] Fri Jan 27 23:16:23 2023: Train Epoch: 20 [25600/60900 (42%)]	Loss: 171.643036 | Elapsed: 12.46s
01/27/2023 11:16:36 PM  [*] Fri Jan 27 23:16:36 2023: Train Epoch: 20 [32000/60900 (53%)]	Loss: 155.190567 | Elapsed: 12.48s
01/27/2023 11:16:48 PM  [*] Fri Jan 27 23:16:48 2023: Train Epoch: 20 [38400/60900 (63%)]	Loss: 181.208481 | Elapsed: 12.51s
01/27/2023 11:17:01 PM  [*] Fri Jan 27 23:17:01 2023: Train Epoch: 20 [44800/60900 (74%)]	Loss: 160.164856 | Elapsed: 12.42s
01/27/2023 11:17:13 PM  [*] Fri Jan 27 23:17:13 2023: Train Epoch: 20 [51200/60900 (84%)]	Loss: 160.153595 | Elapsed: 12.39s
01/27/2023 11:17:25 PM  [*] Fri Jan 27 23:17:25 2023: Train Epoch: 20 [57600/60900 (95%)]	Loss: 166.621353 | Elapsed: 12.41s
01/27/2023 11:17:34 PM  [*] Fri Jan 27 23:17:34 2023:   20    | Tr.loss: 171.979886 | Elapsed:  120.66  s
01/27/2023 11:17:34 PM [!] Fri Jan 27 23:17:34 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_20_1674857854-model.torch
01/27/2023 11:17:34 PM  [*] Started epoch: 21
01/27/2023 11:17:34 PM  [*] Fri Jan 27 23:17:34 2023: Train Epoch: 21 [  0  /60900 (0 %)]	Loss: 154.440796 | Elapsed: 0.24s
01/27/2023 11:17:47 PM  [*] Fri Jan 27 23:17:47 2023: Train Epoch: 21 [6400 /60900 (11%)]	Loss: 161.291611 | Elapsed: 12.50s
01/27/2023 11:17:59 PM  [*] Fri Jan 27 23:17:59 2023: Train Epoch: 21 [12800/60900 (21%)]	Loss: 179.395630 | Elapsed: 12.52s
01/27/2023 11:18:12 PM  [*] Fri Jan 27 23:18:12 2023: Train Epoch: 21 [19200/60900 (32%)]	Loss: 158.821930 | Elapsed: 12.52s
01/27/2023 11:18:24 PM  [*] Fri Jan 27 23:18:24 2023: Train Epoch: 21 [25600/60900 (42%)]	Loss: 164.904114 | Elapsed: 12.40s
01/27/2023 11:18:37 PM  [*] Fri Jan 27 23:18:37 2023: Train Epoch: 21 [32000/60900 (53%)]	Loss: 164.460602 | Elapsed: 12.61s
01/27/2023 11:18:49 PM  [*] Fri Jan 27 23:18:49 2023: Train Epoch: 21 [38400/60900 (63%)]	Loss: 155.445847 | Elapsed: 12.48s
01/27/2023 11:19:02 PM  [*] Fri Jan 27 23:19:02 2023: Train Epoch: 21 [44800/60900 (74%)]	Loss: 166.665527 | Elapsed: 12.47s
01/27/2023 11:19:14 PM  [*] Fri Jan 27 23:19:14 2023: Train Epoch: 21 [51200/60900 (84%)]	Loss: 176.376419 | Elapsed: 12.41s
01/27/2023 11:19:27 PM  [*] Fri Jan 27 23:19:27 2023: Train Epoch: 21 [57600/60900 (95%)]	Loss: 172.158966 | Elapsed: 12.48s
01/27/2023 11:19:35 PM  [*] Fri Jan 27 23:19:35 2023:   21    | Tr.loss: 171.850681 | Elapsed:  120.76  s
01/27/2023 11:19:35 PM [!] Fri Jan 27 23:19:35 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_21_1674857975-model.torch
01/27/2023 11:19:35 PM  [*] Started epoch: 22
01/27/2023 11:19:36 PM  [*] Fri Jan 27 23:19:36 2023: Train Epoch: 22 [  0  /60900 (0 %)]	Loss: 175.458267 | Elapsed: 0.25s
01/27/2023 11:19:37 PM [!] Learning rate: 2.5e-06
01/27/2023 11:19:48 PM  [*] Fri Jan 27 23:19:48 2023: Train Epoch: 22 [6400 /60900 (11%)]	Loss: 149.995148 | Elapsed: 12.51s
01/27/2023 11:20:01 PM  [*] Fri Jan 27 23:20:01 2023: Train Epoch: 22 [12800/60900 (21%)]	Loss: 176.535675 | Elapsed: 12.51s
01/27/2023 11:20:13 PM  [*] Fri Jan 27 23:20:13 2023: Train Epoch: 22 [19200/60900 (32%)]	Loss: 178.409393 | Elapsed: 12.47s
01/27/2023 11:20:26 PM  [*] Fri Jan 27 23:20:26 2023: Train Epoch: 22 [25600/60900 (42%)]	Loss: 160.056915 | Elapsed: 12.49s
01/27/2023 11:20:38 PM  [*] Fri Jan 27 23:20:38 2023: Train Epoch: 22 [32000/60900 (53%)]	Loss: 183.654053 | Elapsed: 12.51s
01/27/2023 11:20:51 PM  [*] Fri Jan 27 23:20:51 2023: Train Epoch: 22 [38400/60900 (63%)]	Loss: 177.409912 | Elapsed: 12.52s
01/27/2023 11:21:03 PM  [*] Fri Jan 27 23:21:03 2023: Train Epoch: 22 [44800/60900 (74%)]	Loss: 184.267365 | Elapsed: 12.49s
01/27/2023 11:21:16 PM  [*] Fri Jan 27 23:21:16 2023: Train Epoch: 22 [51200/60900 (84%)]	Loss: 168.066772 | Elapsed: 12.56s
01/27/2023 11:21:28 PM  [*] Fri Jan 27 23:21:28 2023: Train Epoch: 22 [57600/60900 (95%)]	Loss: 164.174698 | Elapsed: 12.34s
01/27/2023 11:21:36 PM  [*] Fri Jan 27 23:21:36 2023:   22    | Tr.loss: 171.770500 | Elapsed:  120.80  s
01/27/2023 11:21:37 PM [!] Fri Jan 27 23:21:37 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_22_1674858096-model.torch
01/27/2023 11:21:37 PM  [*] Started epoch: 23
01/27/2023 11:21:37 PM  [*] Fri Jan 27 23:21:37 2023: Train Epoch: 23 [  0  /60900 (0 %)]	Loss: 159.966644 | Elapsed: 0.31s
01/27/2023 11:21:50 PM  [*] Fri Jan 27 23:21:50 2023: Train Epoch: 23 [6400 /60900 (11%)]	Loss: 170.067734 | Elapsed: 12.51s
01/27/2023 11:22:02 PM  [*] Fri Jan 27 23:22:02 2023: Train Epoch: 23 [12800/60900 (21%)]	Loss: 186.900009 | Elapsed: 12.57s
01/27/2023 11:22:15 PM  [*] Fri Jan 27 23:22:15 2023: Train Epoch: 23 [19200/60900 (32%)]	Loss: 179.197083 | Elapsed: 12.45s
01/27/2023 11:22:27 PM  [*] Fri Jan 27 23:22:27 2023: Train Epoch: 23 [25600/60900 (42%)]	Loss: 150.230652 | Elapsed: 12.50s
01/27/2023 11:22:40 PM  [*] Fri Jan 27 23:22:40 2023: Train Epoch: 23 [32000/60900 (53%)]	Loss: 149.194290 | Elapsed: 12.42s
01/27/2023 11:22:52 PM  [*] Fri Jan 27 23:22:52 2023: Train Epoch: 23 [38400/60900 (63%)]	Loss: 181.339935 | Elapsed: 12.59s
01/27/2023 11:23:05 PM  [*] Fri Jan 27 23:23:05 2023: Train Epoch: 23 [44800/60900 (74%)]	Loss: 159.890152 | Elapsed: 12.48s
01/27/2023 11:23:17 PM  [*] Fri Jan 27 23:23:17 2023: Train Epoch: 23 [51200/60900 (84%)]	Loss: 175.973389 | Elapsed: 12.55s
01/27/2023 11:23:30 PM  [*] Fri Jan 27 23:23:30 2023: Train Epoch: 23 [57600/60900 (95%)]	Loss: 203.007294 | Elapsed: 12.37s
01/27/2023 11:23:38 PM  [*] Fri Jan 27 23:23:38 2023:   23    | Tr.loss: 171.817859 | Elapsed:  120.94  s
01/27/2023 11:23:38 PM [!] Fri Jan 27 23:23:38 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_23_1674858218-model.torch
01/27/2023 11:23:38 PM  [*] Started epoch: 24
01/27/2023 11:23:39 PM  [*] Fri Jan 27 23:23:39 2023: Train Epoch: 24 [  0  /60900 (0 %)]	Loss: 158.923523 | Elapsed: 0.27s
01/27/2023 11:23:51 PM  [*] Fri Jan 27 23:23:51 2023: Train Epoch: 24 [6400 /60900 (11%)]	Loss: 180.897400 | Elapsed: 12.51s
01/27/2023 11:24:04 PM  [*] Fri Jan 27 23:24:04 2023: Train Epoch: 24 [12800/60900 (21%)]	Loss: 166.223160 | Elapsed: 12.60s
01/27/2023 11:24:16 PM  [*] Fri Jan 27 23:24:16 2023: Train Epoch: 24 [19200/60900 (32%)]	Loss: 151.085541 | Elapsed: 12.46s
01/27/2023 11:24:29 PM  [*] Fri Jan 27 23:24:29 2023: Train Epoch: 24 [25600/60900 (42%)]	Loss: 158.432251 | Elapsed: 12.51s
01/27/2023 11:24:41 PM  [*] Fri Jan 27 23:24:41 2023: Train Epoch: 24 [32000/60900 (53%)]	Loss: 159.675415 | Elapsed: 12.41s
01/27/2023 11:24:53 PM  [*] Fri Jan 27 23:24:53 2023: Train Epoch: 24 [38400/60900 (63%)]	Loss: 159.714478 | Elapsed: 12.44s
01/27/2023 11:25:06 PM  [*] Fri Jan 27 23:25:06 2023: Train Epoch: 24 [44800/60900 (74%)]	Loss: 153.395996 | Elapsed: 12.42s
01/27/2023 11:25:18 PM  [*] Fri Jan 27 23:25:18 2023: Train Epoch: 24 [51200/60900 (84%)]	Loss: 164.826340 | Elapsed: 12.52s
01/27/2023 11:25:31 PM  [*] Fri Jan 27 23:25:31 2023: Train Epoch: 24 [57600/60900 (95%)]	Loss: 169.209335 | Elapsed: 12.45s
01/27/2023 11:25:39 PM  [*] Fri Jan 27 23:25:39 2023:   24    | Tr.loss: 171.802530 | Elapsed:  120.85  s
01/27/2023 11:25:40 PM [!] Fri Jan 27 23:25:40 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_24_1674858339-model.torch
01/27/2023 11:25:40 PM  [*] Started epoch: 25
01/27/2023 11:25:40 PM  [*] Fri Jan 27 23:25:40 2023: Train Epoch: 25 [  0  /60900 (0 %)]	Loss: 172.299011 | Elapsed: 0.31s
01/27/2023 11:25:52 PM  [*] Fri Jan 27 23:25:52 2023: Train Epoch: 25 [6400 /60900 (11%)]	Loss: 179.188553 | Elapsed: 12.53s
01/27/2023 11:26:05 PM  [*] Fri Jan 27 23:26:05 2023: Train Epoch: 25 [12800/60900 (21%)]	Loss: 183.010803 | Elapsed: 12.49s
01/27/2023 11:26:18 PM  [*] Fri Jan 27 23:26:18 2023: Train Epoch: 25 [19200/60900 (32%)]	Loss: 179.598206 | Elapsed: 12.59s
01/27/2023 11:26:30 PM  [*] Fri Jan 27 23:26:30 2023: Train Epoch: 25 [25600/60900 (42%)]	Loss: 187.247314 | Elapsed: 12.54s
01/27/2023 11:26:43 PM  [*] Fri Jan 27 23:26:43 2023: Train Epoch: 25 [32000/60900 (53%)]	Loss: 163.070740 | Elapsed: 12.48s
01/27/2023 11:26:55 PM  [*] Fri Jan 27 23:26:55 2023: Train Epoch: 25 [38400/60900 (63%)]	Loss: 152.648163 | Elapsed: 12.42s
01/27/2023 11:27:08 PM  [*] Fri Jan 27 23:27:08 2023: Train Epoch: 25 [44800/60900 (74%)]	Loss: 163.890411 | Elapsed: 12.56s
01/27/2023 11:27:20 PM  [*] Fri Jan 27 23:27:20 2023: Train Epoch: 25 [51200/60900 (84%)]	Loss: 159.238159 | Elapsed: 12.43s
01/27/2023 11:27:33 PM  [*] Fri Jan 27 23:27:33 2023: Train Epoch: 25 [57600/60900 (95%)]	Loss: 165.358765 | Elapsed: 12.58s
01/27/2023 11:27:41 PM  [*] Fri Jan 27 23:27:41 2023:   25    | Tr.loss: 171.696407 | Elapsed:  121.17  s
01/27/2023 11:27:41 PM [!] Fri Jan 27 23:27:41 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_25_1674858461-model.torch
01/27/2023 11:27:41 PM  [*] Started epoch: 26
01/27/2023 11:27:42 PM  [*] Fri Jan 27 23:27:42 2023: Train Epoch: 26 [  0  /60900 (0 %)]	Loss: 179.712875 | Elapsed: 0.23s
01/27/2023 11:27:54 PM  [*] Fri Jan 27 23:27:54 2023: Train Epoch: 26 [6400 /60900 (11%)]	Loss: 171.658966 | Elapsed: 12.54s
01/27/2023 11:28:06 PM  [*] Fri Jan 27 23:28:06 2023: Train Epoch: 26 [12800/60900 (21%)]	Loss: 154.496445 | Elapsed: 12.40s
01/27/2023 11:28:19 PM  [*] Fri Jan 27 23:28:19 2023: Train Epoch: 26 [19200/60900 (32%)]	Loss: 169.941132 | Elapsed: 12.57s
01/27/2023 11:28:31 PM  [*] Fri Jan 27 23:28:31 2023: Train Epoch: 26 [25600/60900 (42%)]	Loss: 169.971817 | Elapsed: 12.41s
01/27/2023 11:28:44 PM  [*] Fri Jan 27 23:28:44 2023: Train Epoch: 26 [32000/60900 (53%)]	Loss: 181.073975 | Elapsed: 12.50s
01/27/2023 11:28:56 PM  [*] Fri Jan 27 23:28:56 2023: Train Epoch: 26 [38400/60900 (63%)]	Loss: 188.127151 | Elapsed: 12.44s
01/27/2023 11:29:09 PM  [*] Fri Jan 27 23:29:09 2023: Train Epoch: 26 [44800/60900 (74%)]	Loss: 188.256531 | Elapsed: 12.53s
01/27/2023 11:29:21 PM  [*] Fri Jan 27 23:29:21 2023: Train Epoch: 26 [51200/60900 (84%)]	Loss: 176.380737 | Elapsed: 12.49s
01/27/2023 11:29:34 PM  [*] Fri Jan 27 23:29:34 2023: Train Epoch: 26 [57600/60900 (95%)]	Loss: 182.320435 | Elapsed: 12.51s
01/27/2023 11:29:42 PM  [*] Fri Jan 27 23:29:42 2023:   26    | Tr.loss: 171.691705 | Elapsed:  120.89  s
01/27/2023 11:29:43 PM [!] Fri Jan 27 23:29:43 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_26_1674858582-model.torch
01/27/2023 11:29:43 PM  [*] Started epoch: 27
01/27/2023 11:29:43 PM  [*] Fri Jan 27 23:29:43 2023: Train Epoch: 27 [  0  /60900 (0 %)]	Loss: 173.358002 | Elapsed: 0.34s
01/27/2023 11:29:56 PM  [*] Fri Jan 27 23:29:56 2023: Train Epoch: 27 [6400 /60900 (11%)]	Loss: 168.677292 | Elapsed: 12.48s
01/27/2023 11:30:08 PM  [*] Fri Jan 27 23:30:08 2023: Train Epoch: 27 [12800/60900 (21%)]	Loss: 182.917755 | Elapsed: 12.51s
01/27/2023 11:30:21 PM  [*] Fri Jan 27 23:30:21 2023: Train Epoch: 27 [19200/60900 (32%)]	Loss: 182.734131 | Elapsed: 12.61s
01/27/2023 11:30:33 PM  [*] Fri Jan 27 23:30:33 2023: Train Epoch: 27 [25600/60900 (42%)]	Loss: 194.634857 | Elapsed: 12.48s
01/27/2023 11:30:46 PM  [*] Fri Jan 27 23:30:46 2023: Train Epoch: 27 [32000/60900 (53%)]	Loss: 164.034088 | Elapsed: 12.50s
01/27/2023 11:30:58 PM  [*] Fri Jan 27 23:30:58 2023: Train Epoch: 27 [38400/60900 (63%)]	Loss: 179.993164 | Elapsed: 12.50s
01/27/2023 11:31:11 PM  [*] Fri Jan 27 23:31:11 2023: Train Epoch: 27 [44800/60900 (74%)]	Loss: 169.724731 | Elapsed: 12.45s
01/27/2023 11:31:23 PM  [*] Fri Jan 27 23:31:23 2023: Train Epoch: 27 [51200/60900 (84%)]	Loss: 170.271973 | Elapsed: 12.59s
01/27/2023 11:31:36 PM  [*] Fri Jan 27 23:31:36 2023: Train Epoch: 27 [57600/60900 (95%)]	Loss: 166.715668 | Elapsed: 12.54s
01/27/2023 11:31:44 PM  [*] Fri Jan 27 23:31:44 2023:   27    | Tr.loss: 171.680592 | Elapsed:  121.28  s
01/27/2023 11:31:44 PM [!] Fri Jan 27 23:31:44 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_27_1674858704-model.torch
01/27/2023 11:31:44 PM  [*] Started epoch: 28
01/27/2023 11:31:45 PM  [*] Fri Jan 27 23:31:45 2023: Train Epoch: 28 [  0  /60900 (0 %)]	Loss: 165.894150 | Elapsed: 0.26s
01/27/2023 11:31:57 PM  [*] Fri Jan 27 23:31:57 2023: Train Epoch: 28 [6400 /60900 (11%)]	Loss: 156.290558 | Elapsed: 12.48s
01/27/2023 11:32:10 PM  [*] Fri Jan 27 23:32:10 2023: Train Epoch: 28 [12800/60900 (21%)]	Loss: 152.015228 | Elapsed: 12.45s
01/27/2023 11:32:22 PM  [*] Fri Jan 27 23:32:22 2023: Train Epoch: 28 [19200/60900 (32%)]	Loss: 179.502136 | Elapsed: 12.40s
01/27/2023 11:32:35 PM  [*] Fri Jan 27 23:32:35 2023: Train Epoch: 28 [25600/60900 (42%)]	Loss: 155.899261 | Elapsed: 12.51s
01/27/2023 11:32:47 PM  [*] Fri Jan 27 23:32:47 2023: Train Epoch: 28 [32000/60900 (53%)]	Loss: 160.878204 | Elapsed: 12.45s
01/27/2023 11:32:59 PM  [*] Fri Jan 27 23:32:59 2023: Train Epoch: 28 [38400/60900 (63%)]	Loss: 159.652130 | Elapsed: 12.46s
01/27/2023 11:33:12 PM  [*] Fri Jan 27 23:33:12 2023: Train Epoch: 28 [44800/60900 (74%)]	Loss: 171.223938 | Elapsed: 12.39s
01/27/2023 11:33:24 PM  [*] Fri Jan 27 23:33:24 2023: Train Epoch: 28 [51200/60900 (84%)]	Loss: 159.621613 | Elapsed: 12.49s
01/27/2023 11:33:37 PM  [*] Fri Jan 27 23:33:37 2023: Train Epoch: 28 [57600/60900 (95%)]	Loss: 163.877319 | Elapsed: 12.44s
01/27/2023 11:33:45 PM  [*] Fri Jan 27 23:33:45 2023:   28    | Tr.loss: 171.595205 | Elapsed:  120.66  s
01/27/2023 11:33:46 PM [!] Fri Jan 27 23:33:46 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_28_1674858825-model.torch
01/27/2023 11:33:46 PM  [*] Started epoch: 29
01/27/2023 11:33:46 PM  [*] Fri Jan 27 23:33:46 2023: Train Epoch: 29 [  0  /60900 (0 %)]	Loss: 178.448212 | Elapsed: 0.26s
01/27/2023 11:33:58 PM  [*] Fri Jan 27 23:33:58 2023: Train Epoch: 29 [6400 /60900 (11%)]	Loss: 182.560684 | Elapsed: 12.47s
01/27/2023 11:34:11 PM  [*] Fri Jan 27 23:34:11 2023: Train Epoch: 29 [12800/60900 (21%)]	Loss: 174.985931 | Elapsed: 12.54s
01/27/2023 11:34:23 PM  [*] Fri Jan 27 23:34:23 2023: Train Epoch: 29 [19200/60900 (32%)]	Loss: 167.773529 | Elapsed: 12.58s
01/27/2023 11:34:36 PM  [*] Fri Jan 27 23:34:36 2023: Train Epoch: 29 [25600/60900 (42%)]	Loss: 188.378113 | Elapsed: 12.53s
01/27/2023 11:34:49 PM  [*] Fri Jan 27 23:34:49 2023: Train Epoch: 29 [32000/60900 (53%)]	Loss: 165.952057 | Elapsed: 12.59s
01/27/2023 11:35:01 PM  [*] Fri Jan 27 23:35:01 2023: Train Epoch: 29 [38400/60900 (63%)]	Loss: 171.846283 | Elapsed: 12.46s
01/27/2023 11:35:14 PM  [*] Fri Jan 27 23:35:14 2023: Train Epoch: 29 [44800/60900 (74%)]	Loss: 174.767563 | Elapsed: 12.51s
01/27/2023 11:35:26 PM  [*] Fri Jan 27 23:35:26 2023: Train Epoch: 29 [51200/60900 (84%)]	Loss: 177.578583 | Elapsed: 12.56s
01/27/2023 11:35:39 PM  [*] Fri Jan 27 23:35:39 2023: Train Epoch: 29 [57600/60900 (95%)]	Loss: 157.728973 | Elapsed: 12.44s
01/27/2023 11:35:47 PM  [*] Fri Jan 27 23:35:47 2023:   29    | Tr.loss: 171.750032 | Elapsed:  121.19  s
01/27/2023 11:35:47 PM [!] Fri Jan 27 23:35:47 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_29_1674858947-model.torch
01/27/2023 11:35:47 PM  [*] Started epoch: 30
01/27/2023 11:35:48 PM  [*] Fri Jan 27 23:35:48 2023: Train Epoch: 30 [  0  /60900 (0 %)]	Loss: 179.265472 | Elapsed: 0.38s
01/27/2023 11:36:00 PM  [*] Fri Jan 27 23:36:00 2023: Train Epoch: 30 [6400 /60900 (11%)]	Loss: 169.670197 | Elapsed: 12.57s
01/27/2023 11:36:13 PM  [*] Fri Jan 27 23:36:13 2023: Train Epoch: 30 [12800/60900 (21%)]	Loss: 168.263153 | Elapsed: 12.51s
01/27/2023 11:36:25 PM  [*] Fri Jan 27 23:36:25 2023: Train Epoch: 30 [19200/60900 (32%)]	Loss: 187.026703 | Elapsed: 12.55s
01/27/2023 11:36:38 PM  [*] Fri Jan 27 23:36:38 2023: Train Epoch: 30 [25600/60900 (42%)]	Loss: 172.741043 | Elapsed: 12.38s
01/27/2023 11:36:50 PM  [*] Fri Jan 27 23:36:50 2023: Train Epoch: 30 [32000/60900 (53%)]	Loss: 169.380829 | Elapsed: 12.64s
01/27/2023 11:37:03 PM  [*] Fri Jan 27 23:37:03 2023: Train Epoch: 30 [38400/60900 (63%)]	Loss: 164.883850 | Elapsed: 12.45s
01/27/2023 11:37:15 PM  [*] Fri Jan 27 23:37:15 2023: Train Epoch: 30 [44800/60900 (74%)]	Loss: 166.988831 | Elapsed: 12.34s
01/27/2023 11:37:27 PM  [*] Fri Jan 27 23:37:27 2023: Train Epoch: 30 [51200/60900 (84%)]	Loss: 178.237686 | Elapsed: 12.34s
01/27/2023 11:37:40 PM  [*] Fri Jan 27 23:37:40 2023: Train Epoch: 30 [57600/60900 (95%)]	Loss: 176.273422 | Elapsed: 12.31s
01/27/2023 11:37:48 PM  [*] Fri Jan 27 23:37:48 2023:   30    | Tr.loss: 171.709182 | Elapsed:  120.56  s
01/27/2023 11:37:48 PM [!] Fri Jan 27 23:37:48 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_30_1674859068-model.torch
01/27/2023 11:37:49 PM [!] Fri Jan 27 23:37:49 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\1674859068-model.torch
		train time: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\1674859068-trainTime.npy
		train losses: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\1674859068-trainLosses.npy
		train AUC: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\1674859068-auc.npy
01/27/2023 11:37:50 PM  [!] Training pretrained model on downstream task...
01/27/2023 11:37:50 PM  [*] Started epoch: 1
01/27/2023 11:37:50 PM  [*] Fri Jan 27 23:37:50 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.981486 | Elapsed: 0.34s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/27/2023 11:37:59 PM  [*] Fri Jan 27 23:37:59 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.430022 | Elapsed: 9.12s | FPR 0.0003 -> TPR 0.3824 & F1 0.5532
01/27/2023 11:38:08 PM  [*] Fri Jan 27 23:38:08 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.411835 | Elapsed: 9.12s | FPR 0.0003 -> TPR 0.3889 & F1 0.5600
01/27/2023 11:38:12 PM  [*] Fri Jan 27 23:38:12 2023:    1    | Tr.loss: 0.541254 | Elapsed:   22.34  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7984
01/27/2023 11:38:12 PM  [*] Started epoch: 2
01/27/2023 11:38:12 PM  [*] Fri Jan 27 23:38:12 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.363874 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.7561 & F1 0.8611
01/27/2023 11:38:21 PM  [*] Fri Jan 27 23:38:21 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.379184 | Elapsed: 9.07s | FPR 0.0003 -> TPR 0.4706 & F1 0.6400
01/27/2023 11:38:30 PM  [*] Fri Jan 27 23:38:30 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.342572 | Elapsed: 9.10s | FPR 0.0003 -> TPR 0.3472 & F1 0.5155
01/27/2023 11:38:34 PM  [*] Fri Jan 27 23:38:34 2023:    2    | Tr.loss: 0.321501 | Elapsed:   21.96  s | FPR 0.0003 -> TPR: 0.16 & F1: 0.27 | AUC: 0.9234
01/27/2023 11:38:34 PM  [*] Started epoch: 3
01/27/2023 11:38:34 PM  [*] Fri Jan 27 23:38:34 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.284860 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.7556 & F1 0.8608
01/27/2023 11:38:43 PM  [*] Fri Jan 27 23:38:43 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.190087 | Elapsed: 9.07s | FPR 0.0003 -> TPR 0.6667 & F1 0.8000
01/27/2023 11:38:52 PM  [*] Fri Jan 27 23:38:52 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.215871 | Elapsed: 9.06s | FPR 0.0003 -> TPR 0.6164 & F1 0.7627
01/27/2023 11:38:56 PM  [*] Fri Jan 27 23:38:56 2023:    3    | Tr.loss: 0.232556 | Elapsed:   21.93  s | FPR 0.0003 -> TPR: 0.33 & F1: 0.49 | AUC: 0.9623
01/27/2023 11:38:56 PM [!] Fri Jan 27 23:38:56 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_pretrained\training_files\1674859136-model.torch
		train time: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_pretrained\training_files\1674859136-trainTime.npy
		train losses: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_pretrained\training_files\1674859136-trainLosses.npy
		train AUC: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_pretrained\training_files\1674859136-auc.npy
		train F1s : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_pretrained\training_files\1674859136-trainF1s.npy
		train TPRs: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_pretrained\training_files\1674859136-trainTPRs.npy
01/27/2023 11:38:56 PM  [!] Training non_pretrained model on downstream task...
01/27/2023 11:38:57 PM  [*] Started epoch: 1
01/27/2023 11:38:57 PM  [*] Fri Jan 27 23:38:57 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.913862 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.2326 & F1 0.3774
01/27/2023 11:39:03 PM  [*] Fri Jan 27 23:39:03 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.347082 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.4247 & F1 0.5962
01/27/2023 11:39:09 PM  [*] Fri Jan 27 23:39:09 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.269603 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.3016 & F1 0.4634
01/27/2023 11:39:12 PM  [*] Fri Jan 27 23:39:12 2023:    1    | Tr.loss: 0.496807 | Elapsed:   15.08  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8218
01/27/2023 11:39:12 PM  [*] Started epoch: 2
01/27/2023 11:39:12 PM  [*] Fri Jan 27 23:39:12 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.308597 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.5532 & F1 0.7123
01/27/2023 11:39:18 PM  [*] Fri Jan 27 23:39:18 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.354757 | Elapsed: 6.16s | FPR 0.0003 -> TPR 0.5634 & F1 0.7207
01/27/2023 11:39:24 PM  [*] Fri Jan 27 23:39:24 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.286537 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.8154 & F1 0.8983
01/27/2023 11:39:27 PM  [*] Fri Jan 27 23:39:27 2023:    2    | Tr.loss: 0.309452 | Elapsed:   15.04  s | FPR 0.0003 -> TPR: 0.19 & F1: 0.32 | AUC: 0.9275
01/27/2023 11:39:27 PM  [*] Started epoch: 3
01/27/2023 11:39:27 PM  [*] Fri Jan 27 23:39:27 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.199976 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.7234 & F1 0.8395
01/27/2023 11:39:33 PM  [*] Fri Jan 27 23:39:33 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.211705 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.6071 & F1 0.7556
01/27/2023 11:39:39 PM  [*] Fri Jan 27 23:39:39 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.293121 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.7612 & F1 0.8644
01/27/2023 11:39:42 PM  [*] Fri Jan 27 23:39:42 2023:    3    | Tr.loss: 0.239280 | Elapsed:   15.01  s | FPR 0.0003 -> TPR: 0.20 & F1: 0.33 | AUC: 0.9593
01/27/2023 11:39:42 PM [!] Fri Jan 27 23:39:42 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_non_pretrained\training_files\1674859182-model.torch
		train time: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_non_pretrained\training_files\1674859182-trainTime.npy
		train losses: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_non_pretrained\training_files\1674859182-trainLosses.npy
		train AUC: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_non_pretrained\training_files\1674859182-auc.npy
		train F1s : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_non_pretrained\training_files\1674859182-trainF1s.npy
		train TPRs: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_non_pretrained\training_files\1674859182-trainTPRs.npy
01/27/2023 11:39:42 PM  [!] Training full_data model on downstream task...
01/27/2023 11:39:43 PM  [*] Started epoch: 1
01/27/2023 11:39:43 PM  [*] Fri Jan 27 23:39:43 2023: Train Epoch: 1 [  0  /76126 (0 %)]	Loss: 2.731800 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0250 & F1 0.0488
01/27/2023 11:39:49 PM  [*] Fri Jan 27 23:39:49 2023: Train Epoch: 1 [6400 /76126 (8 %)]	Loss: 0.440572 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.2899 & F1 0.4494
01/27/2023 11:39:55 PM  [*] Fri Jan 27 23:39:55 2023: Train Epoch: 1 [12800/76126 (17%)]	Loss: 0.299208 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.6197 & F1 0.7652
01/27/2023 11:40:02 PM  [*] Fri Jan 27 23:40:02 2023: Train Epoch: 1 [19200/76126 (25%)]	Loss: 0.247208 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.4444 & F1 0.6154
01/27/2023 11:40:08 PM  [*] Fri Jan 27 23:40:08 2023: Train Epoch: 1 [25600/76126 (34%)]	Loss: 0.174422 | Elapsed: 6.26s | FPR 0.0003 -> TPR 0.6230 & F1 0.7677
01/27/2023 11:40:14 PM  [*] Fri Jan 27 23:40:14 2023: Train Epoch: 1 [32000/76126 (42%)]	Loss: 0.323984 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.5000 & F1 0.6667
01/27/2023 11:40:20 PM  [*] Fri Jan 27 23:40:20 2023: Train Epoch: 1 [38400/76126 (50%)]	Loss: 0.222281 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.7344 & F1 0.8468
01/27/2023 11:40:26 PM  [*] Fri Jan 27 23:40:26 2023: Train Epoch: 1 [44800/76126 (59%)]	Loss: 0.217680 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.8451 & F1 0.9160
01/27/2023 11:40:33 PM  [*] Fri Jan 27 23:40:33 2023: Train Epoch: 1 [51200/76126 (67%)]	Loss: 0.183227 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.9016 & F1 0.9483
01/27/2023 11:40:39 PM  [*] Fri Jan 27 23:40:39 2023: Train Epoch: 1 [57600/76126 (76%)]	Loss: 0.221347 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.7429 & F1 0.8525
01/27/2023 11:40:45 PM  [*] Fri Jan 27 23:40:45 2023: Train Epoch: 1 [64000/76126 (84%)]	Loss: 0.382722 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.6212 & F1 0.7664
01/27/2023 11:40:51 PM  [*] Fri Jan 27 23:40:51 2023: Train Epoch: 1 [70400/76126 (92%)]	Loss: 0.121978 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.7568 & F1 0.8615
01/27/2023 11:40:59 PM  [*] Fri Jan 27 23:40:59 2023:    1    | Tr.loss: 0.304725 | Elapsed:   75.70  s | FPR 0.0003 -> TPR: 0.03 & F1: 0.06 | AUC: 0.9328
01/27/2023 11:40:59 PM  [*] Started epoch: 2
01/27/2023 11:40:59 PM  [*] Fri Jan 27 23:40:59 2023: Train Epoch: 2 [  0  /76126 (0 %)]	Loss: 0.154329 | Elapsed: 0.12s | FPR 0.0003 -> TPR 0.9111 & F1 0.9535
01/27/2023 11:41:05 PM  [*] Fri Jan 27 23:41:05 2023: Train Epoch: 2 [6400 /76126 (8 %)]	Loss: 0.173180 | Elapsed: 6.27s | FPR 0.0003 -> TPR 0.7313 & F1 0.8448
01/27/2023 11:41:11 PM  [*] Fri Jan 27 23:41:11 2023: Train Epoch: 2 [12800/76126 (17%)]	Loss: 0.214062 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.5797 & F1 0.7339
01/27/2023 11:41:17 PM  [*] Fri Jan 27 23:41:17 2023: Train Epoch: 2 [19200/76126 (25%)]	Loss: 0.110694 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.7424 & F1 0.8522
01/27/2023 11:41:24 PM  [*] Fri Jan 27 23:41:24 2023: Train Epoch: 2 [25600/76126 (34%)]	Loss: 0.075652 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.9868 & F1 0.9934
01/27/2023 11:41:30 PM  [*] Fri Jan 27 23:41:30 2023: Train Epoch: 2 [32000/76126 (42%)]	Loss: 0.122675 | Elapsed: 6.26s | FPR 0.0003 -> TPR 0.9385 & F1 0.9683
01/27/2023 11:41:36 PM  [*] Fri Jan 27 23:41:36 2023: Train Epoch: 2 [38400/76126 (50%)]	Loss: 0.139448 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.8718 & F1 0.9315
01/27/2023 11:41:42 PM  [*] Fri Jan 27 23:41:42 2023: Train Epoch: 2 [44800/76126 (59%)]	Loss: 0.069682 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.9275 & F1 0.9624
01/27/2023 11:41:49 PM  [*] Fri Jan 27 23:41:49 2023: Train Epoch: 2 [51200/76126 (67%)]	Loss: 0.157524 | Elapsed: 6.44s | FPR 0.0003 -> TPR 0.9155 & F1 0.9559
01/27/2023 11:41:49 PM [!] Learning rate: 2.5e-05
01/27/2023 11:41:55 PM  [*] Fri Jan 27 23:41:55 2023: Train Epoch: 2 [57600/76126 (76%)]	Loss: 0.126885 | Elapsed: 6.58s | FPR 0.0003 -> TPR 0.8030 & F1 0.8908
01/27/2023 11:42:02 PM  [*] Fri Jan 27 23:42:02 2023: Train Epoch: 2 [64000/76126 (84%)]	Loss: 0.189331 | Elapsed: 6.50s | FPR 0.0003 -> TPR 0.7794 & F1 0.8760
01/27/2023 11:42:09 PM  [*] Fri Jan 27 23:42:09 2023: Train Epoch: 2 [70400/76126 (92%)]	Loss: 0.146643 | Elapsed: 6.68s | FPR 0.0003 -> TPR 0.9310 & F1 0.9643
01/27/2023 11:42:17 PM  [*] Fri Jan 27 23:42:17 2023:    2    | Tr.loss: 0.136250 | Elapsed:   77.98  s | FPR 0.0003 -> TPR: 0.51 & F1: 0.67 | AUC: 0.9871
01/27/2023 11:42:17 PM  [*] Started epoch: 3
01/27/2023 11:42:17 PM  [*] Fri Jan 27 23:42:17 2023: Train Epoch: 3 [  0  /76126 (0 %)]	Loss: 0.172687 | Elapsed: 0.17s | FPR 0.0003 -> TPR 0.8500 & F1 0.9189
01/27/2023 11:42:23 PM  [*] Fri Jan 27 23:42:23 2023: Train Epoch: 3 [6400 /76126 (8 %)]	Loss: 0.101476 | Elapsed: 6.33s | FPR 0.0003 -> TPR 0.9367 & F1 0.9673
01/27/2023 11:42:29 PM  [*] Fri Jan 27 23:42:29 2023: Train Epoch: 3 [12800/76126 (17%)]	Loss: 0.097737 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.9306 & F1 0.9640
01/27/2023 11:42:35 PM  [*] Fri Jan 27 23:42:35 2023: Train Epoch: 3 [19200/76126 (25%)]	Loss: 0.091623 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.9077 & F1 0.9516
01/27/2023 11:42:42 PM  [*] Fri Jan 27 23:42:42 2023: Train Epoch: 3 [25600/76126 (34%)]	Loss: 0.249309 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.6944 & F1 0.8197
01/27/2023 11:42:48 PM  [*] Fri Jan 27 23:42:48 2023: Train Epoch: 3 [32000/76126 (42%)]	Loss: 0.061903 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.9710 & F1 0.9853
01/27/2023 11:42:54 PM  [*] Fri Jan 27 23:42:54 2023: Train Epoch: 3 [38400/76126 (50%)]	Loss: 0.106304 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.8750 & F1 0.9333
01/27/2023 11:43:00 PM  [*] Fri Jan 27 23:43:00 2023: Train Epoch: 3 [44800/76126 (59%)]	Loss: 0.104624 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.9595 & F1 0.9793
01/27/2023 11:43:06 PM  [*] Fri Jan 27 23:43:06 2023: Train Epoch: 3 [51200/76126 (67%)]	Loss: 0.056167 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.9710 & F1 0.9853
01/27/2023 11:43:13 PM  [*] Fri Jan 27 23:43:13 2023: Train Epoch: 3 [57600/76126 (76%)]	Loss: 0.063723 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.9697 & F1 0.9846
01/27/2023 11:43:19 PM  [*] Fri Jan 27 23:43:19 2023: Train Epoch: 3 [64000/76126 (84%)]	Loss: 0.042544 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.9733 & F1 0.9865
01/27/2023 11:43:25 PM  [*] Fri Jan 27 23:43:25 2023: Train Epoch: 3 [70400/76126 (92%)]	Loss: 0.108813 | Elapsed: 6.27s | FPR 0.0003 -> TPR 0.8983 & F1 0.9464
01/27/2023 11:43:32 PM  [*] Fri Jan 27 23:43:32 2023:    3    | Tr.loss: 0.103678 | Elapsed:   75.86  s | FPR 0.0003 -> TPR: 0.55 & F1: 0.71 | AUC: 0.9925
01/27/2023 11:43:33 PM [!] Fri Jan 27 23:43:33 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_full_data\training_files\1674859412-model.torch
		train time: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_full_data\training_files\1674859412-trainTime.npy
		train losses: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_full_data\training_files\1674859412-trainLosses.npy
		train AUC: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_full_data\training_files\1674859412-auc.npy
		train F1s : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_full_data\training_files\1674859412-trainF1s.npy
		train TPRs: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_full_data\training_files\1674859412-trainTPRs.npy
01/27/2023 11:43:33 PM  [*] Evaluating pretrained model on test set...
01/27/2023 11:43:38 PM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0934 | F1: 0.1708
01/27/2023 11:43:38 PM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1830 | F1: 0.3094
01/27/2023 11:43:38 PM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.3498 | F1: 0.5180
01/27/2023 11:43:38 PM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3913 | F1: 0.5614
01/27/2023 11:43:38 PM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.5104 | F1: 0.6720
01/27/2023 11:43:38 PM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.6263 | F1: 0.7583
01/27/2023 11:43:38 PM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.7869 | F1: 0.8407
01/27/2023 11:43:38 PM  [*] Evaluating non_pretrained model on test set...
01/27/2023 11:43:43 PM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0182 | F1: 0.0357
01/27/2023 11:43:43 PM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1121 | F1: 0.2015
01/27/2023 11:43:43 PM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.2419 | F1: 0.3894
01/27/2023 11:43:43 PM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.2927 | F1: 0.4519
01/27/2023 11:43:43 PM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3600 | F1: 0.5262
01/27/2023 11:43:43 PM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4823 | F1: 0.6397
01/27/2023 11:43:43 PM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.7072 | F1: 0.7892
01/27/2023 11:43:43 PM  [*] Evaluating full_data model on test set...
01/27/2023 11:43:48 PM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.1824 | F1: 0.3085
01/27/2023 11:43:48 PM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.3638 | F1: 0.5334
01/27/2023 11:43:48 PM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.4076 | F1: 0.5788
01/27/2023 11:43:48 PM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.4490 | F1: 0.6187
01/27/2023 11:43:48 PM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.5688 | F1: 0.7212
01/27/2023 11:43:48 PM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.6415 | F1: 0.7696
01/27/2023 11:43:48 PM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.8697 | F1: 0.8898
01/27/2023 11:43:48 PM  [!] Running pre-training split 2/3
01/27/2023 11:43:51 PM  [!] Pre-training model...
01/27/2023 11:43:51 PM  [*] Masking sequences...
01/27/2023 11:44:10 PM  [*] Started epoch: 1
01/27/2023 11:44:11 PM  [*] Fri Jan 27 23:44:11 2023: Train Epoch: 1 [  0  /60900 (0 %)]	Loss: 460.083282 | Elapsed: 0.82s
01/27/2023 11:44:23 PM  [*] Fri Jan 27 23:44:23 2023: Train Epoch: 1 [6400 /60900 (11%)]	Loss: 235.587280 | Elapsed: 12.20s
01/27/2023 11:44:36 PM  [*] Fri Jan 27 23:44:36 2023: Train Epoch: 1 [12800/60900 (21%)]	Loss: 213.640823 | Elapsed: 12.26s
01/27/2023 11:44:48 PM  [*] Fri Jan 27 23:44:48 2023: Train Epoch: 1 [19200/60900 (32%)]	Loss: 192.539276 | Elapsed: 12.25s
01/27/2023 11:45:00 PM  [*] Fri Jan 27 23:45:00 2023: Train Epoch: 1 [25600/60900 (42%)]	Loss: 177.869598 | Elapsed: 12.36s
01/27/2023 11:45:13 PM  [*] Fri Jan 27 23:45:13 2023: Train Epoch: 1 [32000/60900 (53%)]	Loss: 206.769470 | Elapsed: 12.29s
01/27/2023 11:45:25 PM  [*] Fri Jan 27 23:45:25 2023: Train Epoch: 1 [38400/60900 (63%)]	Loss: 218.364075 | Elapsed: 12.34s
01/27/2023 11:45:37 PM  [*] Fri Jan 27 23:45:37 2023: Train Epoch: 1 [44800/60900 (74%)]	Loss: 174.290253 | Elapsed: 12.30s
01/27/2023 11:45:50 PM  [*] Fri Jan 27 23:45:50 2023: Train Epoch: 1 [51200/60900 (84%)]	Loss: 189.343109 | Elapsed: 12.33s
01/27/2023 11:46:02 PM  [*] Fri Jan 27 23:46:02 2023: Train Epoch: 1 [57600/60900 (95%)]	Loss: 191.189590 | Elapsed: 12.42s
01/27/2023 11:46:11 PM  [*] Fri Jan 27 23:46:11 2023:    1    | Tr.loss: 207.486983 | Elapsed:  120.50  s
01/27/2023 11:46:11 PM [!] Fri Jan 27 23:46:11 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_1_1674859571-model.torch
01/27/2023 11:46:11 PM  [*] Started epoch: 2
01/27/2023 11:46:12 PM  [*] Fri Jan 27 23:46:12 2023: Train Epoch: 2 [  0  /60900 (0 %)]	Loss: 185.659943 | Elapsed: 0.17s
01/27/2023 11:46:24 PM  [*] Fri Jan 27 23:46:24 2023: Train Epoch: 2 [6400 /60900 (11%)]	Loss: 182.041656 | Elapsed: 12.27s
01/27/2023 11:46:36 PM  [*] Fri Jan 27 23:46:36 2023: Train Epoch: 2 [12800/60900 (21%)]	Loss: 182.773163 | Elapsed: 12.32s
01/27/2023 11:46:48 PM  [*] Fri Jan 27 23:46:48 2023: Train Epoch: 2 [19200/60900 (32%)]	Loss: 198.225403 | Elapsed: 12.26s
01/27/2023 11:47:01 PM  [*] Fri Jan 27 23:47:01 2023: Train Epoch: 2 [25600/60900 (42%)]	Loss: 193.639999 | Elapsed: 12.31s
01/27/2023 11:47:13 PM  [*] Fri Jan 27 23:47:13 2023: Train Epoch: 2 [32000/60900 (53%)]	Loss: 184.536438 | Elapsed: 12.31s
01/27/2023 11:47:25 PM  [*] Fri Jan 27 23:47:25 2023: Train Epoch: 2 [38400/60900 (63%)]	Loss: 188.481934 | Elapsed: 12.32s
01/27/2023 11:47:38 PM  [*] Fri Jan 27 23:47:38 2023: Train Epoch: 2 [44800/60900 (74%)]	Loss: 191.661011 | Elapsed: 12.30s
01/27/2023 11:47:50 PM  [*] Fri Jan 27 23:47:50 2023: Train Epoch: 2 [51200/60900 (84%)]	Loss: 195.172272 | Elapsed: 12.38s
01/27/2023 11:48:02 PM  [*] Fri Jan 27 23:48:02 2023: Train Epoch: 2 [57600/60900 (95%)]	Loss: 183.408417 | Elapsed: 12.25s
01/27/2023 11:48:11 PM  [*] Fri Jan 27 23:48:11 2023:    2    | Tr.loss: 185.708580 | Elapsed:  119.76  s
01/27/2023 11:48:12 PM [!] Fri Jan 27 23:48:12 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_2_1674859691-model.torch
01/27/2023 11:48:12 PM  [*] Started epoch: 3
01/27/2023 11:48:12 PM  [*] Fri Jan 27 23:48:12 2023: Train Epoch: 3 [  0  /60900 (0 %)]	Loss: 162.668945 | Elapsed: 0.36s
01/27/2023 11:48:24 PM  [*] Fri Jan 27 23:48:24 2023: Train Epoch: 3 [6400 /60900 (11%)]	Loss: 159.666901 | Elapsed: 12.28s
01/27/2023 11:48:37 PM  [*] Fri Jan 27 23:48:37 2023: Train Epoch: 3 [12800/60900 (21%)]	Loss: 196.448975 | Elapsed: 12.31s
01/27/2023 11:48:49 PM  [*] Fri Jan 27 23:48:49 2023: Train Epoch: 3 [19200/60900 (32%)]	Loss: 187.274124 | Elapsed: 12.28s
01/27/2023 11:49:01 PM  [*] Fri Jan 27 23:49:01 2023: Train Epoch: 3 [25600/60900 (42%)]	Loss: 184.181244 | Elapsed: 12.27s
01/27/2023 11:49:13 PM  [*] Fri Jan 27 23:49:13 2023: Train Epoch: 3 [32000/60900 (53%)]	Loss: 171.436523 | Elapsed: 12.28s
01/27/2023 11:49:26 PM  [*] Fri Jan 27 23:49:26 2023: Train Epoch: 3 [38400/60900 (63%)]	Loss: 173.435364 | Elapsed: 12.35s
01/27/2023 11:49:38 PM  [*] Fri Jan 27 23:49:38 2023: Train Epoch: 3 [44800/60900 (74%)]	Loss: 176.467651 | Elapsed: 12.33s
01/27/2023 11:49:50 PM  [*] Fri Jan 27 23:49:50 2023: Train Epoch: 3 [51200/60900 (84%)]	Loss: 159.071243 | Elapsed: 12.24s
01/27/2023 11:50:03 PM  [*] Fri Jan 27 23:50:03 2023: Train Epoch: 3 [57600/60900 (95%)]	Loss: 197.165863 | Elapsed: 12.30s
01/27/2023 11:50:11 PM  [*] Fri Jan 27 23:50:11 2023:    3    | Tr.loss: 180.388583 | Elapsed:  119.84  s
01/27/2023 11:50:12 PM [!] Fri Jan 27 23:50:12 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_3_1674859811-model.torch
01/27/2023 11:50:12 PM  [*] Started epoch: 4
01/27/2023 11:50:12 PM  [*] Fri Jan 27 23:50:12 2023: Train Epoch: 4 [  0  /60900 (0 %)]	Loss: 192.838013 | Elapsed: 0.23s
01/27/2023 11:50:25 PM  [*] Fri Jan 27 23:50:25 2023: Train Epoch: 4 [6400 /60900 (11%)]	Loss: 200.319794 | Elapsed: 12.48s
01/27/2023 11:50:37 PM  [*] Fri Jan 27 23:50:37 2023: Train Epoch: 4 [12800/60900 (21%)]	Loss: 187.388763 | Elapsed: 12.39s
01/27/2023 11:50:49 PM  [*] Fri Jan 27 23:50:49 2023: Train Epoch: 4 [19200/60900 (32%)]	Loss: 163.614929 | Elapsed: 12.40s
01/27/2023 11:51:02 PM  [*] Fri Jan 27 23:51:02 2023: Train Epoch: 4 [25600/60900 (42%)]	Loss: 174.418884 | Elapsed: 12.38s
01/27/2023 11:51:14 PM  [*] Fri Jan 27 23:51:14 2023: Train Epoch: 4 [32000/60900 (53%)]	Loss: 192.275543 | Elapsed: 12.40s
01/27/2023 11:51:27 PM  [*] Fri Jan 27 23:51:27 2023: Train Epoch: 4 [38400/60900 (63%)]	Loss: 147.901657 | Elapsed: 12.30s
01/27/2023 11:51:39 PM  [*] Fri Jan 27 23:51:39 2023: Train Epoch: 4 [44800/60900 (74%)]	Loss: 195.192413 | Elapsed: 12.42s
01/27/2023 11:51:51 PM  [*] Fri Jan 27 23:51:51 2023: Train Epoch: 4 [51200/60900 (84%)]	Loss: 168.351440 | Elapsed: 12.24s
01/27/2023 11:52:04 PM  [*] Fri Jan 27 23:52:04 2023: Train Epoch: 4 [57600/60900 (95%)]	Loss: 186.817795 | Elapsed: 12.35s
01/27/2023 11:52:12 PM  [*] Fri Jan 27 23:52:12 2023:    4    | Tr.loss: 177.654361 | Elapsed:  120.48  s
01/27/2023 11:52:13 PM [!] Fri Jan 27 23:52:13 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_4_1674859932-model.torch
01/27/2023 11:52:13 PM  [*] Started epoch: 5
01/27/2023 11:52:13 PM  [*] Fri Jan 27 23:52:13 2023: Train Epoch: 5 [  0  /60900 (0 %)]	Loss: 184.248886 | Elapsed: 0.24s
01/27/2023 11:52:26 PM  [*] Fri Jan 27 23:52:26 2023: Train Epoch: 5 [6400 /60900 (11%)]	Loss: 188.994080 | Elapsed: 12.38s
01/27/2023 11:52:38 PM  [*] Fri Jan 27 23:52:38 2023: Train Epoch: 5 [12800/60900 (21%)]	Loss: 157.171021 | Elapsed: 12.23s
01/27/2023 11:52:50 PM  [*] Fri Jan 27 23:52:50 2023: Train Epoch: 5 [19200/60900 (32%)]	Loss: 160.094635 | Elapsed: 12.34s
01/27/2023 11:53:02 PM  [*] Fri Jan 27 23:53:02 2023: Train Epoch: 5 [25600/60900 (42%)]	Loss: 189.674652 | Elapsed: 12.37s
01/27/2023 11:53:15 PM  [*] Fri Jan 27 23:53:15 2023: Train Epoch: 5 [32000/60900 (53%)]	Loss: 178.702591 | Elapsed: 12.29s
01/27/2023 11:53:27 PM  [*] Fri Jan 27 23:53:27 2023: Train Epoch: 5 [38400/60900 (63%)]	Loss: 185.894272 | Elapsed: 12.49s
01/27/2023 11:53:40 PM  [*] Fri Jan 27 23:53:40 2023: Train Epoch: 5 [44800/60900 (74%)]	Loss: 171.222305 | Elapsed: 12.42s
01/27/2023 11:53:52 PM  [*] Fri Jan 27 23:53:52 2023: Train Epoch: 5 [51200/60900 (84%)]	Loss: 179.705688 | Elapsed: 12.26s
01/27/2023 11:54:04 PM  [*] Fri Jan 27 23:54:04 2023: Train Epoch: 5 [57600/60900 (95%)]	Loss: 163.506989 | Elapsed: 12.38s
01/27/2023 11:54:12 PM  [*] Fri Jan 27 23:54:12 2023:    5    | Tr.loss: 175.792857 | Elapsed:  119.50  s
01/27/2023 11:54:13 PM [!] Fri Jan 27 23:54:13 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_5_1674860052-model.torch
01/27/2023 11:54:13 PM  [*] Started epoch: 6
01/27/2023 11:54:13 PM  [*] Fri Jan 27 23:54:13 2023: Train Epoch: 6 [  0  /60900 (0 %)]	Loss: 169.210144 | Elapsed: 0.17s
01/27/2023 11:54:25 PM  [*] Fri Jan 27 23:54:25 2023: Train Epoch: 6 [6400 /60900 (11%)]	Loss: 163.984772 | Elapsed: 12.35s
01/27/2023 11:54:38 PM  [*] Fri Jan 27 23:54:38 2023: Train Epoch: 6 [12800/60900 (21%)]	Loss: 164.443542 | Elapsed: 12.26s
01/27/2023 11:54:50 PM  [*] Fri Jan 27 23:54:50 2023: Train Epoch: 6 [19200/60900 (32%)]	Loss: 180.210892 | Elapsed: 12.27s
01/27/2023 11:55:02 PM  [*] Fri Jan 27 23:55:02 2023: Train Epoch: 6 [25600/60900 (42%)]	Loss: 174.662201 | Elapsed: 12.27s
01/27/2023 11:55:14 PM  [*] Fri Jan 27 23:55:14 2023: Train Epoch: 6 [32000/60900 (53%)]	Loss: 186.729248 | Elapsed: 12.30s
01/27/2023 11:55:27 PM  [*] Fri Jan 27 23:55:27 2023: Train Epoch: 6 [38400/60900 (63%)]	Loss: 182.847290 | Elapsed: 12.28s
01/27/2023 11:55:39 PM  [*] Fri Jan 27 23:55:39 2023: Train Epoch: 6 [44800/60900 (74%)]	Loss: 169.305054 | Elapsed: 12.42s
01/27/2023 11:55:51 PM  [*] Fri Jan 27 23:55:51 2023: Train Epoch: 6 [51200/60900 (84%)]	Loss: 160.586624 | Elapsed: 12.31s
01/27/2023 11:56:04 PM  [*] Fri Jan 27 23:56:04 2023: Train Epoch: 6 [57600/60900 (95%)]	Loss: 186.936234 | Elapsed: 12.29s
01/27/2023 11:56:12 PM  [*] Fri Jan 27 23:56:12 2023:    6    | Tr.loss: 174.434169 | Elapsed:  119.01  s
01/27/2023 11:56:12 PM [!] Fri Jan 27 23:56:12 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_6_1674860172-model.torch
01/27/2023 11:56:12 PM  [*] Started epoch: 7
01/27/2023 11:56:13 PM  [*] Fri Jan 27 23:56:13 2023: Train Epoch: 7 [  0  /60900 (0 %)]	Loss: 186.616211 | Elapsed: 0.23s
01/27/2023 11:56:25 PM  [*] Fri Jan 27 23:56:25 2023: Train Epoch: 7 [6400 /60900 (11%)]	Loss: 183.886703 | Elapsed: 12.30s
01/27/2023 11:56:37 PM  [*] Fri Jan 27 23:56:37 2023: Train Epoch: 7 [12800/60900 (21%)]	Loss: 143.113403 | Elapsed: 12.29s
01/27/2023 11:56:50 PM  [*] Fri Jan 27 23:56:50 2023: Train Epoch: 7 [19200/60900 (32%)]	Loss: 162.004211 | Elapsed: 12.39s
01/27/2023 11:57:02 PM  [*] Fri Jan 27 23:57:02 2023: Train Epoch: 7 [25600/60900 (42%)]	Loss: 170.741302 | Elapsed: 12.41s
01/27/2023 11:57:14 PM  [*] Fri Jan 27 23:57:14 2023: Train Epoch: 7 [32000/60900 (53%)]	Loss: 192.504944 | Elapsed: 12.53s
01/27/2023 11:57:27 PM  [*] Fri Jan 27 23:57:27 2023: Train Epoch: 7 [38400/60900 (63%)]	Loss: 189.116302 | Elapsed: 12.46s
01/27/2023 11:57:39 PM  [*] Fri Jan 27 23:57:39 2023: Train Epoch: 7 [44800/60900 (74%)]	Loss: 174.005981 | Elapsed: 12.48s
01/27/2023 11:57:52 PM  [*] Fri Jan 27 23:57:52 2023: Train Epoch: 7 [51200/60900 (84%)]	Loss: 182.894348 | Elapsed: 12.49s
01/27/2023 11:58:04 PM  [*] Fri Jan 27 23:58:04 2023: Train Epoch: 7 [57600/60900 (95%)]	Loss: 166.204803 | Elapsed: 12.46s
01/27/2023 11:58:13 PM  [*] Fri Jan 27 23:58:13 2023:    7    | Tr.loss: 173.446705 | Elapsed:  120.32  s
01/27/2023 11:58:13 PM [!] Fri Jan 27 23:58:13 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_7_1674860293-model.torch
01/27/2023 11:58:13 PM  [*] Started epoch: 8
01/27/2023 11:58:13 PM  [*] Fri Jan 27 23:58:13 2023: Train Epoch: 8 [  0  /60900 (0 %)]	Loss: 194.869858 | Elapsed: 0.35s
01/27/2023 11:58:26 PM  [*] Fri Jan 27 23:58:26 2023: Train Epoch: 8 [6400 /60900 (11%)]	Loss: 196.471390 | Elapsed: 12.51s
01/27/2023 11:58:38 PM  [*] Fri Jan 27 23:58:38 2023: Train Epoch: 8 [12800/60900 (21%)]	Loss: 169.628784 | Elapsed: 12.49s
01/27/2023 11:58:51 PM  [*] Fri Jan 27 23:58:51 2023: Train Epoch: 8 [19200/60900 (32%)]	Loss: 187.401688 | Elapsed: 12.53s
01/27/2023 11:59:04 PM  [*] Fri Jan 27 23:59:04 2023: Train Epoch: 8 [25600/60900 (42%)]	Loss: 180.127838 | Elapsed: 12.51s
01/27/2023 11:59:16 PM  [*] Fri Jan 27 23:59:16 2023: Train Epoch: 8 [32000/60900 (53%)]	Loss: 166.091507 | Elapsed: 12.41s
01/27/2023 11:59:28 PM  [*] Fri Jan 27 23:59:28 2023: Train Epoch: 8 [38400/60900 (63%)]	Loss: 167.342926 | Elapsed: 12.54s
01/27/2023 11:59:41 PM  [*] Fri Jan 27 23:59:41 2023: Train Epoch: 8 [44800/60900 (74%)]	Loss: 179.860138 | Elapsed: 12.48s
01/27/2023 11:59:53 PM  [*] Fri Jan 27 23:59:53 2023: Train Epoch: 8 [51200/60900 (84%)]	Loss: 173.549606 | Elapsed: 12.53s
01/28/2023 12:00:06 AM  [*] Sat Jan 28 00:00:06 2023: Train Epoch: 8 [57600/60900 (95%)]	Loss: 189.718140 | Elapsed: 12.53s
01/28/2023 12:00:14 AM  [*] Sat Jan 28 00:00:14 2023:    8    | Tr.loss: 172.569600 | Elapsed:  121.15  s
01/28/2023 12:00:15 AM [!] Sat Jan 28 00:00:15 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_8_1674860414-model.torch
01/28/2023 12:00:15 AM  [*] Started epoch: 9
01/28/2023 12:00:15 AM  [*] Sat Jan 28 00:00:15 2023: Train Epoch: 9 [  0  /60900 (0 %)]	Loss: 176.579102 | Elapsed: 0.24s
01/28/2023 12:00:28 AM  [*] Sat Jan 28 00:00:28 2023: Train Epoch: 9 [6400 /60900 (11%)]	Loss: 175.880829 | Elapsed: 12.57s
01/28/2023 12:00:40 AM  [*] Sat Jan 28 00:00:40 2023: Train Epoch: 9 [12800/60900 (21%)]	Loss: 150.153442 | Elapsed: 12.51s
01/28/2023 12:00:53 AM  [*] Sat Jan 28 00:00:53 2023: Train Epoch: 9 [19200/60900 (32%)]	Loss: 169.125427 | Elapsed: 12.43s
01/28/2023 12:01:05 AM  [*] Sat Jan 28 00:01:05 2023: Train Epoch: 9 [25600/60900 (42%)]	Loss: 157.031265 | Elapsed: 12.68s
01/28/2023 12:01:18 AM  [*] Sat Jan 28 00:01:18 2023: Train Epoch: 9 [32000/60900 (53%)]	Loss: 173.570160 | Elapsed: 12.41s
01/28/2023 12:01:30 AM  [*] Sat Jan 28 00:01:30 2023: Train Epoch: 9 [38400/60900 (63%)]	Loss: 188.372604 | Elapsed: 12.43s
01/28/2023 12:01:42 AM  [*] Sat Jan 28 00:01:42 2023: Train Epoch: 9 [44800/60900 (74%)]	Loss: 162.784439 | Elapsed: 12.41s
01/28/2023 12:01:55 AM  [*] Sat Jan 28 00:01:55 2023: Train Epoch: 9 [51200/60900 (84%)]	Loss: 151.253418 | Elapsed: 12.41s
01/28/2023 12:02:07 AM  [*] Sat Jan 28 00:02:07 2023: Train Epoch: 9 [57600/60900 (95%)]	Loss: 159.015045 | Elapsed: 12.51s
01/28/2023 12:02:16 AM  [*] Sat Jan 28 00:02:16 2023:    9    | Tr.loss: 171.874952 | Elapsed:  120.82  s
01/28/2023 12:02:16 AM [!] Sat Jan 28 00:02:16 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_9_1674860536-model.torch
01/28/2023 12:02:16 AM  [*] Started epoch: 10
01/28/2023 12:02:16 AM  [*] Sat Jan 28 00:02:16 2023: Train Epoch: 10 [  0  /60900 (0 %)]	Loss: 169.612152 | Elapsed: 0.34s
01/28/2023 12:02:29 AM  [*] Sat Jan 28 00:02:29 2023: Train Epoch: 10 [6400 /60900 (11%)]	Loss: 165.914948 | Elapsed: 12.45s
01/28/2023 12:02:41 AM  [*] Sat Jan 28 00:02:41 2023: Train Epoch: 10 [12800/60900 (21%)]	Loss: 160.055939 | Elapsed: 12.53s
01/28/2023 12:02:54 AM  [*] Sat Jan 28 00:02:54 2023: Train Epoch: 10 [19200/60900 (32%)]	Loss: 168.443695 | Elapsed: 12.61s
01/28/2023 12:03:07 AM  [*] Sat Jan 28 00:03:07 2023: Train Epoch: 10 [25600/60900 (42%)]	Loss: 165.945694 | Elapsed: 12.62s
01/28/2023 12:03:19 AM  [*] Sat Jan 28 00:03:19 2023: Train Epoch: 10 [32000/60900 (53%)]	Loss: 180.959198 | Elapsed: 12.45s
01/28/2023 12:03:32 AM  [*] Sat Jan 28 00:03:32 2023: Train Epoch: 10 [38400/60900 (63%)]	Loss: 166.280090 | Elapsed: 12.51s
01/28/2023 12:03:44 AM  [*] Sat Jan 28 00:03:44 2023: Train Epoch: 10 [44800/60900 (74%)]	Loss: 179.786072 | Elapsed: 12.60s
01/28/2023 12:03:57 AM  [*] Sat Jan 28 00:03:57 2023: Train Epoch: 10 [51200/60900 (84%)]	Loss: 180.634155 | Elapsed: 12.43s
01/28/2023 12:04:09 AM  [*] Sat Jan 28 00:04:09 2023: Train Epoch: 10 [57600/60900 (95%)]	Loss: 170.556808 | Elapsed: 12.52s
01/28/2023 12:04:17 AM  [*] Sat Jan 28 00:04:17 2023:   10    | Tr.loss: 171.199415 | Elapsed:  121.33  s
01/28/2023 12:04:18 AM [!] Sat Jan 28 00:04:18 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_10_1674860657-model.torch
01/28/2023 12:04:18 AM  [*] Started epoch: 11
01/28/2023 12:04:18 AM  [*] Sat Jan 28 00:04:18 2023: Train Epoch: 11 [  0  /60900 (0 %)]	Loss: 185.528595 | Elapsed: 0.30s
01/28/2023 12:04:31 AM  [*] Sat Jan 28 00:04:31 2023: Train Epoch: 11 [6400 /60900 (11%)]	Loss: 163.009674 | Elapsed: 12.59s
01/28/2023 12:04:43 AM  [*] Sat Jan 28 00:04:43 2023: Train Epoch: 11 [12800/60900 (21%)]	Loss: 184.425766 | Elapsed: 12.43s
01/28/2023 12:04:56 AM  [*] Sat Jan 28 00:04:56 2023: Train Epoch: 11 [19200/60900 (32%)]	Loss: 188.183990 | Elapsed: 12.63s
01/28/2023 12:05:08 AM  [*] Sat Jan 28 00:05:08 2023: Train Epoch: 11 [25600/60900 (42%)]	Loss: 172.601379 | Elapsed: 12.51s
01/28/2023 12:05:18 AM [!] Learning rate: 2.5e-05
01/28/2023 12:05:21 AM  [*] Sat Jan 28 00:05:21 2023: Train Epoch: 11 [32000/60900 (53%)]	Loss: 157.922546 | Elapsed: 12.55s
01/28/2023 12:05:33 AM  [*] Sat Jan 28 00:05:33 2023: Train Epoch: 11 [38400/60900 (63%)]	Loss: 171.743439 | Elapsed: 12.46s
01/28/2023 12:05:46 AM  [*] Sat Jan 28 00:05:46 2023: Train Epoch: 11 [44800/60900 (74%)]	Loss: 178.759277 | Elapsed: 12.49s
01/28/2023 12:05:58 AM  [*] Sat Jan 28 00:05:58 2023: Train Epoch: 11 [51200/60900 (84%)]	Loss: 166.949097 | Elapsed: 12.37s
01/28/2023 12:06:11 AM  [*] Sat Jan 28 00:06:11 2023: Train Epoch: 11 [57600/60900 (95%)]	Loss: 162.386230 | Elapsed: 12.49s
01/28/2023 12:06:19 AM  [*] Sat Jan 28 00:06:19 2023:   11    | Tr.loss: 170.567705 | Elapsed:  121.28  s
01/28/2023 12:06:20 AM [!] Sat Jan 28 00:06:20 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_11_1674860779-model.torch
01/28/2023 12:06:20 AM  [*] Started epoch: 12
01/28/2023 12:06:20 AM  [*] Sat Jan 28 00:06:20 2023: Train Epoch: 12 [  0  /60900 (0 %)]	Loss: 179.925018 | Elapsed: 0.29s
01/28/2023 12:06:33 AM  [*] Sat Jan 28 00:06:33 2023: Train Epoch: 12 [6400 /60900 (11%)]	Loss: 182.212585 | Elapsed: 12.59s
01/28/2023 12:06:45 AM  [*] Sat Jan 28 00:06:45 2023: Train Epoch: 12 [12800/60900 (21%)]	Loss: 157.926514 | Elapsed: 12.52s
01/28/2023 12:06:58 AM  [*] Sat Jan 28 00:06:58 2023: Train Epoch: 12 [19200/60900 (32%)]	Loss: 160.534286 | Elapsed: 12.60s
01/28/2023 12:07:10 AM  [*] Sat Jan 28 00:07:10 2023: Train Epoch: 12 [25600/60900 (42%)]	Loss: 165.619186 | Elapsed: 12.51s
01/28/2023 12:07:23 AM  [*] Sat Jan 28 00:07:23 2023: Train Epoch: 12 [32000/60900 (53%)]	Loss: 195.627487 | Elapsed: 12.48s
01/28/2023 12:07:35 AM  [*] Sat Jan 28 00:07:35 2023: Train Epoch: 12 [38400/60900 (63%)]	Loss: 174.357620 | Elapsed: 12.48s
01/28/2023 12:07:48 AM  [*] Sat Jan 28 00:07:48 2023: Train Epoch: 12 [44800/60900 (74%)]	Loss: 146.510361 | Elapsed: 12.40s
01/28/2023 12:08:00 AM  [*] Sat Jan 28 00:08:00 2023: Train Epoch: 12 [51200/60900 (84%)]	Loss: 182.697327 | Elapsed: 12.61s
01/28/2023 12:08:13 AM  [*] Sat Jan 28 00:08:13 2023: Train Epoch: 12 [57600/60900 (95%)]	Loss: 173.708649 | Elapsed: 12.50s
01/28/2023 12:08:21 AM  [*] Sat Jan 28 00:08:21 2023:   12    | Tr.loss: 169.911461 | Elapsed:  121.24  s
01/28/2023 12:08:21 AM [!] Sat Jan 28 00:08:21 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_12_1674860901-model.torch
01/28/2023 12:08:21 AM  [*] Started epoch: 13
01/28/2023 12:08:22 AM  [*] Sat Jan 28 00:08:22 2023: Train Epoch: 13 [  0  /60900 (0 %)]	Loss: 156.168518 | Elapsed: 0.27s
01/28/2023 12:08:34 AM  [*] Sat Jan 28 00:08:34 2023: Train Epoch: 13 [6400 /60900 (11%)]	Loss: 164.519012 | Elapsed: 12.50s
01/28/2023 12:08:47 AM  [*] Sat Jan 28 00:08:47 2023: Train Epoch: 13 [12800/60900 (21%)]	Loss: 169.203339 | Elapsed: 12.54s
01/28/2023 12:08:59 AM  [*] Sat Jan 28 00:08:59 2023: Train Epoch: 13 [19200/60900 (32%)]	Loss: 177.929291 | Elapsed: 12.43s
01/28/2023 12:09:12 AM  [*] Sat Jan 28 00:09:12 2023: Train Epoch: 13 [25600/60900 (42%)]	Loss: 158.297302 | Elapsed: 12.60s
01/28/2023 12:09:24 AM  [*] Sat Jan 28 00:09:24 2023: Train Epoch: 13 [32000/60900 (53%)]	Loss: 186.898849 | Elapsed: 12.47s
01/28/2023 12:09:37 AM  [*] Sat Jan 28 00:09:37 2023: Train Epoch: 13 [38400/60900 (63%)]	Loss: 170.266617 | Elapsed: 12.41s
01/28/2023 12:09:49 AM  [*] Sat Jan 28 00:09:49 2023: Train Epoch: 13 [44800/60900 (74%)]	Loss: 159.732086 | Elapsed: 12.41s
01/28/2023 12:10:02 AM  [*] Sat Jan 28 00:10:02 2023: Train Epoch: 13 [51200/60900 (84%)]	Loss: 163.641068 | Elapsed: 12.60s
01/28/2023 12:10:14 AM  [*] Sat Jan 28 00:10:14 2023: Train Epoch: 13 [57600/60900 (95%)]	Loss: 151.770782 | Elapsed: 12.44s
01/28/2023 12:10:22 AM  [*] Sat Jan 28 00:10:22 2023:   13    | Tr.loss: 169.808169 | Elapsed:  121.12  s
01/28/2023 12:10:23 AM [!] Sat Jan 28 00:10:23 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_13_1674861022-model.torch
01/28/2023 12:10:23 AM  [*] Started epoch: 14
01/28/2023 12:10:23 AM  [*] Sat Jan 28 00:10:23 2023: Train Epoch: 14 [  0  /60900 (0 %)]	Loss: 163.498260 | Elapsed: 0.35s
01/28/2023 12:10:36 AM  [*] Sat Jan 28 00:10:36 2023: Train Epoch: 14 [6400 /60900 (11%)]	Loss: 169.598419 | Elapsed: 12.64s
01/28/2023 12:10:48 AM  [*] Sat Jan 28 00:10:48 2023: Train Epoch: 14 [12800/60900 (21%)]	Loss: 190.265808 | Elapsed: 12.46s
01/28/2023 12:11:01 AM  [*] Sat Jan 28 00:11:01 2023: Train Epoch: 14 [19200/60900 (32%)]	Loss: 165.028442 | Elapsed: 12.64s
01/28/2023 12:11:14 AM  [*] Sat Jan 28 00:11:14 2023: Train Epoch: 14 [25600/60900 (42%)]	Loss: 148.799194 | Elapsed: 12.50s
01/28/2023 12:11:26 AM  [*] Sat Jan 28 00:11:26 2023: Train Epoch: 14 [32000/60900 (53%)]	Loss: 178.941452 | Elapsed: 12.48s
01/28/2023 12:11:39 AM  [*] Sat Jan 28 00:11:39 2023: Train Epoch: 14 [38400/60900 (63%)]	Loss: 165.044876 | Elapsed: 12.49s
01/28/2023 12:11:51 AM  [*] Sat Jan 28 00:11:51 2023: Train Epoch: 14 [44800/60900 (74%)]	Loss: 159.295547 | Elapsed: 12.49s
01/28/2023 12:12:04 AM  [*] Sat Jan 28 00:12:04 2023: Train Epoch: 14 [51200/60900 (84%)]	Loss: 179.996506 | Elapsed: 12.49s
01/28/2023 12:12:16 AM  [*] Sat Jan 28 00:12:16 2023: Train Epoch: 14 [57600/60900 (95%)]	Loss: 166.883011 | Elapsed: 12.57s
01/28/2023 12:12:24 AM  [*] Sat Jan 28 00:12:24 2023:   14    | Tr.loss: 169.613317 | Elapsed:  121.34  s
01/28/2023 12:12:25 AM [!] Sat Jan 28 00:12:25 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_14_1674861144-model.torch
01/28/2023 12:12:25 AM  [*] Started epoch: 15
01/28/2023 12:12:25 AM  [*] Sat Jan 28 00:12:25 2023: Train Epoch: 15 [  0  /60900 (0 %)]	Loss: 170.940247 | Elapsed: 0.31s
01/28/2023 12:12:38 AM  [*] Sat Jan 28 00:12:38 2023: Train Epoch: 15 [6400 /60900 (11%)]	Loss: 171.999420 | Elapsed: 12.51s
01/28/2023 12:12:50 AM  [*] Sat Jan 28 00:12:50 2023: Train Epoch: 15 [12800/60900 (21%)]	Loss: 177.578506 | Elapsed: 12.43s
01/28/2023 12:13:03 AM  [*] Sat Jan 28 00:13:03 2023: Train Epoch: 15 [19200/60900 (32%)]	Loss: 159.110016 | Elapsed: 12.53s
01/28/2023 12:13:15 AM  [*] Sat Jan 28 00:13:15 2023: Train Epoch: 15 [25600/60900 (42%)]	Loss: 162.718628 | Elapsed: 12.50s
01/28/2023 12:13:28 AM  [*] Sat Jan 28 00:13:28 2023: Train Epoch: 15 [32000/60900 (53%)]	Loss: 192.296036 | Elapsed: 12.61s
01/28/2023 12:13:40 AM  [*] Sat Jan 28 00:13:40 2023: Train Epoch: 15 [38400/60900 (63%)]	Loss: 140.618835 | Elapsed: 12.40s
01/28/2023 12:13:53 AM  [*] Sat Jan 28 00:13:53 2023: Train Epoch: 15 [44800/60900 (74%)]	Loss: 165.010040 | Elapsed: 12.46s
01/28/2023 12:14:05 AM  [*] Sat Jan 28 00:14:05 2023: Train Epoch: 15 [51200/60900 (84%)]	Loss: 159.929718 | Elapsed: 12.41s
01/28/2023 12:14:18 AM  [*] Sat Jan 28 00:14:18 2023: Train Epoch: 15 [57600/60900 (95%)]	Loss: 164.022171 | Elapsed: 12.55s
01/28/2023 12:14:26 AM  [*] Sat Jan 28 00:14:26 2023:   15    | Tr.loss: 169.554972 | Elapsed:  121.02  s
01/28/2023 12:14:26 AM [!] Sat Jan 28 00:14:26 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_15_1674861266-model.torch
01/28/2023 12:14:26 AM  [*] Started epoch: 16
01/28/2023 12:14:27 AM  [*] Sat Jan 28 00:14:27 2023: Train Epoch: 16 [  0  /60900 (0 %)]	Loss: 176.484161 | Elapsed: 0.26s
01/28/2023 12:14:39 AM  [*] Sat Jan 28 00:14:39 2023: Train Epoch: 16 [6400 /60900 (11%)]	Loss: 154.078888 | Elapsed: 12.62s
01/28/2023 12:14:52 AM  [*] Sat Jan 28 00:14:52 2023: Train Epoch: 16 [12800/60900 (21%)]	Loss: 188.589813 | Elapsed: 12.40s
01/28/2023 12:15:04 AM  [*] Sat Jan 28 00:15:04 2023: Train Epoch: 16 [19200/60900 (32%)]	Loss: 162.867706 | Elapsed: 12.61s
01/28/2023 12:15:17 AM  [*] Sat Jan 28 00:15:17 2023: Train Epoch: 16 [25600/60900 (42%)]	Loss: 147.423401 | Elapsed: 12.38s
01/28/2023 12:15:29 AM  [*] Sat Jan 28 00:15:29 2023: Train Epoch: 16 [32000/60900 (53%)]	Loss: 149.703278 | Elapsed: 12.54s
01/28/2023 12:15:42 AM  [*] Sat Jan 28 00:15:42 2023: Train Epoch: 16 [38400/60900 (63%)]	Loss: 173.892532 | Elapsed: 12.44s
01/28/2023 12:15:54 AM  [*] Sat Jan 28 00:15:54 2023: Train Epoch: 16 [44800/60900 (74%)]	Loss: 150.446426 | Elapsed: 12.49s
01/28/2023 12:16:07 AM  [*] Sat Jan 28 00:16:07 2023: Train Epoch: 16 [51200/60900 (84%)]	Loss: 177.037033 | Elapsed: 12.58s
01/28/2023 12:16:19 AM  [*] Sat Jan 28 00:16:19 2023: Train Epoch: 16 [57600/60900 (95%)]	Loss: 178.775848 | Elapsed: 12.40s
01/28/2023 12:16:27 AM  [*] Sat Jan 28 00:16:27 2023:   16    | Tr.loss: 169.428939 | Elapsed:  121.05  s
01/28/2023 12:16:28 AM [!] Sat Jan 28 00:16:28 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_16_1674861387-model.torch
01/28/2023 12:16:28 AM  [*] Started epoch: 17
01/28/2023 12:16:28 AM  [*] Sat Jan 28 00:16:28 2023: Train Epoch: 17 [  0  /60900 (0 %)]	Loss: 175.266449 | Elapsed: 0.37s
01/28/2023 12:16:41 AM  [*] Sat Jan 28 00:16:41 2023: Train Epoch: 17 [6400 /60900 (11%)]	Loss: 164.712738 | Elapsed: 12.63s
01/28/2023 12:16:53 AM  [*] Sat Jan 28 00:16:53 2023: Train Epoch: 17 [12800/60900 (21%)]	Loss: 179.435760 | Elapsed: 12.59s
01/28/2023 12:17:06 AM  [*] Sat Jan 28 00:17:06 2023: Train Epoch: 17 [19200/60900 (32%)]	Loss: 173.514374 | Elapsed: 12.61s
01/28/2023 12:17:18 AM  [*] Sat Jan 28 00:17:18 2023: Train Epoch: 17 [25600/60900 (42%)]	Loss: 150.765167 | Elapsed: 12.46s
01/28/2023 12:17:31 AM  [*] Sat Jan 28 00:17:31 2023: Train Epoch: 17 [32000/60900 (53%)]	Loss: 180.972626 | Elapsed: 12.45s
01/28/2023 12:17:43 AM  [*] Sat Jan 28 00:17:43 2023: Train Epoch: 17 [38400/60900 (63%)]	Loss: 167.420303 | Elapsed: 12.48s
01/28/2023 12:17:56 AM  [*] Sat Jan 28 00:17:56 2023: Train Epoch: 17 [44800/60900 (74%)]	Loss: 158.850586 | Elapsed: 12.48s
01/28/2023 12:18:08 AM  [*] Sat Jan 28 00:18:08 2023: Train Epoch: 17 [51200/60900 (84%)]	Loss: 158.044434 | Elapsed: 12.56s
01/28/2023 12:18:21 AM  [*] Sat Jan 28 00:18:21 2023: Train Epoch: 17 [57600/60900 (95%)]	Loss: 184.000397 | Elapsed: 12.45s
01/28/2023 12:18:29 AM  [*] Sat Jan 28 00:18:29 2023:   17    | Tr.loss: 169.445643 | Elapsed:  121.45  s
01/28/2023 12:18:30 AM [!] Sat Jan 28 00:18:30 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_17_1674861509-model.torch
01/28/2023 12:18:30 AM  [*] Started epoch: 18
01/28/2023 12:18:30 AM  [*] Sat Jan 28 00:18:30 2023: Train Epoch: 18 [  0  /60900 (0 %)]	Loss: 159.089752 | Elapsed: 0.22s
01/28/2023 12:18:43 AM  [*] Sat Jan 28 00:18:43 2023: Train Epoch: 18 [6400 /60900 (11%)]	Loss: 175.680054 | Elapsed: 12.60s
01/28/2023 12:18:55 AM  [*] Sat Jan 28 00:18:55 2023: Train Epoch: 18 [12800/60900 (21%)]	Loss: 176.350540 | Elapsed: 12.54s
01/28/2023 12:19:08 AM  [*] Sat Jan 28 00:19:08 2023: Train Epoch: 18 [19200/60900 (32%)]	Loss: 177.307770 | Elapsed: 12.47s
01/28/2023 12:19:20 AM  [*] Sat Jan 28 00:19:20 2023: Train Epoch: 18 [25600/60900 (42%)]	Loss: 151.353180 | Elapsed: 12.51s
01/28/2023 12:19:33 AM  [*] Sat Jan 28 00:19:33 2023: Train Epoch: 18 [32000/60900 (53%)]	Loss: 174.761475 | Elapsed: 12.44s
01/28/2023 12:19:45 AM  [*] Sat Jan 28 00:19:45 2023: Train Epoch: 18 [38400/60900 (63%)]	Loss: 170.715530 | Elapsed: 12.48s
01/28/2023 12:19:57 AM  [*] Sat Jan 28 00:19:57 2023: Train Epoch: 18 [44800/60900 (74%)]	Loss: 142.639359 | Elapsed: 12.36s
01/28/2023 12:20:10 AM  [*] Sat Jan 28 00:20:10 2023: Train Epoch: 18 [51200/60900 (84%)]	Loss: 166.173553 | Elapsed: 12.44s
01/28/2023 12:20:22 AM  [*] Sat Jan 28 00:20:22 2023: Train Epoch: 18 [57600/60900 (95%)]	Loss: 171.303650 | Elapsed: 12.51s
01/28/2023 12:20:31 AM  [*] Sat Jan 28 00:20:31 2023:   18    | Tr.loss: 169.315001 | Elapsed:  120.96  s
01/28/2023 12:20:31 AM [!] Sat Jan 28 00:20:31 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_18_1674861631-model.torch
01/28/2023 12:20:31 AM  [*] Started epoch: 19
01/28/2023 12:20:32 AM  [*] Sat Jan 28 00:20:32 2023: Train Epoch: 19 [  0  /60900 (0 %)]	Loss: 169.206696 | Elapsed: 0.32s
01/28/2023 12:20:44 AM  [*] Sat Jan 28 00:20:44 2023: Train Epoch: 19 [6400 /60900 (11%)]	Loss: 152.833496 | Elapsed: 12.55s
01/28/2023 12:20:57 AM  [*] Sat Jan 28 00:20:57 2023: Train Epoch: 19 [12800/60900 (21%)]	Loss: 171.547668 | Elapsed: 12.48s
01/28/2023 12:21:09 AM  [*] Sat Jan 28 00:21:09 2023: Train Epoch: 19 [19200/60900 (32%)]	Loss: 167.542908 | Elapsed: 12.66s
01/28/2023 12:21:22 AM  [*] Sat Jan 28 00:21:22 2023: Train Epoch: 19 [25600/60900 (42%)]	Loss: 162.848190 | Elapsed: 12.49s
01/28/2023 12:21:34 AM  [*] Sat Jan 28 00:21:34 2023: Train Epoch: 19 [32000/60900 (53%)]	Loss: 164.482971 | Elapsed: 12.55s
01/28/2023 12:21:47 AM  [*] Sat Jan 28 00:21:47 2023: Train Epoch: 19 [38400/60900 (63%)]	Loss: 152.433472 | Elapsed: 12.42s
01/28/2023 12:21:59 AM  [*] Sat Jan 28 00:21:59 2023: Train Epoch: 19 [44800/60900 (74%)]	Loss: 159.429932 | Elapsed: 12.48s
01/28/2023 12:22:12 AM  [*] Sat Jan 28 00:22:12 2023: Train Epoch: 19 [51200/60900 (84%)]	Loss: 155.235199 | Elapsed: 12.55s
01/28/2023 12:22:24 AM  [*] Sat Jan 28 00:22:24 2023: Train Epoch: 19 [57600/60900 (95%)]	Loss: 161.514313 | Elapsed: 12.46s
01/28/2023 12:22:32 AM  [*] Sat Jan 28 00:22:32 2023:   19    | Tr.loss: 169.335825 | Elapsed:  121.22  s
01/28/2023 12:22:33 AM [!] Sat Jan 28 00:22:33 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_19_1674861752-model.torch
01/28/2023 12:22:33 AM  [*] Started epoch: 20
01/28/2023 12:22:33 AM  [*] Sat Jan 28 00:22:33 2023: Train Epoch: 20 [  0  /60900 (0 %)]	Loss: 183.579086 | Elapsed: 0.37s
01/28/2023 12:22:46 AM  [*] Sat Jan 28 00:22:46 2023: Train Epoch: 20 [6400 /60900 (11%)]	Loss: 186.152496 | Elapsed: 12.61s
01/28/2023 12:22:58 AM  [*] Sat Jan 28 00:22:58 2023: Train Epoch: 20 [12800/60900 (21%)]	Loss: 174.421600 | Elapsed: 12.46s
01/28/2023 12:23:11 AM  [*] Sat Jan 28 00:23:11 2023: Train Epoch: 20 [19200/60900 (32%)]	Loss: 169.151642 | Elapsed: 12.51s
01/28/2023 12:23:23 AM  [*] Sat Jan 28 00:23:23 2023: Train Epoch: 20 [25600/60900 (42%)]	Loss: 184.756592 | Elapsed: 12.44s
01/28/2023 12:23:36 AM  [*] Sat Jan 28 00:23:36 2023: Train Epoch: 20 [32000/60900 (53%)]	Loss: 160.375305 | Elapsed: 12.48s
01/28/2023 12:23:48 AM  [*] Sat Jan 28 00:23:48 2023: Train Epoch: 20 [38400/60900 (63%)]	Loss: 157.659424 | Elapsed: 12.46s
01/28/2023 12:24:01 AM  [*] Sat Jan 28 00:24:01 2023: Train Epoch: 20 [44800/60900 (74%)]	Loss: 170.036682 | Elapsed: 12.46s
01/28/2023 12:24:13 AM  [*] Sat Jan 28 00:24:13 2023: Train Epoch: 20 [51200/60900 (84%)]	Loss: 170.388382 | Elapsed: 12.39s
01/28/2023 12:24:26 AM  [*] Sat Jan 28 00:24:26 2023: Train Epoch: 20 [57600/60900 (95%)]	Loss: 178.923996 | Elapsed: 12.47s
01/28/2023 12:24:34 AM  [*] Sat Jan 28 00:24:34 2023:   20    | Tr.loss: 169.137355 | Elapsed:  120.86  s
01/28/2023 12:24:34 AM [!] Sat Jan 28 00:24:34 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_20_1674861874-model.torch
01/28/2023 12:24:34 AM  [*] Started epoch: 21
01/28/2023 12:24:35 AM  [*] Sat Jan 28 00:24:35 2023: Train Epoch: 21 [  0  /60900 (0 %)]	Loss: 161.480927 | Elapsed: 0.40s
01/28/2023 12:24:47 AM  [*] Sat Jan 28 00:24:47 2023: Train Epoch: 21 [6400 /60900 (11%)]	Loss: 170.177780 | Elapsed: 12.48s
01/28/2023 12:24:59 AM  [*] Sat Jan 28 00:24:59 2023: Train Epoch: 21 [12800/60900 (21%)]	Loss: 165.254181 | Elapsed: 12.42s
01/28/2023 12:25:12 AM  [*] Sat Jan 28 00:25:12 2023: Train Epoch: 21 [19200/60900 (32%)]	Loss: 157.316635 | Elapsed: 12.61s
01/28/2023 12:25:25 AM  [*] Sat Jan 28 00:25:25 2023: Train Epoch: 21 [25600/60900 (42%)]	Loss: 184.059128 | Elapsed: 12.60s
01/28/2023 12:25:37 AM  [*] Sat Jan 28 00:25:37 2023: Train Epoch: 21 [32000/60900 (53%)]	Loss: 162.786942 | Elapsed: 12.51s
01/28/2023 12:25:50 AM  [*] Sat Jan 28 00:25:50 2023: Train Epoch: 21 [38400/60900 (63%)]	Loss: 162.666351 | Elapsed: 12.34s
01/28/2023 12:26:02 AM  [*] Sat Jan 28 00:26:02 2023: Train Epoch: 21 [44800/60900 (74%)]	Loss: 179.297516 | Elapsed: 12.42s
01/28/2023 12:26:14 AM  [*] Sat Jan 28 00:26:14 2023: Train Epoch: 21 [51200/60900 (84%)]	Loss: 186.562622 | Elapsed: 12.50s
01/28/2023 12:26:27 AM  [*] Sat Jan 28 00:26:27 2023: Train Epoch: 21 [57600/60900 (95%)]	Loss: 161.751587 | Elapsed: 12.45s
01/28/2023 12:26:35 AM  [*] Sat Jan 28 00:26:35 2023:   21    | Tr.loss: 169.195969 | Elapsed:  120.94  s
01/28/2023 12:26:36 AM [!] Sat Jan 28 00:26:36 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_21_1674861995-model.torch
01/28/2023 12:26:36 AM  [*] Started epoch: 22
01/28/2023 12:26:36 AM  [*] Sat Jan 28 00:26:36 2023: Train Epoch: 22 [  0  /60900 (0 %)]	Loss: 185.509384 | Elapsed: 0.26s
01/28/2023 12:26:37 AM [!] Learning rate: 2.5e-06
01/28/2023 12:26:49 AM  [*] Sat Jan 28 00:26:49 2023: Train Epoch: 22 [6400 /60900 (11%)]	Loss: 170.992249 | Elapsed: 12.62s
01/28/2023 12:27:01 AM  [*] Sat Jan 28 00:27:01 2023: Train Epoch: 22 [12800/60900 (21%)]	Loss: 172.446320 | Elapsed: 12.38s
01/28/2023 12:27:13 AM  [*] Sat Jan 28 00:27:13 2023: Train Epoch: 22 [19200/60900 (32%)]	Loss: 152.980545 | Elapsed: 12.56s
01/28/2023 12:27:26 AM  [*] Sat Jan 28 00:27:26 2023: Train Epoch: 22 [25600/60900 (42%)]	Loss: 161.263702 | Elapsed: 12.49s
01/28/2023 12:27:38 AM  [*] Sat Jan 28 00:27:38 2023: Train Epoch: 22 [32000/60900 (53%)]	Loss: 156.339142 | Elapsed: 12.45s
01/28/2023 12:27:51 AM  [*] Sat Jan 28 00:27:51 2023: Train Epoch: 22 [38400/60900 (63%)]	Loss: 171.654694 | Elapsed: 12.41s
01/28/2023 12:28:03 AM  [*] Sat Jan 28 00:28:03 2023: Train Epoch: 22 [44800/60900 (74%)]	Loss: 160.098297 | Elapsed: 12.38s
01/28/2023 12:28:16 AM  [*] Sat Jan 28 00:28:16 2023: Train Epoch: 22 [51200/60900 (84%)]	Loss: 173.832336 | Elapsed: 12.58s
01/28/2023 12:28:28 AM  [*] Sat Jan 28 00:28:28 2023: Train Epoch: 22 [57600/60900 (95%)]	Loss: 189.584412 | Elapsed: 12.43s
01/28/2023 12:28:36 AM  [*] Sat Jan 28 00:28:36 2023:   22    | Tr.loss: 169.065740 | Elapsed:  120.80  s
01/28/2023 12:28:37 AM [!] Sat Jan 28 00:28:37 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_22_1674862116-model.torch
01/28/2023 12:28:37 AM  [*] Started epoch: 23
01/28/2023 12:28:37 AM  [*] Sat Jan 28 00:28:37 2023: Train Epoch: 23 [  0  /60900 (0 %)]	Loss: 153.030869 | Elapsed: 0.36s
01/28/2023 12:28:50 AM  [*] Sat Jan 28 00:28:50 2023: Train Epoch: 23 [6400 /60900 (11%)]	Loss: 179.001556 | Elapsed: 12.49s
01/28/2023 12:29:02 AM  [*] Sat Jan 28 00:29:02 2023: Train Epoch: 23 [12800/60900 (21%)]	Loss: 185.472565 | Elapsed: 12.53s
01/28/2023 12:29:15 AM  [*] Sat Jan 28 00:29:15 2023: Train Epoch: 23 [19200/60900 (32%)]	Loss: 172.815048 | Elapsed: 12.54s
01/28/2023 12:29:27 AM  [*] Sat Jan 28 00:29:27 2023: Train Epoch: 23 [25600/60900 (42%)]	Loss: 168.042755 | Elapsed: 12.57s
01/28/2023 12:29:40 AM  [*] Sat Jan 28 00:29:40 2023: Train Epoch: 23 [32000/60900 (53%)]	Loss: 168.534164 | Elapsed: 12.42s
01/28/2023 12:29:52 AM  [*] Sat Jan 28 00:29:52 2023: Train Epoch: 23 [38400/60900 (63%)]	Loss: 156.217575 | Elapsed: 12.44s
01/28/2023 12:30:05 AM  [*] Sat Jan 28 00:30:05 2023: Train Epoch: 23 [44800/60900 (74%)]	Loss: 160.268402 | Elapsed: 12.45s
01/28/2023 12:30:17 AM  [*] Sat Jan 28 00:30:17 2023: Train Epoch: 23 [51200/60900 (84%)]	Loss: 160.620667 | Elapsed: 12.48s
01/28/2023 12:30:30 AM  [*] Sat Jan 28 00:30:30 2023: Train Epoch: 23 [57600/60900 (95%)]	Loss: 191.705902 | Elapsed: 12.42s
01/28/2023 12:30:38 AM  [*] Sat Jan 28 00:30:38 2023:   23    | Tr.loss: 169.068274 | Elapsed:  121.01  s
01/28/2023 12:30:38 AM [!] Sat Jan 28 00:30:38 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_23_1674862238-model.torch
01/28/2023 12:30:38 AM  [*] Started epoch: 24
01/28/2023 12:30:39 AM  [*] Sat Jan 28 00:30:39 2023: Train Epoch: 24 [  0  /60900 (0 %)]	Loss: 172.524460 | Elapsed: 0.21s
01/28/2023 12:30:51 AM  [*] Sat Jan 28 00:30:51 2023: Train Epoch: 24 [6400 /60900 (11%)]	Loss: 162.045792 | Elapsed: 12.44s
01/28/2023 12:31:04 AM  [*] Sat Jan 28 00:31:04 2023: Train Epoch: 24 [12800/60900 (21%)]	Loss: 166.820999 | Elapsed: 12.61s
01/28/2023 12:31:16 AM  [*] Sat Jan 28 00:31:16 2023: Train Epoch: 24 [19200/60900 (32%)]	Loss: 171.778290 | Elapsed: 12.46s
01/28/2023 12:31:29 AM  [*] Sat Jan 28 00:31:29 2023: Train Epoch: 24 [25600/60900 (42%)]	Loss: 149.928253 | Elapsed: 12.64s
01/28/2023 12:31:41 AM  [*] Sat Jan 28 00:31:41 2023: Train Epoch: 24 [32000/60900 (53%)]	Loss: 177.069778 | Elapsed: 12.41s
01/28/2023 12:31:54 AM  [*] Sat Jan 28 00:31:54 2023: Train Epoch: 24 [38400/60900 (63%)]	Loss: 177.016403 | Elapsed: 12.50s
01/28/2023 12:32:06 AM  [*] Sat Jan 28 00:32:06 2023: Train Epoch: 24 [44800/60900 (74%)]	Loss: 136.723663 | Elapsed: 12.44s
01/28/2023 12:32:19 AM  [*] Sat Jan 28 00:32:19 2023: Train Epoch: 24 [51200/60900 (84%)]	Loss: 178.023453 | Elapsed: 12.54s
01/28/2023 12:32:31 AM  [*] Sat Jan 28 00:32:31 2023: Train Epoch: 24 [57600/60900 (95%)]	Loss: 185.262848 | Elapsed: 12.52s
01/28/2023 12:32:39 AM  [*] Sat Jan 28 00:32:39 2023:   24    | Tr.loss: 169.032067 | Elapsed:  121.00  s
01/28/2023 12:32:40 AM [!] Sat Jan 28 00:32:40 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_24_1674862359-model.torch
01/28/2023 12:32:40 AM  [*] Started epoch: 25
01/28/2023 12:32:40 AM  [*] Sat Jan 28 00:32:40 2023: Train Epoch: 25 [  0  /60900 (0 %)]	Loss: 180.162872 | Elapsed: 0.32s
01/28/2023 12:32:53 AM  [*] Sat Jan 28 00:32:53 2023: Train Epoch: 25 [6400 /60900 (11%)]	Loss: 170.818985 | Elapsed: 12.55s
01/28/2023 12:33:05 AM  [*] Sat Jan 28 00:33:05 2023: Train Epoch: 25 [12800/60900 (21%)]	Loss: 191.698242 | Elapsed: 12.48s
01/28/2023 12:33:18 AM  [*] Sat Jan 28 00:33:18 2023: Train Epoch: 25 [19200/60900 (32%)]	Loss: 167.695160 | Elapsed: 12.57s
01/28/2023 12:33:30 AM  [*] Sat Jan 28 00:33:30 2023: Train Epoch: 25 [25600/60900 (42%)]	Loss: 157.786148 | Elapsed: 12.55s
01/28/2023 12:33:43 AM  [*] Sat Jan 28 00:33:43 2023: Train Epoch: 25 [32000/60900 (53%)]	Loss: 163.224274 | Elapsed: 12.54s
01/28/2023 12:33:55 AM  [*] Sat Jan 28 00:33:55 2023: Train Epoch: 25 [38400/60900 (63%)]	Loss: 159.369247 | Elapsed: 12.52s
01/28/2023 12:34:08 AM  [*] Sat Jan 28 00:34:08 2023: Train Epoch: 25 [44800/60900 (74%)]	Loss: 166.338913 | Elapsed: 12.50s
01/28/2023 12:34:20 AM  [*] Sat Jan 28 00:34:20 2023: Train Epoch: 25 [51200/60900 (84%)]	Loss: 188.442657 | Elapsed: 12.45s
01/28/2023 12:34:33 AM  [*] Sat Jan 28 00:34:33 2023: Train Epoch: 25 [57600/60900 (95%)]	Loss: 168.110397 | Elapsed: 12.53s
01/28/2023 12:34:41 AM  [*] Sat Jan 28 00:34:41 2023:   25    | Tr.loss: 169.059703 | Elapsed:  121.19  s
01/28/2023 12:34:42 AM [!] Sat Jan 28 00:34:42 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_25_1674862481-model.torch
01/28/2023 12:34:42 AM  [*] Started epoch: 26
01/28/2023 12:34:42 AM  [*] Sat Jan 28 00:34:42 2023: Train Epoch: 26 [  0  /60900 (0 %)]	Loss: 162.242889 | Elapsed: 0.37s
01/28/2023 12:34:54 AM  [*] Sat Jan 28 00:34:54 2023: Train Epoch: 26 [6400 /60900 (11%)]	Loss: 174.701401 | Elapsed: 12.51s
01/28/2023 12:35:07 AM  [*] Sat Jan 28 00:35:07 2023: Train Epoch: 26 [12800/60900 (21%)]	Loss: 172.970200 | Elapsed: 12.58s
01/28/2023 12:35:20 AM  [*] Sat Jan 28 00:35:20 2023: Train Epoch: 26 [19200/60900 (32%)]	Loss: 161.509796 | Elapsed: 12.52s
01/28/2023 12:35:32 AM  [*] Sat Jan 28 00:35:32 2023: Train Epoch: 26 [25600/60900 (42%)]	Loss: 160.746948 | Elapsed: 12.50s
01/28/2023 12:35:45 AM  [*] Sat Jan 28 00:35:45 2023: Train Epoch: 26 [32000/60900 (53%)]	Loss: 154.153442 | Elapsed: 12.51s
01/28/2023 12:35:57 AM  [*] Sat Jan 28 00:35:57 2023: Train Epoch: 26 [38400/60900 (63%)]	Loss: 182.754379 | Elapsed: 12.41s
01/28/2023 12:36:10 AM  [*] Sat Jan 28 00:36:10 2023: Train Epoch: 26 [44800/60900 (74%)]	Loss: 177.224136 | Elapsed: 12.56s
01/28/2023 12:36:22 AM  [*] Sat Jan 28 00:36:22 2023: Train Epoch: 26 [51200/60900 (84%)]	Loss: 177.462250 | Elapsed: 12.44s
01/28/2023 12:36:34 AM  [*] Sat Jan 28 00:36:34 2023: Train Epoch: 26 [57600/60900 (95%)]	Loss: 170.846802 | Elapsed: 12.52s
01/28/2023 12:36:43 AM  [*] Sat Jan 28 00:36:43 2023:   26    | Tr.loss: 168.934150 | Elapsed:  121.23  s
01/28/2023 12:36:43 AM [!] Sat Jan 28 00:36:43 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_26_1674862603-model.torch
01/28/2023 12:36:43 AM  [*] Started epoch: 27
01/28/2023 12:36:43 AM  [*] Sat Jan 28 00:36:43 2023: Train Epoch: 27 [  0  /60900 (0 %)]	Loss: 150.865387 | Elapsed: 0.22s
01/28/2023 12:36:56 AM  [*] Sat Jan 28 00:36:56 2023: Train Epoch: 27 [6400 /60900 (11%)]	Loss: 153.122696 | Elapsed: 12.67s
01/28/2023 12:37:09 AM  [*] Sat Jan 28 00:37:09 2023: Train Epoch: 27 [12800/60900 (21%)]	Loss: 154.139648 | Elapsed: 12.50s
01/28/2023 12:37:21 AM  [*] Sat Jan 28 00:37:21 2023: Train Epoch: 27 [19200/60900 (32%)]	Loss: 153.355087 | Elapsed: 12.55s
01/28/2023 12:37:34 AM  [*] Sat Jan 28 00:37:34 2023: Train Epoch: 27 [25600/60900 (42%)]	Loss: 166.976715 | Elapsed: 12.42s
01/28/2023 12:37:46 AM  [*] Sat Jan 28 00:37:46 2023: Train Epoch: 27 [32000/60900 (53%)]	Loss: 157.663971 | Elapsed: 12.37s
01/28/2023 12:37:58 AM  [*] Sat Jan 28 00:37:58 2023: Train Epoch: 27 [38400/60900 (63%)]	Loss: 171.693802 | Elapsed: 12.47s
01/28/2023 12:38:11 AM  [*] Sat Jan 28 00:38:11 2023: Train Epoch: 27 [44800/60900 (74%)]	Loss: 168.371338 | Elapsed: 12.46s
01/28/2023 12:38:23 AM  [*] Sat Jan 28 00:38:23 2023: Train Epoch: 27 [51200/60900 (84%)]	Loss: 181.842987 | Elapsed: 12.48s
01/28/2023 12:38:36 AM  [*] Sat Jan 28 00:38:36 2023: Train Epoch: 27 [57600/60900 (95%)]	Loss: 171.537872 | Elapsed: 12.44s
01/28/2023 12:38:44 AM  [*] Sat Jan 28 00:38:44 2023:   27    | Tr.loss: 169.038417 | Elapsed:  120.72  s
01/28/2023 12:38:44 AM [!] Sat Jan 28 00:38:44 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_27_1674862724-model.torch
01/28/2023 12:38:44 AM  [*] Started epoch: 28
01/28/2023 12:38:45 AM  [*] Sat Jan 28 00:38:45 2023: Train Epoch: 28 [  0  /60900 (0 %)]	Loss: 172.593170 | Elapsed: 0.35s
01/28/2023 12:38:57 AM  [*] Sat Jan 28 00:38:57 2023: Train Epoch: 28 [6400 /60900 (11%)]	Loss: 159.036438 | Elapsed: 12.48s
01/28/2023 12:39:10 AM  [*] Sat Jan 28 00:39:10 2023: Train Epoch: 28 [12800/60900 (21%)]	Loss: 160.569244 | Elapsed: 12.48s
01/28/2023 12:39:22 AM  [*] Sat Jan 28 00:39:22 2023: Train Epoch: 28 [19200/60900 (32%)]	Loss: 177.785614 | Elapsed: 12.61s
01/28/2023 12:39:35 AM  [*] Sat Jan 28 00:39:35 2023: Train Epoch: 28 [25600/60900 (42%)]	Loss: 168.721024 | Elapsed: 12.44s
01/28/2023 12:39:47 AM  [*] Sat Jan 28 00:39:47 2023: Train Epoch: 28 [32000/60900 (53%)]	Loss: 171.136612 | Elapsed: 12.43s
01/28/2023 12:40:00 AM  [*] Sat Jan 28 00:40:00 2023: Train Epoch: 28 [38400/60900 (63%)]	Loss: 157.821793 | Elapsed: 12.51s
01/28/2023 12:40:12 AM  [*] Sat Jan 28 00:40:12 2023: Train Epoch: 28 [44800/60900 (74%)]	Loss: 183.399536 | Elapsed: 12.42s
01/28/2023 12:40:25 AM  [*] Sat Jan 28 00:40:25 2023: Train Epoch: 28 [51200/60900 (84%)]	Loss: 156.412933 | Elapsed: 12.43s
01/28/2023 12:40:37 AM  [*] Sat Jan 28 00:40:37 2023: Train Epoch: 28 [57600/60900 (95%)]	Loss: 173.532135 | Elapsed: 12.47s
01/28/2023 12:40:45 AM  [*] Sat Jan 28 00:40:45 2023:   28    | Tr.loss: 169.029393 | Elapsed:  120.89  s
01/28/2023 12:40:46 AM [!] Sat Jan 28 00:40:46 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_28_1674862845-model.torch
01/28/2023 12:40:46 AM  [*] Started epoch: 29
01/28/2023 12:40:46 AM  [*] Sat Jan 28 00:40:46 2023: Train Epoch: 29 [  0  /60900 (0 %)]	Loss: 155.377777 | Elapsed: 0.36s
01/28/2023 12:40:59 AM  [*] Sat Jan 28 00:40:59 2023: Train Epoch: 29 [6400 /60900 (11%)]	Loss: 186.991577 | Elapsed: 12.50s
01/28/2023 12:41:11 AM  [*] Sat Jan 28 00:41:11 2023: Train Epoch: 29 [12800/60900 (21%)]	Loss: 164.321716 | Elapsed: 12.49s
01/28/2023 12:41:24 AM  [*] Sat Jan 28 00:41:24 2023: Train Epoch: 29 [19200/60900 (32%)]	Loss: 172.003403 | Elapsed: 12.51s
01/28/2023 12:41:36 AM  [*] Sat Jan 28 00:41:36 2023: Train Epoch: 29 [25600/60900 (42%)]	Loss: 172.595001 | Elapsed: 12.39s
01/28/2023 12:41:49 AM  [*] Sat Jan 28 00:41:49 2023: Train Epoch: 29 [32000/60900 (53%)]	Loss: 155.491028 | Elapsed: 12.49s
01/28/2023 12:42:01 AM  [*] Sat Jan 28 00:42:01 2023: Train Epoch: 29 [38400/60900 (63%)]	Loss: 173.390640 | Elapsed: 12.48s
01/28/2023 12:42:13 AM  [*] Sat Jan 28 00:42:13 2023: Train Epoch: 29 [44800/60900 (74%)]	Loss: 152.383789 | Elapsed: 12.31s
01/28/2023 12:42:26 AM  [*] Sat Jan 28 00:42:26 2023: Train Epoch: 29 [51200/60900 (84%)]	Loss: 157.555038 | Elapsed: 12.48s
01/28/2023 12:42:38 AM  [*] Sat Jan 28 00:42:38 2023: Train Epoch: 29 [57600/60900 (95%)]	Loss: 161.460205 | Elapsed: 12.40s
01/28/2023 12:42:46 AM  [*] Sat Jan 28 00:42:46 2023:   29    | Tr.loss: 168.993436 | Elapsed:  120.61  s
01/28/2023 12:42:47 AM [!] Sat Jan 28 00:42:47 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_29_1674862966-model.torch
01/28/2023 12:42:47 AM  [*] Started epoch: 30
01/28/2023 12:42:47 AM  [*] Sat Jan 28 00:42:47 2023: Train Epoch: 30 [  0  /60900 (0 %)]	Loss: 159.021545 | Elapsed: 0.24s
01/28/2023 12:43:00 AM  [*] Sat Jan 28 00:43:00 2023: Train Epoch: 30 [6400 /60900 (11%)]	Loss: 169.289764 | Elapsed: 12.51s
01/28/2023 12:43:12 AM  [*] Sat Jan 28 00:43:12 2023: Train Epoch: 30 [12800/60900 (21%)]	Loss: 155.799927 | Elapsed: 12.41s
01/28/2023 12:43:25 AM  [*] Sat Jan 28 00:43:25 2023: Train Epoch: 30 [19200/60900 (32%)]	Loss: 169.882111 | Elapsed: 12.59s
01/28/2023 12:43:37 AM  [*] Sat Jan 28 00:43:37 2023: Train Epoch: 30 [25600/60900 (42%)]	Loss: 182.254303 | Elapsed: 12.43s
01/28/2023 12:43:50 AM  [*] Sat Jan 28 00:43:50 2023: Train Epoch: 30 [32000/60900 (53%)]	Loss: 186.947876 | Elapsed: 12.47s
01/28/2023 12:44:02 AM  [*] Sat Jan 28 00:44:02 2023: Train Epoch: 30 [38400/60900 (63%)]	Loss: 163.542816 | Elapsed: 12.55s
01/28/2023 12:44:15 AM  [*] Sat Jan 28 00:44:15 2023: Train Epoch: 30 [44800/60900 (74%)]	Loss: 179.856934 | Elapsed: 12.53s
01/28/2023 12:44:27 AM  [*] Sat Jan 28 00:44:27 2023: Train Epoch: 30 [51200/60900 (84%)]	Loss: 175.849182 | Elapsed: 12.48s
01/28/2023 12:44:40 AM  [*] Sat Jan 28 00:44:40 2023: Train Epoch: 30 [57600/60900 (95%)]	Loss: 160.957275 | Elapsed: 12.39s
01/28/2023 12:44:48 AM  [*] Sat Jan 28 00:44:48 2023:   30    | Tr.loss: 169.019892 | Elapsed:  120.84  s
01/28/2023 12:44:48 AM [!] Sat Jan 28 00:44:48 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_30_1674863088-model.torch
01/28/2023 12:44:49 AM [!] Sat Jan 28 00:44:49 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\1674863088-model.torch
		train time: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\1674863088-trainTime.npy
		train losses: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\1674863088-trainLosses.npy
		train AUC: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\1674863088-auc.npy
01/28/2023 12:44:50 AM  [!] Training pretrained model on downstream task...
01/28/2023 12:44:50 AM  [*] Started epoch: 1
01/28/2023 12:44:50 AM  [*] Sat Jan 28 00:44:50 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 2.871741 | Elapsed: 0.24s | FPR 0.0003 -> TPR 0.2326 & F1 0.3774
01/28/2023 12:44:59 AM  [*] Sat Jan 28 00:44:59 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.379732 | Elapsed: 9.14s | FPR 0.0003 -> TPR 0.4426 & F1 0.6136
01/28/2023 12:45:08 AM  [*] Sat Jan 28 00:45:08 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.486340 | Elapsed: 9.12s | FPR 0.0003 -> TPR 0.2000 & F1 0.3333
01/28/2023 12:45:12 AM  [*] Sat Jan 28 00:45:12 2023:    1    | Tr.loss: 0.551606 | Elapsed:   22.24  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8301
01/28/2023 12:45:12 AM  [*] Started epoch: 2
01/28/2023 12:45:12 AM  [*] Sat Jan 28 00:45:12 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.323753 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.5581 & F1 0.7164
01/28/2023 12:45:21 AM  [*] Sat Jan 28 00:45:21 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.334624 | Elapsed: 9.14s | FPR 0.0003 -> TPR 0.3966 & F1 0.5679
01/28/2023 12:45:30 AM  [*] Sat Jan 28 00:45:30 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.295607 | Elapsed: 9.19s | FPR 0.0003 -> TPR 0.6618 & F1 0.7965
01/28/2023 12:45:34 AM  [*] Sat Jan 28 00:45:34 2023:    2    | Tr.loss: 0.314047 | Elapsed:   22.12  s | FPR 0.0003 -> TPR: 0.27 & F1: 0.43 | AUC: 0.9246
01/28/2023 12:45:34 AM  [*] Started epoch: 3
01/28/2023 12:45:34 AM  [*] Sat Jan 28 00:45:34 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.315637 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.6842 & F1 0.8125
01/28/2023 12:45:43 AM  [*] Sat Jan 28 00:45:43 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.144078 | Elapsed: 9.12s | FPR 0.0003 -> TPR 0.8889 & F1 0.9412
01/28/2023 12:45:52 AM  [*] Sat Jan 28 00:45:52 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.215591 | Elapsed: 9.11s | FPR 0.0003 -> TPR 0.8108 & F1 0.8955
01/28/2023 12:45:56 AM  [*] Sat Jan 28 00:45:56 2023:    3    | Tr.loss: 0.238785 | Elapsed:   22.10  s | FPR 0.0003 -> TPR: 0.27 & F1: 0.42 | AUC: 0.9574
01/28/2023 12:45:57 AM [!] Sat Jan 28 00:45:57 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_pretrained\training_files\1674863156-model.torch
		train time: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_pretrained\training_files\1674863156-trainTime.npy
		train losses: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_pretrained\training_files\1674863156-trainLosses.npy
		train AUC: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_pretrained\training_files\1674863156-auc.npy
		train F1s : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_pretrained\training_files\1674863156-trainF1s.npy
		train TPRs: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_pretrained\training_files\1674863156-trainTPRs.npy
01/28/2023 12:45:57 AM  [!] Training non_pretrained model on downstream task...
01/28/2023 12:45:57 AM  [*] Started epoch: 1
01/28/2023 12:45:57 AM  [*] Sat Jan 28 00:45:57 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 2.257583 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0233 & F1 0.0455
01/28/2023 12:46:03 AM  [*] Sat Jan 28 00:46:03 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.428573 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.2714 & F1 0.4270
01/28/2023 12:46:10 AM  [*] Sat Jan 28 00:46:10 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.296631 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.6471 & F1 0.7857
01/28/2023 12:46:12 AM  [*] Sat Jan 28 00:46:12 2023:    1    | Tr.loss: 0.470284 | Elapsed:   15.22  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8289
01/28/2023 12:46:12 AM  [*] Started epoch: 2
01/28/2023 12:46:12 AM  [*] Sat Jan 28 00:46:12 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.352462 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.6818 & F1 0.8108
01/28/2023 12:46:19 AM  [*] Sat Jan 28 00:46:19 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.331292 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.3284 & F1 0.4944
01/28/2023 12:46:25 AM  [*] Sat Jan 28 00:46:25 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.235044 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.6027 & F1 0.7521
01/28/2023 12:46:27 AM  [*] Sat Jan 28 00:46:27 2023:    2    | Tr.loss: 0.302952 | Elapsed:   15.19  s | FPR 0.0003 -> TPR: 0.24 & F1: 0.38 | AUC: 0.9309
01/28/2023 12:46:27 AM  [*] Started epoch: 3
01/28/2023 12:46:28 AM  [*] Sat Jan 28 00:46:28 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.422965 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.5128 & F1 0.6780
01/28/2023 12:46:34 AM  [*] Sat Jan 28 00:46:34 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.183095 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.6923 & F1 0.8182
01/28/2023 12:46:40 AM  [*] Sat Jan 28 00:46:40 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.183346 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.9697 & F1 0.9846
01/28/2023 12:46:43 AM  [*] Sat Jan 28 00:46:43 2023:    3    | Tr.loss: 0.238769 | Elapsed:   15.22  s | FPR 0.0003 -> TPR: 0.25 & F1: 0.39 | AUC: 0.9591
01/28/2023 12:46:43 AM [!] Sat Jan 28 00:46:43 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_non_pretrained\training_files\1674863203-model.torch
		train time: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_non_pretrained\training_files\1674863203-trainTime.npy
		train losses: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_non_pretrained\training_files\1674863203-trainLosses.npy
		train AUC: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_non_pretrained\training_files\1674863203-auc.npy
		train F1s : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_non_pretrained\training_files\1674863203-trainF1s.npy
		train TPRs: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_non_pretrained\training_files\1674863203-trainTPRs.npy
01/28/2023 12:46:43 AM  [!] Training full_data model on downstream task...
01/28/2023 12:46:44 AM  [*] Started epoch: 1
01/28/2023 12:46:44 AM  [*] Sat Jan 28 00:46:44 2023: Train Epoch: 1 [  0  /76126 (0 %)]	Loss: 1.666725 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.0976 & F1 0.1778
01/28/2023 12:46:50 AM  [*] Sat Jan 28 00:46:50 2023: Train Epoch: 1 [6400 /76126 (8 %)]	Loss: 0.372075 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.2329 & F1 0.3778
01/28/2023 12:46:56 AM  [*] Sat Jan 28 00:46:56 2023: Train Epoch: 1 [12800/76126 (17%)]	Loss: 0.277840 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.2778 & F1 0.4348
01/28/2023 12:47:02 AM  [*] Sat Jan 28 00:47:02 2023: Train Epoch: 1 [19200/76126 (25%)]	Loss: 0.266848 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.4923 & F1 0.6598
01/28/2023 12:47:09 AM  [*] Sat Jan 28 00:47:09 2023: Train Epoch: 1 [25600/76126 (34%)]	Loss: 0.243175 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.5493 & F1 0.7091
01/28/2023 12:47:15 AM  [*] Sat Jan 28 00:47:15 2023: Train Epoch: 1 [32000/76126 (42%)]	Loss: 0.448573 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.3968 & F1 0.5682
01/28/2023 12:47:21 AM  [*] Sat Jan 28 00:47:21 2023: Train Epoch: 1 [38400/76126 (50%)]	Loss: 0.240487 | Elapsed: 6.30s | FPR 0.0003 -> TPR 0.6232 & F1 0.7679
01/28/2023 12:47:27 AM  [*] Sat Jan 28 00:47:27 2023: Train Epoch: 1 [44800/76126 (59%)]	Loss: 0.247228 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.7971 & F1 0.8871
01/28/2023 12:47:34 AM  [*] Sat Jan 28 00:47:34 2023: Train Epoch: 1 [51200/76126 (67%)]	Loss: 0.210787 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.6761 & F1 0.8067
01/28/2023 12:47:40 AM  [*] Sat Jan 28 00:47:40 2023: Train Epoch: 1 [57600/76126 (76%)]	Loss: 0.193365 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.8676 & F1 0.9291
01/28/2023 12:47:46 AM  [*] Sat Jan 28 00:47:46 2023: Train Epoch: 1 [64000/76126 (84%)]	Loss: 0.163904 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.7018 & F1 0.8247
01/28/2023 12:47:52 AM  [*] Sat Jan 28 00:47:52 2023: Train Epoch: 1 [70400/76126 (92%)]	Loss: 0.283362 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.6364 & F1 0.7778
01/28/2023 12:48:00 AM  [*] Sat Jan 28 00:48:00 2023:    1    | Tr.loss: 0.295632 | Elapsed:   76.24  s | FPR 0.0003 -> TPR: 0.09 & F1: 0.17 | AUC: 0.9361
01/28/2023 12:48:00 AM  [*] Started epoch: 2
01/28/2023 12:48:00 AM  [*] Sat Jan 28 00:48:00 2023: Train Epoch: 2 [  0  /76126 (0 %)]	Loss: 0.156357 | Elapsed: 0.13s | FPR 0.0003 -> TPR 0.9048 & F1 0.9500
01/28/2023 12:48:06 AM  [*] Sat Jan 28 00:48:06 2023: Train Epoch: 2 [6400 /76126 (8 %)]	Loss: 0.156376 | Elapsed: 6.31s | FPR 0.0003 -> TPR 0.9107 & F1 0.9533
01/28/2023 12:48:13 AM  [*] Sat Jan 28 00:48:13 2023: Train Epoch: 2 [12800/76126 (17%)]	Loss: 0.114520 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.8696 & F1 0.9302
01/28/2023 12:48:19 AM  [*] Sat Jan 28 00:48:19 2023: Train Epoch: 2 [19200/76126 (25%)]	Loss: 0.161313 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.8947 & F1 0.9444
01/28/2023 12:48:25 AM  [*] Sat Jan 28 00:48:25 2023: Train Epoch: 2 [25600/76126 (34%)]	Loss: 0.271250 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.7973 & F1 0.8872
01/28/2023 12:48:31 AM  [*] Sat Jan 28 00:48:31 2023: Train Epoch: 2 [32000/76126 (42%)]	Loss: 0.134965 | Elapsed: 6.27s | FPR 0.0003 -> TPR 0.9429 & F1 0.9706
01/28/2023 12:48:38 AM  [*] Sat Jan 28 00:48:38 2023: Train Epoch: 2 [38400/76126 (50%)]	Loss: 0.128549 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.7619 & F1 0.8649
01/28/2023 12:48:44 AM  [*] Sat Jan 28 00:48:44 2023: Train Epoch: 2 [44800/76126 (59%)]	Loss: 0.081130 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.8701 & F1 0.9306
01/28/2023 12:48:50 AM  [*] Sat Jan 28 00:48:50 2023: Train Epoch: 2 [51200/76126 (67%)]	Loss: 0.087402 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.9143 & F1 0.9552
01/28/2023 12:48:51 AM [!] Learning rate: 2.5e-05
01/28/2023 12:48:56 AM  [*] Sat Jan 28 00:48:56 2023: Train Epoch: 2 [57600/76126 (76%)]	Loss: 0.122631 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.9265 & F1 0.9618
01/28/2023 12:49:03 AM  [*] Sat Jan 28 00:49:03 2023: Train Epoch: 2 [64000/76126 (84%)]	Loss: 0.147331 | Elapsed: 6.33s | FPR 0.0003 -> TPR 0.6765 & F1 0.8070
01/28/2023 12:49:09 AM  [*] Sat Jan 28 00:49:09 2023: Train Epoch: 2 [70400/76126 (92%)]	Loss: 0.087815 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.9714 & F1 0.9855
01/28/2023 12:49:16 AM  [*] Sat Jan 28 00:49:16 2023:    2    | Tr.loss: 0.134087 | Elapsed:   76.36  s | FPR 0.0003 -> TPR: 0.49 & F1: 0.66 | AUC: 0.9875
01/28/2023 12:49:16 AM  [*] Started epoch: 3
01/28/2023 12:49:16 AM  [*] Sat Jan 28 00:49:16 2023: Train Epoch: 3 [  0  /76126 (0 %)]	Loss: 0.120180 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.9783 & F1 0.9890
01/28/2023 12:49:23 AM  [*] Sat Jan 28 00:49:23 2023: Train Epoch: 3 [6400 /76126 (8 %)]	Loss: 0.126743 | Elapsed: 6.32s | FPR 0.0003 -> TPR 0.9733 & F1 0.9865
01/28/2023 12:49:29 AM  [*] Sat Jan 28 00:49:29 2023: Train Epoch: 3 [12800/76126 (17%)]	Loss: 0.149284 | Elapsed: 6.31s | FPR 0.0003 -> TPR 0.9189 & F1 0.9577
01/28/2023 12:49:35 AM  [*] Sat Jan 28 00:49:35 2023: Train Epoch: 3 [19200/76126 (25%)]	Loss: 0.232138 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.8209 & F1 0.9016
01/28/2023 12:49:41 AM  [*] Sat Jan 28 00:49:41 2023: Train Epoch: 3 [25600/76126 (34%)]	Loss: 0.109537 | Elapsed: 6.26s | FPR 0.0003 -> TPR 0.9565 & F1 0.9778
01/28/2023 12:49:48 AM  [*] Sat Jan 28 00:49:48 2023: Train Epoch: 3 [32000/76126 (42%)]	Loss: 0.072411 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.9552 & F1 0.9771
01/28/2023 12:49:54 AM  [*] Sat Jan 28 00:49:54 2023: Train Epoch: 3 [38400/76126 (50%)]	Loss: 0.201515 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.9041 & F1 0.9496
01/28/2023 12:50:00 AM  [*] Sat Jan 28 00:50:00 2023: Train Epoch: 3 [44800/76126 (59%)]	Loss: 0.083985 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.9077 & F1 0.9516
01/28/2023 12:50:06 AM  [*] Sat Jan 28 00:50:06 2023: Train Epoch: 3 [51200/76126 (67%)]	Loss: 0.036871 | Elapsed: 6.24s | FPR 0.0003 -> TPR 1.0000 & F1 1.0000
01/28/2023 12:50:13 AM  [*] Sat Jan 28 00:50:13 2023: Train Epoch: 3 [57600/76126 (76%)]	Loss: 0.147997 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.9167 & F1 0.9565
01/28/2023 12:50:19 AM  [*] Sat Jan 28 00:50:19 2023: Train Epoch: 3 [64000/76126 (84%)]	Loss: 0.049013 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.9836 & F1 0.9917
01/28/2023 12:50:25 AM  [*] Sat Jan 28 00:50:25 2023: Train Epoch: 3 [70400/76126 (92%)]	Loss: 0.051679 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.9841 & F1 0.9920
01/28/2023 12:50:33 AM  [*] Sat Jan 28 00:50:33 2023:    3    | Tr.loss: 0.099427 | Elapsed:   76.35  s | FPR 0.0003 -> TPR: 0.69 & F1: 0.82 | AUC: 0.9931
01/28/2023 12:50:33 AM [!] Sat Jan 28 00:50:33 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_full_data\training_files\1674863433-model.torch
		train time: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_full_data\training_files\1674863433-trainTime.npy
		train losses: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_full_data\training_files\1674863433-trainLosses.npy
		train AUC: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_full_data\training_files\1674863433-auc.npy
		train F1s : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_full_data\training_files\1674863433-trainF1s.npy
		train TPRs: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_full_data\training_files\1674863433-trainTPRs.npy
01/28/2023 12:50:33 AM  [*] Evaluating pretrained model on test set...
01/28/2023 12:50:38 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.1969 | F1: 0.3289
01/28/2023 12:50:38 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.2614 | F1: 0.4144
01/28/2023 12:50:38 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.3466 | F1: 0.5144
01/28/2023 12:50:38 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.4159 | F1: 0.5864
01/28/2023 12:50:38 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.4482 | F1: 0.6153
01/28/2023 12:50:38 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4911 | F1: 0.6476
01/28/2023 12:50:38 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.8011 | F1: 0.8495
01/28/2023 12:50:38 AM  [*] Evaluating non_pretrained model on test set...
01/28/2023 12:50:43 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0706 | F1: 0.1319
01/28/2023 12:50:43 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1568 | F1: 0.2710
01/28/2023 12:50:43 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.2601 | F1: 0.4126
01/28/2023 12:50:43 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.2957 | F1: 0.4555
01/28/2023 12:50:43 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3498 | F1: 0.5150
01/28/2023 12:50:43 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4639 | F1: 0.6230
01/28/2023 12:50:43 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.7667 | F1: 0.8280
01/28/2023 12:50:43 AM  [*] Evaluating full_data model on test set...
01/28/2023 12:50:48 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.1903 | F1: 0.3197
01/28/2023 12:50:48 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.3721 | F1: 0.5423
01/28/2023 12:50:48 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.4192 | F1: 0.5904
01/28/2023 12:50:48 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.4755 | F1: 0.6434
01/28/2023 12:50:48 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.6126 | F1: 0.7558
01/28/2023 12:50:48 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.6842 | F1: 0.8004
01/28/2023 12:50:48 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.8594 | F1: 0.8839
01/28/2023 12:50:48 AM  [!] Running pre-training split 3/3
01/28/2023 12:50:51 AM  [!] Pre-training model...
01/28/2023 12:50:52 AM  [*] Masking sequences...
01/28/2023 12:51:12 AM  [*] Started epoch: 1
01/28/2023 12:51:13 AM  [*] Sat Jan 28 00:51:13 2023: Train Epoch: 1 [  0  /60900 (0 %)]	Loss: 444.229614 | Elapsed: 0.81s
01/28/2023 12:51:25 AM  [*] Sat Jan 28 00:51:25 2023: Train Epoch: 1 [6400 /60900 (11%)]	Loss: 254.570145 | Elapsed: 12.34s
01/28/2023 12:51:38 AM  [*] Sat Jan 28 00:51:38 2023: Train Epoch: 1 [12800/60900 (21%)]	Loss: 206.059113 | Elapsed: 12.38s
01/28/2023 12:51:50 AM  [*] Sat Jan 28 00:51:50 2023: Train Epoch: 1 [19200/60900 (32%)]	Loss: 197.710602 | Elapsed: 12.42s
01/28/2023 12:52:03 AM  [*] Sat Jan 28 00:52:03 2023: Train Epoch: 1 [25600/60900 (42%)]	Loss: 185.693359 | Elapsed: 12.44s
01/28/2023 12:52:15 AM  [*] Sat Jan 28 00:52:15 2023: Train Epoch: 1 [32000/60900 (53%)]	Loss: 183.100006 | Elapsed: 12.49s
01/28/2023 12:52:28 AM  [*] Sat Jan 28 00:52:28 2023: Train Epoch: 1 [38400/60900 (63%)]	Loss: 182.630630 | Elapsed: 12.47s
01/28/2023 12:52:40 AM  [*] Sat Jan 28 00:52:40 2023: Train Epoch: 1 [44800/60900 (74%)]	Loss: 212.059235 | Elapsed: 12.52s
01/28/2023 12:52:53 AM  [*] Sat Jan 28 00:52:53 2023: Train Epoch: 1 [51200/60900 (84%)]	Loss: 181.710831 | Elapsed: 12.41s
01/28/2023 12:53:05 AM  [*] Sat Jan 28 00:53:05 2023: Train Epoch: 1 [57600/60900 (95%)]	Loss: 191.998505 | Elapsed: 12.51s
01/28/2023 12:53:14 AM  [*] Sat Jan 28 00:53:14 2023:    1    | Tr.loss: 206.455221 | Elapsed:  121.22  s
01/28/2023 12:53:14 AM [!] Sat Jan 28 00:53:14 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_1_1674863594-model.torch
01/28/2023 12:53:14 AM  [*] Started epoch: 2
01/28/2023 12:53:14 AM  [*] Sat Jan 28 00:53:14 2023: Train Epoch: 2 [  0  /60900 (0 %)]	Loss: 205.439453 | Elapsed: 0.25s
01/28/2023 12:53:27 AM  [*] Sat Jan 28 00:53:27 2023: Train Epoch: 2 [6400 /60900 (11%)]	Loss: 192.941833 | Elapsed: 12.73s
01/28/2023 12:53:40 AM  [*] Sat Jan 28 00:53:40 2023: Train Epoch: 2 [12800/60900 (21%)]	Loss: 196.807465 | Elapsed: 12.58s
01/28/2023 12:53:52 AM  [*] Sat Jan 28 00:53:52 2023: Train Epoch: 2 [19200/60900 (32%)]	Loss: 182.961868 | Elapsed: 12.49s
01/28/2023 12:54:05 AM  [*] Sat Jan 28 00:54:05 2023: Train Epoch: 2 [25600/60900 (42%)]	Loss: 190.784286 | Elapsed: 12.48s
01/28/2023 12:54:17 AM  [*] Sat Jan 28 00:54:17 2023: Train Epoch: 2 [32000/60900 (53%)]	Loss: 196.692657 | Elapsed: 12.48s
01/28/2023 12:54:30 AM  [*] Sat Jan 28 00:54:30 2023: Train Epoch: 2 [38400/60900 (63%)]	Loss: 190.541351 | Elapsed: 12.45s
01/28/2023 12:54:42 AM  [*] Sat Jan 28 00:54:42 2023: Train Epoch: 2 [44800/60900 (74%)]	Loss: 208.213135 | Elapsed: 12.64s
01/28/2023 12:54:55 AM  [*] Sat Jan 28 00:54:55 2023: Train Epoch: 2 [51200/60900 (84%)]	Loss: 164.436249 | Elapsed: 12.47s
01/28/2023 12:55:07 AM  [*] Sat Jan 28 00:55:07 2023: Train Epoch: 2 [57600/60900 (95%)]	Loss: 178.334579 | Elapsed: 12.51s
01/28/2023 12:55:16 AM  [*] Sat Jan 28 00:55:16 2023:    2    | Tr.loss: 184.178398 | Elapsed:  121.62  s
01/28/2023 12:55:16 AM [!] Sat Jan 28 00:55:16 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_2_1674863716-model.torch
01/28/2023 12:55:16 AM  [*] Started epoch: 3
01/28/2023 12:55:16 AM  [*] Sat Jan 28 00:55:16 2023: Train Epoch: 3 [  0  /60900 (0 %)]	Loss: 175.724945 | Elapsed: 0.23s
01/28/2023 12:55:29 AM  [*] Sat Jan 28 00:55:29 2023: Train Epoch: 3 [6400 /60900 (11%)]	Loss: 191.279694 | Elapsed: 12.54s
01/28/2023 12:55:41 AM  [*] Sat Jan 28 00:55:41 2023: Train Epoch: 3 [12800/60900 (21%)]	Loss: 168.436859 | Elapsed: 12.45s
01/28/2023 12:55:54 AM  [*] Sat Jan 28 00:55:54 2023: Train Epoch: 3 [19200/60900 (32%)]	Loss: 159.165436 | Elapsed: 12.53s
01/28/2023 12:56:06 AM  [*] Sat Jan 28 00:56:06 2023: Train Epoch: 3 [25600/60900 (42%)]	Loss: 180.778595 | Elapsed: 12.35s
01/28/2023 12:56:19 AM  [*] Sat Jan 28 00:56:19 2023: Train Epoch: 3 [32000/60900 (53%)]	Loss: 176.856689 | Elapsed: 12.42s
01/28/2023 12:56:31 AM  [*] Sat Jan 28 00:56:31 2023: Train Epoch: 3 [38400/60900 (63%)]	Loss: 166.573181 | Elapsed: 12.49s
01/28/2023 12:56:44 AM  [*] Sat Jan 28 00:56:44 2023: Train Epoch: 3 [44800/60900 (74%)]	Loss: 182.329407 | Elapsed: 12.50s
01/28/2023 12:56:56 AM  [*] Sat Jan 28 00:56:56 2023: Train Epoch: 3 [51200/60900 (84%)]	Loss: 171.702835 | Elapsed: 12.44s
01/28/2023 12:57:08 AM  [*] Sat Jan 28 00:57:08 2023: Train Epoch: 3 [57600/60900 (95%)]	Loss: 188.601517 | Elapsed: 12.37s
01/28/2023 12:57:17 AM  [*] Sat Jan 28 00:57:17 2023:    3    | Tr.loss: 178.909842 | Elapsed:  120.77  s
01/28/2023 12:57:17 AM [!] Sat Jan 28 00:57:17 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_3_1674863837-model.torch
01/28/2023 12:57:17 AM  [*] Started epoch: 4
01/28/2023 12:57:18 AM  [*] Sat Jan 28 00:57:18 2023: Train Epoch: 4 [  0  /60900 (0 %)]	Loss: 168.604095 | Elapsed: 0.23s
01/28/2023 12:57:30 AM  [*] Sat Jan 28 00:57:30 2023: Train Epoch: 4 [6400 /60900 (11%)]	Loss: 188.837036 | Elapsed: 12.42s
01/28/2023 12:57:42 AM  [*] Sat Jan 28 00:57:42 2023: Train Epoch: 4 [12800/60900 (21%)]	Loss: 178.778900 | Elapsed: 12.23s
01/28/2023 12:57:55 AM  [*] Sat Jan 28 00:57:55 2023: Train Epoch: 4 [19200/60900 (32%)]	Loss: 172.111206 | Elapsed: 12.32s
01/28/2023 12:58:07 AM  [*] Sat Jan 28 00:58:07 2023: Train Epoch: 4 [25600/60900 (42%)]	Loss: 174.213165 | Elapsed: 12.26s
01/28/2023 12:58:19 AM  [*] Sat Jan 28 00:58:19 2023: Train Epoch: 4 [32000/60900 (53%)]	Loss: 190.605667 | Elapsed: 12.34s
01/28/2023 12:58:31 AM  [*] Sat Jan 28 00:58:31 2023: Train Epoch: 4 [38400/60900 (63%)]	Loss: 179.741547 | Elapsed: 12.27s
01/28/2023 12:58:44 AM  [*] Sat Jan 28 00:58:44 2023: Train Epoch: 4 [44800/60900 (74%)]	Loss: 170.542892 | Elapsed: 12.26s
01/28/2023 12:58:56 AM  [*] Sat Jan 28 00:58:56 2023: Train Epoch: 4 [51200/60900 (84%)]	Loss: 175.984283 | Elapsed: 12.30s
01/28/2023 12:59:08 AM  [*] Sat Jan 28 00:59:08 2023: Train Epoch: 4 [57600/60900 (95%)]	Loss: 155.758102 | Elapsed: 12.30s
01/28/2023 12:59:17 AM  [*] Sat Jan 28 00:59:17 2023:    4    | Tr.loss: 176.259950 | Elapsed:  119.20  s
01/28/2023 12:59:17 AM [!] Sat Jan 28 00:59:17 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_4_1674863957-model.torch
01/28/2023 12:59:17 AM  [*] Started epoch: 5
01/28/2023 12:59:17 AM  [*] Sat Jan 28 00:59:17 2023: Train Epoch: 5 [  0  /60900 (0 %)]	Loss: 166.090881 | Elapsed: 0.17s
01/28/2023 12:59:30 AM  [*] Sat Jan 28 00:59:30 2023: Train Epoch: 5 [6400 /60900 (11%)]	Loss: 159.686447 | Elapsed: 12.43s
01/28/2023 12:59:42 AM  [*] Sat Jan 28 00:59:42 2023: Train Epoch: 5 [12800/60900 (21%)]	Loss: 169.901733 | Elapsed: 12.28s
01/28/2023 12:59:54 AM  [*] Sat Jan 28 00:59:54 2023: Train Epoch: 5 [19200/60900 (32%)]	Loss: 146.669281 | Elapsed: 12.25s
01/28/2023 01:00:07 AM  [*] Sat Jan 28 01:00:07 2023: Train Epoch: 5 [25600/60900 (42%)]	Loss: 189.079102 | Elapsed: 12.41s
01/28/2023 01:00:19 AM  [*] Sat Jan 28 01:00:19 2023: Train Epoch: 5 [32000/60900 (53%)]	Loss: 173.371368 | Elapsed: 12.20s
01/28/2023 01:00:31 AM  [*] Sat Jan 28 01:00:31 2023: Train Epoch: 5 [38400/60900 (63%)]	Loss: 165.848816 | Elapsed: 12.32s
01/28/2023 01:00:43 AM  [*] Sat Jan 28 01:00:43 2023: Train Epoch: 5 [44800/60900 (74%)]	Loss: 165.882660 | Elapsed: 12.31s
01/28/2023 01:00:56 AM  [*] Sat Jan 28 01:00:56 2023: Train Epoch: 5 [51200/60900 (84%)]	Loss: 192.113174 | Elapsed: 12.21s
01/28/2023 01:01:08 AM  [*] Sat Jan 28 01:01:08 2023: Train Epoch: 5 [57600/60900 (95%)]	Loss: 188.873474 | Elapsed: 12.34s
01/28/2023 01:01:16 AM  [*] Sat Jan 28 01:01:16 2023:    5    | Tr.loss: 174.377660 | Elapsed:  119.01  s
01/28/2023 01:01:17 AM [!] Sat Jan 28 01:01:17 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_5_1674864076-model.torch
01/28/2023 01:01:17 AM  [*] Started epoch: 6
01/28/2023 01:01:17 AM  [*] Sat Jan 28 01:01:17 2023: Train Epoch: 6 [  0  /60900 (0 %)]	Loss: 188.349915 | Elapsed: 0.24s
01/28/2023 01:01:29 AM  [*] Sat Jan 28 01:01:29 2023: Train Epoch: 6 [6400 /60900 (11%)]	Loss: 186.247330 | Elapsed: 12.38s
01/28/2023 01:01:41 AM  [*] Sat Jan 28 01:01:41 2023: Train Epoch: 6 [12800/60900 (21%)]	Loss: 174.496460 | Elapsed: 12.25s
01/28/2023 01:01:54 AM  [*] Sat Jan 28 01:01:54 2023: Train Epoch: 6 [19200/60900 (32%)]	Loss: 158.123734 | Elapsed: 12.24s
01/28/2023 01:02:06 AM  [*] Sat Jan 28 01:02:06 2023: Train Epoch: 6 [25600/60900 (42%)]	Loss: 180.830719 | Elapsed: 12.27s
01/28/2023 01:02:18 AM  [*] Sat Jan 28 01:02:18 2023: Train Epoch: 6 [32000/60900 (53%)]	Loss: 171.842529 | Elapsed: 12.26s
01/28/2023 01:02:31 AM  [*] Sat Jan 28 01:02:31 2023: Train Epoch: 6 [38400/60900 (63%)]	Loss: 176.429581 | Elapsed: 12.43s
01/28/2023 01:02:43 AM  [*] Sat Jan 28 01:02:43 2023: Train Epoch: 6 [44800/60900 (74%)]	Loss: 178.112244 | Elapsed: 12.27s
01/28/2023 01:02:55 AM  [*] Sat Jan 28 01:02:55 2023: Train Epoch: 6 [51200/60900 (84%)]	Loss: 176.782928 | Elapsed: 12.30s
01/28/2023 01:03:07 AM  [*] Sat Jan 28 01:03:07 2023: Train Epoch: 6 [57600/60900 (95%)]	Loss: 169.495743 | Elapsed: 12.24s
01/28/2023 01:03:16 AM  [*] Sat Jan 28 01:03:16 2023:    6    | Tr.loss: 173.025047 | Elapsed:  118.98  s
01/28/2023 01:03:16 AM [!] Sat Jan 28 01:03:16 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_6_1674864196-model.torch
01/28/2023 01:03:16 AM  [*] Started epoch: 7
01/28/2023 01:03:16 AM  [*] Sat Jan 28 01:03:16 2023: Train Epoch: 7 [  0  /60900 (0 %)]	Loss: 164.467438 | Elapsed: 0.18s
01/28/2023 01:03:29 AM  [*] Sat Jan 28 01:03:29 2023: Train Epoch: 7 [6400 /60900 (11%)]	Loss: 184.514740 | Elapsed: 12.35s
01/28/2023 01:03:41 AM  [*] Sat Jan 28 01:03:41 2023: Train Epoch: 7 [12800/60900 (21%)]	Loss: 158.241455 | Elapsed: 12.32s
01/28/2023 01:03:53 AM  [*] Sat Jan 28 01:03:53 2023: Train Epoch: 7 [19200/60900 (32%)]	Loss: 169.931183 | Elapsed: 12.27s
01/28/2023 01:04:05 AM  [*] Sat Jan 28 01:04:05 2023: Train Epoch: 7 [25600/60900 (42%)]	Loss: 183.787537 | Elapsed: 12.27s
01/28/2023 01:04:18 AM  [*] Sat Jan 28 01:04:18 2023: Train Epoch: 7 [32000/60900 (53%)]	Loss: 188.304077 | Elapsed: 12.25s
01/28/2023 01:04:30 AM  [*] Sat Jan 28 01:04:30 2023: Train Epoch: 7 [38400/60900 (63%)]	Loss: 165.892258 | Elapsed: 12.32s
01/28/2023 01:04:42 AM  [*] Sat Jan 28 01:04:42 2023: Train Epoch: 7 [44800/60900 (74%)]	Loss: 170.940765 | Elapsed: 12.24s
01/28/2023 01:04:54 AM  [*] Sat Jan 28 01:04:54 2023: Train Epoch: 7 [51200/60900 (84%)]	Loss: 190.294418 | Elapsed: 12.28s
01/28/2023 01:05:07 AM  [*] Sat Jan 28 01:05:07 2023: Train Epoch: 7 [57600/60900 (95%)]	Loss: 170.386719 | Elapsed: 12.33s
01/28/2023 01:05:15 AM  [*] Sat Jan 28 01:05:15 2023:    7    | Tr.loss: 172.004174 | Elapsed:  118.89  s
01/28/2023 01:05:15 AM [!] Sat Jan 28 01:05:15 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_7_1674864315-model.torch
01/28/2023 01:05:15 AM  [*] Started epoch: 8
01/28/2023 01:05:16 AM  [*] Sat Jan 28 01:05:16 2023: Train Epoch: 8 [  0  /60900 (0 %)]	Loss: 164.823822 | Elapsed: 0.24s
01/28/2023 01:05:28 AM  [*] Sat Jan 28 01:05:28 2023: Train Epoch: 8 [6400 /60900 (11%)]	Loss: 154.525696 | Elapsed: 12.33s
01/28/2023 01:05:40 AM  [*] Sat Jan 28 01:05:40 2023: Train Epoch: 8 [12800/60900 (21%)]	Loss: 172.954315 | Elapsed: 12.38s
01/28/2023 01:05:53 AM  [*] Sat Jan 28 01:05:53 2023: Train Epoch: 8 [19200/60900 (32%)]	Loss: 186.220932 | Elapsed: 12.32s
01/28/2023 01:06:05 AM  [*] Sat Jan 28 01:06:05 2023: Train Epoch: 8 [25600/60900 (42%)]	Loss: 192.940247 | Elapsed: 12.29s
01/28/2023 01:06:17 AM  [*] Sat Jan 28 01:06:17 2023: Train Epoch: 8 [32000/60900 (53%)]	Loss: 158.372345 | Elapsed: 12.24s
01/28/2023 01:06:30 AM  [*] Sat Jan 28 01:06:30 2023: Train Epoch: 8 [38400/60900 (63%)]	Loss: 173.378204 | Elapsed: 12.36s
01/28/2023 01:06:42 AM  [*] Sat Jan 28 01:06:42 2023: Train Epoch: 8 [44800/60900 (74%)]	Loss: 201.236420 | Elapsed: 12.25s
01/28/2023 01:06:54 AM  [*] Sat Jan 28 01:06:54 2023: Train Epoch: 8 [51200/60900 (84%)]	Loss: 179.010468 | Elapsed: 12.38s
01/28/2023 01:07:06 AM  [*] Sat Jan 28 01:07:06 2023: Train Epoch: 8 [57600/60900 (95%)]	Loss: 180.729431 | Elapsed: 12.30s
01/28/2023 01:07:15 AM  [*] Sat Jan 28 01:07:15 2023:    8    | Tr.loss: 171.236304 | Elapsed:  119.21  s
01/28/2023 01:07:15 AM [!] Sat Jan 28 01:07:15 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_8_1674864435-model.torch
01/28/2023 01:07:15 AM  [*] Started epoch: 9
01/28/2023 01:07:15 AM  [*] Sat Jan 28 01:07:15 2023: Train Epoch: 9 [  0  /60900 (0 %)]	Loss: 163.459427 | Elapsed: 0.33s
01/28/2023 01:07:28 AM  [*] Sat Jan 28 01:07:28 2023: Train Epoch: 9 [6400 /60900 (11%)]	Loss: 174.060394 | Elapsed: 12.28s
01/28/2023 01:07:40 AM  [*] Sat Jan 28 01:07:40 2023: Train Epoch: 9 [12800/60900 (21%)]	Loss: 183.658386 | Elapsed: 12.26s
01/28/2023 01:07:52 AM  [*] Sat Jan 28 01:07:52 2023: Train Epoch: 9 [19200/60900 (32%)]	Loss: 157.010193 | Elapsed: 12.22s
01/28/2023 01:08:04 AM  [*] Sat Jan 28 01:08:04 2023: Train Epoch: 9 [25600/60900 (42%)]	Loss: 151.794662 | Elapsed: 12.35s
01/28/2023 01:08:17 AM  [*] Sat Jan 28 01:08:17 2023: Train Epoch: 9 [32000/60900 (53%)]	Loss: 190.105621 | Elapsed: 12.25s
01/28/2023 01:08:29 AM  [*] Sat Jan 28 01:08:29 2023: Train Epoch: 9 [38400/60900 (63%)]	Loss: 170.284592 | Elapsed: 12.27s
01/28/2023 01:08:41 AM  [*] Sat Jan 28 01:08:41 2023: Train Epoch: 9 [44800/60900 (74%)]	Loss: 166.190948 | Elapsed: 12.29s
01/28/2023 01:08:54 AM  [*] Sat Jan 28 01:08:54 2023: Train Epoch: 9 [51200/60900 (84%)]	Loss: 151.706940 | Elapsed: 12.28s
01/28/2023 01:09:06 AM  [*] Sat Jan 28 01:09:06 2023: Train Epoch: 9 [57600/60900 (95%)]	Loss: 180.788696 | Elapsed: 12.35s
01/28/2023 01:09:14 AM  [*] Sat Jan 28 01:09:14 2023:    9    | Tr.loss: 170.459533 | Elapsed:  119.16  s
01/28/2023 01:09:15 AM [!] Sat Jan 28 01:09:15 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_9_1674864554-model.torch
01/28/2023 01:09:15 AM  [*] Started epoch: 10
01/28/2023 01:09:15 AM  [*] Sat Jan 28 01:09:15 2023: Train Epoch: 10 [  0  /60900 (0 %)]	Loss: 176.611389 | Elapsed: 0.23s
01/28/2023 01:09:27 AM  [*] Sat Jan 28 01:09:27 2023: Train Epoch: 10 [6400 /60900 (11%)]	Loss: 195.930023 | Elapsed: 12.57s
01/28/2023 01:09:40 AM  [*] Sat Jan 28 01:09:40 2023: Train Epoch: 10 [12800/60900 (21%)]	Loss: 172.636353 | Elapsed: 12.61s
01/28/2023 01:09:53 AM  [*] Sat Jan 28 01:09:53 2023: Train Epoch: 10 [19200/60900 (32%)]	Loss: 155.579620 | Elapsed: 12.54s
01/28/2023 01:10:05 AM  [*] Sat Jan 28 01:10:05 2023: Train Epoch: 10 [25600/60900 (42%)]	Loss: 168.567398 | Elapsed: 12.67s
01/28/2023 01:10:18 AM  [*] Sat Jan 28 01:10:18 2023: Train Epoch: 10 [32000/60900 (53%)]	Loss: 151.290161 | Elapsed: 12.72s
01/28/2023 01:10:31 AM  [*] Sat Jan 28 01:10:31 2023: Train Epoch: 10 [38400/60900 (63%)]	Loss: 176.889801 | Elapsed: 12.54s
01/28/2023 01:10:43 AM  [*] Sat Jan 28 01:10:43 2023: Train Epoch: 10 [44800/60900 (74%)]	Loss: 170.474884 | Elapsed: 12.51s
01/28/2023 01:10:55 AM  [*] Sat Jan 28 01:10:55 2023: Train Epoch: 10 [51200/60900 (84%)]	Loss: 183.057587 | Elapsed: 12.35s
01/28/2023 01:11:08 AM  [*] Sat Jan 28 01:11:08 2023: Train Epoch: 10 [57600/60900 (95%)]	Loss: 168.960083 | Elapsed: 12.45s
01/28/2023 01:11:16 AM  [*] Sat Jan 28 01:11:16 2023:   10    | Tr.loss: 169.877466 | Elapsed:  121.48  s
01/28/2023 01:11:17 AM [!] Sat Jan 28 01:11:17 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_10_1674864676-model.torch
01/28/2023 01:11:17 AM  [*] Started epoch: 11
01/28/2023 01:11:17 AM  [*] Sat Jan 28 01:11:17 2023: Train Epoch: 11 [  0  /60900 (0 %)]	Loss: 172.005142 | Elapsed: 0.22s
01/28/2023 01:11:29 AM  [*] Sat Jan 28 01:11:29 2023: Train Epoch: 11 [6400 /60900 (11%)]	Loss: 165.074402 | Elapsed: 12.57s
01/28/2023 01:11:42 AM  [*] Sat Jan 28 01:11:42 2023: Train Epoch: 11 [12800/60900 (21%)]	Loss: 144.951294 | Elapsed: 12.48s
01/28/2023 01:11:55 AM  [*] Sat Jan 28 01:11:55 2023: Train Epoch: 11 [19200/60900 (32%)]	Loss: 185.618927 | Elapsed: 12.65s
01/28/2023 01:12:07 AM  [*] Sat Jan 28 01:12:07 2023: Train Epoch: 11 [25600/60900 (42%)]	Loss: 159.770691 | Elapsed: 12.45s
01/28/2023 01:12:17 AM [!] Learning rate: 2.5e-05
01/28/2023 01:12:19 AM  [*] Sat Jan 28 01:12:19 2023: Train Epoch: 11 [32000/60900 (53%)]	Loss: 181.443085 | Elapsed: 12.53s
01/28/2023 01:12:32 AM  [*] Sat Jan 28 01:12:32 2023: Train Epoch: 11 [38400/60900 (63%)]	Loss: 164.702026 | Elapsed: 12.53s
01/28/2023 01:12:45 AM  [*] Sat Jan 28 01:12:45 2023: Train Epoch: 11 [44800/60900 (74%)]	Loss: 181.231674 | Elapsed: 12.49s
01/28/2023 01:12:57 AM  [*] Sat Jan 28 01:12:57 2023: Train Epoch: 11 [51200/60900 (84%)]	Loss: 185.171555 | Elapsed: 12.56s
01/28/2023 01:13:10 AM  [*] Sat Jan 28 01:13:10 2023: Train Epoch: 11 [57600/60900 (95%)]	Loss: 185.107224 | Elapsed: 12.59s
01/28/2023 01:13:18 AM  [*] Sat Jan 28 01:13:18 2023:   11    | Tr.loss: 169.168699 | Elapsed:  121.33  s
01/28/2023 01:13:18 AM [!] Sat Jan 28 01:13:18 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_11_1674864798-model.torch
01/28/2023 01:13:18 AM  [*] Started epoch: 12
01/28/2023 01:13:19 AM  [*] Sat Jan 28 01:13:19 2023: Train Epoch: 12 [  0  /60900 (0 %)]	Loss: 171.362976 | Elapsed: 0.34s
01/28/2023 01:13:31 AM  [*] Sat Jan 28 01:13:31 2023: Train Epoch: 12 [6400 /60900 (11%)]	Loss: 172.623611 | Elapsed: 12.54s
01/28/2023 01:13:44 AM  [*] Sat Jan 28 01:13:44 2023: Train Epoch: 12 [12800/60900 (21%)]	Loss: 158.867065 | Elapsed: 12.64s
01/28/2023 01:13:56 AM  [*] Sat Jan 28 01:13:56 2023: Train Epoch: 12 [19200/60900 (32%)]	Loss: 174.221008 | Elapsed: 12.54s
01/28/2023 01:14:09 AM  [*] Sat Jan 28 01:14:09 2023: Train Epoch: 12 [25600/60900 (42%)]	Loss: 169.609634 | Elapsed: 12.48s
01/28/2023 01:14:21 AM  [*] Sat Jan 28 01:14:21 2023: Train Epoch: 12 [32000/60900 (53%)]	Loss: 164.703445 | Elapsed: 12.43s
01/28/2023 01:14:34 AM  [*] Sat Jan 28 01:14:34 2023: Train Epoch: 12 [38400/60900 (63%)]	Loss: 177.843689 | Elapsed: 12.47s
01/28/2023 01:14:46 AM  [*] Sat Jan 28 01:14:46 2023: Train Epoch: 12 [44800/60900 (74%)]	Loss: 176.959320 | Elapsed: 12.44s
01/28/2023 01:14:59 AM  [*] Sat Jan 28 01:14:59 2023: Train Epoch: 12 [51200/60900 (84%)]	Loss: 167.100922 | Elapsed: 12.40s
01/28/2023 01:15:11 AM  [*] Sat Jan 28 01:15:11 2023: Train Epoch: 12 [57600/60900 (95%)]	Loss: 169.655548 | Elapsed: 12.31s
01/28/2023 01:15:19 AM  [*] Sat Jan 28 01:15:19 2023:   12    | Tr.loss: 168.588175 | Elapsed:  120.62  s
01/28/2023 01:15:20 AM [!] Sat Jan 28 01:15:20 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_12_1674864919-model.torch
01/28/2023 01:15:20 AM  [*] Started epoch: 13
01/28/2023 01:15:20 AM  [*] Sat Jan 28 01:15:20 2023: Train Epoch: 13 [  0  /60900 (0 %)]	Loss: 159.927811 | Elapsed: 0.37s
01/28/2023 01:15:32 AM  [*] Sat Jan 28 01:15:32 2023: Train Epoch: 13 [6400 /60900 (11%)]	Loss: 168.336655 | Elapsed: 12.37s
01/28/2023 01:15:45 AM  [*] Sat Jan 28 01:15:45 2023: Train Epoch: 13 [12800/60900 (21%)]	Loss: 177.400269 | Elapsed: 12.51s
01/28/2023 01:15:57 AM  [*] Sat Jan 28 01:15:57 2023: Train Epoch: 13 [19200/60900 (32%)]	Loss: 161.573730 | Elapsed: 12.27s
01/28/2023 01:16:09 AM  [*] Sat Jan 28 01:16:09 2023: Train Epoch: 13 [25600/60900 (42%)]	Loss: 152.639511 | Elapsed: 12.22s
01/28/2023 01:16:22 AM  [*] Sat Jan 28 01:16:22 2023: Train Epoch: 13 [32000/60900 (53%)]	Loss: 185.857635 | Elapsed: 12.24s
01/28/2023 01:16:34 AM  [*] Sat Jan 28 01:16:34 2023: Train Epoch: 13 [38400/60900 (63%)]	Loss: 179.165482 | Elapsed: 12.31s
01/28/2023 01:16:46 AM  [*] Sat Jan 28 01:16:46 2023: Train Epoch: 13 [44800/60900 (74%)]	Loss: 177.928207 | Elapsed: 12.27s
01/28/2023 01:16:58 AM  [*] Sat Jan 28 01:16:58 2023: Train Epoch: 13 [51200/60900 (84%)]	Loss: 153.168884 | Elapsed: 12.33s
01/28/2023 01:17:11 AM  [*] Sat Jan 28 01:17:11 2023: Train Epoch: 13 [57600/60900 (95%)]	Loss: 174.500198 | Elapsed: 12.27s
01/28/2023 01:17:19 AM  [*] Sat Jan 28 01:17:19 2023:   13    | Tr.loss: 168.506459 | Elapsed:  119.21  s
01/28/2023 01:17:19 AM [!] Sat Jan 28 01:17:19 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_13_1674865039-model.torch
01/28/2023 01:17:19 AM  [*] Started epoch: 14
01/28/2023 01:17:19 AM  [*] Sat Jan 28 01:17:19 2023: Train Epoch: 14 [  0  /60900 (0 %)]	Loss: 171.006775 | Elapsed: 0.25s
01/28/2023 01:17:32 AM  [*] Sat Jan 28 01:17:32 2023: Train Epoch: 14 [6400 /60900 (11%)]	Loss: 166.329605 | Elapsed: 12.28s
01/28/2023 01:17:44 AM  [*] Sat Jan 28 01:17:44 2023: Train Epoch: 14 [12800/60900 (21%)]	Loss: 159.892365 | Elapsed: 12.39s
01/28/2023 01:17:56 AM  [*] Sat Jan 28 01:17:56 2023: Train Epoch: 14 [19200/60900 (32%)]	Loss: 157.463959 | Elapsed: 12.31s
01/28/2023 01:18:09 AM  [*] Sat Jan 28 01:18:09 2023: Train Epoch: 14 [25600/60900 (42%)]	Loss: 180.178970 | Elapsed: 12.30s
01/28/2023 01:18:21 AM  [*] Sat Jan 28 01:18:21 2023: Train Epoch: 14 [32000/60900 (53%)]	Loss: 159.123230 | Elapsed: 12.24s
01/28/2023 01:18:33 AM  [*] Sat Jan 28 01:18:33 2023: Train Epoch: 14 [38400/60900 (63%)]	Loss: 167.907104 | Elapsed: 12.28s
01/28/2023 01:18:45 AM  [*] Sat Jan 28 01:18:45 2023: Train Epoch: 14 [44800/60900 (74%)]	Loss: 165.099335 | Elapsed: 12.25s
01/28/2023 01:18:58 AM  [*] Sat Jan 28 01:18:58 2023: Train Epoch: 14 [51200/60900 (84%)]	Loss: 173.202621 | Elapsed: 12.35s
01/28/2023 01:19:10 AM  [*] Sat Jan 28 01:19:10 2023: Train Epoch: 14 [57600/60900 (95%)]	Loss: 178.683197 | Elapsed: 12.26s
01/28/2023 01:19:18 AM  [*] Sat Jan 28 01:19:18 2023:   14    | Tr.loss: 168.351022 | Elapsed:  119.00  s
01/28/2023 01:19:19 AM [!] Sat Jan 28 01:19:19 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_14_1674865158-model.torch
01/28/2023 01:19:19 AM  [*] Started epoch: 15
01/28/2023 01:19:19 AM  [*] Sat Jan 28 01:19:19 2023: Train Epoch: 15 [  0  /60900 (0 %)]	Loss: 138.858704 | Elapsed: 0.17s
01/28/2023 01:19:31 AM  [*] Sat Jan 28 01:19:31 2023: Train Epoch: 15 [6400 /60900 (11%)]	Loss: 178.434326 | Elapsed: 12.38s
01/28/2023 01:19:43 AM  [*] Sat Jan 28 01:19:43 2023: Train Epoch: 15 [12800/60900 (21%)]	Loss: 194.059677 | Elapsed: 12.32s
01/28/2023 01:19:56 AM  [*] Sat Jan 28 01:19:56 2023: Train Epoch: 15 [19200/60900 (32%)]	Loss: 160.424103 | Elapsed: 12.25s
01/28/2023 01:20:08 AM  [*] Sat Jan 28 01:20:08 2023: Train Epoch: 15 [25600/60900 (42%)]	Loss: 156.597168 | Elapsed: 12.33s
01/28/2023 01:20:20 AM  [*] Sat Jan 28 01:20:20 2023: Train Epoch: 15 [32000/60900 (53%)]	Loss: 145.382202 | Elapsed: 12.24s
01/28/2023 01:20:33 AM  [*] Sat Jan 28 01:20:33 2023: Train Epoch: 15 [38400/60900 (63%)]	Loss: 172.705994 | Elapsed: 12.34s
01/28/2023 01:20:45 AM  [*] Sat Jan 28 01:20:45 2023: Train Epoch: 15 [44800/60900 (74%)]	Loss: 152.905014 | Elapsed: 12.38s
01/28/2023 01:20:57 AM  [*] Sat Jan 28 01:20:57 2023: Train Epoch: 15 [51200/60900 (84%)]	Loss: 175.343124 | Elapsed: 12.34s
01/28/2023 01:21:10 AM  [*] Sat Jan 28 01:21:10 2023: Train Epoch: 15 [57600/60900 (95%)]	Loss: 184.291077 | Elapsed: 12.34s
01/28/2023 01:21:18 AM  [*] Sat Jan 28 01:21:18 2023:   15    | Tr.loss: 168.185599 | Elapsed:  119.11  s
01/28/2023 01:21:18 AM [!] Sat Jan 28 01:21:18 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_15_1674865278-model.torch
01/28/2023 01:21:18 AM  [*] Started epoch: 16
01/28/2023 01:21:18 AM  [*] Sat Jan 28 01:21:18 2023: Train Epoch: 16 [  0  /60900 (0 %)]	Loss: 175.140320 | Elapsed: 0.30s
01/28/2023 01:21:31 AM  [*] Sat Jan 28 01:21:31 2023: Train Epoch: 16 [6400 /60900 (11%)]	Loss: 176.674103 | Elapsed: 12.25s
01/28/2023 01:21:43 AM  [*] Sat Jan 28 01:21:43 2023: Train Epoch: 16 [12800/60900 (21%)]	Loss: 185.079071 | Elapsed: 12.29s
01/28/2023 01:21:55 AM  [*] Sat Jan 28 01:21:55 2023: Train Epoch: 16 [19200/60900 (32%)]	Loss: 150.919235 | Elapsed: 12.36s
01/28/2023 01:22:08 AM  [*] Sat Jan 28 01:22:08 2023: Train Epoch: 16 [25600/60900 (42%)]	Loss: 172.889053 | Elapsed: 12.35s
01/28/2023 01:22:20 AM  [*] Sat Jan 28 01:22:20 2023: Train Epoch: 16 [32000/60900 (53%)]	Loss: 157.407944 | Elapsed: 12.26s
01/28/2023 01:22:32 AM  [*] Sat Jan 28 01:22:32 2023: Train Epoch: 16 [38400/60900 (63%)]	Loss: 158.528732 | Elapsed: 12.37s
01/28/2023 01:22:45 AM  [*] Sat Jan 28 01:22:45 2023: Train Epoch: 16 [44800/60900 (74%)]	Loss: 182.382919 | Elapsed: 12.29s
01/28/2023 01:22:57 AM  [*] Sat Jan 28 01:22:57 2023: Train Epoch: 16 [51200/60900 (84%)]	Loss: 144.611877 | Elapsed: 12.35s
01/28/2023 01:23:09 AM  [*] Sat Jan 28 01:23:09 2023: Train Epoch: 16 [57600/60900 (95%)]	Loss: 147.915558 | Elapsed: 12.40s
01/28/2023 01:23:17 AM  [*] Sat Jan 28 01:23:17 2023:   16    | Tr.loss: 168.179776 | Elapsed:  119.30  s
01/28/2023 01:23:18 AM [!] Sat Jan 28 01:23:18 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_16_1674865397-model.torch
01/28/2023 01:23:18 AM  [*] Started epoch: 17
01/28/2023 01:23:18 AM  [*] Sat Jan 28 01:23:18 2023: Train Epoch: 17 [  0  /60900 (0 %)]	Loss: 172.054443 | Elapsed: 0.23s
01/28/2023 01:23:30 AM  [*] Sat Jan 28 01:23:30 2023: Train Epoch: 17 [6400 /60900 (11%)]	Loss: 148.997253 | Elapsed: 12.32s
01/28/2023 01:23:43 AM  [*] Sat Jan 28 01:23:43 2023: Train Epoch: 17 [12800/60900 (21%)]	Loss: 156.813065 | Elapsed: 12.33s
01/28/2023 01:23:55 AM  [*] Sat Jan 28 01:23:55 2023: Train Epoch: 17 [19200/60900 (32%)]	Loss: 173.289764 | Elapsed: 12.27s
01/28/2023 01:24:07 AM  [*] Sat Jan 28 01:24:07 2023: Train Epoch: 17 [25600/60900 (42%)]	Loss: 174.531815 | Elapsed: 12.27s
01/28/2023 01:24:20 AM  [*] Sat Jan 28 01:24:20 2023: Train Epoch: 17 [32000/60900 (53%)]	Loss: 167.682861 | Elapsed: 12.26s
01/28/2023 01:24:32 AM  [*] Sat Jan 28 01:24:32 2023: Train Epoch: 17 [38400/60900 (63%)]	Loss: 150.310760 | Elapsed: 12.26s
01/28/2023 01:24:44 AM  [*] Sat Jan 28 01:24:44 2023: Train Epoch: 17 [44800/60900 (74%)]	Loss: 166.123154 | Elapsed: 12.32s
01/28/2023 01:24:56 AM  [*] Sat Jan 28 01:24:56 2023: Train Epoch: 17 [51200/60900 (84%)]	Loss: 178.725494 | Elapsed: 12.24s
01/28/2023 01:25:09 AM  [*] Sat Jan 28 01:25:09 2023: Train Epoch: 17 [57600/60900 (95%)]	Loss: 174.329498 | Elapsed: 12.24s
01/28/2023 01:25:17 AM  [*] Sat Jan 28 01:25:17 2023:   17    | Tr.loss: 167.980333 | Elapsed:  118.80  s
01/28/2023 01:25:17 AM [!] Sat Jan 28 01:25:17 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_17_1674865517-model.torch
01/28/2023 01:25:17 AM  [*] Started epoch: 18
01/28/2023 01:25:17 AM  [*] Sat Jan 28 01:25:17 2023: Train Epoch: 18 [  0  /60900 (0 %)]	Loss: 168.926224 | Elapsed: 0.17s
01/28/2023 01:25:30 AM  [*] Sat Jan 28 01:25:30 2023: Train Epoch: 18 [6400 /60900 (11%)]	Loss: 170.096710 | Elapsed: 12.33s
01/28/2023 01:25:42 AM  [*] Sat Jan 28 01:25:42 2023: Train Epoch: 18 [12800/60900 (21%)]	Loss: 165.844208 | Elapsed: 12.32s
01/28/2023 01:25:54 AM  [*] Sat Jan 28 01:25:54 2023: Train Epoch: 18 [19200/60900 (32%)]	Loss: 165.038284 | Elapsed: 12.35s
01/28/2023 01:26:07 AM  [*] Sat Jan 28 01:26:07 2023: Train Epoch: 18 [25600/60900 (42%)]	Loss: 189.995621 | Elapsed: 12.28s
01/28/2023 01:26:19 AM  [*] Sat Jan 28 01:26:19 2023: Train Epoch: 18 [32000/60900 (53%)]	Loss: 162.357269 | Elapsed: 12.28s
01/28/2023 01:26:31 AM  [*] Sat Jan 28 01:26:31 2023: Train Epoch: 18 [38400/60900 (63%)]	Loss: 166.119797 | Elapsed: 12.26s
01/28/2023 01:26:44 AM  [*] Sat Jan 28 01:26:44 2023: Train Epoch: 18 [44800/60900 (74%)]	Loss: 166.923737 | Elapsed: 12.32s
01/28/2023 01:26:56 AM  [*] Sat Jan 28 01:26:56 2023: Train Epoch: 18 [51200/60900 (84%)]	Loss: 189.367645 | Elapsed: 12.21s
01/28/2023 01:27:08 AM  [*] Sat Jan 28 01:27:08 2023: Train Epoch: 18 [57600/60900 (95%)]	Loss: 158.240784 | Elapsed: 12.30s
01/28/2023 01:27:16 AM  [*] Sat Jan 28 01:27:16 2023:   18    | Tr.loss: 168.041579 | Elapsed:  118.83  s
01/28/2023 01:27:16 AM [!] Sat Jan 28 01:27:16 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_18_1674865636-model.torch
01/28/2023 01:27:16 AM  [*] Started epoch: 19
01/28/2023 01:27:17 AM  [*] Sat Jan 28 01:27:17 2023: Train Epoch: 19 [  0  /60900 (0 %)]	Loss: 157.471512 | Elapsed: 0.20s
01/28/2023 01:27:29 AM  [*] Sat Jan 28 01:27:29 2023: Train Epoch: 19 [6400 /60900 (11%)]	Loss: 168.996674 | Elapsed: 12.38s
01/28/2023 01:27:41 AM  [*] Sat Jan 28 01:27:41 2023: Train Epoch: 19 [12800/60900 (21%)]	Loss: 193.814468 | Elapsed: 12.26s
01/28/2023 01:27:54 AM  [*] Sat Jan 28 01:27:54 2023: Train Epoch: 19 [19200/60900 (32%)]	Loss: 155.143997 | Elapsed: 12.27s
01/28/2023 01:28:06 AM  [*] Sat Jan 28 01:28:06 2023: Train Epoch: 19 [25600/60900 (42%)]	Loss: 167.919113 | Elapsed: 12.20s
01/28/2023 01:28:18 AM  [*] Sat Jan 28 01:28:18 2023: Train Epoch: 19 [32000/60900 (53%)]	Loss: 155.807617 | Elapsed: 12.26s
01/28/2023 01:28:30 AM  [*] Sat Jan 28 01:28:30 2023: Train Epoch: 19 [38400/60900 (63%)]	Loss: 170.515945 | Elapsed: 12.29s
01/28/2023 01:28:43 AM  [*] Sat Jan 28 01:28:43 2023: Train Epoch: 19 [44800/60900 (74%)]	Loss: 167.489288 | Elapsed: 12.26s
01/28/2023 01:28:55 AM  [*] Sat Jan 28 01:28:55 2023: Train Epoch: 19 [51200/60900 (84%)]	Loss: 177.938782 | Elapsed: 12.25s
01/28/2023 01:29:07 AM  [*] Sat Jan 28 01:29:07 2023: Train Epoch: 19 [57600/60900 (95%)]	Loss: 161.174133 | Elapsed: 12.24s
01/28/2023 01:29:15 AM  [*] Sat Jan 28 01:29:15 2023:   19    | Tr.loss: 167.942651 | Elapsed:  118.60  s
01/28/2023 01:29:16 AM [!] Sat Jan 28 01:29:16 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_19_1674865755-model.torch
01/28/2023 01:29:16 AM  [*] Started epoch: 20
01/28/2023 01:29:16 AM  [*] Sat Jan 28 01:29:16 2023: Train Epoch: 20 [  0  /60900 (0 %)]	Loss: 174.171478 | Elapsed: 0.28s
01/28/2023 01:29:28 AM  [*] Sat Jan 28 01:29:28 2023: Train Epoch: 20 [6400 /60900 (11%)]	Loss: 163.779144 | Elapsed: 12.36s
01/28/2023 01:29:40 AM  [*] Sat Jan 28 01:29:40 2023: Train Epoch: 20 [12800/60900 (21%)]	Loss: 150.204163 | Elapsed: 12.25s
01/28/2023 01:29:53 AM  [*] Sat Jan 28 01:29:53 2023: Train Epoch: 20 [19200/60900 (32%)]	Loss: 171.336700 | Elapsed: 12.28s
01/28/2023 01:30:05 AM  [*] Sat Jan 28 01:30:05 2023: Train Epoch: 20 [25600/60900 (42%)]	Loss: 158.159668 | Elapsed: 12.27s
01/28/2023 01:30:17 AM  [*] Sat Jan 28 01:30:17 2023: Train Epoch: 20 [32000/60900 (53%)]	Loss: 172.302933 | Elapsed: 12.30s
01/28/2023 01:30:30 AM  [*] Sat Jan 28 01:30:30 2023: Train Epoch: 20 [38400/60900 (63%)]	Loss: 164.165039 | Elapsed: 12.26s
01/28/2023 01:30:42 AM  [*] Sat Jan 28 01:30:42 2023: Train Epoch: 20 [44800/60900 (74%)]	Loss: 181.253784 | Elapsed: 12.31s
01/28/2023 01:30:54 AM  [*] Sat Jan 28 01:30:54 2023: Train Epoch: 20 [51200/60900 (84%)]	Loss: 163.620743 | Elapsed: 12.23s
01/28/2023 01:31:06 AM  [*] Sat Jan 28 01:31:06 2023: Train Epoch: 20 [57600/60900 (95%)]	Loss: 168.663116 | Elapsed: 12.37s
01/28/2023 01:31:15 AM  [*] Sat Jan 28 01:31:15 2023:   20    | Tr.loss: 167.816911 | Elapsed:  119.03  s
01/28/2023 01:31:15 AM [!] Sat Jan 28 01:31:15 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_20_1674865875-model.torch
01/28/2023 01:31:15 AM  [*] Started epoch: 21
01/28/2023 01:31:15 AM  [*] Sat Jan 28 01:31:15 2023: Train Epoch: 21 [  0  /60900 (0 %)]	Loss: 162.193909 | Elapsed: 0.23s
01/28/2023 01:31:28 AM  [*] Sat Jan 28 01:31:28 2023: Train Epoch: 21 [6400 /60900 (11%)]	Loss: 163.729538 | Elapsed: 12.52s
01/28/2023 01:31:40 AM  [*] Sat Jan 28 01:31:40 2023: Train Epoch: 21 [12800/60900 (21%)]	Loss: 180.049194 | Elapsed: 12.25s
01/28/2023 01:31:52 AM  [*] Sat Jan 28 01:31:52 2023: Train Epoch: 21 [19200/60900 (32%)]	Loss: 145.633591 | Elapsed: 12.34s
01/28/2023 01:32:05 AM  [*] Sat Jan 28 01:32:05 2023: Train Epoch: 21 [25600/60900 (42%)]	Loss: 214.096344 | Elapsed: 12.31s
01/28/2023 01:32:17 AM  [*] Sat Jan 28 01:32:17 2023: Train Epoch: 21 [32000/60900 (53%)]	Loss: 158.670410 | Elapsed: 12.33s
01/28/2023 01:32:29 AM  [*] Sat Jan 28 01:32:29 2023: Train Epoch: 21 [38400/60900 (63%)]	Loss: 178.917358 | Elapsed: 12.29s
01/28/2023 01:32:42 AM  [*] Sat Jan 28 01:32:42 2023: Train Epoch: 21 [44800/60900 (74%)]	Loss: 151.618805 | Elapsed: 12.25s
01/28/2023 01:32:54 AM  [*] Sat Jan 28 01:32:54 2023: Train Epoch: 21 [51200/60900 (84%)]	Loss: 180.740631 | Elapsed: 12.27s
01/28/2023 01:33:06 AM  [*] Sat Jan 28 01:33:06 2023: Train Epoch: 21 [57600/60900 (95%)]	Loss: 189.013245 | Elapsed: 12.24s
01/28/2023 01:33:14 AM  [*] Sat Jan 28 01:33:14 2023:   21    | Tr.loss: 167.760033 | Elapsed:  119.04  s
01/28/2023 01:33:15 AM [!] Sat Jan 28 01:33:15 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_21_1674865994-model.torch
01/28/2023 01:33:15 AM  [*] Started epoch: 22
01/28/2023 01:33:15 AM  [*] Sat Jan 28 01:33:15 2023: Train Epoch: 22 [  0  /60900 (0 %)]	Loss: 150.841690 | Elapsed: 0.21s
01/28/2023 01:33:16 AM [!] Learning rate: 2.5e-06
01/28/2023 01:33:27 AM  [*] Sat Jan 28 01:33:27 2023: Train Epoch: 22 [6400 /60900 (11%)]	Loss: 163.931274 | Elapsed: 12.31s
01/28/2023 01:33:39 AM  [*] Sat Jan 28 01:33:39 2023: Train Epoch: 22 [12800/60900 (21%)]	Loss: 169.512207 | Elapsed: 12.22s
01/28/2023 01:33:52 AM  [*] Sat Jan 28 01:33:52 2023: Train Epoch: 22 [19200/60900 (32%)]	Loss: 160.498993 | Elapsed: 12.36s
01/28/2023 01:34:04 AM  [*] Sat Jan 28 01:34:04 2023: Train Epoch: 22 [25600/60900 (42%)]	Loss: 167.329620 | Elapsed: 12.31s
01/28/2023 01:34:16 AM  [*] Sat Jan 28 01:34:16 2023: Train Epoch: 22 [32000/60900 (53%)]	Loss: 154.413727 | Elapsed: 12.38s
01/28/2023 01:34:29 AM  [*] Sat Jan 28 01:34:29 2023: Train Epoch: 22 [38400/60900 (63%)]	Loss: 165.555435 | Elapsed: 12.27s
01/28/2023 01:34:41 AM  [*] Sat Jan 28 01:34:41 2023: Train Epoch: 22 [44800/60900 (74%)]	Loss: 159.704330 | Elapsed: 12.28s
01/28/2023 01:34:53 AM  [*] Sat Jan 28 01:34:53 2023: Train Epoch: 22 [51200/60900 (84%)]	Loss: 173.009460 | Elapsed: 12.27s
01/28/2023 01:35:05 AM  [*] Sat Jan 28 01:35:05 2023: Train Epoch: 22 [57600/60900 (95%)]	Loss: 184.711060 | Elapsed: 12.25s
01/28/2023 01:35:13 AM  [*] Sat Jan 28 01:35:13 2023:   22    | Tr.loss: 167.659245 | Elapsed:  118.84  s
01/28/2023 01:35:14 AM [!] Sat Jan 28 01:35:14 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_22_1674866113-model.torch
01/28/2023 01:35:14 AM  [*] Started epoch: 23
01/28/2023 01:35:14 AM  [*] Sat Jan 28 01:35:14 2023: Train Epoch: 23 [  0  /60900 (0 %)]	Loss: 166.121765 | Elapsed: 0.18s
01/28/2023 01:35:26 AM  [*] Sat Jan 28 01:35:26 2023: Train Epoch: 23 [6400 /60900 (11%)]	Loss: 162.523483 | Elapsed: 12.39s
01/28/2023 01:35:39 AM  [*] Sat Jan 28 01:35:39 2023: Train Epoch: 23 [12800/60900 (21%)]	Loss: 154.946808 | Elapsed: 12.31s
01/28/2023 01:35:51 AM  [*] Sat Jan 28 01:35:51 2023: Train Epoch: 23 [19200/60900 (32%)]	Loss: 164.028015 | Elapsed: 12.32s
01/28/2023 01:36:03 AM  [*] Sat Jan 28 01:36:03 2023: Train Epoch: 23 [25600/60900 (42%)]	Loss: 168.886871 | Elapsed: 12.28s
01/28/2023 01:36:16 AM  [*] Sat Jan 28 01:36:16 2023: Train Epoch: 23 [32000/60900 (53%)]	Loss: 165.385101 | Elapsed: 12.30s
01/28/2023 01:36:28 AM  [*] Sat Jan 28 01:36:28 2023: Train Epoch: 23 [38400/60900 (63%)]	Loss: 175.285751 | Elapsed: 12.37s
01/28/2023 01:36:40 AM  [*] Sat Jan 28 01:36:40 2023: Train Epoch: 23 [44800/60900 (74%)]	Loss: 163.958099 | Elapsed: 12.26s
01/28/2023 01:36:53 AM  [*] Sat Jan 28 01:36:53 2023: Train Epoch: 23 [51200/60900 (84%)]	Loss: 166.201248 | Elapsed: 12.26s
01/28/2023 01:37:05 AM  [*] Sat Jan 28 01:37:05 2023: Train Epoch: 23 [57600/60900 (95%)]	Loss: 167.941650 | Elapsed: 12.29s
01/28/2023 01:37:13 AM  [*] Sat Jan 28 01:37:13 2023:   23    | Tr.loss: 167.633224 | Elapsed:  119.01  s
01/28/2023 01:37:13 AM [!] Sat Jan 28 01:37:13 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_23_1674866233-model.torch
01/28/2023 01:37:13 AM  [*] Started epoch: 24
01/28/2023 01:37:14 AM  [*] Sat Jan 28 01:37:14 2023: Train Epoch: 24 [  0  /60900 (0 %)]	Loss: 160.005768 | Elapsed: 0.34s
01/28/2023 01:37:26 AM  [*] Sat Jan 28 01:37:26 2023: Train Epoch: 24 [6400 /60900 (11%)]	Loss: 178.595367 | Elapsed: 12.32s
01/28/2023 01:37:38 AM  [*] Sat Jan 28 01:37:38 2023: Train Epoch: 24 [12800/60900 (21%)]	Loss: 163.646698 | Elapsed: 12.32s
01/28/2023 01:37:51 AM  [*] Sat Jan 28 01:37:51 2023: Train Epoch: 24 [19200/60900 (32%)]	Loss: 164.937683 | Elapsed: 12.35s
01/28/2023 01:38:03 AM  [*] Sat Jan 28 01:38:03 2023: Train Epoch: 24 [25600/60900 (42%)]	Loss: 167.007507 | Elapsed: 12.26s
01/28/2023 01:38:15 AM  [*] Sat Jan 28 01:38:15 2023: Train Epoch: 24 [32000/60900 (53%)]	Loss: 167.510620 | Elapsed: 12.27s
01/28/2023 01:38:27 AM  [*] Sat Jan 28 01:38:27 2023: Train Epoch: 24 [38400/60900 (63%)]	Loss: 180.112228 | Elapsed: 12.30s
01/28/2023 01:38:40 AM  [*] Sat Jan 28 01:38:40 2023: Train Epoch: 24 [44800/60900 (74%)]	Loss: 169.307129 | Elapsed: 12.23s
01/28/2023 01:38:52 AM  [*] Sat Jan 28 01:38:52 2023: Train Epoch: 24 [51200/60900 (84%)]	Loss: 176.731232 | Elapsed: 12.40s
01/28/2023 01:39:04 AM  [*] Sat Jan 28 01:39:04 2023: Train Epoch: 24 [57600/60900 (95%)]	Loss: 156.212631 | Elapsed: 12.22s
01/28/2023 01:39:12 AM  [*] Sat Jan 28 01:39:12 2023:   24    | Tr.loss: 167.634469 | Elapsed:  119.08  s
01/28/2023 01:39:13 AM [!] Sat Jan 28 01:39:13 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_24_1674866352-model.torch
01/28/2023 01:39:13 AM  [*] Started epoch: 25
01/28/2023 01:39:13 AM  [*] Sat Jan 28 01:39:13 2023: Train Epoch: 25 [  0  /60900 (0 %)]	Loss: 193.459198 | Elapsed: 0.17s
01/28/2023 01:39:25 AM  [*] Sat Jan 28 01:39:25 2023: Train Epoch: 25 [6400 /60900 (11%)]	Loss: 168.213165 | Elapsed: 12.42s
01/28/2023 01:39:38 AM  [*] Sat Jan 28 01:39:38 2023: Train Epoch: 25 [12800/60900 (21%)]	Loss: 159.353409 | Elapsed: 12.41s
01/28/2023 01:39:50 AM  [*] Sat Jan 28 01:39:50 2023: Train Epoch: 25 [19200/60900 (32%)]	Loss: 183.781006 | Elapsed: 12.45s
01/28/2023 01:40:03 AM  [*] Sat Jan 28 01:40:03 2023: Train Epoch: 25 [25600/60900 (42%)]	Loss: 159.075287 | Elapsed: 12.46s
01/28/2023 01:40:15 AM  [*] Sat Jan 28 01:40:15 2023: Train Epoch: 25 [32000/60900 (53%)]	Loss: 182.120743 | Elapsed: 12.28s
01/28/2023 01:40:27 AM  [*] Sat Jan 28 01:40:27 2023: Train Epoch: 25 [38400/60900 (63%)]	Loss: 178.490875 | Elapsed: 12.27s
01/28/2023 01:40:40 AM  [*] Sat Jan 28 01:40:40 2023: Train Epoch: 25 [44800/60900 (74%)]	Loss: 166.156570 | Elapsed: 12.25s
01/28/2023 01:40:52 AM  [*] Sat Jan 28 01:40:52 2023: Train Epoch: 25 [51200/60900 (84%)]	Loss: 153.230103 | Elapsed: 12.35s
01/28/2023 01:41:04 AM  [*] Sat Jan 28 01:41:04 2023: Train Epoch: 25 [57600/60900 (95%)]	Loss: 162.048691 | Elapsed: 12.27s
01/28/2023 01:41:12 AM  [*] Sat Jan 28 01:41:12 2023:   25    | Tr.loss: 167.631569 | Elapsed:  119.43  s
01/28/2023 01:41:13 AM [!] Sat Jan 28 01:41:13 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_25_1674866472-model.torch
01/28/2023 01:41:13 AM  [*] Started epoch: 26
01/28/2023 01:41:13 AM  [*] Sat Jan 28 01:41:13 2023: Train Epoch: 26 [  0  /60900 (0 %)]	Loss: 161.679428 | Elapsed: 0.17s
01/28/2023 01:41:25 AM  [*] Sat Jan 28 01:41:25 2023: Train Epoch: 26 [6400 /60900 (11%)]	Loss: 174.518585 | Elapsed: 12.33s
01/28/2023 01:41:38 AM  [*] Sat Jan 28 01:41:38 2023: Train Epoch: 26 [12800/60900 (21%)]	Loss: 169.369537 | Elapsed: 12.31s
01/28/2023 01:41:50 AM  [*] Sat Jan 28 01:41:50 2023: Train Epoch: 26 [19200/60900 (32%)]	Loss: 173.735779 | Elapsed: 12.39s
01/28/2023 01:42:02 AM  [*] Sat Jan 28 01:42:02 2023: Train Epoch: 26 [25600/60900 (42%)]	Loss: 177.474564 | Elapsed: 12.31s
01/28/2023 01:42:15 AM  [*] Sat Jan 28 01:42:15 2023: Train Epoch: 26 [32000/60900 (53%)]	Loss: 158.768066 | Elapsed: 12.24s
01/28/2023 01:42:27 AM  [*] Sat Jan 28 01:42:27 2023: Train Epoch: 26 [38400/60900 (63%)]	Loss: 163.809631 | Elapsed: 12.28s
01/28/2023 01:42:39 AM  [*] Sat Jan 28 01:42:39 2023: Train Epoch: 26 [44800/60900 (74%)]	Loss: 154.243256 | Elapsed: 12.21s
01/28/2023 01:42:51 AM  [*] Sat Jan 28 01:42:51 2023: Train Epoch: 26 [51200/60900 (84%)]	Loss: 180.151733 | Elapsed: 12.29s
01/28/2023 01:43:04 AM  [*] Sat Jan 28 01:43:04 2023: Train Epoch: 26 [57600/60900 (95%)]	Loss: 159.876007 | Elapsed: 12.23s
01/28/2023 01:43:12 AM  [*] Sat Jan 28 01:43:12 2023:   26    | Tr.loss: 167.621445 | Elapsed:  118.87  s
01/28/2023 01:43:12 AM [!] Sat Jan 28 01:43:12 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_26_1674866592-model.torch
01/28/2023 01:43:12 AM  [*] Started epoch: 27
01/28/2023 01:43:12 AM  [*] Sat Jan 28 01:43:12 2023: Train Epoch: 27 [  0  /60900 (0 %)]	Loss: 162.607788 | Elapsed: 0.17s
01/28/2023 01:43:25 AM  [*] Sat Jan 28 01:43:25 2023: Train Epoch: 27 [6400 /60900 (11%)]	Loss: 194.430054 | Elapsed: 12.36s
01/28/2023 01:43:37 AM  [*] Sat Jan 28 01:43:37 2023: Train Epoch: 27 [12800/60900 (21%)]	Loss: 173.224411 | Elapsed: 12.34s
01/28/2023 01:43:49 AM  [*] Sat Jan 28 01:43:49 2023: Train Epoch: 27 [19200/60900 (32%)]	Loss: 162.752563 | Elapsed: 12.23s
01/28/2023 01:44:02 AM  [*] Sat Jan 28 01:44:02 2023: Train Epoch: 27 [25600/60900 (42%)]	Loss: 175.107269 | Elapsed: 12.32s
01/28/2023 01:44:14 AM  [*] Sat Jan 28 01:44:14 2023: Train Epoch: 27 [32000/60900 (53%)]	Loss: 153.609131 | Elapsed: 12.33s
01/28/2023 01:44:26 AM  [*] Sat Jan 28 01:44:26 2023: Train Epoch: 27 [38400/60900 (63%)]	Loss: 177.047760 | Elapsed: 12.28s
01/28/2023 01:44:38 AM  [*] Sat Jan 28 01:44:38 2023: Train Epoch: 27 [44800/60900 (74%)]	Loss: 162.674591 | Elapsed: 12.21s
01/28/2023 01:44:51 AM  [*] Sat Jan 28 01:44:51 2023: Train Epoch: 27 [51200/60900 (84%)]	Loss: 185.385651 | Elapsed: 12.32s
01/28/2023 01:45:03 AM  [*] Sat Jan 28 01:45:03 2023: Train Epoch: 27 [57600/60900 (95%)]	Loss: 158.725433 | Elapsed: 12.28s
01/28/2023 01:45:11 AM  [*] Sat Jan 28 01:45:11 2023:   27    | Tr.loss: 167.610421 | Elapsed:  118.92  s
01/28/2023 01:45:11 AM [!] Sat Jan 28 01:45:11 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_27_1674866711-model.torch
01/28/2023 01:45:11 AM  [*] Started epoch: 28
01/28/2023 01:45:12 AM  [*] Sat Jan 28 01:45:12 2023: Train Epoch: 28 [  0  /60900 (0 %)]	Loss: 153.473877 | Elapsed: 0.21s
01/28/2023 01:45:24 AM  [*] Sat Jan 28 01:45:24 2023: Train Epoch: 28 [6400 /60900 (11%)]	Loss: 160.289597 | Elapsed: 12.38s
01/28/2023 01:45:36 AM  [*] Sat Jan 28 01:45:36 2023: Train Epoch: 28 [12800/60900 (21%)]	Loss: 156.136139 | Elapsed: 12.35s
01/28/2023 01:45:49 AM  [*] Sat Jan 28 01:45:49 2023: Train Epoch: 28 [19200/60900 (32%)]	Loss: 143.063965 | Elapsed: 12.26s
01/28/2023 01:46:01 AM  [*] Sat Jan 28 01:46:01 2023: Train Epoch: 28 [25600/60900 (42%)]	Loss: 166.201538 | Elapsed: 12.27s
01/28/2023 01:46:13 AM  [*] Sat Jan 28 01:46:13 2023: Train Epoch: 28 [32000/60900 (53%)]	Loss: 177.280411 | Elapsed: 12.21s
01/28/2023 01:46:25 AM  [*] Sat Jan 28 01:46:25 2023: Train Epoch: 28 [38400/60900 (63%)]	Loss: 179.154922 | Elapsed: 12.22s
01/28/2023 01:46:38 AM  [*] Sat Jan 28 01:46:38 2023: Train Epoch: 28 [44800/60900 (74%)]	Loss: 158.916626 | Elapsed: 12.33s
01/28/2023 01:46:50 AM  [*] Sat Jan 28 01:46:50 2023: Train Epoch: 28 [51200/60900 (84%)]	Loss: 177.447845 | Elapsed: 12.27s
01/28/2023 01:47:02 AM  [*] Sat Jan 28 01:47:02 2023: Train Epoch: 28 [57600/60900 (95%)]	Loss: 198.016830 | Elapsed: 12.28s
01/28/2023 01:47:10 AM  [*] Sat Jan 28 01:47:10 2023:   28    | Tr.loss: 167.588027 | Elapsed:  118.88  s
01/28/2023 01:47:11 AM [!] Sat Jan 28 01:47:11 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_28_1674866830-model.torch
01/28/2023 01:47:11 AM  [*] Started epoch: 29
01/28/2023 01:47:11 AM  [*] Sat Jan 28 01:47:11 2023: Train Epoch: 29 [  0  /60900 (0 %)]	Loss: 172.248596 | Elapsed: 0.20s
01/28/2023 01:47:23 AM  [*] Sat Jan 28 01:47:23 2023: Train Epoch: 29 [6400 /60900 (11%)]	Loss: 160.945786 | Elapsed: 12.31s
01/28/2023 01:47:36 AM  [*] Sat Jan 28 01:47:36 2023: Train Epoch: 29 [12800/60900 (21%)]	Loss: 158.065903 | Elapsed: 12.29s
01/28/2023 01:47:48 AM  [*] Sat Jan 28 01:47:48 2023: Train Epoch: 29 [19200/60900 (32%)]	Loss: 176.678131 | Elapsed: 12.29s
01/28/2023 01:48:00 AM  [*] Sat Jan 28 01:48:00 2023: Train Epoch: 29 [25600/60900 (42%)]	Loss: 176.212830 | Elapsed: 12.28s
01/28/2023 01:48:12 AM  [*] Sat Jan 28 01:48:12 2023: Train Epoch: 29 [32000/60900 (53%)]	Loss: 157.033783 | Elapsed: 12.28s
01/28/2023 01:48:25 AM  [*] Sat Jan 28 01:48:25 2023: Train Epoch: 29 [38400/60900 (63%)]	Loss: 163.017212 | Elapsed: 12.24s
01/28/2023 01:48:37 AM  [*] Sat Jan 28 01:48:37 2023: Train Epoch: 29 [44800/60900 (74%)]	Loss: 185.985138 | Elapsed: 12.32s
01/28/2023 01:48:49 AM  [*] Sat Jan 28 01:48:49 2023: Train Epoch: 29 [51200/60900 (84%)]	Loss: 175.177826 | Elapsed: 12.28s
01/28/2023 01:49:02 AM  [*] Sat Jan 28 01:49:02 2023: Train Epoch: 29 [57600/60900 (95%)]	Loss: 167.180206 | Elapsed: 12.28s
01/28/2023 01:49:10 AM  [*] Sat Jan 28 01:49:10 2023:   29    | Tr.loss: 167.603340 | Elapsed:  118.78  s
01/28/2023 01:49:10 AM [!] Sat Jan 28 01:49:10 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_29_1674866950-model.torch
01/28/2023 01:49:10 AM  [*] Started epoch: 30
01/28/2023 01:49:10 AM  [*] Sat Jan 28 01:49:10 2023: Train Epoch: 30 [  0  /60900 (0 %)]	Loss: 156.344559 | Elapsed: 0.23s
01/28/2023 01:49:23 AM  [*] Sat Jan 28 01:49:23 2023: Train Epoch: 30 [6400 /60900 (11%)]	Loss: 161.303955 | Elapsed: 12.43s
01/28/2023 01:49:35 AM  [*] Sat Jan 28 01:49:35 2023: Train Epoch: 30 [12800/60900 (21%)]	Loss: 154.992432 | Elapsed: 12.28s
01/28/2023 01:49:47 AM  [*] Sat Jan 28 01:49:47 2023: Train Epoch: 30 [19200/60900 (32%)]	Loss: 177.934052 | Elapsed: 12.28s
01/28/2023 01:50:00 AM  [*] Sat Jan 28 01:50:00 2023: Train Epoch: 30 [25600/60900 (42%)]	Loss: 171.849533 | Elapsed: 12.27s
01/28/2023 01:50:12 AM  [*] Sat Jan 28 01:50:12 2023: Train Epoch: 30 [32000/60900 (53%)]	Loss: 160.926178 | Elapsed: 12.29s
01/28/2023 01:50:24 AM  [*] Sat Jan 28 01:50:24 2023: Train Epoch: 30 [38400/60900 (63%)]	Loss: 152.239120 | Elapsed: 12.23s
01/28/2023 01:50:36 AM  [*] Sat Jan 28 01:50:36 2023: Train Epoch: 30 [44800/60900 (74%)]	Loss: 172.898102 | Elapsed: 12.33s
01/28/2023 01:50:49 AM  [*] Sat Jan 28 01:50:49 2023: Train Epoch: 30 [51200/60900 (84%)]	Loss: 179.313797 | Elapsed: 12.22s
01/28/2023 01:51:01 AM  [*] Sat Jan 28 01:51:01 2023: Train Epoch: 30 [57600/60900 (95%)]	Loss: 175.279800 | Elapsed: 12.34s
01/28/2023 01:51:09 AM  [*] Sat Jan 28 01:51:09 2023:   30    | Tr.loss: 167.604373 | Elapsed:  118.92  s
01/28/2023 01:51:09 AM [!] Sat Jan 28 01:51:09 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\epoch_30_1674867069-model.torch
01/28/2023 01:51:10 AM [!] Sat Jan 28 01:51:10 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\1674867069-model.torch
		train time: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\1674867069-trainTime.npy
		train losses: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\1674867069-trainLosses.npy
		train AUC: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\preTraining\training_files\1674867069-auc.npy
01/28/2023 01:51:11 AM  [!] Training pretrained model on downstream task...
01/28/2023 01:51:11 AM  [*] Started epoch: 1
01/28/2023 01:51:11 AM  [*] Sat Jan 28 01:51:11 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 4.062935 | Elapsed: 0.23s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 01:51:20 AM  [*] Sat Jan 28 01:51:20 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.345320 | Elapsed: 9.10s | FPR 0.0003 -> TPR 0.6957 & F1 0.8205
01/28/2023 01:51:29 AM  [*] Sat Jan 28 01:51:29 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.348822 | Elapsed: 9.05s | FPR 0.0003 -> TPR 0.3676 & F1 0.5376
01/28/2023 01:51:33 AM  [*] Sat Jan 28 01:51:33 2023:    1    | Tr.loss: 0.513770 | Elapsed:   22.10  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8449
01/28/2023 01:51:33 AM  [*] Started epoch: 2
01/28/2023 01:51:33 AM  [*] Sat Jan 28 01:51:33 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.246659 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.4091 & F1 0.5806
01/28/2023 01:51:42 AM  [*] Sat Jan 28 01:51:42 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.239599 | Elapsed: 9.06s | FPR 0.0003 -> TPR 0.5942 & F1 0.7455
01/28/2023 01:51:51 AM  [*] Sat Jan 28 01:51:51 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.189586 | Elapsed: 9.06s | FPR 0.0003 -> TPR 0.7031 & F1 0.8257
01/28/2023 01:51:55 AM  [*] Sat Jan 28 01:51:55 2023:    2    | Tr.loss: 0.261782 | Elapsed:   21.92  s | FPR 0.0003 -> TPR: 0.24 & F1: 0.38 | AUC: 0.9523
01/28/2023 01:51:55 AM  [*] Started epoch: 3
01/28/2023 01:51:55 AM  [*] Sat Jan 28 01:51:55 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.215752 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.8837 & F1 0.9383
01/28/2023 01:52:04 AM  [*] Sat Jan 28 01:52:04 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.204194 | Elapsed: 9.07s | FPR 0.0003 -> TPR 0.9429 & F1 0.9706
01/28/2023 01:52:13 AM  [*] Sat Jan 28 01:52:13 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.348474 | Elapsed: 9.04s | FPR 0.0003 -> TPR 0.5833 & F1 0.7368
01/28/2023 01:52:17 AM  [*] Sat Jan 28 01:52:17 2023:    3    | Tr.loss: 0.195885 | Elapsed:   21.84  s | FPR 0.0003 -> TPR: 0.53 & F1: 0.69 | AUC: 0.9744
01/28/2023 01:52:17 AM [!] Sat Jan 28 01:52:17 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_pretrained\training_files\1674867137-model.torch
		train time: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_pretrained\training_files\1674867137-trainTime.npy
		train losses: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_pretrained\training_files\1674867137-trainLosses.npy
		train AUC: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_pretrained\training_files\1674867137-auc.npy
		train F1s : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_pretrained\training_files\1674867137-trainF1s.npy
		train TPRs: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_pretrained\training_files\1674867137-trainTPRs.npy
01/28/2023 01:52:17 AM  [!] Training non_pretrained model on downstream task...
01/28/2023 01:52:18 AM  [*] Started epoch: 1
01/28/2023 01:52:18 AM  [*] Sat Jan 28 01:52:18 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 1.931144 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0250 & F1 0.0488
01/28/2023 01:52:24 AM  [*] Sat Jan 28 01:52:24 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.471910 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.3944 & F1 0.5657
01/28/2023 01:52:30 AM  [*] Sat Jan 28 01:52:30 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.376909 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.3226 & F1 0.4878
01/28/2023 01:52:33 AM  [*] Sat Jan 28 01:52:33 2023:    1    | Tr.loss: 0.481070 | Elapsed:   15.05  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8290
01/28/2023 01:52:33 AM  [*] Started epoch: 2
01/28/2023 01:52:33 AM  [*] Sat Jan 28 01:52:33 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.261114 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.7083 & F1 0.8293
01/28/2023 01:52:39 AM  [*] Sat Jan 28 01:52:39 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.224057 | Elapsed: 6.16s | FPR 0.0003 -> TPR 0.6714 & F1 0.8034
01/28/2023 01:52:45 AM  [*] Sat Jan 28 01:52:45 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.411396 | Elapsed: 6.14s | FPR 0.0003 -> TPR 0.7460 & F1 0.8545
01/28/2023 01:52:48 AM  [*] Sat Jan 28 01:52:48 2023:    2    | Tr.loss: 0.302630 | Elapsed:   15.01  s | FPR 0.0003 -> TPR: 0.30 & F1: 0.46 | AUC: 0.9314
01/28/2023 01:52:48 AM  [*] Started epoch: 3
01/28/2023 01:52:48 AM  [*] Sat Jan 28 01:52:48 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.305747 | Elapsed: 0.05s | FPR 0.0003 -> TPR 0.7179 & F1 0.8358
01/28/2023 01:52:54 AM  [*] Sat Jan 28 01:52:54 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.241672 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.6429 & F1 0.7826
01/28/2023 01:53:00 AM  [*] Sat Jan 28 01:53:00 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.221938 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.7746 & F1 0.8730
01/28/2023 01:53:03 AM  [*] Sat Jan 28 01:53:03 2023:    3    | Tr.loss: 0.236969 | Elapsed:   15.25  s | FPR 0.0003 -> TPR: 0.35 & F1: 0.52 | AUC: 0.9604
01/28/2023 01:53:03 AM [!] Sat Jan 28 01:53:03 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_non_pretrained\training_files\1674867183-model.torch
		train time: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_non_pretrained\training_files\1674867183-trainTime.npy
		train losses: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_non_pretrained\training_files\1674867183-trainLosses.npy
		train AUC: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_non_pretrained\training_files\1674867183-auc.npy
		train F1s : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_non_pretrained\training_files\1674867183-trainF1s.npy
		train TPRs: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_non_pretrained\training_files\1674867183-trainTPRs.npy
01/28/2023 01:53:03 AM  [!] Training full_data model on downstream task...
01/28/2023 01:53:04 AM  [*] Started epoch: 1
01/28/2023 01:53:04 AM  [*] Sat Jan 28 01:53:04 2023: Train Epoch: 1 [  0  /76126 (0 %)]	Loss: 3.050142 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.1818 & F1 0.3077
01/28/2023 01:53:10 AM  [*] Sat Jan 28 01:53:10 2023: Train Epoch: 1 [6400 /76126 (8 %)]	Loss: 0.406594 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.5672 & F1 0.7238
01/28/2023 01:53:16 AM  [*] Sat Jan 28 01:53:16 2023: Train Epoch: 1 [12800/76126 (17%)]	Loss: 0.382399 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.5000 & F1 0.6667
01/28/2023 01:53:22 AM  [*] Sat Jan 28 01:53:22 2023: Train Epoch: 1 [19200/76126 (25%)]	Loss: 0.329035 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.4032 & F1 0.5747
01/28/2023 01:53:29 AM  [*] Sat Jan 28 01:53:29 2023: Train Epoch: 1 [25600/76126 (34%)]	Loss: 0.324160 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.5672 & F1 0.7238
01/28/2023 01:53:35 AM  [*] Sat Jan 28 01:53:35 2023: Train Epoch: 1 [32000/76126 (42%)]	Loss: 0.249373 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.4627 & F1 0.6327
01/28/2023 01:53:41 AM  [*] Sat Jan 28 01:53:41 2023: Train Epoch: 1 [38400/76126 (50%)]	Loss: 0.168557 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.7778 & F1 0.8750
01/28/2023 01:53:47 AM  [*] Sat Jan 28 01:53:47 2023: Train Epoch: 1 [44800/76126 (59%)]	Loss: 0.184503 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.9306 & F1 0.9640
01/28/2023 01:53:53 AM  [*] Sat Jan 28 01:53:53 2023: Train Epoch: 1 [51200/76126 (67%)]	Loss: 0.159426 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.8400 & F1 0.9130
01/28/2023 01:54:00 AM  [*] Sat Jan 28 01:54:00 2023: Train Epoch: 1 [57600/76126 (76%)]	Loss: 0.226025 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.6923 & F1 0.8182
01/28/2023 01:54:06 AM  [*] Sat Jan 28 01:54:06 2023: Train Epoch: 1 [64000/76126 (84%)]	Loss: 0.315370 | Elapsed: 6.26s | FPR 0.0003 -> TPR 0.5303 & F1 0.6931
01/28/2023 01:54:12 AM  [*] Sat Jan 28 01:54:12 2023: Train Epoch: 1 [70400/76126 (92%)]	Loss: 0.120331 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.9077 & F1 0.9516
01/28/2023 01:54:19 AM  [*] Sat Jan 28 01:54:19 2023:    1    | Tr.loss: 0.297146 | Elapsed:   75.51  s | FPR 0.0003 -> TPR: 0.09 & F1: 0.17 | AUC: 0.9360
01/28/2023 01:54:19 AM  [*] Started epoch: 2
01/28/2023 01:54:19 AM  [*] Sat Jan 28 01:54:19 2023: Train Epoch: 2 [  0  /76126 (0 %)]	Loss: 0.141005 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.8636 & F1 0.9268
01/28/2023 01:54:26 AM  [*] Sat Jan 28 01:54:26 2023: Train Epoch: 2 [6400 /76126 (8 %)]	Loss: 0.146457 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.9385 & F1 0.9683
01/28/2023 01:54:32 AM  [*] Sat Jan 28 01:54:32 2023: Train Epoch: 2 [12800/76126 (17%)]	Loss: 0.215240 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.6567 & F1 0.7928
01/28/2023 01:54:38 AM  [*] Sat Jan 28 01:54:38 2023: Train Epoch: 2 [19200/76126 (25%)]	Loss: 0.081947 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.8806 & F1 0.9365
01/28/2023 01:54:44 AM  [*] Sat Jan 28 01:54:44 2023: Train Epoch: 2 [25600/76126 (34%)]	Loss: 0.097895 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.9508 & F1 0.9748
01/28/2023 01:54:50 AM  [*] Sat Jan 28 01:54:50 2023: Train Epoch: 2 [32000/76126 (42%)]	Loss: 0.115802 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.8676 & F1 0.9291
01/28/2023 01:54:57 AM  [*] Sat Jan 28 01:54:57 2023: Train Epoch: 2 [38400/76126 (50%)]	Loss: 0.045679 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.5143 & F1 0.6792
01/28/2023 01:55:03 AM  [*] Sat Jan 28 01:55:03 2023: Train Epoch: 2 [44800/76126 (59%)]	Loss: 0.135011 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.7647 & F1 0.8667
01/28/2023 01:55:09 AM  [*] Sat Jan 28 01:55:09 2023: Train Epoch: 2 [51200/76126 (67%)]	Loss: 0.175754 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.8095 & F1 0.8947
01/28/2023 01:55:10 AM [!] Learning rate: 2.5e-05
01/28/2023 01:55:15 AM  [*] Sat Jan 28 01:55:15 2023: Train Epoch: 2 [57600/76126 (76%)]	Loss: 0.140997 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.7937 & F1 0.8850
01/28/2023 01:55:21 AM  [*] Sat Jan 28 01:55:21 2023: Train Epoch: 2 [64000/76126 (84%)]	Loss: 0.107348 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.9324 & F1 0.9650
01/28/2023 01:55:28 AM  [*] Sat Jan 28 01:55:28 2023: Train Epoch: 2 [70400/76126 (92%)]	Loss: 0.117540 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.8356 & F1 0.9104
01/28/2023 01:55:35 AM  [*] Sat Jan 28 01:55:35 2023:    2    | Tr.loss: 0.135413 | Elapsed:   75.62  s | FPR 0.0003 -> TPR: 0.55 & F1: 0.71 | AUC: 0.9872
01/28/2023 01:55:35 AM  [*] Started epoch: 3
01/28/2023 01:55:35 AM  [*] Sat Jan 28 01:55:35 2023: Train Epoch: 3 [  0  /76126 (0 %)]	Loss: 0.042726 | Elapsed: 0.07s | FPR 0.0003 -> TPR 1.0000 & F1 1.0000
01/28/2023 01:55:41 AM  [*] Sat Jan 28 01:55:41 2023: Train Epoch: 3 [6400 /76126 (8 %)]	Loss: 0.043964 | Elapsed: 6.18s | FPR 0.0003 -> TPR 1.0000 & F1 1.0000
01/28/2023 01:55:47 AM  [*] Sat Jan 28 01:55:47 2023: Train Epoch: 3 [12800/76126 (17%)]	Loss: 0.109704 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.8986 & F1 0.9466
01/28/2023 01:55:54 AM  [*] Sat Jan 28 01:55:54 2023: Train Epoch: 3 [19200/76126 (25%)]	Loss: 0.060499 | Elapsed: 6.21s | FPR 0.0003 -> TPR 1.0000 & F1 1.0000
01/28/2023 01:56:00 AM  [*] Sat Jan 28 01:56:00 2023: Train Epoch: 3 [25600/76126 (34%)]	Loss: 0.082241 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.9733 & F1 0.9865
01/28/2023 01:56:06 AM  [*] Sat Jan 28 01:56:06 2023: Train Epoch: 3 [32000/76126 (42%)]	Loss: 0.063724 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.9130 & F1 0.9545
01/28/2023 01:56:12 AM  [*] Sat Jan 28 01:56:12 2023: Train Epoch: 3 [38400/76126 (50%)]	Loss: 0.026419 | Elapsed: 6.26s | FPR 0.0003 -> TPR 0.9605 & F1 0.9799
01/28/2023 01:56:18 AM  [*] Sat Jan 28 01:56:18 2023: Train Epoch: 3 [44800/76126 (59%)]	Loss: 0.118604 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.8955 & F1 0.9449
01/28/2023 01:56:25 AM  [*] Sat Jan 28 01:56:25 2023: Train Epoch: 3 [51200/76126 (67%)]	Loss: 0.137370 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.9167 & F1 0.9565
01/28/2023 01:56:31 AM  [*] Sat Jan 28 01:56:31 2023: Train Epoch: 3 [57600/76126 (76%)]	Loss: 0.070376 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.8696 & F1 0.9302
01/28/2023 01:56:37 AM  [*] Sat Jan 28 01:56:37 2023: Train Epoch: 3 [64000/76126 (84%)]	Loss: 0.078321 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.9412 & F1 0.9697
01/28/2023 01:56:43 AM  [*] Sat Jan 28 01:56:43 2023: Train Epoch: 3 [70400/76126 (92%)]	Loss: 0.069936 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.8788 & F1 0.9355
01/28/2023 01:56:50 AM  [*] Sat Jan 28 01:56:50 2023:    3    | Tr.loss: 0.102297 | Elapsed:   75.57  s | FPR 0.0003 -> TPR: 0.65 & F1: 0.79 | AUC: 0.9927
01/28/2023 01:56:51 AM [!] Sat Jan 28 01:56:51 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_full_data\training_files\1674867410-model.torch
		train time: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_full_data\training_files\1674867410-trainTime.npy
		train losses: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_full_data\training_files\1674867410-trainLosses.npy
		train AUC: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_full_data\training_files\1674867410-auc.npy
		train F1s : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_full_data\training_files\1674867410-trainF1s.npy
		train TPRs: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395\downstreamTask_full_data\training_files\1674867410-trainTPRs.npy
01/28/2023 01:56:51 AM  [*] Evaluating pretrained model on test set...
01/28/2023 01:56:56 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.1614 | F1: 0.2780
01/28/2023 01:56:56 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.2924 | F1: 0.4524
01/28/2023 01:56:56 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.3730 | F1: 0.5430
01/28/2023 01:56:56 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.4030 | F1: 0.5734
01/28/2023 01:56:56 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.5029 | F1: 0.6655
01/28/2023 01:56:56 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.5847 | F1: 0.7263
01/28/2023 01:56:56 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.8157 | F1: 0.8583
01/28/2023 01:56:56 AM  [*] Evaluating non_pretrained model on test set...
01/28/2023 01:57:01 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0965 | F1: 0.1759
01/28/2023 01:57:01 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1488 | F1: 0.2590
01/28/2023 01:57:01 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.2273 | F1: 0.3701
01/28/2023 01:57:01 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.2606 | F1: 0.4126
01/28/2023 01:57:01 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.2970 | F1: 0.4550
01/28/2023 01:57:01 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4386 | F1: 0.5991
01/28/2023 01:57:01 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.6755 | F1: 0.7674
01/28/2023 01:57:01 AM  [*] Evaluating full_data model on test set...
01/28/2023 01:57:06 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0573 | F1: 0.1084
01/28/2023 01:57:06 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.3529 | F1: 0.5216
01/28/2023 01:57:06 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.4468 | F1: 0.6172
01/28/2023 01:57:06 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.5047 | F1: 0.6697
01/28/2023 01:57:06 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.6215 | F1: 0.7626
01/28/2023 01:57:06 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.7082 | F1: 0.8170
01/28/2023 01:57:06 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.8419 | F1: 0.8739
01/28/2023 01:57:06 AM  [!] Finished pre-training evaluation over 3 splits! Saved metrics to:
	C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\pretrain_epoch_analysis_1674855395/results_full.json
01/28/2023 01:57:07 AM  [*] Evaluating pre-training length utility -- looping over per-epcoh models...
01/28/2023 01:57:07 AM Split: 0
01/28/2023 01:57:08 AM  [*] Started epoch: 1
01/28/2023 01:57:08 AM  [*] Sat Jan 28 01:57:08 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.204796 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 01:57:14 AM  [*] Sat Jan 28 01:57:14 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.511632 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.0556 & F1 0.1053
01/28/2023 01:57:20 AM  [*] Sat Jan 28 01:57:20 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.479231 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.2923 & F1 0.4524
01/28/2023 01:57:23 AM  [*] Sat Jan 28 01:57:23 2023:    1    | Tr.loss: 0.527649 | Elapsed:   15.17  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8023
01/28/2023 01:57:23 AM  [*] Started epoch: 2
01/28/2023 01:57:23 AM  [*] Sat Jan 28 01:57:23 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.324446 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.7556 & F1 0.8608
01/28/2023 01:57:29 AM  [*] Sat Jan 28 01:57:29 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.360205 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.3425 & F1 0.5102
01/28/2023 01:57:35 AM  [*] Sat Jan 28 01:57:35 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.221585 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.3485 & F1 0.5169
01/28/2023 01:57:38 AM  [*] Sat Jan 28 01:57:38 2023:    2    | Tr.loss: 0.322577 | Elapsed:   15.15  s | FPR 0.0003 -> TPR: 0.16 & F1: 0.28 | AUC: 0.9220
01/28/2023 01:57:38 AM  [*] Started epoch: 3
01/28/2023 01:57:38 AM  [*] Sat Jan 28 01:57:38 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.265898 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.5854 & F1 0.7385
01/28/2023 01:57:44 AM  [*] Sat Jan 28 01:57:44 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.328378 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.5469 & F1 0.7071
01/28/2023 01:57:51 AM  [*] Sat Jan 28 01:57:51 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.189299 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.8209 & F1 0.9016
01/28/2023 01:57:53 AM  [*] Sat Jan 28 01:57:53 2023:    3    | Tr.loss: 0.230781 | Elapsed:   15.18  s | FPR 0.0003 -> TPR: 0.36 & F1: 0.53 | AUC: 0.9627
01/28/2023 01:57:59 AM  [*] Started epoch: 1
01/28/2023 01:57:59 AM  [*] Sat Jan 28 01:57:59 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 4.143753 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 01:58:05 AM  [*] Sat Jan 28 01:58:05 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.492985 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.0725 & F1 0.1351
01/28/2023 01:58:12 AM  [*] Sat Jan 28 01:58:12 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.508818 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.2985 & F1 0.4598
01/28/2023 01:58:14 AM  [*] Sat Jan 28 01:58:14 2023:    1    | Tr.loss: 0.567241 | Elapsed:   15.17  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7902
01/28/2023 01:58:14 AM  [*] Started epoch: 2
01/28/2023 01:58:14 AM  [*] Sat Jan 28 01:58:14 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.459653 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.1064 & F1 0.1923
01/28/2023 01:58:21 AM  [*] Sat Jan 28 01:58:21 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.339535 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.5652 & F1 0.7222
01/28/2023 01:58:27 AM  [*] Sat Jan 28 01:58:27 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.332585 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.3284 & F1 0.4944
01/28/2023 01:58:29 AM  [*] Sat Jan 28 01:58:29 2023:    2    | Tr.loss: 0.328716 | Elapsed:   15.21  s | FPR 0.0003 -> TPR: 0.12 & F1: 0.22 | AUC: 0.9198
01/28/2023 01:58:29 AM  [*] Started epoch: 3
01/28/2023 01:58:29 AM  [*] Sat Jan 28 01:58:29 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.266408 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.7857 & F1 0.8800
01/28/2023 01:58:36 AM  [*] Sat Jan 28 01:58:36 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.321786 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.5970 & F1 0.7477
01/28/2023 01:58:42 AM  [*] Sat Jan 28 01:58:42 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.187872 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.7222 & F1 0.8387
01/28/2023 01:58:45 AM  [*] Sat Jan 28 01:58:45 2023:    3    | Tr.loss: 0.237148 | Elapsed:   15.19  s | FPR 0.0003 -> TPR: 0.25 & F1: 0.40 | AUC: 0.9610
01/28/2023 01:58:50 AM  [*] Started epoch: 1
01/28/2023 01:58:50 AM  [*] Sat Jan 28 01:58:50 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.139745 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 01:58:57 AM  [*] Sat Jan 28 01:58:57 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.455132 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.1831 & F1 0.3095
01/28/2023 01:59:03 AM  [*] Sat Jan 28 01:59:03 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.456100 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.2537 & F1 0.4048
01/28/2023 01:59:05 AM  [*] Sat Jan 28 01:59:05 2023:    1    | Tr.loss: 0.543862 | Elapsed:   15.18  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7984
01/28/2023 01:59:05 AM  [*] Started epoch: 2
01/28/2023 01:59:06 AM  [*] Sat Jan 28 01:59:06 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.400746 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.1250 & F1 0.2222
01/28/2023 01:59:12 AM  [*] Sat Jan 28 01:59:12 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.187869 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.7465 & F1 0.8548
01/28/2023 01:59:18 AM  [*] Sat Jan 28 01:59:18 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.242051 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.6338 & F1 0.7759
01/28/2023 01:59:21 AM  [*] Sat Jan 28 01:59:21 2023:    2    | Tr.loss: 0.327306 | Elapsed:   15.21  s | FPR 0.0003 -> TPR: 0.12 & F1: 0.22 | AUC: 0.9207
01/28/2023 01:59:21 AM  [*] Started epoch: 3
01/28/2023 01:59:21 AM  [*] Sat Jan 28 01:59:21 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.347223 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.7045 & F1 0.8267
01/28/2023 01:59:27 AM  [*] Sat Jan 28 01:59:27 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.142637 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.9403 & F1 0.9692
01/28/2023 01:59:33 AM  [*] Sat Jan 28 01:59:33 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.273670 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.7833 & F1 0.8785
01/28/2023 01:59:36 AM  [*] Sat Jan 28 01:59:36 2023:    3    | Tr.loss: 0.232059 | Elapsed:   15.18  s | FPR 0.0003 -> TPR: 0.31 & F1: 0.48 | AUC: 0.9623
01/28/2023 01:59:42 AM  [*] Started epoch: 1
01/28/2023 01:59:42 AM  [*] Sat Jan 28 01:59:42 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 1.744616 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0250 & F1 0.0488
01/28/2023 01:59:48 AM  [*] Sat Jan 28 01:59:48 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.503884 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.1333 & F1 0.2353
01/28/2023 01:59:54 AM  [*] Sat Jan 28 01:59:54 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.314581 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.1831 & F1 0.3095
01/28/2023 01:59:57 AM  [*] Sat Jan 28 01:59:57 2023:    1    | Tr.loss: 0.467992 | Elapsed:   15.13  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8258
01/28/2023 01:59:57 AM  [*] Started epoch: 2
01/28/2023 01:59:57 AM  [*] Sat Jan 28 01:59:57 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.401621 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.2326 & F1 0.3774
01/28/2023 02:00:03 AM  [*] Sat Jan 28 02:00:03 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.372401 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.2812 & F1 0.4390
01/28/2023 02:00:09 AM  [*] Sat Jan 28 02:00:09 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.232958 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.7222 & F1 0.8387
01/28/2023 02:00:12 AM  [*] Sat Jan 28 02:00:12 2023:    2    | Tr.loss: 0.294803 | Elapsed:   15.16  s | FPR 0.0003 -> TPR: 0.17 & F1: 0.28 | AUC: 0.9383
01/28/2023 02:00:12 AM  [*] Started epoch: 3
01/28/2023 02:00:12 AM  [*] Sat Jan 28 02:00:12 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.197146 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.6522 & F1 0.7895
01/28/2023 02:00:18 AM  [*] Sat Jan 28 02:00:18 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.230614 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.8923 & F1 0.9431
01/28/2023 02:00:24 AM  [*] Sat Jan 28 02:00:24 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.179720 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.7969 & F1 0.8870
01/28/2023 02:00:27 AM  [*] Sat Jan 28 02:00:27 2023:    3    | Tr.loss: 0.205806 | Elapsed:   15.20  s | FPR 0.0003 -> TPR: 0.27 & F1: 0.42 | AUC: 0.9712
01/28/2023 02:00:33 AM  [*] Started epoch: 1
01/28/2023 02:00:33 AM  [*] Sat Jan 28 02:00:33 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 2.574231 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 02:00:39 AM  [*] Sat Jan 28 02:00:39 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.427809 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.3803 & F1 0.5510
01/28/2023 02:00:45 AM  [*] Sat Jan 28 02:00:45 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.499774 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.3485 & F1 0.5169
01/28/2023 02:00:48 AM  [*] Sat Jan 28 02:00:48 2023:    1    | Tr.loss: 0.469285 | Elapsed:   15.12  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8309
01/28/2023 02:00:48 AM  [*] Started epoch: 2
01/28/2023 02:00:48 AM  [*] Sat Jan 28 02:00:48 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.356244 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.4762 & F1 0.6452
01/28/2023 02:00:54 AM  [*] Sat Jan 28 02:00:54 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.232256 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.5758 & F1 0.7308
01/28/2023 02:01:01 AM  [*] Sat Jan 28 02:01:01 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.236306 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.5781 & F1 0.7327
01/28/2023 02:01:03 AM  [*] Sat Jan 28 02:01:03 2023:    2    | Tr.loss: 0.287014 | Elapsed:   15.20  s | FPR 0.0003 -> TPR: 0.19 & F1: 0.32 | AUC: 0.9386
01/28/2023 02:01:03 AM  [*] Started epoch: 3
01/28/2023 02:01:03 AM  [*] Sat Jan 28 02:01:03 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.248334 | Elapsed: 0.05s | FPR 0.0003 -> TPR 0.4667 & F1 0.6364
01/28/2023 02:01:09 AM  [*] Sat Jan 28 02:01:09 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.199513 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.6618 & F1 0.7965
01/28/2023 02:01:16 AM  [*] Sat Jan 28 02:01:16 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.215517 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.7656 & F1 0.8673
01/28/2023 02:01:18 AM  [*] Sat Jan 28 02:01:18 2023:    3    | Tr.loss: 0.210765 | Elapsed:   15.20  s | FPR 0.0003 -> TPR: 0.36 & F1: 0.53 | AUC: 0.9684
01/28/2023 02:01:24 AM  [*] Started epoch: 1
01/28/2023 02:01:24 AM  [*] Sat Jan 28 02:01:24 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.051569 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 02:01:30 AM  [*] Sat Jan 28 02:01:30 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.436430 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.3382 & F1 0.5055
01/28/2023 02:01:37 AM  [*] Sat Jan 28 02:01:37 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.475532 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.2537 & F1 0.4048
01/28/2023 02:01:39 AM  [*] Sat Jan 28 02:01:39 2023:    1    | Tr.loss: 0.483181 | Elapsed:   15.17  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8232
01/28/2023 02:01:39 AM  [*] Started epoch: 2
01/28/2023 02:01:39 AM  [*] Sat Jan 28 02:01:39 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.457516 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.2326 & F1 0.3774
01/28/2023 02:01:46 AM  [*] Sat Jan 28 02:01:46 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.305604 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.4769 & F1 0.6458
01/28/2023 02:01:52 AM  [*] Sat Jan 28 02:01:52 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.161852 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.8615 & F1 0.9256
01/28/2023 02:01:54 AM  [*] Sat Jan 28 02:01:54 2023:    2    | Tr.loss: 0.301735 | Elapsed:   15.22  s | FPR 0.0003 -> TPR: 0.18 & F1: 0.30 | AUC: 0.9333
01/28/2023 02:01:54 AM  [*] Started epoch: 3
01/28/2023 02:01:55 AM  [*] Sat Jan 28 02:01:55 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.204284 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.8511 & F1 0.9195
01/28/2023 02:02:01 AM  [*] Sat Jan 28 02:02:01 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.252847 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.7971 & F1 0.8871
01/28/2023 02:02:07 AM  [*] Sat Jan 28 02:02:07 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.295378 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.7500 & F1 0.8571
01/28/2023 02:02:10 AM  [*] Sat Jan 28 02:02:10 2023:    3    | Tr.loss: 0.213261 | Elapsed:   15.21  s | FPR 0.0003 -> TPR: 0.25 & F1: 0.40 | AUC: 0.9686
01/28/2023 02:02:15 AM  [*] Started epoch: 1
01/28/2023 02:02:15 AM  [*] Sat Jan 28 02:02:15 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.267712 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 02:02:22 AM  [*] Sat Jan 28 02:02:22 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.391095 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.3651 & F1 0.5349
01/28/2023 02:02:28 AM  [*] Sat Jan 28 02:02:28 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.310461 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.6000 & F1 0.7500
01/28/2023 02:02:31 AM  [*] Sat Jan 28 02:02:31 2023:    1    | Tr.loss: 0.499583 | Elapsed:   15.14  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8164
01/28/2023 02:02:31 AM  [*] Started epoch: 2
01/28/2023 02:02:31 AM  [*] Sat Jan 28 02:02:31 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.328782 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.4634 & F1 0.6333
01/28/2023 02:02:37 AM  [*] Sat Jan 28 02:02:37 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.364859 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.3333 & F1 0.5000
01/28/2023 02:02:43 AM  [*] Sat Jan 28 02:02:43 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.274204 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.5735 & F1 0.7290
01/28/2023 02:02:46 AM  [*] Sat Jan 28 02:02:46 2023:    2    | Tr.loss: 0.304955 | Elapsed:   15.20  s | FPR 0.0003 -> TPR: 0.17 & F1: 0.29 | AUC: 0.9319
01/28/2023 02:02:46 AM  [*] Started epoch: 3
01/28/2023 02:02:46 AM  [*] Sat Jan 28 02:02:46 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.228625 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.6744 & F1 0.8056
01/28/2023 02:02:52 AM  [*] Sat Jan 28 02:02:52 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.260120 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.6364 & F1 0.7778
01/28/2023 02:02:58 AM  [*] Sat Jan 28 02:02:58 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.172165 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.7344 & F1 0.8468
01/28/2023 02:03:01 AM  [*] Sat Jan 28 02:03:01 2023:    3    | Tr.loss: 0.219292 | Elapsed:   15.23  s | FPR 0.0003 -> TPR: 0.26 & F1: 0.41 | AUC: 0.9673
01/28/2023 02:03:07 AM  [*] Started epoch: 1
01/28/2023 02:03:07 AM  [*] Sat Jan 28 02:03:07 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 2.684513 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 02:03:13 AM  [*] Sat Jan 28 02:03:13 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.381108 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.2985 & F1 0.4598
01/28/2023 02:03:19 AM  [*] Sat Jan 28 02:03:19 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.265232 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.1733 & F1 0.2955
01/28/2023 02:03:22 AM  [*] Sat Jan 28 02:03:22 2023:    1    | Tr.loss: 0.504943 | Elapsed:   15.17  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8113
01/28/2023 02:03:22 AM  [*] Started epoch: 2
01/28/2023 02:03:22 AM  [*] Sat Jan 28 02:03:22 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.357412 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.6250 & F1 0.7692
01/28/2023 02:03:28 AM  [*] Sat Jan 28 02:03:28 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.303790 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.8732 & F1 0.9323
01/28/2023 02:03:34 AM  [*] Sat Jan 28 02:03:34 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.284530 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.3088 & F1 0.4719
01/28/2023 02:03:37 AM  [*] Sat Jan 28 02:03:37 2023:    2    | Tr.loss: 0.320428 | Elapsed:   15.20  s | FPR 0.0003 -> TPR: 0.20 & F1: 0.33 | AUC: 0.9222
01/28/2023 02:03:37 AM  [*] Started epoch: 3
01/28/2023 02:03:37 AM  [*] Sat Jan 28 02:03:37 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.212994 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.8889 & F1 0.9412
01/28/2023 02:03:43 AM  [*] Sat Jan 28 02:03:43 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.255717 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.6716 & F1 0.8036
01/28/2023 02:03:50 AM  [*] Sat Jan 28 02:03:50 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.159964 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.7246 & F1 0.8403
01/28/2023 02:03:52 AM  [*] Sat Jan 28 02:03:52 2023:    3    | Tr.loss: 0.230051 | Elapsed:   15.17  s | FPR 0.0003 -> TPR: 0.33 & F1: 0.50 | AUC: 0.9632
01/28/2023 02:03:58 AM  [*] Started epoch: 1
01/28/2023 02:03:58 AM  [*] Sat Jan 28 02:03:58 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 2.964783 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 02:04:04 AM  [*] Sat Jan 28 02:04:04 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.440483 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.1714 & F1 0.2927
01/28/2023 02:04:10 AM  [*] Sat Jan 28 02:04:10 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.311197 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.3611 & F1 0.5306
01/28/2023 02:04:13 AM  [*] Sat Jan 28 02:04:13 2023:    1    | Tr.loss: 0.511427 | Elapsed:   15.14  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8116
01/28/2023 02:04:13 AM  [*] Started epoch: 2
01/28/2023 02:04:13 AM  [*] Sat Jan 28 02:04:13 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.365646 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.6400 & F1 0.7805
01/28/2023 02:04:19 AM  [*] Sat Jan 28 02:04:19 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.347852 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.5821 & F1 0.7358
01/28/2023 02:04:26 AM  [*] Sat Jan 28 02:04:26 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.344240 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.6970 & F1 0.8214
01/28/2023 02:04:28 AM  [*] Sat Jan 28 02:04:28 2023:    2    | Tr.loss: 0.315267 | Elapsed:   15.18  s | FPR 0.0003 -> TPR: 0.16 & F1: 0.28 | AUC: 0.9256
01/28/2023 02:04:28 AM  [*] Started epoch: 3
01/28/2023 02:04:28 AM  [*] Sat Jan 28 02:04:28 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.262886 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.6486 & F1 0.7869
01/28/2023 02:04:35 AM  [*] Sat Jan 28 02:04:35 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.268082 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.2361 & F1 0.3820
01/28/2023 02:04:41 AM  [*] Sat Jan 28 02:04:41 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.256483 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.7049 & F1 0.8269
01/28/2023 02:04:43 AM  [*] Sat Jan 28 02:04:43 2023:    3    | Tr.loss: 0.229895 | Elapsed:   15.17  s | FPR 0.0003 -> TPR: 0.19 & F1: 0.33 | AUC: 0.9631
01/28/2023 02:04:49 AM  [*] Started epoch: 1
01/28/2023 02:04:49 AM  [*] Sat Jan 28 02:04:49 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.768470 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 02:04:55 AM  [*] Sat Jan 28 02:04:55 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.456923 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.0435 & F1 0.0833
01/28/2023 02:05:02 AM  [*] Sat Jan 28 02:05:02 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.423504 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.1143 & F1 0.2051
01/28/2023 02:05:04 AM  [*] Sat Jan 28 02:05:04 2023:    1    | Tr.loss: 0.528115 | Elapsed:   15.16  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8021
01/28/2023 02:05:04 AM  [*] Started epoch: 2
01/28/2023 02:05:04 AM  [*] Sat Jan 28 02:05:04 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.310609 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.5106 & F1 0.6761
01/28/2023 02:05:11 AM  [*] Sat Jan 28 02:05:11 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.344052 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.5714 & F1 0.7273
01/28/2023 02:05:17 AM  [*] Sat Jan 28 02:05:17 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.283956 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.6000 & F1 0.7500
01/28/2023 02:05:19 AM  [*] Sat Jan 28 02:05:19 2023:    2    | Tr.loss: 0.322450 | Elapsed:   15.24  s | FPR 0.0003 -> TPR: 0.14 & F1: 0.24 | AUC: 0.9216
01/28/2023 02:05:19 AM  [*] Started epoch: 3
01/28/2023 02:05:20 AM  [*] Sat Jan 28 02:05:20 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.306036 | Elapsed: 0.05s | FPR 0.0003 -> TPR 0.6512 & F1 0.7887
01/28/2023 02:05:26 AM  [*] Sat Jan 28 02:05:26 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.209310 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.7941 & F1 0.8852
01/28/2023 02:05:32 AM  [*] Sat Jan 28 02:05:32 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.205299 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.7015 & F1 0.8246
01/28/2023 02:05:35 AM  [*] Sat Jan 28 02:05:35 2023:    3    | Tr.loss: 0.227580 | Elapsed:   15.18  s | FPR 0.0003 -> TPR: 0.18 & F1: 0.30 | AUC: 0.9639
01/28/2023 02:05:40 AM  [*] Started epoch: 1
01/28/2023 02:05:40 AM  [*] Sat Jan 28 02:05:40 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 4.540378 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 02:05:47 AM  [*] Sat Jan 28 02:05:47 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.366613 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.3594 & F1 0.5287
01/28/2023 02:05:53 AM  [*] Sat Jan 28 02:05:53 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.344019 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.3824 & F1 0.5532
01/28/2023 02:05:55 AM  [*] Sat Jan 28 02:05:55 2023:    1    | Tr.loss: 0.533344 | Elapsed:   15.14  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8001
01/28/2023 02:05:55 AM  [*] Started epoch: 2
01/28/2023 02:05:56 AM  [*] Sat Jan 28 02:05:56 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.316278 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.8000 & F1 0.8889
01/28/2023 02:06:02 AM  [*] Sat Jan 28 02:06:02 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.404736 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.6462 & F1 0.7850
01/28/2023 02:06:08 AM  [*] Sat Jan 28 02:06:08 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.303099 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.5942 & F1 0.7455
01/28/2023 02:06:11 AM  [*] Sat Jan 28 02:06:11 2023:    2    | Tr.loss: 0.327844 | Elapsed:   15.25  s | FPR 0.0003 -> TPR: 0.16 & F1: 0.28 | AUC: 0.9186
01/28/2023 02:06:11 AM  [*] Started epoch: 3
01/28/2023 02:06:11 AM  [*] Sat Jan 28 02:06:11 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.307568 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.4889 & F1 0.6567
01/28/2023 02:06:17 AM  [*] Sat Jan 28 02:06:17 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.226710 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.7077 & F1 0.8288
01/28/2023 02:06:23 AM  [*] Sat Jan 28 02:06:23 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.218205 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.8354 & F1 0.9103
01/28/2023 02:06:26 AM  [*] Sat Jan 28 02:06:26 2023:    3    | Tr.loss: 0.227411 | Elapsed:   15.15  s | FPR 0.0003 -> TPR: 0.32 & F1: 0.48 | AUC: 0.9641
01/28/2023 02:06:32 AM  [*] Started epoch: 1
01/28/2023 02:06:32 AM  [*] Sat Jan 28 02:06:32 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.025152 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 02:06:38 AM  [*] Sat Jan 28 02:06:38 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.486835 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.2687 & F1 0.4235
01/28/2023 02:06:44 AM  [*] Sat Jan 28 02:06:44 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.319434 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.5862 & F1 0.7391
01/28/2023 02:06:47 AM  [*] Sat Jan 28 02:06:47 2023:    1    | Tr.loss: 0.528003 | Elapsed:   15.11  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8037
01/28/2023 02:06:47 AM  [*] Started epoch: 2
01/28/2023 02:06:47 AM  [*] Sat Jan 28 02:06:47 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.410679 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.2273 & F1 0.3704
01/28/2023 02:06:53 AM  [*] Sat Jan 28 02:06:53 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.256353 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.6212 & F1 0.7664
01/28/2023 02:06:59 AM  [*] Sat Jan 28 02:06:59 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.199919 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.7083 & F1 0.8293
01/28/2023 02:07:02 AM  [*] Sat Jan 28 02:07:02 2023:    2    | Tr.loss: 0.317425 | Elapsed:   15.21  s | FPR 0.0003 -> TPR: 0.18 & F1: 0.30 | AUC: 0.9251
01/28/2023 02:07:02 AM  [*] Started epoch: 3
01/28/2023 02:07:02 AM  [*] Sat Jan 28 02:07:02 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.307355 | Elapsed: 0.05s | FPR 0.0003 -> TPR 0.6341 & F1 0.7761
01/28/2023 02:07:08 AM  [*] Sat Jan 28 02:07:08 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.234776 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.6957 & F1 0.8205
01/28/2023 02:07:15 AM  [*] Sat Jan 28 02:07:15 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.121577 | Elapsed: 6.31s | FPR 0.0003 -> TPR 0.7792 & F1 0.8759
01/28/2023 02:07:17 AM  [*] Sat Jan 28 02:07:17 2023:    3    | Tr.loss: 0.232374 | Elapsed:   15.43  s | FPR 0.0003 -> TPR: 0.34 & F1: 0.51 | AUC: 0.9623
01/28/2023 02:07:23 AM  [*] Started epoch: 1
01/28/2023 02:07:23 AM  [*] Sat Jan 28 02:07:23 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.207609 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 02:07:30 AM  [*] Sat Jan 28 02:07:30 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.581368 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.1692 & F1 0.2895
01/28/2023 02:07:36 AM  [*] Sat Jan 28 02:07:36 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.407134 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.1857 & F1 0.3133
01/28/2023 02:07:38 AM  [*] Sat Jan 28 02:07:38 2023:    1    | Tr.loss: 0.540505 | Elapsed:   15.15  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8007
01/28/2023 02:07:38 AM  [*] Started epoch: 2
01/28/2023 02:07:38 AM  [*] Sat Jan 28 02:07:38 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.554733 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0444 & F1 0.0851
01/28/2023 02:07:45 AM  [*] Sat Jan 28 02:07:45 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.381024 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.7231 & F1 0.8393
01/28/2023 02:07:51 AM  [*] Sat Jan 28 02:07:51 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.243598 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.8769 & F1 0.9344
01/28/2023 02:07:54 AM  [*] Sat Jan 28 02:07:54 2023:    2    | Tr.loss: 0.327183 | Elapsed:   15.20  s | FPR 0.0003 -> TPR: 0.13 & F1: 0.23 | AUC: 0.9203
01/28/2023 02:07:54 AM  [*] Started epoch: 3
01/28/2023 02:07:54 AM  [*] Sat Jan 28 02:07:54 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.365766 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.5455 & F1 0.7059
01/28/2023 02:08:00 AM  [*] Sat Jan 28 02:08:00 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.167164 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.9014 & F1 0.9481
01/28/2023 02:08:06 AM  [*] Sat Jan 28 02:08:06 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.137412 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.7101 & F1 0.8305
01/28/2023 02:08:09 AM  [*] Sat Jan 28 02:08:09 2023:    3    | Tr.loss: 0.231304 | Elapsed:   15.23  s | FPR 0.0003 -> TPR: 0.27 & F1: 0.43 | AUC: 0.9628
01/28/2023 02:08:15 AM  [*] Started epoch: 1
01/28/2023 02:08:15 AM  [*] Sat Jan 28 02:08:15 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.066309 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 02:08:21 AM  [*] Sat Jan 28 02:08:21 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.447014 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.0952 & F1 0.1739
01/28/2023 02:08:27 AM  [*] Sat Jan 28 02:08:27 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.302358 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.6515 & F1 0.7890
01/28/2023 02:08:30 AM  [*] Sat Jan 28 02:08:30 2023:    1    | Tr.loss: 0.537041 | Elapsed:   15.16  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7977
01/28/2023 02:08:30 AM  [*] Started epoch: 2
01/28/2023 02:08:30 AM  [*] Sat Jan 28 02:08:30 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.324687 | Elapsed: 0.05s | FPR 0.0003 -> TPR 0.4800 & F1 0.6486
01/28/2023 02:08:36 AM  [*] Sat Jan 28 02:08:36 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.337527 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.4306 & F1 0.6019
01/28/2023 02:08:42 AM  [*] Sat Jan 28 02:08:42 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.191787 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.5522 & F1 0.7115
01/28/2023 02:08:45 AM  [*] Sat Jan 28 02:08:45 2023:    2    | Tr.loss: 0.315918 | Elapsed:   15.17  s | FPR 0.0003 -> TPR: 0.16 & F1: 0.28 | AUC: 0.9262
01/28/2023 02:08:45 AM  [*] Started epoch: 3
01/28/2023 02:08:45 AM  [*] Sat Jan 28 02:08:45 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.384751 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.6905 & F1 0.8169
01/28/2023 02:08:51 AM  [*] Sat Jan 28 02:08:51 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.209204 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.8333 & F1 0.9091
01/28/2023 02:08:57 AM  [*] Sat Jan 28 02:08:57 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.347690 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.3529 & F1 0.5217
01/28/2023 02:09:00 AM  [*] Sat Jan 28 02:09:00 2023:    3    | Tr.loss: 0.231100 | Elapsed:   15.17  s | FPR 0.0003 -> TPR: 0.28 & F1: 0.44 | AUC: 0.9630
01/28/2023 02:09:06 AM  [*] Started epoch: 1
01/28/2023 02:09:06 AM  [*] Sat Jan 28 02:09:06 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 4.056074 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 02:09:12 AM  [*] Sat Jan 28 02:09:12 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.517728 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.2812 & F1 0.4390
01/28/2023 02:09:18 AM  [*] Sat Jan 28 02:09:18 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.374566 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.2143 & F1 0.3529
01/28/2023 02:09:21 AM  [*] Sat Jan 28 02:09:21 2023:    1    | Tr.loss: 0.547066 | Elapsed:   15.15  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8009
01/28/2023 02:09:21 AM  [*] Started epoch: 2
01/28/2023 02:09:21 AM  [*] Sat Jan 28 02:09:21 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.449744 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.4595 & F1 0.6296
01/28/2023 02:09:27 AM  [*] Sat Jan 28 02:09:27 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.283269 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.7656 & F1 0.8673
01/28/2023 02:09:33 AM  [*] Sat Jan 28 02:09:33 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.310894 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.4848 & F1 0.6531
01/28/2023 02:09:36 AM  [*] Sat Jan 28 02:09:36 2023:    2    | Tr.loss: 0.328412 | Elapsed:   15.20  s | FPR 0.0003 -> TPR: 0.15 & F1: 0.26 | AUC: 0.9205
01/28/2023 02:09:36 AM  [*] Started epoch: 3
01/28/2023 02:09:36 AM  [*] Sat Jan 28 02:09:36 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.273283 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.6512 & F1 0.7887
01/28/2023 02:09:42 AM  [*] Sat Jan 28 02:09:42 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.282032 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.7794 & F1 0.8760
01/28/2023 02:09:49 AM  [*] Sat Jan 28 02:09:49 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.208462 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.5000 & F1 0.6667
01/28/2023 02:09:51 AM  [*] Sat Jan 28 02:09:51 2023:    3    | Tr.loss: 0.234632 | Elapsed:   15.20  s | FPR 0.0003 -> TPR: 0.35 & F1: 0.52 | AUC: 0.9618
01/28/2023 02:09:57 AM  [*] Started epoch: 1
01/28/2023 02:09:57 AM  [*] Sat Jan 28 02:09:57 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.386963 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 02:10:03 AM  [*] Sat Jan 28 02:10:03 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.490980 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.1000 & F1 0.1818
01/28/2023 02:10:10 AM  [*] Sat Jan 28 02:10:10 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.412108 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.2295 & F1 0.3733
01/28/2023 02:10:12 AM  [*] Sat Jan 28 02:10:12 2023:    1    | Tr.loss: 0.538897 | Elapsed:   15.18  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8052
01/28/2023 02:10:12 AM  [*] Started epoch: 2
01/28/2023 02:10:12 AM  [*] Sat Jan 28 02:10:12 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.383923 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.5476 & F1 0.7077
01/28/2023 02:10:18 AM  [*] Sat Jan 28 02:10:18 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.379996 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.4000 & F1 0.5714
01/28/2023 02:10:25 AM  [*] Sat Jan 28 02:10:25 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.292856 | Elapsed: 6.26s | FPR 0.0003 -> TPR 0.2763 & F1 0.4330
01/28/2023 02:10:27 AM  [*] Sat Jan 28 02:10:27 2023:    2    | Tr.loss: 0.324805 | Elapsed:   15.21  s | FPR 0.0003 -> TPR: 0.15 & F1: 0.27 | AUC: 0.9219
01/28/2023 02:10:27 AM  [*] Started epoch: 3
01/28/2023 02:10:27 AM  [*] Sat Jan 28 02:10:27 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.275334 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.7105 & F1 0.8308
01/28/2023 02:10:34 AM  [*] Sat Jan 28 02:10:34 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.242343 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.8364 & F1 0.9109
01/28/2023 02:10:40 AM  [*] Sat Jan 28 02:10:40 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.210142 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.6901 & F1 0.8167
01/28/2023 02:10:43 AM  [*] Sat Jan 28 02:10:43 2023:    3    | Tr.loss: 0.232314 | Elapsed:   15.17  s | FPR 0.0003 -> TPR: 0.28 & F1: 0.43 | AUC: 0.9622
01/28/2023 02:10:48 AM  [*] Started epoch: 1
01/28/2023 02:10:48 AM  [*] Sat Jan 28 02:10:48 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.067742 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 02:10:55 AM  [*] Sat Jan 28 02:10:55 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.417916 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.1304 & F1 0.2308
01/28/2023 02:11:01 AM  [*] Sat Jan 28 02:11:01 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.383315 | Elapsed: 6.26s | FPR 0.0003 -> TPR 0.1857 & F1 0.3133
01/28/2023 02:11:03 AM  [*] Sat Jan 28 02:11:03 2023:    1    | Tr.loss: 0.536657 | Elapsed:   15.18  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8026
01/28/2023 02:11:03 AM  [*] Started epoch: 2
01/28/2023 02:11:04 AM  [*] Sat Jan 28 02:11:04 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.386878 | Elapsed: 0.05s | FPR 0.0003 -> TPR 0.1591 & F1 0.2745
01/28/2023 02:11:10 AM  [*] Sat Jan 28 02:11:10 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.293785 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.3793 & F1 0.5500
01/28/2023 02:11:16 AM  [*] Sat Jan 28 02:11:16 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.328484 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.6765 & F1 0.8070
01/28/2023 02:11:19 AM  [*] Sat Jan 28 02:11:19 2023:    2    | Tr.loss: 0.322489 | Elapsed:   15.19  s | FPR 0.0003 -> TPR: 0.14 & F1: 0.25 | AUC: 0.9229
01/28/2023 02:11:19 AM  [*] Started epoch: 3
01/28/2023 02:11:19 AM  [*] Sat Jan 28 02:11:19 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.270869 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.6136 & F1 0.7606
01/28/2023 02:11:25 AM  [*] Sat Jan 28 02:11:25 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.237063 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.7313 & F1 0.8448
01/28/2023 02:11:31 AM  [*] Sat Jan 28 02:11:31 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.263613 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.7778 & F1 0.8750
01/28/2023 02:11:34 AM  [*] Sat Jan 28 02:11:34 2023:    3    | Tr.loss: 0.238412 | Elapsed:   15.18  s | FPR 0.0003 -> TPR: 0.20 & F1: 0.33 | AUC: 0.9605
01/28/2023 02:11:40 AM  [*] Started epoch: 1
01/28/2023 02:11:40 AM  [*] Sat Jan 28 02:11:40 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 2.772946 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 02:11:46 AM  [*] Sat Jan 28 02:11:46 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.422459 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.2394 & F1 0.3864
01/28/2023 02:11:52 AM  [*] Sat Jan 28 02:11:52 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.369558 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.3286 & F1 0.4946
01/28/2023 02:11:55 AM  [*] Sat Jan 28 02:11:55 2023:    1    | Tr.loss: 0.554931 | Elapsed:   15.13  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7961
01/28/2023 02:11:55 AM  [*] Started epoch: 2
01/28/2023 02:11:55 AM  [*] Sat Jan 28 02:11:55 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.323126 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.5581 & F1 0.7164
01/28/2023 02:12:01 AM  [*] Sat Jan 28 02:12:01 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.270023 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.4930 & F1 0.6604
01/28/2023 02:12:07 AM  [*] Sat Jan 28 02:12:07 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.216739 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.8028 & F1 0.8906
01/28/2023 02:12:10 AM  [*] Sat Jan 28 02:12:10 2023:    2    | Tr.loss: 0.327760 | Elapsed:   15.19  s | FPR 0.0003 -> TPR: 0.13 & F1: 0.23 | AUC: 0.9208
01/28/2023 02:12:10 AM  [*] Started epoch: 3
01/28/2023 02:12:10 AM  [*] Sat Jan 28 02:12:10 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.284743 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.6744 & F1 0.8056
01/28/2023 02:12:16 AM  [*] Sat Jan 28 02:12:16 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.326680 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.9189 & F1 0.9577
01/28/2023 02:12:22 AM  [*] Sat Jan 28 02:12:22 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.192927 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.4937 & F1 0.6610
01/28/2023 02:12:25 AM  [*] Sat Jan 28 02:12:25 2023:    3    | Tr.loss: 0.240325 | Elapsed:   15.18  s | FPR 0.0003 -> TPR: 0.21 & F1: 0.35 | AUC: 0.9597
01/28/2023 02:12:31 AM  [*] Started epoch: 1
01/28/2023 02:12:31 AM  [*] Sat Jan 28 02:12:31 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.284782 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 02:12:37 AM  [*] Sat Jan 28 02:12:37 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.519023 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.1714 & F1 0.2927
01/28/2023 02:12:43 AM  [*] Sat Jan 28 02:12:43 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.332988 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.5294 & F1 0.6923
01/28/2023 02:12:46 AM  [*] Sat Jan 28 02:12:46 2023:    1    | Tr.loss: 0.552874 | Elapsed:   15.14  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7973
01/28/2023 02:12:46 AM  [*] Started epoch: 2
01/28/2023 02:12:46 AM  [*] Sat Jan 28 02:12:46 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.401200 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.5476 & F1 0.7077
01/28/2023 02:12:52 AM  [*] Sat Jan 28 02:12:52 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.282860 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.7460 & F1 0.8545
01/28/2023 02:12:58 AM  [*] Sat Jan 28 02:12:58 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.287090 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.7536 & F1 0.8595
01/28/2023 02:13:01 AM  [*] Sat Jan 28 02:13:01 2023:    2    | Tr.loss: 0.321144 | Elapsed:   15.27  s | FPR 0.0003 -> TPR: 0.12 & F1: 0.22 | AUC: 0.9232
01/28/2023 02:13:01 AM  [*] Started epoch: 3
01/28/2023 02:13:01 AM  [*] Sat Jan 28 02:13:01 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.287683 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.3243 & F1 0.4898
01/28/2023 02:13:07 AM  [*] Sat Jan 28 02:13:07 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.289416 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.2113 & F1 0.3488
01/28/2023 02:13:14 AM  [*] Sat Jan 28 02:13:14 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.210730 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.6197 & F1 0.7652
01/28/2023 02:13:16 AM  [*] Sat Jan 28 02:13:16 2023:    3    | Tr.loss: 0.234616 | Elapsed:   15.16  s | FPR 0.0003 -> TPR: 0.24 & F1: 0.39 | AUC: 0.9620
01/28/2023 02:13:22 AM  [*] Started epoch: 1
01/28/2023 02:13:22 AM  [*] Sat Jan 28 02:13:22 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 2.888906 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 02:13:28 AM  [*] Sat Jan 28 02:13:28 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.331143 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.1286 & F1 0.2278
01/28/2023 02:13:35 AM  [*] Sat Jan 28 02:13:35 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.481517 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.3056 & F1 0.4681
01/28/2023 02:13:37 AM  [*] Sat Jan 28 02:13:37 2023:    1    | Tr.loss: 0.545515 | Elapsed:   15.12  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8029
01/28/2023 02:13:37 AM  [*] Started epoch: 2
01/28/2023 02:13:37 AM  [*] Sat Jan 28 02:13:37 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.319240 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.4681 & F1 0.6377
01/28/2023 02:13:43 AM  [*] Sat Jan 28 02:13:43 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.294387 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.3768 & F1 0.5474
01/28/2023 02:13:50 AM  [*] Sat Jan 28 02:13:50 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.209046 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.5000 & F1 0.6667
01/28/2023 02:13:52 AM  [*] Sat Jan 28 02:13:52 2023:    2    | Tr.loss: 0.325793 | Elapsed:   15.19  s | FPR 0.0003 -> TPR: 0.15 & F1: 0.26 | AUC: 0.9217
01/28/2023 02:13:52 AM  [*] Started epoch: 3
01/28/2023 02:13:52 AM  [*] Sat Jan 28 02:13:52 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.164133 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.9231 & F1 0.9600
01/28/2023 02:13:59 AM  [*] Sat Jan 28 02:13:59 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.167185 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.7703 & F1 0.8702
01/28/2023 02:14:05 AM  [*] Sat Jan 28 02:14:05 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.225317 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.8382 & F1 0.9120
01/28/2023 02:14:07 AM  [*] Sat Jan 28 02:14:07 2023:    3    | Tr.loss: 0.237485 | Elapsed:   15.19  s | FPR 0.0003 -> TPR: 0.26 & F1: 0.41 | AUC: 0.9610
01/28/2023 02:14:13 AM  [*] Started epoch: 1
01/28/2023 02:14:13 AM  [*] Sat Jan 28 02:14:13 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.652443 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 02:14:20 AM  [*] Sat Jan 28 02:14:20 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.524396 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.4032 & F1 0.5747
01/28/2023 02:14:26 AM  [*] Sat Jan 28 02:14:26 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.478320 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.0156 & F1 0.0308
01/28/2023 02:14:28 AM  [*] Sat Jan 28 02:14:28 2023:    1    | Tr.loss: 0.552826 | Elapsed:   15.18  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7968
01/28/2023 02:14:28 AM  [*] Started epoch: 2
01/28/2023 02:14:28 AM  [*] Sat Jan 28 02:14:28 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.344861 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.3333 & F1 0.5000
01/28/2023 02:14:35 AM  [*] Sat Jan 28 02:14:35 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.226802 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.6197 & F1 0.7652
01/28/2023 02:14:41 AM  [*] Sat Jan 28 02:14:41 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.294848 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.6667 & F1 0.8000
01/28/2023 02:14:44 AM  [*] Sat Jan 28 02:14:44 2023:    2    | Tr.loss: 0.322147 | Elapsed:   15.20  s | FPR 0.0003 -> TPR: 0.17 & F1: 0.29 | AUC: 0.9222
01/28/2023 02:14:44 AM  [*] Started epoch: 3
01/28/2023 02:14:44 AM  [*] Sat Jan 28 02:14:44 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.230683 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.7872 & F1 0.8810
01/28/2023 02:14:50 AM  [*] Sat Jan 28 02:14:50 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.185901 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.7619 & F1 0.8649
01/28/2023 02:14:56 AM  [*] Sat Jan 28 02:14:56 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.213988 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.8816 & F1 0.9371
01/28/2023 02:14:59 AM  [*] Sat Jan 28 02:14:59 2023:    3    | Tr.loss: 0.229355 | Elapsed:   15.19  s | FPR 0.0003 -> TPR: 0.21 & F1: 0.35 | AUC: 0.9636
01/28/2023 02:15:05 AM  [*] Started epoch: 1
01/28/2023 02:15:05 AM  [*] Sat Jan 28 02:15:05 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 2.696117 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 02:15:11 AM  [*] Sat Jan 28 02:15:11 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.410619 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.2609 & F1 0.4138
01/28/2023 02:15:17 AM  [*] Sat Jan 28 02:15:17 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.335826 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.0685 & F1 0.1282
01/28/2023 02:15:20 AM  [*] Sat Jan 28 02:15:20 2023:    1    | Tr.loss: 0.542836 | Elapsed:   15.12  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8042
01/28/2023 02:15:20 AM  [*] Started epoch: 2
01/28/2023 02:15:20 AM  [*] Sat Jan 28 02:15:20 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.362487 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.5641 & F1 0.7213
01/28/2023 02:15:26 AM  [*] Sat Jan 28 02:15:26 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.345722 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.4412 & F1 0.6122
01/28/2023 02:15:32 AM  [*] Sat Jan 28 02:15:32 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.177797 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.7333 & F1 0.8462
01/28/2023 02:15:35 AM  [*] Sat Jan 28 02:15:35 2023:    2    | Tr.loss: 0.325984 | Elapsed:   15.20  s | FPR 0.0003 -> TPR: 0.14 & F1: 0.25 | AUC: 0.9216
01/28/2023 02:15:35 AM  [*] Started epoch: 3
01/28/2023 02:15:35 AM  [*] Sat Jan 28 02:15:35 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.232584 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.7619 & F1 0.8649
01/28/2023 02:15:41 AM  [*] Sat Jan 28 02:15:41 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.193072 | Elapsed: 6.27s | FPR 0.0003 -> TPR 0.7581 & F1 0.8624
01/28/2023 02:15:47 AM  [*] Sat Jan 28 02:15:47 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.381665 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.6389 & F1 0.7797
01/28/2023 02:15:50 AM  [*] Sat Jan 28 02:15:50 2023:    3    | Tr.loss: 0.238469 | Elapsed:   15.26  s | FPR 0.0003 -> TPR: 0.36 & F1: 0.53 | AUC: 0.9606
01/28/2023 02:15:56 AM  [*] Started epoch: 1
01/28/2023 02:15:56 AM  [*] Sat Jan 28 02:15:56 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.428617 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 02:16:02 AM  [*] Sat Jan 28 02:16:02 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.532959 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.0317 & F1 0.0615
01/28/2023 02:16:08 AM  [*] Sat Jan 28 02:16:08 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.336010 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.4706 & F1 0.6400
01/28/2023 02:16:11 AM  [*] Sat Jan 28 02:16:11 2023:    1    | Tr.loss: 0.544568 | Elapsed:   15.18  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8005
01/28/2023 02:16:11 AM  [*] Started epoch: 2
01/28/2023 02:16:11 AM  [*] Sat Jan 28 02:16:11 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.486583 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.1351 & F1 0.2381
01/28/2023 02:16:17 AM  [*] Sat Jan 28 02:16:17 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.257086 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.5429 & F1 0.7037
01/28/2023 02:16:23 AM  [*] Sat Jan 28 02:16:23 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.233485 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.2879 & F1 0.4471
01/28/2023 02:16:26 AM  [*] Sat Jan 28 02:16:26 2023:    2    | Tr.loss: 0.326190 | Elapsed:   15.16  s | FPR 0.0003 -> TPR: 0.14 & F1: 0.25 | AUC: 0.9209
01/28/2023 02:16:26 AM  [*] Started epoch: 3
01/28/2023 02:16:26 AM  [*] Sat Jan 28 02:16:26 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.355662 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.2162 & F1 0.3556
01/28/2023 02:16:32 AM  [*] Sat Jan 28 02:16:32 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.255645 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.8514 & F1 0.9197
01/28/2023 02:16:39 AM  [*] Sat Jan 28 02:16:39 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.252223 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.7031 & F1 0.8257
01/28/2023 02:16:41 AM  [*] Sat Jan 28 02:16:41 2023:    3    | Tr.loss: 0.237969 | Elapsed:   15.19  s | FPR 0.0003 -> TPR: 0.29 & F1: 0.45 | AUC: 0.9605
01/28/2023 02:16:47 AM  [*] Started epoch: 1
01/28/2023 02:16:47 AM  [*] Sat Jan 28 02:16:47 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.286170 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 02:16:53 AM  [*] Sat Jan 28 02:16:53 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.497446 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.2833 & F1 0.4416
01/28/2023 02:17:00 AM  [*] Sat Jan 28 02:17:00 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.403702 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.3051 & F1 0.4675
01/28/2023 02:17:02 AM  [*] Sat Jan 28 02:17:02 2023:    1    | Tr.loss: 0.549933 | Elapsed:   15.16  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7985
01/28/2023 02:17:02 AM  [*] Started epoch: 2
01/28/2023 02:17:02 AM  [*] Sat Jan 28 02:17:02 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.302018 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.8913 & F1 0.9425
01/28/2023 02:17:08 AM  [*] Sat Jan 28 02:17:08 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.332175 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.5278 & F1 0.6909
01/28/2023 02:17:15 AM  [*] Sat Jan 28 02:17:15 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.399547 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.5231 & F1 0.6869
01/28/2023 02:17:17 AM  [*] Sat Jan 28 02:17:17 2023:    2    | Tr.loss: 0.324732 | Elapsed:   15.18  s | FPR 0.0003 -> TPR: 0.13 & F1: 0.24 | AUC: 0.9222
01/28/2023 02:17:17 AM  [*] Started epoch: 3
01/28/2023 02:17:17 AM  [*] Sat Jan 28 02:17:17 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.383094 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.4000 & F1 0.5714
01/28/2023 02:17:24 AM  [*] Sat Jan 28 02:17:24 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.227685 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.4857 & F1 0.6538
01/28/2023 02:17:30 AM  [*] Sat Jan 28 02:17:30 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.152632 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.8358 & F1 0.9106
01/28/2023 02:17:33 AM  [*] Sat Jan 28 02:17:33 2023:    3    | Tr.loss: 0.229755 | Elapsed:   15.18  s | FPR 0.0003 -> TPR: 0.22 & F1: 0.36 | AUC: 0.9633
01/28/2023 02:17:38 AM  [*] Started epoch: 1
01/28/2023 02:17:38 AM  [*] Sat Jan 28 02:17:38 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 2.363154 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 02:17:45 AM  [*] Sat Jan 28 02:17:45 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.380659 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.3182 & F1 0.4828
01/28/2023 02:17:51 AM  [*] Sat Jan 28 02:17:51 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.412854 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.1970 & F1 0.3291
01/28/2023 02:17:53 AM  [*] Sat Jan 28 02:17:53 2023:    1    | Tr.loss: 0.544754 | Elapsed:   15.13  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8023
01/28/2023 02:17:53 AM  [*] Started epoch: 2
01/28/2023 02:17:53 AM  [*] Sat Jan 28 02:17:53 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.390508 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.4091 & F1 0.5806
01/28/2023 02:18:00 AM  [*] Sat Jan 28 02:18:00 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.340520 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.2895 & F1 0.4490
01/28/2023 02:18:06 AM  [*] Sat Jan 28 02:18:06 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.298726 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.6719 & F1 0.8037
01/28/2023 02:18:09 AM  [*] Sat Jan 28 02:18:09 2023:    2    | Tr.loss: 0.325611 | Elapsed:   15.21  s | FPR 0.0003 -> TPR: 0.16 & F1: 0.27 | AUC: 0.9215
01/28/2023 02:18:09 AM  [*] Started epoch: 3
01/28/2023 02:18:09 AM  [*] Sat Jan 28 02:18:09 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.141426 | Elapsed: 0.07s | FPR 0.0003 -> TPR 1.0000 & F1 1.0000
01/28/2023 02:18:15 AM  [*] Sat Jan 28 02:18:15 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.284862 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.7576 & F1 0.8621
01/28/2023 02:18:21 AM  [*] Sat Jan 28 02:18:21 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.216593 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.7027 & F1 0.8254
01/28/2023 02:18:24 AM  [*] Sat Jan 28 02:18:24 2023:    3    | Tr.loss: 0.237676 | Elapsed:   15.19  s | FPR 0.0003 -> TPR: 0.34 & F1: 0.51 | AUC: 0.9607
01/28/2023 02:18:30 AM  [*] Started epoch: 1
01/28/2023 02:18:30 AM  [*] Sat Jan 28 02:18:30 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.084471 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 02:18:36 AM  [*] Sat Jan 28 02:18:36 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.456516 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.2879 & F1 0.4471
01/28/2023 02:18:42 AM  [*] Sat Jan 28 02:18:42 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.371857 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.3016 & F1 0.4634
01/28/2023 02:18:45 AM  [*] Sat Jan 28 02:18:45 2023:    1    | Tr.loss: 0.535692 | Elapsed:   15.16  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8022
01/28/2023 02:18:45 AM  [*] Started epoch: 2
01/28/2023 02:18:45 AM  [*] Sat Jan 28 02:18:45 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.339854 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.5854 & F1 0.7385
01/28/2023 02:18:51 AM  [*] Sat Jan 28 02:18:51 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.317323 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.3036 & F1 0.4658
01/28/2023 02:18:57 AM  [*] Sat Jan 28 02:18:57 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.299596 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.3553 & F1 0.5243
01/28/2023 02:19:00 AM  [*] Sat Jan 28 02:19:00 2023:    2    | Tr.loss: 0.324348 | Elapsed:   15.22  s | FPR 0.0003 -> TPR: 0.16 & F1: 0.27 | AUC: 0.9223
01/28/2023 02:19:00 AM  [*] Started epoch: 3
01/28/2023 02:19:00 AM  [*] Sat Jan 28 02:19:00 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.266699 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.7805 & F1 0.8767
01/28/2023 02:19:06 AM  [*] Sat Jan 28 02:19:06 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.373248 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.5857 & F1 0.7387
01/28/2023 02:19:12 AM  [*] Sat Jan 28 02:19:12 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.342478 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.5692 & F1 0.7255
01/28/2023 02:19:15 AM  [*] Sat Jan 28 02:19:15 2023:    3    | Tr.loss: 0.231661 | Elapsed:   15.24  s | FPR 0.0003 -> TPR: 0.28 & F1: 0.44 | AUC: 0.9630
01/28/2023 02:19:21 AM  [*] Started epoch: 1
01/28/2023 02:19:21 AM  [*] Sat Jan 28 02:19:21 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.548720 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 02:19:27 AM  [*] Sat Jan 28 02:19:27 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.443613 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.1940 & F1 0.3250
01/28/2023 02:19:33 AM  [*] Sat Jan 28 02:19:33 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.387605 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.0746 & F1 0.1389
01/28/2023 02:19:36 AM  [*] Sat Jan 28 02:19:36 2023:    1    | Tr.loss: 0.545692 | Elapsed:   15.18  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8015
01/28/2023 02:19:36 AM  [*] Started epoch: 2
01/28/2023 02:19:36 AM  [*] Sat Jan 28 02:19:36 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.400026 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.6667 & F1 0.8000
01/28/2023 02:19:42 AM  [*] Sat Jan 28 02:19:42 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.366877 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.5362 & F1 0.6981
01/28/2023 02:19:49 AM  [*] Sat Jan 28 02:19:49 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.266052 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.7260 & F1 0.8413
01/28/2023 02:19:51 AM  [*] Sat Jan 28 02:19:51 2023:    2    | Tr.loss: 0.326235 | Elapsed:   15.21  s | FPR 0.0003 -> TPR: 0.12 & F1: 0.22 | AUC: 0.9214
01/28/2023 02:19:51 AM  [*] Started epoch: 3
01/28/2023 02:19:51 AM  [*] Sat Jan 28 02:19:51 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.204378 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.8085 & F1 0.8941
01/28/2023 02:19:58 AM  [*] Sat Jan 28 02:19:58 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.216734 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.7971 & F1 0.8871
01/28/2023 02:20:04 AM  [*] Sat Jan 28 02:20:04 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.222278 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.8590 & F1 0.9241
01/28/2023 02:20:06 AM  [*] Sat Jan 28 02:20:06 2023:    3    | Tr.loss: 0.233404 | Elapsed:   15.21  s | FPR 0.0003 -> TPR: 0.35 & F1: 0.52 | AUC: 0.9618
01/28/2023 02:20:12 AM  [*] Started epoch: 1
01/28/2023 02:20:12 AM  [*] Sat Jan 28 02:20:12 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.626872 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 02:20:19 AM  [*] Sat Jan 28 02:20:19 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.574427 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.1000 & F1 0.1818
01/28/2023 02:20:25 AM  [*] Sat Jan 28 02:20:25 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.408116 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.2031 & F1 0.3377
01/28/2023 02:20:27 AM  [*] Sat Jan 28 02:20:27 2023:    1    | Tr.loss: 0.551125 | Elapsed:   15.15  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7977
01/28/2023 02:20:27 AM  [*] Started epoch: 2
01/28/2023 02:20:27 AM  [*] Sat Jan 28 02:20:27 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.415211 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.5000 & F1 0.6667
01/28/2023 02:20:34 AM  [*] Sat Jan 28 02:20:34 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.358097 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.5000 & F1 0.6667
01/28/2023 02:20:40 AM  [*] Sat Jan 28 02:20:40 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.280286 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.5833 & F1 0.7368
01/28/2023 02:20:43 AM  [*] Sat Jan 28 02:20:43 2023:    2    | Tr.loss: 0.329145 | Elapsed:   15.22  s | FPR 0.0003 -> TPR: 0.12 & F1: 0.22 | AUC: 0.9200
01/28/2023 02:20:43 AM  [*] Started epoch: 3
01/28/2023 02:20:43 AM  [*] Sat Jan 28 02:20:43 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.321033 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.3778 & F1 0.5484
01/28/2023 02:20:49 AM  [*] Sat Jan 28 02:20:49 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.197422 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.7857 & F1 0.8800
01/28/2023 02:20:55 AM  [*] Sat Jan 28 02:20:55 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.221485 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.7941 & F1 0.8852
01/28/2023 02:20:58 AM  [*] Sat Jan 28 02:20:58 2023:    3    | Tr.loss: 0.236514 | Elapsed:   15.21  s | FPR 0.0003 -> TPR: 0.13 & F1: 0.24 | AUC: 0.9613
01/28/2023 02:21:03 AM  [*] Started epoch: 1
01/28/2023 02:21:04 AM  [*] Sat Jan 28 02:21:04 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 2.770773 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 02:21:10 AM  [*] Sat Jan 28 02:21:10 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.513865 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.0556 & F1 0.1053
01/28/2023 02:21:16 AM  [*] Sat Jan 28 02:21:16 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.372199 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.4127 & F1 0.5843
01/28/2023 02:21:19 AM  [*] Sat Jan 28 02:21:19 2023:    1    | Tr.loss: 0.542219 | Elapsed:   15.16  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8019
01/28/2023 02:21:19 AM  [*] Started epoch: 2
01/28/2023 02:21:19 AM  [*] Sat Jan 28 02:21:19 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.315445 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.5238 & F1 0.6875
01/28/2023 02:21:25 AM  [*] Sat Jan 28 02:21:25 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.271064 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.3492 & F1 0.5176
01/28/2023 02:21:31 AM  [*] Sat Jan 28 02:21:31 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.334791 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.3676 & F1 0.5376
01/28/2023 02:21:34 AM  [*] Sat Jan 28 02:21:34 2023:    2    | Tr.loss: 0.330144 | Elapsed:   15.20  s | FPR 0.0003 -> TPR: 0.16 & F1: 0.27 | AUC: 0.9194
01/28/2023 02:21:34 AM  [*] Started epoch: 3
01/28/2023 02:21:34 AM  [*] Sat Jan 28 02:21:34 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.249238 | Elapsed: 0.05s | FPR 0.0003 -> TPR 0.6304 & F1 0.7733
01/28/2023 02:21:40 AM  [*] Sat Jan 28 02:21:40 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.282107 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.6825 & F1 0.8113
01/28/2023 02:21:46 AM  [*] Sat Jan 28 02:21:46 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.215358 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.8333 & F1 0.9091
01/28/2023 02:21:49 AM  [*] Sat Jan 28 02:21:49 2023:    3    | Tr.loss: 0.235190 | Elapsed:   15.20  s | FPR 0.0003 -> TPR: 0.31 & F1: 0.48 | AUC: 0.9614
01/28/2023 02:21:55 AM  [*] Started epoch: 1
01/28/2023 02:21:55 AM  [*] Sat Jan 28 02:21:55 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.667087 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 02:22:01 AM  [*] Sat Jan 28 02:22:01 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.393515 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.2174 & F1 0.3571
01/28/2023 02:22:07 AM  [*] Sat Jan 28 02:22:07 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.391059 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.1918 & F1 0.3218
01/28/2023 02:22:10 AM  [*] Sat Jan 28 02:22:10 2023:    1    | Tr.loss: 0.554940 | Elapsed:   15.14  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7951
01/28/2023 02:22:10 AM  [*] Started epoch: 2
01/28/2023 02:22:10 AM  [*] Sat Jan 28 02:22:10 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.487102 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.1136 & F1 0.2041
01/28/2023 02:22:16 AM  [*] Sat Jan 28 02:22:16 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.298080 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.3125 & F1 0.4762
01/28/2023 02:22:22 AM  [*] Sat Jan 28 02:22:22 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.226641 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.9091 & F1 0.9524
01/28/2023 02:22:25 AM  [*] Sat Jan 28 02:22:25 2023:    2    | Tr.loss: 0.322483 | Elapsed:   15.19  s | FPR 0.0003 -> TPR: 0.11 & F1: 0.20 | AUC: 0.9235
01/28/2023 02:22:25 AM  [*] Started epoch: 3
01/28/2023 02:22:25 AM  [*] Sat Jan 28 02:22:25 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.242672 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.8605 & F1 0.9250
01/28/2023 02:22:31 AM  [*] Sat Jan 28 02:22:31 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.310163 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.7917 & F1 0.8837
01/28/2023 02:22:38 AM  [*] Sat Jan 28 02:22:38 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.100531 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.5395 & F1 0.7009
01/28/2023 02:22:40 AM  [*] Sat Jan 28 02:22:40 2023:    3    | Tr.loss: 0.233927 | Elapsed:   15.18  s | FPR 0.0003 -> TPR: 0.30 & F1: 0.46 | AUC: 0.9619
01/28/2023 02:22:45 AM Split: 1
01/28/2023 02:22:46 AM  [*] Started epoch: 1
01/28/2023 02:22:46 AM  [*] Sat Jan 28 02:22:46 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 4.452830 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.1778 & F1 0.3019
01/28/2023 02:22:52 AM  [*] Sat Jan 28 02:22:52 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.410486 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.3857 & F1 0.5567
01/28/2023 02:22:59 AM  [*] Sat Jan 28 02:22:59 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.471658 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.3529 & F1 0.5217
01/28/2023 02:23:01 AM  [*] Sat Jan 28 02:23:01 2023:    1    | Tr.loss: 0.533055 | Elapsed:   15.14  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.01 | AUC: 0.8325
01/28/2023 02:23:01 AM  [*] Started epoch: 2
01/28/2023 02:23:01 AM  [*] Sat Jan 28 02:23:01 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.338164 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.2143 & F1 0.3529
01/28/2023 02:23:07 AM  [*] Sat Jan 28 02:23:07 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.293900 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.6087 & F1 0.7568
01/28/2023 02:23:14 AM  [*] Sat Jan 28 02:23:14 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.275633 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.6462 & F1 0.7850
01/28/2023 02:23:16 AM  [*] Sat Jan 28 02:23:16 2023:    2    | Tr.loss: 0.306175 | Elapsed:   15.22  s | FPR 0.0003 -> TPR: 0.25 & F1: 0.41 | AUC: 0.9310
01/28/2023 02:23:16 AM  [*] Started epoch: 3
01/28/2023 02:23:16 AM  [*] Sat Jan 28 02:23:16 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.302071 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.7143 & F1 0.8333
01/28/2023 02:23:23 AM  [*] Sat Jan 28 02:23:23 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.227220 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.7077 & F1 0.8288
01/28/2023 02:23:29 AM  [*] Sat Jan 28 02:23:29 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.182048 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.7260 & F1 0.8413
01/28/2023 02:23:32 AM  [*] Sat Jan 28 02:23:32 2023:    3    | Tr.loss: 0.228928 | Elapsed:   15.19  s | FPR 0.0003 -> TPR: 0.30 & F1: 0.46 | AUC: 0.9622
01/28/2023 02:23:37 AM  [*] Started epoch: 1
01/28/2023 02:23:37 AM  [*] Sat Jan 28 02:23:37 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.456456 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0857 & F1 0.1579
01/28/2023 02:23:44 AM  [*] Sat Jan 28 02:23:44 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.371607 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.2206 & F1 0.3614
01/28/2023 02:23:50 AM  [*] Sat Jan 28 02:23:50 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.375895 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.4857 & F1 0.6538
01/28/2023 02:23:52 AM  [*] Sat Jan 28 02:23:52 2023:    1    | Tr.loss: 0.557812 | Elapsed:   15.18  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8247
01/28/2023 02:23:52 AM  [*] Started epoch: 2
01/28/2023 02:23:53 AM  [*] Sat Jan 28 02:23:53 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.306664 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.6957 & F1 0.8205
01/28/2023 02:23:59 AM  [*] Sat Jan 28 02:23:59 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.311574 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.6667 & F1 0.8000
01/28/2023 02:24:05 AM  [*] Sat Jan 28 02:24:05 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.424179 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.4118 & F1 0.5833
01/28/2023 02:24:08 AM  [*] Sat Jan 28 02:24:08 2023:    2    | Tr.loss: 0.314387 | Elapsed:   15.19  s | FPR 0.0003 -> TPR: 0.22 & F1: 0.37 | AUC: 0.9250
01/28/2023 02:24:08 AM  [*] Started epoch: 3
01/28/2023 02:24:08 AM  [*] Sat Jan 28 02:24:08 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.258233 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.6905 & F1 0.8169
01/28/2023 02:24:14 AM  [*] Sat Jan 28 02:24:14 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.221020 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.3333 & F1 0.5000
01/28/2023 02:24:20 AM  [*] Sat Jan 28 02:24:20 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.255402 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.7500 & F1 0.8571
01/28/2023 02:24:23 AM  [*] Sat Jan 28 02:24:23 2023:    3    | Tr.loss: 0.244373 | Elapsed:   15.17  s | FPR 0.0003 -> TPR: 0.33 & F1: 0.50 | AUC: 0.9556
01/28/2023 02:24:29 AM  [*] Started epoch: 1
01/28/2023 02:24:29 AM  [*] Sat Jan 28 02:24:29 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.559107 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.2667 & F1 0.4211
01/28/2023 02:24:35 AM  [*] Sat Jan 28 02:24:35 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.359513 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.1571 & F1 0.2716
01/28/2023 02:24:41 AM  [*] Sat Jan 28 02:24:41 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.339163 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.2000 & F1 0.3333
01/28/2023 02:24:44 AM  [*] Sat Jan 28 02:24:44 2023:    1    | Tr.loss: 0.577683 | Elapsed:   15.13  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8226
01/28/2023 02:24:44 AM  [*] Started epoch: 2
01/28/2023 02:24:44 AM  [*] Sat Jan 28 02:24:44 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.380687 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.7576 & F1 0.8621
01/28/2023 02:24:50 AM  [*] Sat Jan 28 02:24:50 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.336460 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.3731 & F1 0.5435
01/28/2023 02:24:56 AM  [*] Sat Jan 28 02:24:56 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.223664 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.6471 & F1 0.7857
01/28/2023 02:24:59 AM  [*] Sat Jan 28 02:24:59 2023:    2    | Tr.loss: 0.315105 | Elapsed:   15.19  s | FPR 0.0003 -> TPR: 0.24 & F1: 0.39 | AUC: 0.9240
01/28/2023 02:24:59 AM  [*] Started epoch: 3
01/28/2023 02:24:59 AM  [*] Sat Jan 28 02:24:59 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.161526 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.8571 & F1 0.9231
01/28/2023 02:25:05 AM  [*] Sat Jan 28 02:25:05 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.269266 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.7568 & F1 0.8615
01/28/2023 02:25:11 AM  [*] Sat Jan 28 02:25:11 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.264473 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.8182 & F1 0.9000
01/28/2023 02:25:14 AM  [*] Sat Jan 28 02:25:14 2023:    3    | Tr.loss: 0.235608 | Elapsed:   15.20  s | FPR 0.0003 -> TPR: 0.37 & F1: 0.54 | AUC: 0.9577
01/28/2023 02:25:20 AM  [*] Started epoch: 1
01/28/2023 02:25:20 AM  [*] Sat Jan 28 02:25:20 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.120121 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 02:25:26 AM  [*] Sat Jan 28 02:25:26 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.532539 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.1639 & F1 0.2817
01/28/2023 02:25:32 AM  [*] Sat Jan 28 02:25:32 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.255510 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.4143 & F1 0.5859
01/28/2023 02:25:35 AM  [*] Sat Jan 28 02:25:35 2023:    1    | Tr.loss: 0.458655 | Elapsed:   15.18  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8576
01/28/2023 02:25:35 AM  [*] Started epoch: 2
01/28/2023 02:25:35 AM  [*] Sat Jan 28 02:25:35 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.215326 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.8367 & F1 0.9111
01/28/2023 02:25:41 AM  [*] Sat Jan 28 02:25:41 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.251630 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.7838 & F1 0.8788
01/28/2023 02:25:48 AM  [*] Sat Jan 28 02:25:48 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.369466 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.5672 & F1 0.7238
01/28/2023 02:25:50 AM  [*] Sat Jan 28 02:25:50 2023:    2    | Tr.loss: 0.287331 | Elapsed:   15.20  s | FPR 0.0003 -> TPR: 0.21 & F1: 0.34 | AUC: 0.9381
01/28/2023 02:25:50 AM  [*] Started epoch: 3
01/28/2023 02:25:50 AM  [*] Sat Jan 28 02:25:50 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.376242 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.5854 & F1 0.7385
01/28/2023 02:25:56 AM  [*] Sat Jan 28 02:25:56 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.250417 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.7910 & F1 0.8833
01/28/2023 02:26:03 AM  [*] Sat Jan 28 02:26:03 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.104033 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.9155 & F1 0.9559
01/28/2023 02:26:05 AM  [*] Sat Jan 28 02:26:05 2023:    3    | Tr.loss: 0.227280 | Elapsed:   15.18  s | FPR 0.0003 -> TPR: 0.25 & F1: 0.40 | AUC: 0.9631
01/28/2023 02:26:11 AM  [*] Started epoch: 1
01/28/2023 02:26:11 AM  [*] Sat Jan 28 02:26:11 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 2.509345 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.2889 & F1 0.4483
01/28/2023 02:26:17 AM  [*] Sat Jan 28 02:26:17 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.492924 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.4118 & F1 0.5833
01/28/2023 02:26:24 AM  [*] Sat Jan 28 02:26:24 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.484573 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.6111 & F1 0.7586
01/28/2023 02:26:26 AM  [*] Sat Jan 28 02:26:26 2023:    1    | Tr.loss: 0.481439 | Elapsed:   15.17  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8514
01/28/2023 02:26:26 AM  [*] Started epoch: 2
01/28/2023 02:26:26 AM  [*] Sat Jan 28 02:26:26 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.311238 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.7442 & F1 0.8533
01/28/2023 02:26:33 AM  [*] Sat Jan 28 02:26:33 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.221483 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.6212 & F1 0.7664
01/28/2023 02:26:39 AM  [*] Sat Jan 28 02:26:39 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.318236 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.4478 & F1 0.6186
01/28/2023 02:26:41 AM  [*] Sat Jan 28 02:26:41 2023:    2    | Tr.loss: 0.297443 | Elapsed:   15.18  s | FPR 0.0003 -> TPR: 0.20 & F1: 0.33 | AUC: 0.9304
01/28/2023 02:26:41 AM  [*] Started epoch: 3
01/28/2023 02:26:41 AM  [*] Sat Jan 28 02:26:41 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.332714 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.7442 & F1 0.8533
01/28/2023 02:26:48 AM  [*] Sat Jan 28 02:26:48 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.299683 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.4928 & F1 0.6602
01/28/2023 02:26:54 AM  [*] Sat Jan 28 02:26:54 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.248570 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.8358 & F1 0.9106
01/28/2023 02:26:57 AM  [*] Sat Jan 28 02:26:57 2023:    3    | Tr.loss: 0.234927 | Elapsed:   15.21  s | FPR 0.0003 -> TPR: 0.37 & F1: 0.54 | AUC: 0.9593
01/28/2023 02:27:02 AM  [*] Started epoch: 1
01/28/2023 02:27:02 AM  [*] Sat Jan 28 02:27:02 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.163542 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.1702 & F1 0.2909
01/28/2023 02:27:09 AM  [*] Sat Jan 28 02:27:09 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.346749 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.4706 & F1 0.6400
01/28/2023 02:27:15 AM  [*] Sat Jan 28 02:27:15 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.355719 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.4355 & F1 0.6067
01/28/2023 02:27:18 AM  [*] Sat Jan 28 02:27:18 2023:    1    | Tr.loss: 0.491850 | Elapsed:   15.16  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8465
01/28/2023 02:27:18 AM  [*] Started epoch: 2
01/28/2023 02:27:18 AM  [*] Sat Jan 28 02:27:18 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.300512 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.4468 & F1 0.6176
01/28/2023 02:27:24 AM  [*] Sat Jan 28 02:27:24 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.318950 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.7042 & F1 0.8264
01/28/2023 02:27:30 AM  [*] Sat Jan 28 02:27:30 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.187010 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.5974 & F1 0.7480
01/28/2023 02:27:33 AM  [*] Sat Jan 28 02:27:33 2023:    2    | Tr.loss: 0.296411 | Elapsed:   15.19  s | FPR 0.0003 -> TPR: 0.30 & F1: 0.46 | AUC: 0.9328
01/28/2023 02:27:33 AM  [*] Started epoch: 3
01/28/2023 02:27:33 AM  [*] Sat Jan 28 02:27:33 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.250018 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.6667 & F1 0.8000
01/28/2023 02:27:39 AM  [*] Sat Jan 28 02:27:39 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.383376 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.5606 & F1 0.7184
01/28/2023 02:27:45 AM  [*] Sat Jan 28 02:27:45 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.228235 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.7917 & F1 0.8837
01/28/2023 02:27:48 AM  [*] Sat Jan 28 02:27:48 2023:    3    | Tr.loss: 0.233863 | Elapsed:   15.21  s | FPR 0.0003 -> TPR: 0.40 & F1: 0.57 | AUC: 0.9589
01/28/2023 02:27:54 AM  [*] Started epoch: 1
01/28/2023 02:27:54 AM  [*] Sat Jan 28 02:27:54 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.304000 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.3019 & F1 0.4638
01/28/2023 02:28:00 AM  [*] Sat Jan 28 02:28:00 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.376475 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.0580 & F1 0.1096
01/28/2023 02:28:06 AM  [*] Sat Jan 28 02:28:06 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.369732 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.5000 & F1 0.6667
01/28/2023 02:28:09 AM  [*] Sat Jan 28 02:28:09 2023:    1    | Tr.loss: 0.499373 | Elapsed:   15.17  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8451
01/28/2023 02:28:09 AM  [*] Started epoch: 2
01/28/2023 02:28:09 AM  [*] Sat Jan 28 02:28:09 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.305778 | Elapsed: 0.05s | FPR 0.0003 -> TPR 0.4565 & F1 0.6269
01/28/2023 02:28:15 AM  [*] Sat Jan 28 02:28:15 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.372503 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.3667 & F1 0.5366
01/28/2023 02:28:21 AM  [*] Sat Jan 28 02:28:21 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.413655 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.6308 & F1 0.7736
01/28/2023 02:28:24 AM  [*] Sat Jan 28 02:28:24 2023:    2    | Tr.loss: 0.301459 | Elapsed:   15.18  s | FPR 0.0003 -> TPR: 0.22 & F1: 0.36 | AUC: 0.9288
01/28/2023 02:28:24 AM  [*] Started epoch: 3
01/28/2023 02:28:24 AM  [*] Sat Jan 28 02:28:24 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.211135 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.8605 & F1 0.9250
01/28/2023 02:28:30 AM  [*] Sat Jan 28 02:28:30 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.184257 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.6479 & F1 0.7863
01/28/2023 02:28:37 AM  [*] Sat Jan 28 02:28:37 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.153601 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.8939 & F1 0.9440
01/28/2023 02:28:39 AM  [*] Sat Jan 28 02:28:39 2023:    3    | Tr.loss: 0.235772 | Elapsed:   15.19  s | FPR 0.0003 -> TPR: 0.36 & F1: 0.53 | AUC: 0.9591
01/28/2023 02:28:45 AM  [*] Started epoch: 1
01/28/2023 02:28:45 AM  [*] Sat Jan 28 02:28:45 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.884781 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0952 & F1 0.1739
01/28/2023 02:28:51 AM  [*] Sat Jan 28 02:28:51 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.318543 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.0615 & F1 0.1159
01/28/2023 02:28:57 AM  [*] Sat Jan 28 02:28:57 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.380643 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.2586 & F1 0.4110
01/28/2023 02:29:00 AM  [*] Sat Jan 28 02:29:00 2023:    1    | Tr.loss: 0.508045 | Elapsed:   15.20  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8439
01/28/2023 02:29:00 AM  [*] Started epoch: 2
01/28/2023 02:29:00 AM  [*] Sat Jan 28 02:29:00 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.223915 | Elapsed: 0.05s | FPR 0.0003 -> TPR 0.8478 & F1 0.9176
01/28/2023 02:29:06 AM  [*] Sat Jan 28 02:29:06 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.226779 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.7534 & F1 0.8594
01/28/2023 02:29:13 AM  [*] Sat Jan 28 02:29:13 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.207892 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.7222 & F1 0.8387
01/28/2023 02:29:15 AM  [*] Sat Jan 28 02:29:15 2023:    2    | Tr.loss: 0.298104 | Elapsed:   15.20  s | FPR 0.0003 -> TPR: 0.25 & F1: 0.40 | AUC: 0.9335
01/28/2023 02:29:15 AM  [*] Started epoch: 3
01/28/2023 02:29:15 AM  [*] Sat Jan 28 02:29:15 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.213550 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.8511 & F1 0.9195
01/28/2023 02:29:22 AM  [*] Sat Jan 28 02:29:22 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.102243 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.8904 & F1 0.9420
01/28/2023 02:29:28 AM  [*] Sat Jan 28 02:29:28 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.312627 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.8696 & F1 0.9302
01/28/2023 02:29:30 AM  [*] Sat Jan 28 02:29:30 2023:    3    | Tr.loss: 0.227917 | Elapsed:   15.17  s | FPR 0.0003 -> TPR: 0.36 & F1: 0.53 | AUC: 0.9616
01/28/2023 02:29:36 AM  [*] Started epoch: 1
01/28/2023 02:29:36 AM  [*] Sat Jan 28 02:29:36 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.098144 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.2791 & F1 0.4364
01/28/2023 02:29:43 AM  [*] Sat Jan 28 02:29:43 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.464373 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.2143 & F1 0.3529
01/28/2023 02:29:49 AM  [*] Sat Jan 28 02:29:49 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.482664 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.3857 & F1 0.5567
01/28/2023 02:29:51 AM  [*] Sat Jan 28 02:29:51 2023:    1    | Tr.loss: 0.533739 | Elapsed:   15.14  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8306
01/28/2023 02:29:51 AM  [*] Started epoch: 2
01/28/2023 02:29:51 AM  [*] Sat Jan 28 02:29:51 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.367142 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.4884 & F1 0.6562
01/28/2023 02:29:58 AM  [*] Sat Jan 28 02:29:58 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.222324 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.6986 & F1 0.8226
01/28/2023 02:30:04 AM  [*] Sat Jan 28 02:30:04 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.368949 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.6094 & F1 0.7573
01/28/2023 02:30:07 AM  [*] Sat Jan 28 02:30:07 2023:    2    | Tr.loss: 0.304312 | Elapsed:   15.21  s | FPR 0.0003 -> TPR: 0.27 & F1: 0.43 | AUC: 0.9289
01/28/2023 02:30:07 AM  [*] Started epoch: 3
01/28/2023 02:30:07 AM  [*] Sat Jan 28 02:30:07 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.275342 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.6429 & F1 0.7826
01/28/2023 02:30:13 AM  [*] Sat Jan 28 02:30:13 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.157709 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.8769 & F1 0.9344
01/28/2023 02:30:19 AM  [*] Sat Jan 28 02:30:19 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.219998 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.7778 & F1 0.8750
01/28/2023 02:30:22 AM  [*] Sat Jan 28 02:30:22 2023:    3    | Tr.loss: 0.239491 | Elapsed:   15.21  s | FPR 0.0003 -> TPR: 0.36 & F1: 0.53 | AUC: 0.9574
01/28/2023 02:30:27 AM  [*] Started epoch: 1
01/28/2023 02:30:27 AM  [*] Sat Jan 28 02:30:27 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 2.816742 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.3333 & F1 0.5000
01/28/2023 02:30:34 AM  [*] Sat Jan 28 02:30:34 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.471639 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.2857 & F1 0.4444
01/28/2023 02:30:40 AM  [*] Sat Jan 28 02:30:40 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.375051 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.3710 & F1 0.5412
01/28/2023 02:30:43 AM  [*] Sat Jan 28 02:30:43 2023:    1    | Tr.loss: 0.533024 | Elapsed:   15.17  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8325
01/28/2023 02:30:43 AM  [*] Started epoch: 2
01/28/2023 02:30:43 AM  [*] Sat Jan 28 02:30:43 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.278444 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.6098 & F1 0.7576
01/28/2023 02:30:49 AM  [*] Sat Jan 28 02:30:49 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.246514 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.7231 & F1 0.8393
01/28/2023 02:30:55 AM  [*] Sat Jan 28 02:30:55 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.230218 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.5323 & F1 0.6947
01/28/2023 02:30:58 AM  [*] Sat Jan 28 02:30:58 2023:    2    | Tr.loss: 0.304994 | Elapsed:   15.23  s | FPR 0.0003 -> TPR: 0.30 & F1: 0.46 | AUC: 0.9292
01/28/2023 02:30:58 AM  [*] Started epoch: 3
01/28/2023 02:30:58 AM  [*] Sat Jan 28 02:30:58 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.150382 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.8571 & F1 0.9231
01/28/2023 02:31:04 AM  [*] Sat Jan 28 02:31:04 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.222694 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.7031 & F1 0.8257
01/28/2023 02:31:10 AM  [*] Sat Jan 28 02:31:10 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.190994 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.8060 & F1 0.8926
01/28/2023 02:31:13 AM  [*] Sat Jan 28 02:31:13 2023:    3    | Tr.loss: 0.237208 | Elapsed:   15.23  s | FPR 0.0003 -> TPR: 0.28 & F1: 0.43 | AUC: 0.9577
01/28/2023 02:31:19 AM  [*] Started epoch: 1
01/28/2023 02:31:19 AM  [*] Sat Jan 28 02:31:19 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.882421 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.1000 & F1 0.1818
01/28/2023 02:31:25 AM  [*] Sat Jan 28 02:31:25 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.426155 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.2381 & F1 0.3846
01/28/2023 02:31:31 AM  [*] Sat Jan 28 02:31:31 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.431830 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.2833 & F1 0.4416
01/28/2023 02:31:34 AM  [*] Sat Jan 28 02:31:34 2023:    1    | Tr.loss: 0.537970 | Elapsed:   15.18  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8296
01/28/2023 02:31:34 AM  [*] Started epoch: 2
01/28/2023 02:31:34 AM  [*] Sat Jan 28 02:31:34 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.379098 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.3514 & F1 0.5200
01/28/2023 02:31:40 AM  [*] Sat Jan 28 02:31:40 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.316059 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.1935 & F1 0.3243
01/28/2023 02:31:46 AM  [*] Sat Jan 28 02:31:46 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.306123 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.6833 & F1 0.8119
01/28/2023 02:31:49 AM  [*] Sat Jan 28 02:31:49 2023:    2    | Tr.loss: 0.312714 | Elapsed:   15.17  s | FPR 0.0003 -> TPR: 0.24 & F1: 0.39 | AUC: 0.9253
01/28/2023 02:31:49 AM  [*] Started epoch: 3
01/28/2023 02:31:49 AM  [*] Sat Jan 28 02:31:49 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.190325 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.9184 & F1 0.9574
01/28/2023 02:31:55 AM  [*] Sat Jan 28 02:31:55 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.176355 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.7368 & F1 0.8485
01/28/2023 02:32:02 AM  [*] Sat Jan 28 02:32:02 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.307087 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.7761 & F1 0.8739
01/28/2023 02:32:04 AM  [*] Sat Jan 28 02:32:04 2023:    3    | Tr.loss: 0.246299 | Elapsed:   15.18  s | FPR 0.0003 -> TPR: 0.39 & F1: 0.56 | AUC: 0.9537
01/28/2023 02:32:10 AM  [*] Started epoch: 1
01/28/2023 02:32:10 AM  [*] Sat Jan 28 02:32:10 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.428467 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.2857 & F1 0.4444
01/28/2023 02:32:16 AM  [*] Sat Jan 28 02:32:16 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.409045 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.5152 & F1 0.6800
01/28/2023 02:32:23 AM  [*] Sat Jan 28 02:32:23 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.440797 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.3065 & F1 0.4691
01/28/2023 02:32:25 AM  [*] Sat Jan 28 02:32:25 2023:    1    | Tr.loss: 0.547634 | Elapsed:   15.15  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8303
01/28/2023 02:32:25 AM  [*] Started epoch: 2
01/28/2023 02:32:25 AM  [*] Sat Jan 28 02:32:25 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.407008 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.5366 & F1 0.6984
01/28/2023 02:32:31 AM  [*] Sat Jan 28 02:32:31 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.353113 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.3088 & F1 0.4719
01/28/2023 02:32:38 AM  [*] Sat Jan 28 02:32:38 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.360373 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.8286 & F1 0.9062
01/28/2023 02:32:40 AM  [*] Sat Jan 28 02:32:40 2023:    2    | Tr.loss: 0.309356 | Elapsed:   15.18  s | FPR 0.0003 -> TPR: 0.25 & F1: 0.40 | AUC: 0.9280
01/28/2023 02:32:40 AM  [*] Started epoch: 3
01/28/2023 02:32:40 AM  [*] Sat Jan 28 02:32:40 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.296696 | Elapsed: 0.05s | FPR 0.0003 -> TPR 0.6087 & F1 0.7568
01/28/2023 02:32:47 AM  [*] Sat Jan 28 02:32:47 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.199940 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.7778 & F1 0.8750
01/28/2023 02:32:53 AM  [*] Sat Jan 28 02:32:53 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.230919 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.8571 & F1 0.9231
01/28/2023 02:32:56 AM  [*] Sat Jan 28 02:32:56 2023:    3    | Tr.loss: 0.239152 | Elapsed:   15.16  s | FPR 0.0003 -> TPR: 0.34 & F1: 0.51 | AUC: 0.9573
01/28/2023 02:33:01 AM  [*] Started epoch: 1
01/28/2023 02:33:01 AM  [*] Sat Jan 28 02:33:01 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.617999 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.2000 & F1 0.3333
01/28/2023 02:33:08 AM  [*] Sat Jan 28 02:33:08 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.518347 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.0588 & F1 0.1111
01/28/2023 02:33:14 AM  [*] Sat Jan 28 02:33:14 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.318862 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.2903 & F1 0.4500
01/28/2023 02:33:16 AM  [*] Sat Jan 28 02:33:16 2023:    1    | Tr.loss: 0.559009 | Elapsed:   15.16  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8205
01/28/2023 02:33:16 AM  [*] Started epoch: 2
01/28/2023 02:33:17 AM  [*] Sat Jan 28 02:33:17 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.455501 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.2558 & F1 0.4074
01/28/2023 02:33:23 AM  [*] Sat Jan 28 02:33:23 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.238802 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.5065 & F1 0.6724
01/28/2023 02:33:29 AM  [*] Sat Jan 28 02:33:29 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.364773 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.4754 & F1 0.6444
01/28/2023 02:33:32 AM  [*] Sat Jan 28 02:33:32 2023:    2    | Tr.loss: 0.321666 | Elapsed:   15.21  s | FPR 0.0003 -> TPR: 0.18 & F1: 0.30 | AUC: 0.9198
01/28/2023 02:33:32 AM  [*] Started epoch: 3
01/28/2023 02:33:32 AM  [*] Sat Jan 28 02:33:32 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.336371 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.6000 & F1 0.7500
01/28/2023 02:33:38 AM  [*] Sat Jan 28 02:33:38 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.198328 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.6000 & F1 0.7500
01/28/2023 02:33:44 AM  [*] Sat Jan 28 02:33:44 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.155155 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.8438 & F1 0.9153
01/28/2023 02:33:47 AM  [*] Sat Jan 28 02:33:47 2023:    3    | Tr.loss: 0.242486 | Elapsed:   15.18  s | FPR 0.0003 -> TPR: 0.30 & F1: 0.47 | AUC: 0.9562
01/28/2023 02:33:53 AM  [*] Started epoch: 1
01/28/2023 02:33:53 AM  [*] Sat Jan 28 02:33:53 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 2.926762 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.1333 & F1 0.2353
01/28/2023 02:33:59 AM  [*] Sat Jan 28 02:33:59 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.430561 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.2237 & F1 0.3656
01/28/2023 02:34:05 AM  [*] Sat Jan 28 02:34:05 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.315825 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.3692 & F1 0.5393
01/28/2023 02:34:08 AM  [*] Sat Jan 28 02:34:08 2023:    1    | Tr.loss: 0.527916 | Elapsed:   15.14  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.01 | AUC: 0.8321
01/28/2023 02:34:08 AM  [*] Started epoch: 2
01/28/2023 02:34:08 AM  [*] Sat Jan 28 02:34:08 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.318194 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.7381 & F1 0.8493
01/28/2023 02:34:14 AM  [*] Sat Jan 28 02:34:14 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.334099 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.5909 & F1 0.7429
01/28/2023 02:34:20 AM  [*] Sat Jan 28 02:34:20 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.219862 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.6471 & F1 0.7857
01/28/2023 02:34:23 AM  [*] Sat Jan 28 02:34:23 2023:    2    | Tr.loss: 0.309454 | Elapsed:   15.24  s | FPR 0.0003 -> TPR: 0.24 & F1: 0.39 | AUC: 0.9270
01/28/2023 02:34:23 AM  [*] Started epoch: 3
01/28/2023 02:34:23 AM  [*] Sat Jan 28 02:34:23 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.326947 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.6458 & F1 0.7848
01/28/2023 02:34:29 AM  [*] Sat Jan 28 02:34:29 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.190831 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.7436 & F1 0.8529
01/28/2023 02:34:35 AM  [*] Sat Jan 28 02:34:35 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.316157 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.6714 & F1 0.8034
01/28/2023 02:34:38 AM  [*] Sat Jan 28 02:34:38 2023:    3    | Tr.loss: 0.235307 | Elapsed:   15.22  s | FPR 0.0003 -> TPR: 0.43 & F1: 0.60 | AUC: 0.9590
01/28/2023 02:34:44 AM  [*] Started epoch: 1
01/28/2023 02:34:44 AM  [*] Sat Jan 28 02:34:44 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 2.679251 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.2500 & F1 0.4000
01/28/2023 02:34:50 AM  [*] Sat Jan 28 02:34:50 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.377373 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.1781 & F1 0.3023
01/28/2023 02:34:56 AM  [*] Sat Jan 28 02:34:56 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.412679 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.2812 & F1 0.4390
01/28/2023 02:34:59 AM  [*] Sat Jan 28 02:34:59 2023:    1    | Tr.loss: 0.556824 | Elapsed:   15.17  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8275
01/28/2023 02:34:59 AM  [*] Started epoch: 2
01/28/2023 02:34:59 AM  [*] Sat Jan 28 02:34:59 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.383883 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.4872 & F1 0.6552
01/28/2023 02:35:05 AM  [*] Sat Jan 28 02:35:05 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.329430 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.6143 & F1 0.7611
01/28/2023 02:35:12 AM  [*] Sat Jan 28 02:35:12 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.237844 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.3651 & F1 0.5349
01/28/2023 02:35:14 AM  [*] Sat Jan 28 02:35:14 2023:    2    | Tr.loss: 0.315058 | Elapsed:   15.24  s | FPR 0.0003 -> TPR: 0.21 & F1: 0.35 | AUC: 0.9240
01/28/2023 02:35:14 AM  [*] Started epoch: 3
01/28/2023 02:35:14 AM  [*] Sat Jan 28 02:35:14 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.168517 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.9250 & F1 0.9610
01/28/2023 02:35:21 AM  [*] Sat Jan 28 02:35:21 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.321151 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.6984 & F1 0.8224
01/28/2023 02:35:27 AM  [*] Sat Jan 28 02:35:27 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.258298 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.7576 & F1 0.8621
01/28/2023 02:35:30 AM  [*] Sat Jan 28 02:35:30 2023:    3    | Tr.loss: 0.243466 | Elapsed:   15.25  s | FPR 0.0003 -> TPR: 0.41 & F1: 0.59 | AUC: 0.9569
01/28/2023 02:35:35 AM  [*] Started epoch: 1
01/28/2023 02:35:35 AM  [*] Sat Jan 28 02:35:35 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.274730 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0851 & F1 0.1569
01/28/2023 02:35:42 AM  [*] Sat Jan 28 02:35:42 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.387033 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.0469 & F1 0.0896
01/28/2023 02:35:48 AM  [*] Sat Jan 28 02:35:48 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.346695 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.3731 & F1 0.5435
01/28/2023 02:35:50 AM  [*] Sat Jan 28 02:35:50 2023:    1    | Tr.loss: 0.558717 | Elapsed:   15.19  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8243
01/28/2023 02:35:50 AM  [*] Started epoch: 2
01/28/2023 02:35:51 AM  [*] Sat Jan 28 02:35:51 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.272362 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.8250 & F1 0.9041
01/28/2023 02:35:57 AM  [*] Sat Jan 28 02:35:57 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.322861 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.4583 & F1 0.6286
01/28/2023 02:36:03 AM  [*] Sat Jan 28 02:36:03 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.225685 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.4677 & F1 0.6374
01/28/2023 02:36:06 AM  [*] Sat Jan 28 02:36:06 2023:    2    | Tr.loss: 0.313278 | Elapsed:   15.20  s | FPR 0.0003 -> TPR: 0.24 & F1: 0.39 | AUC: 0.9252
01/28/2023 02:36:06 AM  [*] Started epoch: 3
01/28/2023 02:36:06 AM  [*] Sat Jan 28 02:36:06 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.253256 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.7727 & F1 0.8718
01/28/2023 02:36:12 AM  [*] Sat Jan 28 02:36:12 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.289287 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.5873 & F1 0.7400
01/28/2023 02:36:18 AM  [*] Sat Jan 28 02:36:18 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.175619 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.8551 & F1 0.9219
01/28/2023 02:36:21 AM  [*] Sat Jan 28 02:36:21 2023:    3    | Tr.loss: 0.243385 | Elapsed:   15.23  s | FPR 0.0003 -> TPR: 0.38 & F1: 0.55 | AUC: 0.9561
01/28/2023 02:36:27 AM  [*] Started epoch: 1
01/28/2023 02:36:27 AM  [*] Sat Jan 28 02:36:27 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 2.808876 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.1111 & F1 0.2000
01/28/2023 02:36:33 AM  [*] Sat Jan 28 02:36:33 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.346695 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.1538 & F1 0.2667
01/28/2023 02:36:39 AM  [*] Sat Jan 28 02:36:39 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.394765 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.4789 & F1 0.6476
01/28/2023 02:36:42 AM  [*] Sat Jan 28 02:36:42 2023:    1    | Tr.loss: 0.547187 | Elapsed:   15.17  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8293
01/28/2023 02:36:42 AM  [*] Started epoch: 2
01/28/2023 02:36:42 AM  [*] Sat Jan 28 02:36:42 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.376877 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.3409 & F1 0.5085
01/28/2023 02:36:48 AM  [*] Sat Jan 28 02:36:48 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.387665 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.3662 & F1 0.5361
01/28/2023 02:36:54 AM  [*] Sat Jan 28 02:36:54 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.339981 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.6061 & F1 0.7547
01/28/2023 02:36:57 AM  [*] Sat Jan 28 02:36:57 2023:    2    | Tr.loss: 0.311534 | Elapsed:   15.18  s | FPR 0.0003 -> TPR: 0.23 & F1: 0.37 | AUC: 0.9271
01/28/2023 02:36:57 AM  [*] Started epoch: 3
01/28/2023 02:36:57 AM  [*] Sat Jan 28 02:36:57 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.327014 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.6429 & F1 0.7826
01/28/2023 02:37:03 AM  [*] Sat Jan 28 02:37:03 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.189315 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.7794 & F1 0.8760
01/28/2023 02:37:10 AM  [*] Sat Jan 28 02:37:10 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.300392 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.6719 & F1 0.8037
01/28/2023 02:37:12 AM  [*] Sat Jan 28 02:37:12 2023:    3    | Tr.loss: 0.241451 | Elapsed:   15.20  s | FPR 0.0003 -> TPR: 0.31 & F1: 0.47 | AUC: 0.9573
01/28/2023 02:37:18 AM  [*] Started epoch: 1
01/28/2023 02:37:18 AM  [*] Sat Jan 28 02:37:18 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 4.159937 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 02:37:24 AM  [*] Sat Jan 28 02:37:24 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.280766 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.2857 & F1 0.4444
01/28/2023 02:37:30 AM  [*] Sat Jan 28 02:37:30 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.314177 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.6949 & F1 0.8200
01/28/2023 02:37:33 AM  [*] Sat Jan 28 02:37:33 2023:    1    | Tr.loss: 0.560100 | Elapsed:   15.15  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8247
01/28/2023 02:37:33 AM  [*] Started epoch: 2
01/28/2023 02:37:33 AM  [*] Sat Jan 28 02:37:33 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.328430 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.5897 & F1 0.7419
01/28/2023 02:37:39 AM  [*] Sat Jan 28 02:37:39 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.281020 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.5797 & F1 0.7339
01/28/2023 02:37:46 AM  [*] Sat Jan 28 02:37:46 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.353293 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.4737 & F1 0.6429
01/28/2023 02:37:48 AM  [*] Sat Jan 28 02:37:48 2023:    2    | Tr.loss: 0.313986 | Elapsed:   15.19  s | FPR 0.0003 -> TPR: 0.19 & F1: 0.32 | AUC: 0.9245
01/28/2023 02:37:48 AM  [*] Started epoch: 3
01/28/2023 02:37:48 AM  [*] Sat Jan 28 02:37:48 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.270749 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.7045 & F1 0.8267
01/28/2023 02:37:55 AM  [*] Sat Jan 28 02:37:55 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.212534 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.8413 & F1 0.9138
01/28/2023 02:38:01 AM  [*] Sat Jan 28 02:38:01 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.153273 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.8767 & F1 0.9343
01/28/2023 02:38:04 AM  [*] Sat Jan 28 02:38:04 2023:    3    | Tr.loss: 0.243337 | Elapsed:   15.25  s | FPR 0.0003 -> TPR: 0.40 & F1: 0.57 | AUC: 0.9554
01/28/2023 02:38:09 AM  [*] Started epoch: 1
01/28/2023 02:38:09 AM  [*] Sat Jan 28 02:38:09 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 2.299778 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.2889 & F1 0.4483
01/28/2023 02:38:16 AM  [*] Sat Jan 28 02:38:16 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.409275 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.1972 & F1 0.3294
01/28/2023 02:38:22 AM  [*] Sat Jan 28 02:38:22 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.527620 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.3731 & F1 0.5435
01/28/2023 02:38:25 AM  [*] Sat Jan 28 02:38:25 2023:    1    | Tr.loss: 0.559092 | Elapsed:   15.22  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8245
01/28/2023 02:38:25 AM  [*] Started epoch: 2
01/28/2023 02:38:25 AM  [*] Sat Jan 28 02:38:25 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.320583 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.5417 & F1 0.7027
01/28/2023 02:38:31 AM  [*] Sat Jan 28 02:38:31 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.302629 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.8056 & F1 0.8923
01/28/2023 02:38:37 AM  [*] Sat Jan 28 02:38:37 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.244099 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.7164 & F1 0.8348
01/28/2023 02:38:40 AM  [*] Sat Jan 28 02:38:40 2023:    2    | Tr.loss: 0.317971 | Elapsed:   15.22  s | FPR 0.0003 -> TPR: 0.23 & F1: 0.38 | AUC: 0.9237
01/28/2023 02:38:40 AM  [*] Started epoch: 3
01/28/2023 02:38:40 AM  [*] Sat Jan 28 02:38:40 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.265079 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.8261 & F1 0.9048
01/28/2023 02:38:46 AM  [*] Sat Jan 28 02:38:46 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.274772 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.2812 & F1 0.4390
01/28/2023 02:38:52 AM  [*] Sat Jan 28 02:38:52 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.207663 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.8030 & F1 0.8908
01/28/2023 02:38:55 AM  [*] Sat Jan 28 02:38:55 2023:    3    | Tr.loss: 0.243018 | Elapsed:   15.19  s | FPR 0.0003 -> TPR: 0.30 & F1: 0.46 | AUC: 0.9565
01/28/2023 02:39:01 AM  [*] Started epoch: 1
01/28/2023 02:39:01 AM  [*] Sat Jan 28 02:39:01 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 4.000362 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 02:39:07 AM  [*] Sat Jan 28 02:39:07 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.463496 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.2687 & F1 0.4235
01/28/2023 02:39:13 AM  [*] Sat Jan 28 02:39:13 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.559300 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.0606 & F1 0.1143
01/28/2023 02:39:16 AM  [*] Sat Jan 28 02:39:16 2023:    1    | Tr.loss: 0.569375 | Elapsed:   15.17  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8212
01/28/2023 02:39:16 AM  [*] Started epoch: 2
01/28/2023 02:39:16 AM  [*] Sat Jan 28 02:39:16 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.396444 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.2727 & F1 0.4286
01/28/2023 02:39:22 AM  [*] Sat Jan 28 02:39:22 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.335282 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.4118 & F1 0.5833
01/28/2023 02:39:28 AM  [*] Sat Jan 28 02:39:28 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.239277 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.6377 & F1 0.7788
01/28/2023 02:39:31 AM  [*] Sat Jan 28 02:39:31 2023:    2    | Tr.loss: 0.321924 | Elapsed:   15.20  s | FPR 0.0003 -> TPR: 0.14 & F1: 0.25 | AUC: 0.9220
01/28/2023 02:39:31 AM  [*] Started epoch: 3
01/28/2023 02:39:31 AM  [*] Sat Jan 28 02:39:31 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.297801 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.7561 & F1 0.8611
01/28/2023 02:39:37 AM  [*] Sat Jan 28 02:39:37 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.302919 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.8261 & F1 0.9048
01/28/2023 02:39:43 AM  [*] Sat Jan 28 02:39:43 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.182194 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.8939 & F1 0.9440
01/28/2023 02:39:46 AM  [*] Sat Jan 28 02:39:46 2023:    3    | Tr.loss: 0.244470 | Elapsed:   15.20  s | FPR 0.0003 -> TPR: 0.38 & F1: 0.55 | AUC: 0.9572
01/28/2023 02:39:52 AM  [*] Started epoch: 1
01/28/2023 02:39:52 AM  [*] Sat Jan 28 02:39:52 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.355856 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 02:39:58 AM  [*] Sat Jan 28 02:39:58 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.389480 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.1429 & F1 0.2500
01/28/2023 02:40:04 AM  [*] Sat Jan 28 02:40:04 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.259111 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.5556 & F1 0.7143
01/28/2023 02:40:07 AM  [*] Sat Jan 28 02:40:07 2023:    1    | Tr.loss: 0.553307 | Elapsed:   15.19  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8300
01/28/2023 02:40:07 AM  [*] Started epoch: 2
01/28/2023 02:40:07 AM  [*] Sat Jan 28 02:40:07 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.406327 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.2889 & F1 0.4483
01/28/2023 02:40:13 AM  [*] Sat Jan 28 02:40:13 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.228875 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.5763 & F1 0.7312
01/28/2023 02:40:20 AM  [*] Sat Jan 28 02:40:20 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.208205 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.5942 & F1 0.7455
01/28/2023 02:40:22 AM  [*] Sat Jan 28 02:40:22 2023:    2    | Tr.loss: 0.312468 | Elapsed:   15.23  s | FPR 0.0003 -> TPR: 0.19 & F1: 0.32 | AUC: 0.9265
01/28/2023 02:40:22 AM  [*] Started epoch: 3
01/28/2023 02:40:22 AM  [*] Sat Jan 28 02:40:22 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.346350 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.6047 & F1 0.7536
01/28/2023 02:40:29 AM  [*] Sat Jan 28 02:40:29 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.237088 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.6500 & F1 0.7879
01/28/2023 02:40:35 AM  [*] Sat Jan 28 02:40:35 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.182807 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.8730 & F1 0.9322
01/28/2023 02:40:37 AM  [*] Sat Jan 28 02:40:37 2023:    3    | Tr.loss: 0.235003 | Elapsed:   15.23  s | FPR 0.0003 -> TPR: 0.30 & F1: 0.46 | AUC: 0.9603
01/28/2023 02:40:43 AM  [*] Started epoch: 1
01/28/2023 02:40:43 AM  [*] Sat Jan 28 02:40:43 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.370163 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.1556 & F1 0.2692
01/28/2023 02:40:50 AM  [*] Sat Jan 28 02:40:50 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.446489 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.1803 & F1 0.3056
01/28/2023 02:40:56 AM  [*] Sat Jan 28 02:40:56 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.409217 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.3043 & F1 0.4667
01/28/2023 02:40:58 AM  [*] Sat Jan 28 02:40:58 2023:    1    | Tr.loss: 0.554491 | Elapsed:   15.21  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8284
01/28/2023 02:40:58 AM  [*] Started epoch: 2
01/28/2023 02:40:58 AM  [*] Sat Jan 28 02:40:58 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.367940 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.4146 & F1 0.5862
01/28/2023 02:41:05 AM  [*] Sat Jan 28 02:41:05 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.396659 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.3500 & F1 0.5185
01/28/2023 02:41:11 AM  [*] Sat Jan 28 02:41:11 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.171941 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.6000 & F1 0.7500
01/28/2023 02:41:14 AM  [*] Sat Jan 28 02:41:14 2023:    2    | Tr.loss: 0.316947 | Elapsed:   15.25  s | FPR 0.0003 -> TPR: 0.19 & F1: 0.32 | AUC: 0.9233
01/28/2023 02:41:14 AM  [*] Started epoch: 3
01/28/2023 02:41:14 AM  [*] Sat Jan 28 02:41:14 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.341109 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.6304 & F1 0.7733
01/28/2023 02:41:20 AM  [*] Sat Jan 28 02:41:20 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.265128 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.6818 & F1 0.8108
01/28/2023 02:41:26 AM  [*] Sat Jan 28 02:41:26 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.330004 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.8462 & F1 0.9167
01/28/2023 02:41:29 AM  [*] Sat Jan 28 02:41:29 2023:    3    | Tr.loss: 0.240416 | Elapsed:   15.21  s | FPR 0.0003 -> TPR: 0.31 & F1: 0.47 | AUC: 0.9578
01/28/2023 02:41:35 AM  [*] Started epoch: 1
01/28/2023 02:41:35 AM  [*] Sat Jan 28 02:41:35 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 2.803749 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.1622 & F1 0.2791
01/28/2023 02:41:41 AM  [*] Sat Jan 28 02:41:41 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.412277 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.3594 & F1 0.5287
01/28/2023 02:41:47 AM  [*] Sat Jan 28 02:41:47 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.293862 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.4000 & F1 0.5714
01/28/2023 02:41:50 AM  [*] Sat Jan 28 02:41:50 2023:    1    | Tr.loss: 0.552837 | Elapsed:   15.11  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8280
01/28/2023 02:41:50 AM  [*] Started epoch: 2
01/28/2023 02:41:50 AM  [*] Sat Jan 28 02:41:50 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.310398 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.6190 & F1 0.7647
01/28/2023 02:41:56 AM  [*] Sat Jan 28 02:41:56 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.350797 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.6479 & F1 0.7863
01/28/2023 02:42:02 AM  [*] Sat Jan 28 02:42:02 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.249859 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.6667 & F1 0.8000
01/28/2023 02:42:05 AM  [*] Sat Jan 28 02:42:05 2023:    2    | Tr.loss: 0.313560 | Elapsed:   15.16  s | FPR 0.0003 -> TPR: 0.23 & F1: 0.37 | AUC: 0.9251
01/28/2023 02:42:05 AM  [*] Started epoch: 3
01/28/2023 02:42:05 AM  [*] Sat Jan 28 02:42:05 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.318566 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.6250 & F1 0.7692
01/28/2023 02:42:11 AM  [*] Sat Jan 28 02:42:11 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.238495 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.8000 & F1 0.8889
01/28/2023 02:42:17 AM  [*] Sat Jan 28 02:42:17 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.201000 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.8286 & F1 0.9062
01/28/2023 02:42:20 AM  [*] Sat Jan 28 02:42:20 2023:    3    | Tr.loss: 0.244457 | Elapsed:   15.23  s | FPR 0.0003 -> TPR: 0.39 & F1: 0.56 | AUC: 0.9554
01/28/2023 02:42:26 AM  [*] Started epoch: 1
01/28/2023 02:42:26 AM  [*] Sat Jan 28 02:42:26 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 4.220696 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.1556 & F1 0.2692
01/28/2023 02:42:32 AM  [*] Sat Jan 28 02:42:32 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.576148 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.2394 & F1 0.3864
01/28/2023 02:42:38 AM  [*] Sat Jan 28 02:42:38 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.370753 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.1935 & F1 0.3243
01/28/2023 02:42:41 AM  [*] Sat Jan 28 02:42:41 2023:    1    | Tr.loss: 0.579439 | Elapsed:   15.16  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8218
01/28/2023 02:42:41 AM  [*] Started epoch: 2
01/28/2023 02:42:41 AM  [*] Sat Jan 28 02:42:41 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.320032 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.7143 & F1 0.8333
01/28/2023 02:42:47 AM  [*] Sat Jan 28 02:42:47 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.326808 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.5000 & F1 0.6667
01/28/2023 02:42:53 AM  [*] Sat Jan 28 02:42:53 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.391295 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.6567 & F1 0.7928
01/28/2023 02:42:56 AM  [*] Sat Jan 28 02:42:56 2023:    2    | Tr.loss: 0.321950 | Elapsed:   15.18  s | FPR 0.0003 -> TPR: 0.16 & F1: 0.27 | AUC: 0.9206
01/28/2023 02:42:56 AM  [*] Started epoch: 3
01/28/2023 02:42:56 AM  [*] Sat Jan 28 02:42:56 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.356241 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.5833 & F1 0.7368
01/28/2023 02:43:02 AM  [*] Sat Jan 28 02:43:02 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.290553 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.6094 & F1 0.7573
01/28/2023 02:43:09 AM  [*] Sat Jan 28 02:43:09 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.297336 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.8378 & F1 0.9118
01/28/2023 02:43:11 AM  [*] Sat Jan 28 02:43:11 2023:    3    | Tr.loss: 0.246810 | Elapsed:   15.26  s | FPR 0.0003 -> TPR: 0.32 & F1: 0.48 | AUC: 0.9557
01/28/2023 02:43:17 AM  [*] Started epoch: 1
01/28/2023 02:43:17 AM  [*] Sat Jan 28 02:43:17 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.765167 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.1395 & F1 0.2449
01/28/2023 02:43:23 AM  [*] Sat Jan 28 02:43:23 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.491647 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.1231 & F1 0.2192
01/28/2023 02:43:30 AM  [*] Sat Jan 28 02:43:30 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.404222 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.4744 & F1 0.6435
01/28/2023 02:43:32 AM  [*] Sat Jan 28 02:43:32 2023:    1    | Tr.loss: 0.565462 | Elapsed:   15.14  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8242
01/28/2023 02:43:32 AM  [*] Started epoch: 2
01/28/2023 02:43:32 AM  [*] Sat Jan 28 02:43:32 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.319859 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.6957 & F1 0.8205
01/28/2023 02:43:39 AM  [*] Sat Jan 28 02:43:39 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.371292 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.4776 & F1 0.6465
01/28/2023 02:43:45 AM  [*] Sat Jan 28 02:43:45 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.193060 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.7727 & F1 0.8718
01/28/2023 02:43:47 AM  [*] Sat Jan 28 02:43:47 2023:    2    | Tr.loss: 0.319572 | Elapsed:   15.20  s | FPR 0.0003 -> TPR: 0.17 & F1: 0.29 | AUC: 0.9219
01/28/2023 02:43:47 AM  [*] Started epoch: 3
01/28/2023 02:43:48 AM  [*] Sat Jan 28 02:43:48 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.188933 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.8478 & F1 0.9176
01/28/2023 02:43:54 AM  [*] Sat Jan 28 02:43:54 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.290257 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.4918 & F1 0.6593
01/28/2023 02:44:00 AM  [*] Sat Jan 28 02:44:00 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.183243 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.8732 & F1 0.9323
01/28/2023 02:44:03 AM  [*] Sat Jan 28 02:44:03 2023:    3    | Tr.loss: 0.244805 | Elapsed:   15.20  s | FPR 0.0003 -> TPR: 0.34 & F1: 0.51 | AUC: 0.9555
01/28/2023 02:44:08 AM  [*] Started epoch: 1
01/28/2023 02:44:08 AM  [*] Sat Jan 28 02:44:08 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 4.137022 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.1860 & F1 0.3137
01/28/2023 02:44:15 AM  [*] Sat Jan 28 02:44:15 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.486833 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.0857 & F1 0.1579
01/28/2023 02:44:21 AM  [*] Sat Jan 28 02:44:21 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.389647 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.2361 & F1 0.3820
01/28/2023 02:44:24 AM  [*] Sat Jan 28 02:44:24 2023:    1    | Tr.loss: 0.562913 | Elapsed:   15.16  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8255
01/28/2023 02:44:24 AM  [*] Started epoch: 2
01/28/2023 02:44:24 AM  [*] Sat Jan 28 02:44:24 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.256271 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.8462 & F1 0.9167
01/28/2023 02:44:30 AM  [*] Sat Jan 28 02:44:30 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.342115 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.4603 & F1 0.6304
01/28/2023 02:44:36 AM  [*] Sat Jan 28 02:44:36 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.324260 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.8095 & F1 0.8947
01/28/2023 02:44:39 AM  [*] Sat Jan 28 02:44:39 2023:    2    | Tr.loss: 0.314747 | Elapsed:   15.21  s | FPR 0.0003 -> TPR: 0.19 & F1: 0.31 | AUC: 0.9235
01/28/2023 02:44:39 AM  [*] Started epoch: 3
01/28/2023 02:44:39 AM  [*] Sat Jan 28 02:44:39 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.264466 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.5641 & F1 0.7213
01/28/2023 02:44:45 AM  [*] Sat Jan 28 02:44:45 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.221169 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.7463 & F1 0.8547
01/28/2023 02:44:51 AM  [*] Sat Jan 28 02:44:51 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.271589 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.4737 & F1 0.6429
01/28/2023 02:44:54 AM  [*] Sat Jan 28 02:44:54 2023:    3    | Tr.loss: 0.240516 | Elapsed:   15.22  s | FPR 0.0003 -> TPR: 0.42 & F1: 0.59 | AUC: 0.9566
01/28/2023 02:45:00 AM  [*] Started epoch: 1
01/28/2023 02:45:00 AM  [*] Sat Jan 28 02:45:00 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 4.247888 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0455 & F1 0.0870
01/28/2023 02:45:06 AM  [*] Sat Jan 28 02:45:06 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.407439 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.2353 & F1 0.3810
01/28/2023 02:45:12 AM  [*] Sat Jan 28 02:45:12 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.408797 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.3881 & F1 0.5591
01/28/2023 02:45:15 AM  [*] Sat Jan 28 02:45:15 2023:    1    | Tr.loss: 0.559427 | Elapsed:   15.19  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8264
01/28/2023 02:45:15 AM  [*] Started epoch: 2
01/28/2023 02:45:15 AM  [*] Sat Jan 28 02:45:15 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.208091 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.8684 & F1 0.9296
01/28/2023 02:45:21 AM  [*] Sat Jan 28 02:45:21 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.369103 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.4167 & F1 0.5882
01/28/2023 02:45:27 AM  [*] Sat Jan 28 02:45:27 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.342063 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.5373 & F1 0.6990
01/28/2023 02:45:30 AM  [*] Sat Jan 28 02:45:30 2023:    2    | Tr.loss: 0.310814 | Elapsed:   15.24  s | FPR 0.0003 -> TPR: 0.25 & F1: 0.40 | AUC: 0.9267
01/28/2023 02:45:30 AM  [*] Started epoch: 3
01/28/2023 02:45:30 AM  [*] Sat Jan 28 02:45:30 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.237787 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.6429 & F1 0.7826
01/28/2023 02:45:36 AM  [*] Sat Jan 28 02:45:36 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.184866 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.6842 & F1 0.8125
01/28/2023 02:45:43 AM  [*] Sat Jan 28 02:45:43 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.159409 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.7222 & F1 0.8387
01/28/2023 02:45:45 AM  [*] Sat Jan 28 02:45:45 2023:    3    | Tr.loss: 0.241438 | Elapsed:   15.22  s | FPR 0.0003 -> TPR: 0.31 & F1: 0.47 | AUC: 0.9579
01/28/2023 02:45:51 AM  [*] Started epoch: 1
01/28/2023 02:45:51 AM  [*] Sat Jan 28 02:45:51 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 2.904200 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.1905 & F1 0.3200
01/28/2023 02:45:57 AM  [*] Sat Jan 28 02:45:57 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.397531 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.4058 & F1 0.5773
01/28/2023 02:46:04 AM  [*] Sat Jan 28 02:46:04 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.265122 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.2063 & F1 0.3421
01/28/2023 02:46:06 AM  [*] Sat Jan 28 02:46:06 2023:    1    | Tr.loss: 0.564742 | Elapsed:   15.14  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8268
01/28/2023 02:46:06 AM  [*] Started epoch: 2
01/28/2023 02:46:06 AM  [*] Sat Jan 28 02:46:06 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.291568 | Elapsed: 0.05s | FPR 0.0003 -> TPR 0.4000 & F1 0.5714
01/28/2023 02:46:13 AM  [*] Sat Jan 28 02:46:13 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.254072 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.7727 & F1 0.8718
01/28/2023 02:46:19 AM  [*] Sat Jan 28 02:46:19 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.399070 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.4500 & F1 0.6207
01/28/2023 02:46:21 AM  [*] Sat Jan 28 02:46:21 2023:    2    | Tr.loss: 0.316039 | Elapsed:   15.18  s | FPR 0.0003 -> TPR: 0.18 & F1: 0.30 | AUC: 0.9241
01/28/2023 02:46:21 AM  [*] Started epoch: 3
01/28/2023 02:46:21 AM  [*] Sat Jan 28 02:46:21 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.283204 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.5476 & F1 0.7077
01/28/2023 02:46:28 AM  [*] Sat Jan 28 02:46:28 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.271704 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.6849 & F1 0.8130
01/28/2023 02:46:34 AM  [*] Sat Jan 28 02:46:34 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.220860 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.5738 & F1 0.7292
01/28/2023 02:46:37 AM  [*] Sat Jan 28 02:46:37 2023:    3    | Tr.loss: 0.239603 | Elapsed:   15.17  s | FPR 0.0003 -> TPR: 0.34 & F1: 0.51 | AUC: 0.9568
01/28/2023 02:46:42 AM  [*] Started epoch: 1
01/28/2023 02:46:42 AM  [*] Sat Jan 28 02:46:42 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.328209 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0732 & F1 0.1364
01/28/2023 02:46:49 AM  [*] Sat Jan 28 02:46:49 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.462935 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.4375 & F1 0.6087
01/28/2023 02:46:55 AM  [*] Sat Jan 28 02:46:55 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.440941 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.3649 & F1 0.5347
01/28/2023 02:46:57 AM  [*] Sat Jan 28 02:46:57 2023:    1    | Tr.loss: 0.557239 | Elapsed:   15.12  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8267
01/28/2023 02:46:57 AM  [*] Started epoch: 2
01/28/2023 02:46:58 AM  [*] Sat Jan 28 02:46:58 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.255143 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.8049 & F1 0.8919
01/28/2023 02:47:04 AM  [*] Sat Jan 28 02:47:04 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.243306 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.6324 & F1 0.7748
01/28/2023 02:47:10 AM  [*] Sat Jan 28 02:47:10 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.325899 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.6154 & F1 0.7619
01/28/2023 02:47:13 AM  [*] Sat Jan 28 02:47:13 2023:    2    | Tr.loss: 0.310564 | Elapsed:   15.18  s | FPR 0.0003 -> TPR: 0.12 & F1: 0.22 | AUC: 0.9261
01/28/2023 02:47:13 AM  [*] Started epoch: 3
01/28/2023 02:47:13 AM  [*] Sat Jan 28 02:47:13 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.273353 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.7436 & F1 0.8529
01/28/2023 02:47:19 AM  [*] Sat Jan 28 02:47:19 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.216859 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.6143 & F1 0.7611
01/28/2023 02:47:25 AM  [*] Sat Jan 28 02:47:25 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.150721 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.8986 & F1 0.9466
01/28/2023 02:47:28 AM  [*] Sat Jan 28 02:47:28 2023:    3    | Tr.loss: 0.236413 | Elapsed:   15.20  s | FPR 0.0003 -> TPR: 0.39 & F1: 0.56 | AUC: 0.9601
01/28/2023 02:47:33 AM  [*] Started epoch: 1
01/28/2023 02:47:34 AM  [*] Sat Jan 28 02:47:34 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 4.149746 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 02:47:40 AM  [*] Sat Jan 28 02:47:40 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.418285 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.2388 & F1 0.3855
01/28/2023 02:47:46 AM  [*] Sat Jan 28 02:47:46 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.380573 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.2836 & F1 0.4419
01/28/2023 02:47:49 AM  [*] Sat Jan 28 02:47:49 2023:    1    | Tr.loss: 0.583103 | Elapsed:   15.13  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8189
01/28/2023 02:47:49 AM  [*] Started epoch: 2
01/28/2023 02:47:49 AM  [*] Sat Jan 28 02:47:49 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.332007 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.5106 & F1 0.6761
01/28/2023 02:47:55 AM  [*] Sat Jan 28 02:47:55 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.382261 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.4769 & F1 0.6458
01/28/2023 02:48:01 AM  [*] Sat Jan 28 02:48:01 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.385004 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.6029 & F1 0.7523
01/28/2023 02:48:04 AM  [*] Sat Jan 28 02:48:04 2023:    2    | Tr.loss: 0.319888 | Elapsed:   15.18  s | FPR 0.0003 -> TPR: 0.22 & F1: 0.37 | AUC: 0.9221
01/28/2023 02:48:04 AM  [*] Started epoch: 3
01/28/2023 02:48:04 AM  [*] Sat Jan 28 02:48:04 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.283895 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.7436 & F1 0.8529
01/28/2023 02:48:10 AM  [*] Sat Jan 28 02:48:10 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.239557 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.5942 & F1 0.7455
01/28/2023 02:48:16 AM  [*] Sat Jan 28 02:48:16 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.305325 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.8413 & F1 0.9138
01/28/2023 02:48:19 AM  [*] Sat Jan 28 02:48:19 2023:    3    | Tr.loss: 0.247794 | Elapsed:   15.20  s | FPR 0.0003 -> TPR: 0.25 & F1: 0.40 | AUC: 0.9548
01/28/2023 02:48:24 AM Split: 2
01/28/2023 02:48:25 AM  [*] Started epoch: 1
01/28/2023 02:48:25 AM  [*] Sat Jan 28 02:48:25 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.137366 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 02:48:31 AM  [*] Sat Jan 28 02:48:31 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.336435 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.5556 & F1 0.7143
01/28/2023 02:48:37 AM  [*] Sat Jan 28 02:48:37 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.267111 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.5429 & F1 0.7037
01/28/2023 02:48:40 AM  [*] Sat Jan 28 02:48:40 2023:    1    | Tr.loss: 0.485855 | Elapsed:   15.15  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8546
01/28/2023 02:48:40 AM  [*] Started epoch: 2
01/28/2023 02:48:40 AM  [*] Sat Jan 28 02:48:40 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.283131 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.2889 & F1 0.4483
01/28/2023 02:48:46 AM  [*] Sat Jan 28 02:48:46 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.393003 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.0149 & F1 0.0294
01/28/2023 02:48:52 AM  [*] Sat Jan 28 02:48:52 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.206347 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.7534 & F1 0.8594
01/28/2023 02:48:55 AM  [*] Sat Jan 28 02:48:55 2023:    2    | Tr.loss: 0.256901 | Elapsed:   15.22  s | FPR 0.0003 -> TPR: 0.15 & F1: 0.26 | AUC: 0.9546
01/28/2023 02:48:55 AM  [*] Started epoch: 3
01/28/2023 02:48:55 AM  [*] Sat Jan 28 02:48:55 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.198999 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.8095 & F1 0.8947
01/28/2023 02:49:01 AM  [*] Sat Jan 28 02:49:01 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.177075 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.8514 & F1 0.9197
01/28/2023 02:49:08 AM  [*] Sat Jan 28 02:49:08 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.152234 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.9118 & F1 0.9538
01/28/2023 02:49:10 AM  [*] Sat Jan 28 02:49:10 2023:    3    | Tr.loss: 0.195393 | Elapsed:   15.22  s | FPR 0.0003 -> TPR: 0.40 & F1: 0.57 | AUC: 0.9742
01/28/2023 02:49:16 AM  [*] Started epoch: 1
01/28/2023 02:49:16 AM  [*] Sat Jan 28 02:49:16 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.296603 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 02:49:22 AM  [*] Sat Jan 28 02:49:22 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.492284 | Elapsed: 6.26s | FPR 0.0003 -> TPR 0.1515 & F1 0.2632
01/28/2023 02:49:29 AM  [*] Sat Jan 28 02:49:29 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.371151 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.7500 & F1 0.8571
01/28/2023 02:49:31 AM  [*] Sat Jan 28 02:49:31 2023:    1    | Tr.loss: 0.501367 | Elapsed:   15.22  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8496
01/28/2023 02:49:31 AM  [*] Started epoch: 2
01/28/2023 02:49:31 AM  [*] Sat Jan 28 02:49:31 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.278800 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.8372 & F1 0.9114
01/28/2023 02:49:38 AM  [*] Sat Jan 28 02:49:38 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.266495 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.6774 & F1 0.8077
01/28/2023 02:49:44 AM  [*] Sat Jan 28 02:49:44 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.285844 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.4638 & F1 0.6337
01/28/2023 02:49:46 AM  [*] Sat Jan 28 02:49:46 2023:    2    | Tr.loss: 0.257695 | Elapsed:   15.22  s | FPR 0.0003 -> TPR: 0.29 & F1: 0.45 | AUC: 0.9546
01/28/2023 02:49:46 AM  [*] Started epoch: 3
01/28/2023 02:49:47 AM  [*] Sat Jan 28 02:49:47 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.389546 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.5111 & F1 0.6765
01/28/2023 02:49:53 AM  [*] Sat Jan 28 02:49:53 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.181717 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.7231 & F1 0.8393
01/28/2023 02:49:59 AM  [*] Sat Jan 28 02:49:59 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.139912 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.9118 & F1 0.9538
01/28/2023 02:50:02 AM  [*] Sat Jan 28 02:50:02 2023:    3    | Tr.loss: 0.189208 | Elapsed:   15.19  s | FPR 0.0003 -> TPR: 0.46 & F1: 0.63 | AUC: 0.9762
01/28/2023 02:50:07 AM  [*] Started epoch: 1
01/28/2023 02:50:07 AM  [*] Sat Jan 28 02:50:07 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 4.160186 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 02:50:14 AM  [*] Sat Jan 28 02:50:14 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.380260 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.4545 & F1 0.6250
01/28/2023 02:50:20 AM  [*] Sat Jan 28 02:50:20 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.339197 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.1429 & F1 0.2500
01/28/2023 02:50:23 AM  [*] Sat Jan 28 02:50:23 2023:    1    | Tr.loss: 0.503803 | Elapsed:   15.19  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8464
01/28/2023 02:50:23 AM  [*] Started epoch: 2
01/28/2023 02:50:23 AM  [*] Sat Jan 28 02:50:23 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.178043 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.9545 & F1 0.9767
01/28/2023 02:50:29 AM  [*] Sat Jan 28 02:50:29 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.302610 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.7600 & F1 0.8636
01/28/2023 02:50:35 AM  [*] Sat Jan 28 02:50:35 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.312756 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.4000 & F1 0.5714
01/28/2023 02:50:38 AM  [*] Sat Jan 28 02:50:38 2023:    2    | Tr.loss: 0.253874 | Elapsed:   15.22  s | FPR 0.0003 -> TPR: 0.16 & F1: 0.28 | AUC: 0.9557
01/28/2023 02:50:38 AM  [*] Started epoch: 3
01/28/2023 02:50:38 AM  [*] Sat Jan 28 02:50:38 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.183710 | Elapsed: 0.05s | FPR 0.0003 -> TPR 0.8667 & F1 0.9286
01/28/2023 02:50:44 AM  [*] Sat Jan 28 02:50:44 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.205247 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.7792 & F1 0.8759
01/28/2023 02:50:50 AM  [*] Sat Jan 28 02:50:50 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.147429 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.7714 & F1 0.8710
01/28/2023 02:50:53 AM  [*] Sat Jan 28 02:50:53 2023:    3    | Tr.loss: 0.193250 | Elapsed:   15.23  s | FPR 0.0003 -> TPR: 0.46 & F1: 0.63 | AUC: 0.9748
01/28/2023 02:50:59 AM  [*] Started epoch: 1
01/28/2023 02:50:59 AM  [*] Sat Jan 28 02:50:59 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.368477 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 02:51:05 AM  [*] Sat Jan 28 02:51:05 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.352453 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.5606 & F1 0.7184
01/28/2023 02:51:11 AM  [*] Sat Jan 28 02:51:11 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.303464 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.5775 & F1 0.7321
01/28/2023 02:51:14 AM  [*] Sat Jan 28 02:51:14 2023:    1    | Tr.loss: 0.471057 | Elapsed:   15.20  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8388
01/28/2023 02:51:14 AM  [*] Started epoch: 2
01/28/2023 02:51:14 AM  [*] Sat Jan 28 02:51:14 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.340869 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.5745 & F1 0.7297
01/28/2023 02:51:20 AM  [*] Sat Jan 28 02:51:20 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.270171 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.5000 & F1 0.6667
01/28/2023 02:51:27 AM  [*] Sat Jan 28 02:51:27 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.316557 | Elapsed: 6.26s | FPR 0.0003 -> TPR 0.4062 & F1 0.5778
01/28/2023 02:51:29 AM  [*] Sat Jan 28 02:51:29 2023:    2    | Tr.loss: 0.275797 | Elapsed:   15.23  s | FPR 0.0003 -> TPR: 0.29 & F1: 0.45 | AUC: 0.9455
01/28/2023 02:51:29 AM  [*] Started epoch: 3
01/28/2023 02:51:29 AM  [*] Sat Jan 28 02:51:29 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.248847 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.6667 & F1 0.8000
01/28/2023 02:51:35 AM  [*] Sat Jan 28 02:51:35 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.144316 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.6866 & F1 0.8142
01/28/2023 02:51:42 AM  [*] Sat Jan 28 02:51:42 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.249268 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.8308 & F1 0.9076
01/28/2023 02:51:44 AM  [*] Sat Jan 28 02:51:44 2023:    3    | Tr.loss: 0.196076 | Elapsed:   15.22  s | FPR 0.0003 -> TPR: 0.43 & F1: 0.60 | AUC: 0.9734
01/28/2023 02:51:50 AM  [*] Started epoch: 1
01/28/2023 02:51:50 AM  [*] Sat Jan 28 02:51:50 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.617570 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 02:51:56 AM  [*] Sat Jan 28 02:51:56 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.407370 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.5077 & F1 0.6735
01/28/2023 02:52:03 AM  [*] Sat Jan 28 02:52:03 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.412366 | Elapsed: 6.27s | FPR 0.0003 -> TPR 0.7015 & F1 0.8246
01/28/2023 02:52:05 AM  [*] Sat Jan 28 02:52:05 2023:    1    | Tr.loss: 0.487852 | Elapsed:   15.23  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8342
01/28/2023 02:52:05 AM  [*] Started epoch: 2
01/28/2023 02:52:05 AM  [*] Sat Jan 28 02:52:05 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.275448 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.6364 & F1 0.7778
01/28/2023 02:52:12 AM  [*] Sat Jan 28 02:52:12 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.385920 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.3333 & F1 0.5000
01/28/2023 02:52:18 AM  [*] Sat Jan 28 02:52:18 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.155703 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.4500 & F1 0.6207
01/28/2023 02:52:21 AM  [*] Sat Jan 28 02:52:21 2023:    2    | Tr.loss: 0.278624 | Elapsed:   15.27  s | FPR 0.0003 -> TPR: 0.20 & F1: 0.34 | AUC: 0.9454
01/28/2023 02:52:21 AM  [*] Started epoch: 3
01/28/2023 02:52:21 AM  [*] Sat Jan 28 02:52:21 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.248138 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.6047 & F1 0.7536
01/28/2023 02:52:27 AM  [*] Sat Jan 28 02:52:27 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.272826 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.7500 & F1 0.8571
01/28/2023 02:52:33 AM  [*] Sat Jan 28 02:52:33 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.179189 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.8429 & F1 0.9147
01/28/2023 02:52:36 AM  [*] Sat Jan 28 02:52:36 2023:    3    | Tr.loss: 0.203086 | Elapsed:   15.17  s | FPR 0.0003 -> TPR: 0.40 & F1: 0.57 | AUC: 0.9720
01/28/2023 02:52:42 AM  [*] Started epoch: 1
01/28/2023 02:52:42 AM  [*] Sat Jan 28 02:52:42 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.563899 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 02:52:48 AM  [*] Sat Jan 28 02:52:48 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.485841 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.2586 & F1 0.4110
01/28/2023 02:52:54 AM  [*] Sat Jan 28 02:52:54 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.434317 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.4769 & F1 0.6458
01/28/2023 02:52:57 AM  [*] Sat Jan 28 02:52:57 2023:    1    | Tr.loss: 0.491281 | Elapsed:   15.14  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8346
01/28/2023 02:52:57 AM  [*] Started epoch: 2
01/28/2023 02:52:57 AM  [*] Sat Jan 28 02:52:57 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.193035 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.9574 & F1 0.9783
01/28/2023 02:53:03 AM  [*] Sat Jan 28 02:53:03 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.181875 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.8824 & F1 0.9375
01/28/2023 02:53:09 AM  [*] Sat Jan 28 02:53:09 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.156026 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.6970 & F1 0.8214
01/28/2023 02:53:12 AM  [*] Sat Jan 28 02:53:12 2023:    2    | Tr.loss: 0.273826 | Elapsed:   15.18  s | FPR 0.0003 -> TPR: 0.37 & F1: 0.54 | AUC: 0.9479
01/28/2023 02:53:12 AM  [*] Started epoch: 3
01/28/2023 02:53:12 AM  [*] Sat Jan 28 02:53:12 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.179433 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.8250 & F1 0.9041
01/28/2023 02:53:18 AM  [*] Sat Jan 28 02:53:18 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.225594 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.7123 & F1 0.8320
01/28/2023 02:53:24 AM  [*] Sat Jan 28 02:53:24 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.207408 | Elapsed: 6.30s | FPR 0.0003 -> TPR 0.8696 & F1 0.9302
01/28/2023 02:53:27 AM  [*] Sat Jan 28 02:53:27 2023:    3    | Tr.loss: 0.206547 | Elapsed:   15.37  s | FPR 0.0003 -> TPR: 0.43 & F1: 0.60 | AUC: 0.9712
01/28/2023 02:53:33 AM  [*] Started epoch: 1
01/28/2023 02:53:33 AM  [*] Sat Jan 28 02:53:33 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 2.612375 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0250 & F1 0.0488
01/28/2023 02:53:39 AM  [*] Sat Jan 28 02:53:39 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.429168 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.3088 & F1 0.4719
01/28/2023 02:53:45 AM  [*] Sat Jan 28 02:53:45 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.311299 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.2267 & F1 0.3696
01/28/2023 02:53:48 AM  [*] Sat Jan 28 02:53:48 2023:    1    | Tr.loss: 0.470673 | Elapsed:   15.14  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8522
01/28/2023 02:53:48 AM  [*] Started epoch: 2
01/28/2023 02:53:48 AM  [*] Sat Jan 28 02:53:48 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.356239 | Elapsed: 0.05s | FPR 0.0003 -> TPR 0.4524 & F1 0.6230
01/28/2023 02:53:54 AM  [*] Sat Jan 28 02:53:54 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.180459 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.8406 & F1 0.9134
01/28/2023 02:54:01 AM  [*] Sat Jan 28 02:54:01 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.210798 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.6438 & F1 0.7833
01/28/2023 02:54:03 AM  [*] Sat Jan 28 02:54:03 2023:    2    | Tr.loss: 0.252566 | Elapsed:   15.24  s | FPR 0.0003 -> TPR: 0.33 & F1: 0.49 | AUC: 0.9559
01/28/2023 02:54:03 AM  [*] Started epoch: 3
01/28/2023 02:54:03 AM  [*] Sat Jan 28 02:54:03 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.213018 | Elapsed: 0.05s | FPR 0.0003 -> TPR 0.9714 & F1 0.9855
01/28/2023 02:54:10 AM  [*] Sat Jan 28 02:54:10 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.133815 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.9692 & F1 0.9844
01/28/2023 02:54:16 AM  [*] Sat Jan 28 02:54:16 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.096467 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.9286 & F1 0.9630
01/28/2023 02:54:19 AM  [*] Sat Jan 28 02:54:19 2023:    3    | Tr.loss: 0.189980 | Elapsed:   15.21  s | FPR 0.0003 -> TPR: 0.51 & F1: 0.67 | AUC: 0.9753
01/28/2023 02:54:24 AM  [*] Started epoch: 1
01/28/2023 02:54:24 AM  [*] Sat Jan 28 02:54:24 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.687865 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0244 & F1 0.0476
01/28/2023 02:54:31 AM  [*] Sat Jan 28 02:54:31 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.379126 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.5082 & F1 0.6739
01/28/2023 02:54:37 AM  [*] Sat Jan 28 02:54:37 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.276801 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.5652 & F1 0.7222
01/28/2023 02:54:39 AM  [*] Sat Jan 28 02:54:39 2023:    1    | Tr.loss: 0.488088 | Elapsed:   15.18  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8444
01/28/2023 02:54:39 AM  [*] Started epoch: 2
01/28/2023 02:54:39 AM  [*] Sat Jan 28 02:54:39 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.329719 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.7000 & F1 0.8235
01/28/2023 02:54:46 AM  [*] Sat Jan 28 02:54:46 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.262743 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.4559 & F1 0.6263
01/28/2023 02:54:52 AM  [*] Sat Jan 28 02:54:52 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.237498 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.6765 & F1 0.8070
01/28/2023 02:54:55 AM  [*] Sat Jan 28 02:54:55 2023:    2    | Tr.loss: 0.265947 | Elapsed:   15.21  s | FPR 0.0003 -> TPR: 0.25 & F1: 0.40 | AUC: 0.9505
01/28/2023 02:54:55 AM  [*] Started epoch: 3
01/28/2023 02:54:55 AM  [*] Sat Jan 28 02:54:55 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.222324 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.7778 & F1 0.8750
01/28/2023 02:55:01 AM  [*] Sat Jan 28 02:55:01 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.203960 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.8767 & F1 0.9343
01/28/2023 02:55:07 AM  [*] Sat Jan 28 02:55:07 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.147540 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.9211 & F1 0.9589
01/28/2023 02:55:10 AM  [*] Sat Jan 28 02:55:10 2023:    3    | Tr.loss: 0.198491 | Elapsed:   15.20  s | FPR 0.0003 -> TPR: 0.49 & F1: 0.66 | AUC: 0.9730
01/28/2023 02:55:16 AM  [*] Started epoch: 1
01/28/2023 02:55:16 AM  [*] Sat Jan 28 02:55:16 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.084501 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 02:55:22 AM  [*] Sat Jan 28 02:55:22 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.461627 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.2969 & F1 0.4578
01/28/2023 02:55:28 AM  [*] Sat Jan 28 02:55:28 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.357071 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.5455 & F1 0.7059
01/28/2023 02:55:31 AM  [*] Sat Jan 28 02:55:31 2023:    1    | Tr.loss: 0.502962 | Elapsed:   15.19  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8374
01/28/2023 02:55:31 AM  [*] Started epoch: 2
01/28/2023 02:55:31 AM  [*] Sat Jan 28 02:55:31 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.274550 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.7234 & F1 0.8395
01/28/2023 02:55:37 AM  [*] Sat Jan 28 02:55:37 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.282160 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.7121 & F1 0.8319
01/28/2023 02:55:43 AM  [*] Sat Jan 28 02:55:43 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.304382 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.6143 & F1 0.7611
01/28/2023 02:55:46 AM  [*] Sat Jan 28 02:55:46 2023:    2    | Tr.loss: 0.266586 | Elapsed:   15.18  s | FPR 0.0003 -> TPR: 0.17 & F1: 0.29 | AUC: 0.9510
01/28/2023 02:55:46 AM  [*] Started epoch: 3
01/28/2023 02:55:46 AM  [*] Sat Jan 28 02:55:46 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.115388 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.9714 & F1 0.9855
01/28/2023 02:55:52 AM  [*] Sat Jan 28 02:55:52 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.223763 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.5758 & F1 0.7308
01/28/2023 02:55:58 AM  [*] Sat Jan 28 02:55:58 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.138698 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.6000 & F1 0.7500
01/28/2023 02:56:01 AM  [*] Sat Jan 28 02:56:01 2023:    3    | Tr.loss: 0.202528 | Elapsed:   15.19  s | FPR 0.0003 -> TPR: 0.47 & F1: 0.64 | AUC: 0.9723
01/28/2023 02:56:07 AM  [*] Started epoch: 1
01/28/2023 02:56:07 AM  [*] Sat Jan 28 02:56:07 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.401894 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 02:56:13 AM  [*] Sat Jan 28 02:56:13 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.339965 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.2462 & F1 0.3951
01/28/2023 02:56:19 AM  [*] Sat Jan 28 02:56:19 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.311118 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.5714 & F1 0.7273
01/28/2023 02:56:22 AM  [*] Sat Jan 28 02:56:22 2023:    1    | Tr.loss: 0.477828 | Elapsed:   15.16  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8534
01/28/2023 02:56:22 AM  [*] Started epoch: 2
01/28/2023 02:56:22 AM  [*] Sat Jan 28 02:56:22 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.396039 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.6410 & F1 0.7813
01/28/2023 02:56:28 AM  [*] Sat Jan 28 02:56:28 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.251295 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.7857 & F1 0.8800
01/28/2023 02:56:34 AM  [*] Sat Jan 28 02:56:34 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.224444 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.4118 & F1 0.5833
01/28/2023 02:56:37 AM  [*] Sat Jan 28 02:56:37 2023:    2    | Tr.loss: 0.264861 | Elapsed:   15.17  s | FPR 0.0003 -> TPR: 0.20 & F1: 0.34 | AUC: 0.9515
01/28/2023 02:56:37 AM  [*] Started epoch: 3
01/28/2023 02:56:37 AM  [*] Sat Jan 28 02:56:37 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.210485 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.8140 & F1 0.8974
01/28/2023 02:56:43 AM  [*] Sat Jan 28 02:56:43 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.283005 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.6271 & F1 0.7708
01/28/2023 02:56:50 AM  [*] Sat Jan 28 02:56:50 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.190346 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.6429 & F1 0.7826
01/28/2023 02:56:52 AM  [*] Sat Jan 28 02:56:52 2023:    3    | Tr.loss: 0.199115 | Elapsed:   15.18  s | FPR 0.0003 -> TPR: 0.48 & F1: 0.65 | AUC: 0.9727
01/28/2023 02:56:58 AM  [*] Started epoch: 1
01/28/2023 02:56:58 AM  [*] Sat Jan 28 02:56:58 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.083936 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 02:57:04 AM  [*] Sat Jan 28 02:57:04 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.382704 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.2432 & F1 0.3913
01/28/2023 02:57:10 AM  [*] Sat Jan 28 02:57:10 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.338631 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.0781 & F1 0.1449
01/28/2023 02:57:13 AM  [*] Sat Jan 28 02:57:13 2023:    1    | Tr.loss: 0.485172 | Elapsed:   15.10  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8506
01/28/2023 02:57:13 AM  [*] Started epoch: 2
01/28/2023 02:57:13 AM  [*] Sat Jan 28 02:57:13 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.418431 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.2558 & F1 0.4074
01/28/2023 02:57:19 AM  [*] Sat Jan 28 02:57:19 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.185187 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.7101 & F1 0.8305
01/28/2023 02:57:26 AM  [*] Sat Jan 28 02:57:26 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.149237 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.9444 & F1 0.9714
01/28/2023 02:57:28 AM  [*] Sat Jan 28 02:57:28 2023:    2    | Tr.loss: 0.267985 | Elapsed:   15.11  s | FPR 0.0003 -> TPR: 0.24 & F1: 0.38 | AUC: 0.9501
01/28/2023 02:57:28 AM  [*] Started epoch: 3
01/28/2023 02:57:28 AM  [*] Sat Jan 28 02:57:28 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.158869 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.9375 & F1 0.9677
01/28/2023 02:57:34 AM  [*] Sat Jan 28 02:57:34 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.153839 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.9692 & F1 0.9844
01/28/2023 02:57:41 AM  [*] Sat Jan 28 02:57:41 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.215809 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.6351 & F1 0.7769
01/28/2023 02:57:43 AM  [*] Sat Jan 28 02:57:43 2023:    3    | Tr.loss: 0.207126 | Elapsed:   15.06  s | FPR 0.0003 -> TPR: 0.47 & F1: 0.64 | AUC: 0.9708
01/28/2023 02:57:49 AM  [*] Started epoch: 1
01/28/2023 02:57:49 AM  [*] Sat Jan 28 02:57:49 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.143875 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0217 & F1 0.0426
01/28/2023 02:57:55 AM  [*] Sat Jan 28 02:57:55 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.498454 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.4507 & F1 0.6214
01/28/2023 02:58:01 AM  [*] Sat Jan 28 02:58:01 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.356816 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.6716 & F1 0.8036
01/28/2023 02:58:04 AM  [*] Sat Jan 28 02:58:04 2023:    1    | Tr.loss: 0.504121 | Elapsed:   15.02  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8384
01/28/2023 02:58:04 AM  [*] Started epoch: 2
01/28/2023 02:58:04 AM  [*] Sat Jan 28 02:58:04 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.239833 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.7111 & F1 0.8312
01/28/2023 02:58:10 AM  [*] Sat Jan 28 02:58:10 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.373877 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.4697 & F1 0.6392
01/28/2023 02:58:16 AM  [*] Sat Jan 28 02:58:16 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.219384 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.8030 & F1 0.8908
01/28/2023 02:58:19 AM  [*] Sat Jan 28 02:58:19 2023:    2    | Tr.loss: 0.281690 | Elapsed:   15.05  s | FPR 0.0003 -> TPR: 0.21 & F1: 0.35 | AUC: 0.9460
01/28/2023 02:58:19 AM  [*] Started epoch: 3
01/28/2023 02:58:19 AM  [*] Sat Jan 28 02:58:19 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.327904 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.6136 & F1 0.7606
01/28/2023 02:58:25 AM  [*] Sat Jan 28 02:58:25 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.273504 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.6857 & F1 0.8136
01/28/2023 02:58:31 AM  [*] Sat Jan 28 02:58:31 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.174191 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.8788 & F1 0.9355
01/28/2023 02:58:34 AM  [*] Sat Jan 28 02:58:34 2023:    3    | Tr.loss: 0.214640 | Elapsed:   15.07  s | FPR 0.0003 -> TPR: 0.30 & F1: 0.46 | AUC: 0.9693
01/28/2023 02:58:40 AM  [*] Started epoch: 1
01/28/2023 02:58:40 AM  [*] Sat Jan 28 02:58:40 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.559384 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 02:58:46 AM  [*] Sat Jan 28 02:58:46 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.509542 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.2836 & F1 0.4419
01/28/2023 02:58:52 AM  [*] Sat Jan 28 02:58:52 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.359789 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.3390 & F1 0.5063
01/28/2023 02:58:55 AM  [*] Sat Jan 28 02:58:55 2023:    1    | Tr.loss: 0.495565 | Elapsed:   15.04  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8463
01/28/2023 02:58:55 AM  [*] Started epoch: 2
01/28/2023 02:58:55 AM  [*] Sat Jan 28 02:58:55 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.406235 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.6316 & F1 0.7742
01/28/2023 02:59:01 AM  [*] Sat Jan 28 02:59:01 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.238667 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.4730 & F1 0.6422
01/28/2023 02:59:07 AM  [*] Sat Jan 28 02:59:07 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.168750 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.7143 & F1 0.8333
01/28/2023 02:59:10 AM  [*] Sat Jan 28 02:59:10 2023:    2    | Tr.loss: 0.260501 | Elapsed:   15.09  s | FPR 0.0003 -> TPR: 0.27 & F1: 0.42 | AUC: 0.9533
01/28/2023 02:59:10 AM  [*] Started epoch: 3
01/28/2023 02:59:10 AM  [*] Sat Jan 28 02:59:10 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.255058 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.7500 & F1 0.8571
01/28/2023 02:59:16 AM  [*] Sat Jan 28 02:59:16 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.159915 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.9259 & F1 0.9615
01/28/2023 02:59:22 AM  [*] Sat Jan 28 02:59:22 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.177969 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.8730 & F1 0.9322
01/28/2023 02:59:25 AM  [*] Sat Jan 28 02:59:25 2023:    3    | Tr.loss: 0.199765 | Elapsed:   15.08  s | FPR 0.0003 -> TPR: 0.32 & F1: 0.48 | AUC: 0.9731
01/28/2023 02:59:30 AM  [*] Started epoch: 1
01/28/2023 02:59:31 AM  [*] Sat Jan 28 02:59:31 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 4.423198 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 02:59:37 AM  [*] Sat Jan 28 02:59:37 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.341302 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.5238 & F1 0.6875
01/28/2023 02:59:43 AM  [*] Sat Jan 28 02:59:43 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.318549 | Elapsed: 6.15s | FPR 0.0003 -> TPR 0.6364 & F1 0.7778
01/28/2023 02:59:45 AM  [*] Sat Jan 28 02:59:45 2023:    1    | Tr.loss: 0.501177 | Elapsed:   15.01  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8471
01/28/2023 02:59:45 AM  [*] Started epoch: 2
01/28/2023 02:59:45 AM  [*] Sat Jan 28 02:59:45 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.325250 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.7500 & F1 0.8571
01/28/2023 02:59:52 AM  [*] Sat Jan 28 02:59:52 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.251003 | Elapsed: 6.13s | FPR 0.0003 -> TPR 0.6000 & F1 0.7500
01/28/2023 02:59:58 AM  [*] Sat Jan 28 02:59:58 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.215675 | Elapsed: 6.15s | FPR 0.0003 -> TPR 0.7353 & F1 0.8475
01/28/2023 03:00:00 AM  [*] Sat Jan 28 03:00:00 2023:    2    | Tr.loss: 0.257361 | Elapsed:   15.02  s | FPR 0.0003 -> TPR: 0.16 & F1: 0.28 | AUC: 0.9550
01/28/2023 03:00:00 AM  [*] Started epoch: 3
01/28/2023 03:00:01 AM  [*] Sat Jan 28 03:00:01 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.183758 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.7660 & F1 0.8675
01/28/2023 03:00:07 AM  [*] Sat Jan 28 03:00:07 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.179177 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.9265 & F1 0.9618
01/28/2023 03:00:13 AM  [*] Sat Jan 28 03:00:13 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.099574 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.6957 & F1 0.8205
01/28/2023 03:00:16 AM  [*] Sat Jan 28 03:00:16 2023:    3    | Tr.loss: 0.192286 | Elapsed:   15.07  s | FPR 0.0003 -> TPR: 0.45 & F1: 0.62 | AUC: 0.9751
01/28/2023 03:00:21 AM  [*] Started epoch: 1
01/28/2023 03:00:21 AM  [*] Sat Jan 28 03:00:21 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.434190 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 03:00:27 AM  [*] Sat Jan 28 03:00:27 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.432659 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.1429 & F1 0.2500
01/28/2023 03:00:34 AM  [*] Sat Jan 28 03:00:34 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.255672 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.8507 & F1 0.9194
01/28/2023 03:00:36 AM  [*] Sat Jan 28 03:00:36 2023:    1    | Tr.loss: 0.486807 | Elapsed:   15.00  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8537
01/28/2023 03:00:36 AM  [*] Started epoch: 2
01/28/2023 03:00:36 AM  [*] Sat Jan 28 03:00:36 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.217646 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.8000 & F1 0.8889
01/28/2023 03:00:42 AM  [*] Sat Jan 28 03:00:42 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.199891 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.6812 & F1 0.8103
01/28/2023 03:00:49 AM  [*] Sat Jan 28 03:00:49 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.216549 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.6806 & F1 0.8099
01/28/2023 03:00:51 AM  [*] Sat Jan 28 03:00:51 2023:    2    | Tr.loss: 0.267061 | Elapsed:   15.06  s | FPR 0.0003 -> TPR: 0.25 & F1: 0.40 | AUC: 0.9509
01/28/2023 03:00:51 AM  [*] Started epoch: 3
01/28/2023 03:00:51 AM  [*] Sat Jan 28 03:00:51 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.316637 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.7143 & F1 0.8333
01/28/2023 03:00:58 AM  [*] Sat Jan 28 03:00:58 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.312656 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.8361 & F1 0.9107
01/28/2023 03:01:04 AM  [*] Sat Jan 28 03:01:04 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.250387 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.4462 & F1 0.6170
01/28/2023 03:01:06 AM  [*] Sat Jan 28 03:01:06 2023:    3    | Tr.loss: 0.201057 | Elapsed:   15.10  s | FPR 0.0003 -> TPR: 0.44 & F1: 0.61 | AUC: 0.9730
01/28/2023 03:01:12 AM  [*] Started epoch: 1
01/28/2023 03:01:12 AM  [*] Sat Jan 28 03:01:12 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.682106 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 03:01:18 AM  [*] Sat Jan 28 03:01:18 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.431029 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.2676 & F1 0.4222
01/28/2023 03:01:24 AM  [*] Sat Jan 28 03:01:24 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.298996 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.5075 & F1 0.6733
01/28/2023 03:01:27 AM  [*] Sat Jan 28 03:01:27 2023:    1    | Tr.loss: 0.508632 | Elapsed:   15.02  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8421
01/28/2023 03:01:27 AM  [*] Started epoch: 2
01/28/2023 03:01:27 AM  [*] Sat Jan 28 03:01:27 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.365698 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.5263 & F1 0.6897
01/28/2023 03:01:33 AM  [*] Sat Jan 28 03:01:33 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.322739 | Elapsed: 6.16s | FPR 0.0003 -> TPR 0.3286 & F1 0.4946
01/28/2023 03:01:39 AM  [*] Sat Jan 28 03:01:39 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.297894 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.7361 & F1 0.8480
01/28/2023 03:01:42 AM  [*] Sat Jan 28 03:01:42 2023:    2    | Tr.loss: 0.273489 | Elapsed:   15.04  s | FPR 0.0003 -> TPR: 0.17 & F1: 0.30 | AUC: 0.9476
01/28/2023 03:01:42 AM  [*] Started epoch: 3
01/28/2023 03:01:42 AM  [*] Sat Jan 28 03:01:42 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.232685 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.7170 & F1 0.8352
01/28/2023 03:01:48 AM  [*] Sat Jan 28 03:01:48 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.163857 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.7647 & F1 0.8667
01/28/2023 03:01:54 AM  [*] Sat Jan 28 03:01:54 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.211960 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.7465 & F1 0.8548
01/28/2023 03:01:57 AM  [*] Sat Jan 28 03:01:57 2023:    3    | Tr.loss: 0.205506 | Elapsed:   15.09  s | FPR 0.0003 -> TPR: 0.42 & F1: 0.59 | AUC: 0.9713
01/28/2023 03:02:03 AM  [*] Started epoch: 1
01/28/2023 03:02:03 AM  [*] Sat Jan 28 03:02:03 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.230455 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 03:02:09 AM  [*] Sat Jan 28 03:02:09 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.341442 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.3247 & F1 0.4902
01/28/2023 03:02:15 AM  [*] Sat Jan 28 03:02:15 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.306362 | Elapsed: 6.16s | FPR 0.0003 -> TPR 0.3478 & F1 0.5161
01/28/2023 03:02:18 AM  [*] Sat Jan 28 03:02:18 2023:    1    | Tr.loss: 0.494073 | Elapsed:   15.00  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8487
01/28/2023 03:02:18 AM  [*] Started epoch: 2
01/28/2023 03:02:18 AM  [*] Sat Jan 28 03:02:18 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.353634 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.6364 & F1 0.7778
01/28/2023 03:02:24 AM  [*] Sat Jan 28 03:02:24 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.219448 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.4571 & F1 0.6275
01/28/2023 03:02:30 AM  [*] Sat Jan 28 03:02:30 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.179828 | Elapsed: 6.14s | FPR 0.0003 -> TPR 0.8493 & F1 0.9185
01/28/2023 03:02:33 AM  [*] Sat Jan 28 03:02:33 2023:    2    | Tr.loss: 0.263008 | Elapsed:   15.05  s | FPR 0.0003 -> TPR: 0.22 & F1: 0.36 | AUC: 0.9522
01/28/2023 03:02:33 AM  [*] Started epoch: 3
01/28/2023 03:02:33 AM  [*] Sat Jan 28 03:02:33 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.344637 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.7750 & F1 0.8732
01/28/2023 03:02:39 AM  [*] Sat Jan 28 03:02:39 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.180613 | Elapsed: 6.15s | FPR 0.0003 -> TPR 0.8406 & F1 0.9134
01/28/2023 03:02:45 AM  [*] Sat Jan 28 03:02:45 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.164458 | Elapsed: 6.14s | FPR 0.0003 -> TPR 0.6986 & F1 0.8226
01/28/2023 03:02:48 AM  [*] Sat Jan 28 03:02:48 2023:    3    | Tr.loss: 0.202505 | Elapsed:   14.99  s | FPR 0.0003 -> TPR: 0.44 & F1: 0.61 | AUC: 0.9725
01/28/2023 03:02:53 AM  [*] Started epoch: 1
01/28/2023 03:02:53 AM  [*] Sat Jan 28 03:02:53 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 4.335378 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 03:03:00 AM  [*] Sat Jan 28 03:03:00 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.488898 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.5065 & F1 0.6724
01/28/2023 03:03:06 AM  [*] Sat Jan 28 03:03:06 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.337261 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.3056 & F1 0.4681
01/28/2023 03:03:08 AM  [*] Sat Jan 28 03:03:08 2023:    1    | Tr.loss: 0.509338 | Elapsed:   15.03  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8436
01/28/2023 03:03:08 AM  [*] Started epoch: 2
01/28/2023 03:03:08 AM  [*] Sat Jan 28 03:03:08 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.227951 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.4773 & F1 0.6462
01/28/2023 03:03:15 AM  [*] Sat Jan 28 03:03:15 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.237747 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.5352 & F1 0.6972
01/28/2023 03:03:21 AM  [*] Sat Jan 28 03:03:21 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.255397 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.4250 & F1 0.5965
01/28/2023 03:03:23 AM  [*] Sat Jan 28 03:03:23 2023:    2    | Tr.loss: 0.257736 | Elapsed:   15.10  s | FPR 0.0003 -> TPR: 0.15 & F1: 0.27 | AUC: 0.9546
01/28/2023 03:03:23 AM  [*] Started epoch: 3
01/28/2023 03:03:24 AM  [*] Sat Jan 28 03:03:24 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.151604 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.9524 & F1 0.9756
01/28/2023 03:03:30 AM  [*] Sat Jan 28 03:03:30 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.232758 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.8529 & F1 0.9206
01/28/2023 03:03:36 AM  [*] Sat Jan 28 03:03:36 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.200296 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.8382 & F1 0.9120
01/28/2023 03:03:39 AM  [*] Sat Jan 28 03:03:39 2023:    3    | Tr.loss: 0.198082 | Elapsed:   15.11  s | FPR 0.0003 -> TPR: 0.46 & F1: 0.63 | AUC: 0.9737
01/28/2023 03:03:44 AM  [*] Started epoch: 1
01/28/2023 03:03:44 AM  [*] Sat Jan 28 03:03:44 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.074903 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 03:03:50 AM  [*] Sat Jan 28 03:03:50 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.337191 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.4429 & F1 0.6139
01/28/2023 03:03:57 AM  [*] Sat Jan 28 03:03:57 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.281081 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.5652 & F1 0.7222
01/28/2023 03:03:59 AM  [*] Sat Jan 28 03:03:59 2023:    1    | Tr.loss: 0.505427 | Elapsed:   15.04  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8466
01/28/2023 03:03:59 AM  [*] Started epoch: 2
01/28/2023 03:03:59 AM  [*] Sat Jan 28 03:03:59 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.204154 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.7391 & F1 0.8500
01/28/2023 03:04:06 AM  [*] Sat Jan 28 03:04:06 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.248071 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.6812 & F1 0.8103
01/28/2023 03:04:12 AM  [*] Sat Jan 28 03:04:12 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.216631 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.7662 & F1 0.8676
01/28/2023 03:04:14 AM  [*] Sat Jan 28 03:04:14 2023:    2    | Tr.loss: 0.267754 | Elapsed:   15.11  s | FPR 0.0003 -> TPR: 0.22 & F1: 0.36 | AUC: 0.9506
01/28/2023 03:04:14 AM  [*] Started epoch: 3
01/28/2023 03:04:14 AM  [*] Sat Jan 28 03:04:14 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.204286 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.6222 & F1 0.7671
01/28/2023 03:04:21 AM  [*] Sat Jan 28 03:04:21 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.280082 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.6780 & F1 0.8081
01/28/2023 03:04:27 AM  [*] Sat Jan 28 03:04:27 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.186550 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.7206 & F1 0.8376
01/28/2023 03:04:30 AM  [*] Sat Jan 28 03:04:30 2023:    3    | Tr.loss: 0.202792 | Elapsed:   15.14  s | FPR 0.0003 -> TPR: 0.44 & F1: 0.61 | AUC: 0.9725
01/28/2023 03:04:35 AM  [*] Started epoch: 1
01/28/2023 03:04:35 AM  [*] Sat Jan 28 03:04:35 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 2.471058 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 03:04:41 AM  [*] Sat Jan 28 03:04:41 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.372509 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.2639 & F1 0.4176
01/28/2023 03:04:48 AM  [*] Sat Jan 28 03:04:48 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.374187 | Elapsed: 6.15s | FPR 0.0003 -> TPR 0.2879 & F1 0.4471
01/28/2023 03:04:50 AM  [*] Sat Jan 28 03:04:50 2023:    1    | Tr.loss: 0.516695 | Elapsed:   15.02  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8409
01/28/2023 03:04:50 AM  [*] Started epoch: 2
01/28/2023 03:04:50 AM  [*] Sat Jan 28 03:04:50 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.410539 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.5952 & F1 0.7463
01/28/2023 03:04:56 AM  [*] Sat Jan 28 03:04:56 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.213219 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.8649 & F1 0.9275
01/28/2023 03:05:03 AM  [*] Sat Jan 28 03:05:03 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.234047 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.9091 & F1 0.9524
01/28/2023 03:05:05 AM  [*] Sat Jan 28 03:05:05 2023:    2    | Tr.loss: 0.266161 | Elapsed:   15.07  s | FPR 0.0003 -> TPR: 0.34 & F1: 0.51 | AUC: 0.9509
01/28/2023 03:05:05 AM  [*] Started epoch: 3
01/28/2023 03:05:05 AM  [*] Sat Jan 28 03:05:05 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.279279 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.7755 & F1 0.8736
01/28/2023 03:05:11 AM  [*] Sat Jan 28 03:05:11 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.233524 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.7258 & F1 0.8411
01/28/2023 03:05:18 AM  [*] Sat Jan 28 03:05:18 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.108519 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.9265 & F1 0.9618
01/28/2023 03:05:20 AM  [*] Sat Jan 28 03:05:20 2023:    3    | Tr.loss: 0.199890 | Elapsed:   15.14  s | FPR 0.0003 -> TPR: 0.42 & F1: 0.59 | AUC: 0.9733
01/28/2023 03:05:26 AM  [*] Started epoch: 1
01/28/2023 03:05:26 AM  [*] Sat Jan 28 03:05:26 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.603154 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 03:05:32 AM  [*] Sat Jan 28 03:05:32 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.470469 | Elapsed: 6.16s | FPR 0.0003 -> TPR 0.3623 & F1 0.5319
01/28/2023 03:05:38 AM  [*] Sat Jan 28 03:05:38 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.313990 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.6267 & F1 0.7705
01/28/2023 03:05:41 AM  [*] Sat Jan 28 03:05:41 2023:    1    | Tr.loss: 0.502507 | Elapsed:   14.99  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8432
01/28/2023 03:05:41 AM  [*] Started epoch: 2
01/28/2023 03:05:41 AM  [*] Sat Jan 28 03:05:41 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.335023 | Elapsed: 0.05s | FPR 0.0003 -> TPR 0.5000 & F1 0.6667
01/28/2023 03:05:47 AM  [*] Sat Jan 28 03:05:47 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.228209 | Elapsed: 6.15s | FPR 0.0003 -> TPR 0.7429 & F1 0.8525
01/28/2023 03:05:53 AM  [*] Sat Jan 28 03:05:53 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.196531 | Elapsed: 6.15s | FPR 0.0003 -> TPR 0.8000 & F1 0.8889
01/28/2023 03:05:56 AM  [*] Sat Jan 28 03:05:56 2023:    2    | Tr.loss: 0.264753 | Elapsed:   15.03  s | FPR 0.0003 -> TPR: 0.15 & F1: 0.25 | AUC: 0.9513
01/28/2023 03:05:56 AM  [*] Started epoch: 3
01/28/2023 03:05:56 AM  [*] Sat Jan 28 03:05:56 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.127285 | Elapsed: 0.05s | FPR 0.0003 -> TPR 0.9535 & F1 0.9762
01/28/2023 03:06:02 AM  [*] Sat Jan 28 03:06:02 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.168252 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.8143 & F1 0.8976
01/28/2023 03:06:08 AM  [*] Sat Jan 28 03:06:08 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.168136 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.7015 & F1 0.8246
01/28/2023 03:06:11 AM  [*] Sat Jan 28 03:06:11 2023:    3    | Tr.loss: 0.195040 | Elapsed:   15.06  s | FPR 0.0003 -> TPR: 0.32 & F1: 0.49 | AUC: 0.9747
01/28/2023 03:06:17 AM  [*] Started epoch: 1
01/28/2023 03:06:17 AM  [*] Sat Jan 28 03:06:17 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.975785 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 03:06:23 AM  [*] Sat Jan 28 03:06:23 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.409737 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.1000 & F1 0.1818
01/28/2023 03:06:29 AM  [*] Sat Jan 28 03:06:29 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.235868 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.7681 & F1 0.8689
01/28/2023 03:06:32 AM  [*] Sat Jan 28 03:06:32 2023:    1    | Tr.loss: 0.508970 | Elapsed:   15.04  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8483
01/28/2023 03:06:32 AM  [*] Started epoch: 2
01/28/2023 03:06:32 AM  [*] Sat Jan 28 03:06:32 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.357681 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.5208 & F1 0.6849
01/28/2023 03:06:38 AM  [*] Sat Jan 28 03:06:38 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.321756 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.5915 & F1 0.7434
01/28/2023 03:06:44 AM  [*] Sat Jan 28 03:06:44 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.381604 | Elapsed: 6.15s | FPR 0.0003 -> TPR 0.5846 & F1 0.7379
01/28/2023 03:06:47 AM  [*] Sat Jan 28 03:06:47 2023:    2    | Tr.loss: 0.258438 | Elapsed:   15.02  s | FPR 0.0003 -> TPR: 0.29 & F1: 0.45 | AUC: 0.9540
01/28/2023 03:06:47 AM  [*] Started epoch: 3
01/28/2023 03:06:47 AM  [*] Sat Jan 28 03:06:47 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.161912 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.7907 & F1 0.8831
01/28/2023 03:06:53 AM  [*] Sat Jan 28 03:06:53 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.247460 | Elapsed: 6.15s | FPR 0.0003 -> TPR 0.7385 & F1 0.8496
01/28/2023 03:06:59 AM  [*] Sat Jan 28 03:06:59 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.108041 | Elapsed: 6.16s | FPR 0.0003 -> TPR 0.7571 & F1 0.8618
01/28/2023 03:07:02 AM  [*] Sat Jan 28 03:07:02 2023:    3    | Tr.loss: 0.204004 | Elapsed:   15.00  s | FPR 0.0003 -> TPR: 0.44 & F1: 0.61 | AUC: 0.9717
01/28/2023 03:07:07 AM  [*] Started epoch: 1
01/28/2023 03:07:07 AM  [*] Sat Jan 28 03:07:07 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.271277 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 03:07:14 AM  [*] Sat Jan 28 03:07:14 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.341031 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.8133 & F1 0.8971
01/28/2023 03:07:20 AM  [*] Sat Jan 28 03:07:20 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.466665 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.3385 & F1 0.5057
01/28/2023 03:07:22 AM  [*] Sat Jan 28 03:07:22 2023:    1    | Tr.loss: 0.495722 | Elapsed:   15.06  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8502
01/28/2023 03:07:22 AM  [*] Started epoch: 2
01/28/2023 03:07:22 AM  [*] Sat Jan 28 03:07:22 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.356980 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.2683 & F1 0.4231
01/28/2023 03:07:29 AM  [*] Sat Jan 28 03:07:29 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.203253 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.6452 & F1 0.7843
01/28/2023 03:07:35 AM  [*] Sat Jan 28 03:07:35 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.365983 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.5690 & F1 0.7253
01/28/2023 03:07:37 AM  [*] Sat Jan 28 03:07:37 2023:    2    | Tr.loss: 0.262882 | Elapsed:   15.08  s | FPR 0.0003 -> TPR: 0.19 & F1: 0.31 | AUC: 0.9516
01/28/2023 03:07:37 AM  [*] Started epoch: 3
01/28/2023 03:07:37 AM  [*] Sat Jan 28 03:07:37 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.270804 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.8125 & F1 0.8966
01/28/2023 03:07:44 AM  [*] Sat Jan 28 03:07:44 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.118957 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.7162 & F1 0.8346
01/28/2023 03:07:50 AM  [*] Sat Jan 28 03:07:50 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.128757 | Elapsed: 6.14s | FPR 0.0003 -> TPR 0.7656 & F1 0.8673
01/28/2023 03:07:52 AM  [*] Sat Jan 28 03:07:52 2023:    3    | Tr.loss: 0.199218 | Elapsed:   15.06  s | FPR 0.0003 -> TPR: 0.52 & F1: 0.69 | AUC: 0.9735
01/28/2023 03:07:58 AM  [*] Started epoch: 1
01/28/2023 03:07:58 AM  [*] Sat Jan 28 03:07:58 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.090887 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 03:08:04 AM  [*] Sat Jan 28 03:08:04 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.548762 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.0725 & F1 0.1351
01/28/2023 03:08:11 AM  [*] Sat Jan 28 03:08:11 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.280065 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.5833 & F1 0.7368
01/28/2023 03:08:13 AM  [*] Sat Jan 28 03:08:13 2023:    1    | Tr.loss: 0.512336 | Elapsed:   15.03  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8446
01/28/2023 03:08:13 AM  [*] Started epoch: 2
01/28/2023 03:08:13 AM  [*] Sat Jan 28 03:08:13 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.218596 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.8537 & F1 0.9211
01/28/2023 03:08:19 AM  [*] Sat Jan 28 03:08:19 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.203033 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.5571 & F1 0.7156
01/28/2023 03:08:26 AM  [*] Sat Jan 28 03:08:26 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.195168 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.4167 & F1 0.5882
01/28/2023 03:08:28 AM  [*] Sat Jan 28 03:08:28 2023:    2    | Tr.loss: 0.266729 | Elapsed:   15.09  s | FPR 0.0003 -> TPR: 0.28 & F1: 0.43 | AUC: 0.9508
01/28/2023 03:08:28 AM  [*] Started epoch: 3
01/28/2023 03:08:28 AM  [*] Sat Jan 28 03:08:28 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.246087 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.6667 & F1 0.8000
01/28/2023 03:08:34 AM  [*] Sat Jan 28 03:08:34 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.224558 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.7647 & F1 0.8667
01/28/2023 03:08:41 AM  [*] Sat Jan 28 03:08:41 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.138115 | Elapsed: 6.16s | FPR 0.0003 -> TPR 0.8873 & F1 0.9403
01/28/2023 03:08:43 AM  [*] Sat Jan 28 03:08:43 2023:    3    | Tr.loss: 0.201004 | Elapsed:   15.07  s | FPR 0.0003 -> TPR: 0.38 & F1: 0.55 | AUC: 0.9725
01/28/2023 03:08:49 AM  [*] Started epoch: 1
01/28/2023 03:08:49 AM  [*] Sat Jan 28 03:08:49 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.794305 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 03:08:55 AM  [*] Sat Jan 28 03:08:55 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.370614 | Elapsed: 6.15s | FPR 0.0003 -> TPR 0.5738 & F1 0.7292
01/28/2023 03:09:01 AM  [*] Sat Jan 28 03:09:01 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.290389 | Elapsed: 6.16s | FPR 0.0003 -> TPR 0.4333 & F1 0.6047
01/28/2023 03:09:04 AM  [*] Sat Jan 28 03:09:04 2023:    1    | Tr.loss: 0.518280 | Elapsed:   14.99  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8380
01/28/2023 03:09:04 AM  [*] Started epoch: 2
01/28/2023 03:09:04 AM  [*] Sat Jan 28 03:09:04 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.350988 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.7447 & F1 0.8537
01/28/2023 03:09:10 AM  [*] Sat Jan 28 03:09:10 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.198532 | Elapsed: 6.15s | FPR 0.0003 -> TPR 0.8356 & F1 0.9104
01/28/2023 03:09:16 AM  [*] Sat Jan 28 03:09:16 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.273808 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.7600 & F1 0.8636
01/28/2023 03:09:19 AM  [*] Sat Jan 28 03:09:19 2023:    2    | Tr.loss: 0.265417 | Elapsed:   15.02  s | FPR 0.0003 -> TPR: 0.20 & F1: 0.33 | AUC: 0.9521
01/28/2023 03:09:19 AM  [*] Started epoch: 3
01/28/2023 03:09:19 AM  [*] Sat Jan 28 03:09:19 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.181730 | Elapsed: 0.05s | FPR 0.0003 -> TPR 0.8958 & F1 0.9451
01/28/2023 03:09:25 AM  [*] Sat Jan 28 03:09:25 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.130677 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.9189 & F1 0.9577
01/28/2023 03:09:31 AM  [*] Sat Jan 28 03:09:31 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.341030 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.4677 & F1 0.6374
01/28/2023 03:09:34 AM  [*] Sat Jan 28 03:09:34 2023:    3    | Tr.loss: 0.195934 | Elapsed:   15.08  s | FPR 0.0003 -> TPR: 0.42 & F1: 0.59 | AUC: 0.9744
01/28/2023 03:09:39 AM  [*] Started epoch: 1
01/28/2023 03:09:40 AM  [*] Sat Jan 28 03:09:40 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.590042 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 03:09:46 AM  [*] Sat Jan 28 03:09:46 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.418848 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.5068 & F1 0.6727
01/28/2023 03:09:52 AM  [*] Sat Jan 28 03:09:52 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.303013 | Elapsed: 6.15s | FPR 0.0003 -> TPR 0.4769 & F1 0.6458
01/28/2023 03:09:54 AM  [*] Sat Jan 28 03:09:54 2023:    1    | Tr.loss: 0.528553 | Elapsed:   14.97  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8316
01/28/2023 03:09:54 AM  [*] Started epoch: 2
01/28/2023 03:09:55 AM  [*] Sat Jan 28 03:09:55 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.269666 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.8367 & F1 0.9111
01/28/2023 03:10:01 AM  [*] Sat Jan 28 03:10:01 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.198680 | Elapsed: 6.14s | FPR 0.0003 -> TPR 0.8026 & F1 0.8905
01/28/2023 03:10:07 AM  [*] Sat Jan 28 03:10:07 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.312230 | Elapsed: 6.14s | FPR 0.0003 -> TPR 0.5479 & F1 0.7080
01/28/2023 03:10:09 AM  [*] Sat Jan 28 03:10:09 2023:    2    | Tr.loss: 0.261306 | Elapsed:   15.01  s | FPR 0.0003 -> TPR: 0.30 & F1: 0.46 | AUC: 0.9541
01/28/2023 03:10:09 AM  [*] Started epoch: 3
01/28/2023 03:10:10 AM  [*] Sat Jan 28 03:10:10 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.231642 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.6842 & F1 0.8125
01/28/2023 03:10:16 AM  [*] Sat Jan 28 03:10:16 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.203655 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.7812 & F1 0.8772
01/28/2023 03:10:22 AM  [*] Sat Jan 28 03:10:22 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.190127 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.8333 & F1 0.9091
01/28/2023 03:10:25 AM  [*] Sat Jan 28 03:10:25 2023:    3    | Tr.loss: 0.200136 | Elapsed:   15.08  s | FPR 0.0003 -> TPR: 0.42 & F1: 0.60 | AUC: 0.9733
01/28/2023 03:10:30 AM  [*] Started epoch: 1
01/28/2023 03:10:30 AM  [*] Sat Jan 28 03:10:30 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 4.409777 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 03:10:36 AM  [*] Sat Jan 28 03:10:36 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.392702 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.2769 & F1 0.4337
01/28/2023 03:10:43 AM  [*] Sat Jan 28 03:10:43 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.332102 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.2113 & F1 0.3488
01/28/2023 03:10:45 AM  [*] Sat Jan 28 03:10:45 2023:    1    | Tr.loss: 0.527212 | Elapsed:   15.02  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8394
01/28/2023 03:10:45 AM  [*] Started epoch: 2
01/28/2023 03:10:45 AM  [*] Sat Jan 28 03:10:45 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.217617 | Elapsed: 0.05s | FPR 0.0003 -> TPR 0.8649 & F1 0.9275
01/28/2023 03:10:51 AM  [*] Sat Jan 28 03:10:51 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.273042 | Elapsed: 6.16s | FPR 0.0003 -> TPR 0.3521 & F1 0.5208
01/28/2023 03:10:58 AM  [*] Sat Jan 28 03:10:58 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.186484 | Elapsed: 6.16s | FPR 0.0003 -> TPR 0.8889 & F1 0.9412
01/28/2023 03:11:00 AM  [*] Sat Jan 28 03:11:00 2023:    2    | Tr.loss: 0.256259 | Elapsed:   15.09  s | FPR 0.0003 -> TPR: 0.20 & F1: 0.33 | AUC: 0.9550
01/28/2023 03:11:00 AM  [*] Started epoch: 3
01/28/2023 03:11:00 AM  [*] Sat Jan 28 03:11:00 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.252796 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.6596 & F1 0.7949
01/28/2023 03:11:07 AM  [*] Sat Jan 28 03:11:07 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.150113 | Elapsed: 6.16s | FPR 0.0003 -> TPR 0.8571 & F1 0.9231
01/28/2023 03:11:13 AM  [*] Sat Jan 28 03:11:13 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.319115 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.4688 & F1 0.6383
01/28/2023 03:11:15 AM  [*] Sat Jan 28 03:11:15 2023:    3    | Tr.loss: 0.194862 | Elapsed:   15.07  s | FPR 0.0003 -> TPR: 0.35 & F1: 0.52 | AUC: 0.9744
01/28/2023 03:11:21 AM  [*] Started epoch: 1
01/28/2023 03:11:21 AM  [*] Sat Jan 28 03:11:21 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 2.602269 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 03:11:27 AM  [*] Sat Jan 28 03:11:27 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.366960 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.3636 & F1 0.5333
01/28/2023 03:11:33 AM  [*] Sat Jan 28 03:11:33 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.302430 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.1892 & F1 0.3182
01/28/2023 03:11:36 AM  [*] Sat Jan 28 03:11:36 2023:    1    | Tr.loss: 0.511882 | Elapsed:   15.05  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8469
01/28/2023 03:11:36 AM  [*] Started epoch: 2
01/28/2023 03:11:36 AM  [*] Sat Jan 28 03:11:36 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.187270 | Elapsed: 0.05s | FPR 0.0003 -> TPR 0.8261 & F1 0.9048
01/28/2023 03:11:42 AM  [*] Sat Jan 28 03:11:42 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.183866 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.9178 & F1 0.9571
01/28/2023 03:11:48 AM  [*] Sat Jan 28 03:11:48 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.270870 | Elapsed: 6.16s | FPR 0.0003 -> TPR 0.5775 & F1 0.7321
01/28/2023 03:11:51 AM  [*] Sat Jan 28 03:11:51 2023:    2    | Tr.loss: 0.257476 | Elapsed:   15.09  s | FPR 0.0003 -> TPR: 0.28 & F1: 0.44 | AUC: 0.9540
01/28/2023 03:11:51 AM  [*] Started epoch: 3
01/28/2023 03:11:51 AM  [*] Sat Jan 28 03:11:51 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.195685 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.7778 & F1 0.8750
01/28/2023 03:11:57 AM  [*] Sat Jan 28 03:11:57 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.181506 | Elapsed: 6.16s | FPR 0.0003 -> TPR 0.7397 & F1 0.8504
01/28/2023 03:12:03 AM  [*] Sat Jan 28 03:12:03 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.166511 | Elapsed: 6.16s | FPR 0.0003 -> TPR 0.8806 & F1 0.9365
01/28/2023 03:12:06 AM  [*] Sat Jan 28 03:12:06 2023:    3    | Tr.loss: 0.197291 | Elapsed:   15.10  s | FPR 0.0003 -> TPR: 0.42 & F1: 0.59 | AUC: 0.9740
01/28/2023 03:12:12 AM  [*] Started epoch: 1
01/28/2023 03:12:12 AM  [*] Sat Jan 28 03:12:12 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.379530 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 03:12:18 AM  [*] Sat Jan 28 03:12:18 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.222267 | Elapsed: 6.16s | FPR 0.0003 -> TPR 0.5867 & F1 0.7395
01/28/2023 03:12:24 AM  [*] Sat Jan 28 03:12:24 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.308132 | Elapsed: 6.16s | FPR 0.0003 -> TPR 0.5000 & F1 0.6667
01/28/2023 03:12:27 AM  [*] Sat Jan 28 03:12:27 2023:    1    | Tr.loss: 0.504111 | Elapsed:   15.01  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8476
01/28/2023 03:12:27 AM  [*] Started epoch: 2
01/28/2023 03:12:27 AM  [*] Sat Jan 28 03:12:27 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.348979 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.5476 & F1 0.7077
01/28/2023 03:12:33 AM  [*] Sat Jan 28 03:12:33 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.314792 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.4242 & F1 0.5957
01/28/2023 03:12:39 AM  [*] Sat Jan 28 03:12:39 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.261570 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.7460 & F1 0.8545
01/28/2023 03:12:42 AM  [*] Sat Jan 28 03:12:42 2023:    2    | Tr.loss: 0.256252 | Elapsed:   15.06  s | FPR 0.0003 -> TPR: 0.17 & F1: 0.29 | AUC: 0.9549
01/28/2023 03:12:42 AM  [*] Started epoch: 3
01/28/2023 03:12:42 AM  [*] Sat Jan 28 03:12:42 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.154315 | Elapsed: 0.05s | FPR 0.0003 -> TPR 0.9302 & F1 0.9639
01/28/2023 03:12:48 AM  [*] Sat Jan 28 03:12:48 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.157046 | Elapsed: 6.16s | FPR 0.0003 -> TPR 0.9130 & F1 0.9545
01/28/2023 03:12:54 AM  [*] Sat Jan 28 03:12:54 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.175205 | Elapsed: 6.16s | FPR 0.0003 -> TPR 0.9265 & F1 0.9618
01/28/2023 03:12:57 AM  [*] Sat Jan 28 03:12:57 2023:    3    | Tr.loss: 0.193009 | Elapsed:   15.05  s | FPR 0.0003 -> TPR: 0.48 & F1: 0.65 | AUC: 0.9750
01/28/2023 03:13:02 AM  [*] Started epoch: 1
01/28/2023 03:13:03 AM  [*] Sat Jan 28 03:13:03 2023: Train Epoch: 1 [  0  /15226 (0 %)]	Loss: 3.670777 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000
01/28/2023 03:13:09 AM  [*] Sat Jan 28 03:13:09 2023: Train Epoch: 1 [6400 /15226 (42%)]	Loss: 0.444907 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.3226 & F1 0.4878
01/28/2023 03:13:15 AM  [*] Sat Jan 28 03:13:15 2023: Train Epoch: 1 [12800/15226 (84%)]	Loss: 0.225963 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.7101 & F1 0.8305
01/28/2023 03:13:17 AM  [*] Sat Jan 28 03:13:17 2023:    1    | Tr.loss: 0.494834 | Elapsed:   15.03  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8537
01/28/2023 03:13:17 AM  [*] Started epoch: 2
01/28/2023 03:13:18 AM  [*] Sat Jan 28 03:13:18 2023: Train Epoch: 2 [  0  /15226 (0 %)]	Loss: 0.439934 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.6512 & F1 0.7887
01/28/2023 03:13:24 AM  [*] Sat Jan 28 03:13:24 2023: Train Epoch: 2 [6400 /15226 (42%)]	Loss: 0.265488 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.7042 & F1 0.8264
01/28/2023 03:13:30 AM  [*] Sat Jan 28 03:13:30 2023: Train Epoch: 2 [12800/15226 (84%)]	Loss: 0.230366 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.9296 & F1 0.9635
01/28/2023 03:13:33 AM  [*] Sat Jan 28 03:13:33 2023:    2    | Tr.loss: 0.259379 | Elapsed:   15.06  s | FPR 0.0003 -> TPR: 0.24 & F1: 0.38 | AUC: 0.9533
01/28/2023 03:13:33 AM  [*] Started epoch: 3
01/28/2023 03:13:33 AM  [*] Sat Jan 28 03:13:33 2023: Train Epoch: 3 [  0  /15226 (0 %)]	Loss: 0.158076 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.8974 & F1 0.9459
01/28/2023 03:13:39 AM  [*] Sat Jan 28 03:13:39 2023: Train Epoch: 3 [6400 /15226 (42%)]	Loss: 0.167313 | Elapsed: 6.16s | FPR 0.0003 -> TPR 0.8710 & F1 0.9310
01/28/2023 03:13:45 AM  [*] Sat Jan 28 03:13:45 2023: Train Epoch: 3 [12800/15226 (84%)]	Loss: 0.163860 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.8209 & F1 0.9016
01/28/2023 03:13:48 AM  [*] Sat Jan 28 03:13:48 2023:    3    | Tr.loss: 0.194400 | Elapsed:   15.08  s | FPR 0.0003 -> TPR: 0.45 & F1: 0.62 | AUC: 0.9743
