WARNING:root: [!] Skipping maxLen_1024_vocabSize_10000 as it already exists
WARNING:root: [!] Skipping maxLen_2048_vocabSize_10000 as it already exists
WARNING:root: [!] Skipping maxLen_4096_vocabSize_10000 as it already exists
WARNING:root: [!] Skipping maxLen_512_vocabSize_10000 as it already exists
WARNING:root: [!] Running Cross Validation with vocabSize: 10000 | maxLen: 6144
WARNING:root: [!] Using device: cuda:0 | Dataset size: 76126
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 10000, 'embeddingDim': 64, 'hiddenNeurons': [512, 256, 128], 'batchNormConv': False, 'batchNormFFNN': False, 'filterSizes': [2, 3, 4, 5]}
WARNING:root: [!] Fold 1/3 | Train set size: 50750, Validation set size: 25376
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Sat Dec 24 09:34:23 2022: Train Epoch: 1 [  0  /50750 (0 %)]	Loss: 0.671425 | F1-score: 0.78 | Elapsed: 2.20s
WARNING:root: [*] Sat Dec 24 09:34:44 2022: Train Epoch: 1 [6400 /50750 (13%)]	Loss: 0.300060 | F1-score: 0.86 | Elapsed: 20.62s
WARNING:root: [*] Sat Dec 24 09:35:06 2022: Train Epoch: 1 [12800/50750 (25%)]	Loss: 0.091147 | F1-score: 0.91 | Elapsed: 21.79s
WARNING:root: [*] Sat Dec 24 09:35:27 2022: Train Epoch: 1 [19200/50750 (38%)]	Loss: 0.117487 | F1-score: 0.93 | Elapsed: 21.21s
WARNING:root: [*] Sat Dec 24 09:35:48 2022: Train Epoch: 1 [25600/50750 (50%)]	Loss: 0.081864 | F1-score: 0.94 | Elapsed: 21.10s
WARNING:root: [*] Sat Dec 24 09:36:09 2022: Train Epoch: 1 [32000/50750 (63%)]	Loss: 0.119369 | F1-score: 0.95 | Elapsed: 21.09s
WARNING:root: [*] Sat Dec 24 09:36:30 2022: Train Epoch: 1 [38400/50750 (76%)]	Loss: 0.025259 | F1-score: 0.95 | Elapsed: 21.02s
WARNING:root: [*] Sat Dec 24 09:36:51 2022: Train Epoch: 1 [44800/50750 (88%)]	Loss: 0.026924 | F1-score: 0.96 | Elapsed: 21.02s
WARNING:root: [*] Sat Dec 24 09:37:10 2022:    1    | Tr.loss: 0.147109 | Tr.F1.:   0.96    |  169.40  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Sat Dec 24 09:37:11 2022: Train Epoch: 2 [  0  /50750 (0 %)]	Loss: 0.146350 | F1-score: 0.96 | Elapsed: 0.21s
WARNING:root: [*] Sat Dec 24 09:37:32 2022: Train Epoch: 2 [6400 /50750 (13%)]	Loss: 0.031561 | F1-score: 0.98 | Elapsed: 21.05s
WARNING:root: [*] Sat Dec 24 09:37:53 2022: Train Epoch: 2 [12800/50750 (25%)]	Loss: 0.028794 | F1-score: 0.98 | Elapsed: 21.05s
WARNING:root: [*] Sat Dec 24 09:38:14 2022: Train Epoch: 2 [19200/50750 (38%)]	Loss: 0.157644 | F1-score: 0.98 | Elapsed: 21.08s
WARNING:root: [*] Sat Dec 24 09:38:35 2022: Train Epoch: 2 [25600/50750 (50%)]	Loss: 0.076904 | F1-score: 0.98 | Elapsed: 21.09s
WARNING:root: [*] Sat Dec 24 09:38:56 2022: Train Epoch: 2 [32000/50750 (63%)]	Loss: 0.057688 | F1-score: 0.98 | Elapsed: 21.09s
WARNING:root: [*] Sat Dec 24 09:39:17 2022: Train Epoch: 2 [38400/50750 (76%)]	Loss: 0.040524 | F1-score: 0.98 | Elapsed: 21.13s
WARNING:root: [*] Sat Dec 24 09:39:38 2022: Train Epoch: 2 [44800/50750 (88%)]	Loss: 0.009485 | F1-score: 0.98 | Elapsed: 21.12s
WARNING:root: [*] Sat Dec 24 09:39:58 2022:    2    | Tr.loss: 0.064771 | Tr.F1.:   0.98    |  167.35  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Sat Dec 24 09:39:58 2022: Train Epoch: 3 [  0  /50750 (0 %)]	Loss: 0.069921 | F1-score: 0.99 | Elapsed: 0.20s
WARNING:root: [*] Sat Dec 24 09:40:19 2022: Train Epoch: 3 [6400 /50750 (13%)]	Loss: 0.048378 | F1-score: 0.99 | Elapsed: 21.27s
WARNING:root: [*] Sat Dec 24 09:40:41 2022: Train Epoch: 3 [12800/50750 (25%)]	Loss: 0.063328 | F1-score: 0.99 | Elapsed: 21.41s
WARNING:root: [*] Sat Dec 24 09:41:02 2022: Train Epoch: 3 [19200/50750 (38%)]	Loss: 0.019983 | F1-score: 0.99 | Elapsed: 21.19s
WARNING:root: [*] Sat Dec 24 09:41:23 2022: Train Epoch: 3 [25600/50750 (50%)]	Loss: 0.052708 | F1-score: 0.99 | Elapsed: 21.24s
WARNING:root: [*] Sat Dec 24 09:41:44 2022: Train Epoch: 3 [32000/50750 (63%)]	Loss: 0.020439 | F1-score: 0.99 | Elapsed: 21.23s
WARNING:root: [*] Sat Dec 24 09:42:05 2022: Train Epoch: 3 [38400/50750 (76%)]	Loss: 0.009894 | F1-score: 0.99 | Elapsed: 21.22s
WARNING:root: [*] Sat Dec 24 09:42:27 2022: Train Epoch: 3 [44800/50750 (88%)]	Loss: 0.055670 | F1-score: 0.99 | Elapsed: 21.23s
WARNING:root: [*] Sat Dec 24 09:42:46 2022:    3    | Tr.loss: 0.054662 | Tr.F1.:   0.99    |  168.52  s
WARNING:root:
        [!] Sat Dec 24 09:42:46 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671871366-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671871366-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671871366-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671871366-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Sat Dec 24 09:43:13 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.702247 | F1-score: 0.57 | Elapsed: 0.25s
WARNING:root: [*] Sat Dec 24 09:43:34 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.176494 | F1-score: 0.88 | Elapsed: 21.17s
WARNING:root: [*] Sat Dec 24 09:43:55 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.150621 | F1-score: 0.92 | Elapsed: 21.19s
WARNING:root: [*] Sat Dec 24 09:44:16 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.339955 | F1-score: 0.93 | Elapsed: 21.19s
WARNING:root: [*] Sat Dec 24 09:44:37 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.069029 | F1-score: 0.94 | Elapsed: 21.21s
WARNING:root: [*] Sat Dec 24 09:44:59 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.075490 | F1-score: 0.95 | Elapsed: 21.19s
WARNING:root: [*] Sat Dec 24 09:45:20 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.075767 | F1-score: 0.95 | Elapsed: 21.48s
WARNING:root: [*] Sat Dec 24 09:45:41 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.054376 | F1-score: 0.96 | Elapsed: 21.24s
WARNING:root: [*] Sat Dec 24 09:46:01 2022:    1    | Tr.loss: 0.143278 | Tr.F1.:   0.96    |  168.43  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Sat Dec 24 09:46:01 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.095647 | F1-score: 0.99 | Elapsed: 0.21s
WARNING:root: [*] Sat Dec 24 09:46:22 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.198915 | F1-score: 0.98 | Elapsed: 21.22s
WARNING:root: [*] Sat Dec 24 09:46:43 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.114915 | F1-score: 0.98 | Elapsed: 21.21s
WARNING:root: [*] Sat Dec 24 09:47:05 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.148121 | F1-score: 0.98 | Elapsed: 21.19s
WARNING:root: [*] Sat Dec 24 09:47:26 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.038632 | F1-score: 0.98 | Elapsed: 21.19s
WARNING:root: [*] Sat Dec 24 09:47:47 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.035890 | F1-score: 0.98 | Elapsed: 21.23s
WARNING:root: [*] Sat Dec 24 09:48:08 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.091340 | F1-score: 0.98 | Elapsed: 21.21s
WARNING:root: [*] Sat Dec 24 09:48:29 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.024439 | F1-score: 0.98 | Elapsed: 21.18s
WARNING:root: [*] Sat Dec 24 09:48:49 2022:    2    | Tr.loss: 0.066732 | Tr.F1.:   0.98    |  168.16  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Sat Dec 24 09:48:49 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.132709 | F1-score: 0.96 | Elapsed: 0.23s
WARNING:root: [*] Sat Dec 24 09:49:10 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.103914 | F1-score: 0.98 | Elapsed: 21.20s
WARNING:root: [*] Sat Dec 24 09:49:32 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.056784 | F1-score: 0.98 | Elapsed: 21.20s
WARNING:root: [*] Sat Dec 24 09:49:53 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.120974 | F1-score: 0.98 | Elapsed: 21.20s
WARNING:root: [*] Sat Dec 24 09:50:14 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.071450 | F1-score: 0.98 | Elapsed: 21.19s
WARNING:root: [*] Sat Dec 24 09:50:35 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.026832 | F1-score: 0.99 | Elapsed: 21.21s
WARNING:root: [*] Sat Dec 24 09:50:56 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.015356 | F1-score: 0.99 | Elapsed: 21.21s
WARNING:root: [*] Sat Dec 24 09:51:18 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.048106 | F1-score: 0.99 | Elapsed: 21.24s
WARNING:root: [*] Sat Dec 24 09:51:37 2022:    3    | Tr.loss: 0.055208 | Tr.F1.:   0.99    |  168.20  s
WARNING:root:
        [!] Sat Dec 24 09:51:37 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671871897-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671871897-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671871897-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671871897-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Sat Dec 24 09:52:04 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.689056 | F1-score: 0.60 | Elapsed: 0.25s
WARNING:root: [*] Sat Dec 24 09:52:25 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.104236 | F1-score: 0.88 | Elapsed: 21.21s
WARNING:root: [*] Sat Dec 24 09:52:46 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.074850 | F1-score: 0.92 | Elapsed: 21.19s
WARNING:root: [*] Sat Dec 24 09:53:07 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.077976 | F1-score: 0.93 | Elapsed: 21.21s
WARNING:root: [*] Sat Dec 24 09:53:29 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.178870 | F1-score: 0.94 | Elapsed: 21.21s
WARNING:root: [*] Sat Dec 24 09:53:50 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.172328 | F1-score: 0.95 | Elapsed: 21.20s
WARNING:root: [*] Sat Dec 24 09:54:11 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.059371 | F1-score: 0.95 | Elapsed: 21.21s
WARNING:root: [*] Sat Dec 24 09:54:32 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.070741 | F1-score: 0.96 | Elapsed: 21.21s
WARNING:root: [*] Sat Dec 24 09:54:52 2022:    1    | Tr.loss: 0.143510 | Tr.F1.:   0.96    |  168.22  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Sat Dec 24 09:54:52 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.042621 | F1-score: 0.99 | Elapsed: 0.22s
WARNING:root: [*] Sat Dec 24 09:55:13 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.042541 | F1-score: 0.98 | Elapsed: 21.23s
WARNING:root: [*] Sat Dec 24 09:55:34 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.037099 | F1-score: 0.98 | Elapsed: 21.26s
WARNING:root: [*] Sat Dec 24 09:55:56 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.098950 | F1-score: 0.98 | Elapsed: 21.24s
WARNING:root: [*] Sat Dec 24 09:56:17 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.027881 | F1-score: 0.98 | Elapsed: 21.24s
WARNING:root: [*] Sat Dec 24 09:56:38 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.033879 | F1-score: 0.98 | Elapsed: 21.23s
WARNING:root: [*] Sat Dec 24 09:56:59 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.012299 | F1-score: 0.98 | Elapsed: 21.23s
WARNING:root: [*] Sat Dec 24 09:57:21 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.034492 | F1-score: 0.98 | Elapsed: 21.35s
WARNING:root: [*] Sat Dec 24 09:57:40 2022:    2    | Tr.loss: 0.066403 | Tr.F1.:   0.98    |  168.53  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Sat Dec 24 09:57:41 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.009510 | F1-score: 1.00 | Elapsed: 0.21s
WARNING:root: [*] Sat Dec 24 09:58:02 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.035489 | F1-score: 0.99 | Elapsed: 21.27s
WARNING:root: [*] Sat Dec 24 09:58:23 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.033495 | F1-score: 0.99 | Elapsed: 21.35s
WARNING:root: [*] Sat Dec 24 09:58:45 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.166652 | F1-score: 0.99 | Elapsed: 21.38s
WARNING:root: [*] Sat Dec 24 09:59:06 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.034924 | F1-score: 0.99 | Elapsed: 21.31s
WARNING:root: [*] Sat Dec 24 09:59:27 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.026590 | F1-score: 0.99 | Elapsed: 21.24s
WARNING:root: [*] Sat Dec 24 09:59:48 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.016994 | F1-score: 0.99 | Elapsed: 21.23s
WARNING:root: [*] Sat Dec 24 10:00:10 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.072904 | F1-score: 0.99 | Elapsed: 21.22s
WARNING:root: [*] Sat Dec 24 10:00:29 2022:    3    | Tr.loss: 0.053327 | Tr.F1.:   0.99    |  168.77  s
WARNING:root:
        [!] Sat Dec 24 10:00:29 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671872429-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671872429-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671872429-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671872429-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\metrics_trainSize_76126_ep_3_cv_3_maxLen_6144_vocabSize_10000_embeddingDim_64_hiddenNeurons_512_256_128_batchNormConv_False_batchNormFFNN_False_filterSizes_2_3_4_5.json
WARNING:root: [!] Average epoch time: 168.40s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.5128 -- F1: 0.6768
	FPR:  0.001 -- TPR: 0.9376 -- F1: 0.9675
	FPR:   0.01 -- TPR: 0.9752 -- F1: 0.9852
	FPR:    0.1 -- TPR: 0.9963 -- F1: 0.9748

WARNING:root: [!] Skipping maxLen_1024_vocabSize_1000 as it already exists
WARNING:root: [!] Skipping maxLen_2048_vocabSize_1000 as it already exists
WARNING:root: [!] Skipping maxLen_4096_vocabSize_1000 as it already exists
WARNING:root: [!] Skipping maxLen_512_vocabSize_1000 as it already exists
WARNING:root: [!] Running Cross Validation with vocabSize: 1000 | maxLen: 6144
WARNING:root: [!] Using device: cuda:0 | Dataset size: 76126
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 1000, 'embeddingDim': 64, 'hiddenNeurons': [512, 256, 128], 'batchNormConv': False, 'batchNormFFNN': False, 'filterSizes': [2, 3, 4, 5]}
WARNING:root: [!] Fold 1/3 | Train set size: 50750, Validation set size: 25376
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Sat Dec 24 10:01:29 2022: Train Epoch: 1 [  0  /50750 (0 %)]	Loss: 0.718324 | F1-score: 0.55 | Elapsed: 0.49s
WARNING:root: [*] Sat Dec 24 10:01:50 2022: Train Epoch: 1 [6400 /50750 (13%)]	Loss: 0.371333 | F1-score: 0.86 | Elapsed: 21.18s
WARNING:root: [*] Sat Dec 24 10:02:11 2022: Train Epoch: 1 [12800/50750 (25%)]	Loss: 0.122399 | F1-score: 0.90 | Elapsed: 21.15s
WARNING:root: [*] Sat Dec 24 10:02:32 2022: Train Epoch: 1 [19200/50750 (38%)]	Loss: 0.098457 | F1-score: 0.91 | Elapsed: 21.11s
WARNING:root: [*] Sat Dec 24 10:02:53 2022: Train Epoch: 1 [25600/50750 (50%)]	Loss: 0.189436 | F1-score: 0.92 | Elapsed: 21.12s
WARNING:root: [*] Sat Dec 24 10:03:14 2022: Train Epoch: 1 [32000/50750 (63%)]	Loss: 0.055974 | F1-score: 0.93 | Elapsed: 21.13s
WARNING:root: [*] Sat Dec 24 10:03:36 2022: Train Epoch: 1 [38400/50750 (76%)]	Loss: 0.072975 | F1-score: 0.94 | Elapsed: 21.14s
WARNING:root: [*] Sat Dec 24 10:03:57 2022: Train Epoch: 1 [44800/50750 (88%)]	Loss: 0.122915 | F1-score: 0.94 | Elapsed: 21.15s
WARNING:root: [*] Sat Dec 24 10:04:16 2022:    1    | Tr.loss: 0.190505 | Tr.F1.:   0.94    |  167.94  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Sat Dec 24 10:04:16 2022: Train Epoch: 2 [  0  /50750 (0 %)]	Loss: 0.106818 | F1-score: 0.97 | Elapsed: 0.21s
WARNING:root: [*] Sat Dec 24 10:04:37 2022: Train Epoch: 2 [6400 /50750 (13%)]	Loss: 0.096717 | F1-score: 0.97 | Elapsed: 21.16s
WARNING:root: [*] Sat Dec 24 10:04:59 2022: Train Epoch: 2 [12800/50750 (25%)]	Loss: 0.119486 | F1-score: 0.97 | Elapsed: 21.17s
WARNING:root: [*] Sat Dec 24 10:05:20 2022: Train Epoch: 2 [19200/50750 (38%)]	Loss: 0.129112 | F1-score: 0.97 | Elapsed: 21.16s
WARNING:root: [*] Sat Dec 24 10:05:41 2022: Train Epoch: 2 [25600/50750 (50%)]	Loss: 0.193701 | F1-score: 0.97 | Elapsed: 21.18s
WARNING:root: [*] Sat Dec 24 10:06:02 2022: Train Epoch: 2 [32000/50750 (63%)]	Loss: 0.150184 | F1-score: 0.97 | Elapsed: 21.15s
WARNING:root: [*] Sat Dec 24 10:06:23 2022: Train Epoch: 2 [38400/50750 (76%)]	Loss: 0.155803 | F1-score: 0.97 | Elapsed: 21.16s
WARNING:root: [*] Sat Dec 24 10:06:44 2022: Train Epoch: 2 [44800/50750 (88%)]	Loss: 0.084387 | F1-score: 0.97 | Elapsed: 21.16s
WARNING:root: [*] Sat Dec 24 10:07:04 2022:    2    | Tr.loss: 0.103455 | Tr.F1.:   0.97    |  167.80  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Sat Dec 24 10:07:04 2022: Train Epoch: 3 [  0  /50750 (0 %)]	Loss: 0.058633 | F1-score: 0.98 | Elapsed: 0.21s
WARNING:root: [*] Sat Dec 24 10:07:25 2022: Train Epoch: 3 [6400 /50750 (13%)]	Loss: 0.070871 | F1-score: 0.98 | Elapsed: 21.18s
WARNING:root: [*] Sat Dec 24 10:07:46 2022: Train Epoch: 3 [12800/50750 (25%)]	Loss: 0.023809 | F1-score: 0.98 | Elapsed: 21.15s
WARNING:root: [*] Sat Dec 24 10:08:08 2022: Train Epoch: 3 [19200/50750 (38%)]	Loss: 0.023952 | F1-score: 0.97 | Elapsed: 21.15s
WARNING:root: [*] Sat Dec 24 10:08:29 2022: Train Epoch: 3 [25600/50750 (50%)]	Loss: 0.140139 | F1-score: 0.98 | Elapsed: 21.18s
WARNING:root: [*] Sat Dec 24 10:08:50 2022: Train Epoch: 3 [32000/50750 (63%)]	Loss: 0.081859 | F1-score: 0.97 | Elapsed: 21.15s
WARNING:root: [*] Sat Dec 24 10:09:11 2022: Train Epoch: 3 [38400/50750 (76%)]	Loss: 0.018362 | F1-score: 0.97 | Elapsed: 21.16s
WARNING:root: [*] Sat Dec 24 10:09:32 2022: Train Epoch: 3 [44800/50750 (88%)]	Loss: 0.070892 | F1-score: 0.97 | Elapsed: 21.17s
WARNING:root: [*] Sat Dec 24 10:09:52 2022:    3    | Tr.loss: 0.086373 | Tr.F1.:   0.97    |  167.80  s
WARNING:root:
        [!] Sat Dec 24 10:09:52 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671872992-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671872992-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671872992-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671872992-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Sat Dec 24 10:10:18 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.742195 | F1-score: 0.21 | Elapsed: 0.25s
WARNING:root: [*] Sat Dec 24 10:10:39 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.290628 | F1-score: 0.86 | Elapsed: 21.16s
WARNING:root: [*] Sat Dec 24 10:11:00 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.147652 | F1-score: 0.90 | Elapsed: 21.18s
WARNING:root: [*] Sat Dec 24 10:11:22 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.063192 | F1-score: 0.91 | Elapsed: 21.15s
WARNING:root: [*] Sat Dec 24 10:11:43 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.128868 | F1-score: 0.92 | Elapsed: 21.17s
WARNING:root: [*] Sat Dec 24 10:12:04 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.088383 | F1-score: 0.93 | Elapsed: 21.17s
WARNING:root: [*] Sat Dec 24 10:12:25 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.221390 | F1-score: 0.94 | Elapsed: 21.17s
WARNING:root: [*] Sat Dec 24 10:12:46 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.078861 | F1-score: 0.94 | Elapsed: 21.16s
WARNING:root: [*] Sat Dec 24 10:13:06 2022:    1    | Tr.loss: 0.192631 | Tr.F1.:   0.94    |  167.88  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Sat Dec 24 10:13:06 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.185488 | F1-score: 0.93 | Elapsed: 0.23s
WARNING:root: [*] Sat Dec 24 10:13:27 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.159750 | F1-score: 0.96 | Elapsed: 21.19s
WARNING:root: [*] Sat Dec 24 10:13:48 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.087192 | F1-score: 0.97 | Elapsed: 21.18s
WARNING:root: [*] Sat Dec 24 10:14:10 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.036171 | F1-score: 0.97 | Elapsed: 21.18s
WARNING:root: [*] Sat Dec 24 10:14:31 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.056078 | F1-score: 0.97 | Elapsed: 21.19s
WARNING:root: [*] Sat Dec 24 10:14:52 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.088227 | F1-score: 0.97 | Elapsed: 21.18s
WARNING:root: [*] Sat Dec 24 10:15:13 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.109003 | F1-score: 0.97 | Elapsed: 21.20s
WARNING:root: [*] Sat Dec 24 10:15:34 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.066107 | F1-score: 0.97 | Elapsed: 21.18s
WARNING:root: [*] Sat Dec 24 10:15:54 2022:    2    | Tr.loss: 0.106325 | Tr.F1.:   0.97    |  168.02  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Sat Dec 24 10:15:54 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.108676 | F1-score: 0.95 | Elapsed: 0.21s
WARNING:root: [*] Sat Dec 24 10:16:15 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.079050 | F1-score: 0.97 | Elapsed: 21.18s
WARNING:root: [*] Sat Dec 24 10:16:36 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.090994 | F1-score: 0.97 | Elapsed: 21.17s
WARNING:root: [*] Sat Dec 24 10:16:58 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.050944 | F1-score: 0.97 | Elapsed: 21.20s
WARNING:root: [*] Sat Dec 24 10:17:19 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.028628 | F1-score: 0.97 | Elapsed: 21.20s
WARNING:root: [*] Sat Dec 24 10:17:40 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.087424 | F1-score: 0.97 | Elapsed: 21.19s
WARNING:root: [*] Sat Dec 24 10:18:01 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.010443 | F1-score: 0.97 | Elapsed: 21.21s
WARNING:root: [*] Sat Dec 24 10:18:22 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.104906 | F1-score: 0.97 | Elapsed: 21.19s
WARNING:root: [*] Sat Dec 24 10:18:42 2022:    3    | Tr.loss: 0.091334 | Tr.F1.:   0.97    |  168.06  s
WARNING:root:
        [!] Sat Dec 24 10:18:42 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671873522-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671873522-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671873522-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671873522-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Sat Dec 24 10:19:08 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.676103 | F1-score: 0.69 | Elapsed: 0.24s
WARNING:root: [*] Sat Dec 24 10:19:29 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.297967 | F1-score: 0.87 | Elapsed: 21.20s
WARNING:root: [*] Sat Dec 24 10:19:51 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.239700 | F1-score: 0.90 | Elapsed: 21.19s
WARNING:root: [*] Sat Dec 24 10:20:12 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.129473 | F1-score: 0.92 | Elapsed: 21.19s
WARNING:root: [*] Sat Dec 24 10:20:33 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.187224 | F1-score: 0.93 | Elapsed: 21.18s
WARNING:root: [*] Sat Dec 24 10:20:54 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.119862 | F1-score: 0.93 | Elapsed: 21.18s
WARNING:root: [*] Sat Dec 24 10:21:15 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.037594 | F1-score: 0.94 | Elapsed: 21.20s
WARNING:root: [*] Sat Dec 24 10:21:37 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.119269 | F1-score: 0.94 | Elapsed: 21.21s
WARNING:root: [*] Sat Dec 24 10:21:56 2022:    1    | Tr.loss: 0.186678 | Tr.F1.:   0.94    |  168.10  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Sat Dec 24 10:21:56 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.075047 | F1-score: 0.99 | Elapsed: 0.22s
WARNING:root: [*] Sat Dec 24 10:22:18 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.121284 | F1-score: 0.96 | Elapsed: 21.21s
WARNING:root: [*] Sat Dec 24 10:22:39 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.128736 | F1-score: 0.97 | Elapsed: 21.18s
WARNING:root: [*] Sat Dec 24 10:23:00 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.087273 | F1-score: 0.97 | Elapsed: 21.20s
WARNING:root: [*] Sat Dec 24 10:23:21 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.087098 | F1-score: 0.97 | Elapsed: 21.20s
WARNING:root: [*] Sat Dec 24 10:23:42 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.067658 | F1-score: 0.97 | Elapsed: 21.20s
WARNING:root: [*] Sat Dec 24 10:24:04 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.105073 | F1-score: 0.97 | Elapsed: 21.21s
WARNING:root: [*] Sat Dec 24 10:24:25 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.069166 | F1-score: 0.97 | Elapsed: 21.21s
WARNING:root: [*] Sat Dec 24 10:24:44 2022:    2    | Tr.loss: 0.102408 | Tr.F1.:   0.97    |  168.15  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Sat Dec 24 10:24:44 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.018308 | F1-score: 1.00 | Elapsed: 0.23s
WARNING:root: [*] Sat Dec 24 10:25:06 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.093334 | F1-score: 0.97 | Elapsed: 21.20s
WARNING:root: [*] Sat Dec 24 10:25:27 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.074114 | F1-score: 0.97 | Elapsed: 21.21s
WARNING:root: [*] Sat Dec 24 10:25:48 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.045062 | F1-score: 0.97 | Elapsed: 21.20s
WARNING:root: [*] Sat Dec 24 10:26:09 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.193447 | F1-score: 0.97 | Elapsed: 21.23s
WARNING:root: [*] Sat Dec 24 10:26:31 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.040148 | F1-score: 0.97 | Elapsed: 21.20s
WARNING:root: [*] Sat Dec 24 10:26:52 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.064652 | F1-score: 0.97 | Elapsed: 21.24s
WARNING:root: [*] Sat Dec 24 10:27:13 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.114394 | F1-score: 0.97 | Elapsed: 21.21s
WARNING:root: [*] Sat Dec 24 10:27:32 2022:    3    | Tr.loss: 0.085699 | Tr.F1.:   0.97    |  168.24  s
WARNING:root:
        [!] Sat Dec 24 10:27:32 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671874052-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671874052-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671874052-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671874052-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\metrics_trainSize_76126_ep_3_cv_3_maxLen_6144_vocabSize_1000_embeddingDim_64_hiddenNeurons_512_256_128_batchNormConv_False_batchNormFFNN_False_filterSizes_2_3_4_5.json
WARNING:root: [!] Average epoch time: 168.00s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.5182 -- F1: 0.6810
	FPR:  0.001 -- TPR: 0.8202 -- F1: 0.8986
	FPR:   0.01 -- TPR: 0.9477 -- F1: 0.9708
	FPR:    0.1 -- TPR: 0.9888 -- F1: 0.9710

WARNING:root: [!] Skipping maxLen_1024_vocabSize_15000 as it already exists
WARNING:root: [!] Skipping maxLen_2048_vocabSize_15000 as it already exists
WARNING:root: [!] Skipping maxLen_4096_vocabSize_15000 as it already exists
WARNING:root: [!] Skipping maxLen_512_vocabSize_15000 as it already exists
WARNING:root: [!] Running Cross Validation with vocabSize: 15000 | maxLen: 6144
WARNING:root: [!] Using device: cuda:0 | Dataset size: 76126
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 15000, 'embeddingDim': 64, 'hiddenNeurons': [512, 256, 128], 'batchNormConv': False, 'batchNormFFNN': False, 'filterSizes': [2, 3, 4, 5]}
WARNING:root: [!] Fold 1/3 | Train set size: 50750, Validation set size: 25376
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Sat Dec 24 10:28:33 2022: Train Epoch: 1 [  0  /50750 (0 %)]	Loss: 0.745538 | F1-score: 0.31 | Elapsed: 0.46s
WARNING:root: [*] Sat Dec 24 10:28:54 2022: Train Epoch: 1 [6400 /50750 (13%)]	Loss: 0.189989 | F1-score: 0.87 | Elapsed: 21.25s
WARNING:root: [*] Sat Dec 24 10:29:16 2022: Train Epoch: 1 [12800/50750 (25%)]	Loss: 0.204791 | F1-score: 0.92 | Elapsed: 22.21s
WARNING:root: [*] Sat Dec 24 10:29:37 2022: Train Epoch: 1 [19200/50750 (38%)]	Loss: 0.101231 | F1-score: 0.93 | Elapsed: 21.28s
WARNING:root: [*] Sat Dec 24 10:29:59 2022: Train Epoch: 1 [25600/50750 (50%)]	Loss: 0.119641 | F1-score: 0.94 | Elapsed: 21.24s
WARNING:root: [*] Sat Dec 24 10:30:20 2022: Train Epoch: 1 [32000/50750 (63%)]	Loss: 0.331827 | F1-score: 0.95 | Elapsed: 21.26s
WARNING:root: [*] Sat Dec 24 10:30:41 2022: Train Epoch: 1 [38400/50750 (76%)]	Loss: 0.241088 | F1-score: 0.95 | Elapsed: 21.28s
WARNING:root: [*] Sat Dec 24 10:31:02 2022: Train Epoch: 1 [44800/50750 (88%)]	Loss: 0.014710 | F1-score: 0.96 | Elapsed: 21.29s
WARNING:root: [*] Sat Dec 24 10:31:22 2022:    1    | Tr.loss: 0.137844 | Tr.F1.:   0.96    |  169.84  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Sat Dec 24 10:31:22 2022: Train Epoch: 2 [  0  /50750 (0 %)]	Loss: 0.083728 | F1-score: 0.99 | Elapsed: 0.22s
WARNING:root: [*] Sat Dec 24 10:31:44 2022: Train Epoch: 2 [6400 /50750 (13%)]	Loss: 0.090996 | F1-score: 0.99 | Elapsed: 21.29s
WARNING:root: [*] Sat Dec 24 10:32:05 2022: Train Epoch: 2 [12800/50750 (25%)]	Loss: 0.074161 | F1-score: 0.99 | Elapsed: 21.30s
WARNING:root: [*] Sat Dec 24 10:32:26 2022: Train Epoch: 2 [19200/50750 (38%)]	Loss: 0.073815 | F1-score: 0.98 | Elapsed: 21.29s
WARNING:root: [*] Sat Dec 24 10:32:47 2022: Train Epoch: 2 [25600/50750 (50%)]	Loss: 0.033157 | F1-score: 0.98 | Elapsed: 21.30s
WARNING:root: [*] Sat Dec 24 10:33:09 2022: Train Epoch: 2 [32000/50750 (63%)]	Loss: 0.053266 | F1-score: 0.98 | Elapsed: 21.28s
WARNING:root: [*] Sat Dec 24 10:33:30 2022: Train Epoch: 2 [38400/50750 (76%)]	Loss: 0.008740 | F1-score: 0.99 | Elapsed: 21.29s
WARNING:root: [*] Sat Dec 24 10:33:51 2022: Train Epoch: 2 [44800/50750 (88%)]	Loss: 0.012126 | F1-score: 0.99 | Elapsed: 21.30s
WARNING:root: [*] Sat Dec 24 10:34:11 2022:    2    | Tr.loss: 0.059362 | Tr.F1.:   0.99    |  168.86  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Sat Dec 24 10:34:11 2022: Train Epoch: 3 [  0  /50750 (0 %)]	Loss: 0.293195 | F1-score: 0.96 | Elapsed: 0.21s
WARNING:root: [*] Sat Dec 24 10:34:32 2022: Train Epoch: 3 [6400 /50750 (13%)]	Loss: 0.067374 | F1-score: 0.99 | Elapsed: 21.30s
WARNING:root: [*] Sat Dec 24 10:34:54 2022: Train Epoch: 3 [12800/50750 (25%)]	Loss: 0.099760 | F1-score: 0.99 | Elapsed: 21.25s
WARNING:root: [*] Sat Dec 24 10:35:15 2022: Train Epoch: 3 [19200/50750 (38%)]	Loss: 0.048010 | F1-score: 0.99 | Elapsed: 21.10s
WARNING:root: [*] Sat Dec 24 10:35:36 2022: Train Epoch: 3 [25600/50750 (50%)]	Loss: 0.015138 | F1-score: 0.99 | Elapsed: 21.30s
WARNING:root: [*] Sat Dec 24 10:35:57 2022: Train Epoch: 3 [32000/50750 (63%)]	Loss: 0.054783 | F1-score: 0.99 | Elapsed: 21.33s
WARNING:root: [*] Sat Dec 24 10:36:19 2022: Train Epoch: 3 [38400/50750 (76%)]	Loss: 0.005597 | F1-score: 0.99 | Elapsed: 21.32s
WARNING:root: [*] Sat Dec 24 10:36:40 2022: Train Epoch: 3 [44800/50750 (88%)]	Loss: 0.037520 | F1-score: 0.99 | Elapsed: 21.32s
WARNING:root: [*] Sat Dec 24 10:37:00 2022:    3    | Tr.loss: 0.049456 | Tr.F1.:   0.99    |  168.76  s
WARNING:root:
        [!] Sat Dec 24 10:37:00 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671874620-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671874620-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671874620-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671874620-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Sat Dec 24 10:37:26 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.695688 | F1-score: 0.63 | Elapsed: 0.23s
WARNING:root: [*] Sat Dec 24 10:37:48 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.144391 | F1-score: 0.88 | Elapsed: 21.28s
WARNING:root: [*] Sat Dec 24 10:38:09 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.049397 | F1-score: 0.92 | Elapsed: 21.30s
WARNING:root: [*] Sat Dec 24 10:38:30 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.104687 | F1-score: 0.93 | Elapsed: 21.29s
WARNING:root: [*] Sat Dec 24 10:38:51 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.062795 | F1-score: 0.94 | Elapsed: 21.31s
WARNING:root: [*] Sat Dec 24 10:39:13 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.056657 | F1-score: 0.95 | Elapsed: 21.30s
WARNING:root: [*] Sat Dec 24 10:39:34 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.123110 | F1-score: 0.96 | Elapsed: 21.28s
WARNING:root: [*] Sat Dec 24 10:39:55 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.036654 | F1-score: 0.96 | Elapsed: 21.30s
WARNING:root: [*] Sat Dec 24 10:40:15 2022:    1    | Tr.loss: 0.137949 | Tr.F1.:   0.96    |  168.94  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Sat Dec 24 10:40:15 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.139537 | F1-score: 0.95 | Elapsed: 0.25s
WARNING:root: [*] Sat Dec 24 10:40:36 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.054000 | F1-score: 0.98 | Elapsed: 21.20s
WARNING:root: [*] Sat Dec 24 10:40:58 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.045303 | F1-score: 0.98 | Elapsed: 21.36s
WARNING:root: [*] Sat Dec 24 10:41:19 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.039217 | F1-score: 0.98 | Elapsed: 21.37s
WARNING:root: [*] Sat Dec 24 10:41:41 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.047010 | F1-score: 0.98 | Elapsed: 21.36s
WARNING:root: [*] Sat Dec 24 10:42:02 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.055804 | F1-score: 0.98 | Elapsed: 21.35s
WARNING:root: [*] Sat Dec 24 10:42:23 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.046597 | F1-score: 0.98 | Elapsed: 21.39s
WARNING:root: [*] Sat Dec 24 10:42:45 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.060907 | F1-score: 0.98 | Elapsed: 21.40s
WARNING:root: [*] Sat Dec 24 10:43:04 2022:    2    | Tr.loss: 0.065509 | Tr.F1.:   0.98    |  169.36  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Sat Dec 24 10:43:05 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.121843 | F1-score: 0.98 | Elapsed: 0.21s
WARNING:root: [*] Sat Dec 24 10:43:26 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.094587 | F1-score: 0.99 | Elapsed: 21.37s
WARNING:root: [*] Sat Dec 24 10:43:47 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.014540 | F1-score: 0.99 | Elapsed: 21.37s
WARNING:root: [*] Sat Dec 24 10:44:09 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.010443 | F1-score: 0.99 | Elapsed: 21.34s
WARNING:root: [*] Sat Dec 24 10:44:30 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.039129 | F1-score: 0.99 | Elapsed: 21.36s
WARNING:root: [*] Sat Dec 24 10:44:51 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.026852 | F1-score: 0.99 | Elapsed: 21.34s
WARNING:root: [*] Sat Dec 24 10:45:13 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.010855 | F1-score: 0.99 | Elapsed: 21.35s
WARNING:root: [*] Sat Dec 24 10:45:34 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.029130 | F1-score: 0.99 | Elapsed: 21.37s
WARNING:root: [*] Sat Dec 24 10:45:54 2022:    3    | Tr.loss: 0.051616 | Tr.F1.:   0.99    |  169.37  s
WARNING:root:
        [!] Sat Dec 24 10:45:54 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671875154-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671875154-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671875154-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671875154-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Sat Dec 24 10:46:21 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.696529 | F1-score: 0.51 | Elapsed: 0.24s
WARNING:root: [*] Sat Dec 24 10:46:42 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.098760 | F1-score: 0.87 | Elapsed: 21.38s
WARNING:root: [*] Sat Dec 24 10:47:03 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.133154 | F1-score: 0.91 | Elapsed: 21.36s
WARNING:root: [*] Sat Dec 24 10:47:25 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.104049 | F1-score: 0.93 | Elapsed: 21.35s
WARNING:root: [*] Sat Dec 24 10:47:46 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.085888 | F1-score: 0.94 | Elapsed: 21.35s
WARNING:root: [*] Sat Dec 24 10:48:07 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.138397 | F1-score: 0.95 | Elapsed: 21.35s
WARNING:root: [*] Sat Dec 24 10:48:29 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.114298 | F1-score: 0.95 | Elapsed: 21.34s
WARNING:root: [*] Sat Dec 24 10:48:50 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.047782 | F1-score: 0.96 | Elapsed: 21.36s
WARNING:root: [*] Sat Dec 24 10:49:10 2022:    1    | Tr.loss: 0.139577 | Tr.F1.:   0.96    |  169.39  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Sat Dec 24 10:49:10 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.105960 | F1-score: 0.96 | Elapsed: 0.22s
WARNING:root: [*] Sat Dec 24 10:49:31 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.009132 | F1-score: 0.98 | Elapsed: 21.35s
WARNING:root: [*] Sat Dec 24 10:49:53 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.009359 | F1-score: 0.99 | Elapsed: 21.37s
WARNING:root: [*] Sat Dec 24 10:50:14 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.061319 | F1-score: 0.98 | Elapsed: 21.36s
WARNING:root: [*] Sat Dec 24 10:50:35 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.008174 | F1-score: 0.98 | Elapsed: 21.37s
WARNING:root: [*] Sat Dec 24 10:50:57 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.020570 | F1-score: 0.99 | Elapsed: 21.41s
WARNING:root: [*] Sat Dec 24 10:51:18 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.018105 | F1-score: 0.98 | Elapsed: 21.35s
WARNING:root: [*] Sat Dec 24 10:51:39 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.036426 | F1-score: 0.99 | Elapsed: 21.16s
WARNING:root: [*] Sat Dec 24 10:51:59 2022:    2    | Tr.loss: 0.060459 | Tr.F1.:   0.99    |  169.23  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Sat Dec 24 10:51:59 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.008656 | F1-score: 1.00 | Elapsed: 0.22s
WARNING:root: [*] Sat Dec 24 10:52:21 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.022458 | F1-score: 0.99 | Elapsed: 21.39s
WARNING:root: [*] Sat Dec 24 10:52:42 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.011575 | F1-score: 0.99 | Elapsed: 21.38s
WARNING:root: [*] Sat Dec 24 10:53:03 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.022806 | F1-score: 0.99 | Elapsed: 21.37s
WARNING:root: [*] Sat Dec 24 10:53:25 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.036027 | F1-score: 0.99 | Elapsed: 21.35s
WARNING:root: [*] Sat Dec 24 10:53:46 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.040660 | F1-score: 0.99 | Elapsed: 21.35s
WARNING:root: [*] Sat Dec 24 10:54:07 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.005029 | F1-score: 0.99 | Elapsed: 21.38s
WARNING:root: [*] Sat Dec 24 10:54:29 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.015823 | F1-score: 0.99 | Elapsed: 21.39s
WARNING:root: [*] Sat Dec 24 10:54:48 2022:    3    | Tr.loss: 0.050064 | Tr.F1.:   0.99    |  169.50  s
WARNING:root:
        [!] Sat Dec 24 10:54:48 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671875688-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671875688-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671875688-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671875688-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\metrics_trainSize_76126_ep_3_cv_3_maxLen_6144_vocabSize_15000_embeddingDim_64_hiddenNeurons_512_256_128_batchNormConv_False_batchNormFFNN_False_filterSizes_2_3_4_5.json
WARNING:root: [!] Average epoch time: 169.25s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.5423 -- F1: 0.6912
	FPR:  0.001 -- TPR: 0.9351 -- F1: 0.9662
	FPR:   0.01 -- TPR: 0.9781 -- F1: 0.9866
	FPR:    0.1 -- TPR: 0.9964 -- F1: 0.9748

WARNING:root: [!] Skipping maxLen_1024_vocabSize_1500 as it already exists
WARNING:root: [!] Skipping maxLen_2048_vocabSize_1500 as it already exists
WARNING:root: [!] Skipping maxLen_4096_vocabSize_1500 as it already exists
WARNING:root: [!] Skipping maxLen_512_vocabSize_1500 as it already exists
WARNING:root: [!] Running Cross Validation with vocabSize: 1500 | maxLen: 6144
WARNING:root: [!] Using device: cuda:0 | Dataset size: 76126
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 1500, 'embeddingDim': 64, 'hiddenNeurons': [512, 256, 128], 'batchNormConv': False, 'batchNormFFNN': False, 'filterSizes': [2, 3, 4, 5]}
WARNING:root: [!] Fold 1/3 | Train set size: 50750, Validation set size: 25376
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Sat Dec 24 10:55:49 2022: Train Epoch: 1 [  0  /50750 (0 %)]	Loss: 0.692165 | F1-score: 0.58 | Elapsed: 0.44s
WARNING:root: [*] Sat Dec 24 10:56:10 2022: Train Epoch: 1 [6400 /50750 (13%)]	Loss: 0.297804 | F1-score: 0.87 | Elapsed: 21.07s
WARNING:root: [*] Sat Dec 24 10:56:31 2022: Train Epoch: 1 [12800/50750 (25%)]	Loss: 0.229970 | F1-score: 0.90 | Elapsed: 21.12s
WARNING:root: [*] Sat Dec 24 10:56:53 2022: Train Epoch: 1 [19200/50750 (38%)]	Loss: 0.119093 | F1-score: 0.92 | Elapsed: 21.16s
WARNING:root: [*] Sat Dec 24 10:57:14 2022: Train Epoch: 1 [25600/50750 (50%)]	Loss: 0.143936 | F1-score: 0.93 | Elapsed: 21.21s
WARNING:root: [*] Sat Dec 24 10:57:35 2022: Train Epoch: 1 [32000/50750 (63%)]	Loss: 0.266279 | F1-score: 0.94 | Elapsed: 21.21s
WARNING:root: [*] Sat Dec 24 10:57:56 2022: Train Epoch: 1 [38400/50750 (76%)]	Loss: 0.150814 | F1-score: 0.94 | Elapsed: 21.25s
WARNING:root: [*] Sat Dec 24 10:58:17 2022: Train Epoch: 1 [44800/50750 (88%)]	Loss: 0.078421 | F1-score: 0.94 | Elapsed: 21.23s
WARNING:root: [*] Sat Dec 24 10:58:37 2022:    1    | Tr.loss: 0.184419 | Tr.F1.:   0.95    |  168.27  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Sat Dec 24 10:58:37 2022: Train Epoch: 2 [  0  /50750 (0 %)]	Loss: 0.222815 | F1-score: 0.93 | Elapsed: 0.22s
WARNING:root: [*] Sat Dec 24 10:58:58 2022: Train Epoch: 2 [6400 /50750 (13%)]	Loss: 0.111223 | F1-score: 0.97 | Elapsed: 21.24s
WARNING:root: [*] Sat Dec 24 10:59:20 2022: Train Epoch: 2 [12800/50750 (25%)]	Loss: 0.170990 | F1-score: 0.97 | Elapsed: 21.26s
WARNING:root: [*] Sat Dec 24 10:59:41 2022: Train Epoch: 2 [19200/50750 (38%)]	Loss: 0.066089 | F1-score: 0.97 | Elapsed: 21.25s
WARNING:root: [*] Sat Dec 24 11:00:02 2022: Train Epoch: 2 [25600/50750 (50%)]	Loss: 0.210433 | F1-score: 0.97 | Elapsed: 21.27s
WARNING:root: [*] Sat Dec 24 11:00:23 2022: Train Epoch: 2 [32000/50750 (63%)]	Loss: 0.089627 | F1-score: 0.97 | Elapsed: 21.26s
WARNING:root: [*] Sat Dec 24 11:00:45 2022: Train Epoch: 2 [38400/50750 (76%)]	Loss: 0.057042 | F1-score: 0.97 | Elapsed: 21.29s
WARNING:root: [*] Sat Dec 24 11:01:06 2022: Train Epoch: 2 [44800/50750 (88%)]	Loss: 0.170369 | F1-score: 0.97 | Elapsed: 21.28s
WARNING:root: [*] Sat Dec 24 11:01:26 2022:    2    | Tr.loss: 0.099891 | Tr.F1.:   0.97    |  168.63  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Sat Dec 24 11:01:26 2022: Train Epoch: 3 [  0  /50750 (0 %)]	Loss: 0.071178 | F1-score: 0.96 | Elapsed: 0.23s
WARNING:root: [*] Sat Dec 24 11:01:47 2022: Train Epoch: 3 [6400 /50750 (13%)]	Loss: 0.122792 | F1-score: 0.97 | Elapsed: 21.25s
WARNING:root: [*] Sat Dec 24 11:02:08 2022: Train Epoch: 3 [12800/50750 (25%)]	Loss: 0.103504 | F1-score: 0.97 | Elapsed: 21.15s
WARNING:root: [*] Sat Dec 24 11:02:30 2022: Train Epoch: 3 [19200/50750 (38%)]	Loss: 0.075659 | F1-score: 0.97 | Elapsed: 21.31s
WARNING:root: [*] Sat Dec 24 11:02:51 2022: Train Epoch: 3 [25600/50750 (50%)]	Loss: 0.059161 | F1-score: 0.97 | Elapsed: 21.29s
WARNING:root: [*] Sat Dec 24 11:03:12 2022: Train Epoch: 3 [32000/50750 (63%)]	Loss: 0.062993 | F1-score: 0.97 | Elapsed: 21.32s
WARNING:root: [*] Sat Dec 24 11:03:33 2022: Train Epoch: 3 [38400/50750 (76%)]	Loss: 0.119611 | F1-score: 0.97 | Elapsed: 21.32s
WARNING:root: [*] Sat Dec 24 11:03:55 2022: Train Epoch: 3 [44800/50750 (88%)]	Loss: 0.114516 | F1-score: 0.97 | Elapsed: 21.31s
WARNING:root: [*] Sat Dec 24 11:04:14 2022:    3    | Tr.loss: 0.084737 | Tr.F1.:   0.98    |  168.77  s
WARNING:root:
        [!] Sat Dec 24 11:04:14 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671876254-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671876254-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671876254-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671876254-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Sat Dec 24 11:04:41 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.683465 | F1-score: 0.65 | Elapsed: 0.25s
WARNING:root: [*] Sat Dec 24 11:05:02 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.186464 | F1-score: 0.87 | Elapsed: 21.28s
WARNING:root: [*] Sat Dec 24 11:05:24 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.088804 | F1-score: 0.90 | Elapsed: 21.31s
WARNING:root: [*] Sat Dec 24 11:05:45 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.099895 | F1-score: 0.92 | Elapsed: 21.30s
WARNING:root: [*] Sat Dec 24 11:06:06 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.209954 | F1-score: 0.93 | Elapsed: 21.32s
WARNING:root: [*] Sat Dec 24 11:06:28 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.037937 | F1-score: 0.93 | Elapsed: 21.29s
WARNING:root: [*] Sat Dec 24 11:06:49 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.213259 | F1-score: 0.94 | Elapsed: 21.29s
WARNING:root: [*] Sat Dec 24 11:07:10 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.114787 | F1-score: 0.94 | Elapsed: 21.28s
WARNING:root: [*] Sat Dec 24 11:07:30 2022:    1    | Tr.loss: 0.187997 | Tr.F1.:   0.94    |  168.95  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Sat Dec 24 11:07:30 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.027768 | F1-score: 1.00 | Elapsed: 0.22s
WARNING:root: [*] Sat Dec 24 11:07:51 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.086839 | F1-score: 0.97 | Elapsed: 21.32s
WARNING:root: [*] Sat Dec 24 11:08:13 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.216582 | F1-score: 0.97 | Elapsed: 21.34s
WARNING:root: [*] Sat Dec 24 11:08:34 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.068408 | F1-score: 0.97 | Elapsed: 21.33s
WARNING:root: [*] Sat Dec 24 11:08:55 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.239304 | F1-score: 0.97 | Elapsed: 21.30s
WARNING:root: [*] Sat Dec 24 11:09:17 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.105938 | F1-score: 0.97 | Elapsed: 21.32s
WARNING:root: [*] Sat Dec 24 11:09:38 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.145071 | F1-score: 0.97 | Elapsed: 21.34s
WARNING:root: [*] Sat Dec 24 11:09:59 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.081578 | F1-score: 0.97 | Elapsed: 21.36s
WARNING:root: [*] Sat Dec 24 11:10:19 2022:    2    | Tr.loss: 0.102803 | Tr.F1.:   0.97    |  169.15  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Sat Dec 24 11:10:19 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.061089 | F1-score: 0.99 | Elapsed: 0.22s
WARNING:root: [*] Sat Dec 24 11:10:41 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.088185 | F1-score: 0.97 | Elapsed: 21.31s
WARNING:root: [*] Sat Dec 24 11:11:02 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.062649 | F1-score: 0.97 | Elapsed: 21.33s
WARNING:root: [*] Sat Dec 24 11:11:23 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.041452 | F1-score: 0.98 | Elapsed: 21.32s
WARNING:root: [*] Sat Dec 24 11:11:44 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.189384 | F1-score: 0.97 | Elapsed: 21.33s
WARNING:root: [*] Sat Dec 24 11:12:06 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.019594 | F1-score: 0.97 | Elapsed: 21.35s
WARNING:root: [*] Sat Dec 24 11:12:27 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.110803 | F1-score: 0.97 | Elapsed: 21.34s
WARNING:root: [*] Sat Dec 24 11:12:49 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.144164 | F1-score: 0.97 | Elapsed: 21.32s
WARNING:root: [*] Sat Dec 24 11:13:08 2022:    3    | Tr.loss: 0.087672 | Tr.F1.:   0.97    |  169.12  s
WARNING:root:
        [!] Sat Dec 24 11:13:08 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671876788-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671876788-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671876788-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671876788-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Sat Dec 24 11:13:35 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.718866 | F1-score: 0.23 | Elapsed: 0.22s
WARNING:root: [*] Sat Dec 24 11:13:56 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.304396 | F1-score: 0.87 | Elapsed: 21.30s
WARNING:root: [*] Sat Dec 24 11:14:17 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.200000 | F1-score: 0.90 | Elapsed: 21.32s
WARNING:root: [*] Sat Dec 24 11:14:39 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.182132 | F1-score: 0.92 | Elapsed: 21.31s
WARNING:root: [*] Sat Dec 24 11:15:00 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.075194 | F1-score: 0.93 | Elapsed: 21.30s
WARNING:root: [*] Sat Dec 24 11:15:21 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.050954 | F1-score: 0.93 | Elapsed: 21.30s
WARNING:root: [*] Sat Dec 24 11:15:43 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.125117 | F1-score: 0.94 | Elapsed: 21.31s
WARNING:root: [*] Sat Dec 24 11:16:04 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.052632 | F1-score: 0.94 | Elapsed: 21.29s
WARNING:root: [*] Sat Dec 24 11:16:24 2022:    1    | Tr.loss: 0.183831 | Tr.F1.:   0.95    |  168.94  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Sat Dec 24 11:16:24 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.170030 | F1-score: 0.94 | Elapsed: 0.22s
WARNING:root: [*] Sat Dec 24 11:16:45 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.226975 | F1-score: 0.96 | Elapsed: 21.31s
WARNING:root: [*] Sat Dec 24 11:17:06 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.061237 | F1-score: 0.97 | Elapsed: 21.30s
WARNING:root: [*] Sat Dec 24 11:17:28 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.078281 | F1-score: 0.97 | Elapsed: 21.30s
WARNING:root: [*] Sat Dec 24 11:17:49 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.125171 | F1-score: 0.97 | Elapsed: 21.15s
WARNING:root: [*] Sat Dec 24 11:18:10 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.047826 | F1-score: 0.97 | Elapsed: 21.13s
WARNING:root: [*] Sat Dec 24 11:18:31 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.117103 | F1-score: 0.97 | Elapsed: 21.37s
WARNING:root: [*] Sat Dec 24 11:18:53 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.098257 | F1-score: 0.97 | Elapsed: 21.36s
WARNING:root: [*] Sat Dec 24 11:19:12 2022:    2    | Tr.loss: 0.100157 | Tr.F1.:   0.97    |  168.79  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Sat Dec 24 11:19:13 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.113942 | F1-score: 0.99 | Elapsed: 0.21s
WARNING:root: [*] Sat Dec 24 11:19:34 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.066616 | F1-score: 0.97 | Elapsed: 21.34s
WARNING:root: [*] Sat Dec 24 11:19:55 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.083895 | F1-score: 0.98 | Elapsed: 21.33s
WARNING:root: [*] Sat Dec 24 11:20:17 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.060629 | F1-score: 0.98 | Elapsed: 21.32s
WARNING:root: [*] Sat Dec 24 11:20:38 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.137529 | F1-score: 0.97 | Elapsed: 21.32s
WARNING:root: [*] Sat Dec 24 11:20:59 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.142076 | F1-score: 0.98 | Elapsed: 21.34s
WARNING:root: [*] Sat Dec 24 11:21:20 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.125330 | F1-score: 0.98 | Elapsed: 21.32s
WARNING:root: [*] Sat Dec 24 11:21:42 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.060890 | F1-score: 0.98 | Elapsed: 21.29s
WARNING:root: [*] Sat Dec 24 11:22:01 2022:    3    | Tr.loss: 0.083943 | Tr.F1.:   0.98    |  169.07  s
WARNING:root:
        [!] Sat Dec 24 11:22:01 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671877321-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671877321-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671877321-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671877321-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\metrics_trainSize_76126_ep_3_cv_3_maxLen_6144_vocabSize_1500_embeddingDim_64_hiddenNeurons_512_256_128_batchNormConv_False_batchNormFFNN_False_filterSizes_2_3_4_5.json
WARNING:root: [!] Average epoch time: 168.86s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.5659 -- F1: 0.7213
	FPR:  0.001 -- TPR: 0.8841 -- F1: 0.9381
	FPR:   0.01 -- TPR: 0.9421 -- F1: 0.9679
	FPR:    0.1 -- TPR: 0.9925 -- F1: 0.9729

WARNING:root: [!] Running Cross Validation with vocabSize: 20000 | maxLen: 1024
WARNING:root: [!] Using device: cuda:0 | Dataset size: 76126
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 20000, 'embeddingDim': 64, 'hiddenNeurons': [512, 256, 128], 'batchNormConv': False, 'batchNormFFNN': False, 'filterSizes': [2, 3, 4, 5]}
WARNING:root: [!] Fold 1/3 | Train set size: 50750, Validation set size: 25376
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Sat Dec 24 11:22:57 2022: Train Epoch: 1 [  0  /50750 (0 %)]	Loss: 0.695829 | F1-score: 0.59 | Elapsed: 0.29s
WARNING:root: [*] Sat Dec 24 11:23:01 2022: Train Epoch: 1 [6400 /50750 (13%)]	Loss: 0.281535 | F1-score: 0.88 | Elapsed: 3.82s
WARNING:root: [*] Sat Dec 24 11:23:05 2022: Train Epoch: 1 [12800/50750 (25%)]	Loss: 0.099429 | F1-score: 0.92 | Elapsed: 3.80s
WARNING:root: [*] Sat Dec 24 11:23:09 2022: Train Epoch: 1 [19200/50750 (38%)]	Loss: 0.140542 | F1-score: 0.94 | Elapsed: 3.79s
WARNING:root: [*] Sat Dec 24 11:23:13 2022: Train Epoch: 1 [25600/50750 (50%)]	Loss: 0.113299 | F1-score: 0.94 | Elapsed: 3.83s
WARNING:root: [*] Sat Dec 24 11:23:17 2022: Train Epoch: 1 [32000/50750 (63%)]	Loss: 0.111803 | F1-score: 0.95 | Elapsed: 3.83s
WARNING:root: [*] Sat Dec 24 11:23:20 2022: Train Epoch: 1 [38400/50750 (76%)]	Loss: 0.106656 | F1-score: 0.96 | Elapsed: 3.85s
WARNING:root: [*] Sat Dec 24 11:23:24 2022: Train Epoch: 1 [44800/50750 (88%)]	Loss: 0.060280 | F1-score: 0.96 | Elapsed: 3.86s
WARNING:root: [*] Sat Dec 24 11:23:28 2022:    1    | Tr.loss: 0.142300 | Tr.F1.:   0.96    |   30.65  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Sat Dec 24 11:23:28 2022: Train Epoch: 2 [  0  /50750 (0 %)]	Loss: 0.067554 | F1-score: 0.97 | Elapsed: 0.04s
WARNING:root: [*] Sat Dec 24 11:23:32 2022: Train Epoch: 2 [6400 /50750 (13%)]	Loss: 0.070050 | F1-score: 0.98 | Elapsed: 3.87s
WARNING:root: [*] Sat Dec 24 11:23:36 2022: Train Epoch: 2 [12800/50750 (25%)]	Loss: 0.040587 | F1-score: 0.98 | Elapsed: 3.87s
WARNING:root: [*] Sat Dec 24 11:23:39 2022: Train Epoch: 2 [19200/50750 (38%)]	Loss: 0.061597 | F1-score: 0.98 | Elapsed: 3.86s
WARNING:root: [*] Sat Dec 24 11:23:43 2022: Train Epoch: 2 [25600/50750 (50%)]	Loss: 0.070579 | F1-score: 0.98 | Elapsed: 3.87s
WARNING:root: [*] Sat Dec 24 11:23:47 2022: Train Epoch: 2 [32000/50750 (63%)]	Loss: 0.027739 | F1-score: 0.98 | Elapsed: 3.87s
WARNING:root: [*] Sat Dec 24 11:23:51 2022: Train Epoch: 2 [38400/50750 (76%)]	Loss: 0.029414 | F1-score: 0.98 | Elapsed: 3.88s
WARNING:root: [*] Sat Dec 24 11:23:55 2022: Train Epoch: 2 [44800/50750 (88%)]	Loss: 0.096233 | F1-score: 0.98 | Elapsed: 3.87s
WARNING:root: [*] Sat Dec 24 11:23:58 2022:    2    | Tr.loss: 0.063233 | Tr.F1.:   0.98    |   30.69  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Sat Dec 24 11:23:59 2022: Train Epoch: 3 [  0  /50750 (0 %)]	Loss: 0.007896 | F1-score: 1.00 | Elapsed: 0.05s
WARNING:root: [*] Sat Dec 24 11:24:02 2022: Train Epoch: 3 [6400 /50750 (13%)]	Loss: 0.088174 | F1-score: 0.99 | Elapsed: 3.87s
WARNING:root: [*] Sat Dec 24 11:24:06 2022: Train Epoch: 3 [12800/50750 (25%)]	Loss: 0.207910 | F1-score: 0.99 | Elapsed: 3.88s
WARNING:root: [*] Sat Dec 24 11:24:10 2022: Train Epoch: 3 [19200/50750 (38%)]	Loss: 0.080157 | F1-score: 0.99 | Elapsed: 3.88s
WARNING:root: [*] Sat Dec 24 11:24:14 2022: Train Epoch: 3 [25600/50750 (50%)]	Loss: 0.023546 | F1-score: 0.99 | Elapsed: 3.88s
WARNING:root: [*] Sat Dec 24 11:24:18 2022: Train Epoch: 3 [32000/50750 (63%)]	Loss: 0.017295 | F1-score: 0.99 | Elapsed: 3.89s
WARNING:root: [*] Sat Dec 24 11:24:22 2022: Train Epoch: 3 [38400/50750 (76%)]	Loss: 0.275100 | F1-score: 0.99 | Elapsed: 3.88s
WARNING:root: [*] Sat Dec 24 11:24:26 2022: Train Epoch: 3 [44800/50750 (88%)]	Loss: 0.021215 | F1-score: 0.99 | Elapsed: 3.88s
WARNING:root: [*] Sat Dec 24 11:24:29 2022:    3    | Tr.loss: 0.050889 | Tr.F1.:   0.99    |   30.81  s
WARNING:root:
        [!] Sat Dec 24 11:24:29 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671877469-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671877469-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671877469-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671877469-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Sat Dec 24 11:24:34 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.729146 | F1-score: 0.35 | Elapsed: 0.04s
WARNING:root: [*] Sat Dec 24 11:24:38 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.205261 | F1-score: 0.87 | Elapsed: 3.91s
WARNING:root: [*] Sat Dec 24 11:24:42 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.072977 | F1-score: 0.91 | Elapsed: 3.91s
WARNING:root: [*] Sat Dec 24 11:24:46 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.106170 | F1-score: 0.93 | Elapsed: 3.90s
WARNING:root: [*] Sat Dec 24 11:24:50 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.027745 | F1-score: 0.94 | Elapsed: 3.90s
WARNING:root: [*] Sat Dec 24 11:24:53 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.068695 | F1-score: 0.95 | Elapsed: 3.89s
WARNING:root: [*] Sat Dec 24 11:24:57 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.076337 | F1-score: 0.95 | Elapsed: 3.89s
WARNING:root: [*] Sat Dec 24 11:25:01 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.114864 | F1-score: 0.96 | Elapsed: 3.90s
WARNING:root: [*] Sat Dec 24 11:25:05 2022:    1    | Tr.loss: 0.144433 | Tr.F1.:   0.96    |   30.92  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Sat Dec 24 11:25:05 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.077543 | F1-score: 0.98 | Elapsed: 0.06s
WARNING:root: [*] Sat Dec 24 11:25:09 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.064788 | F1-score: 0.98 | Elapsed: 3.90s
WARNING:root: [*] Sat Dec 24 11:25:13 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.120991 | F1-score: 0.98 | Elapsed: 3.90s
WARNING:root: [*] Sat Dec 24 11:25:17 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.127497 | F1-score: 0.98 | Elapsed: 3.91s
WARNING:root: [*] Sat Dec 24 11:25:21 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.053772 | F1-score: 0.98 | Elapsed: 3.90s
WARNING:root: [*] Sat Dec 24 11:25:24 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.100815 | F1-score: 0.98 | Elapsed: 3.90s
WARNING:root: [*] Sat Dec 24 11:25:28 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.262339 | F1-score: 0.98 | Elapsed: 3.90s
WARNING:root: [*] Sat Dec 24 11:25:32 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.019339 | F1-score: 0.98 | Elapsed: 3.92s
WARNING:root: [*] Sat Dec 24 11:25:36 2022:    2    | Tr.loss: 0.066044 | Tr.F1.:   0.98    |   30.98  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Sat Dec 24 11:25:36 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.031952 | F1-score: 0.99 | Elapsed: 0.04s
WARNING:root: [*] Sat Dec 24 11:25:40 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.035798 | F1-score: 0.99 | Elapsed: 3.92s
WARNING:root: [*] Sat Dec 24 11:25:44 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.043299 | F1-score: 0.99 | Elapsed: 3.94s
WARNING:root: [*] Sat Dec 24 11:25:48 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.009346 | F1-score: 0.99 | Elapsed: 3.90s
WARNING:root: [*] Sat Dec 24 11:25:52 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.025132 | F1-score: 0.99 | Elapsed: 3.90s
WARNING:root: [*] Sat Dec 24 11:25:55 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.013300 | F1-score: 0.99 | Elapsed: 3.90s
WARNING:root: [*] Sat Dec 24 11:25:59 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.008510 | F1-score: 0.99 | Elapsed: 3.89s
WARNING:root: [*] Sat Dec 24 11:26:03 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.019725 | F1-score: 0.99 | Elapsed: 3.89s
WARNING:root: [*] Sat Dec 24 11:26:07 2022:    3    | Tr.loss: 0.051296 | Tr.F1.:   0.99    |   30.98  s
WARNING:root:
        [!] Sat Dec 24 11:26:07 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671877567-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671877567-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671877567-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671877567-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Sat Dec 24 11:26:12 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.721317 | F1-score: 0.27 | Elapsed: 0.05s
WARNING:root: [*] Sat Dec 24 11:26:15 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.259664 | F1-score: 0.87 | Elapsed: 3.93s
WARNING:root: [*] Sat Dec 24 11:26:19 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.139618 | F1-score: 0.91 | Elapsed: 3.90s
WARNING:root: [*] Sat Dec 24 11:26:23 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.062164 | F1-score: 0.93 | Elapsed: 3.91s
WARNING:root: [*] Sat Dec 24 11:26:27 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.017662 | F1-score: 0.94 | Elapsed: 3.91s
WARNING:root: [*] Sat Dec 24 11:26:31 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.040843 | F1-score: 0.95 | Elapsed: 3.90s
WARNING:root: [*] Sat Dec 24 11:26:35 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.108596 | F1-score: 0.95 | Elapsed: 3.91s
WARNING:root: [*] Sat Dec 24 11:26:39 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.131648 | F1-score: 0.96 | Elapsed: 3.91s
WARNING:root: [*] Sat Dec 24 11:26:42 2022:    1    | Tr.loss: 0.144469 | Tr.F1.:   0.96    |   31.00  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Sat Dec 24 11:26:43 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.064167 | F1-score: 0.98 | Elapsed: 0.06s
WARNING:root: [*] Sat Dec 24 11:26:46 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.072593 | F1-score: 0.98 | Elapsed: 3.91s
WARNING:root: [*] Sat Dec 24 11:26:50 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.127144 | F1-score: 0.98 | Elapsed: 3.90s
WARNING:root: [*] Sat Dec 24 11:26:54 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.058951 | F1-score: 0.98 | Elapsed: 3.91s
WARNING:root: [*] Sat Dec 24 11:26:58 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.032004 | F1-score: 0.98 | Elapsed: 3.90s
WARNING:root: [*] Sat Dec 24 11:27:02 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.053902 | F1-score: 0.98 | Elapsed: 3.90s
WARNING:root: [*] Sat Dec 24 11:27:06 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.038979 | F1-score: 0.98 | Elapsed: 3.91s
WARNING:root: [*] Sat Dec 24 11:27:10 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.036871 | F1-score: 0.98 | Elapsed: 3.90s
WARNING:root: [*] Sat Dec 24 11:27:13 2022:    2    | Tr.loss: 0.062735 | Tr.F1.:   0.98    |   30.99  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Sat Dec 24 11:27:14 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.129951 | F1-score: 0.97 | Elapsed: 0.05s
WARNING:root: [*] Sat Dec 24 11:27:17 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.014713 | F1-score: 0.99 | Elapsed: 3.90s
WARNING:root: [*] Sat Dec 24 11:27:21 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.023438 | F1-score: 0.99 | Elapsed: 3.90s
WARNING:root: [*] Sat Dec 24 11:27:25 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.021408 | F1-score: 0.99 | Elapsed: 3.90s
WARNING:root: [*] Sat Dec 24 11:27:29 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.014673 | F1-score: 0.99 | Elapsed: 3.90s
WARNING:root: [*] Sat Dec 24 11:27:33 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.048672 | F1-score: 0.99 | Elapsed: 3.92s
WARNING:root: [*] Sat Dec 24 11:27:37 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.020055 | F1-score: 0.99 | Elapsed: 3.92s
WARNING:root: [*] Sat Dec 24 11:27:41 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.028765 | F1-score: 0.99 | Elapsed: 3.90s
WARNING:root: [*] Sat Dec 24 11:27:44 2022:    3    | Tr.loss: 0.049707 | Tr.F1.:   0.99    |   30.99  s
WARNING:root:
        [!] Sat Dec 24 11:27:44 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671877664-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671877664-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671877664-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671877664-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\metrics_trainSize_76126_ep_3_cv_3_maxLen_1024_vocabSize_20000_embeddingDim_64_hiddenNeurons_512_256_128_batchNormConv_False_batchNormFFNN_False_filterSizes_2_3_4_5.json
WARNING:root: [!] Average epoch time: 30.89s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.5327 -- F1: 0.6887
	FPR:  0.001 -- TPR: 0.9309 -- F1: 0.9638
	FPR:   0.01 -- TPR: 0.9783 -- F1: 0.9869
	FPR:    0.1 -- TPR: 0.9962 -- F1: 0.9747

WARNING:root: [!] Running Cross Validation with vocabSize: 20000 | maxLen: 2048
WARNING:root: [!] Using device: cuda:0 | Dataset size: 76126
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 20000, 'embeddingDim': 64, 'hiddenNeurons': [512, 256, 128], 'batchNormConv': False, 'batchNormFFNN': False, 'filterSizes': [2, 3, 4, 5]}
WARNING:root: [!] Fold 1/3 | Train set size: 50750, Validation set size: 25376
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Sat Dec 24 11:28:20 2022: Train Epoch: 1 [  0  /50750 (0 %)]	Loss: 0.729168 | F1-score: 0.37 | Elapsed: 0.37s
WARNING:root: [*] Sat Dec 24 11:28:27 2022: Train Epoch: 1 [6400 /50750 (13%)]	Loss: 0.142774 | F1-score: 0.87 | Elapsed: 7.08s
WARNING:root: [*] Sat Dec 24 11:28:34 2022: Train Epoch: 1 [12800/50750 (25%)]	Loss: 0.166835 | F1-score: 0.91 | Elapsed: 7.11s
WARNING:root: [*] Sat Dec 24 11:28:41 2022: Train Epoch: 1 [19200/50750 (38%)]	Loss: 0.101128 | F1-score: 0.93 | Elapsed: 7.14s
WARNING:root: [*] Sat Dec 24 11:28:48 2022: Train Epoch: 1 [25600/50750 (50%)]	Loss: 0.217866 | F1-score: 0.94 | Elapsed: 7.16s
WARNING:root: [*] Sat Dec 24 11:28:56 2022: Train Epoch: 1 [32000/50750 (63%)]	Loss: 0.071530 | F1-score: 0.95 | Elapsed: 7.18s
WARNING:root: [*] Sat Dec 24 11:29:03 2022: Train Epoch: 1 [38400/50750 (76%)]	Loss: 0.059865 | F1-score: 0.95 | Elapsed: 7.18s
WARNING:root: [*] Sat Dec 24 11:29:10 2022: Train Epoch: 1 [44800/50750 (88%)]	Loss: 0.028955 | F1-score: 0.96 | Elapsed: 7.20s
WARNING:root: [*] Sat Dec 24 11:29:17 2022:    1    | Tr.loss: 0.139064 | Tr.F1.:   0.96    |   57.06  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Sat Dec 24 11:29:17 2022: Train Epoch: 2 [  0  /50750 (0 %)]	Loss: 0.111460 | F1-score: 0.97 | Elapsed: 0.08s
WARNING:root: [*] Sat Dec 24 11:29:24 2022: Train Epoch: 2 [6400 /50750 (13%)]	Loss: 0.044640 | F1-score: 0.98 | Elapsed: 7.20s
WARNING:root: [*] Sat Dec 24 11:29:31 2022: Train Epoch: 2 [12800/50750 (25%)]	Loss: 0.036020 | F1-score: 0.98 | Elapsed: 7.22s
WARNING:root: [*] Sat Dec 24 11:29:38 2022: Train Epoch: 2 [19200/50750 (38%)]	Loss: 0.043859 | F1-score: 0.98 | Elapsed: 7.22s
WARNING:root: [*] Sat Dec 24 11:29:45 2022: Train Epoch: 2 [25600/50750 (50%)]	Loss: 0.069913 | F1-score: 0.98 | Elapsed: 7.22s
WARNING:root: [*] Sat Dec 24 11:29:53 2022: Train Epoch: 2 [32000/50750 (63%)]	Loss: 0.022997 | F1-score: 0.98 | Elapsed: 7.23s
WARNING:root: [*] Sat Dec 24 11:30:00 2022: Train Epoch: 2 [38400/50750 (76%)]	Loss: 0.044393 | F1-score: 0.99 | Elapsed: 7.22s
WARNING:root: [*] Sat Dec 24 11:30:07 2022: Train Epoch: 2 [44800/50750 (88%)]	Loss: 0.044828 | F1-score: 0.99 | Elapsed: 7.23s
WARNING:root: [*] Sat Dec 24 11:30:14 2022:    2    | Tr.loss: 0.059225 | Tr.F1.:   0.99    |   57.27  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Sat Dec 24 11:30:14 2022: Train Epoch: 3 [  0  /50750 (0 %)]	Loss: 0.052694 | F1-score: 0.97 | Elapsed: 0.08s
WARNING:root: [*] Sat Dec 24 11:30:21 2022: Train Epoch: 3 [6400 /50750 (13%)]	Loss: 0.138433 | F1-score: 0.99 | Elapsed: 7.25s
WARNING:root: [*] Sat Dec 24 11:30:28 2022: Train Epoch: 3 [12800/50750 (25%)]	Loss: 0.041681 | F1-score: 0.99 | Elapsed: 7.23s
WARNING:root: [*] Sat Dec 24 11:30:36 2022: Train Epoch: 3 [19200/50750 (38%)]	Loss: 0.014915 | F1-score: 0.99 | Elapsed: 7.26s
WARNING:root: [*] Sat Dec 24 11:30:43 2022: Train Epoch: 3 [25600/50750 (50%)]	Loss: 0.003940 | F1-score: 0.99 | Elapsed: 7.24s
WARNING:root: [*] Sat Dec 24 11:30:50 2022: Train Epoch: 3 [32000/50750 (63%)]	Loss: 0.018626 | F1-score: 0.99 | Elapsed: 7.24s
WARNING:root: [*] Sat Dec 24 11:30:57 2022: Train Epoch: 3 [38400/50750 (76%)]	Loss: 0.015834 | F1-score: 0.99 | Elapsed: 7.24s
WARNING:root: [*] Sat Dec 24 11:31:05 2022: Train Epoch: 3 [44800/50750 (88%)]	Loss: 0.038392 | F1-score: 0.99 | Elapsed: 7.25s
WARNING:root: [*] Sat Dec 24 11:31:11 2022:    3    | Tr.loss: 0.047811 | Tr.F1.:   0.99    |   57.45  s
WARNING:root:
        [!] Sat Dec 24 11:31:11 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671877871-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671877871-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671877871-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671877871-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Sat Dec 24 11:31:20 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.709708 | F1-score: 0.44 | Elapsed: 0.09s
WARNING:root: [*] Sat Dec 24 11:31:27 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.205551 | F1-score: 0.86 | Elapsed: 7.23s
WARNING:root: [*] Sat Dec 24 11:31:35 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.061943 | F1-score: 0.91 | Elapsed: 7.25s
WARNING:root: [*] Sat Dec 24 11:31:42 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.069060 | F1-score: 0.93 | Elapsed: 7.28s
WARNING:root: [*] Sat Dec 24 11:31:49 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.028780 | F1-score: 0.94 | Elapsed: 7.25s
WARNING:root: [*] Sat Dec 24 11:31:56 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.077125 | F1-score: 0.95 | Elapsed: 7.25s
WARNING:root: [*] Sat Dec 24 11:32:04 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.148109 | F1-score: 0.95 | Elapsed: 7.27s
WARNING:root: [*] Sat Dec 24 11:32:11 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.029137 | F1-score: 0.96 | Elapsed: 7.28s
WARNING:root: [*] Sat Dec 24 11:32:18 2022:    1    | Tr.loss: 0.142934 | Tr.F1.:   0.96    |   57.59  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Sat Dec 24 11:32:18 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.023961 | F1-score: 1.00 | Elapsed: 0.08s
WARNING:root: [*] Sat Dec 24 11:32:25 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.166752 | F1-score: 0.98 | Elapsed: 7.16s
WARNING:root: [*] Sat Dec 24 11:32:32 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.369051 | F1-score: 0.98 | Elapsed: 7.16s
WARNING:root: [*] Sat Dec 24 11:32:39 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.012290 | F1-score: 0.98 | Elapsed: 7.22s
WARNING:root: [*] Sat Dec 24 11:32:47 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.052952 | F1-score: 0.99 | Elapsed: 7.27s
WARNING:root: [*] Sat Dec 24 11:32:54 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.106890 | F1-score: 0.99 | Elapsed: 7.30s
WARNING:root: [*] Sat Dec 24 11:33:01 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.043958 | F1-score: 0.99 | Elapsed: 7.28s
WARNING:root: [*] Sat Dec 24 11:33:08 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.034825 | F1-score: 0.99 | Elapsed: 7.30s
WARNING:root: [*] Sat Dec 24 11:33:15 2022:    2    | Tr.loss: 0.060572 | Tr.F1.:   0.99    |   57.48  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Sat Dec 24 11:33:15 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.016600 | F1-score: 1.00 | Elapsed: 0.09s
WARNING:root: [*] Sat Dec 24 11:33:23 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.030890 | F1-score: 0.99 | Elapsed: 7.34s
WARNING:root: [*] Sat Dec 24 11:33:30 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.090900 | F1-score: 0.99 | Elapsed: 7.33s
WARNING:root: [*] Sat Dec 24 11:33:37 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.031141 | F1-score: 0.99 | Elapsed: 7.29s
WARNING:root: [*] Sat Dec 24 11:33:45 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.108102 | F1-score: 0.99 | Elapsed: 7.33s
WARNING:root: [*] Sat Dec 24 11:33:52 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.057871 | F1-score: 0.99 | Elapsed: 7.31s
WARNING:root: [*] Sat Dec 24 11:33:59 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.119486 | F1-score: 0.99 | Elapsed: 7.30s
WARNING:root: [*] Sat Dec 24 11:34:06 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.043811 | F1-score: 0.99 | Elapsed: 7.27s
WARNING:root: [*] Sat Dec 24 11:34:13 2022:    3    | Tr.loss: 0.048759 | Tr.F1.:   0.99    |   57.98  s
WARNING:root:
        [!] Sat Dec 24 11:34:13 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671878053-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671878053-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671878053-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671878053-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Sat Dec 24 11:34:22 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.713188 | F1-score: 0.55 | Elapsed: 0.11s
WARNING:root: [*] Sat Dec 24 11:34:29 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.146668 | F1-score: 0.87 | Elapsed: 7.30s
WARNING:root: [*] Sat Dec 24 11:34:37 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.066843 | F1-score: 0.92 | Elapsed: 7.30s
WARNING:root: [*] Sat Dec 24 11:34:44 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.103236 | F1-score: 0.94 | Elapsed: 7.30s
WARNING:root: [*] Sat Dec 24 11:34:51 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.092401 | F1-score: 0.95 | Elapsed: 7.34s
WARNING:root: [*] Sat Dec 24 11:34:59 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.056468 | F1-score: 0.95 | Elapsed: 7.33s
WARNING:root: [*] Sat Dec 24 11:35:06 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.140988 | F1-score: 0.96 | Elapsed: 7.33s
WARNING:root: [*] Sat Dec 24 11:35:13 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.114958 | F1-score: 0.96 | Elapsed: 7.35s
WARNING:root: [*] Sat Dec 24 11:35:20 2022:    1    | Tr.loss: 0.139456 | Tr.F1.:   0.96    |   58.11  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Sat Dec 24 11:35:20 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.100575 | F1-score: 0.98 | Elapsed: 0.08s
WARNING:root: [*] Sat Dec 24 11:35:28 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.038939 | F1-score: 0.98 | Elapsed: 7.32s
WARNING:root: [*] Sat Dec 24 11:35:35 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.030082 | F1-score: 0.98 | Elapsed: 7.36s
WARNING:root: [*] Sat Dec 24 11:35:42 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.144076 | F1-score: 0.98 | Elapsed: 7.36s
WARNING:root: [*] Sat Dec 24 11:35:50 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.180991 | F1-score: 0.98 | Elapsed: 7.33s
WARNING:root: [*] Sat Dec 24 11:35:57 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.042719 | F1-score: 0.98 | Elapsed: 7.30s
WARNING:root: [*] Sat Dec 24 11:36:04 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.056833 | F1-score: 0.98 | Elapsed: 7.33s
WARNING:root: [*] Sat Dec 24 11:36:12 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.079380 | F1-score: 0.98 | Elapsed: 7.29s
WARNING:root: [*] Sat Dec 24 11:36:18 2022:    2    | Tr.loss: 0.062396 | Tr.F1.:   0.98    |   58.11  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Sat Dec 24 11:36:18 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.022825 | F1-score: 0.99 | Elapsed: 0.08s
WARNING:root: [*] Sat Dec 24 11:36:26 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.239043 | F1-score: 0.99 | Elapsed: 7.31s
WARNING:root: [*] Sat Dec 24 11:36:33 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.022470 | F1-score: 0.99 | Elapsed: 7.31s
WARNING:root: [*] Sat Dec 24 11:36:40 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.061106 | F1-score: 0.99 | Elapsed: 7.30s
WARNING:root: [*] Sat Dec 24 11:36:48 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.013026 | F1-score: 0.99 | Elapsed: 7.31s
WARNING:root: [*] Sat Dec 24 11:36:55 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.028444 | F1-score: 0.99 | Elapsed: 7.29s
WARNING:root: [*] Sat Dec 24 11:37:02 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.006444 | F1-score: 0.99 | Elapsed: 7.32s
WARNING:root: [*] Sat Dec 24 11:37:10 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.079543 | F1-score: 0.99 | Elapsed: 7.35s
WARNING:root: [*] Sat Dec 24 11:37:16 2022:    3    | Tr.loss: 0.049266 | Tr.F1.:   0.99    |   58.00  s
WARNING:root:
        [!] Sat Dec 24 11:37:16 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671878236-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671878236-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671878236-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671878236-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\metrics_trainSize_76126_ep_3_cv_3_maxLen_2048_vocabSize_20000_embeddingDim_64_hiddenNeurons_512_256_128_batchNormConv_False_batchNormFFNN_False_filterSizes_2_3_4_5.json
WARNING:root: [!] Average epoch time: 57.67s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.4362 -- F1: 0.5254
	FPR:  0.001 -- TPR: 0.9294 -- F1: 0.9632
	FPR:   0.01 -- TPR: 0.9812 -- F1: 0.9882
	FPR:    0.1 -- TPR: 0.9966 -- F1: 0.9749

WARNING:root: [!] Running Cross Validation with vocabSize: 20000 | maxLen: 4096
WARNING:root: [!] Using device: cuda:0 | Dataset size: 76126
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 20000, 'embeddingDim': 64, 'hiddenNeurons': [512, 256, 128], 'batchNormConv': False, 'batchNormFFNN': False, 'filterSizes': [2, 3, 4, 5]}
WARNING:root: [!] Fold 1/3 | Train set size: 50750, Validation set size: 25376
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Sat Dec 24 11:37:57 2022: Train Epoch: 1 [  0  /50750 (0 %)]	Loss: 0.685361 | F1-score: 0.64 | Elapsed: 0.42s
WARNING:root: [*] Sat Dec 24 11:38:11 2022: Train Epoch: 1 [6400 /50750 (13%)]	Loss: 0.204840 | F1-score: 0.88 | Elapsed: 14.20s
WARNING:root: [*] Sat Dec 24 11:38:25 2022: Train Epoch: 1 [12800/50750 (25%)]	Loss: 0.141357 | F1-score: 0.92 | Elapsed: 14.23s
WARNING:root: [*] Sat Dec 24 11:38:39 2022: Train Epoch: 1 [19200/50750 (38%)]	Loss: 0.052305 | F1-score: 0.94 | Elapsed: 14.24s
WARNING:root: [*] Sat Dec 24 11:38:53 2022: Train Epoch: 1 [25600/50750 (50%)]	Loss: 0.057980 | F1-score: 0.94 | Elapsed: 14.28s
WARNING:root: [*] Sat Dec 24 11:39:08 2022: Train Epoch: 1 [32000/50750 (63%)]	Loss: 0.113425 | F1-score: 0.95 | Elapsed: 14.35s
WARNING:root: [*] Sat Dec 24 11:39:22 2022: Train Epoch: 1 [38400/50750 (76%)]	Loss: 0.061701 | F1-score: 0.96 | Elapsed: 14.35s
WARNING:root: [*] Sat Dec 24 11:39:37 2022: Train Epoch: 1 [44800/50750 (88%)]	Loss: 0.117986 | F1-score: 0.96 | Elapsed: 14.36s
WARNING:root: [*] Sat Dec 24 11:39:50 2022:    1    | Tr.loss: 0.139376 | Tr.F1.:   0.96    |  113.66  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Sat Dec 24 11:39:50 2022: Train Epoch: 2 [  0  /50750 (0 %)]	Loss: 0.079641 | F1-score: 0.97 | Elapsed: 0.14s
WARNING:root: [*] Sat Dec 24 11:40:04 2022: Train Epoch: 2 [6400 /50750 (13%)]	Loss: 0.018079 | F1-score: 0.98 | Elapsed: 14.39s
WARNING:root: [*] Sat Dec 24 11:40:19 2022: Train Epoch: 2 [12800/50750 (25%)]	Loss: 0.098767 | F1-score: 0.98 | Elapsed: 14.40s
WARNING:root: [*] Sat Dec 24 11:40:33 2022: Train Epoch: 2 [19200/50750 (38%)]	Loss: 0.171387 | F1-score: 0.98 | Elapsed: 14.38s
WARNING:root: [*] Sat Dec 24 11:40:47 2022: Train Epoch: 2 [25600/50750 (50%)]	Loss: 0.021938 | F1-score: 0.98 | Elapsed: 14.37s
WARNING:root: [*] Sat Dec 24 11:41:02 2022: Train Epoch: 2 [32000/50750 (63%)]	Loss: 0.194835 | F1-score: 0.99 | Elapsed: 14.38s
WARNING:root: [*] Sat Dec 24 11:41:16 2022: Train Epoch: 2 [38400/50750 (76%)]	Loss: 0.092329 | F1-score: 0.99 | Elapsed: 14.38s
WARNING:root: [*] Sat Dec 24 11:41:31 2022: Train Epoch: 2 [44800/50750 (88%)]	Loss: 0.082204 | F1-score: 0.99 | Elapsed: 14.46s
WARNING:root: [*] Sat Dec 24 11:41:44 2022:    2    | Tr.loss: 0.060950 | Tr.F1.:   0.99    |  114.28  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Sat Dec 24 11:41:44 2022: Train Epoch: 3 [  0  /50750 (0 %)]	Loss: 0.090006 | F1-score: 0.99 | Elapsed: 0.15s
WARNING:root: [*] Sat Dec 24 11:41:59 2022: Train Epoch: 3 [6400 /50750 (13%)]	Loss: 0.038434 | F1-score: 0.99 | Elapsed: 14.44s
WARNING:root: [*] Sat Dec 24 11:42:13 2022: Train Epoch: 3 [12800/50750 (25%)]	Loss: 0.016255 | F1-score: 0.99 | Elapsed: 14.44s
WARNING:root: [*] Sat Dec 24 11:42:28 2022: Train Epoch: 3 [19200/50750 (38%)]	Loss: 0.076713 | F1-score: 0.99 | Elapsed: 14.52s
WARNING:root: [*] Sat Dec 24 11:42:42 2022: Train Epoch: 3 [25600/50750 (50%)]	Loss: 0.007885 | F1-score: 0.99 | Elapsed: 14.50s
WARNING:root: [*] Sat Dec 24 11:42:57 2022: Train Epoch: 3 [32000/50750 (63%)]	Loss: 0.012594 | F1-score: 0.99 | Elapsed: 14.54s
WARNING:root: [*] Sat Dec 24 11:43:11 2022: Train Epoch: 3 [38400/50750 (76%)]	Loss: 0.040641 | F1-score: 0.99 | Elapsed: 14.49s
WARNING:root: [*] Sat Dec 24 11:43:26 2022: Train Epoch: 3 [44800/50750 (88%)]	Loss: 0.057287 | F1-score: 0.99 | Elapsed: 14.47s
WARNING:root: [*] Sat Dec 24 11:43:39 2022:    3    | Tr.loss: 0.047200 | Tr.F1.:   0.99    |  114.85  s
WARNING:root:
        [!] Sat Dec 24 11:43:39 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671878619-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671878619-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671878619-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671878619-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Sat Dec 24 11:43:57 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.703081 | F1-score: 0.39 | Elapsed: 0.15s
WARNING:root: [*] Sat Dec 24 11:44:11 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.061818 | F1-score: 0.86 | Elapsed: 14.51s
WARNING:root: [*] Sat Dec 24 11:44:26 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.108124 | F1-score: 0.91 | Elapsed: 14.42s
WARNING:root: [*] Sat Dec 24 11:44:40 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.062253 | F1-score: 0.93 | Elapsed: 14.42s
WARNING:root: [*] Sat Dec 24 11:44:55 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.067795 | F1-score: 0.94 | Elapsed: 14.42s
WARNING:root: [*] Sat Dec 24 11:45:09 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.053230 | F1-score: 0.95 | Elapsed: 14.43s
WARNING:root: [*] Sat Dec 24 11:45:24 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.140129 | F1-score: 0.95 | Elapsed: 14.49s
WARNING:root: [*] Sat Dec 24 11:45:38 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.120119 | F1-score: 0.96 | Elapsed: 14.44s
WARNING:root: [*] Sat Dec 24 11:45:51 2022:    1    | Tr.loss: 0.143771 | Tr.F1.:   0.96    |  114.57  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Sat Dec 24 11:45:52 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.039357 | F1-score: 0.98 | Elapsed: 0.14s
WARNING:root: [*] Sat Dec 24 11:46:06 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.009776 | F1-score: 0.99 | Elapsed: 14.66s
WARNING:root: [*] Sat Dec 24 11:46:21 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.068414 | F1-score: 0.98 | Elapsed: 14.42s
WARNING:root: [*] Sat Dec 24 11:46:35 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.042278 | F1-score: 0.99 | Elapsed: 14.43s
WARNING:root: [*] Sat Dec 24 11:46:49 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.140856 | F1-score: 0.99 | Elapsed: 14.44s
WARNING:root: [*] Sat Dec 24 11:47:04 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.038470 | F1-score: 0.98 | Elapsed: 14.45s
WARNING:root: [*] Sat Dec 24 11:47:18 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.059030 | F1-score: 0.99 | Elapsed: 14.49s
WARNING:root: [*] Sat Dec 24 11:47:33 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.048859 | F1-score: 0.99 | Elapsed: 14.45s
WARNING:root: [*] Sat Dec 24 11:47:46 2022:    2    | Tr.loss: 0.058629 | Tr.F1.:   0.99    |  114.76  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Sat Dec 24 11:47:46 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.017277 | F1-score: 1.00 | Elapsed: 0.15s
WARNING:root: [*] Sat Dec 24 11:48:01 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.037234 | F1-score: 0.99 | Elapsed: 14.44s
WARNING:root: [*] Sat Dec 24 11:48:15 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.043495 | F1-score: 0.99 | Elapsed: 14.46s
WARNING:root: [*] Sat Dec 24 11:48:30 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.265657 | F1-score: 0.99 | Elapsed: 14.46s
WARNING:root: [*] Sat Dec 24 11:48:44 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.022626 | F1-score: 0.99 | Elapsed: 14.47s
WARNING:root: [*] Sat Dec 24 11:48:59 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.043403 | F1-score: 0.99 | Elapsed: 14.45s
WARNING:root: [*] Sat Dec 24 11:49:13 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.022166 | F1-score: 0.99 | Elapsed: 14.43s
WARNING:root: [*] Sat Dec 24 11:49:27 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.009148 | F1-score: 0.99 | Elapsed: 14.46s
WARNING:root: [*] Sat Dec 24 11:49:41 2022:    3    | Tr.loss: 0.050816 | Tr.F1.:   0.99    |  114.60  s
WARNING:root:
        [!] Sat Dec 24 11:49:41 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671878981-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671878981-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671878981-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671878981-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Sat Dec 24 11:49:59 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.687974 | F1-score: 0.68 | Elapsed: 0.16s
WARNING:root: [*] Sat Dec 24 11:50:13 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.290670 | F1-score: 0.86 | Elapsed: 14.44s
WARNING:root: [*] Sat Dec 24 11:50:27 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.107612 | F1-score: 0.91 | Elapsed: 14.45s
WARNING:root: [*] Sat Dec 24 11:50:42 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.092936 | F1-score: 0.93 | Elapsed: 14.43s
WARNING:root: [*] Sat Dec 24 11:50:56 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.093133 | F1-score: 0.94 | Elapsed: 14.42s
WARNING:root: [*] Sat Dec 24 11:51:11 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.162126 | F1-score: 0.95 | Elapsed: 14.44s
WARNING:root: [*] Sat Dec 24 11:51:25 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.042964 | F1-score: 0.95 | Elapsed: 14.44s
WARNING:root: [*] Sat Dec 24 11:51:40 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.070789 | F1-score: 0.96 | Elapsed: 14.48s
WARNING:root: [*] Sat Dec 24 11:51:53 2022:    1    | Tr.loss: 0.145320 | Tr.F1.:   0.96    |  114.59  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Sat Dec 24 11:51:53 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.043475 | F1-score: 0.99 | Elapsed: 0.15s
WARNING:root: [*] Sat Dec 24 11:52:08 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.081595 | F1-score: 0.99 | Elapsed: 14.47s
WARNING:root: [*] Sat Dec 24 11:52:22 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.042127 | F1-score: 0.99 | Elapsed: 14.45s
WARNING:root: [*] Sat Dec 24 11:52:37 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.089672 | F1-score: 0.98 | Elapsed: 14.46s
WARNING:root: [*] Sat Dec 24 11:52:51 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.031477 | F1-score: 0.98 | Elapsed: 14.46s
WARNING:root: [*] Sat Dec 24 11:53:05 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.008113 | F1-score: 0.98 | Elapsed: 14.42s
WARNING:root: [*] Sat Dec 24 11:53:20 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.077253 | F1-score: 0.98 | Elapsed: 14.44s
WARNING:root: [*] Sat Dec 24 11:53:34 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.048229 | F1-score: 0.98 | Elapsed: 14.46s
WARNING:root: [*] Sat Dec 24 11:53:48 2022:    2    | Tr.loss: 0.060554 | Tr.F1.:   0.99    |  114.61  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Sat Dec 24 11:53:48 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.015905 | F1-score: 1.00 | Elapsed: 0.15s
WARNING:root: [*] Sat Dec 24 11:54:02 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.007941 | F1-score: 0.99 | Elapsed: 14.45s
WARNING:root: [*] Sat Dec 24 11:54:17 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.074512 | F1-score: 0.99 | Elapsed: 14.46s
WARNING:root: [*] Sat Dec 24 11:54:31 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.040660 | F1-score: 0.99 | Elapsed: 14.46s
WARNING:root: [*] Sat Dec 24 11:54:46 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.038477 | F1-score: 0.99 | Elapsed: 14.45s
WARNING:root: [*] Sat Dec 24 11:55:00 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.037261 | F1-score: 0.99 | Elapsed: 14.43s
WARNING:root: [*] Sat Dec 24 11:55:14 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.098900 | F1-score: 0.99 | Elapsed: 14.46s
WARNING:root: [*] Sat Dec 24 11:55:29 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.022264 | F1-score: 0.99 | Elapsed: 14.46s
WARNING:root: [*] Sat Dec 24 11:55:42 2022:    3    | Tr.loss: 0.047310 | Tr.F1.:   0.99    |  114.63  s
WARNING:root:
        [!] Sat Dec 24 11:55:42 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671879342-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671879342-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671879342-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671879342-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\metrics_trainSize_76126_ep_3_cv_3_maxLen_4096_vocabSize_20000_embeddingDim_64_hiddenNeurons_512_256_128_batchNormConv_False_batchNormFFNN_False_filterSizes_2_3_4_5.json
WARNING:root: [!] Average epoch time: 114.51s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.4857 -- F1: 0.5618
	FPR:  0.001 -- TPR: 0.9413 -- F1: 0.9695
	FPR:   0.01 -- TPR: 0.9805 -- F1: 0.9879
	FPR:    0.1 -- TPR: 0.9970 -- F1: 0.9752

WARNING:root: [!] Running Cross Validation with vocabSize: 20000 | maxLen: 512
WARNING:root: [!] Using device: cuda:0 | Dataset size: 76126
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 20000, 'embeddingDim': 64, 'hiddenNeurons': [512, 256, 128], 'batchNormConv': False, 'batchNormFFNN': False, 'filterSizes': [2, 3, 4, 5]}
WARNING:root: [!] Fold 1/3 | Train set size: 50750, Validation set size: 25376
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Sat Dec 24 11:56:30 2022: Train Epoch: 1 [  0  /50750 (0 %)]	Loss: 0.726502 | F1-score: 0.15 | Elapsed: 0.17s
WARNING:root: [*] Sat Dec 24 11:56:32 2022: Train Epoch: 1 [6400 /50750 (13%)]	Loss: 0.155076 | F1-score: 0.87 | Elapsed: 2.31s
WARNING:root: [*] Sat Dec 24 11:56:34 2022: Train Epoch: 1 [12800/50750 (25%)]	Loss: 0.070759 | F1-score: 0.91 | Elapsed: 2.27s
WARNING:root: [*] Sat Dec 24 11:56:37 2022: Train Epoch: 1 [19200/50750 (38%)]	Loss: 0.146873 | F1-score: 0.93 | Elapsed: 2.32s
WARNING:root: [*] Sat Dec 24 11:56:39 2022: Train Epoch: 1 [25600/50750 (50%)]	Loss: 0.196456 | F1-score: 0.94 | Elapsed: 2.25s
WARNING:root: [*] Sat Dec 24 11:56:41 2022: Train Epoch: 1 [32000/50750 (63%)]	Loss: 0.181335 | F1-score: 0.95 | Elapsed: 2.29s
WARNING:root: [*] Sat Dec 24 11:56:44 2022: Train Epoch: 1 [38400/50750 (76%)]	Loss: 0.121365 | F1-score: 0.95 | Elapsed: 2.26s
WARNING:root: [*] Sat Dec 24 11:56:46 2022: Train Epoch: 1 [44800/50750 (88%)]	Loss: 0.198607 | F1-score: 0.96 | Elapsed: 2.28s
WARNING:root: [*] Sat Dec 24 11:56:48 2022:    1    | Tr.loss: 0.147422 | Tr.F1.:   0.96    |   18.31  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Sat Dec 24 11:56:48 2022: Train Epoch: 2 [  0  /50750 (0 %)]	Loss: 0.036423 | F1-score: 0.99 | Elapsed: 0.03s
WARNING:root: [*] Sat Dec 24 11:56:50 2022: Train Epoch: 2 [6400 /50750 (13%)]	Loss: 0.081591 | F1-score: 0.98 | Elapsed: 2.32s
WARNING:root: [*] Sat Dec 24 11:56:53 2022: Train Epoch: 2 [12800/50750 (25%)]	Loss: 0.063941 | F1-score: 0.98 | Elapsed: 2.35s
WARNING:root: [*] Sat Dec 24 11:56:55 2022: Train Epoch: 2 [19200/50750 (38%)]	Loss: 0.193694 | F1-score: 0.98 | Elapsed: 2.32s
WARNING:root: [*] Sat Dec 24 11:56:57 2022: Train Epoch: 2 [25600/50750 (50%)]	Loss: 0.038728 | F1-score: 0.98 | Elapsed: 2.35s
WARNING:root: [*] Sat Dec 24 11:57:00 2022: Train Epoch: 2 [32000/50750 (63%)]	Loss: 0.044373 | F1-score: 0.98 | Elapsed: 2.34s
WARNING:root: [*] Sat Dec 24 11:57:02 2022: Train Epoch: 2 [38400/50750 (76%)]	Loss: 0.015981 | F1-score: 0.98 | Elapsed: 2.32s
WARNING:root: [*] Sat Dec 24 11:57:04 2022: Train Epoch: 2 [44800/50750 (88%)]	Loss: 0.004823 | F1-score: 0.98 | Elapsed: 2.28s
WARNING:root: [*] Sat Dec 24 11:57:06 2022:    2    | Tr.loss: 0.065108 | Tr.F1.:   0.98    |   18.43  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Sat Dec 24 11:57:06 2022: Train Epoch: 3 [  0  /50750 (0 %)]	Loss: 0.134038 | F1-score: 0.99 | Elapsed: 0.04s
WARNING:root: [*] Sat Dec 24 11:57:09 2022: Train Epoch: 3 [6400 /50750 (13%)]	Loss: 0.048347 | F1-score: 0.99 | Elapsed: 2.24s
WARNING:root: [*] Sat Dec 24 11:57:11 2022: Train Epoch: 3 [12800/50750 (25%)]	Loss: 0.072743 | F1-score: 0.99 | Elapsed: 2.31s
WARNING:root: [*] Sat Dec 24 11:57:13 2022: Train Epoch: 3 [19200/50750 (38%)]	Loss: 0.088680 | F1-score: 0.99 | Elapsed: 2.39s
WARNING:root: [*] Sat Dec 24 11:57:16 2022: Train Epoch: 3 [25600/50750 (50%)]	Loss: 0.026339 | F1-score: 0.99 | Elapsed: 2.31s
WARNING:root: [*] Sat Dec 24 11:57:18 2022: Train Epoch: 3 [32000/50750 (63%)]	Loss: 0.157142 | F1-score: 0.99 | Elapsed: 2.25s
WARNING:root: [*] Sat Dec 24 11:57:20 2022: Train Epoch: 3 [38400/50750 (76%)]	Loss: 0.017138 | F1-score: 0.99 | Elapsed: 2.24s
WARNING:root: [*] Sat Dec 24 11:57:22 2022: Train Epoch: 3 [44800/50750 (88%)]	Loss: 0.008048 | F1-score: 0.99 | Elapsed: 2.31s
WARNING:root: [*] Sat Dec 24 11:57:25 2022:    3    | Tr.loss: 0.050276 | Tr.F1.:   0.99    |   18.21  s
WARNING:root:
        [!] Sat Dec 24 11:57:25 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671879445-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671879445-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671879445-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671879445-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Sat Dec 24 11:57:27 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.689951 | F1-score: 0.60 | Elapsed: 0.03s
WARNING:root: [*] Sat Dec 24 11:57:29 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.380943 | F1-score: 0.87 | Elapsed: 2.38s
WARNING:root: [*] Sat Dec 24 11:57:32 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.087739 | F1-score: 0.91 | Elapsed: 2.40s
WARNING:root: [*] Sat Dec 24 11:57:34 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.176797 | F1-score: 0.93 | Elapsed: 2.31s
WARNING:root: [*] Sat Dec 24 11:57:36 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.102970 | F1-score: 0.94 | Elapsed: 2.27s
WARNING:root: [*] Sat Dec 24 11:57:39 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.171743 | F1-score: 0.94 | Elapsed: 2.27s
WARNING:root: [*] Sat Dec 24 11:57:41 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.102586 | F1-score: 0.95 | Elapsed: 2.26s
WARNING:root: [*] Sat Dec 24 11:57:43 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.010047 | F1-score: 0.95 | Elapsed: 2.33s
WARNING:root: [*] Sat Dec 24 11:57:45 2022:    1    | Tr.loss: 0.151566 | Tr.F1.:   0.96    |   18.35  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Sat Dec 24 11:57:45 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.045728 | F1-score: 0.99 | Elapsed: 0.04s
WARNING:root: [*] Sat Dec 24 11:57:48 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.009917 | F1-score: 0.98 | Elapsed: 2.32s
WARNING:root: [*] Sat Dec 24 11:57:50 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.128572 | F1-score: 0.98 | Elapsed: 2.38s
WARNING:root: [*] Sat Dec 24 11:57:52 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.097408 | F1-score: 0.98 | Elapsed: 2.32s
WARNING:root: [*] Sat Dec 24 11:57:55 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.081303 | F1-score: 0.98 | Elapsed: 2.30s
WARNING:root: [*] Sat Dec 24 11:57:57 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.031458 | F1-score: 0.98 | Elapsed: 2.40s
WARNING:root: [*] Sat Dec 24 11:57:59 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.012104 | F1-score: 0.98 | Elapsed: 2.34s
WARNING:root: [*] Sat Dec 24 11:58:02 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.018929 | F1-score: 0.98 | Elapsed: 2.33s
WARNING:root: [*] Sat Dec 24 11:58:04 2022:    2    | Tr.loss: 0.064319 | Tr.F1.:   0.98    |   18.62  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Sat Dec 24 11:58:04 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.027038 | F1-score: 0.99 | Elapsed: 0.03s
WARNING:root: [*] Sat Dec 24 11:58:06 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.004879 | F1-score: 0.98 | Elapsed: 2.34s
WARNING:root: [*] Sat Dec 24 11:58:09 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.059560 | F1-score: 0.99 | Elapsed: 2.31s
WARNING:root: [*] Sat Dec 24 11:58:11 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.286447 | F1-score: 0.99 | Elapsed: 2.33s
WARNING:root: [*] Sat Dec 24 11:58:13 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.004488 | F1-score: 0.99 | Elapsed: 2.35s
WARNING:root: [*] Sat Dec 24 11:58:16 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.135355 | F1-score: 0.99 | Elapsed: 2.32s
WARNING:root: [*] Sat Dec 24 11:58:18 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.057387 | F1-score: 0.99 | Elapsed: 2.35s
WARNING:root: [*] Sat Dec 24 11:58:20 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.062537 | F1-score: 0.99 | Elapsed: 2.30s
WARNING:root: [*] Sat Dec 24 11:58:22 2022:    3    | Tr.loss: 0.053187 | Tr.F1.:   0.99    |   18.45  s
WARNING:root:
        [!] Sat Dec 24 11:58:22 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671879502-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671879502-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671879502-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671879502-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Sat Dec 24 11:58:25 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.686973 | F1-score: 0.62 | Elapsed: 0.03s
WARNING:root: [*] Sat Dec 24 11:58:27 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.248812 | F1-score: 0.88 | Elapsed: 2.36s
WARNING:root: [*] Sat Dec 24 11:58:30 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.099367 | F1-score: 0.92 | Elapsed: 2.31s
WARNING:root: [*] Sat Dec 24 11:58:32 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.095731 | F1-score: 0.93 | Elapsed: 2.32s
WARNING:root: [*] Sat Dec 24 11:58:34 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.071890 | F1-score: 0.94 | Elapsed: 2.28s
WARNING:root: [*] Sat Dec 24 11:58:37 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.175780 | F1-score: 0.95 | Elapsed: 2.30s
WARNING:root: [*] Sat Dec 24 11:58:39 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.090009 | F1-score: 0.95 | Elapsed: 2.35s
WARNING:root: [*] Sat Dec 24 11:58:41 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.040066 | F1-score: 0.96 | Elapsed: 2.27s
WARNING:root: [*] Sat Dec 24 11:58:43 2022:    1    | Tr.loss: 0.146364 | Tr.F1.:   0.96    |   18.38  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Sat Dec 24 11:58:43 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.027740 | F1-score: 1.00 | Elapsed: 0.03s
WARNING:root: [*] Sat Dec 24 11:58:46 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.044568 | F1-score: 0.98 | Elapsed: 2.29s
WARNING:root: [*] Sat Dec 24 11:58:48 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.045681 | F1-score: 0.98 | Elapsed: 2.30s
WARNING:root: [*] Sat Dec 24 11:58:50 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.042275 | F1-score: 0.98 | Elapsed: 2.31s
WARNING:root: [*] Sat Dec 24 11:58:53 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.014421 | F1-score: 0.98 | Elapsed: 2.34s
WARNING:root: [*] Sat Dec 24 11:58:55 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.028942 | F1-score: 0.98 | Elapsed: 2.35s
WARNING:root: [*] Sat Dec 24 11:58:57 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.041364 | F1-score: 0.99 | Elapsed: 2.29s
WARNING:root: [*] Sat Dec 24 11:59:00 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.049249 | F1-score: 0.98 | Elapsed: 2.33s
WARNING:root: [*] Sat Dec 24 11:59:02 2022:    2    | Tr.loss: 0.063860 | Tr.F1.:   0.98    |   18.34  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Sat Dec 24 11:59:02 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.030628 | F1-score: 1.00 | Elapsed: 0.03s
WARNING:root: [*] Sat Dec 24 11:59:04 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.042487 | F1-score: 0.99 | Elapsed: 2.26s
WARNING:root: [*] Sat Dec 24 11:59:06 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.063369 | F1-score: 0.99 | Elapsed: 2.26s
WARNING:root: [*] Sat Dec 24 11:59:08 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.131178 | F1-score: 0.99 | Elapsed: 2.26s
WARNING:root: [*] Sat Dec 24 11:59:11 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.076986 | F1-score: 0.99 | Elapsed: 2.28s
WARNING:root: [*] Sat Dec 24 11:59:13 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.012104 | F1-score: 0.99 | Elapsed: 2.36s
WARNING:root: [*] Sat Dec 24 11:59:15 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.034202 | F1-score: 0.99 | Elapsed: 2.32s
WARNING:root: [*] Sat Dec 24 11:59:18 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.047229 | F1-score: 0.99 | Elapsed: 2.30s
WARNING:root: [*] Sat Dec 24 11:59:20 2022:    3    | Tr.loss: 0.051319 | Tr.F1.:   0.99    |   18.23  s
WARNING:root:
        [!] Sat Dec 24 11:59:20 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671879560-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671879560-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671879560-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671879560-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\metrics_trainSize_76126_ep_3_cv_3_maxLen_512_vocabSize_20000_embeddingDim_64_hiddenNeurons_512_256_128_batchNormConv_False_batchNormFFNN_False_filterSizes_2_3_4_5.json
WARNING:root: [!] Average epoch time: 18.37s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.3547 -- F1: 0.4575
	FPR:  0.001 -- TPR: 0.9336 -- F1: 0.9653
	FPR:   0.01 -- TPR: 0.9778 -- F1: 0.9865
	FPR:    0.1 -- TPR: 0.9960 -- F1: 0.9747

WARNING:root: [!] Running Cross Validation with vocabSize: 20000 | maxLen: 6144
WARNING:root: [!] Using device: cuda:0 | Dataset size: 76126
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 20000, 'embeddingDim': 64, 'hiddenNeurons': [512, 256, 128], 'batchNormConv': False, 'batchNormFFNN': False, 'filterSizes': [2, 3, 4, 5]}
WARNING:root: [!] Fold 1/3 | Train set size: 50750, Validation set size: 25376
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Sat Dec 24 11:59:54 2022: Train Epoch: 1 [  0  /50750 (0 %)]	Loss: 0.713395 | F1-score: 0.23 | Elapsed: 0.54s
WARNING:root: [*] Sat Dec 24 12:00:16 2022: Train Epoch: 1 [6400 /50750 (13%)]	Loss: 0.355528 | F1-score: 0.87 | Elapsed: 21.10s
WARNING:root: [*] Sat Dec 24 12:00:37 2022: Train Epoch: 1 [12800/50750 (25%)]	Loss: 0.091237 | F1-score: 0.91 | Elapsed: 21.33s
WARNING:root: [*] Sat Dec 24 12:00:58 2022: Train Epoch: 1 [19200/50750 (38%)]	Loss: 0.130524 | F1-score: 0.93 | Elapsed: 21.34s
WARNING:root: [*] Sat Dec 24 12:01:20 2022: Train Epoch: 1 [25600/50750 (50%)]	Loss: 0.095489 | F1-score: 0.94 | Elapsed: 21.46s
WARNING:root: [*] Sat Dec 24 12:01:41 2022: Train Epoch: 1 [32000/50750 (63%)]	Loss: 0.043073 | F1-score: 0.95 | Elapsed: 21.41s
