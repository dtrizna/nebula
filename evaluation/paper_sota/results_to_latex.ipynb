{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiclass_speakeasy_val = \"\"\"clean\n",
    "              0.01       AUC        F1    Recall  Precision  Accuracy\n",
    "dmds      0.114002  0.920885  0.879307  0.932985   0.833872  0.916612\n",
    "nebula    0.447454  0.972893  0.961305  0.967613   0.955102  0.974752\n",
    "neurlux   0.348600  0.975635  0.960859  0.979979   0.942521  0.974109\n",
    "quovadis  0.460534  0.958050  0.946272  0.936779   0.956065  0.965531\n",
    "backdoor\n",
    "              0.01       AUC        F1    Recall  Precision  Accuracy\n",
    "dmds      0.697381  0.845552  0.805897  0.695558   0.965290  0.951974\n",
    "nebula    0.774952  0.920938  0.896454  0.849543   0.951042  0.971587\n",
    "neurlux   0.658602  0.922327  0.892895  0.854517   0.945415  0.970404\n",
    "quovadis  0.789767  0.892371  0.871144  0.788416   0.973434  0.966122\n",
    "coinminer\n",
    "              0.01       AUC        F1    Recall  Precision  Accuracy\n",
    "dmds      0.553021  0.891672  0.800972  0.804144   0.812683  0.963364\n",
    "nebula    0.880392  0.937070  0.908294  0.879875   0.938765  0.983908\n",
    "neurlux   0.893842  0.944493  0.922978  0.893131   0.956921  0.986549\n",
    "quovadis  0.847713  0.928786  0.881135  0.867683   0.895225  0.978825\n",
    "dropper\n",
    "              0.01       AUC        F1    Recall  Precision  Accuracy\n",
    "dmds      0.240735  0.879342  0.766491  0.792066   0.743064  0.947731\n",
    "nebula    0.414818  0.948150  0.874186  0.918500   0.834079  0.971376\n",
    "neurlux   0.450522  0.965908  0.889465  0.955439   0.834117  0.974096\n",
    "quovadis  0.343377  0.959013  0.870353  0.945632   0.806202  0.969498\n",
    "keylogger\n",
    "              0.01       AUC        F1    Recall  Precision  Accuracy\n",
    "dmds      0.460075  0.840283  0.717699  0.695039   0.760194  0.968894\n",
    "nebula    0.568454  0.937636  0.829267  0.890994   0.775567  0.978917\n",
    "neurlux   0.692548  0.950281  0.857623  0.913818   0.808230  0.982555\n",
    "quovadis  0.364445  0.957668  0.796051  0.941163   0.689745  0.972270\n",
    "ransomware\n",
    "              0.01       AUC        F1    Recall  Precision  Accuracy\n",
    "dmds      0.925158  0.958698  0.935647  0.924976   0.946635  0.983895\n",
    "nebula    0.971318  0.983295  0.969864  0.971162   0.968608  0.992355\n",
    "neurlux   0.960951  0.979314  0.973162  0.960616   0.986318  0.993301\n",
    "quovadis  0.983908  0.990807  0.984401  0.983780   0.985024  0.996059\n",
    "rat\n",
    "              0.01       AUC        F1    Recall  Precision  Accuracy\n",
    "dmds      0.038060  0.514170  0.052002  0.028393   0.308642  0.978247\n",
    "nebula    0.417056  0.705336  0.561783  0.411907   0.883483  0.985655\n",
    "neurlux   0.504666  0.749712  0.656389  0.499881   0.963319  0.988388\n",
    "quovadis  0.286149  0.638676  0.368812  0.280696   0.821406  0.980611\n",
    "trojan\n",
    "              0.01       AUC        F1    Recall  Precision  Accuracy\n",
    "dmds      0.125293  0.842519  0.689126  0.744911   0.641635  0.915640\n",
    "nebula    0.226790  0.887843  0.785325  0.812607   0.761360  0.944198\n",
    "neurlux   0.390303  0.882694  0.802180  0.790725   0.829100  0.951580\n",
    "quovadis  0.200671  0.878805  0.766593  0.798253   0.739895  0.939127\"\"\"\n",
    "\n",
    "multiclass_speakeasy_test = \"\"\"clean\n",
    "              0.01       AUC        F1    Recall  Precision  Accuracy\n",
    "dmds      0.022942  0.748188  0.758818  0.899758   0.657691  0.736007\n",
    "nebula    0.038209  0.855520  0.852634  0.963477   0.764701  0.846843\n",
    "neurlux   0.034734  0.846400  0.845251  0.972889   0.747251  0.836234\n",
    "quovadis  0.039514  0.838515  0.833750  0.911211   0.768742  0.832673\n",
    "backdoor\n",
    "              0.01       AUC        F1    Recall  Precision  Accuracy\n",
    "dmds      0.410211  0.789360  0.686977  0.596220   0.861423  0.939450\n",
    "nebula    0.785124  0.888982  0.854750  0.784364   0.939070  0.970280\n",
    "neurlux   0.738174  0.866284  0.832900  0.736598   0.958201  0.967063\n",
    "quovadis  0.774114  0.883894  0.852010  0.773024   0.949531  0.970050\n",
    "coinminer\n",
    "              0.01       AUC        F1    Recall  Precision  Accuracy\n",
    "dmds      0.106564  0.785349  0.558558  0.642716   0.508632  0.900385\n",
    "nebula    0.246825  0.770491  0.630264  0.565914   0.713992  0.935486\n",
    "neurlux   0.491341  0.785783  0.691004  0.582740   0.849532  0.949541\n",
    "quovadis  0.082952  0.723957  0.488396  0.510095   0.469035  0.896440\n",
    "dropper\n",
    "              0.01       AUC        F1    Recall  Precision  Accuracy\n",
    "dmds      0.106260  0.690071  0.201513  0.420635   0.134615  0.951705\n",
    "nebula    0.184617  0.709699  0.285044  0.444444   0.210562  0.967274\n",
    "neurlux   0.443261  0.829410  0.448844  0.687831   0.361069  0.966891\n",
    "quovadis  0.229852  0.794784  0.358026  0.616402   0.252407  0.968001\n",
    "keylogger\n",
    "              0.01       AUC        F1    Recall  Precision  Accuracy\n",
    "dmds      0.052716  0.521524  0.079420  0.044188   0.780009  0.941767\n",
    "nebula    0.030589  0.536186  0.129529  0.108870   0.160435  0.912392\n",
    "neurlux   0.051865  0.569942  0.203185  0.173551   0.247921  0.918922\n",
    "quovadis  0.038751  0.584788  0.211929  0.228947   0.197608  0.898068\n",
    "ransomware\n",
    "              0.01       AUC        F1    Recall  Precision  Accuracy\n",
    "dmds      0.231809  0.611227  0.358425  0.229702   0.815745  0.898987\n",
    "nebula    0.615397  0.804047  0.742148  0.613682   0.939576  0.947626\n",
    "neurlux   0.396902  0.694877  0.552656  0.392395   0.953912  0.923019\n",
    "quovadis  0.538453  0.765947  0.686104  0.535453   0.954726  0.939794\n",
    "rat\n",
    "              0.01       AUC        F1    Recall  Precision  Accuracy\n",
    "dmds      0.009857  0.499928  0.000000  0.000000   0.000000  0.927596\n",
    "nebula    0.242493  0.617133  0.368282  0.236619   0.882865  0.942648\n",
    "neurlux   0.504413  0.749537  0.662516  0.499735   0.983478  0.963233\n",
    "quovadis  0.059765  0.532584  0.119476  0.074457   0.513051  0.924494\n",
    "trojan\n",
    "              0.01       AUC        F1    Recall  Precision  Accuracy\n",
    "dmds      0.148252  0.770502  0.528229  0.581879   0.490882  0.935524\n",
    "nebula    0.241262  0.868782  0.682707  0.770125   0.613675  0.955095\n",
    "neurlux   0.308709  0.825405  0.615327  0.691460   0.579782  0.942590\n",
    "quovadis  0.165616  0.767423  0.535911  0.571778   0.519571  0.938588\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDENT = \"\\t\"*2\n",
    "def print_latex_table(inp, shuffle_speakeasy=True, chunk=6):\n",
    "    lines = inp.split(\"\\n\")\n",
    "    value_map = {\n",
    "        \"dmds\": r\"Zhang et al. \\cite{zhang_dmds}\",\n",
    "        \"nebula\": \"Ours (BPE)\",\n",
    "        \"nebula_bpe\": \"Ours (BPE)\",\n",
    "        \"nebula_wht\": \"Ours (whtsp.)\",\n",
    "        \"neurlux\": r\"Jindal et al. \\cite{neurlux}\",\n",
    "        \"quovadis\": r\"Trizna \\cite{quoVadis}\"\n",
    "    }\n",
    "    # loop over lines by 5 lines in chunk\n",
    "    for i in range(0, len(lines), chunk):\n",
    "        value = lines[i:i+chunk]\n",
    "        # convert it to latex table\n",
    "        print(INDENT + fr\"\\multicolumn{{5}}{{c}}{{{value[0].capitalize()}}} \\\\\")\n",
    "        print(INDENT + r\"\\midrule\")\n",
    "        msgs = []\n",
    "        for v in value[2:]:\n",
    "            v_split = v.split()\n",
    "            need = [1, 2, 3, 6]\n",
    "            v_need = [v_split[i] for i in need]\n",
    "            # round each element to 4 decimal places\n",
    "            v_need = [str(round(float(i), 4)) for i in v_need]\n",
    "            name = value_map[v_split[0]]\n",
    "            msg = INDENT + name + \" & \" + \" & \".join(v_need) + r\" \\\\\"\n",
    "            msgs.append(msg)\n",
    "        # reshufle messages so 2nd element goes to the end\n",
    "        if shuffle_speakeasy:\n",
    "            msgs = [msgs[0]] + msgs[2:] + [msgs[1]]\n",
    "        else:\n",
    "        # reshufle so 2nd element goes to the start\n",
    "            msgs = [msgs[2]] + msgs[0:2] + msgs[3:]\n",
    "        print(\"\\n\".join(msgs))\n",
    "        print(INDENT + r\"\\midrule\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\\multicolumn{5}{c}{Clean} \\\\\n",
      "\t\t\\midrule\n",
      "\t\tZhang et al. \\cite{zhang_dmds} & 0.114 & 0.9209 & 0.8793 & 0.9166 \\\\\n",
      "\t\tJindal et al. \\cite{neurlux} & 0.3486 & 0.9756 & 0.9609 & 0.9741 \\\\\n",
      "\t\tTrizna \\cite{quoVadis} & 0.4605 & 0.958 & 0.9463 & 0.9655 \\\\\n",
      "\t\tOurs (BPE) & 0.4475 & 0.9729 & 0.9613 & 0.9748 \\\\\n",
      "\t\t\\midrule\n",
      "\t\t\\multicolumn{5}{c}{Backdoor} \\\\\n",
      "\t\t\\midrule\n",
      "\t\tZhang et al. \\cite{zhang_dmds} & 0.6974 & 0.8456 & 0.8059 & 0.952 \\\\\n",
      "\t\tJindal et al. \\cite{neurlux} & 0.6586 & 0.9223 & 0.8929 & 0.9704 \\\\\n",
      "\t\tTrizna \\cite{quoVadis} & 0.7898 & 0.8924 & 0.8711 & 0.9661 \\\\\n",
      "\t\tOurs (BPE) & 0.775 & 0.9209 & 0.8965 & 0.9716 \\\\\n",
      "\t\t\\midrule\n",
      "\t\t\\multicolumn{5}{c}{Coinminer} \\\\\n",
      "\t\t\\midrule\n",
      "\t\tZhang et al. \\cite{zhang_dmds} & 0.553 & 0.8917 & 0.801 & 0.9634 \\\\\n",
      "\t\tJindal et al. \\cite{neurlux} & 0.8938 & 0.9445 & 0.923 & 0.9865 \\\\\n",
      "\t\tTrizna \\cite{quoVadis} & 0.8477 & 0.9288 & 0.8811 & 0.9788 \\\\\n",
      "\t\tOurs (BPE) & 0.8804 & 0.9371 & 0.9083 & 0.9839 \\\\\n",
      "\t\t\\midrule\n",
      "\t\t\\multicolumn{5}{c}{Dropper} \\\\\n",
      "\t\t\\midrule\n",
      "\t\tZhang et al. \\cite{zhang_dmds} & 0.2407 & 0.8793 & 0.7665 & 0.9477 \\\\\n",
      "\t\tJindal et al. \\cite{neurlux} & 0.4505 & 0.9659 & 0.8895 & 0.9741 \\\\\n",
      "\t\tTrizna \\cite{quoVadis} & 0.3434 & 0.959 & 0.8704 & 0.9695 \\\\\n",
      "\t\tOurs (BPE) & 0.4148 & 0.9482 & 0.8742 & 0.9714 \\\\\n",
      "\t\t\\midrule\n",
      "\t\t\\multicolumn{5}{c}{Keylogger} \\\\\n",
      "\t\t\\midrule\n",
      "\t\tZhang et al. \\cite{zhang_dmds} & 0.4601 & 0.8403 & 0.7177 & 0.9689 \\\\\n",
      "\t\tJindal et al. \\cite{neurlux} & 0.6925 & 0.9503 & 0.8576 & 0.9826 \\\\\n",
      "\t\tTrizna \\cite{quoVadis} & 0.3644 & 0.9577 & 0.7961 & 0.9723 \\\\\n",
      "\t\tOurs (BPE) & 0.5685 & 0.9376 & 0.8293 & 0.9789 \\\\\n",
      "\t\t\\midrule\n",
      "\t\t\\multicolumn{5}{c}{Ransomware} \\\\\n",
      "\t\t\\midrule\n",
      "\t\tZhang et al. \\cite{zhang_dmds} & 0.9252 & 0.9587 & 0.9356 & 0.9839 \\\\\n",
      "\t\tJindal et al. \\cite{neurlux} & 0.961 & 0.9793 & 0.9732 & 0.9933 \\\\\n",
      "\t\tTrizna \\cite{quoVadis} & 0.9839 & 0.9908 & 0.9844 & 0.9961 \\\\\n",
      "\t\tOurs (BPE) & 0.9713 & 0.9833 & 0.9699 & 0.9924 \\\\\n",
      "\t\t\\midrule\n",
      "\t\t\\multicolumn{5}{c}{Rat} \\\\\n",
      "\t\t\\midrule\n",
      "\t\tZhang et al. \\cite{zhang_dmds} & 0.0381 & 0.5142 & 0.052 & 0.9782 \\\\\n",
      "\t\tJindal et al. \\cite{neurlux} & 0.5047 & 0.7497 & 0.6564 & 0.9884 \\\\\n",
      "\t\tTrizna \\cite{quoVadis} & 0.2861 & 0.6387 & 0.3688 & 0.9806 \\\\\n",
      "\t\tOurs (BPE) & 0.4171 & 0.7053 & 0.5618 & 0.9857 \\\\\n",
      "\t\t\\midrule\n",
      "\t\t\\multicolumn{5}{c}{Trojan} \\\\\n",
      "\t\t\\midrule\n",
      "\t\tZhang et al. \\cite{zhang_dmds} & 0.1253 & 0.8425 & 0.6891 & 0.9156 \\\\\n",
      "\t\tJindal et al. \\cite{neurlux} & 0.3903 & 0.8827 & 0.8022 & 0.9516 \\\\\n",
      "\t\tTrizna \\cite{quoVadis} & 0.2007 & 0.8788 & 0.7666 & 0.9391 \\\\\n",
      "\t\tOurs (BPE) & 0.2268 & 0.8878 & 0.7853 & 0.9442 \\\\\n",
      "\t\t\\midrule\n"
     ]
    }
   ],
   "source": [
    "print_latex_table(multiclass_speakeasy_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\\multicolumn{5}{c}{Clean} \\\\\n",
      "\t\t\\midrule\n",
      "\t\tZhang et al. \\cite{zhang_dmds} & 0.0229 & 0.7482 & 0.7588 & 0.736 \\\\\n",
      "\t\tJindal et al. \\cite{neurlux} & 0.0347 & 0.8464 & 0.8453 & 0.8362 \\\\\n",
      "\t\tTrizna \\cite{quoVadis} & 0.0395 & 0.8385 & 0.8337 & 0.8327 \\\\\n",
      "\t\tOurs (BPE) & 0.0382 & 0.8555 & 0.8526 & 0.8468 \\\\\n",
      "\t\t\\midrule\n",
      "\t\t\\multicolumn{5}{c}{Backdoor} \\\\\n",
      "\t\t\\midrule\n",
      "\t\tZhang et al. \\cite{zhang_dmds} & 0.4102 & 0.7894 & 0.687 & 0.9395 \\\\\n",
      "\t\tJindal et al. \\cite{neurlux} & 0.7382 & 0.8663 & 0.8329 & 0.9671 \\\\\n",
      "\t\tTrizna \\cite{quoVadis} & 0.7741 & 0.8839 & 0.852 & 0.97 \\\\\n",
      "\t\tOurs (BPE) & 0.7851 & 0.889 & 0.8548 & 0.9703 \\\\\n",
      "\t\t\\midrule\n",
      "\t\t\\multicolumn{5}{c}{Coinminer} \\\\\n",
      "\t\t\\midrule\n",
      "\t\tZhang et al. \\cite{zhang_dmds} & 0.1066 & 0.7853 & 0.5586 & 0.9004 \\\\\n",
      "\t\tJindal et al. \\cite{neurlux} & 0.4913 & 0.7858 & 0.691 & 0.9495 \\\\\n",
      "\t\tTrizna \\cite{quoVadis} & 0.083 & 0.724 & 0.4884 & 0.8964 \\\\\n",
      "\t\tOurs (BPE) & 0.2468 & 0.7705 & 0.6303 & 0.9355 \\\\\n",
      "\t\t\\midrule\n",
      "\t\t\\multicolumn{5}{c}{Dropper} \\\\\n",
      "\t\t\\midrule\n",
      "\t\tZhang et al. \\cite{zhang_dmds} & 0.1063 & 0.6901 & 0.2015 & 0.9517 \\\\\n",
      "\t\tJindal et al. \\cite{neurlux} & 0.4433 & 0.8294 & 0.4488 & 0.9669 \\\\\n",
      "\t\tTrizna \\cite{quoVadis} & 0.2299 & 0.7948 & 0.358 & 0.968 \\\\\n",
      "\t\tOurs (BPE) & 0.1846 & 0.7097 & 0.285 & 0.9673 \\\\\n",
      "\t\t\\midrule\n",
      "\t\t\\multicolumn{5}{c}{Keylogger} \\\\\n",
      "\t\t\\midrule\n",
      "\t\tZhang et al. \\cite{zhang_dmds} & 0.0527 & 0.5215 & 0.0794 & 0.9418 \\\\\n",
      "\t\tJindal et al. \\cite{neurlux} & 0.0519 & 0.5699 & 0.2032 & 0.9189 \\\\\n",
      "\t\tTrizna \\cite{quoVadis} & 0.0388 & 0.5848 & 0.2119 & 0.8981 \\\\\n",
      "\t\tOurs (BPE) & 0.0306 & 0.5362 & 0.1295 & 0.9124 \\\\\n",
      "\t\t\\midrule\n",
      "\t\t\\multicolumn{5}{c}{Ransomware} \\\\\n",
      "\t\t\\midrule\n",
      "\t\tZhang et al. \\cite{zhang_dmds} & 0.2318 & 0.6112 & 0.3584 & 0.899 \\\\\n",
      "\t\tJindal et al. \\cite{neurlux} & 0.3969 & 0.6949 & 0.5527 & 0.923 \\\\\n",
      "\t\tTrizna \\cite{quoVadis} & 0.5385 & 0.7659 & 0.6861 & 0.9398 \\\\\n",
      "\t\tOurs (BPE) & 0.6154 & 0.804 & 0.7421 & 0.9476 \\\\\n",
      "\t\t\\midrule\n",
      "\t\t\\multicolumn{5}{c}{Rat} \\\\\n",
      "\t\t\\midrule\n",
      "\t\tZhang et al. \\cite{zhang_dmds} & 0.0099 & 0.4999 & 0.0 & 0.9276 \\\\\n",
      "\t\tJindal et al. \\cite{neurlux} & 0.5044 & 0.7495 & 0.6625 & 0.9632 \\\\\n",
      "\t\tTrizna \\cite{quoVadis} & 0.0598 & 0.5326 & 0.1195 & 0.9245 \\\\\n",
      "\t\tOurs (BPE) & 0.2425 & 0.6171 & 0.3683 & 0.9426 \\\\\n",
      "\t\t\\midrule\n",
      "\t\t\\multicolumn{5}{c}{Trojan} \\\\\n",
      "\t\t\\midrule\n",
      "\t\tZhang et al. \\cite{zhang_dmds} & 0.1483 & 0.7705 & 0.5282 & 0.9355 \\\\\n",
      "\t\tJindal et al. \\cite{neurlux} & 0.3087 & 0.8254 & 0.6153 & 0.9426 \\\\\n",
      "\t\tTrizna \\cite{quoVadis} & 0.1656 & 0.7674 & 0.5359 & 0.9386 \\\\\n",
      "\t\tOurs (BPE) & 0.2413 & 0.8688 & 0.6827 & 0.9551 \\\\\n",
      "\t\t\\midrule\n"
     ]
    }
   ],
   "source": [
    "print_latex_table(multiclass_speakeasy_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "avast_test = \"\"\"Adload\n",
    "               0.001       AUC        F1    Recall  Precision  Accuracy\n",
    "nebula_bpe  0.544652  0.865998  0.439000  0.733333   0.451754  0.998546\n",
    "nebula_wht  0.824753  0.966390  0.697531  0.933333   0.647186  0.999418\n",
    "neurlux     0.731407  0.999142  0.714976  1.000000   0.692708  0.998284\n",
    "Emotet\n",
    "               0.001       AUC        F1    Recall  Precision  Accuracy\n",
    "nebula_bpe  0.180619  0.945309  0.939160  0.895910   0.986935  0.964294\n",
    "nebula_wht  0.453669  0.938136  0.931919  0.880136   0.990376  0.960427\n",
    "neurlux     0.724392  0.934505  0.929410  0.869935   0.997615  0.959322\n",
    "HarHar\n",
    "               0.001       AUC        F1    Recall  Precision  Accuracy\n",
    "nebula_bpe  0.666984  0.833319  0.776261  0.666667   0.989583  0.997965\n",
    "nebula_wht  0.739391  0.869565  0.836308  0.739130   1.000000  0.998430\n",
    "neurlux     0.869652  0.934666  0.903125  0.869565   0.953704  0.998982\n",
    "Lokibot\n",
    "               0.001       AUC        F1    Recall  Precision  Accuracy\n",
    "nebula_bpe  0.158345  0.949921  0.895719  0.907543   0.886545  0.987235\n",
    "nebula_wht  0.280204  0.956112  0.904769  0.919708   0.896324  0.988166\n",
    "neurlux     0.069670  0.943042  0.831987  0.903650   0.774374  0.977727\n",
    "Qakbot\n",
    "               0.001       AUC        F1    Recall  Precision  Accuracy\n",
    "nebula_bpe  0.983898  0.991792  0.987645  0.983885   0.991573  0.999157\n",
    "nebula_wht  0.750479  0.995476  0.976850  0.992366   0.962210  0.998372\n",
    "neurlux     0.417193  0.994472  0.931980  0.994063   0.880955  0.994853\n",
    "Swisyn\n",
    "               0.001       AUC        F1    Recall  Precision  Accuracy\n",
    "nebula_bpe  0.739623  0.997788  0.997263  0.997103   0.997428  0.997965\n",
    "nebula_wht  0.997184  0.998475  0.998393  0.997182   0.999608  0.998808\n",
    "neurlux     0.998670  0.999173  0.999060  0.998669   0.999452  0.999302\n",
    "Trickbot\n",
    "               0.001       AUC        F1    Recall  Precision  Accuracy\n",
    "nebula_bpe  0.057277  0.974917  0.922726  0.966816   0.882631  0.981129\n",
    "nebula_wht  0.038899  0.981101  0.905574  0.987774   0.836151  0.975983\n",
    "neurlux     0.113719  0.981093  0.953570  0.970808   0.936949  0.988980\n",
    "Ursnif\n",
    "               0.001       AUC        F1    Recall  Precision  Accuracy\n",
    "nebula_bpe  0.730695  0.953167  0.936244  0.907703   0.968785  0.994650\n",
    "nebula_wht  0.787486  0.968366  0.958477  0.937583   0.980967  0.996453\n",
    "neurlux     0.828745  0.913993  0.890989  0.828685   0.981508  0.991829\n",
    "Zeus\n",
    "               0.001       AUC        F1    Recall  Precision  Accuracy\n",
    "nebula_bpe  0.100721  0.917021  0.641870  0.844907   0.533110  0.987323\n",
    "nebula_wht  0.100031  0.919224  0.669049  0.847222   0.554419  0.989416\n",
    "neurlux     0.081057  0.953675  0.650305  0.918981   0.504552  0.987497\n",
    "njRAT\n",
    "               0.001       AUC        F1    Recall  Precision  Accuracy\n",
    "nebula_bpe  0.077985  0.974453  0.865629  0.961940   0.788423  0.985782\n",
    "nebula_wht  0.126338  0.971604  0.889586  0.952732   0.837892  0.988689\n",
    "neurlux     0.063269  0.982690  0.847869  0.982198   0.747500  0.983136\"\"\"\n",
    "\n",
    "avast_val = \"\"\"Adload\n",
    "               0.001       AUC        F1    Recall  Precision  Accuracy\n",
    "nebula_bpe  0.968565  0.983976  0.968495  0.968549   0.968728  0.998827\n",
    "nebula_wht  0.976790  0.988118  0.973789  0.976779   0.971022  0.999040\n",
    "neurlux     0.992710  0.996324  0.995014  0.992702   0.997354  0.999813\n",
    "Emotet\n",
    "               0.001       AUC        F1    Recall  Precision  Accuracy\n",
    "nebula_bpe  0.457241  0.996211  0.993550  0.996143   0.990996  0.996241\n",
    "nebula_wht  0.260138  0.995812  0.992915  0.995685   0.990169  0.995868\n",
    "neurlux     0.732856  0.996760  0.995727  0.994949   0.996508  0.997521\n",
    "HarHar\n",
    "               0.001       AUC        F1    Recall  Precision  Accuracy\n",
    "nebula_bpe  0.996478  0.998183  0.994955  0.996475   0.993460  0.999840\n",
    "nebula_wht  0.996478  0.998197  0.995791  0.996475   0.995127  0.999867\n",
    "neurlux     1.000000  0.999959  0.997522  1.000000   0.995064  0.999920\n",
    "Lokibot\n",
    "               0.001       AUC        F1    Recall  Precision  Accuracy\n",
    "nebula_bpe  0.323075  0.972931  0.956487  0.949597   0.963805  0.991896\n",
    "nebula_wht  0.265549  0.978126  0.959456  0.960609   0.958683  0.992402\n",
    "neurlux     0.528968  0.980991  0.972687  0.963835   0.981717  0.994935\n",
    "Qakbot\n",
    "               0.001       AUC        F1    Recall  Precision  Accuracy\n",
    "nebula_bpe  0.986901  0.993250  0.991963  0.986893   0.997091  0.998081\n",
    "nebula_wht  0.838728  0.993428  0.990575  0.987766   0.993419  0.997734\n",
    "neurlux     0.994640  0.997092  0.995648  0.994638   0.996660  0.998960\n",
    "Swisyn\n",
    "               0.001       AUC        F1    Recall  Precision  Accuracy\n",
    "nebula_bpe  0.997239  0.998532  0.998317  0.997236   0.999403  0.999254\n",
    "nebula_wht  0.997844  0.998887  0.998799  0.997842   0.999759  0.999467\n",
    "neurlux     0.999029  0.999445  0.999274  0.999028   0.999522  0.999680\n",
    "Trickbot\n",
    "               0.001       AUC        F1    Recall  Precision  Accuracy\n",
    "nebula_bpe  0.661966  0.991297  0.982452  0.984211   0.980761  0.997308\n",
    "nebula_wht  0.544557  0.992830  0.981291  0.987798   0.974914  0.997094\n",
    "neurlux     0.608627  0.995354  0.985970  0.992411   0.979628  0.997841\n",
    "Ursnif\n",
    "               0.001       AUC        F1    Recall  Precision  Accuracy\n",
    "nebula_bpe  0.734649  0.943527  0.917978  0.888146   0.950847  0.996428\n",
    "nebula_wht  0.856959  0.956245  0.940655  0.913144   0.970055  0.997414\n",
    "neurlux     0.952429  0.976061  0.969756  0.952394   0.987866  0.998667\n",
    "Zeus\n",
    "               0.001       AUC        F1    Recall  Precision  Accuracy\n",
    "nebula_bpe  0.359265  0.963793  0.941133  0.930953   0.951817  0.992349\n",
    "nebula_wht  0.401610  0.966278  0.947365  0.935294   0.960194  0.993229\n",
    "neurlux     0.422805  0.981658  0.966280  0.965627   0.966955  0.995601\n",
    "njRAT\n",
    "               0.001       AUC        F1    Recall  Precision  Accuracy\n",
    "nebula_bpe  0.134713  0.974953  0.932903  0.957658   0.910170  0.989630\n",
    "nebula_wht  0.232811  0.972745  0.945043  0.950539   0.940385  0.991629\n",
    "neurlux     0.233042  0.985759  0.960608  0.976071   0.945828  0.993975\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_latex_table(avast_test, shuffle_speakeasy=False, chunk=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\\multicolumn{5}{c}{Adload} \\\\\n",
      "\t\t\\midrule\n",
      "\t\tJindal et al. \\cite{neurlux} & 0.9927 & 0.9963 & 0.995 & 0.9998 \\\\\n",
      "\t\tOurs (BPE) & 0.9686 & 0.984 & 0.9685 & 0.9988 \\\\\n",
      "\t\tOurs (whtsp.) & 0.9768 & 0.9881 & 0.9738 & 0.999 \\\\\n",
      "\t\t\\midrule\n",
      "\t\t\\multicolumn{5}{c}{Emotet} \\\\\n",
      "\t\t\\midrule\n",
      "\t\tJindal et al. \\cite{neurlux} & 0.7329 & 0.9968 & 0.9957 & 0.9975 \\\\\n",
      "\t\tOurs (BPE) & 0.4572 & 0.9962 & 0.9936 & 0.9962 \\\\\n",
      "\t\tOurs (whtsp.) & 0.2601 & 0.9958 & 0.9929 & 0.9959 \\\\\n",
      "\t\t\\midrule\n",
      "\t\t\\multicolumn{5}{c}{Harhar} \\\\\n",
      "\t\t\\midrule\n",
      "\t\tJindal et al. \\cite{neurlux} & 1.0 & 1.0 & 0.9975 & 0.9999 \\\\\n",
      "\t\tOurs (BPE) & 0.9965 & 0.9982 & 0.995 & 0.9998 \\\\\n",
      "\t\tOurs (whtsp.) & 0.9965 & 0.9982 & 0.9958 & 0.9999 \\\\\n",
      "\t\t\\midrule\n",
      "\t\t\\multicolumn{5}{c}{Lokibot} \\\\\n",
      "\t\t\\midrule\n",
      "\t\tJindal et al. \\cite{neurlux} & 0.529 & 0.981 & 0.9727 & 0.9949 \\\\\n",
      "\t\tOurs (BPE) & 0.3231 & 0.9729 & 0.9565 & 0.9919 \\\\\n",
      "\t\tOurs (whtsp.) & 0.2655 & 0.9781 & 0.9595 & 0.9924 \\\\\n",
      "\t\t\\midrule\n",
      "\t\t\\multicolumn{5}{c}{Qakbot} \\\\\n",
      "\t\t\\midrule\n",
      "\t\tJindal et al. \\cite{neurlux} & 0.9946 & 0.9971 & 0.9956 & 0.999 \\\\\n",
      "\t\tOurs (BPE) & 0.9869 & 0.9932 & 0.992 & 0.9981 \\\\\n",
      "\t\tOurs (whtsp.) & 0.8387 & 0.9934 & 0.9906 & 0.9977 \\\\\n",
      "\t\t\\midrule\n",
      "\t\t\\multicolumn{5}{c}{Swisyn} \\\\\n",
      "\t\t\\midrule\n",
      "\t\tJindal et al. \\cite{neurlux} & 0.999 & 0.9994 & 0.9993 & 0.9997 \\\\\n",
      "\t\tOurs (BPE) & 0.9972 & 0.9985 & 0.9983 & 0.9993 \\\\\n",
      "\t\tOurs (whtsp.) & 0.9978 & 0.9989 & 0.9988 & 0.9995 \\\\\n",
      "\t\t\\midrule\n",
      "\t\t\\multicolumn{5}{c}{Trickbot} \\\\\n",
      "\t\t\\midrule\n",
      "\t\tJindal et al. \\cite{neurlux} & 0.6086 & 0.9954 & 0.986 & 0.9978 \\\\\n",
      "\t\tOurs (BPE) & 0.662 & 0.9913 & 0.9825 & 0.9973 \\\\\n",
      "\t\tOurs (whtsp.) & 0.5446 & 0.9928 & 0.9813 & 0.9971 \\\\\n",
      "\t\t\\midrule\n",
      "\t\t\\multicolumn{5}{c}{Ursnif} \\\\\n",
      "\t\t\\midrule\n",
      "\t\tJindal et al. \\cite{neurlux} & 0.9524 & 0.9761 & 0.9698 & 0.9987 \\\\\n",
      "\t\tOurs (BPE) & 0.7346 & 0.9435 & 0.918 & 0.9964 \\\\\n",
      "\t\tOurs (whtsp.) & 0.857 & 0.9562 & 0.9407 & 0.9974 \\\\\n",
      "\t\t\\midrule\n",
      "\t\t\\multicolumn{5}{c}{Zeus} \\\\\n",
      "\t\t\\midrule\n",
      "\t\tJindal et al. \\cite{neurlux} & 0.4228 & 0.9817 & 0.9663 & 0.9956 \\\\\n",
      "\t\tOurs (BPE) & 0.3593 & 0.9638 & 0.9411 & 0.9923 \\\\\n",
      "\t\tOurs (whtsp.) & 0.4016 & 0.9663 & 0.9474 & 0.9932 \\\\\n",
      "\t\t\\midrule\n",
      "\t\t\\multicolumn{5}{c}{Njrat} \\\\\n",
      "\t\t\\midrule\n",
      "\t\tJindal et al. \\cite{neurlux} & 0.233 & 0.9858 & 0.9606 & 0.994 \\\\\n",
      "\t\tOurs (BPE) & 0.1347 & 0.975 & 0.9329 & 0.9896 \\\\\n",
      "\t\tOurs (whtsp.) & 0.2328 & 0.9727 & 0.945 & 0.9916 \\\\\n",
      "\t\t\\midrule\n"
     ]
    }
   ],
   "source": [
    "print_latex_table(avast_val, shuffle_speakeasy=False, chunk=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
