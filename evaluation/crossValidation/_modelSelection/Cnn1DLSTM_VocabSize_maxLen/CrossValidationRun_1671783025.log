WARNING:root: [!] Using vocabSize: 1000 | maxLen: 2048
WARNING:root: [!] Using device: cuda:0 | Dataset size: 91096
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 1000, 'embeddingDim': 64, 'lstmHidden': 128, 'lstmLayers': 1, 'lstmDropout': 0, 'lstmBidirectional': True, 'batchNormConv': False, 'hiddenNeurons': [256, 128], 'batchNormFFNN': False}
WARNING:root: [!] Fold 1/3 | Train set size: 60730, Validation set size: 30366
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 09:10:29 2022: Train Epoch: 1 [  0  /60730 (0 %)]	Loss: 0.678621 | F1-score: 0.90 | Elapsed: 1.03s
WARNING:root: [*] Fri Dec 23 09:10:38 2022: Train Epoch: 1 [6400 /60730 (11%)]	Loss: 0.358989 | F1-score: 0.91 | Elapsed: 8.85s
WARNING:root: [*] Fri Dec 23 09:10:46 2022: Train Epoch: 1 [12800/60730 (21%)]	Loss: 0.129698 | F1-score: 0.93 | Elapsed: 8.63s
WARNING:root: [*] Fri Dec 23 09:10:55 2022: Train Epoch: 1 [19200/60730 (32%)]	Loss: 0.169655 | F1-score: 0.94 | Elapsed: 8.67s
WARNING:root: [*] Fri Dec 23 09:11:04 2022: Train Epoch: 1 [25600/60730 (42%)]	Loss: 0.098332 | F1-score: 0.94 | Elapsed: 8.67s
WARNING:root: [*] Fri Dec 23 09:11:12 2022: Train Epoch: 1 [32000/60730 (53%)]	Loss: 0.198402 | F1-score: 0.94 | Elapsed: 8.62s
WARNING:root: [*] Fri Dec 23 09:11:21 2022: Train Epoch: 1 [38400/60730 (63%)]	Loss: 0.091226 | F1-score: 0.95 | Elapsed: 8.69s
WARNING:root: [*] Fri Dec 23 09:11:30 2022: Train Epoch: 1 [44800/60730 (74%)]	Loss: 0.330406 | F1-score: 0.95 | Elapsed: 8.75s
WARNING:root: [*] Fri Dec 23 09:11:38 2022: Train Epoch: 1 [51200/60730 (84%)]	Loss: 0.110915 | F1-score: 0.95 | Elapsed: 8.71s
WARNING:root: [*] Fri Dec 23 09:11:47 2022: Train Epoch: 1 [57600/60730 (95%)]	Loss: 0.094521 | F1-score: 0.95 | Elapsed: 8.74s
WARNING:root: [*] Fri Dec 23 09:11:51 2022:    1    | Tr.loss: 0.185136 | Tr.F1.:   0.95    |   83.53  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 09:11:51 2022: Train Epoch: 2 [  0  /60730 (0 %)]	Loss: 0.071703 | F1-score: 0.98 | Elapsed: 0.10s
WARNING:root: [*] Fri Dec 23 09:12:00 2022: Train Epoch: 2 [6400 /60730 (11%)]	Loss: 0.121788 | F1-score: 0.97 | Elapsed: 8.69s
WARNING:root: [*] Fri Dec 23 09:12:09 2022: Train Epoch: 2 [12800/60730 (21%)]	Loss: 0.198898 | F1-score: 0.97 | Elapsed: 8.76s
WARNING:root: [*] Fri Dec 23 09:12:18 2022: Train Epoch: 2 [19200/60730 (32%)]	Loss: 0.186767 | F1-score: 0.97 | Elapsed: 8.83s
WARNING:root: [*] Fri Dec 23 09:12:26 2022: Train Epoch: 2 [25600/60730 (42%)]	Loss: 0.121163 | F1-score: 0.97 | Elapsed: 8.81s
WARNING:root: [*] Fri Dec 23 09:12:35 2022: Train Epoch: 2 [32000/60730 (53%)]	Loss: 0.085549 | F1-score: 0.97 | Elapsed: 8.75s
WARNING:root: [*] Fri Dec 23 09:12:44 2022: Train Epoch: 2 [38400/60730 (63%)]	Loss: 0.108848 | F1-score: 0.97 | Elapsed: 8.72s
WARNING:root: [*] Fri Dec 23 09:12:53 2022: Train Epoch: 2 [44800/60730 (74%)]	Loss: 0.098518 | F1-score: 0.97 | Elapsed: 8.78s
WARNING:root: [*] Fri Dec 23 09:13:02 2022: Train Epoch: 2 [51200/60730 (84%)]	Loss: 0.093270 | F1-score: 0.97 | Elapsed: 8.80s
WARNING:root: [*] Fri Dec 23 09:13:10 2022: Train Epoch: 2 [57600/60730 (95%)]	Loss: 0.123840 | F1-score: 0.97 | Elapsed: 8.78s
WARNING:root: [*] Fri Dec 23 09:13:14 2022:    2    | Tr.loss: 0.124576 | Tr.F1.:   0.97    |   83.21  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 09:13:15 2022: Train Epoch: 3 [  0  /60730 (0 %)]	Loss: 0.247469 | F1-score: 0.91 | Elapsed: 0.10s
WARNING:root: [*] Fri Dec 23 09:13:23 2022: Train Epoch: 3 [6400 /60730 (11%)]	Loss: 0.149495 | F1-score: 0.97 | Elapsed: 8.72s
WARNING:root: [*] Fri Dec 23 09:13:32 2022: Train Epoch: 3 [12800/60730 (21%)]	Loss: 0.103371 | F1-score: 0.97 | Elapsed: 8.72s
WARNING:root: [*] Fri Dec 23 09:13:41 2022: Train Epoch: 3 [19200/60730 (32%)]	Loss: 0.048909 | F1-score: 0.97 | Elapsed: 8.70s
WARNING:root: [*] Fri Dec 23 09:13:50 2022: Train Epoch: 3 [25600/60730 (42%)]	Loss: 0.166742 | F1-score: 0.97 | Elapsed: 8.79s
WARNING:root: [*] Fri Dec 23 09:13:58 2022: Train Epoch: 3 [32000/60730 (53%)]	Loss: 0.069812 | F1-score: 0.97 | Elapsed: 8.84s
WARNING:root: [*] Fri Dec 23 09:14:07 2022: Train Epoch: 3 [38400/60730 (63%)]	Loss: 0.104098 | F1-score: 0.97 | Elapsed: 8.77s
WARNING:root: [*] Fri Dec 23 09:14:16 2022: Train Epoch: 3 [44800/60730 (74%)]	Loss: 0.233488 | F1-score: 0.97 | Elapsed: 8.72s
WARNING:root: [*] Fri Dec 23 09:14:25 2022: Train Epoch: 3 [51200/60730 (84%)]	Loss: 0.264339 | F1-score: 0.97 | Elapsed: 8.76s
WARNING:root: [*] Fri Dec 23 09:14:33 2022: Train Epoch: 3 [57600/60730 (95%)]	Loss: 0.075488 | F1-score: 0.97 | Elapsed: 8.81s
WARNING:root: [*] Fri Dec 23 09:14:38 2022:    3    | Tr.loss: 0.113409 | Tr.F1.:   0.97    |   83.13  s
WARNING:root:
        [!] Fri Dec 23 09:14:38 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671783278-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671783278-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671783278-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671783278-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 60731, Validation set size: 30365
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 09:14:53 2022: Train Epoch: 1 [  0  /60731 (0 %)]	Loss: 0.679666 | F1-score: 0.84 | Elapsed: 0.10s
WARNING:root: [*] Fri Dec 23 09:15:02 2022: Train Epoch: 1 [6400 /60731 (11%)]	Loss: 0.227476 | F1-score: 0.91 | Elapsed: 8.76s
WARNING:root: [*] Fri Dec 23 09:15:11 2022: Train Epoch: 1 [12800/60731 (21%)]	Loss: 0.180737 | F1-score: 0.93 | Elapsed: 8.75s
WARNING:root: [*] Fri Dec 23 09:15:20 2022: Train Epoch: 1 [19200/60731 (32%)]	Loss: 0.132747 | F1-score: 0.94 | Elapsed: 8.77s
WARNING:root: [*] Fri Dec 23 09:15:28 2022: Train Epoch: 1 [25600/60731 (42%)]	Loss: 0.180904 | F1-score: 0.94 | Elapsed: 8.78s
WARNING:root: [*] Fri Dec 23 09:15:37 2022: Train Epoch: 1 [32000/60731 (53%)]	Loss: 0.179562 | F1-score: 0.95 | Elapsed: 8.77s
WARNING:root: [*] Fri Dec 23 09:15:46 2022: Train Epoch: 1 [38400/60731 (63%)]	Loss: 0.117619 | F1-score: 0.95 | Elapsed: 8.83s
WARNING:root: [*] Fri Dec 23 09:15:55 2022: Train Epoch: 1 [44800/60731 (74%)]	Loss: 0.078749 | F1-score: 0.95 | Elapsed: 8.89s
WARNING:root: [*] Fri Dec 23 09:16:04 2022: Train Epoch: 1 [51200/60731 (84%)]	Loss: 0.163539 | F1-score: 0.95 | Elapsed: 8.87s
WARNING:root: [*] Fri Dec 23 09:16:13 2022: Train Epoch: 1 [57600/60731 (95%)]	Loss: 0.116241 | F1-score: 0.95 | Elapsed: 8.84s
WARNING:root: [*] Fri Dec 23 09:16:17 2022:    1    | Tr.loss: 0.185433 | Tr.F1.:   0.95    |   83.58  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 09:16:17 2022: Train Epoch: 2 [  0  /60731 (0 %)]	Loss: 0.100139 | F1-score: 0.94 | Elapsed: 0.11s
WARNING:root: [*] Fri Dec 23 09:16:26 2022: Train Epoch: 2 [6400 /60731 (11%)]	Loss: 0.103144 | F1-score: 0.97 | Elapsed: 8.85s
WARNING:root: [*] Fri Dec 23 09:16:35 2022: Train Epoch: 2 [12800/60731 (21%)]	Loss: 0.132758 | F1-score: 0.97 | Elapsed: 8.98s
WARNING:root: [*] Fri Dec 23 09:16:44 2022: Train Epoch: 2 [19200/60731 (32%)]	Loss: 0.312007 | F1-score: 0.97 | Elapsed: 8.87s
WARNING:root: [*] Fri Dec 23 09:16:53 2022: Train Epoch: 2 [25600/60731 (42%)]	Loss: 0.086918 | F1-score: 0.97 | Elapsed: 8.83s
WARNING:root: [*] Fri Dec 23 09:17:01 2022: Train Epoch: 2 [32000/60731 (53%)]	Loss: 0.221877 | F1-score: 0.97 | Elapsed: 8.90s
WARNING:root: [*] Fri Dec 23 09:17:10 2022: Train Epoch: 2 [38400/60731 (63%)]	Loss: 0.124126 | F1-score: 0.97 | Elapsed: 8.88s
WARNING:root: [*] Fri Dec 23 09:17:19 2022: Train Epoch: 2 [44800/60731 (74%)]	Loss: 0.140688 | F1-score: 0.97 | Elapsed: 8.88s
WARNING:root: [*] Fri Dec 23 09:17:28 2022: Train Epoch: 2 [51200/60731 (84%)]	Loss: 0.045069 | F1-score: 0.97 | Elapsed: 8.82s
WARNING:root: [*] Fri Dec 23 09:17:37 2022: Train Epoch: 2 [57600/60731 (95%)]	Loss: 0.131417 | F1-score: 0.97 | Elapsed: 8.81s
WARNING:root: [*] Fri Dec 23 09:17:41 2022:    2    | Tr.loss: 0.124517 | Tr.F1.:   0.97    |   84.20  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 09:17:41 2022: Train Epoch: 3 [  0  /60731 (0 %)]	Loss: 0.085966 | F1-score: 0.99 | Elapsed: 0.09s
WARNING:root: [*] Fri Dec 23 09:17:50 2022: Train Epoch: 3 [6400 /60731 (11%)]	Loss: 0.131401 | F1-score: 0.97 | Elapsed: 8.92s
WARNING:root: [*] Fri Dec 23 09:17:59 2022: Train Epoch: 3 [12800/60731 (21%)]	Loss: 0.188778 | F1-score: 0.97 | Elapsed: 8.82s
WARNING:root: [*] Fri Dec 23 09:18:08 2022: Train Epoch: 3 [19200/60731 (32%)]	Loss: 0.138961 | F1-score: 0.97 | Elapsed: 8.84s
WARNING:root: [*] Fri Dec 23 09:18:17 2022: Train Epoch: 3 [25600/60731 (42%)]	Loss: 0.159104 | F1-score: 0.97 | Elapsed: 8.82s
WARNING:root: [*] Fri Dec 23 09:18:25 2022: Train Epoch: 3 [32000/60731 (53%)]	Loss: 0.189994 | F1-score: 0.97 | Elapsed: 8.76s
WARNING:root: [*] Fri Dec 23 09:18:34 2022: Train Epoch: 3 [38400/60731 (63%)]	Loss: 0.110546 | F1-score: 0.97 | Elapsed: 8.78s
WARNING:root: [*] Fri Dec 23 09:18:43 2022: Train Epoch: 3 [44800/60731 (74%)]	Loss: 0.090184 | F1-score: 0.97 | Elapsed: 8.76s
WARNING:root: [*] Fri Dec 23 09:18:52 2022: Train Epoch: 3 [51200/60731 (84%)]	Loss: 0.067991 | F1-score: 0.97 | Elapsed: 8.74s
WARNING:root: [*] Fri Dec 23 09:19:00 2022: Train Epoch: 3 [57600/60731 (95%)]	Loss: 0.076282 | F1-score: 0.97 | Elapsed: 8.81s
WARNING:root: [*] Fri Dec 23 09:19:05 2022:    3    | Tr.loss: 0.115262 | Tr.F1.:   0.97    |   83.62  s
WARNING:root:
        [!] Fri Dec 23 09:19:05 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671783545-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671783545-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671783545-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671783545-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 60731, Validation set size: 30365
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 09:19:21 2022: Train Epoch: 1 [  0  /60731 (0 %)]	Loss: 0.697294 | F1-score: 0.27 | Elapsed: 0.09s
WARNING:root: [*] Fri Dec 23 09:19:29 2022: Train Epoch: 1 [6400 /60731 (11%)]	Loss: 0.164200 | F1-score: 0.91 | Elapsed: 8.78s
WARNING:root: [*] Fri Dec 23 09:19:38 2022: Train Epoch: 1 [12800/60731 (21%)]	Loss: 0.308624 | F1-score: 0.93 | Elapsed: 8.80s
WARNING:root: [*] Fri Dec 23 09:19:47 2022: Train Epoch: 1 [19200/60731 (32%)]	Loss: 0.132163 | F1-score: 0.94 | Elapsed: 8.76s
WARNING:root: [*] Fri Dec 23 09:19:56 2022: Train Epoch: 1 [25600/60731 (42%)]	Loss: 0.121647 | F1-score: 0.94 | Elapsed: 8.77s
WARNING:root: [*] Fri Dec 23 09:20:04 2022: Train Epoch: 1 [32000/60731 (53%)]	Loss: 0.102736 | F1-score: 0.95 | Elapsed: 8.76s
WARNING:root: [*] Fri Dec 23 09:20:13 2022: Train Epoch: 1 [38400/60731 (63%)]	Loss: 0.162839 | F1-score: 0.95 | Elapsed: 8.81s
WARNING:root: [*] Fri Dec 23 09:20:22 2022: Train Epoch: 1 [44800/60731 (74%)]	Loss: 0.295859 | F1-score: 0.95 | Elapsed: 8.81s
WARNING:root: [*] Fri Dec 23 09:20:31 2022: Train Epoch: 1 [51200/60731 (84%)]	Loss: 0.105212 | F1-score: 0.95 | Elapsed: 8.77s
WARNING:root: [*] Fri Dec 23 09:20:40 2022: Train Epoch: 1 [57600/60731 (95%)]	Loss: 0.173138 | F1-score: 0.95 | Elapsed: 8.80s
WARNING:root: [*] Fri Dec 23 09:20:44 2022:    1    | Tr.loss: 0.181078 | Tr.F1.:   0.95    |   83.34  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 09:20:44 2022: Train Epoch: 2 [  0  /60731 (0 %)]	Loss: 0.099866 | F1-score: 0.98 | Elapsed: 0.10s
WARNING:root: [*] Fri Dec 23 09:20:53 2022: Train Epoch: 2 [6400 /60731 (11%)]	Loss: 0.065821 | F1-score: 0.96 | Elapsed: 8.80s
WARNING:root: [*] Fri Dec 23 09:21:02 2022: Train Epoch: 2 [12800/60731 (21%)]	Loss: 0.159969 | F1-score: 0.97 | Elapsed: 8.78s
WARNING:root: [*] Fri Dec 23 09:21:10 2022: Train Epoch: 2 [19200/60731 (32%)]	Loss: 0.095310 | F1-score: 0.97 | Elapsed: 8.77s
WARNING:root: [*] Fri Dec 23 09:21:19 2022: Train Epoch: 2 [25600/60731 (42%)]	Loss: 0.213184 | F1-score: 0.97 | Elapsed: 8.74s
WARNING:root: [*] Fri Dec 23 09:21:28 2022: Train Epoch: 2 [32000/60731 (53%)]	Loss: 0.068454 | F1-score: 0.97 | Elapsed: 8.74s
WARNING:root: [*] Fri Dec 23 09:21:37 2022: Train Epoch: 2 [38400/60731 (63%)]	Loss: 0.151570 | F1-score: 0.97 | Elapsed: 8.79s
WARNING:root: [*] Fri Dec 23 09:21:45 2022: Train Epoch: 2 [44800/60731 (74%)]	Loss: 0.063118 | F1-score: 0.97 | Elapsed: 8.80s
WARNING:root: [*] Fri Dec 23 09:21:54 2022: Train Epoch: 2 [51200/60731 (84%)]	Loss: 0.120032 | F1-score: 0.97 | Elapsed: 8.75s
WARNING:root: [*] Fri Dec 23 09:22:03 2022: Train Epoch: 2 [57600/60731 (95%)]	Loss: 0.052449 | F1-score: 0.97 | Elapsed: 8.77s
WARNING:root: [*] Fri Dec 23 09:22:07 2022:    2    | Tr.loss: 0.124483 | Tr.F1.:   0.97    |   83.24  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 09:22:07 2022: Train Epoch: 3 [  0  /60731 (0 %)]	Loss: 0.105331 | F1-score: 0.99 | Elapsed: 0.10s
WARNING:root: [*] Fri Dec 23 09:22:16 2022: Train Epoch: 3 [6400 /60731 (11%)]	Loss: 0.049099 | F1-score: 0.97 | Elapsed: 8.75s
WARNING:root: [*] Fri Dec 23 09:22:25 2022: Train Epoch: 3 [12800/60731 (21%)]	Loss: 0.077943 | F1-score: 0.97 | Elapsed: 8.76s
WARNING:root: [*] Fri Dec 23 09:22:33 2022: Train Epoch: 3 [19200/60731 (32%)]	Loss: 0.263513 | F1-score: 0.97 | Elapsed: 8.78s
WARNING:root: [*] Fri Dec 23 09:22:42 2022: Train Epoch: 3 [25600/60731 (42%)]	Loss: 0.188188 | F1-score: 0.97 | Elapsed: 8.75s
WARNING:root: [*] Fri Dec 23 09:22:51 2022: Train Epoch: 3 [32000/60731 (53%)]	Loss: 0.250579 | F1-score: 0.97 | Elapsed: 8.74s
WARNING:root: [*] Fri Dec 23 09:23:00 2022: Train Epoch: 3 [38400/60731 (63%)]	Loss: 0.185440 | F1-score: 0.97 | Elapsed: 8.78s
WARNING:root: [*] Fri Dec 23 09:23:08 2022: Train Epoch: 3 [44800/60731 (74%)]	Loss: 0.151985 | F1-score: 0.97 | Elapsed: 8.76s
WARNING:root: [*] Fri Dec 23 09:23:17 2022: Train Epoch: 3 [51200/60731 (84%)]	Loss: 0.069606 | F1-score: 0.97 | Elapsed: 8.74s
WARNING:root: [*] Fri Dec 23 09:23:26 2022: Train Epoch: 3 [57600/60731 (95%)]	Loss: 0.201533 | F1-score: 0.97 | Elapsed: 8.80s
WARNING:root: [*] Fri Dec 23 09:23:30 2022:    3    | Tr.loss: 0.115031 | Tr.F1.:   0.97    |   83.15  s
WARNING:root:
        [!] Fri Dec 23 09:23:30 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671783810-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671783810-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671783810-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671783810-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\metrics_trainSize_91096_ep_3_cv_3_maxLen_2048_vocabSize_1000_embeddingDim_64_lstmHidden_128_lstmLayers_1_lstmDropout_0_lstmBidirectional_True_batchNormConv_False_hiddenNeurons_256_128_batchNormFFNN_False.json
WARNING:root: [!] Average epoch time: 83.44s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.2586 -- F1: 0.3817
	FPR:  0.001 -- TPR: 0.6464 -- F1: 0.7850
	FPR:   0.01 -- TPR: 0.6970 -- F1: 0.8199
	FPR:    0.1 -- TPR: 0.9805 -- F1: 0.9715

WARNING:root: [!] Using vocabSize: 1000 | maxLen: 512
WARNING:root: [!] Using device: cuda:0 | Dataset size: 91096
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 1000, 'embeddingDim': 64, 'lstmHidden': 128, 'lstmLayers': 1, 'lstmDropout': 0, 'lstmBidirectional': True, 'batchNormConv': False, 'hiddenNeurons': [256, 128], 'batchNormFFNN': False}
WARNING:root: [!] Fold 1/3 | Train set size: 60730, Validation set size: 30366
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 09:24:16 2022: Train Epoch: 1 [  0  /60730 (0 %)]	Loss: 0.715298 | F1-score: 0.00 | Elapsed: 0.25s
WARNING:root: [*] Fri Dec 23 09:24:19 2022: Train Epoch: 1 [6400 /60730 (11%)]	Loss: 0.212682 | F1-score: 0.90 | Elapsed: 2.99s
WARNING:root: [*] Fri Dec 23 09:24:22 2022: Train Epoch: 1 [12800/60730 (21%)]	Loss: 0.181086 | F1-score: 0.93 | Elapsed: 2.87s
WARNING:root: [*] Fri Dec 23 09:24:25 2022: Train Epoch: 1 [19200/60730 (32%)]	Loss: 0.159112 | F1-score: 0.93 | Elapsed: 2.85s
WARNING:root: [*] Fri Dec 23 09:24:28 2022: Train Epoch: 1 [25600/60730 (42%)]	Loss: 0.200731 | F1-score: 0.94 | Elapsed: 2.90s
WARNING:root: [*] Fri Dec 23 09:24:31 2022: Train Epoch: 1 [32000/60730 (53%)]	Loss: 0.234763 | F1-score: 0.94 | Elapsed: 2.83s
WARNING:root: [*] Fri Dec 23 09:24:33 2022: Train Epoch: 1 [38400/60730 (63%)]	Loss: 0.160349 | F1-score: 0.94 | Elapsed: 2.84s
WARNING:root: [*] Fri Dec 23 09:24:36 2022: Train Epoch: 1 [44800/60730 (74%)]	Loss: 0.161361 | F1-score: 0.94 | Elapsed: 2.86s
WARNING:root: [*] Fri Dec 23 09:24:39 2022: Train Epoch: 1 [51200/60730 (84%)]	Loss: 0.149559 | F1-score: 0.95 | Elapsed: 2.87s
WARNING:root: [*] Fri Dec 23 09:24:42 2022: Train Epoch: 1 [57600/60730 (95%)]	Loss: 0.161062 | F1-score: 0.95 | Elapsed: 2.90s
WARNING:root: [*] Fri Dec 23 09:24:43 2022:    1    | Tr.loss: 0.197201 | Tr.F1.:   0.95    |   27.52  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 09:24:43 2022: Train Epoch: 2 [  0  /60730 (0 %)]	Loss: 0.140713 | F1-score: 0.96 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 09:24:46 2022: Train Epoch: 2 [6400 /60730 (11%)]	Loss: 0.193357 | F1-score: 0.96 | Elapsed: 2.86s
WARNING:root: [*] Fri Dec 23 09:24:49 2022: Train Epoch: 2 [12800/60730 (21%)]	Loss: 0.174845 | F1-score: 0.96 | Elapsed: 2.80s
WARNING:root: [*] Fri Dec 23 09:24:52 2022: Train Epoch: 2 [19200/60730 (32%)]	Loss: 0.123131 | F1-score: 0.96 | Elapsed: 2.85s
WARNING:root: [*] Fri Dec 23 09:24:55 2022: Train Epoch: 2 [25600/60730 (42%)]	Loss: 0.160780 | F1-score: 0.96 | Elapsed: 2.91s
WARNING:root: [*] Fri Dec 23 09:24:58 2022: Train Epoch: 2 [32000/60730 (53%)]	Loss: 0.156966 | F1-score: 0.96 | Elapsed: 2.88s
WARNING:root: [*] Fri Dec 23 09:25:01 2022: Train Epoch: 2 [38400/60730 (63%)]	Loss: 0.150112 | F1-score: 0.96 | Elapsed: 2.86s
WARNING:root: [*] Fri Dec 23 09:25:04 2022: Train Epoch: 2 [44800/60730 (74%)]	Loss: 0.146501 | F1-score: 0.96 | Elapsed: 2.87s
WARNING:root: [*] Fri Dec 23 09:25:06 2022: Train Epoch: 2 [51200/60730 (84%)]	Loss: 0.130210 | F1-score: 0.96 | Elapsed: 2.86s
WARNING:root: [*] Fri Dec 23 09:25:09 2022: Train Epoch: 2 [57600/60730 (95%)]	Loss: 0.188262 | F1-score: 0.96 | Elapsed: 2.87s
WARNING:root: [*] Fri Dec 23 09:25:11 2022:    2    | Tr.loss: 0.141251 | Tr.F1.:   0.96    |   27.15  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 09:25:11 2022: Train Epoch: 3 [  0  /60730 (0 %)]	Loss: 0.178740 | F1-score: 0.97 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 09:25:14 2022: Train Epoch: 3 [6400 /60730 (11%)]	Loss: 0.276977 | F1-score: 0.96 | Elapsed: 2.87s
WARNING:root: [*] Fri Dec 23 09:25:16 2022: Train Epoch: 3 [12800/60730 (21%)]	Loss: 0.097040 | F1-score: 0.96 | Elapsed: 2.85s
WARNING:root: [*] Fri Dec 23 09:25:19 2022: Train Epoch: 3 [19200/60730 (32%)]	Loss: 0.067834 | F1-score: 0.96 | Elapsed: 2.92s
WARNING:root: [*] Fri Dec 23 09:25:22 2022: Train Epoch: 3 [25600/60730 (42%)]	Loss: 0.154365 | F1-score: 0.96 | Elapsed: 2.91s
WARNING:root: [*] Fri Dec 23 09:25:25 2022: Train Epoch: 3 [32000/60730 (53%)]	Loss: 0.107581 | F1-score: 0.96 | Elapsed: 2.95s
WARNING:root: [*] Fri Dec 23 09:25:28 2022: Train Epoch: 3 [38400/60730 (63%)]	Loss: 0.145316 | F1-score: 0.96 | Elapsed: 2.91s
WARNING:root: [*] Fri Dec 23 09:25:31 2022: Train Epoch: 3 [44800/60730 (74%)]	Loss: 0.123625 | F1-score: 0.96 | Elapsed: 2.96s
WARNING:root: [*] Fri Dec 23 09:25:34 2022: Train Epoch: 3 [51200/60730 (84%)]	Loss: 0.126710 | F1-score: 0.96 | Elapsed: 2.99s
WARNING:root: [*] Fri Dec 23 09:25:37 2022: Train Epoch: 3 [57600/60730 (95%)]	Loss: 0.042333 | F1-score: 0.96 | Elapsed: 3.01s
WARNING:root: [*] Fri Dec 23 09:25:38 2022:    3    | Tr.loss: 0.131273 | Tr.F1.:   0.96    |   27.78  s
WARNING:root:
        [!] Fri Dec 23 09:25:38 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671783938-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671783938-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671783938-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671783938-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 60731, Validation set size: 30365
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 09:25:43 2022: Train Epoch: 1 [  0  /60731 (0 %)]	Loss: 0.694339 | F1-score: 0.55 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 09:25:46 2022: Train Epoch: 1 [6400 /60731 (11%)]	Loss: 0.207303 | F1-score: 0.91 | Elapsed: 2.89s
WARNING:root: [*] Fri Dec 23 09:25:49 2022: Train Epoch: 1 [12800/60731 (21%)]	Loss: 0.155086 | F1-score: 0.93 | Elapsed: 2.84s
WARNING:root: [*] Fri Dec 23 09:25:51 2022: Train Epoch: 1 [19200/60731 (32%)]	Loss: 0.185950 | F1-score: 0.94 | Elapsed: 2.83s
WARNING:root: [*] Fri Dec 23 09:25:54 2022: Train Epoch: 1 [25600/60731 (42%)]	Loss: 0.211765 | F1-score: 0.94 | Elapsed: 2.93s
WARNING:root: [*] Fri Dec 23 09:25:57 2022: Train Epoch: 1 [32000/60731 (53%)]	Loss: 0.270388 | F1-score: 0.94 | Elapsed: 2.81s
WARNING:root: [*] Fri Dec 23 09:26:00 2022: Train Epoch: 1 [38400/60731 (63%)]	Loss: 0.100100 | F1-score: 0.94 | Elapsed: 2.85s
WARNING:root: [*] Fri Dec 23 09:26:03 2022: Train Epoch: 1 [44800/60731 (74%)]	Loss: 0.145594 | F1-score: 0.95 | Elapsed: 2.86s
WARNING:root: [*] Fri Dec 23 09:26:06 2022: Train Epoch: 1 [51200/60731 (84%)]	Loss: 0.161595 | F1-score: 0.95 | Elapsed: 2.87s
WARNING:root: [*] Fri Dec 23 09:26:09 2022: Train Epoch: 1 [57600/60731 (95%)]	Loss: 0.119369 | F1-score: 0.95 | Elapsed: 2.88s
WARNING:root: [*] Fri Dec 23 09:26:10 2022:    1    | Tr.loss: 0.194403 | Tr.F1.:   0.95    |   27.21  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 09:26:10 2022: Train Epoch: 2 [  0  /60731 (0 %)]	Loss: 0.107140 | F1-score: 0.97 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 09:26:13 2022: Train Epoch: 2 [6400 /60731 (11%)]	Loss: 0.141698 | F1-score: 0.96 | Elapsed: 2.93s
WARNING:root: [*] Fri Dec 23 09:26:16 2022: Train Epoch: 2 [12800/60731 (21%)]	Loss: 0.194768 | F1-score: 0.96 | Elapsed: 2.92s
WARNING:root: [*] Fri Dec 23 09:26:19 2022: Train Epoch: 2 [19200/60731 (32%)]	Loss: 0.128832 | F1-score: 0.96 | Elapsed: 2.83s
WARNING:root: [*] Fri Dec 23 09:26:22 2022: Train Epoch: 2 [25600/60731 (42%)]	Loss: 0.060778 | F1-score: 0.96 | Elapsed: 2.87s
WARNING:root: [*] Fri Dec 23 09:26:25 2022: Train Epoch: 2 [32000/60731 (53%)]	Loss: 0.119870 | F1-score: 0.96 | Elapsed: 2.88s
WARNING:root: [*] Fri Dec 23 09:26:27 2022: Train Epoch: 2 [38400/60731 (63%)]	Loss: 0.173431 | F1-score: 0.96 | Elapsed: 2.87s
WARNING:root: [*] Fri Dec 23 09:26:30 2022: Train Epoch: 2 [44800/60731 (74%)]	Loss: 0.070872 | F1-score: 0.96 | Elapsed: 2.81s
WARNING:root: [*] Fri Dec 23 09:26:33 2022: Train Epoch: 2 [51200/60731 (84%)]	Loss: 0.189136 | F1-score: 0.96 | Elapsed: 2.89s
WARNING:root: [*] Fri Dec 23 09:26:36 2022: Train Epoch: 2 [57600/60731 (95%)]	Loss: 0.120625 | F1-score: 0.96 | Elapsed: 2.83s
WARNING:root: [*] Fri Dec 23 09:26:37 2022:    2    | Tr.loss: 0.140772 | Tr.F1.:   0.96    |   27.26  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 09:26:37 2022: Train Epoch: 3 [  0  /60731 (0 %)]	Loss: 0.191978 | F1-score: 0.93 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 09:26:40 2022: Train Epoch: 3 [6400 /60731 (11%)]	Loss: 0.121779 | F1-score: 0.97 | Elapsed: 2.88s
WARNING:root: [*] Fri Dec 23 09:26:43 2022: Train Epoch: 3 [12800/60731 (21%)]	Loss: 0.136303 | F1-score: 0.96 | Elapsed: 2.86s
WARNING:root: [*] Fri Dec 23 09:26:46 2022: Train Epoch: 3 [19200/60731 (32%)]	Loss: 0.065214 | F1-score: 0.96 | Elapsed: 2.87s
WARNING:root: [*] Fri Dec 23 09:26:49 2022: Train Epoch: 3 [25600/60731 (42%)]	Loss: 0.093978 | F1-score: 0.96 | Elapsed: 2.87s
WARNING:root: [*] Fri Dec 23 09:26:52 2022: Train Epoch: 3 [32000/60731 (53%)]	Loss: 0.255607 | F1-score: 0.96 | Elapsed: 2.86s
WARNING:root: [*] Fri Dec 23 09:26:55 2022: Train Epoch: 3 [38400/60731 (63%)]	Loss: 0.146262 | F1-score: 0.96 | Elapsed: 2.84s
WARNING:root: [*] Fri Dec 23 09:26:57 2022: Train Epoch: 3 [44800/60731 (74%)]	Loss: 0.103314 | F1-score: 0.96 | Elapsed: 2.85s
WARNING:root: [*] Fri Dec 23 09:27:00 2022: Train Epoch: 3 [51200/60731 (84%)]	Loss: 0.085436 | F1-score: 0.96 | Elapsed: 2.92s
WARNING:root: [*] Fri Dec 23 09:27:03 2022: Train Epoch: 3 [57600/60731 (95%)]	Loss: 0.132735 | F1-score: 0.96 | Elapsed: 2.94s
WARNING:root: [*] Fri Dec 23 09:27:05 2022:    3    | Tr.loss: 0.131366 | Tr.F1.:   0.96    |   27.27  s
WARNING:root:
        [!] Fri Dec 23 09:27:05 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671784025-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671784025-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671784025-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671784025-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 60731, Validation set size: 30365
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 09:27:09 2022: Train Epoch: 1 [  0  /60731 (0 %)]	Loss: 0.699866 | F1-score: 0.00 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 09:27:12 2022: Train Epoch: 1 [6400 /60731 (11%)]	Loss: 0.331692 | F1-score: 0.90 | Elapsed: 2.89s
WARNING:root: [*] Fri Dec 23 09:27:15 2022: Train Epoch: 1 [12800/60731 (21%)]	Loss: 0.217461 | F1-score: 0.92 | Elapsed: 2.81s
WARNING:root: [*] Fri Dec 23 09:27:18 2022: Train Epoch: 1 [19200/60731 (32%)]	Loss: 0.158184 | F1-score: 0.93 | Elapsed: 2.80s
WARNING:root: [*] Fri Dec 23 09:27:20 2022: Train Epoch: 1 [25600/60731 (42%)]	Loss: 0.106660 | F1-score: 0.94 | Elapsed: 2.82s
WARNING:root: [*] Fri Dec 23 09:27:23 2022: Train Epoch: 1 [32000/60731 (53%)]	Loss: 0.188895 | F1-score: 0.94 | Elapsed: 2.91s
WARNING:root: [*] Fri Dec 23 09:27:26 2022: Train Epoch: 1 [38400/60731 (63%)]	Loss: 0.093879 | F1-score: 0.94 | Elapsed: 2.88s
WARNING:root: [*] Fri Dec 23 09:27:29 2022: Train Epoch: 1 [44800/60731 (74%)]	Loss: 0.188086 | F1-score: 0.94 | Elapsed: 2.86s
WARNING:root: [*] Fri Dec 23 09:27:32 2022: Train Epoch: 1 [51200/60731 (84%)]	Loss: 0.331605 | F1-score: 0.95 | Elapsed: 2.86s
WARNING:root: [*] Fri Dec 23 09:27:35 2022: Train Epoch: 1 [57600/60731 (95%)]	Loss: 0.138116 | F1-score: 0.95 | Elapsed: 2.86s
WARNING:root: [*] Fri Dec 23 09:27:36 2022:    1    | Tr.loss: 0.197527 | Tr.F1.:   0.95    |   27.14  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 09:27:36 2022: Train Epoch: 2 [  0  /60731 (0 %)]	Loss: 0.175042 | F1-score: 0.96 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 09:27:39 2022: Train Epoch: 2 [6400 /60731 (11%)]	Loss: 0.209393 | F1-score: 0.96 | Elapsed: 2.96s
WARNING:root: [*] Fri Dec 23 09:27:42 2022: Train Epoch: 2 [12800/60731 (21%)]	Loss: 0.161451 | F1-score: 0.96 | Elapsed: 2.92s
WARNING:root: [*] Fri Dec 23 09:27:45 2022: Train Epoch: 2 [19200/60731 (32%)]	Loss: 0.151573 | F1-score: 0.96 | Elapsed: 2.90s
WARNING:root: [*] Fri Dec 23 09:27:48 2022: Train Epoch: 2 [25600/60731 (42%)]	Loss: 0.146118 | F1-score: 0.96 | Elapsed: 2.91s
WARNING:root: [*] Fri Dec 23 09:27:51 2022: Train Epoch: 2 [32000/60731 (53%)]	Loss: 0.303593 | F1-score: 0.96 | Elapsed: 2.90s
WARNING:root: [*] Fri Dec 23 09:27:54 2022: Train Epoch: 2 [38400/60731 (63%)]	Loss: 0.095528 | F1-score: 0.96 | Elapsed: 2.87s
WARNING:root: [*] Fri Dec 23 09:27:57 2022: Train Epoch: 2 [44800/60731 (74%)]	Loss: 0.151914 | F1-score: 0.96 | Elapsed: 2.81s
WARNING:root: [*] Fri Dec 23 09:28:00 2022: Train Epoch: 2 [51200/60731 (84%)]	Loss: 0.118463 | F1-score: 0.96 | Elapsed: 2.94s
WARNING:root: [*] Fri Dec 23 09:28:02 2022: Train Epoch: 2 [57600/60731 (95%)]	Loss: 0.168744 | F1-score: 0.96 | Elapsed: 2.90s
WARNING:root: [*] Fri Dec 23 09:28:04 2022:    2    | Tr.loss: 0.143291 | Tr.F1.:   0.96    |   27.56  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 09:28:04 2022: Train Epoch: 3 [  0  /60731 (0 %)]	Loss: 0.206871 | F1-score: 0.96 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 09:28:07 2022: Train Epoch: 3 [6400 /60731 (11%)]	Loss: 0.107491 | F1-score: 0.96 | Elapsed: 2.92s
WARNING:root: [*] Fri Dec 23 09:28:10 2022: Train Epoch: 3 [12800/60731 (21%)]	Loss: 0.128695 | F1-score: 0.96 | Elapsed: 2.91s
WARNING:root: [*] Fri Dec 23 09:28:13 2022: Train Epoch: 3 [19200/60731 (32%)]	Loss: 0.078046 | F1-score: 0.96 | Elapsed: 2.90s
WARNING:root: [*] Fri Dec 23 09:28:15 2022: Train Epoch: 3 [25600/60731 (42%)]	Loss: 0.236852 | F1-score: 0.96 | Elapsed: 2.90s
WARNING:root: [*] Fri Dec 23 09:28:18 2022: Train Epoch: 3 [32000/60731 (53%)]	Loss: 0.111916 | F1-score: 0.96 | Elapsed: 2.89s
WARNING:root: [*] Fri Dec 23 09:28:21 2022: Train Epoch: 3 [38400/60731 (63%)]	Loss: 0.211924 | F1-score: 0.96 | Elapsed: 2.89s
WARNING:root: [*] Fri Dec 23 09:28:24 2022: Train Epoch: 3 [44800/60731 (74%)]	Loss: 0.109567 | F1-score: 0.96 | Elapsed: 2.91s
WARNING:root: [*] Fri Dec 23 09:28:27 2022: Train Epoch: 3 [51200/60731 (84%)]	Loss: 0.145510 | F1-score: 0.96 | Elapsed: 2.88s
WARNING:root: [*] Fri Dec 23 09:28:30 2022: Train Epoch: 3 [57600/60731 (95%)]	Loss: 0.110375 | F1-score: 0.96 | Elapsed: 2.92s
WARNING:root: [*] Fri Dec 23 09:28:31 2022:    3    | Tr.loss: 0.131125 | Tr.F1.:   0.96    |   27.57  s
WARNING:root:
        [!] Fri Dec 23 09:28:31 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671784111-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671784111-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671784111-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671784111-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\metrics_trainSize_91096_ep_3_cv_3_maxLen_512_vocabSize_1000_embeddingDim_64_lstmHidden_128_lstmLayers_1_lstmDropout_0_lstmBidirectional_True_batchNormConv_False_hiddenNeurons_256_128_batchNormFFNN_False.json
WARNING:root: [!] Average epoch time: 27.38s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.1438 -- F1: 0.2314
	FPR:  0.001 -- TPR: 0.6119 -- F1: 0.7589
	FPR:   0.01 -- TPR: 0.6863 -- F1: 0.8128
	FPR:    0.1 -- TPR: 0.9676 -- F1: 0.9655

WARNING:root: [!] Using vocabSize: 1500 | maxLen: 1024
WARNING:root: [!] Using device: cuda:0 | Dataset size: 91096
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 1500, 'embeddingDim': 64, 'lstmHidden': 128, 'lstmLayers': 1, 'lstmDropout': 0, 'lstmBidirectional': True, 'batchNormConv': False, 'hiddenNeurons': [256, 128], 'batchNormFFNN': False}
WARNING:root: [!] Fold 1/3 | Train set size: 60730, Validation set size: 30366
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 09:29:07 2022: Train Epoch: 1 [  0  /60730 (0 %)]	Loss: 0.700414 | F1-score: 0.00 | Elapsed: 0.25s
WARNING:root: [*] Fri Dec 23 09:29:12 2022: Train Epoch: 1 [6400 /60730 (11%)]	Loss: 0.245352 | F1-score: 0.90 | Elapsed: 4.86s
WARNING:root: [*] Fri Dec 23 09:29:16 2022: Train Epoch: 1 [12800/60730 (21%)]	Loss: 0.169548 | F1-score: 0.92 | Elapsed: 4.80s
WARNING:root: [*] Fri Dec 23 09:29:21 2022: Train Epoch: 1 [19200/60730 (32%)]	Loss: 0.213867 | F1-score: 0.93 | Elapsed: 4.88s
WARNING:root: [*] Fri Dec 23 09:29:26 2022: Train Epoch: 1 [25600/60730 (42%)]	Loss: 0.161562 | F1-score: 0.94 | Elapsed: 4.85s
WARNING:root: [*] Fri Dec 23 09:29:31 2022: Train Epoch: 1 [32000/60730 (53%)]	Loss: 0.121315 | F1-score: 0.94 | Elapsed: 4.83s
WARNING:root: [*] Fri Dec 23 09:29:36 2022: Train Epoch: 1 [38400/60730 (63%)]	Loss: 0.128909 | F1-score: 0.94 | Elapsed: 4.82s
WARNING:root: [*] Fri Dec 23 09:29:41 2022: Train Epoch: 1 [44800/60730 (74%)]	Loss: 0.050004 | F1-score: 0.95 | Elapsed: 4.89s
WARNING:root: [*] Fri Dec 23 09:29:45 2022: Train Epoch: 1 [51200/60730 (84%)]	Loss: 0.172069 | F1-score: 0.95 | Elapsed: 4.80s
WARNING:root: [*] Fri Dec 23 09:29:50 2022: Train Epoch: 1 [57600/60730 (95%)]	Loss: 0.171438 | F1-score: 0.95 | Elapsed: 4.94s
WARNING:root: [*] Fri Dec 23 09:29:53 2022:    1    | Tr.loss: 0.185416 | Tr.F1.:   0.95    |   46.31  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 09:29:53 2022: Train Epoch: 2 [  0  /60730 (0 %)]	Loss: 0.140685 | F1-score: 0.97 | Elapsed: 0.05s
WARNING:root: [*] Fri Dec 23 09:29:58 2022: Train Epoch: 2 [6400 /60730 (11%)]	Loss: 0.138334 | F1-score: 0.97 | Elapsed: 4.85s
WARNING:root: [*] Fri Dec 23 09:30:03 2022: Train Epoch: 2 [12800/60730 (21%)]	Loss: 0.109432 | F1-score: 0.97 | Elapsed: 4.83s
WARNING:root: [*] Fri Dec 23 09:30:07 2022: Train Epoch: 2 [19200/60730 (32%)]	Loss: 0.239110 | F1-score: 0.97 | Elapsed: 4.80s
WARNING:root: [*] Fri Dec 23 09:30:12 2022: Train Epoch: 2 [25600/60730 (42%)]	Loss: 0.146850 | F1-score: 0.97 | Elapsed: 4.78s
WARNING:root: [*] Fri Dec 23 09:30:17 2022: Train Epoch: 2 [32000/60730 (53%)]	Loss: 0.240068 | F1-score: 0.97 | Elapsed: 4.78s
WARNING:root: [*] Fri Dec 23 09:30:22 2022: Train Epoch: 2 [38400/60730 (63%)]	Loss: 0.194581 | F1-score: 0.97 | Elapsed: 4.90s
WARNING:root: [*] Fri Dec 23 09:30:27 2022: Train Epoch: 2 [44800/60730 (74%)]	Loss: 0.103194 | F1-score: 0.97 | Elapsed: 4.88s
WARNING:root: [*] Fri Dec 23 09:30:31 2022: Train Epoch: 2 [51200/60730 (84%)]	Loss: 0.108701 | F1-score: 0.97 | Elapsed: 4.86s
WARNING:root: [*] Fri Dec 23 09:30:36 2022: Train Epoch: 2 [57600/60730 (95%)]	Loss: 0.042343 | F1-score: 0.97 | Elapsed: 4.92s
WARNING:root: [*] Fri Dec 23 09:30:39 2022:    2    | Tr.loss: 0.124181 | Tr.F1.:   0.97    |   45.96  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 09:30:39 2022: Train Epoch: 3 [  0  /60730 (0 %)]	Loss: 0.082853 | F1-score: 0.98 | Elapsed: 0.06s
WARNING:root: [*] Fri Dec 23 09:30:44 2022: Train Epoch: 3 [6400 /60730 (11%)]	Loss: 0.304326 | F1-score: 0.97 | Elapsed: 4.86s
WARNING:root: [*] Fri Dec 23 09:30:48 2022: Train Epoch: 3 [12800/60730 (21%)]	Loss: 0.087169 | F1-score: 0.97 | Elapsed: 4.85s
WARNING:root: [*] Fri Dec 23 09:30:53 2022: Train Epoch: 3 [19200/60730 (32%)]	Loss: 0.141469 | F1-score: 0.97 | Elapsed: 4.85s
WARNING:root: [*] Fri Dec 23 09:30:58 2022: Train Epoch: 3 [25600/60730 (42%)]	Loss: 0.244877 | F1-score: 0.97 | Elapsed: 4.78s
WARNING:root: [*] Fri Dec 23 09:31:03 2022: Train Epoch: 3 [32000/60730 (53%)]	Loss: 0.128689 | F1-score: 0.97 | Elapsed: 4.89s
WARNING:root: [*] Fri Dec 23 09:31:08 2022: Train Epoch: 3 [38400/60730 (63%)]	Loss: 0.197548 | F1-score: 0.97 | Elapsed: 4.89s
WARNING:root: [*] Fri Dec 23 09:31:13 2022: Train Epoch: 3 [44800/60730 (74%)]	Loss: 0.058709 | F1-score: 0.97 | Elapsed: 4.88s
WARNING:root: [*] Fri Dec 23 09:31:18 2022: Train Epoch: 3 [51200/60730 (84%)]	Loss: 0.081875 | F1-score: 0.97 | Elapsed: 4.90s
WARNING:root: [*] Fri Dec 23 09:31:22 2022: Train Epoch: 3 [57600/60730 (95%)]	Loss: 0.147547 | F1-score: 0.97 | Elapsed: 4.80s
WARNING:root: [*] Fri Dec 23 09:31:25 2022:    3    | Tr.loss: 0.113934 | Tr.F1.:   0.97    |   46.16  s
WARNING:root:
        [!] Fri Dec 23 09:31:25 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671784285-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671784285-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671784285-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671784285-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 60731, Validation set size: 30365
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 09:31:33 2022: Train Epoch: 1 [  0  /60731 (0 %)]	Loss: 0.690670 | F1-score: 0.75 | Elapsed: 0.06s
WARNING:root: [*] Fri Dec 23 09:31:38 2022: Train Epoch: 1 [6400 /60731 (11%)]	Loss: 0.227000 | F1-score: 0.92 | Elapsed: 4.92s
WARNING:root: [*] Fri Dec 23 09:31:43 2022: Train Epoch: 1 [12800/60731 (21%)]	Loss: 0.147385 | F1-score: 0.93 | Elapsed: 4.88s
WARNING:root: [*] Fri Dec 23 09:31:48 2022: Train Epoch: 1 [19200/60731 (32%)]	Loss: 0.223081 | F1-score: 0.94 | Elapsed: 4.85s
WARNING:root: [*] Fri Dec 23 09:31:53 2022: Train Epoch: 1 [25600/60731 (42%)]	Loss: 0.250430 | F1-score: 0.94 | Elapsed: 4.87s
WARNING:root: [*] Fri Dec 23 09:31:57 2022: Train Epoch: 1 [32000/60731 (53%)]	Loss: 0.083648 | F1-score: 0.95 | Elapsed: 4.90s
WARNING:root: [*] Fri Dec 23 09:32:02 2022: Train Epoch: 1 [38400/60731 (63%)]	Loss: 0.117914 | F1-score: 0.95 | Elapsed: 4.99s
WARNING:root: [*] Fri Dec 23 09:32:07 2022: Train Epoch: 1 [44800/60731 (74%)]	Loss: 0.034133 | F1-score: 0.95 | Elapsed: 4.99s
WARNING:root: [*] Fri Dec 23 09:32:12 2022: Train Epoch: 1 [51200/60731 (84%)]	Loss: 0.158501 | F1-score: 0.95 | Elapsed: 4.85s
WARNING:root: [*] Fri Dec 23 09:32:17 2022: Train Epoch: 1 [57600/60731 (95%)]	Loss: 0.097271 | F1-score: 0.95 | Elapsed: 4.95s
WARNING:root: [*] Fri Dec 23 09:32:20 2022:    1    | Tr.loss: 0.185281 | Tr.F1.:   0.95    |   46.66  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 09:32:20 2022: Train Epoch: 2 [  0  /60731 (0 %)]	Loss: 0.093519 | F1-score: 0.97 | Elapsed: 0.05s
WARNING:root: [*] Fri Dec 23 09:32:25 2022: Train Epoch: 2 [6400 /60731 (11%)]	Loss: 0.162981 | F1-score: 0.97 | Elapsed: 5.00s
WARNING:root: [*] Fri Dec 23 09:32:30 2022: Train Epoch: 2 [12800/60731 (21%)]	Loss: 0.139262 | F1-score: 0.97 | Elapsed: 4.93s
WARNING:root: [*] Fri Dec 23 09:32:35 2022: Train Epoch: 2 [19200/60731 (32%)]	Loss: 0.074011 | F1-score: 0.97 | Elapsed: 4.96s
WARNING:root: [*] Fri Dec 23 09:32:40 2022: Train Epoch: 2 [25600/60731 (42%)]	Loss: 0.260465 | F1-score: 0.97 | Elapsed: 4.94s
WARNING:root: [*] Fri Dec 23 09:32:44 2022: Train Epoch: 2 [32000/60731 (53%)]	Loss: 0.123053 | F1-score: 0.97 | Elapsed: 4.89s
WARNING:root: [*] Fri Dec 23 09:32:49 2022: Train Epoch: 2 [38400/60731 (63%)]	Loss: 0.109359 | F1-score: 0.97 | Elapsed: 4.95s
WARNING:root: [*] Fri Dec 23 09:32:54 2022: Train Epoch: 2 [44800/60731 (74%)]	Loss: 0.086736 | F1-score: 0.97 | Elapsed: 4.94s
WARNING:root: [*] Fri Dec 23 09:32:59 2022: Train Epoch: 2 [51200/60731 (84%)]	Loss: 0.029493 | F1-score: 0.97 | Elapsed: 4.88s
WARNING:root: [*] Fri Dec 23 09:33:04 2022: Train Epoch: 2 [57600/60731 (95%)]	Loss: 0.121816 | F1-score: 0.97 | Elapsed: 4.92s
WARNING:root: [*] Fri Dec 23 09:33:06 2022:    2    | Tr.loss: 0.125482 | Tr.F1.:   0.97    |   46.79  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 09:33:07 2022: Train Epoch: 3 [  0  /60731 (0 %)]	Loss: 0.142427 | F1-score: 0.96 | Elapsed: 0.06s
WARNING:root: [*] Fri Dec 23 09:33:11 2022: Train Epoch: 3 [6400 /60731 (11%)]	Loss: 0.065742 | F1-score: 0.97 | Elapsed: 4.80s
WARNING:root: [*] Fri Dec 23 09:33:16 2022: Train Epoch: 3 [12800/60731 (21%)]	Loss: 0.088763 | F1-score: 0.97 | Elapsed: 4.80s
WARNING:root: [*] Fri Dec 23 09:33:21 2022: Train Epoch: 3 [19200/60731 (32%)]	Loss: 0.070125 | F1-score: 0.97 | Elapsed: 4.78s
WARNING:root: [*] Fri Dec 23 09:33:26 2022: Train Epoch: 3 [25600/60731 (42%)]	Loss: 0.142957 | F1-score: 0.97 | Elapsed: 4.78s
WARNING:root: [*] Fri Dec 23 09:33:30 2022: Train Epoch: 3 [32000/60731 (53%)]	Loss: 0.166310 | F1-score: 0.97 | Elapsed: 4.80s
WARNING:root: [*] Fri Dec 23 09:33:35 2022: Train Epoch: 3 [38400/60731 (63%)]	Loss: 0.126774 | F1-score: 0.97 | Elapsed: 4.79s
WARNING:root: [*] Fri Dec 23 09:33:40 2022: Train Epoch: 3 [44800/60731 (74%)]	Loss: 0.117697 | F1-score: 0.97 | Elapsed: 4.79s
WARNING:root: [*] Fri Dec 23 09:33:45 2022: Train Epoch: 3 [51200/60731 (84%)]	Loss: 0.089624 | F1-score: 0.97 | Elapsed: 4.81s
WARNING:root: [*] Fri Dec 23 09:33:50 2022: Train Epoch: 3 [57600/60731 (95%)]	Loss: 0.215357 | F1-score: 0.97 | Elapsed: 4.85s
WARNING:root: [*] Fri Dec 23 09:33:52 2022:    3    | Tr.loss: 0.113628 | Tr.F1.:   0.97    |   45.63  s
WARNING:root:
        [!] Fri Dec 23 09:33:52 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671784432-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671784432-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671784432-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671784432-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 60731, Validation set size: 30365
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 09:34:00 2022: Train Epoch: 1 [  0  /60731 (0 %)]	Loss: 0.678743 | F1-score: 0.88 | Elapsed: 0.06s
WARNING:root: [*] Fri Dec 23 09:34:05 2022: Train Epoch: 1 [6400 /60731 (11%)]	Loss: 0.113301 | F1-score: 0.91 | Elapsed: 4.85s
WARNING:root: [*] Fri Dec 23 09:34:10 2022: Train Epoch: 1 [12800/60731 (21%)]	Loss: 0.183057 | F1-score: 0.93 | Elapsed: 4.90s
WARNING:root: [*] Fri Dec 23 09:34:15 2022: Train Epoch: 1 [19200/60731 (32%)]	Loss: 0.140128 | F1-score: 0.94 | Elapsed: 4.85s
WARNING:root: [*] Fri Dec 23 09:34:20 2022: Train Epoch: 1 [25600/60731 (42%)]	Loss: 0.136999 | F1-score: 0.94 | Elapsed: 4.85s
WARNING:root: [*] Fri Dec 23 09:34:25 2022: Train Epoch: 1 [32000/60731 (53%)]	Loss: 0.177446 | F1-score: 0.94 | Elapsed: 4.85s
WARNING:root: [*] Fri Dec 23 09:34:29 2022: Train Epoch: 1 [38400/60731 (63%)]	Loss: 0.197813 | F1-score: 0.95 | Elapsed: 4.90s
WARNING:root: [*] Fri Dec 23 09:34:34 2022: Train Epoch: 1 [44800/60731 (74%)]	Loss: 0.164177 | F1-score: 0.95 | Elapsed: 4.86s
WARNING:root: [*] Fri Dec 23 09:34:39 2022: Train Epoch: 1 [51200/60731 (84%)]	Loss: 0.120662 | F1-score: 0.95 | Elapsed: 4.90s
WARNING:root: [*] Fri Dec 23 09:34:44 2022: Train Epoch: 1 [57600/60731 (95%)]	Loss: 0.175072 | F1-score: 0.95 | Elapsed: 4.82s
WARNING:root: [*] Fri Dec 23 09:34:46 2022:    1    | Tr.loss: 0.187859 | Tr.F1.:   0.95    |   46.17  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 09:34:46 2022: Train Epoch: 2 [  0  /60731 (0 %)]	Loss: 0.140127 | F1-score: 0.96 | Elapsed: 0.05s
WARNING:root: [*] Fri Dec 23 09:34:51 2022: Train Epoch: 2 [6400 /60731 (11%)]	Loss: 0.130646 | F1-score: 0.97 | Elapsed: 4.85s
WARNING:root: [*] Fri Dec 23 09:34:56 2022: Train Epoch: 2 [12800/60731 (21%)]	Loss: 0.128806 | F1-score: 0.97 | Elapsed: 4.84s
WARNING:root: [*] Fri Dec 23 09:35:01 2022: Train Epoch: 2 [19200/60731 (32%)]	Loss: 0.176845 | F1-score: 0.97 | Elapsed: 4.87s
WARNING:root: [*] Fri Dec 23 09:35:06 2022: Train Epoch: 2 [25600/60731 (42%)]	Loss: 0.066132 | F1-score: 0.97 | Elapsed: 4.89s
WARNING:root: [*] Fri Dec 23 09:35:11 2022: Train Epoch: 2 [32000/60731 (53%)]	Loss: 0.101022 | F1-score: 0.97 | Elapsed: 4.89s
WARNING:root: [*] Fri Dec 23 09:35:16 2022: Train Epoch: 2 [38400/60731 (63%)]	Loss: 0.125609 | F1-score: 0.97 | Elapsed: 4.83s
WARNING:root: [*] Fri Dec 23 09:35:20 2022: Train Epoch: 2 [44800/60731 (74%)]	Loss: 0.112722 | F1-score: 0.97 | Elapsed: 4.91s
WARNING:root: [*] Fri Dec 23 09:35:25 2022: Train Epoch: 2 [51200/60731 (84%)]	Loss: 0.114554 | F1-score: 0.97 | Elapsed: 4.86s
WARNING:root: [*] Fri Dec 23 09:35:30 2022: Train Epoch: 2 [57600/60731 (95%)]	Loss: 0.065556 | F1-score: 0.97 | Elapsed: 4.97s
WARNING:root: [*] Fri Dec 23 09:35:33 2022:    2    | Tr.loss: 0.127047 | Tr.F1.:   0.97    |   46.30  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 09:35:33 2022: Train Epoch: 3 [  0  /60731 (0 %)]	Loss: 0.110022 | F1-score: 0.98 | Elapsed: 0.05s
WARNING:root: [*] Fri Dec 23 09:35:38 2022: Train Epoch: 3 [6400 /60731 (11%)]	Loss: 0.126650 | F1-score: 0.97 | Elapsed: 4.91s
WARNING:root: [*] Fri Dec 23 09:35:42 2022: Train Epoch: 3 [12800/60731 (21%)]	Loss: 0.131375 | F1-score: 0.97 | Elapsed: 4.86s
WARNING:root: [*] Fri Dec 23 09:35:47 2022: Train Epoch: 3 [19200/60731 (32%)]	Loss: 0.264399 | F1-score: 0.97 | Elapsed: 4.93s
WARNING:root: [*] Fri Dec 23 09:35:52 2022: Train Epoch: 3 [25600/60731 (42%)]	Loss: 0.061606 | F1-score: 0.97 | Elapsed: 4.84s
WARNING:root: [*] Fri Dec 23 09:35:57 2022: Train Epoch: 3 [32000/60731 (53%)]	Loss: 0.118190 | F1-score: 0.97 | Elapsed: 4.83s
WARNING:root: [*] Fri Dec 23 09:36:02 2022: Train Epoch: 3 [38400/60731 (63%)]	Loss: 0.215886 | F1-score: 0.97 | Elapsed: 4.87s
WARNING:root: [*] Fri Dec 23 09:36:07 2022: Train Epoch: 3 [44800/60731 (74%)]	Loss: 0.062253 | F1-score: 0.97 | Elapsed: 4.86s
WARNING:root: [*] Fri Dec 23 09:36:12 2022: Train Epoch: 3 [51200/60731 (84%)]	Loss: 0.124951 | F1-score: 0.97 | Elapsed: 5.01s
WARNING:root: [*] Fri Dec 23 09:36:17 2022: Train Epoch: 3 [57600/60731 (95%)]	Loss: 0.078293 | F1-score: 0.97 | Elapsed: 4.94s
WARNING:root: [*] Fri Dec 23 09:36:19 2022:    3    | Tr.loss: 0.113521 | Tr.F1.:   0.97    |   46.44  s
WARNING:root:
        [!] Fri Dec 23 09:36:19 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671784579-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671784579-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671784579-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671784579-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\metrics_trainSize_91096_ep_3_cv_3_maxLen_1024_vocabSize_1500_embeddingDim_64_lstmHidden_128_lstmLayers_1_lstmDropout_0_lstmBidirectional_True_batchNormConv_False_hiddenNeurons_256_128_batchNormFFNN_False.json
WARNING:root: [!] Average epoch time: 46.27s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.2815 -- F1: 0.4209
	FPR:  0.001 -- TPR: 0.6175 -- F1: 0.7619
	FPR:   0.01 -- TPR: 0.6803 -- F1: 0.8090
	FPR:    0.1 -- TPR: 0.9826 -- F1: 0.9722

WARNING:root: [!] Using vocabSize: 1500 | maxLen: 2048
WARNING:root: [!] Using device: cuda:0 | Dataset size: 91096
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 1500, 'embeddingDim': 64, 'lstmHidden': 128, 'lstmLayers': 1, 'lstmDropout': 0, 'lstmBidirectional': True, 'batchNormConv': False, 'hiddenNeurons': [256, 128], 'batchNormFFNN': False}
WARNING:root: [!] Fold 1/3 | Train set size: 60730, Validation set size: 30366
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 09:36:58 2022: Train Epoch: 1 [  0  /60730 (0 %)]	Loss: 0.675496 | F1-score: 0.86 | Elapsed: 0.36s
WARNING:root: [*] Fri Dec 23 09:37:07 2022: Train Epoch: 1 [6400 /60730 (11%)]	Loss: 0.130404 | F1-score: 0.91 | Elapsed: 8.69s
WARNING:root: [*] Fri Dec 23 09:37:16 2022: Train Epoch: 1 [12800/60730 (21%)]	Loss: 0.115237 | F1-score: 0.93 | Elapsed: 8.71s
WARNING:root: [*] Fri Dec 23 09:37:25 2022: Train Epoch: 1 [19200/60730 (32%)]	Loss: 0.172926 | F1-score: 0.94 | Elapsed: 8.75s
WARNING:root: [*] Fri Dec 23 09:37:33 2022: Train Epoch: 1 [25600/60730 (42%)]	Loss: 0.102499 | F1-score: 0.94 | Elapsed: 8.73s
WARNING:root: [*] Fri Dec 23 09:37:42 2022: Train Epoch: 1 [32000/60730 (53%)]	Loss: 0.200208 | F1-score: 0.94 | Elapsed: 8.78s
WARNING:root: [*] Fri Dec 23 09:37:51 2022: Train Epoch: 1 [38400/60730 (63%)]	Loss: 0.136113 | F1-score: 0.95 | Elapsed: 8.82s
WARNING:root: [*] Fri Dec 23 09:38:00 2022: Train Epoch: 1 [44800/60730 (74%)]	Loss: 0.123994 | F1-score: 0.95 | Elapsed: 8.88s
WARNING:root: [*] Fri Dec 23 09:38:09 2022: Train Epoch: 1 [51200/60730 (84%)]	Loss: 0.145640 | F1-score: 0.95 | Elapsed: 8.89s
WARNING:root: [*] Fri Dec 23 09:38:17 2022: Train Epoch: 1 [57600/60730 (95%)]	Loss: 0.162690 | F1-score: 0.95 | Elapsed: 8.78s
WARNING:root: [*] Fri Dec 23 09:38:22 2022:    1    | Tr.loss: 0.185848 | Tr.F1.:   0.95    |   83.59  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 09:38:22 2022: Train Epoch: 2 [  0  /60730 (0 %)]	Loss: 0.149354 | F1-score: 0.94 | Elapsed: 0.09s
WARNING:root: [*] Fri Dec 23 09:38:31 2022: Train Epoch: 2 [6400 /60730 (11%)]	Loss: 0.207057 | F1-score: 0.96 | Elapsed: 8.81s
WARNING:root: [*] Fri Dec 23 09:38:39 2022: Train Epoch: 2 [12800/60730 (21%)]	Loss: 0.069862 | F1-score: 0.97 | Elapsed: 8.77s
WARNING:root: [*] Fri Dec 23 09:38:48 2022: Train Epoch: 2 [19200/60730 (32%)]	Loss: 0.204613 | F1-score: 0.96 | Elapsed: 8.79s
WARNING:root: [*] Fri Dec 23 09:38:57 2022: Train Epoch: 2 [25600/60730 (42%)]	Loss: 0.062421 | F1-score: 0.96 | Elapsed: 8.81s
WARNING:root: [*] Fri Dec 23 09:39:06 2022: Train Epoch: 2 [32000/60730 (53%)]	Loss: 0.017316 | F1-score: 0.97 | Elapsed: 8.81s
WARNING:root: [*] Fri Dec 23 09:39:15 2022: Train Epoch: 2 [38400/60730 (63%)]	Loss: 0.132200 | F1-score: 0.97 | Elapsed: 8.83s
WARNING:root: [*] Fri Dec 23 09:39:23 2022: Train Epoch: 2 [44800/60730 (74%)]	Loss: 0.122842 | F1-score: 0.97 | Elapsed: 8.77s
WARNING:root: [*] Fri Dec 23 09:39:32 2022: Train Epoch: 2 [51200/60730 (84%)]	Loss: 0.129798 | F1-score: 0.97 | Elapsed: 8.83s
WARNING:root: [*] Fri Dec 23 09:39:41 2022: Train Epoch: 2 [57600/60730 (95%)]	Loss: 0.120239 | F1-score: 0.97 | Elapsed: 8.90s
WARNING:root: [*] Fri Dec 23 09:39:45 2022:    2    | Tr.loss: 0.128100 | Tr.F1.:   0.97    |   83.63  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 09:39:45 2022: Train Epoch: 3 [  0  /60730 (0 %)]	Loss: 0.156414 | F1-score: 0.94 | Elapsed: 0.10s
WARNING:root: [*] Fri Dec 23 09:39:54 2022: Train Epoch: 3 [6400 /60730 (11%)]	Loss: 0.268202 | F1-score: 0.97 | Elapsed: 8.81s
WARNING:root: [*] Fri Dec 23 09:40:03 2022: Train Epoch: 3 [12800/60730 (21%)]	Loss: 0.082301 | F1-score: 0.97 | Elapsed: 8.82s
WARNING:root: [*] Fri Dec 23 09:40:12 2022: Train Epoch: 3 [19200/60730 (32%)]	Loss: 0.130697 | F1-score: 0.97 | Elapsed: 8.88s
WARNING:root: [*] Fri Dec 23 09:40:21 2022: Train Epoch: 3 [25600/60730 (42%)]	Loss: 0.078905 | F1-score: 0.97 | Elapsed: 8.79s
WARNING:root: [*] Fri Dec 23 09:40:30 2022: Train Epoch: 3 [32000/60730 (53%)]	Loss: 0.066424 | F1-score: 0.97 | Elapsed: 8.83s
WARNING:root: [*] Fri Dec 23 09:40:38 2022: Train Epoch: 3 [38400/60730 (63%)]	Loss: 0.048772 | F1-score: 0.97 | Elapsed: 8.84s
WARNING:root: [*] Fri Dec 23 09:40:47 2022: Train Epoch: 3 [44800/60730 (74%)]	Loss: 0.107699 | F1-score: 0.97 | Elapsed: 8.78s
WARNING:root: [*] Fri Dec 23 09:40:56 2022: Train Epoch: 3 [51200/60730 (84%)]	Loss: 0.052812 | F1-score: 0.97 | Elapsed: 8.81s
WARNING:root: [*] Fri Dec 23 09:41:05 2022: Train Epoch: 3 [57600/60730 (95%)]	Loss: 0.093505 | F1-score: 0.97 | Elapsed: 8.79s
WARNING:root: [*] Fri Dec 23 09:41:09 2022:    3    | Tr.loss: 0.115957 | Tr.F1.:   0.97    |   83.65  s
WARNING:root:
        [!] Fri Dec 23 09:41:09 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671784869-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671784869-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671784869-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671784869-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 60731, Validation set size: 30365
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 09:41:25 2022: Train Epoch: 1 [  0  /60731 (0 %)]	Loss: 0.699537 | F1-score: 0.21 | Elapsed: 0.09s
WARNING:root: [*] Fri Dec 23 09:41:34 2022: Train Epoch: 1 [6400 /60731 (11%)]	Loss: 0.147752 | F1-score: 0.90 | Elapsed: 8.78s
WARNING:root: [*] Fri Dec 23 09:41:42 2022: Train Epoch: 1 [12800/60731 (21%)]	Loss: 0.146617 | F1-score: 0.92 | Elapsed: 8.78s
WARNING:root: [*] Fri Dec 23 09:41:51 2022: Train Epoch: 1 [19200/60731 (32%)]	Loss: 0.232332 | F1-score: 0.93 | Elapsed: 8.81s
WARNING:root: [*] Fri Dec 23 09:42:00 2022: Train Epoch: 1 [25600/60731 (42%)]	Loss: 0.272958 | F1-score: 0.94 | Elapsed: 8.94s
WARNING:root: [*] Fri Dec 23 09:42:09 2022: Train Epoch: 1 [32000/60731 (53%)]	Loss: 0.148088 | F1-score: 0.94 | Elapsed: 8.78s
WARNING:root: [*] Fri Dec 23 09:42:18 2022: Train Epoch: 1 [38400/60731 (63%)]	Loss: 0.182020 | F1-score: 0.94 | Elapsed: 8.83s
WARNING:root: [*] Fri Dec 23 09:42:27 2022: Train Epoch: 1 [44800/60731 (74%)]	Loss: 0.220949 | F1-score: 0.95 | Elapsed: 8.87s
WARNING:root: [*] Fri Dec 23 09:42:35 2022: Train Epoch: 1 [51200/60731 (84%)]	Loss: 0.038214 | F1-score: 0.95 | Elapsed: 8.77s
WARNING:root: [*] Fri Dec 23 09:42:44 2022: Train Epoch: 1 [57600/60731 (95%)]	Loss: 0.141953 | F1-score: 0.95 | Elapsed: 8.77s
WARNING:root: [*] Fri Dec 23 09:42:48 2022:    1    | Tr.loss: 0.190596 | Tr.F1.:   0.95    |   83.70  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 09:42:49 2022: Train Epoch: 2 [  0  /60731 (0 %)]	Loss: 0.152915 | F1-score: 0.96 | Elapsed: 0.10s
WARNING:root: [*] Fri Dec 23 09:42:57 2022: Train Epoch: 2 [6400 /60731 (11%)]	Loss: 0.092864 | F1-score: 0.97 | Elapsed: 8.83s
WARNING:root: [*] Fri Dec 23 09:43:06 2022: Train Epoch: 2 [12800/60731 (21%)]	Loss: 0.064530 | F1-score: 0.97 | Elapsed: 8.90s
WARNING:root: [*] Fri Dec 23 09:43:15 2022: Train Epoch: 2 [19200/60731 (32%)]	Loss: 0.284854 | F1-score: 0.97 | Elapsed: 8.87s
WARNING:root: [*] Fri Dec 23 09:43:24 2022: Train Epoch: 2 [25600/60731 (42%)]	Loss: 0.112557 | F1-score: 0.97 | Elapsed: 8.85s
WARNING:root: [*] Fri Dec 23 09:43:33 2022: Train Epoch: 2 [32000/60731 (53%)]	Loss: 0.055550 | F1-score: 0.97 | Elapsed: 8.97s
WARNING:root: [*] Fri Dec 23 09:43:42 2022: Train Epoch: 2 [38400/60731 (63%)]	Loss: 0.096997 | F1-score: 0.97 | Elapsed: 9.22s
WARNING:root: [*] Fri Dec 23 09:43:51 2022: Train Epoch: 2 [44800/60731 (74%)]	Loss: 0.101828 | F1-score: 0.97 | Elapsed: 9.19s
WARNING:root: [*] Fri Dec 23 09:44:00 2022: Train Epoch: 2 [51200/60731 (84%)]	Loss: 0.053980 | F1-score: 0.97 | Elapsed: 9.14s
WARNING:root: [*] Fri Dec 23 09:44:10 2022: Train Epoch: 2 [57600/60731 (95%)]	Loss: 0.076203 | F1-score: 0.97 | Elapsed: 9.13s
WARNING:root: [*] Fri Dec 23 09:44:14 2022:    2    | Tr.loss: 0.126679 | Tr.F1.:   0.97    |   85.54  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 09:44:14 2022: Train Epoch: 3 [  0  /60731 (0 %)]	Loss: 0.115388 | F1-score: 0.98 | Elapsed: 0.10s
WARNING:root: [*] Fri Dec 23 09:44:23 2022: Train Epoch: 3 [6400 /60731 (11%)]	Loss: 0.174786 | F1-score: 0.97 | Elapsed: 8.89s
WARNING:root: [*] Fri Dec 23 09:44:32 2022: Train Epoch: 3 [12800/60731 (21%)]	Loss: 0.077887 | F1-score: 0.97 | Elapsed: 8.82s
WARNING:root: [*] Fri Dec 23 09:44:41 2022: Train Epoch: 3 [19200/60731 (32%)]	Loss: 0.168743 | F1-score: 0.97 | Elapsed: 8.81s
WARNING:root: [*] Fri Dec 23 09:44:49 2022: Train Epoch: 3 [25600/60731 (42%)]	Loss: 0.102793 | F1-score: 0.97 | Elapsed: 8.77s
WARNING:root: [*] Fri Dec 23 09:44:58 2022: Train Epoch: 3 [32000/60731 (53%)]	Loss: 0.138322 | F1-score: 0.97 | Elapsed: 8.87s
WARNING:root: [*] Fri Dec 23 09:45:07 2022: Train Epoch: 3 [38400/60731 (63%)]	Loss: 0.047364 | F1-score: 0.97 | Elapsed: 8.87s
WARNING:root: [*] Fri Dec 23 09:45:16 2022: Train Epoch: 3 [44800/60731 (74%)]	Loss: 0.068764 | F1-score: 0.97 | Elapsed: 8.95s
WARNING:root: [*] Fri Dec 23 09:45:25 2022: Train Epoch: 3 [51200/60731 (84%)]	Loss: 0.047488 | F1-score: 0.97 | Elapsed: 8.83s
WARNING:root: [*] Fri Dec 23 09:45:34 2022: Train Epoch: 3 [57600/60731 (95%)]	Loss: 0.147283 | F1-score: 0.97 | Elapsed: 8.74s
WARNING:root: [*] Fri Dec 23 09:45:38 2022:    3    | Tr.loss: 0.115226 | Tr.F1.:   0.97    |   83.85  s
WARNING:root:
        [!] Fri Dec 23 09:45:38 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671785138-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671785138-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671785138-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671785138-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 60731, Validation set size: 30365
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 09:45:54 2022: Train Epoch: 1 [  0  /60731 (0 %)]	Loss: 0.697990 | F1-score: 0.05 | Elapsed: 0.10s
WARNING:root: [*] Fri Dec 23 09:46:03 2022: Train Epoch: 1 [6400 /60731 (11%)]	Loss: 0.176128 | F1-score: 0.90 | Elapsed: 8.86s
WARNING:root: [*] Fri Dec 23 09:46:12 2022: Train Epoch: 1 [12800/60731 (21%)]	Loss: 0.112365 | F1-score: 0.93 | Elapsed: 8.78s
WARNING:root: [*] Fri Dec 23 09:46:20 2022: Train Epoch: 1 [19200/60731 (32%)]	Loss: 0.109234 | F1-score: 0.93 | Elapsed: 8.76s
WARNING:root: [*] Fri Dec 23 09:46:29 2022: Train Epoch: 1 [25600/60731 (42%)]	Loss: 0.039911 | F1-score: 0.94 | Elapsed: 8.75s
WARNING:root: [*] Fri Dec 23 09:46:38 2022: Train Epoch: 1 [32000/60731 (53%)]	Loss: 0.265655 | F1-score: 0.94 | Elapsed: 8.77s
WARNING:root: [*] Fri Dec 23 09:46:47 2022: Train Epoch: 1 [38400/60731 (63%)]	Loss: 0.174013 | F1-score: 0.95 | Elapsed: 8.77s
WARNING:root: [*] Fri Dec 23 09:46:55 2022: Train Epoch: 1 [44800/60731 (74%)]	Loss: 0.186784 | F1-score: 0.95 | Elapsed: 8.77s
WARNING:root: [*] Fri Dec 23 09:47:04 2022: Train Epoch: 1 [51200/60731 (84%)]	Loss: 0.170862 | F1-score: 0.95 | Elapsed: 8.82s
WARNING:root: [*] Fri Dec 23 09:47:13 2022: Train Epoch: 1 [57600/60731 (95%)]	Loss: 0.090710 | F1-score: 0.95 | Elapsed: 8.76s
WARNING:root: [*] Fri Dec 23 09:47:17 2022:    1    | Tr.loss: 0.185316 | Tr.F1.:   0.95    |   83.36  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 09:47:17 2022: Train Epoch: 2 [  0  /60731 (0 %)]	Loss: 0.111238 | F1-score: 0.97 | Elapsed: 0.09s
WARNING:root: [*] Fri Dec 23 09:47:26 2022: Train Epoch: 2 [6400 /60731 (11%)]	Loss: 0.101120 | F1-score: 0.97 | Elapsed: 8.79s
WARNING:root: [*] Fri Dec 23 09:47:35 2022: Train Epoch: 2 [12800/60731 (21%)]	Loss: 0.192710 | F1-score: 0.97 | Elapsed: 8.78s
WARNING:root: [*] Fri Dec 23 09:47:44 2022: Train Epoch: 2 [19200/60731 (32%)]	Loss: 0.080399 | F1-score: 0.97 | Elapsed: 8.85s
WARNING:root: [*] Fri Dec 23 09:47:52 2022: Train Epoch: 2 [25600/60731 (42%)]	Loss: 0.090420 | F1-score: 0.97 | Elapsed: 8.73s
WARNING:root: [*] Fri Dec 23 09:48:01 2022: Train Epoch: 2 [32000/60731 (53%)]	Loss: 0.080279 | F1-score: 0.97 | Elapsed: 8.74s
WARNING:root: [*] Fri Dec 23 09:48:10 2022: Train Epoch: 2 [38400/60731 (63%)]	Loss: 0.091441 | F1-score: 0.97 | Elapsed: 8.79s
WARNING:root: [*] Fri Dec 23 09:48:19 2022: Train Epoch: 2 [44800/60731 (74%)]	Loss: 0.142980 | F1-score: 0.97 | Elapsed: 8.77s
WARNING:root: [*] Fri Dec 23 09:48:27 2022: Train Epoch: 2 [51200/60731 (84%)]	Loss: 0.110870 | F1-score: 0.97 | Elapsed: 8.79s
WARNING:root: [*] Fri Dec 23 09:48:36 2022: Train Epoch: 2 [57600/60731 (95%)]	Loss: 0.113616 | F1-score: 0.97 | Elapsed: 8.92s
WARNING:root: [*] Fri Dec 23 09:48:41 2022:    2    | Tr.loss: 0.123930 | Tr.F1.:   0.97    |   83.47  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 09:48:41 2022: Train Epoch: 3 [  0  /60731 (0 %)]	Loss: 0.047076 | F1-score: 1.00 | Elapsed: 0.10s
WARNING:root: [*] Fri Dec 23 09:48:50 2022: Train Epoch: 3 [6400 /60731 (11%)]	Loss: 0.112018 | F1-score: 0.97 | Elapsed: 8.80s
WARNING:root: [*] Fri Dec 23 09:48:58 2022: Train Epoch: 3 [12800/60731 (21%)]	Loss: 0.060976 | F1-score: 0.97 | Elapsed: 8.79s
WARNING:root: [*] Fri Dec 23 09:49:07 2022: Train Epoch: 3 [19200/60731 (32%)]	Loss: 0.065624 | F1-score: 0.97 | Elapsed: 8.82s
WARNING:root: [*] Fri Dec 23 09:49:16 2022: Train Epoch: 3 [25600/60731 (42%)]	Loss: 0.082756 | F1-score: 0.97 | Elapsed: 8.83s
WARNING:root: [*] Fri Dec 23 09:49:25 2022: Train Epoch: 3 [32000/60731 (53%)]	Loss: 0.073011 | F1-score: 0.97 | Elapsed: 8.81s
WARNING:root: [*] Fri Dec 23 09:49:34 2022: Train Epoch: 3 [38400/60731 (63%)]	Loss: 0.101248 | F1-score: 0.97 | Elapsed: 8.86s
WARNING:root: [*] Fri Dec 23 09:49:42 2022: Train Epoch: 3 [44800/60731 (74%)]	Loss: 0.137802 | F1-score: 0.97 | Elapsed: 8.77s
WARNING:root: [*] Fri Dec 23 09:49:51 2022: Train Epoch: 3 [51200/60731 (84%)]	Loss: 0.137288 | F1-score: 0.97 | Elapsed: 8.80s
WARNING:root: [*] Fri Dec 23 09:50:00 2022: Train Epoch: 3 [57600/60731 (95%)]	Loss: 0.054116 | F1-score: 0.97 | Elapsed: 8.82s
WARNING:root: [*] Fri Dec 23 09:50:04 2022:    3    | Tr.loss: 0.114727 | Tr.F1.:   0.97    |   83.63  s
WARNING:root:
        [!] Fri Dec 23 09:50:04 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671785404-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671785404-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671785404-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671785404-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\metrics_trainSize_91096_ep_3_cv_3_maxLen_2048_vocabSize_1500_embeddingDim_64_lstmHidden_128_lstmLayers_1_lstmDropout_0_lstmBidirectional_True_batchNormConv_False_hiddenNeurons_256_128_batchNormFFNN_False.json
WARNING:root: [!] Average epoch time: 83.83s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.1536 -- F1: 0.2398
	FPR:  0.001 -- TPR: 0.6015 -- F1: 0.7501
	FPR:   0.01 -- TPR: 0.6682 -- F1: 0.7998
	FPR:    0.1 -- TPR: 0.9804 -- F1: 0.9712

WARNING:root: [!] Using vocabSize: 1500 | maxLen: 512
WARNING:root: [!] Using device: cuda:0 | Dataset size: 91096
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 1500, 'embeddingDim': 64, 'lstmHidden': 128, 'lstmLayers': 1, 'lstmDropout': 0, 'lstmBidirectional': True, 'batchNormConv': False, 'hiddenNeurons': [256, 128], 'batchNormFFNN': False}
WARNING:root: [!] Fold 1/3 | Train set size: 60730, Validation set size: 30366
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 09:50:50 2022: Train Epoch: 1 [  0  /60730 (0 %)]	Loss: 0.697932 | F1-score: 0.20 | Elapsed: 0.23s
WARNING:root: [*] Fri Dec 23 09:50:53 2022: Train Epoch: 1 [6400 /60730 (11%)]	Loss: 0.278542 | F1-score: 0.90 | Elapsed: 3.07s
WARNING:root: [*] Fri Dec 23 09:50:56 2022: Train Epoch: 1 [12800/60730 (21%)]	Loss: 0.240774 | F1-score: 0.92 | Elapsed: 2.94s
WARNING:root: [*] Fri Dec 23 09:50:59 2022: Train Epoch: 1 [19200/60730 (32%)]	Loss: 0.075773 | F1-score: 0.93 | Elapsed: 3.03s
WARNING:root: [*] Fri Dec 23 09:51:02 2022: Train Epoch: 1 [25600/60730 (42%)]	Loss: 0.282904 | F1-score: 0.93 | Elapsed: 3.05s
WARNING:root: [*] Fri Dec 23 09:51:05 2022: Train Epoch: 1 [32000/60730 (53%)]	Loss: 0.128908 | F1-score: 0.94 | Elapsed: 3.05s
WARNING:root: [*] Fri Dec 23 09:51:08 2022: Train Epoch: 1 [38400/60730 (63%)]	Loss: 0.109197 | F1-score: 0.94 | Elapsed: 3.09s
WARNING:root: [*] Fri Dec 23 09:51:11 2022: Train Epoch: 1 [44800/60730 (74%)]	Loss: 0.161338 | F1-score: 0.94 | Elapsed: 2.98s
WARNING:root: [*] Fri Dec 23 09:51:14 2022: Train Epoch: 1 [51200/60730 (84%)]	Loss: 0.256488 | F1-score: 0.95 | Elapsed: 2.94s
WARNING:root: [*] Fri Dec 23 09:51:17 2022: Train Epoch: 1 [57600/60730 (95%)]	Loss: 0.113138 | F1-score: 0.95 | Elapsed: 3.05s
WARNING:root: [*] Fri Dec 23 09:51:19 2022:    1    | Tr.loss: 0.198749 | Tr.F1.:   0.95    |   28.91  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 09:51:19 2022: Train Epoch: 2 [  0  /60730 (0 %)]	Loss: 0.079386 | F1-score: 0.98 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 09:51:22 2022: Train Epoch: 2 [6400 /60730 (11%)]	Loss: 0.114769 | F1-score: 0.96 | Elapsed: 2.98s
WARNING:root: [*] Fri Dec 23 09:51:25 2022: Train Epoch: 2 [12800/60730 (21%)]	Loss: 0.236638 | F1-score: 0.96 | Elapsed: 2.94s
WARNING:root: [*] Fri Dec 23 09:51:28 2022: Train Epoch: 2 [19200/60730 (32%)]	Loss: 0.147154 | F1-score: 0.96 | Elapsed: 3.02s
WARNING:root: [*] Fri Dec 23 09:51:31 2022: Train Epoch: 2 [25600/60730 (42%)]	Loss: 0.075582 | F1-score: 0.96 | Elapsed: 2.91s
WARNING:root: [*] Fri Dec 23 09:51:34 2022: Train Epoch: 2 [32000/60730 (53%)]	Loss: 0.175139 | F1-score: 0.96 | Elapsed: 3.03s
WARNING:root: [*] Fri Dec 23 09:51:37 2022: Train Epoch: 2 [38400/60730 (63%)]	Loss: 0.104983 | F1-score: 0.96 | Elapsed: 2.91s
WARNING:root: [*] Fri Dec 23 09:51:40 2022: Train Epoch: 2 [44800/60730 (74%)]	Loss: 0.250256 | F1-score: 0.96 | Elapsed: 2.92s
WARNING:root: [*] Fri Dec 23 09:51:43 2022: Train Epoch: 2 [51200/60730 (84%)]	Loss: 0.151507 | F1-score: 0.96 | Elapsed: 3.04s
WARNING:root: [*] Fri Dec 23 09:51:46 2022: Train Epoch: 2 [57600/60730 (95%)]	Loss: 0.108683 | F1-score: 0.96 | Elapsed: 2.96s
WARNING:root: [*] Fri Dec 23 09:51:47 2022:    2    | Tr.loss: 0.142303 | Tr.F1.:   0.96    |   28.19  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 09:51:47 2022: Train Epoch: 3 [  0  /60730 (0 %)]	Loss: 0.158293 | F1-score: 0.95 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 09:51:50 2022: Train Epoch: 3 [6400 /60730 (11%)]	Loss: 0.094321 | F1-score: 0.96 | Elapsed: 2.94s
WARNING:root: [*] Fri Dec 23 09:51:53 2022: Train Epoch: 3 [12800/60730 (21%)]	Loss: 0.218727 | F1-score: 0.96 | Elapsed: 2.94s
WARNING:root: [*] Fri Dec 23 09:51:56 2022: Train Epoch: 3 [19200/60730 (32%)]	Loss: 0.079911 | F1-score: 0.96 | Elapsed: 2.92s
WARNING:root: [*] Fri Dec 23 09:51:59 2022: Train Epoch: 3 [25600/60730 (42%)]	Loss: 0.096610 | F1-score: 0.96 | Elapsed: 2.90s
WARNING:root: [*] Fri Dec 23 09:52:02 2022: Train Epoch: 3 [32000/60730 (53%)]	Loss: 0.289723 | F1-score: 0.96 | Elapsed: 2.95s
WARNING:root: [*] Fri Dec 23 09:52:05 2022: Train Epoch: 3 [38400/60730 (63%)]	Loss: 0.153592 | F1-score: 0.96 | Elapsed: 2.90s
WARNING:root: [*] Fri Dec 23 09:52:08 2022: Train Epoch: 3 [44800/60730 (74%)]	Loss: 0.158095 | F1-score: 0.96 | Elapsed: 2.87s
WARNING:root: [*] Fri Dec 23 09:52:10 2022: Train Epoch: 3 [51200/60730 (84%)]	Loss: 0.142794 | F1-score: 0.96 | Elapsed: 2.88s
WARNING:root: [*] Fri Dec 23 09:52:13 2022: Train Epoch: 3 [57600/60730 (95%)]	Loss: 0.110694 | F1-score: 0.96 | Elapsed: 2.88s
WARNING:root: [*] Fri Dec 23 09:52:15 2022:    3    | Tr.loss: 0.131169 | Tr.F1.:   0.96    |   27.59  s
WARNING:root:
        [!] Fri Dec 23 09:52:15 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671785535-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671785535-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671785535-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671785535-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 60731, Validation set size: 30365
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 09:52:19 2022: Train Epoch: 1 [  0  /60731 (0 %)]	Loss: 0.698033 | F1-score: 0.05 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 09:52:22 2022: Train Epoch: 1 [6400 /60731 (11%)]	Loss: 0.231497 | F1-score: 0.90 | Elapsed: 2.92s
WARNING:root: [*] Fri Dec 23 09:52:25 2022: Train Epoch: 1 [12800/60731 (21%)]	Loss: 0.144875 | F1-score: 0.93 | Elapsed: 2.88s
WARNING:root: [*] Fri Dec 23 09:52:28 2022: Train Epoch: 1 [19200/60731 (32%)]	Loss: 0.087985 | F1-score: 0.93 | Elapsed: 2.90s
WARNING:root: [*] Fri Dec 23 09:52:31 2022: Train Epoch: 1 [25600/60731 (42%)]	Loss: 0.170884 | F1-score: 0.94 | Elapsed: 2.89s
WARNING:root: [*] Fri Dec 23 09:52:34 2022: Train Epoch: 1 [32000/60731 (53%)]	Loss: 0.169295 | F1-score: 0.94 | Elapsed: 2.95s
WARNING:root: [*] Fri Dec 23 09:52:37 2022: Train Epoch: 1 [38400/60731 (63%)]	Loss: 0.138591 | F1-score: 0.94 | Elapsed: 2.98s
WARNING:root: [*] Fri Dec 23 09:52:40 2022: Train Epoch: 1 [44800/60731 (74%)]	Loss: 0.120830 | F1-score: 0.94 | Elapsed: 3.13s
WARNING:root: [*] Fri Dec 23 09:52:43 2022: Train Epoch: 1 [51200/60731 (84%)]	Loss: 0.247157 | F1-score: 0.95 | Elapsed: 3.09s
WARNING:root: [*] Fri Dec 23 09:52:46 2022: Train Epoch: 1 [57600/60731 (95%)]	Loss: 0.098894 | F1-score: 0.95 | Elapsed: 3.06s
WARNING:root: [*] Fri Dec 23 09:52:48 2022:    1    | Tr.loss: 0.196040 | Tr.F1.:   0.95    |   28.30  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 09:52:48 2022: Train Epoch: 2 [  0  /60731 (0 %)]	Loss: 0.133787 | F1-score: 0.97 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 09:52:51 2022: Train Epoch: 2 [6400 /60731 (11%)]	Loss: 0.141884 | F1-score: 0.96 | Elapsed: 3.06s
WARNING:root: [*] Fri Dec 23 09:52:54 2022: Train Epoch: 2 [12800/60731 (21%)]	Loss: 0.108486 | F1-score: 0.96 | Elapsed: 3.01s
WARNING:root: [*] Fri Dec 23 09:52:57 2022: Train Epoch: 2 [19200/60731 (32%)]	Loss: 0.052359 | F1-score: 0.96 | Elapsed: 3.03s
WARNING:root: [*] Fri Dec 23 09:53:00 2022: Train Epoch: 2 [25600/60731 (42%)]	Loss: 0.139783 | F1-score: 0.96 | Elapsed: 2.96s
WARNING:root: [*] Fri Dec 23 09:53:03 2022: Train Epoch: 2 [32000/60731 (53%)]	Loss: 0.092540 | F1-score: 0.96 | Elapsed: 3.02s
WARNING:root: [*] Fri Dec 23 09:53:06 2022: Train Epoch: 2 [38400/60731 (63%)]	Loss: 0.082318 | F1-score: 0.96 | Elapsed: 3.03s
WARNING:root: [*] Fri Dec 23 09:53:09 2022: Train Epoch: 2 [44800/60731 (74%)]	Loss: 0.223059 | F1-score: 0.96 | Elapsed: 2.97s
WARNING:root: [*] Fri Dec 23 09:53:12 2022: Train Epoch: 2 [51200/60731 (84%)]	Loss: 0.059834 | F1-score: 0.96 | Elapsed: 3.08s
WARNING:root: [*] Fri Dec 23 09:53:15 2022: Train Epoch: 2 [57600/60731 (95%)]	Loss: 0.128082 | F1-score: 0.96 | Elapsed: 2.91s
WARNING:root: [*] Fri Dec 23 09:53:16 2022:    2    | Tr.loss: 0.139423 | Tr.F1.:   0.96    |   28.64  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 09:53:16 2022: Train Epoch: 3 [  0  /60731 (0 %)]	Loss: 0.161984 | F1-score: 0.97 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 09:53:19 2022: Train Epoch: 3 [6400 /60731 (11%)]	Loss: 0.057706 | F1-score: 0.97 | Elapsed: 3.01s
WARNING:root: [*] Fri Dec 23 09:53:22 2022: Train Epoch: 3 [12800/60731 (21%)]	Loss: 0.092976 | F1-score: 0.97 | Elapsed: 3.10s
WARNING:root: [*] Fri Dec 23 09:53:25 2022: Train Epoch: 3 [19200/60731 (32%)]	Loss: 0.076759 | F1-score: 0.97 | Elapsed: 2.88s
WARNING:root: [*] Fri Dec 23 09:53:28 2022: Train Epoch: 3 [25600/60731 (42%)]	Loss: 0.075913 | F1-score: 0.97 | Elapsed: 2.89s
WARNING:root: [*] Fri Dec 23 09:53:31 2022: Train Epoch: 3 [32000/60731 (53%)]	Loss: 0.211824 | F1-score: 0.97 | Elapsed: 2.85s
WARNING:root: [*] Fri Dec 23 09:53:34 2022: Train Epoch: 3 [38400/60731 (63%)]	Loss: 0.101526 | F1-score: 0.97 | Elapsed: 3.00s
WARNING:root: [*] Fri Dec 23 09:53:37 2022: Train Epoch: 3 [44800/60731 (74%)]	Loss: 0.123183 | F1-score: 0.96 | Elapsed: 3.08s
WARNING:root: [*] Fri Dec 23 09:53:40 2022: Train Epoch: 3 [51200/60731 (84%)]	Loss: 0.182719 | F1-score: 0.97 | Elapsed: 3.12s
WARNING:root: [*] Fri Dec 23 09:53:43 2022: Train Epoch: 3 [57600/60731 (95%)]	Loss: 0.151229 | F1-score: 0.97 | Elapsed: 3.08s
WARNING:root: [*] Fri Dec 23 09:53:45 2022:    3    | Tr.loss: 0.127724 | Tr.F1.:   0.97    |   28.55  s
WARNING:root:
        [!] Fri Dec 23 09:53:45 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671785625-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671785625-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671785625-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671785625-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 60731, Validation set size: 30365
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 09:53:49 2022: Train Epoch: 1 [  0  /60731 (0 %)]	Loss: 0.693752 | F1-score: 0.69 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 09:53:52 2022: Train Epoch: 1 [6400 /60731 (11%)]	Loss: 0.272611 | F1-score: 0.91 | Elapsed: 2.91s
WARNING:root: [*] Fri Dec 23 09:53:55 2022: Train Epoch: 1 [12800/60731 (21%)]	Loss: 0.136096 | F1-score: 0.93 | Elapsed: 2.83s
WARNING:root: [*] Fri Dec 23 09:53:58 2022: Train Epoch: 1 [19200/60731 (32%)]	Loss: 0.265214 | F1-score: 0.94 | Elapsed: 2.88s
WARNING:root: [*] Fri Dec 23 09:54:01 2022: Train Epoch: 1 [25600/60731 (42%)]	Loss: 0.157379 | F1-score: 0.94 | Elapsed: 3.06s
WARNING:root: [*] Fri Dec 23 09:54:04 2022: Train Epoch: 1 [32000/60731 (53%)]	Loss: 0.093383 | F1-score: 0.94 | Elapsed: 3.03s
WARNING:root: [*] Fri Dec 23 09:54:07 2022: Train Epoch: 1 [38400/60731 (63%)]	Loss: 0.144985 | F1-score: 0.94 | Elapsed: 3.00s
WARNING:root: [*] Fri Dec 23 09:54:10 2022: Train Epoch: 1 [44800/60731 (74%)]	Loss: 0.099119 | F1-score: 0.95 | Elapsed: 2.96s
WARNING:root: [*] Fri Dec 23 09:54:13 2022: Train Epoch: 1 [51200/60731 (84%)]	Loss: 0.169988 | F1-score: 0.95 | Elapsed: 2.91s
WARNING:root: [*] Fri Dec 23 09:54:16 2022: Train Epoch: 1 [57600/60731 (95%)]	Loss: 0.214031 | F1-score: 0.95 | Elapsed: 2.99s
WARNING:root: [*] Fri Dec 23 09:54:17 2022:    1    | Tr.loss: 0.194874 | Tr.F1.:   0.95    |   28.05  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 09:54:17 2022: Train Epoch: 2 [  0  /60731 (0 %)]	Loss: 0.312553 | F1-score: 0.90 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 09:54:20 2022: Train Epoch: 2 [6400 /60731 (11%)]	Loss: 0.155849 | F1-score: 0.96 | Elapsed: 3.03s
WARNING:root: [*] Fri Dec 23 09:54:23 2022: Train Epoch: 2 [12800/60731 (21%)]	Loss: 0.089609 | F1-score: 0.96 | Elapsed: 2.93s
WARNING:root: [*] Fri Dec 23 09:54:26 2022: Train Epoch: 2 [19200/60731 (32%)]	Loss: 0.111046 | F1-score: 0.96 | Elapsed: 2.97s
WARNING:root: [*] Fri Dec 23 09:54:29 2022: Train Epoch: 2 [25600/60731 (42%)]	Loss: 0.230162 | F1-score: 0.96 | Elapsed: 2.99s
WARNING:root: [*] Fri Dec 23 09:54:32 2022: Train Epoch: 2 [32000/60731 (53%)]	Loss: 0.106258 | F1-score: 0.96 | Elapsed: 2.97s
WARNING:root: [*] Fri Dec 23 09:54:35 2022: Train Epoch: 2 [38400/60731 (63%)]	Loss: 0.194728 | F1-score: 0.96 | Elapsed: 2.94s
WARNING:root: [*] Fri Dec 23 09:54:38 2022: Train Epoch: 2 [44800/60731 (74%)]	Loss: 0.124475 | F1-score: 0.96 | Elapsed: 2.87s
WARNING:root: [*] Fri Dec 23 09:54:41 2022: Train Epoch: 2 [51200/60731 (84%)]	Loss: 0.129997 | F1-score: 0.96 | Elapsed: 2.87s
WARNING:root: [*] Fri Dec 23 09:54:44 2022: Train Epoch: 2 [57600/60731 (95%)]	Loss: 0.178562 | F1-score: 0.96 | Elapsed: 2.94s
WARNING:root: [*] Fri Dec 23 09:54:45 2022:    2    | Tr.loss: 0.140650 | Tr.F1.:   0.96    |   28.02  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 09:54:45 2022: Train Epoch: 3 [  0  /60731 (0 %)]	Loss: 0.103218 | F1-score: 0.98 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 09:54:48 2022: Train Epoch: 3 [6400 /60731 (11%)]	Loss: 0.263987 | F1-score: 0.97 | Elapsed: 3.07s
WARNING:root: [*] Fri Dec 23 09:54:51 2022: Train Epoch: 3 [12800/60731 (21%)]	Loss: 0.148064 | F1-score: 0.96 | Elapsed: 3.05s
WARNING:root: [*] Fri Dec 23 09:54:54 2022: Train Epoch: 3 [19200/60731 (32%)]	Loss: 0.091164 | F1-score: 0.96 | Elapsed: 3.02s
WARNING:root: [*] Fri Dec 23 09:54:57 2022: Train Epoch: 3 [25600/60731 (42%)]	Loss: 0.099241 | F1-score: 0.96 | Elapsed: 2.99s
WARNING:root: [*] Fri Dec 23 09:55:00 2022: Train Epoch: 3 [32000/60731 (53%)]	Loss: 0.122646 | F1-score: 0.97 | Elapsed: 2.96s
WARNING:root: [*] Fri Dec 23 09:55:03 2022: Train Epoch: 3 [38400/60731 (63%)]	Loss: 0.043854 | F1-score: 0.97 | Elapsed: 2.88s
WARNING:root: [*] Fri Dec 23 09:55:06 2022: Train Epoch: 3 [44800/60731 (74%)]	Loss: 0.254519 | F1-score: 0.97 | Elapsed: 2.91s
WARNING:root: [*] Fri Dec 23 09:55:09 2022: Train Epoch: 3 [51200/60731 (84%)]	Loss: 0.089216 | F1-score: 0.96 | Elapsed: 2.89s
WARNING:root: [*] Fri Dec 23 09:55:12 2022: Train Epoch: 3 [57600/60731 (95%)]	Loss: 0.111238 | F1-score: 0.96 | Elapsed: 2.92s
WARNING:root: [*] Fri Dec 23 09:55:13 2022:    3    | Tr.loss: 0.130160 | Tr.F1.:   0.96    |   28.13  s
WARNING:root:
        [!] Fri Dec 23 09:55:13 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671785713-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671785713-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671785713-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671785713-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\metrics_trainSize_91096_ep_3_cv_3_maxLen_512_vocabSize_1500_embeddingDim_64_lstmHidden_128_lstmLayers_1_lstmDropout_0_lstmBidirectional_True_batchNormConv_False_hiddenNeurons_256_128_batchNormFFNN_False.json
WARNING:root: [!] Average epoch time: 28.26s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.2059 -- F1: 0.3185
	FPR:  0.001 -- TPR: 0.5923 -- F1: 0.7420
	FPR:   0.01 -- TPR: 0.6800 -- F1: 0.8073
	FPR:    0.1 -- TPR: 0.9717 -- F1: 0.9666

WARNING:root: [!] Using vocabSize: 2000 | maxLen: 1024
WARNING:root: [!] Using device: cuda:0 | Dataset size: 91096
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 2000, 'embeddingDim': 64, 'lstmHidden': 128, 'lstmLayers': 1, 'lstmDropout': 0, 'lstmBidirectional': True, 'batchNormConv': False, 'hiddenNeurons': [256, 128], 'batchNormFFNN': False}
WARNING:root: [!] Fold 1/3 | Train set size: 60730, Validation set size: 30366
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 09:55:49 2022: Train Epoch: 1 [  0  /60730 (0 %)]	Loss: 0.722329 | F1-score: 0.00 | Elapsed: 0.33s
WARNING:root: [*] Fri Dec 23 09:55:54 2022: Train Epoch: 1 [6400 /60730 (11%)]	Loss: 0.222436 | F1-score: 0.90 | Elapsed: 4.86s
WARNING:root: [*] Fri Dec 23 09:55:58 2022: Train Epoch: 1 [12800/60730 (21%)]	Loss: 0.200782 | F1-score: 0.92 | Elapsed: 4.92s
WARNING:root: [*] Fri Dec 23 09:56:03 2022: Train Epoch: 1 [19200/60730 (32%)]	Loss: 0.069720 | F1-score: 0.93 | Elapsed: 4.88s
WARNING:root: [*] Fri Dec 23 09:56:08 2022: Train Epoch: 1 [25600/60730 (42%)]	Loss: 0.266461 | F1-score: 0.94 | Elapsed: 4.87s
WARNING:root: [*] Fri Dec 23 09:56:13 2022: Train Epoch: 1 [32000/60730 (53%)]	Loss: 0.330802 | F1-score: 0.94 | Elapsed: 4.81s
WARNING:root: [*] Fri Dec 23 09:56:18 2022: Train Epoch: 1 [38400/60730 (63%)]	Loss: 0.076895 | F1-score: 0.95 | Elapsed: 4.83s
WARNING:root: [*] Fri Dec 23 09:56:23 2022: Train Epoch: 1 [44800/60730 (74%)]	Loss: 0.115812 | F1-score: 0.95 | Elapsed: 4.84s
WARNING:root: [*] Fri Dec 23 09:56:27 2022: Train Epoch: 1 [51200/60730 (84%)]	Loss: 0.259136 | F1-score: 0.95 | Elapsed: 4.81s
WARNING:root: [*] Fri Dec 23 09:56:32 2022: Train Epoch: 1 [57600/60730 (95%)]	Loss: 0.102424 | F1-score: 0.95 | Elapsed: 4.83s
WARNING:root: [*] Fri Dec 23 09:56:35 2022:    1    | Tr.loss: 0.187486 | Tr.F1.:   0.95    |   46.33  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 09:56:35 2022: Train Epoch: 2 [  0  /60730 (0 %)]	Loss: 0.070379 | F1-score: 1.00 | Elapsed: 0.06s
WARNING:root: [*] Fri Dec 23 09:56:40 2022: Train Epoch: 2 [6400 /60730 (11%)]	Loss: 0.168175 | F1-score: 0.97 | Elapsed: 4.88s
WARNING:root: [*] Fri Dec 23 09:56:44 2022: Train Epoch: 2 [12800/60730 (21%)]	Loss: 0.125180 | F1-score: 0.97 | Elapsed: 4.83s
WARNING:root: [*] Fri Dec 23 09:56:49 2022: Train Epoch: 2 [19200/60730 (32%)]	Loss: 0.288780 | F1-score: 0.97 | Elapsed: 4.91s
WARNING:root: [*] Fri Dec 23 09:56:54 2022: Train Epoch: 2 [25600/60730 (42%)]	Loss: 0.116898 | F1-score: 0.97 | Elapsed: 5.02s
WARNING:root: [*] Fri Dec 23 09:56:59 2022: Train Epoch: 2 [32000/60730 (53%)]	Loss: 0.071060 | F1-score: 0.97 | Elapsed: 4.89s
WARNING:root: [*] Fri Dec 23 09:57:04 2022: Train Epoch: 2 [38400/60730 (63%)]	Loss: 0.149586 | F1-score: 0.97 | Elapsed: 4.90s
WARNING:root: [*] Fri Dec 23 09:57:09 2022: Train Epoch: 2 [44800/60730 (74%)]	Loss: 0.051887 | F1-score: 0.97 | Elapsed: 4.97s
WARNING:root: [*] Fri Dec 23 09:57:14 2022: Train Epoch: 2 [51200/60730 (84%)]	Loss: 0.119751 | F1-score: 0.97 | Elapsed: 5.03s
WARNING:root: [*] Fri Dec 23 09:57:19 2022: Train Epoch: 2 [57600/60730 (95%)]	Loss: 0.141479 | F1-score: 0.97 | Elapsed: 4.93s
WARNING:root: [*] Fri Dec 23 09:57:21 2022:    2    | Tr.loss: 0.126631 | Tr.F1.:   0.97    |   46.73  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 09:57:21 2022: Train Epoch: 3 [  0  /60730 (0 %)]	Loss: 0.196374 | F1-score: 0.94 | Elapsed: 0.06s
WARNING:root: [*] Fri Dec 23 09:57:26 2022: Train Epoch: 3 [6400 /60730 (11%)]	Loss: 0.096815 | F1-score: 0.97 | Elapsed: 4.83s
WARNING:root: [*] Fri Dec 23 09:57:31 2022: Train Epoch: 3 [12800/60730 (21%)]	Loss: 0.206791 | F1-score: 0.97 | Elapsed: 4.80s
WARNING:root: [*] Fri Dec 23 09:57:36 2022: Train Epoch: 3 [19200/60730 (32%)]	Loss: 0.099841 | F1-score: 0.97 | Elapsed: 4.92s
WARNING:root: [*] Fri Dec 23 09:57:41 2022: Train Epoch: 3 [25600/60730 (42%)]	Loss: 0.045429 | F1-score: 0.97 | Elapsed: 4.87s
WARNING:root: [*] Fri Dec 23 09:57:46 2022: Train Epoch: 3 [32000/60730 (53%)]	Loss: 0.399029 | F1-score: 0.97 | Elapsed: 4.84s
WARNING:root: [*] Fri Dec 23 09:57:51 2022: Train Epoch: 3 [38400/60730 (63%)]	Loss: 0.073463 | F1-score: 0.97 | Elapsed: 4.87s
WARNING:root: [*] Fri Dec 23 09:57:56 2022: Train Epoch: 3 [44800/60730 (74%)]	Loss: 0.098458 | F1-score: 0.97 | Elapsed: 5.03s
WARNING:root: [*] Fri Dec 23 09:58:00 2022: Train Epoch: 3 [51200/60730 (84%)]	Loss: 0.055569 | F1-score: 0.97 | Elapsed: 4.86s
WARNING:root: [*] Fri Dec 23 09:58:05 2022: Train Epoch: 3 [57600/60730 (95%)]	Loss: 0.176004 | F1-score: 0.97 | Elapsed: 4.85s
WARNING:root: [*] Fri Dec 23 09:58:08 2022:    3    | Tr.loss: 0.114488 | Tr.F1.:   0.97    |   46.30  s
WARNING:root:
        [!] Fri Dec 23 09:58:08 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671785888-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671785888-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671785888-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671785888-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 60731, Validation set size: 30365
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 09:58:16 2022: Train Epoch: 1 [  0  /60731 (0 %)]	Loss: 0.691203 | F1-score: 0.63 | Elapsed: 0.05s
WARNING:root: [*] Fri Dec 23 09:58:21 2022: Train Epoch: 1 [6400 /60731 (11%)]	Loss: 0.244235 | F1-score: 0.91 | Elapsed: 4.82s
WARNING:root: [*] Fri Dec 23 09:58:26 2022: Train Epoch: 1 [12800/60731 (21%)]	Loss: 0.155078 | F1-score: 0.93 | Elapsed: 4.86s
WARNING:root: [*] Fri Dec 23 09:58:30 2022: Train Epoch: 1 [19200/60731 (32%)]	Loss: 0.125930 | F1-score: 0.94 | Elapsed: 4.90s
WARNING:root: [*] Fri Dec 23 09:58:35 2022: Train Epoch: 1 [25600/60731 (42%)]	Loss: 0.178231 | F1-score: 0.94 | Elapsed: 4.92s
WARNING:root: [*] Fri Dec 23 09:58:40 2022: Train Epoch: 1 [32000/60731 (53%)]	Loss: 0.177947 | F1-score: 0.95 | Elapsed: 4.91s
WARNING:root: [*] Fri Dec 23 09:58:45 2022: Train Epoch: 1 [38400/60731 (63%)]	Loss: 0.209740 | F1-score: 0.95 | Elapsed: 5.02s
WARNING:root: [*] Fri Dec 23 09:58:50 2022: Train Epoch: 1 [44800/60731 (74%)]	Loss: 0.142245 | F1-score: 0.95 | Elapsed: 4.91s
WARNING:root: [*] Fri Dec 23 09:58:55 2022: Train Epoch: 1 [51200/60731 (84%)]	Loss: 0.137133 | F1-score: 0.95 | Elapsed: 4.91s
WARNING:root: [*] Fri Dec 23 09:59:00 2022: Train Epoch: 1 [57600/60731 (95%)]	Loss: 0.169359 | F1-score: 0.95 | Elapsed: 4.93s
WARNING:root: [*] Fri Dec 23 09:59:02 2022:    1    | Tr.loss: 0.184627 | Tr.F1.:   0.95    |   46.54  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 09:59:02 2022: Train Epoch: 2 [  0  /60731 (0 %)]	Loss: 0.079635 | F1-score: 0.99 | Elapsed: 0.06s
WARNING:root: [*] Fri Dec 23 09:59:07 2022: Train Epoch: 2 [6400 /60731 (11%)]	Loss: 0.148614 | F1-score: 0.97 | Elapsed: 4.90s
WARNING:root: [*] Fri Dec 23 09:59:12 2022: Train Epoch: 2 [12800/60731 (21%)]	Loss: 0.053496 | F1-score: 0.97 | Elapsed: 5.00s
WARNING:root: [*] Fri Dec 23 09:59:17 2022: Train Epoch: 2 [19200/60731 (32%)]	Loss: 0.104302 | F1-score: 0.97 | Elapsed: 4.99s
WARNING:root: [*] Fri Dec 23 09:59:22 2022: Train Epoch: 2 [25600/60731 (42%)]	Loss: 0.113127 | F1-score: 0.97 | Elapsed: 4.81s
WARNING:root: [*] Fri Dec 23 09:59:27 2022: Train Epoch: 2 [32000/60731 (53%)]	Loss: 0.098059 | F1-score: 0.97 | Elapsed: 4.88s
WARNING:root: [*] Fri Dec 23 09:59:32 2022: Train Epoch: 2 [38400/60731 (63%)]	Loss: 0.135466 | F1-score: 0.97 | Elapsed: 4.96s
WARNING:root: [*] Fri Dec 23 09:59:37 2022: Train Epoch: 2 [44800/60731 (74%)]	Loss: 0.082654 | F1-score: 0.97 | Elapsed: 4.92s
WARNING:root: [*] Fri Dec 23 09:59:42 2022: Train Epoch: 2 [51200/60731 (84%)]	Loss: 0.081080 | F1-score: 0.97 | Elapsed: 4.93s
WARNING:root: [*] Fri Dec 23 09:59:47 2022: Train Epoch: 2 [57600/60731 (95%)]	Loss: 0.227468 | F1-score: 0.97 | Elapsed: 4.93s
WARNING:root: [*] Fri Dec 23 09:59:49 2022:    2    | Tr.loss: 0.124967 | Tr.F1.:   0.97    |   46.77  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 09:59:49 2022: Train Epoch: 3 [  0  /60731 (0 %)]	Loss: 0.098488 | F1-score: 0.98 | Elapsed: 0.05s
WARNING:root: [*] Fri Dec 23 09:59:54 2022: Train Epoch: 3 [6400 /60731 (11%)]	Loss: 0.130307 | F1-score: 0.97 | Elapsed: 4.92s
WARNING:root: [*] Fri Dec 23 09:59:59 2022: Train Epoch: 3 [12800/60731 (21%)]	Loss: 0.062827 | F1-score: 0.97 | Elapsed: 4.81s
WARNING:root: [*] Fri Dec 23 10:00:04 2022: Train Epoch: 3 [19200/60731 (32%)]	Loss: 0.196907 | F1-score: 0.97 | Elapsed: 4.94s
WARNING:root: [*] Fri Dec 23 10:00:09 2022: Train Epoch: 3 [25600/60731 (42%)]	Loss: 0.119288 | F1-score: 0.97 | Elapsed: 5.24s
WARNING:root: [*] Fri Dec 23 10:00:14 2022: Train Epoch: 3 [32000/60731 (53%)]	Loss: 0.153951 | F1-score: 0.97 | Elapsed: 5.14s
WARNING:root: [*] Fri Dec 23 10:00:19 2022: Train Epoch: 3 [38400/60731 (63%)]	Loss: 0.078186 | F1-score: 0.97 | Elapsed: 5.04s
WARNING:root: [*] Fri Dec 23 10:00:24 2022: Train Epoch: 3 [44800/60731 (74%)]	Loss: 0.145140 | F1-score: 0.97 | Elapsed: 4.98s
WARNING:root: [*] Fri Dec 23 10:00:29 2022: Train Epoch: 3 [51200/60731 (84%)]	Loss: 0.213318 | F1-score: 0.97 | Elapsed: 4.98s
WARNING:root: [*] Fri Dec 23 10:00:34 2022: Train Epoch: 3 [57600/60731 (95%)]	Loss: 0.070368 | F1-score: 0.97 | Elapsed: 4.96s
WARNING:root: [*] Fri Dec 23 10:00:37 2022:    3    | Tr.loss: 0.114100 | Tr.F1.:   0.97    |   47.47  s
WARNING:root:
        [!] Fri Dec 23 10:00:37 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671786037-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671786037-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671786037-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671786037-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 60731, Validation set size: 30365
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 10:00:45 2022: Train Epoch: 1 [  0  /60731 (0 %)]	Loss: 0.698651 | F1-score: 0.32 | Elapsed: 0.06s
WARNING:root: [*] Fri Dec 23 10:00:50 2022: Train Epoch: 1 [6400 /60731 (11%)]	Loss: 0.234660 | F1-score: 0.91 | Elapsed: 4.96s
WARNING:root: [*] Fri Dec 23 10:00:55 2022: Train Epoch: 1 [12800/60731 (21%)]	Loss: 0.170452 | F1-score: 0.93 | Elapsed: 4.94s
WARNING:root: [*] Fri Dec 23 10:01:00 2022: Train Epoch: 1 [19200/60731 (32%)]	Loss: 0.285469 | F1-score: 0.94 | Elapsed: 4.97s
WARNING:root: [*] Fri Dec 23 10:01:05 2022: Train Epoch: 1 [25600/60731 (42%)]	Loss: 0.127626 | F1-score: 0.94 | Elapsed: 4.96s
WARNING:root: [*] Fri Dec 23 10:01:10 2022: Train Epoch: 1 [32000/60731 (53%)]	Loss: 0.224842 | F1-score: 0.94 | Elapsed: 4.90s
WARNING:root: [*] Fri Dec 23 10:01:15 2022: Train Epoch: 1 [38400/60731 (63%)]	Loss: 0.144028 | F1-score: 0.95 | Elapsed: 4.97s
WARNING:root: [*] Fri Dec 23 10:01:20 2022: Train Epoch: 1 [44800/60731 (74%)]	Loss: 0.121745 | F1-score: 0.95 | Elapsed: 5.12s
WARNING:root: [*] Fri Dec 23 10:01:25 2022: Train Epoch: 1 [51200/60731 (84%)]	Loss: 0.085908 | F1-score: 0.95 | Elapsed: 5.06s
WARNING:root: [*] Fri Dec 23 10:01:30 2022: Train Epoch: 1 [57600/60731 (95%)]	Loss: 0.095396 | F1-score: 0.95 | Elapsed: 5.03s
WARNING:root: [*] Fri Dec 23 10:01:32 2022:    1    | Tr.loss: 0.181223 | Tr.F1.:   0.95    |   47.43  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 10:01:32 2022: Train Epoch: 2 [  0  /60731 (0 %)]	Loss: 0.156834 | F1-score: 0.95 | Elapsed: 0.06s
WARNING:root: [*] Fri Dec 23 10:01:37 2022: Train Epoch: 2 [6400 /60731 (11%)]	Loss: 0.170422 | F1-score: 0.97 | Elapsed: 5.19s
WARNING:root: [*] Fri Dec 23 10:01:42 2022: Train Epoch: 2 [12800/60731 (21%)]	Loss: 0.053024 | F1-score: 0.97 | Elapsed: 5.03s
WARNING:root: [*] Fri Dec 23 10:01:47 2022: Train Epoch: 2 [19200/60731 (32%)]	Loss: 0.016016 | F1-score: 0.97 | Elapsed: 4.90s
WARNING:root: [*] Fri Dec 23 10:01:52 2022: Train Epoch: 2 [25600/60731 (42%)]	Loss: 0.100986 | F1-score: 0.97 | Elapsed: 4.90s
WARNING:root: [*] Fri Dec 23 10:01:57 2022: Train Epoch: 2 [32000/60731 (53%)]	Loss: 0.081360 | F1-score: 0.97 | Elapsed: 4.95s
WARNING:root: [*] Fri Dec 23 10:02:02 2022: Train Epoch: 2 [38400/60731 (63%)]	Loss: 0.213853 | F1-score: 0.97 | Elapsed: 4.99s
WARNING:root: [*] Fri Dec 23 10:02:07 2022: Train Epoch: 2 [44800/60731 (74%)]	Loss: 0.130348 | F1-score: 0.97 | Elapsed: 4.93s
WARNING:root: [*] Fri Dec 23 10:02:12 2022: Train Epoch: 2 [51200/60731 (84%)]	Loss: 0.026114 | F1-score: 0.97 | Elapsed: 5.04s
WARNING:root: [*] Fri Dec 23 10:02:17 2022: Train Epoch: 2 [57600/60731 (95%)]	Loss: 0.113174 | F1-score: 0.97 | Elapsed: 5.14s
WARNING:root: [*] Fri Dec 23 10:02:20 2022:    2    | Tr.loss: 0.122383 | Tr.F1.:   0.97    |   47.69  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 10:02:20 2022: Train Epoch: 3 [  0  /60731 (0 %)]	Loss: 0.064602 | F1-score: 0.99 | Elapsed: 0.06s
WARNING:root: [*] Fri Dec 23 10:02:25 2022: Train Epoch: 3 [6400 /60731 (11%)]	Loss: 0.105453 | F1-score: 0.97 | Elapsed: 5.10s
WARNING:root: [*] Fri Dec 23 10:02:30 2022: Train Epoch: 3 [12800/60731 (21%)]	Loss: 0.110217 | F1-score: 0.97 | Elapsed: 5.13s
WARNING:root: [*] Fri Dec 23 10:02:35 2022: Train Epoch: 3 [19200/60731 (32%)]	Loss: 0.084204 | F1-score: 0.97 | Elapsed: 4.90s
WARNING:root: [*] Fri Dec 23 10:02:40 2022: Train Epoch: 3 [25600/60731 (42%)]	Loss: 0.118095 | F1-score: 0.97 | Elapsed: 4.91s
WARNING:root: [*] Fri Dec 23 10:02:45 2022: Train Epoch: 3 [32000/60731 (53%)]	Loss: 0.188915 | F1-score: 0.97 | Elapsed: 4.91s
WARNING:root: [*] Fri Dec 23 10:02:50 2022: Train Epoch: 3 [38400/60731 (63%)]	Loss: 0.100750 | F1-score: 0.97 | Elapsed: 4.88s
WARNING:root: [*] Fri Dec 23 10:02:55 2022: Train Epoch: 3 [44800/60731 (74%)]	Loss: 0.178901 | F1-score: 0.97 | Elapsed: 4.91s
WARNING:root: [*] Fri Dec 23 10:03:00 2022: Train Epoch: 3 [51200/60731 (84%)]	Loss: 0.090566 | F1-score: 0.97 | Elapsed: 4.84s
WARNING:root: [*] Fri Dec 23 10:03:04 2022: Train Epoch: 3 [57600/60731 (95%)]	Loss: 0.150822 | F1-score: 0.97 | Elapsed: 4.94s
WARNING:root: [*] Fri Dec 23 10:03:07 2022:    3    | Tr.loss: 0.113223 | Tr.F1.:   0.97    |   47.00  s
WARNING:root:
        [!] Fri Dec 23 10:03:07 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671786187-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671786187-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671786187-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671786187-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\metrics_trainSize_91096_ep_3_cv_3_maxLen_1024_vocabSize_2000_embeddingDim_64_lstmHidden_128_lstmLayers_1_lstmDropout_0_lstmBidirectional_True_batchNormConv_False_hiddenNeurons_256_128_batchNormFFNN_False.json
WARNING:root: [!] Average epoch time: 46.92s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.1702 -- F1: 0.2848
	FPR:  0.001 -- TPR: 0.6256 -- F1: 0.7694
	FPR:   0.01 -- TPR: 0.7077 -- F1: 0.8277
	FPR:    0.1 -- TPR: 0.9825 -- F1: 0.9727

WARNING:root: [!] Using vocabSize: 2000 | maxLen: 2048
WARNING:root: [!] Using device: cuda:0 | Dataset size: 91096
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 2000, 'embeddingDim': 64, 'lstmHidden': 128, 'lstmLayers': 1, 'lstmDropout': 0, 'lstmBidirectional': True, 'batchNormConv': False, 'hiddenNeurons': [256, 128], 'batchNormFFNN': False}
WARNING:root: [!] Fold 1/3 | Train set size: 60730, Validation set size: 30366
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 10:03:46 2022: Train Epoch: 1 [  0  /60730 (0 %)]	Loss: 0.716434 | F1-score: 0.00 | Elapsed: 0.32s
WARNING:root: [*] Fri Dec 23 10:03:55 2022: Train Epoch: 1 [6400 /60730 (11%)]	Loss: 0.244610 | F1-score: 0.90 | Elapsed: 8.76s
WARNING:root: [*] Fri Dec 23 10:04:04 2022: Train Epoch: 1 [12800/60730 (21%)]	Loss: 0.224304 | F1-score: 0.92 | Elapsed: 8.79s
WARNING:root: [*] Fri Dec 23 10:04:13 2022: Train Epoch: 1 [19200/60730 (32%)]	Loss: 0.238224 | F1-score: 0.93 | Elapsed: 8.79s
WARNING:root: [*] Fri Dec 23 10:04:21 2022: Train Epoch: 1 [25600/60730 (42%)]	Loss: 0.135698 | F1-score: 0.94 | Elapsed: 8.81s
WARNING:root: [*] Fri Dec 23 10:04:30 2022: Train Epoch: 1 [32000/60730 (53%)]	Loss: 0.099952 | F1-score: 0.94 | Elapsed: 8.92s
WARNING:root: [*] Fri Dec 23 10:04:39 2022: Train Epoch: 1 [38400/60730 (63%)]	Loss: 0.269768 | F1-score: 0.94 | Elapsed: 8.89s
WARNING:root: [*] Fri Dec 23 10:04:48 2022: Train Epoch: 1 [44800/60730 (74%)]	Loss: 0.262659 | F1-score: 0.95 | Elapsed: 8.86s
WARNING:root: [*] Fri Dec 23 10:04:57 2022: Train Epoch: 1 [51200/60730 (84%)]	Loss: 0.232499 | F1-score: 0.95 | Elapsed: 8.97s
WARNING:root: [*] Fri Dec 23 10:05:06 2022: Train Epoch: 1 [57600/60730 (95%)]	Loss: 0.142130 | F1-score: 0.95 | Elapsed: 8.93s
WARNING:root: [*] Fri Dec 23 10:05:10 2022:    1    | Tr.loss: 0.188011 | Tr.F1.:   0.95    |   84.30  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 10:05:10 2022: Train Epoch: 2 [  0  /60730 (0 %)]	Loss: 0.184160 | F1-score: 0.97 | Elapsed: 0.09s
WARNING:root: [*] Fri Dec 23 10:05:19 2022: Train Epoch: 2 [6400 /60730 (11%)]	Loss: 0.054947 | F1-score: 0.96 | Elapsed: 8.86s
WARNING:root: [*] Fri Dec 23 10:05:28 2022: Train Epoch: 2 [12800/60730 (21%)]	Loss: 0.065028 | F1-score: 0.97 | Elapsed: 8.89s
WARNING:root: [*] Fri Dec 23 10:05:37 2022: Train Epoch: 2 [19200/60730 (32%)]	Loss: 0.083343 | F1-score: 0.96 | Elapsed: 8.90s
WARNING:root: [*] Fri Dec 23 10:05:46 2022: Train Epoch: 2 [25600/60730 (42%)]	Loss: 0.170867 | F1-score: 0.97 | Elapsed: 8.80s
WARNING:root: [*] Fri Dec 23 10:05:55 2022: Train Epoch: 2 [32000/60730 (53%)]	Loss: 0.082877 | F1-score: 0.97 | Elapsed: 8.77s
WARNING:root: [*] Fri Dec 23 10:06:03 2022: Train Epoch: 2 [38400/60730 (63%)]	Loss: 0.169370 | F1-score: 0.97 | Elapsed: 8.91s
WARNING:root: [*] Fri Dec 23 10:06:12 2022: Train Epoch: 2 [44800/60730 (74%)]	Loss: 0.177630 | F1-score: 0.97 | Elapsed: 8.87s
WARNING:root: [*] Fri Dec 23 10:06:21 2022: Train Epoch: 2 [51200/60730 (84%)]	Loss: 0.194047 | F1-score: 0.97 | Elapsed: 8.95s
WARNING:root: [*] Fri Dec 23 10:06:30 2022: Train Epoch: 2 [57600/60730 (95%)]	Loss: 0.127571 | F1-score: 0.97 | Elapsed: 8.91s
WARNING:root: [*] Fri Dec 23 10:06:35 2022:    2    | Tr.loss: 0.126524 | Tr.F1.:   0.97    |   84.27  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 10:06:35 2022: Train Epoch: 3 [  0  /60730 (0 %)]	Loss: 0.070204 | F1-score: 0.97 | Elapsed: 0.10s
WARNING:root: [*] Fri Dec 23 10:06:43 2022: Train Epoch: 3 [6400 /60730 (11%)]	Loss: 0.111668 | F1-score: 0.97 | Elapsed: 8.88s
WARNING:root: [*] Fri Dec 23 10:06:52 2022: Train Epoch: 3 [12800/60730 (21%)]	Loss: 0.200012 | F1-score: 0.97 | Elapsed: 8.88s
WARNING:root: [*] Fri Dec 23 10:07:01 2022: Train Epoch: 3 [19200/60730 (32%)]	Loss: 0.026028 | F1-score: 0.97 | Elapsed: 8.94s
WARNING:root: [*] Fri Dec 23 10:07:10 2022: Train Epoch: 3 [25600/60730 (42%)]	Loss: 0.121562 | F1-score: 0.97 | Elapsed: 8.99s
WARNING:root: [*] Fri Dec 23 10:07:19 2022: Train Epoch: 3 [32000/60730 (53%)]	Loss: 0.131535 | F1-score: 0.97 | Elapsed: 8.84s
WARNING:root: [*] Fri Dec 23 10:07:28 2022: Train Epoch: 3 [38400/60730 (63%)]	Loss: 0.062284 | F1-score: 0.97 | Elapsed: 8.88s
WARNING:root: [*] Fri Dec 23 10:07:37 2022: Train Epoch: 3 [44800/60730 (74%)]	Loss: 0.130895 | F1-score: 0.97 | Elapsed: 8.92s
WARNING:root: [*] Fri Dec 23 10:07:46 2022: Train Epoch: 3 [51200/60730 (84%)]	Loss: 0.054468 | F1-score: 0.97 | Elapsed: 8.90s
WARNING:root: [*] Fri Dec 23 10:07:55 2022: Train Epoch: 3 [57600/60730 (95%)]	Loss: 0.128101 | F1-score: 0.97 | Elapsed: 8.78s
WARNING:root: [*] Fri Dec 23 10:07:59 2022:    3    | Tr.loss: 0.113242 | Tr.F1.:   0.97    |   84.38  s
WARNING:root:
        [!] Fri Dec 23 10:07:59 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671786479-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671786479-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671786479-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671786479-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 60731, Validation set size: 30365
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 10:08:15 2022: Train Epoch: 1 [  0  /60731 (0 %)]	Loss: 0.673506 | F1-score: 0.85 | Elapsed: 0.11s
WARNING:root: [*] Fri Dec 23 10:08:24 2022: Train Epoch: 1 [6400 /60731 (11%)]	Loss: 0.242915 | F1-score: 0.90 | Elapsed: 9.15s
WARNING:root: [*] Fri Dec 23 10:08:33 2022: Train Epoch: 1 [12800/60731 (21%)]	Loss: 0.161623 | F1-score: 0.92 | Elapsed: 8.88s
WARNING:root: [*] Fri Dec 23 10:08:42 2022: Train Epoch: 1 [19200/60731 (32%)]	Loss: 0.122355 | F1-score: 0.93 | Elapsed: 8.87s
WARNING:root: [*] Fri Dec 23 10:08:51 2022: Train Epoch: 1 [25600/60731 (42%)]	Loss: 0.144992 | F1-score: 0.94 | Elapsed: 8.81s
WARNING:root: [*] Fri Dec 23 10:09:00 2022: Train Epoch: 1 [32000/60731 (53%)]	Loss: 0.257436 | F1-score: 0.94 | Elapsed: 8.82s
WARNING:root: [*] Fri Dec 23 10:09:09 2022: Train Epoch: 1 [38400/60731 (63%)]	Loss: 0.104695 | F1-score: 0.95 | Elapsed: 8.84s
WARNING:root: [*] Fri Dec 23 10:09:17 2022: Train Epoch: 1 [44800/60731 (74%)]	Loss: 0.199592 | F1-score: 0.95 | Elapsed: 8.84s
WARNING:root: [*] Fri Dec 23 10:09:26 2022: Train Epoch: 1 [51200/60731 (84%)]	Loss: 0.133799 | F1-score: 0.95 | Elapsed: 8.83s
WARNING:root: [*] Fri Dec 23 10:09:35 2022: Train Epoch: 1 [57600/60731 (95%)]	Loss: 0.126244 | F1-score: 0.95 | Elapsed: 8.90s
WARNING:root: [*] Fri Dec 23 10:09:39 2022:    1    | Tr.loss: 0.185394 | Tr.F1.:   0.95    |   84.31  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 10:09:39 2022: Train Epoch: 2 [  0  /60731 (0 %)]	Loss: 0.146563 | F1-score: 0.98 | Elapsed: 0.09s
WARNING:root: [*] Fri Dec 23 10:09:48 2022: Train Epoch: 2 [6400 /60731 (11%)]	Loss: 0.136128 | F1-score: 0.97 | Elapsed: 8.88s
WARNING:root: [*] Fri Dec 23 10:09:57 2022: Train Epoch: 2 [12800/60731 (21%)]	Loss: 0.083151 | F1-score: 0.97 | Elapsed: 8.91s
WARNING:root: [*] Fri Dec 23 10:10:06 2022: Train Epoch: 2 [19200/60731 (32%)]	Loss: 0.108309 | F1-score: 0.97 | Elapsed: 8.91s
WARNING:root: [*] Fri Dec 23 10:10:15 2022: Train Epoch: 2 [25600/60731 (42%)]	Loss: 0.176996 | F1-score: 0.97 | Elapsed: 8.86s
WARNING:root: [*] Fri Dec 23 10:10:24 2022: Train Epoch: 2 [32000/60731 (53%)]	Loss: 0.174638 | F1-score: 0.97 | Elapsed: 8.98s
WARNING:root: [*] Fri Dec 23 10:10:33 2022: Train Epoch: 2 [38400/60731 (63%)]	Loss: 0.095249 | F1-score: 0.97 | Elapsed: 8.86s
WARNING:root: [*] Fri Dec 23 10:10:42 2022: Train Epoch: 2 [44800/60731 (74%)]	Loss: 0.197531 | F1-score: 0.97 | Elapsed: 8.93s
WARNING:root: [*] Fri Dec 23 10:10:51 2022: Train Epoch: 2 [51200/60731 (84%)]	Loss: 0.116226 | F1-score: 0.97 | Elapsed: 8.94s
WARNING:root: [*] Fri Dec 23 10:11:00 2022: Train Epoch: 2 [57600/60731 (95%)]	Loss: 0.170806 | F1-score: 0.97 | Elapsed: 8.96s
WARNING:root: [*] Fri Dec 23 10:11:04 2022:    2    | Tr.loss: 0.123991 | Tr.F1.:   0.97    |   84.62  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 10:11:04 2022: Train Epoch: 3 [  0  /60731 (0 %)]	Loss: 0.202345 | F1-score: 0.96 | Elapsed: 0.09s
WARNING:root: [*] Fri Dec 23 10:11:13 2022: Train Epoch: 3 [6400 /60731 (11%)]	Loss: 0.079475 | F1-score: 0.97 | Elapsed: 8.93s
WARNING:root: [*] Fri Dec 23 10:11:22 2022: Train Epoch: 3 [12800/60731 (21%)]	Loss: 0.098346 | F1-score: 0.97 | Elapsed: 8.98s
WARNING:root: [*] Fri Dec 23 10:11:31 2022: Train Epoch: 3 [19200/60731 (32%)]	Loss: 0.058446 | F1-score: 0.97 | Elapsed: 8.88s
WARNING:root: [*] Fri Dec 23 10:11:40 2022: Train Epoch: 3 [25600/60731 (42%)]	Loss: 0.067007 | F1-score: 0.97 | Elapsed: 8.83s
WARNING:root: [*] Fri Dec 23 10:11:49 2022: Train Epoch: 3 [32000/60731 (53%)]	Loss: 0.063402 | F1-score: 0.97 | Elapsed: 8.87s
WARNING:root: [*] Fri Dec 23 10:11:57 2022: Train Epoch: 3 [38400/60731 (63%)]	Loss: 0.034398 | F1-score: 0.97 | Elapsed: 8.91s
WARNING:root: [*] Fri Dec 23 10:12:06 2022: Train Epoch: 3 [44800/60731 (74%)]	Loss: 0.154725 | F1-score: 0.97 | Elapsed: 8.90s
WARNING:root: [*] Fri Dec 23 10:12:15 2022: Train Epoch: 3 [51200/60731 (84%)]	Loss: 0.082342 | F1-score: 0.97 | Elapsed: 8.80s
WARNING:root: [*] Fri Dec 23 10:12:24 2022: Train Epoch: 3 [57600/60731 (95%)]	Loss: 0.054402 | F1-score: 0.97 | Elapsed: 8.85s
WARNING:root: [*] Fri Dec 23 10:12:28 2022:    3    | Tr.loss: 0.114979 | Tr.F1.:   0.97    |   84.24  s
WARNING:root:
        [!] Fri Dec 23 10:12:28 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671786748-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671786748-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671786748-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671786748-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 60731, Validation set size: 30365
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 10:12:44 2022: Train Epoch: 1 [  0  /60731 (0 %)]	Loss: 0.702646 | F1-score: 0.00 | Elapsed: 0.10s
WARNING:root: [*] Fri Dec 23 10:12:53 2022: Train Epoch: 1 [6400 /60731 (11%)]	Loss: 0.164661 | F1-score: 0.90 | Elapsed: 8.78s
WARNING:root: [*] Fri Dec 23 10:13:02 2022: Train Epoch: 1 [12800/60731 (21%)]	Loss: 0.190622 | F1-score: 0.92 | Elapsed: 8.89s
WARNING:root: [*] Fri Dec 23 10:13:11 2022: Train Epoch: 1 [19200/60731 (32%)]	Loss: 0.218760 | F1-score: 0.93 | Elapsed: 8.83s
WARNING:root: [*] Fri Dec 23 10:13:19 2022: Train Epoch: 1 [25600/60731 (42%)]	Loss: 0.186970 | F1-score: 0.94 | Elapsed: 8.80s
WARNING:root: [*] Fri Dec 23 10:13:28 2022: Train Epoch: 1 [32000/60731 (53%)]	Loss: 0.214075 | F1-score: 0.94 | Elapsed: 8.81s
WARNING:root: [*] Fri Dec 23 10:13:37 2022: Train Epoch: 1 [38400/60731 (63%)]	Loss: 0.165541 | F1-score: 0.95 | Elapsed: 8.82s
WARNING:root: [*] Fri Dec 23 10:13:46 2022: Train Epoch: 1 [44800/60731 (74%)]	Loss: 0.241063 | F1-score: 0.95 | Elapsed: 8.84s
WARNING:root: [*] Fri Dec 23 10:13:55 2022: Train Epoch: 1 [51200/60731 (84%)]	Loss: 0.078094 | F1-score: 0.95 | Elapsed: 8.82s
WARNING:root: [*] Fri Dec 23 10:14:03 2022: Train Epoch: 1 [57600/60731 (95%)]	Loss: 0.118172 | F1-score: 0.95 | Elapsed: 8.87s
WARNING:root: [*] Fri Dec 23 10:14:08 2022:    1    | Tr.loss: 0.184726 | Tr.F1.:   0.95    |   83.78  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 10:14:08 2022: Train Epoch: 2 [  0  /60731 (0 %)]	Loss: 0.154918 | F1-score: 0.96 | Elapsed: 0.09s
WARNING:root: [*] Fri Dec 23 10:14:17 2022: Train Epoch: 2 [6400 /60731 (11%)]	Loss: 0.107179 | F1-score: 0.97 | Elapsed: 8.81s
WARNING:root: [*] Fri Dec 23 10:14:25 2022: Train Epoch: 2 [12800/60731 (21%)]	Loss: 0.077594 | F1-score: 0.97 | Elapsed: 8.79s
WARNING:root: [*] Fri Dec 23 10:14:34 2022: Train Epoch: 2 [19200/60731 (32%)]	Loss: 0.160990 | F1-score: 0.97 | Elapsed: 8.78s
WARNING:root: [*] Fri Dec 23 10:14:43 2022: Train Epoch: 2 [25600/60731 (42%)]	Loss: 0.048556 | F1-score: 0.97 | Elapsed: 8.78s
WARNING:root: [*] Fri Dec 23 10:14:52 2022: Train Epoch: 2 [32000/60731 (53%)]	Loss: 0.149169 | F1-score: 0.97 | Elapsed: 8.78s
WARNING:root: [*] Fri Dec 23 10:15:01 2022: Train Epoch: 2 [38400/60731 (63%)]	Loss: 0.127858 | F1-score: 0.97 | Elapsed: 8.78s
WARNING:root: [*] Fri Dec 23 10:15:09 2022: Train Epoch: 2 [44800/60731 (74%)]	Loss: 0.106703 | F1-score: 0.97 | Elapsed: 8.80s
WARNING:root: [*] Fri Dec 23 10:15:18 2022: Train Epoch: 2 [51200/60731 (84%)]	Loss: 0.122397 | F1-score: 0.97 | Elapsed: 8.78s
WARNING:root: [*] Fri Dec 23 10:15:27 2022: Train Epoch: 2 [57600/60731 (95%)]	Loss: 0.203192 | F1-score: 0.97 | Elapsed: 8.79s
WARNING:root: [*] Fri Dec 23 10:15:31 2022:    2    | Tr.loss: 0.127917 | Tr.F1.:   0.97    |   83.40  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 10:15:31 2022: Train Epoch: 3 [  0  /60731 (0 %)]	Loss: 0.041316 | F1-score: 0.99 | Elapsed: 0.10s
WARNING:root: [*] Fri Dec 23 10:15:40 2022: Train Epoch: 3 [6400 /60731 (11%)]	Loss: 0.060973 | F1-score: 0.98 | Elapsed: 8.79s
WARNING:root: [*] Fri Dec 23 10:15:49 2022: Train Epoch: 3 [12800/60731 (21%)]	Loss: 0.150878 | F1-score: 0.97 | Elapsed: 8.77s
WARNING:root: [*] Fri Dec 23 10:15:58 2022: Train Epoch: 3 [19200/60731 (32%)]	Loss: 0.091254 | F1-score: 0.97 | Elapsed: 8.78s
WARNING:root: [*] Fri Dec 23 10:16:06 2022: Train Epoch: 3 [25600/60731 (42%)]	Loss: 0.134996 | F1-score: 0.97 | Elapsed: 8.78s
WARNING:root: [*] Fri Dec 23 10:16:15 2022: Train Epoch: 3 [32000/60731 (53%)]	Loss: 0.138400 | F1-score: 0.97 | Elapsed: 8.79s
WARNING:root: [*] Fri Dec 23 10:16:24 2022: Train Epoch: 3 [38400/60731 (63%)]	Loss: 0.126361 | F1-score: 0.97 | Elapsed: 8.81s
WARNING:root: [*] Fri Dec 23 10:16:33 2022: Train Epoch: 3 [44800/60731 (74%)]	Loss: 0.059265 | F1-score: 0.97 | Elapsed: 8.76s
WARNING:root: [*] Fri Dec 23 10:16:41 2022: Train Epoch: 3 [51200/60731 (84%)]	Loss: 0.083925 | F1-score: 0.97 | Elapsed: 8.79s
WARNING:root: [*] Fri Dec 23 10:16:50 2022: Train Epoch: 3 [57600/60731 (95%)]	Loss: 0.189448 | F1-score: 0.97 | Elapsed: 8.79s
WARNING:root: [*] Fri Dec 23 10:16:55 2022:    3    | Tr.loss: 0.114889 | Tr.F1.:   0.97    |   83.40  s
WARNING:root:
        [!] Fri Dec 23 10:16:55 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671787015-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671787015-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671787015-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671787015-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\metrics_trainSize_91096_ep_3_cv_3_maxLen_2048_vocabSize_2000_embeddingDim_64_lstmHidden_128_lstmLayers_1_lstmDropout_0_lstmBidirectional_True_batchNormConv_False_hiddenNeurons_256_128_batchNormFFNN_False.json
WARNING:root: [!] Average epoch time: 84.08s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.1708 -- F1: 0.2807
	FPR:  0.001 -- TPR: 0.6047 -- F1: 0.7533
	FPR:   0.01 -- TPR: 0.6959 -- F1: 0.8198
	FPR:    0.1 -- TPR: 0.9793 -- F1: 0.9715

WARNING:root: [!] Using vocabSize: 2000 | maxLen: 512
WARNING:root: [!] Using device: cuda:0 | Dataset size: 91096
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 2000, 'embeddingDim': 64, 'lstmHidden': 128, 'lstmLayers': 1, 'lstmDropout': 0, 'lstmBidirectional': True, 'batchNormConv': False, 'hiddenNeurons': [256, 128], 'batchNormFFNN': False}
WARNING:root: [!] Fold 1/3 | Train set size: 60730, Validation set size: 30366
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 10:17:40 2022: Train Epoch: 1 [  0  /60730 (0 %)]	Loss: 0.711521 | F1-score: 0.00 | Elapsed: 0.18s
WARNING:root: [*] Fri Dec 23 10:17:43 2022: Train Epoch: 1 [6400 /60730 (11%)]	Loss: 0.211919 | F1-score: 0.89 | Elapsed: 2.85s
WARNING:root: [*] Fri Dec 23 10:17:46 2022: Train Epoch: 1 [12800/60730 (21%)]	Loss: 0.213376 | F1-score: 0.92 | Elapsed: 2.82s
WARNING:root: [*] Fri Dec 23 10:17:49 2022: Train Epoch: 1 [19200/60730 (32%)]	Loss: 0.166235 | F1-score: 0.93 | Elapsed: 2.84s
WARNING:root: [*] Fri Dec 23 10:17:52 2022: Train Epoch: 1 [25600/60730 (42%)]	Loss: 0.142108 | F1-score: 0.93 | Elapsed: 2.84s
WARNING:root: [*] Fri Dec 23 10:17:55 2022: Train Epoch: 1 [32000/60730 (53%)]	Loss: 0.150233 | F1-score: 0.94 | Elapsed: 2.86s
WARNING:root: [*] Fri Dec 23 10:17:57 2022: Train Epoch: 1 [38400/60730 (63%)]	Loss: 0.093849 | F1-score: 0.94 | Elapsed: 2.84s
WARNING:root: [*] Fri Dec 23 10:18:00 2022: Train Epoch: 1 [44800/60730 (74%)]	Loss: 0.142911 | F1-score: 0.94 | Elapsed: 2.85s
WARNING:root: [*] Fri Dec 23 10:18:03 2022: Train Epoch: 1 [51200/60730 (84%)]	Loss: 0.171665 | F1-score: 0.94 | Elapsed: 2.85s
WARNING:root: [*] Fri Dec 23 10:18:06 2022: Train Epoch: 1 [57600/60730 (95%)]	Loss: 0.186200 | F1-score: 0.95 | Elapsed: 2.85s
WARNING:root: [*] Fri Dec 23 10:18:07 2022:    1    | Tr.loss: 0.200470 | Tr.F1.:   0.95    |   27.16  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 10:18:07 2022: Train Epoch: 2 [  0  /60730 (0 %)]	Loss: 0.057805 | F1-score: 0.98 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 10:18:10 2022: Train Epoch: 2 [6400 /60730 (11%)]	Loss: 0.265177 | F1-score: 0.96 | Elapsed: 2.86s
WARNING:root: [*] Fri Dec 23 10:18:13 2022: Train Epoch: 2 [12800/60730 (21%)]	Loss: 0.165825 | F1-score: 0.96 | Elapsed: 2.86s
WARNING:root: [*] Fri Dec 23 10:18:16 2022: Train Epoch: 2 [19200/60730 (32%)]	Loss: 0.120401 | F1-score: 0.96 | Elapsed: 2.85s
WARNING:root: [*] Fri Dec 23 10:18:19 2022: Train Epoch: 2 [25600/60730 (42%)]	Loss: 0.111695 | F1-score: 0.96 | Elapsed: 2.87s
WARNING:root: [*] Fri Dec 23 10:18:22 2022: Train Epoch: 2 [32000/60730 (53%)]	Loss: 0.140112 | F1-score: 0.96 | Elapsed: 2.86s
WARNING:root: [*] Fri Dec 23 10:18:25 2022: Train Epoch: 2 [38400/60730 (63%)]	Loss: 0.116126 | F1-score: 0.96 | Elapsed: 2.82s
WARNING:root: [*] Fri Dec 23 10:18:27 2022: Train Epoch: 2 [44800/60730 (74%)]	Loss: 0.148965 | F1-score: 0.96 | Elapsed: 2.82s
WARNING:root: [*] Fri Dec 23 10:18:30 2022: Train Epoch: 2 [51200/60730 (84%)]	Loss: 0.152625 | F1-score: 0.96 | Elapsed: 2.83s
WARNING:root: [*] Fri Dec 23 10:18:33 2022: Train Epoch: 2 [57600/60730 (95%)]	Loss: 0.129743 | F1-score: 0.96 | Elapsed: 2.84s
WARNING:root: [*] Fri Dec 23 10:18:34 2022:    2    | Tr.loss: 0.141981 | Tr.F1.:   0.96    |   27.03  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 10:18:34 2022: Train Epoch: 3 [  0  /60730 (0 %)]	Loss: 0.131470 | F1-score: 0.98 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 10:18:37 2022: Train Epoch: 3 [6400 /60730 (11%)]	Loss: 0.082159 | F1-score: 0.97 | Elapsed: 2.85s
WARNING:root: [*] Fri Dec 23 10:18:40 2022: Train Epoch: 3 [12800/60730 (21%)]	Loss: 0.072759 | F1-score: 0.96 | Elapsed: 2.84s
WARNING:root: [*] Fri Dec 23 10:18:43 2022: Train Epoch: 3 [19200/60730 (32%)]	Loss: 0.078221 | F1-score: 0.97 | Elapsed: 2.87s
WARNING:root: [*] Fri Dec 23 10:18:46 2022: Train Epoch: 3 [25600/60730 (42%)]	Loss: 0.108756 | F1-score: 0.97 | Elapsed: 2.81s
WARNING:root: [*] Fri Dec 23 10:18:49 2022: Train Epoch: 3 [32000/60730 (53%)]	Loss: 0.097702 | F1-score: 0.97 | Elapsed: 2.82s
WARNING:root: [*] Fri Dec 23 10:18:51 2022: Train Epoch: 3 [38400/60730 (63%)]	Loss: 0.075934 | F1-score: 0.97 | Elapsed: 2.83s
WARNING:root: [*] Fri Dec 23 10:18:54 2022: Train Epoch: 3 [44800/60730 (74%)]	Loss: 0.115091 | F1-score: 0.97 | Elapsed: 2.81s
WARNING:root: [*] Fri Dec 23 10:18:57 2022: Train Epoch: 3 [51200/60730 (84%)]	Loss: 0.217998 | F1-score: 0.97 | Elapsed: 2.83s
WARNING:root: [*] Fri Dec 23 10:19:00 2022: Train Epoch: 3 [57600/60730 (95%)]	Loss: 0.147380 | F1-score: 0.97 | Elapsed: 2.82s
WARNING:root: [*] Fri Dec 23 10:19:01 2022:    3    | Tr.loss: 0.128382 | Tr.F1.:   0.97    |   26.87  s
WARNING:root:
        [!] Fri Dec 23 10:19:01 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671787141-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671787141-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671787141-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671787141-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 60731, Validation set size: 30365
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 10:19:06 2022: Train Epoch: 1 [  0  /60731 (0 %)]	Loss: 0.699527 | F1-score: 0.00 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 10:19:09 2022: Train Epoch: 1 [6400 /60731 (11%)]	Loss: 0.258817 | F1-score: 0.89 | Elapsed: 2.86s
WARNING:root: [*] Fri Dec 23 10:19:12 2022: Train Epoch: 1 [12800/60731 (21%)]	Loss: 0.149765 | F1-score: 0.92 | Elapsed: 2.85s
WARNING:root: [*] Fri Dec 23 10:19:14 2022: Train Epoch: 1 [19200/60731 (32%)]	Loss: 0.194855 | F1-score: 0.93 | Elapsed: 2.81s
WARNING:root: [*] Fri Dec 23 10:19:17 2022: Train Epoch: 1 [25600/60731 (42%)]	Loss: 0.181379 | F1-score: 0.93 | Elapsed: 2.84s
WARNING:root: [*] Fri Dec 23 10:19:20 2022: Train Epoch: 1 [32000/60731 (53%)]	Loss: 0.132474 | F1-score: 0.94 | Elapsed: 2.83s
WARNING:root: [*] Fri Dec 23 10:19:23 2022: Train Epoch: 1 [38400/60731 (63%)]	Loss: 0.186402 | F1-score: 0.94 | Elapsed: 2.82s
WARNING:root: [*] Fri Dec 23 10:19:26 2022: Train Epoch: 1 [44800/60731 (74%)]	Loss: 0.122310 | F1-score: 0.94 | Elapsed: 2.84s
WARNING:root: [*] Fri Dec 23 10:19:28 2022: Train Epoch: 1 [51200/60731 (84%)]	Loss: 0.324871 | F1-score: 0.94 | Elapsed: 2.83s
WARNING:root: [*] Fri Dec 23 10:19:31 2022: Train Epoch: 1 [57600/60731 (95%)]	Loss: 0.213068 | F1-score: 0.95 | Elapsed: 2.81s
WARNING:root: [*] Fri Dec 23 10:19:33 2022:    1    | Tr.loss: 0.200861 | Tr.F1.:   0.95    |   26.89  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 10:19:33 2022: Train Epoch: 2 [  0  /60731 (0 %)]	Loss: 0.168315 | F1-score: 0.95 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 10:19:36 2022: Train Epoch: 2 [6400 /60731 (11%)]	Loss: 0.134592 | F1-score: 0.96 | Elapsed: 2.84s
WARNING:root: [*] Fri Dec 23 10:19:38 2022: Train Epoch: 2 [12800/60731 (21%)]	Loss: 0.151910 | F1-score: 0.96 | Elapsed: 2.84s
WARNING:root: [*] Fri Dec 23 10:19:41 2022: Train Epoch: 2 [19200/60731 (32%)]	Loss: 0.179533 | F1-score: 0.96 | Elapsed: 2.85s
WARNING:root: [*] Fri Dec 23 10:19:44 2022: Train Epoch: 2 [25600/60731 (42%)]	Loss: 0.088966 | F1-score: 0.96 | Elapsed: 2.83s
WARNING:root: [*] Fri Dec 23 10:19:47 2022: Train Epoch: 2 [32000/60731 (53%)]	Loss: 0.121397 | F1-score: 0.96 | Elapsed: 2.81s
WARNING:root: [*] Fri Dec 23 10:19:50 2022: Train Epoch: 2 [38400/60731 (63%)]	Loss: 0.067845 | F1-score: 0.96 | Elapsed: 2.82s
WARNING:root: [*] Fri Dec 23 10:19:53 2022: Train Epoch: 2 [44800/60731 (74%)]	Loss: 0.287368 | F1-score: 0.96 | Elapsed: 2.84s
WARNING:root: [*] Fri Dec 23 10:19:55 2022: Train Epoch: 2 [51200/60731 (84%)]	Loss: 0.093879 | F1-score: 0.96 | Elapsed: 2.83s
WARNING:root: [*] Fri Dec 23 10:19:58 2022: Train Epoch: 2 [57600/60731 (95%)]	Loss: 0.194016 | F1-score: 0.96 | Elapsed: 2.83s
WARNING:root: [*] Fri Dec 23 10:20:00 2022:    2    | Tr.loss: 0.137472 | Tr.F1.:   0.96    |   26.88  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 10:20:00 2022: Train Epoch: 3 [  0  /60731 (0 %)]	Loss: 0.105908 | F1-score: 0.97 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 10:20:02 2022: Train Epoch: 3 [6400 /60731 (11%)]	Loss: 0.104073 | F1-score: 0.97 | Elapsed: 2.84s
WARNING:root: [*] Fri Dec 23 10:20:05 2022: Train Epoch: 3 [12800/60731 (21%)]	Loss: 0.181094 | F1-score: 0.96 | Elapsed: 2.82s
WARNING:root: [*] Fri Dec 23 10:20:08 2022: Train Epoch: 3 [19200/60731 (32%)]	Loss: 0.164705 | F1-score: 0.96 | Elapsed: 2.85s
WARNING:root: [*] Fri Dec 23 10:20:11 2022: Train Epoch: 3 [25600/60731 (42%)]	Loss: 0.120148 | F1-score: 0.96 | Elapsed: 2.84s
WARNING:root: [*] Fri Dec 23 10:20:14 2022: Train Epoch: 3 [32000/60731 (53%)]	Loss: 0.061800 | F1-score: 0.96 | Elapsed: 2.83s
WARNING:root: [*] Fri Dec 23 10:20:17 2022: Train Epoch: 3 [38400/60731 (63%)]	Loss: 0.068867 | F1-score: 0.96 | Elapsed: 2.82s
WARNING:root: [*] Fri Dec 23 10:20:19 2022: Train Epoch: 3 [44800/60731 (74%)]	Loss: 0.086919 | F1-score: 0.96 | Elapsed: 2.82s
WARNING:root: [*] Fri Dec 23 10:20:22 2022: Train Epoch: 3 [51200/60731 (84%)]	Loss: 0.204413 | F1-score: 0.96 | Elapsed: 2.90s
WARNING:root: [*] Fri Dec 23 10:20:25 2022: Train Epoch: 3 [57600/60731 (95%)]	Loss: 0.252648 | F1-score: 0.96 | Elapsed: 2.87s
WARNING:root: [*] Fri Dec 23 10:20:27 2022:    3    | Tr.loss: 0.128571 | Tr.F1.:   0.96    |   27.02  s
WARNING:root:
        [!] Fri Dec 23 10:20:27 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671787227-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671787227-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671787227-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671787227-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 60731, Validation set size: 30365
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 10:20:31 2022: Train Epoch: 1 [  0  /60731 (0 %)]	Loss: 0.706212 | F1-score: 0.00 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 10:20:34 2022: Train Epoch: 1 [6400 /60731 (11%)]	Loss: 0.254803 | F1-score: 0.91 | Elapsed: 2.91s
WARNING:root: [*] Fri Dec 23 10:20:37 2022: Train Epoch: 1 [12800/60731 (21%)]	Loss: 0.181112 | F1-score: 0.92 | Elapsed: 3.03s
WARNING:root: [*] Fri Dec 23 10:20:40 2022: Train Epoch: 1 [19200/60731 (32%)]	Loss: 0.295557 | F1-score: 0.93 | Elapsed: 3.01s
WARNING:root: [*] Fri Dec 23 10:20:43 2022: Train Epoch: 1 [25600/60731 (42%)]	Loss: 0.130684 | F1-score: 0.94 | Elapsed: 3.03s
WARNING:root: [*] Fri Dec 23 10:20:46 2022: Train Epoch: 1 [32000/60731 (53%)]	Loss: 0.200540 | F1-score: 0.94 | Elapsed: 2.85s
WARNING:root: [*] Fri Dec 23 10:20:49 2022: Train Epoch: 1 [38400/60731 (63%)]	Loss: 0.129576 | F1-score: 0.94 | Elapsed: 2.83s
WARNING:root: [*] Fri Dec 23 10:20:52 2022: Train Epoch: 1 [44800/60731 (74%)]	Loss: 0.183536 | F1-score: 0.94 | Elapsed: 2.94s
WARNING:root: [*] Fri Dec 23 10:20:55 2022: Train Epoch: 1 [51200/60731 (84%)]	Loss: 0.177399 | F1-score: 0.94 | Elapsed: 3.03s
WARNING:root: [*] Fri Dec 23 10:20:58 2022: Train Epoch: 1 [57600/60731 (95%)]	Loss: 0.198835 | F1-score: 0.95 | Elapsed: 2.91s
WARNING:root: [*] Fri Dec 23 10:20:59 2022:    1    | Tr.loss: 0.200219 | Tr.F1.:   0.95    |   27.97  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 10:20:59 2022: Train Epoch: 2 [  0  /60731 (0 %)]	Loss: 0.303088 | F1-score: 0.91 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 10:21:02 2022: Train Epoch: 2 [6400 /60731 (11%)]	Loss: 0.096399 | F1-score: 0.96 | Elapsed: 3.00s
WARNING:root: [*] Fri Dec 23 10:21:05 2022: Train Epoch: 2 [12800/60731 (21%)]	Loss: 0.107701 | F1-score: 0.96 | Elapsed: 3.04s
WARNING:root: [*] Fri Dec 23 10:21:08 2022: Train Epoch: 2 [19200/60731 (32%)]	Loss: 0.212500 | F1-score: 0.96 | Elapsed: 3.04s
WARNING:root: [*] Fri Dec 23 10:21:11 2022: Train Epoch: 2 [25600/60731 (42%)]	Loss: 0.302682 | F1-score: 0.96 | Elapsed: 2.98s
WARNING:root: [*] Fri Dec 23 10:21:14 2022: Train Epoch: 2 [32000/60731 (53%)]	Loss: 0.130055 | F1-score: 0.96 | Elapsed: 2.93s
WARNING:root: [*] Fri Dec 23 10:21:17 2022: Train Epoch: 2 [38400/60731 (63%)]	Loss: 0.359746 | F1-score: 0.96 | Elapsed: 2.95s
WARNING:root: [*] Fri Dec 23 10:21:20 2022: Train Epoch: 2 [44800/60731 (74%)]	Loss: 0.113533 | F1-score: 0.96 | Elapsed: 2.92s
WARNING:root: [*] Fri Dec 23 10:21:23 2022: Train Epoch: 2 [51200/60731 (84%)]	Loss: 0.203335 | F1-score: 0.96 | Elapsed: 2.92s
WARNING:root: [*] Fri Dec 23 10:21:26 2022: Train Epoch: 2 [57600/60731 (95%)]	Loss: 0.117362 | F1-score: 0.96 | Elapsed: 2.98s
WARNING:root: [*] Fri Dec 23 10:21:27 2022:    2    | Tr.loss: 0.139907 | Tr.F1.:   0.96    |   28.21  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 10:21:27 2022: Train Epoch: 3 [  0  /60731 (0 %)]	Loss: 0.117173 | F1-score: 0.97 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 10:21:30 2022: Train Epoch: 3 [6400 /60731 (11%)]	Loss: 0.073319 | F1-score: 0.96 | Elapsed: 2.92s
WARNING:root: [*] Fri Dec 23 10:21:33 2022: Train Epoch: 3 [12800/60731 (21%)]	Loss: 0.094602 | F1-score: 0.96 | Elapsed: 2.84s
WARNING:root: [*] Fri Dec 23 10:21:36 2022: Train Epoch: 3 [19200/60731 (32%)]	Loss: 0.120522 | F1-score: 0.96 | Elapsed: 2.85s
WARNING:root: [*] Fri Dec 23 10:21:39 2022: Train Epoch: 3 [25600/60731 (42%)]	Loss: 0.337543 | F1-score: 0.96 | Elapsed: 2.88s
WARNING:root: [*] Fri Dec 23 10:21:42 2022: Train Epoch: 3 [32000/60731 (53%)]	Loss: 0.037410 | F1-score: 0.96 | Elapsed: 2.93s
WARNING:root: [*] Fri Dec 23 10:21:45 2022: Train Epoch: 3 [38400/60731 (63%)]	Loss: 0.106812 | F1-score: 0.96 | Elapsed: 2.91s
WARNING:root: [*] Fri Dec 23 10:21:48 2022: Train Epoch: 3 [44800/60731 (74%)]	Loss: 0.103910 | F1-score: 0.96 | Elapsed: 2.99s
WARNING:root: [*] Fri Dec 23 10:21:51 2022: Train Epoch: 3 [51200/60731 (84%)]	Loss: 0.136747 | F1-score: 0.96 | Elapsed: 2.98s
WARNING:root: [*] Fri Dec 23 10:21:54 2022: Train Epoch: 3 [57600/60731 (95%)]	Loss: 0.101604 | F1-score: 0.96 | Elapsed: 2.98s
WARNING:root: [*] Fri Dec 23 10:21:55 2022:    3    | Tr.loss: 0.128922 | Tr.F1.:   0.96    |   27.80  s
WARNING:root:
        [!] Fri Dec 23 10:21:55 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671787315-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671787315-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671787315-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671787315-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\metrics_trainSize_91096_ep_3_cv_3_maxLen_512_vocabSize_2000_embeddingDim_64_lstmHidden_128_lstmLayers_1_lstmDropout_0_lstmBidirectional_True_batchNormConv_False_hiddenNeurons_256_128_batchNormFFNN_False.json
WARNING:root: [!] Average epoch time: 27.31s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.3022 -- F1: 0.4598
	FPR:  0.001 -- TPR: 0.5942 -- F1: 0.7436
	FPR:   0.01 -- TPR: 0.6783 -- F1: 0.8073
	FPR:    0.1 -- TPR: 0.9670 -- F1: 0.9646

WARNING:root: [!] Using vocabSize: 500 | maxLen: 1024
WARNING:root: [!] Using device: cuda:0 | Dataset size: 91096
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 500, 'embeddingDim': 64, 'lstmHidden': 128, 'lstmLayers': 1, 'lstmDropout': 0, 'lstmBidirectional': True, 'batchNormConv': False, 'hiddenNeurons': [256, 128], 'batchNormFFNN': False}
WARNING:root: [!] Fold 1/3 | Train set size: 60730, Validation set size: 30366
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 10:22:30 2022: Train Epoch: 1 [  0  /60730 (0 %)]	Loss: 0.695256 | F1-score: 0.48 | Elapsed: 0.35s
WARNING:root: [*] Fri Dec 23 10:22:35 2022: Train Epoch: 1 [6400 /60730 (11%)]	Loss: 0.194707 | F1-score: 0.91 | Elapsed: 4.86s
WARNING:root: [*] Fri Dec 23 10:22:40 2022: Train Epoch: 1 [12800/60730 (21%)]	Loss: 0.196696 | F1-score: 0.93 | Elapsed: 4.86s
WARNING:root: [*] Fri Dec 23 10:22:45 2022: Train Epoch: 1 [19200/60730 (32%)]	Loss: 0.128584 | F1-score: 0.94 | Elapsed: 4.87s
WARNING:root: [*] Fri Dec 23 10:22:50 2022: Train Epoch: 1 [25600/60730 (42%)]	Loss: 0.115391 | F1-score: 0.94 | Elapsed: 4.87s
WARNING:root: [*] Fri Dec 23 10:22:55 2022: Train Epoch: 1 [32000/60730 (53%)]	Loss: 0.099566 | F1-score: 0.94 | Elapsed: 4.85s
WARNING:root: [*] Fri Dec 23 10:23:00 2022: Train Epoch: 1 [38400/60730 (63%)]	Loss: 0.097080 | F1-score: 0.95 | Elapsed: 4.89s
WARNING:root: [*] Fri Dec 23 10:23:05 2022: Train Epoch: 1 [44800/60730 (74%)]	Loss: 0.135464 | F1-score: 0.95 | Elapsed: 5.00s
WARNING:root: [*] Fri Dec 23 10:23:09 2022: Train Epoch: 1 [51200/60730 (84%)]	Loss: 0.144803 | F1-score: 0.95 | Elapsed: 4.87s
WARNING:root: [*] Fri Dec 23 10:23:14 2022: Train Epoch: 1 [57600/60730 (95%)]	Loss: 0.148066 | F1-score: 0.95 | Elapsed: 4.86s
WARNING:root: [*] Fri Dec 23 10:23:17 2022:    1    | Tr.loss: 0.187414 | Tr.F1.:   0.95    |   46.67  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 10:23:17 2022: Train Epoch: 2 [  0  /60730 (0 %)]	Loss: 0.069641 | F1-score: 0.99 | Elapsed: 0.05s
WARNING:root: [*] Fri Dec 23 10:23:22 2022: Train Epoch: 2 [6400 /60730 (11%)]	Loss: 0.098778 | F1-score: 0.97 | Elapsed: 4.89s
WARNING:root: [*] Fri Dec 23 10:23:26 2022: Train Epoch: 2 [12800/60730 (21%)]	Loss: 0.082500 | F1-score: 0.96 | Elapsed: 4.84s
WARNING:root: [*] Fri Dec 23 10:23:31 2022: Train Epoch: 2 [19200/60730 (32%)]	Loss: 0.087630 | F1-score: 0.96 | Elapsed: 4.92s
WARNING:root: [*] Fri Dec 23 10:23:36 2022: Train Epoch: 2 [25600/60730 (42%)]	Loss: 0.045014 | F1-score: 0.96 | Elapsed: 4.89s
WARNING:root: [*] Fri Dec 23 10:23:41 2022: Train Epoch: 2 [32000/60730 (53%)]	Loss: 0.028744 | F1-score: 0.97 | Elapsed: 4.86s
WARNING:root: [*] Fri Dec 23 10:23:46 2022: Train Epoch: 2 [38400/60730 (63%)]	Loss: 0.087082 | F1-score: 0.97 | Elapsed: 4.87s
WARNING:root: [*] Fri Dec 23 10:23:51 2022: Train Epoch: 2 [44800/60730 (74%)]	Loss: 0.110019 | F1-score: 0.97 | Elapsed: 4.87s
WARNING:root: [*] Fri Dec 23 10:23:56 2022: Train Epoch: 2 [51200/60730 (84%)]	Loss: 0.102686 | F1-score: 0.97 | Elapsed: 4.90s
WARNING:root: [*] Fri Dec 23 10:24:01 2022: Train Epoch: 2 [57600/60730 (95%)]	Loss: 0.288848 | F1-score: 0.97 | Elapsed: 4.86s
WARNING:root: [*] Fri Dec 23 10:24:03 2022:    2    | Tr.loss: 0.128886 | Tr.F1.:   0.97    |   46.27  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 10:24:03 2022: Train Epoch: 3 [  0  /60730 (0 %)]	Loss: 0.220922 | F1-score: 0.97 | Elapsed: 0.06s
WARNING:root: [*] Fri Dec 23 10:24:08 2022: Train Epoch: 3 [6400 /60730 (11%)]	Loss: 0.117989 | F1-score: 0.97 | Elapsed: 5.04s
WARNING:root: [*] Fri Dec 23 10:24:13 2022: Train Epoch: 3 [12800/60730 (21%)]	Loss: 0.072729 | F1-score: 0.97 | Elapsed: 4.85s
WARNING:root: [*] Fri Dec 23 10:24:18 2022: Train Epoch: 3 [19200/60730 (32%)]	Loss: 0.056750 | F1-score: 0.97 | Elapsed: 4.90s
WARNING:root: [*] Fri Dec 23 10:24:23 2022: Train Epoch: 3 [25600/60730 (42%)]	Loss: 0.078744 | F1-score: 0.97 | Elapsed: 4.83s
WARNING:root: [*] Fri Dec 23 10:24:27 2022: Train Epoch: 3 [32000/60730 (53%)]	Loss: 0.093516 | F1-score: 0.97 | Elapsed: 4.81s
WARNING:root: [*] Fri Dec 23 10:24:32 2022: Train Epoch: 3 [38400/60730 (63%)]	Loss: 0.062173 | F1-score: 0.97 | Elapsed: 4.90s
WARNING:root: [*] Fri Dec 23 10:24:37 2022: Train Epoch: 3 [44800/60730 (74%)]	Loss: 0.232415 | F1-score: 0.97 | Elapsed: 4.86s
WARNING:root: [*] Fri Dec 23 10:24:42 2022: Train Epoch: 3 [51200/60730 (84%)]	Loss: 0.158361 | F1-score: 0.97 | Elapsed: 4.90s
WARNING:root: [*] Fri Dec 23 10:24:47 2022: Train Epoch: 3 [57600/60730 (95%)]	Loss: 0.175691 | F1-score: 0.97 | Elapsed: 4.84s
WARNING:root: [*] Fri Dec 23 10:24:49 2022:    3    | Tr.loss: 0.118205 | Tr.F1.:   0.97    |   46.33  s
WARNING:root:
        [!] Fri Dec 23 10:24:49 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671787489-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671787489-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671787489-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671787489-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 60731, Validation set size: 30365
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 10:24:58 2022: Train Epoch: 1 [  0  /60731 (0 %)]	Loss: 0.688175 | F1-score: 0.77 | Elapsed: 0.06s
WARNING:root: [*] Fri Dec 23 10:25:03 2022: Train Epoch: 1 [6400 /60731 (11%)]	Loss: 0.262569 | F1-score: 0.91 | Elapsed: 5.00s
WARNING:root: [*] Fri Dec 23 10:25:07 2022: Train Epoch: 1 [12800/60731 (21%)]	Loss: 0.219602 | F1-score: 0.93 | Elapsed: 4.88s
WARNING:root: [*] Fri Dec 23 10:25:12 2022: Train Epoch: 1 [19200/60731 (32%)]	Loss: 0.213225 | F1-score: 0.94 | Elapsed: 4.87s
WARNING:root: [*] Fri Dec 23 10:25:17 2022: Train Epoch: 1 [25600/60731 (42%)]	Loss: 0.102271 | F1-score: 0.94 | Elapsed: 4.90s
WARNING:root: [*] Fri Dec 23 10:25:22 2022: Train Epoch: 1 [32000/60731 (53%)]	Loss: 0.302523 | F1-score: 0.95 | Elapsed: 5.04s
WARNING:root: [*] Fri Dec 23 10:25:27 2022: Train Epoch: 1 [38400/60731 (63%)]	Loss: 0.071731 | F1-score: 0.95 | Elapsed: 5.10s
WARNING:root: [*] Fri Dec 23 10:25:32 2022: Train Epoch: 1 [44800/60731 (74%)]	Loss: 0.096833 | F1-score: 0.95 | Elapsed: 4.96s
WARNING:root: [*] Fri Dec 23 10:25:37 2022: Train Epoch: 1 [51200/60731 (84%)]	Loss: 0.145309 | F1-score: 0.95 | Elapsed: 4.93s
WARNING:root: [*] Fri Dec 23 10:25:42 2022: Train Epoch: 1 [57600/60731 (95%)]	Loss: 0.145425 | F1-score: 0.95 | Elapsed: 4.84s
WARNING:root: [*] Fri Dec 23 10:25:44 2022:    1    | Tr.loss: 0.184827 | Tr.F1.:   0.95    |   46.91  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 10:25:44 2022: Train Epoch: 2 [  0  /60731 (0 %)]	Loss: 0.120834 | F1-score: 0.97 | Elapsed: 0.06s
WARNING:root: [*] Fri Dec 23 10:25:49 2022: Train Epoch: 2 [6400 /60731 (11%)]	Loss: 0.100325 | F1-score: 0.97 | Elapsed: 4.86s
WARNING:root: [*] Fri Dec 23 10:25:54 2022: Train Epoch: 2 [12800/60731 (21%)]	Loss: 0.118932 | F1-score: 0.96 | Elapsed: 4.83s
WARNING:root: [*] Fri Dec 23 10:25:59 2022: Train Epoch: 2 [19200/60731 (32%)]	Loss: 0.164123 | F1-score: 0.96 | Elapsed: 4.86s
WARNING:root: [*] Fri Dec 23 10:26:04 2022: Train Epoch: 2 [25600/60731 (42%)]	Loss: 0.133221 | F1-score: 0.97 | Elapsed: 4.86s
WARNING:root: [*] Fri Dec 23 10:26:09 2022: Train Epoch: 2 [32000/60731 (53%)]	Loss: 0.106812 | F1-score: 0.97 | Elapsed: 4.91s
WARNING:root: [*] Fri Dec 23 10:26:14 2022: Train Epoch: 2 [38400/60731 (63%)]	Loss: 0.073060 | F1-score: 0.97 | Elapsed: 4.88s
WARNING:root: [*] Fri Dec 23 10:26:19 2022: Train Epoch: 2 [44800/60731 (74%)]	Loss: 0.100341 | F1-score: 0.97 | Elapsed: 4.89s
WARNING:root: [*] Fri Dec 23 10:26:23 2022: Train Epoch: 2 [51200/60731 (84%)]	Loss: 0.365327 | F1-score: 0.97 | Elapsed: 4.84s
WARNING:root: [*] Fri Dec 23 10:26:28 2022: Train Epoch: 2 [57600/60731 (95%)]	Loss: 0.115994 | F1-score: 0.97 | Elapsed: 4.88s
WARNING:root: [*] Fri Dec 23 10:26:31 2022:    2    | Tr.loss: 0.126445 | Tr.F1.:   0.97    |   46.21  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 10:26:31 2022: Train Epoch: 3 [  0  /60731 (0 %)]	Loss: 0.067553 | F1-score: 0.99 | Elapsed: 0.05s
WARNING:root: [*] Fri Dec 23 10:26:36 2022: Train Epoch: 3 [6400 /60731 (11%)]	Loss: 0.074457 | F1-score: 0.97 | Elapsed: 4.91s
WARNING:root: [*] Fri Dec 23 10:26:40 2022: Train Epoch: 3 [12800/60731 (21%)]	Loss: 0.122135 | F1-score: 0.97 | Elapsed: 4.84s
WARNING:root: [*] Fri Dec 23 10:26:45 2022: Train Epoch: 3 [19200/60731 (32%)]	Loss: 0.083459 | F1-score: 0.97 | Elapsed: 4.89s
WARNING:root: [*] Fri Dec 23 10:26:50 2022: Train Epoch: 3 [25600/60731 (42%)]	Loss: 0.153246 | F1-score: 0.97 | Elapsed: 4.86s
WARNING:root: [*] Fri Dec 23 10:26:55 2022: Train Epoch: 3 [32000/60731 (53%)]	Loss: 0.156133 | F1-score: 0.97 | Elapsed: 4.87s
WARNING:root: [*] Fri Dec 23 10:27:00 2022: Train Epoch: 3 [38400/60731 (63%)]	Loss: 0.092873 | F1-score: 0.97 | Elapsed: 4.84s
WARNING:root: [*] Fri Dec 23 10:27:05 2022: Train Epoch: 3 [44800/60731 (74%)]	Loss: 0.101250 | F1-score: 0.97 | Elapsed: 4.87s
WARNING:root: [*] Fri Dec 23 10:27:10 2022: Train Epoch: 3 [51200/60731 (84%)]	Loss: 0.108769 | F1-score: 0.97 | Elapsed: 4.86s
WARNING:root: [*] Fri Dec 23 10:27:14 2022: Train Epoch: 3 [57600/60731 (95%)]	Loss: 0.069359 | F1-score: 0.97 | Elapsed: 4.87s
WARNING:root: [*] Fri Dec 23 10:27:17 2022:    3    | Tr.loss: 0.116982 | Tr.F1.:   0.97    |   46.20  s
WARNING:root:
        [!] Fri Dec 23 10:27:17 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671787637-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671787637-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671787637-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671787637-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 60731, Validation set size: 30365
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 10:27:25 2022: Train Epoch: 1 [  0  /60731 (0 %)]	Loss: 0.680338 | F1-score: 0.83 | Elapsed: 0.06s
WARNING:root: [*] Fri Dec 23 10:27:30 2022: Train Epoch: 1 [6400 /60731 (11%)]	Loss: 0.270140 | F1-score: 0.91 | Elapsed: 4.97s
WARNING:root: [*] Fri Dec 23 10:27:35 2022: Train Epoch: 1 [12800/60731 (21%)]	Loss: 0.208205 | F1-score: 0.93 | Elapsed: 4.90s
WARNING:root: [*] Fri Dec 23 10:27:40 2022: Train Epoch: 1 [19200/60731 (32%)]	Loss: 0.115070 | F1-score: 0.94 | Elapsed: 4.89s
WARNING:root: [*] Fri Dec 23 10:27:45 2022: Train Epoch: 1 [25600/60731 (42%)]	Loss: 0.153487 | F1-score: 0.94 | Elapsed: 4.89s
WARNING:root: [*] Fri Dec 23 10:27:50 2022: Train Epoch: 1 [32000/60731 (53%)]	Loss: 0.180471 | F1-score: 0.94 | Elapsed: 4.86s
WARNING:root: [*] Fri Dec 23 10:27:54 2022: Train Epoch: 1 [38400/60731 (63%)]	Loss: 0.183095 | F1-score: 0.95 | Elapsed: 4.87s
WARNING:root: [*] Fri Dec 23 10:27:59 2022: Train Epoch: 1 [44800/60731 (74%)]	Loss: 0.141945 | F1-score: 0.95 | Elapsed: 4.92s
WARNING:root: [*] Fri Dec 23 10:28:04 2022: Train Epoch: 1 [51200/60731 (84%)]	Loss: 0.077065 | F1-score: 0.95 | Elapsed: 4.86s
WARNING:root: [*] Fri Dec 23 10:28:09 2022: Train Epoch: 1 [57600/60731 (95%)]	Loss: 0.102736 | F1-score: 0.95 | Elapsed: 5.09s
WARNING:root: [*] Fri Dec 23 10:28:12 2022:    1    | Tr.loss: 0.185929 | Tr.F1.:   0.95    |   46.69  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 10:28:12 2022: Train Epoch: 2 [  0  /60731 (0 %)]	Loss: 0.129485 | F1-score: 0.96 | Elapsed: 0.06s
WARNING:root: [*] Fri Dec 23 10:28:17 2022: Train Epoch: 2 [6400 /60731 (11%)]	Loss: 0.191594 | F1-score: 0.97 | Elapsed: 5.09s
WARNING:root: [*] Fri Dec 23 10:28:22 2022: Train Epoch: 2 [12800/60731 (21%)]	Loss: 0.120075 | F1-score: 0.97 | Elapsed: 5.01s
WARNING:root: [*] Fri Dec 23 10:28:27 2022: Train Epoch: 2 [19200/60731 (32%)]	Loss: 0.206695 | F1-score: 0.97 | Elapsed: 5.01s
WARNING:root: [*] Fri Dec 23 10:28:32 2022: Train Epoch: 2 [25600/60731 (42%)]	Loss: 0.150307 | F1-score: 0.97 | Elapsed: 4.98s
WARNING:root: [*] Fri Dec 23 10:28:37 2022: Train Epoch: 2 [32000/60731 (53%)]	Loss: 0.117299 | F1-score: 0.97 | Elapsed: 5.02s
WARNING:root: [*] Fri Dec 23 10:28:42 2022: Train Epoch: 2 [38400/60731 (63%)]	Loss: 0.139505 | F1-score: 0.97 | Elapsed: 4.97s
WARNING:root: [*] Fri Dec 23 10:28:47 2022: Train Epoch: 2 [44800/60731 (74%)]	Loss: 0.157530 | F1-score: 0.97 | Elapsed: 4.94s
WARNING:root: [*] Fri Dec 23 10:28:52 2022: Train Epoch: 2 [51200/60731 (84%)]	Loss: 0.137999 | F1-score: 0.97 | Elapsed: 4.90s
WARNING:root: [*] Fri Dec 23 10:28:57 2022: Train Epoch: 2 [57600/60731 (95%)]	Loss: 0.119061 | F1-score: 0.97 | Elapsed: 4.92s
WARNING:root: [*] Fri Dec 23 10:28:59 2022:    2    | Tr.loss: 0.128295 | Tr.F1.:   0.97    |   47.26  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 10:28:59 2022: Train Epoch: 3 [  0  /60731 (0 %)]	Loss: 0.179312 | F1-score: 0.96 | Elapsed: 0.05s
WARNING:root: [*] Fri Dec 23 10:29:04 2022: Train Epoch: 3 [6400 /60731 (11%)]	Loss: 0.277637 | F1-score: 0.97 | Elapsed: 4.88s
WARNING:root: [*] Fri Dec 23 10:29:09 2022: Train Epoch: 3 [12800/60731 (21%)]	Loss: 0.072782 | F1-score: 0.97 | Elapsed: 4.90s
WARNING:root: [*] Fri Dec 23 10:29:14 2022: Train Epoch: 3 [19200/60731 (32%)]	Loss: 0.099041 | F1-score: 0.97 | Elapsed: 4.86s
WARNING:root: [*] Fri Dec 23 10:29:18 2022: Train Epoch: 3 [25600/60731 (42%)]	Loss: 0.147607 | F1-score: 0.97 | Elapsed: 4.87s
WARNING:root: [*] Fri Dec 23 10:29:23 2022: Train Epoch: 3 [32000/60731 (53%)]	Loss: 0.098941 | F1-score: 0.97 | Elapsed: 4.87s
WARNING:root: [*] Fri Dec 23 10:29:28 2022: Train Epoch: 3 [38400/60731 (63%)]	Loss: 0.093305 | F1-score: 0.97 | Elapsed: 4.90s
WARNING:root: [*] Fri Dec 23 10:29:33 2022: Train Epoch: 3 [44800/60731 (74%)]	Loss: 0.037271 | F1-score: 0.97 | Elapsed: 4.86s
WARNING:root: [*] Fri Dec 23 10:29:38 2022: Train Epoch: 3 [51200/60731 (84%)]	Loss: 0.098803 | F1-score: 0.97 | Elapsed: 4.91s
WARNING:root: [*] Fri Dec 23 10:29:43 2022: Train Epoch: 3 [57600/60731 (95%)]	Loss: 0.108720 | F1-score: 0.97 | Elapsed: 4.84s
WARNING:root: [*] Fri Dec 23 10:29:45 2022:    3    | Tr.loss: 0.114975 | Tr.F1.:   0.97    |   46.26  s
WARNING:root:
        [!] Fri Dec 23 10:29:45 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671787785-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671787785-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671787785-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671787785-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\metrics_trainSize_91096_ep_3_cv_3_maxLen_1024_vocabSize_500_embeddingDim_64_lstmHidden_128_lstmLayers_1_lstmDropout_0_lstmBidirectional_True_batchNormConv_False_hiddenNeurons_256_128_batchNormFFNN_False.json
WARNING:root: [!] Average epoch time: 46.53s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.1098 -- F1: 0.1819
	FPR:  0.001 -- TPR: 0.5556 -- F1: 0.7124
	FPR:   0.01 -- TPR: 0.7017 -- F1: 0.8232
	FPR:    0.1 -- TPR: 0.9782 -- F1: 0.9707

WARNING:root: [!] Using vocabSize: 500 | maxLen: 2048
WARNING:root: [!] Using device: cuda:0 | Dataset size: 91096
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 500, 'embeddingDim': 64, 'lstmHidden': 128, 'lstmLayers': 1, 'lstmDropout': 0, 'lstmBidirectional': True, 'batchNormConv': False, 'hiddenNeurons': [256, 128], 'batchNormFFNN': False}
WARNING:root: [!] Fold 1/3 | Train set size: 60730, Validation set size: 30366
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 10:30:24 2022: Train Epoch: 1 [  0  /60730 (0 %)]	Loss: 0.695205 | F1-score: 0.32 | Elapsed: 0.34s
WARNING:root: [*] Fri Dec 23 10:30:33 2022: Train Epoch: 1 [6400 /60730 (11%)]	Loss: 0.264907 | F1-score: 0.91 | Elapsed: 8.73s
WARNING:root: [*] Fri Dec 23 10:30:42 2022: Train Epoch: 1 [12800/60730 (21%)]	Loss: 0.149628 | F1-score: 0.93 | Elapsed: 8.76s
WARNING:root: [*] Fri Dec 23 10:30:51 2022: Train Epoch: 1 [19200/60730 (32%)]	Loss: 0.199004 | F1-score: 0.93 | Elapsed: 8.79s
WARNING:root: [*] Fri Dec 23 10:31:00 2022: Train Epoch: 1 [25600/60730 (42%)]	Loss: 0.194227 | F1-score: 0.94 | Elapsed: 8.87s
WARNING:root: [*] Fri Dec 23 10:31:08 2022: Train Epoch: 1 [32000/60730 (53%)]	Loss: 0.263601 | F1-score: 0.94 | Elapsed: 8.81s
WARNING:root: [*] Fri Dec 23 10:31:17 2022: Train Epoch: 1 [38400/60730 (63%)]	Loss: 0.113620 | F1-score: 0.95 | Elapsed: 8.78s
WARNING:root: [*] Fri Dec 23 10:31:26 2022: Train Epoch: 1 [44800/60730 (74%)]	Loss: 0.233535 | F1-score: 0.95 | Elapsed: 8.77s
WARNING:root: [*] Fri Dec 23 10:31:35 2022: Train Epoch: 1 [51200/60730 (84%)]	Loss: 0.244523 | F1-score: 0.95 | Elapsed: 8.86s
WARNING:root: [*] Fri Dec 23 10:31:44 2022: Train Epoch: 1 [57600/60730 (95%)]	Loss: 0.117056 | F1-score: 0.95 | Elapsed: 8.89s
WARNING:root: [*] Fri Dec 23 10:31:48 2022:    1    | Tr.loss: 0.182272 | Tr.F1.:   0.95    |   83.84  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 10:31:48 2022: Train Epoch: 2 [  0  /60730 (0 %)]	Loss: 0.040761 | F1-score: 0.99 | Elapsed: 0.10s
WARNING:root: [*] Fri Dec 23 10:31:57 2022: Train Epoch: 2 [6400 /60730 (11%)]	Loss: 0.175146 | F1-score: 0.96 | Elapsed: 8.76s
WARNING:root: [*] Fri Dec 23 10:32:06 2022: Train Epoch: 2 [12800/60730 (21%)]	Loss: 0.172951 | F1-score: 0.97 | Elapsed: 8.80s
WARNING:root: [*] Fri Dec 23 10:32:14 2022: Train Epoch: 2 [19200/60730 (32%)]	Loss: 0.177105 | F1-score: 0.97 | Elapsed: 8.82s
WARNING:root: [*] Fri Dec 23 10:32:23 2022: Train Epoch: 2 [25600/60730 (42%)]	Loss: 0.094528 | F1-score: 0.97 | Elapsed: 8.75s
WARNING:root: [*] Fri Dec 23 10:32:32 2022: Train Epoch: 2 [32000/60730 (53%)]	Loss: 0.089363 | F1-score: 0.97 | Elapsed: 8.78s
WARNING:root: [*] Fri Dec 23 10:32:41 2022: Train Epoch: 2 [38400/60730 (63%)]	Loss: 0.239603 | F1-score: 0.97 | Elapsed: 8.88s
WARNING:root: [*] Fri Dec 23 10:32:50 2022: Train Epoch: 2 [44800/60730 (74%)]	Loss: 0.071722 | F1-score: 0.97 | Elapsed: 8.87s
WARNING:root: [*] Fri Dec 23 10:32:58 2022: Train Epoch: 2 [51200/60730 (84%)]	Loss: 0.088274 | F1-score: 0.97 | Elapsed: 8.82s
WARNING:root: [*] Fri Dec 23 10:33:07 2022: Train Epoch: 2 [57600/60730 (95%)]	Loss: 0.053303 | F1-score: 0.97 | Elapsed: 8.80s
WARNING:root: [*] Fri Dec 23 10:33:12 2022:    2    | Tr.loss: 0.125993 | Tr.F1.:   0.97    |   83.62  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 10:33:12 2022: Train Epoch: 3 [  0  /60730 (0 %)]	Loss: 0.162871 | F1-score: 0.97 | Elapsed: 0.10s
WARNING:root: [*] Fri Dec 23 10:33:21 2022: Train Epoch: 3 [6400 /60730 (11%)]	Loss: 0.160243 | F1-score: 0.97 | Elapsed: 8.90s
WARNING:root: [*] Fri Dec 23 10:33:29 2022: Train Epoch: 3 [12800/60730 (21%)]	Loss: 0.183457 | F1-score: 0.97 | Elapsed: 8.85s
WARNING:root: [*] Fri Dec 23 10:33:38 2022: Train Epoch: 3 [19200/60730 (32%)]	Loss: 0.040344 | F1-score: 0.97 | Elapsed: 8.84s
WARNING:root: [*] Fri Dec 23 10:33:47 2022: Train Epoch: 3 [25600/60730 (42%)]	Loss: 0.192294 | F1-score: 0.97 | Elapsed: 8.79s
WARNING:root: [*] Fri Dec 23 10:33:56 2022: Train Epoch: 3 [32000/60730 (53%)]	Loss: 0.088596 | F1-score: 0.97 | Elapsed: 8.83s
WARNING:root: [*] Fri Dec 23 10:34:05 2022: Train Epoch: 3 [38400/60730 (63%)]	Loss: 0.149914 | F1-score: 0.97 | Elapsed: 8.79s
WARNING:root: [*] Fri Dec 23 10:34:13 2022: Train Epoch: 3 [44800/60730 (74%)]	Loss: 0.204401 | F1-score: 0.97 | Elapsed: 8.80s
WARNING:root: [*] Fri Dec 23 10:34:22 2022: Train Epoch: 3 [51200/60730 (84%)]	Loss: 0.248245 | F1-score: 0.97 | Elapsed: 8.80s
WARNING:root: [*] Fri Dec 23 10:34:31 2022: Train Epoch: 3 [57600/60730 (95%)]	Loss: 0.117036 | F1-score: 0.97 | Elapsed: 8.83s
WARNING:root: [*] Fri Dec 23 10:34:35 2022:    3    | Tr.loss: 0.117664 | Tr.F1.:   0.97    |   83.80  s
WARNING:root:
        [!] Fri Dec 23 10:34:35 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671788075-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671788075-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671788075-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671788075-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 60731, Validation set size: 30365
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 10:34:51 2022: Train Epoch: 1 [  0  /60731 (0 %)]	Loss: 0.705948 | F1-score: 0.00 | Elapsed: 0.10s
WARNING:root: [*] Fri Dec 23 10:35:00 2022: Train Epoch: 1 [6400 /60731 (11%)]	Loss: 0.420897 | F1-score: 0.91 | Elapsed: 8.80s
WARNING:root: [*] Fri Dec 23 10:35:09 2022: Train Epoch: 1 [12800/60731 (21%)]	Loss: 0.137523 | F1-score: 0.93 | Elapsed: 8.81s
WARNING:root: [*] Fri Dec 23 10:35:18 2022: Train Epoch: 1 [19200/60731 (32%)]	Loss: 0.279736 | F1-score: 0.93 | Elapsed: 8.83s
WARNING:root: [*] Fri Dec 23 10:35:26 2022: Train Epoch: 1 [25600/60731 (42%)]	Loss: 0.195484 | F1-score: 0.94 | Elapsed: 8.80s
WARNING:root: [*] Fri Dec 23 10:35:35 2022: Train Epoch: 1 [32000/60731 (53%)]	Loss: 0.118177 | F1-score: 0.94 | Elapsed: 8.82s
WARNING:root: [*] Fri Dec 23 10:35:44 2022: Train Epoch: 1 [38400/60731 (63%)]	Loss: 0.068098 | F1-score: 0.95 | Elapsed: 8.83s
WARNING:root: [*] Fri Dec 23 10:35:53 2022: Train Epoch: 1 [44800/60731 (74%)]	Loss: 0.270989 | F1-score: 0.95 | Elapsed: 8.80s
WARNING:root: [*] Fri Dec 23 10:36:02 2022: Train Epoch: 1 [51200/60731 (84%)]	Loss: 0.095198 | F1-score: 0.95 | Elapsed: 8.81s
WARNING:root: [*] Fri Dec 23 10:36:10 2022: Train Epoch: 1 [57600/60731 (95%)]	Loss: 0.339095 | F1-score: 0.95 | Elapsed: 8.83s
WARNING:root: [*] Fri Dec 23 10:36:15 2022:    1    | Tr.loss: 0.184657 | Tr.F1.:   0.95    |   83.71  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 10:36:15 2022: Train Epoch: 2 [  0  /60731 (0 %)]	Loss: 0.238612 | F1-score: 0.92 | Elapsed: 0.10s
WARNING:root: [*] Fri Dec 23 10:36:24 2022: Train Epoch: 2 [6400 /60731 (11%)]	Loss: 0.132985 | F1-score: 0.97 | Elapsed: 8.88s
WARNING:root: [*] Fri Dec 23 10:36:33 2022: Train Epoch: 2 [12800/60731 (21%)]	Loss: 0.112359 | F1-score: 0.97 | Elapsed: 8.81s
WARNING:root: [*] Fri Dec 23 10:36:41 2022: Train Epoch: 2 [19200/60731 (32%)]	Loss: 0.119602 | F1-score: 0.97 | Elapsed: 8.84s
WARNING:root: [*] Fri Dec 23 10:36:50 2022: Train Epoch: 2 [25600/60731 (42%)]	Loss: 0.063613 | F1-score: 0.97 | Elapsed: 8.84s
WARNING:root: [*] Fri Dec 23 10:36:59 2022: Train Epoch: 2 [32000/60731 (53%)]	Loss: 0.041579 | F1-score: 0.97 | Elapsed: 8.82s
WARNING:root: [*] Fri Dec 23 10:37:08 2022: Train Epoch: 2 [38400/60731 (63%)]	Loss: 0.238215 | F1-score: 0.97 | Elapsed: 8.81s
WARNING:root: [*] Fri Dec 23 10:37:17 2022: Train Epoch: 2 [44800/60731 (74%)]	Loss: 0.208993 | F1-score: 0.97 | Elapsed: 8.89s
WARNING:root: [*] Fri Dec 23 10:37:26 2022: Train Epoch: 2 [51200/60731 (84%)]	Loss: 0.195285 | F1-score: 0.97 | Elapsed: 8.87s
WARNING:root: [*] Fri Dec 23 10:37:35 2022: Train Epoch: 2 [57600/60731 (95%)]	Loss: 0.103185 | F1-score: 0.97 | Elapsed: 8.89s
WARNING:root: [*] Fri Dec 23 10:37:39 2022:    2    | Tr.loss: 0.128773 | Tr.F1.:   0.97    |   83.99  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 10:37:39 2022: Train Epoch: 3 [  0  /60731 (0 %)]	Loss: 0.148723 | F1-score: 0.96 | Elapsed: 0.10s
WARNING:root: [*] Fri Dec 23 10:37:48 2022: Train Epoch: 3 [6400 /60731 (11%)]	Loss: 0.150634 | F1-score: 0.97 | Elapsed: 8.85s
WARNING:root: [*] Fri Dec 23 10:37:57 2022: Train Epoch: 3 [12800/60731 (21%)]	Loss: 0.135861 | F1-score: 0.97 | Elapsed: 8.87s
WARNING:root: [*] Fri Dec 23 10:38:05 2022: Train Epoch: 3 [19200/60731 (32%)]	Loss: 0.122666 | F1-score: 0.97 | Elapsed: 8.82s
WARNING:root: [*] Fri Dec 23 10:38:14 2022: Train Epoch: 3 [25600/60731 (42%)]	Loss: 0.192704 | F1-score: 0.97 | Elapsed: 8.85s
WARNING:root: [*] Fri Dec 23 10:38:23 2022: Train Epoch: 3 [32000/60731 (53%)]	Loss: 0.069257 | F1-score: 0.97 | Elapsed: 8.93s
WARNING:root: [*] Fri Dec 23 10:38:32 2022: Train Epoch: 3 [38400/60731 (63%)]	Loss: 0.122126 | F1-score: 0.97 | Elapsed: 8.86s
WARNING:root: [*] Fri Dec 23 10:38:41 2022: Train Epoch: 3 [44800/60731 (74%)]	Loss: 0.134249 | F1-score: 0.97 | Elapsed: 8.98s
WARNING:root: [*] Fri Dec 23 10:38:50 2022: Train Epoch: 3 [51200/60731 (84%)]	Loss: 0.088301 | F1-score: 0.97 | Elapsed: 8.94s
WARNING:root: [*] Fri Dec 23 10:38:59 2022: Train Epoch: 3 [57600/60731 (95%)]	Loss: 0.120345 | F1-score: 0.97 | Elapsed: 8.97s
WARNING:root: [*] Fri Dec 23 10:39:03 2022:    3    | Tr.loss: 0.117933 | Tr.F1.:   0.97    |   84.48  s
WARNING:root:
        [!] Fri Dec 23 10:39:03 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671788343-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671788343-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671788343-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671788343-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 60731, Validation set size: 30365
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 10:39:19 2022: Train Epoch: 1 [  0  /60731 (0 %)]	Loss: 0.705723 | F1-score: 0.07 | Elapsed: 0.09s
WARNING:root: [*] Fri Dec 23 10:39:28 2022: Train Epoch: 1 [6400 /60731 (11%)]	Loss: 0.184987 | F1-score: 0.90 | Elapsed: 8.85s
WARNING:root: [*] Fri Dec 23 10:39:37 2022: Train Epoch: 1 [12800/60731 (21%)]	Loss: 0.263287 | F1-score: 0.92 | Elapsed: 8.81s
WARNING:root: [*] Fri Dec 23 10:39:46 2022: Train Epoch: 1 [19200/60731 (32%)]	Loss: 0.113760 | F1-score: 0.93 | Elapsed: 8.84s
WARNING:root: [*] Fri Dec 23 10:39:55 2022: Train Epoch: 1 [25600/60731 (42%)]	Loss: 0.323776 | F1-score: 0.94 | Elapsed: 8.84s
WARNING:root: [*] Fri Dec 23 10:40:03 2022: Train Epoch: 1 [32000/60731 (53%)]	Loss: 0.129981 | F1-score: 0.94 | Elapsed: 8.92s
WARNING:root: [*] Fri Dec 23 10:40:12 2022: Train Epoch: 1 [38400/60731 (63%)]	Loss: 0.122963 | F1-score: 0.94 | Elapsed: 8.82s
WARNING:root: [*] Fri Dec 23 10:40:21 2022: Train Epoch: 1 [44800/60731 (74%)]	Loss: 0.087404 | F1-score: 0.95 | Elapsed: 8.84s
WARNING:root: [*] Fri Dec 23 10:40:30 2022: Train Epoch: 1 [51200/60731 (84%)]	Loss: 0.124355 | F1-score: 0.95 | Elapsed: 8.89s
WARNING:root: [*] Fri Dec 23 10:40:39 2022: Train Epoch: 1 [57600/60731 (95%)]	Loss: 0.071119 | F1-score: 0.95 | Elapsed: 8.85s
WARNING:root: [*] Fri Dec 23 10:40:43 2022:    1    | Tr.loss: 0.184919 | Tr.F1.:   0.95    |   84.03  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 10:40:43 2022: Train Epoch: 2 [  0  /60731 (0 %)]	Loss: 0.099419 | F1-score: 0.97 | Elapsed: 0.09s
WARNING:root: [*] Fri Dec 23 10:40:52 2022: Train Epoch: 2 [6400 /60731 (11%)]	Loss: 0.150786 | F1-score: 0.97 | Elapsed: 8.88s
WARNING:root: [*] Fri Dec 23 10:41:01 2022: Train Epoch: 2 [12800/60731 (21%)]	Loss: 0.155143 | F1-score: 0.97 | Elapsed: 8.81s
WARNING:root: [*] Fri Dec 23 10:41:10 2022: Train Epoch: 2 [19200/60731 (32%)]	Loss: 0.080015 | F1-score: 0.97 | Elapsed: 8.82s
WARNING:root: [*] Fri Dec 23 10:41:18 2022: Train Epoch: 2 [25600/60731 (42%)]	Loss: 0.151882 | F1-score: 0.97 | Elapsed: 8.79s
WARNING:root: [*] Fri Dec 23 10:41:27 2022: Train Epoch: 2 [32000/60731 (53%)]	Loss: 0.188086 | F1-score: 0.97 | Elapsed: 8.83s
WARNING:root: [*] Fri Dec 23 10:41:36 2022: Train Epoch: 2 [38400/60731 (63%)]	Loss: 0.115488 | F1-score: 0.97 | Elapsed: 8.83s
WARNING:root: [*] Fri Dec 23 10:41:45 2022: Train Epoch: 2 [44800/60731 (74%)]	Loss: 0.152639 | F1-score: 0.97 | Elapsed: 8.83s
WARNING:root: [*] Fri Dec 23 10:41:54 2022: Train Epoch: 2 [51200/60731 (84%)]	Loss: 0.096109 | F1-score: 0.97 | Elapsed: 8.82s
WARNING:root: [*] Fri Dec 23 10:42:03 2022: Train Epoch: 2 [57600/60731 (95%)]	Loss: 0.040849 | F1-score: 0.97 | Elapsed: 8.81s
WARNING:root: [*] Fri Dec 23 10:42:07 2022:    2    | Tr.loss: 0.129540 | Tr.F1.:   0.97    |   83.76  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 10:42:07 2022: Train Epoch: 3 [  0  /60731 (0 %)]	Loss: 0.111683 | F1-score: 0.99 | Elapsed: 0.09s
WARNING:root: [*] Fri Dec 23 10:42:16 2022: Train Epoch: 3 [6400 /60731 (11%)]	Loss: 0.046997 | F1-score: 0.97 | Elapsed: 8.85s
WARNING:root: [*] Fri Dec 23 10:42:25 2022: Train Epoch: 3 [12800/60731 (21%)]	Loss: 0.159907 | F1-score: 0.97 | Elapsed: 8.85s
WARNING:root: [*] Fri Dec 23 10:42:33 2022: Train Epoch: 3 [19200/60731 (32%)]	Loss: 0.155264 | F1-score: 0.97 | Elapsed: 8.84s
WARNING:root: [*] Fri Dec 23 10:42:42 2022: Train Epoch: 3 [25600/60731 (42%)]	Loss: 0.049021 | F1-score: 0.97 | Elapsed: 8.83s
WARNING:root: [*] Fri Dec 23 10:42:51 2022: Train Epoch: 3 [32000/60731 (53%)]	Loss: 0.126353 | F1-score: 0.97 | Elapsed: 8.83s
WARNING:root: [*] Fri Dec 23 10:43:00 2022: Train Epoch: 3 [38400/60731 (63%)]	Loss: 0.200905 | F1-score: 0.97 | Elapsed: 8.81s
WARNING:root: [*] Fri Dec 23 10:43:09 2022: Train Epoch: 3 [44800/60731 (74%)]	Loss: 0.031127 | F1-score: 0.97 | Elapsed: 8.89s
WARNING:root: [*] Fri Dec 23 10:43:18 2022: Train Epoch: 3 [51200/60731 (84%)]	Loss: 0.102448 | F1-score: 0.97 | Elapsed: 8.82s
WARNING:root: [*] Fri Dec 23 10:43:26 2022: Train Epoch: 3 [57600/60731 (95%)]	Loss: 0.125545 | F1-score: 0.97 | Elapsed: 8.81s
WARNING:root: [*] Fri Dec 23 10:43:31 2022:    3    | Tr.loss: 0.118006 | Tr.F1.:   0.97    |   83.83  s
WARNING:root:
        [!] Fri Dec 23 10:43:31 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671788611-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671788611-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671788611-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671788611-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\metrics_trainSize_91096_ep_3_cv_3_maxLen_2048_vocabSize_500_embeddingDim_64_lstmHidden_128_lstmLayers_1_lstmDropout_0_lstmBidirectional_True_batchNormConv_False_hiddenNeurons_256_128_batchNormFFNN_False.json
WARNING:root: [!] Average epoch time: 83.90s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.1669 -- F1: 0.2691
	FPR:  0.001 -- TPR: 0.6229 -- F1: 0.7673
	FPR:   0.01 -- TPR: 0.6914 -- F1: 0.8161
	FPR:    0.1 -- TPR: 0.9820 -- F1: 0.9722

WARNING:root: [!] Using vocabSize: 500 | maxLen: 512
WARNING:root: [!] Using device: cuda:0 | Dataset size: 91096
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 500, 'embeddingDim': 64, 'lstmHidden': 128, 'lstmLayers': 1, 'lstmDropout': 0, 'lstmBidirectional': True, 'batchNormConv': False, 'hiddenNeurons': [256, 128], 'batchNormFFNN': False}
WARNING:root: [!] Fold 1/3 | Train set size: 60730, Validation set size: 30366
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 10:44:17 2022: Train Epoch: 1 [  0  /60730 (0 %)]	Loss: 0.683478 | F1-score: 0.80 | Elapsed: 0.30s
WARNING:root: [*] Fri Dec 23 10:44:20 2022: Train Epoch: 1 [6400 /60730 (11%)]	Loss: 0.285496 | F1-score: 0.91 | Elapsed: 2.90s
WARNING:root: [*] Fri Dec 23 10:44:22 2022: Train Epoch: 1 [12800/60730 (21%)]	Loss: 0.150789 | F1-score: 0.93 | Elapsed: 2.87s
WARNING:root: [*] Fri Dec 23 10:44:25 2022: Train Epoch: 1 [19200/60730 (32%)]	Loss: 0.153233 | F1-score: 0.93 | Elapsed: 2.89s
WARNING:root: [*] Fri Dec 23 10:44:28 2022: Train Epoch: 1 [25600/60730 (42%)]	Loss: 0.263374 | F1-score: 0.94 | Elapsed: 2.87s
WARNING:root: [*] Fri Dec 23 10:44:31 2022: Train Epoch: 1 [32000/60730 (53%)]	Loss: 0.211099 | F1-score: 0.94 | Elapsed: 2.89s
WARNING:root: [*] Fri Dec 23 10:44:34 2022: Train Epoch: 1 [38400/60730 (63%)]	Loss: 0.160923 | F1-score: 0.94 | Elapsed: 2.93s
WARNING:root: [*] Fri Dec 23 10:44:37 2022: Train Epoch: 1 [44800/60730 (74%)]	Loss: 0.202288 | F1-score: 0.94 | Elapsed: 3.12s
WARNING:root: [*] Fri Dec 23 10:44:40 2022: Train Epoch: 1 [51200/60730 (84%)]	Loss: 0.208250 | F1-score: 0.95 | Elapsed: 3.14s
WARNING:root: [*] Fri Dec 23 10:44:43 2022: Train Epoch: 1 [57600/60730 (95%)]	Loss: 0.185988 | F1-score: 0.95 | Elapsed: 2.95s
WARNING:root: [*] Fri Dec 23 10:44:45 2022:    1    | Tr.loss: 0.196105 | Tr.F1.:   0.95    |   28.29  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 10:44:45 2022: Train Epoch: 2 [  0  /60730 (0 %)]	Loss: 0.113478 | F1-score: 0.98 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 10:44:48 2022: Train Epoch: 2 [6400 /60730 (11%)]	Loss: 0.110285 | F1-score: 0.96 | Elapsed: 2.95s
WARNING:root: [*] Fri Dec 23 10:44:51 2022: Train Epoch: 2 [12800/60730 (21%)]	Loss: 0.163722 | F1-score: 0.96 | Elapsed: 3.04s
WARNING:root: [*] Fri Dec 23 10:44:54 2022: Train Epoch: 2 [19200/60730 (32%)]	Loss: 0.258105 | F1-score: 0.96 | Elapsed: 3.00s
WARNING:root: [*] Fri Dec 23 10:44:57 2022: Train Epoch: 2 [25600/60730 (42%)]	Loss: 0.123214 | F1-score: 0.96 | Elapsed: 2.88s
WARNING:root: [*] Fri Dec 23 10:45:00 2022: Train Epoch: 2 [32000/60730 (53%)]	Loss: 0.079824 | F1-score: 0.96 | Elapsed: 3.07s
WARNING:root: [*] Fri Dec 23 10:45:03 2022: Train Epoch: 2 [38400/60730 (63%)]	Loss: 0.150908 | F1-score: 0.96 | Elapsed: 3.05s
WARNING:root: [*] Fri Dec 23 10:45:06 2022: Train Epoch: 2 [44800/60730 (74%)]	Loss: 0.205720 | F1-score: 0.96 | Elapsed: 3.18s
WARNING:root: [*] Fri Dec 23 10:45:09 2022: Train Epoch: 2 [51200/60730 (84%)]	Loss: 0.101466 | F1-score: 0.96 | Elapsed: 2.99s
WARNING:root: [*] Fri Dec 23 10:45:12 2022: Train Epoch: 2 [57600/60730 (95%)]	Loss: 0.228974 | F1-score: 0.96 | Elapsed: 2.95s
WARNING:root: [*] Fri Dec 23 10:45:13 2022:    2    | Tr.loss: 0.144001 | Tr.F1.:   0.96    |   28.57  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 10:45:13 2022: Train Epoch: 3 [  0  /60730 (0 %)]	Loss: 0.088209 | F1-score: 0.95 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 10:45:16 2022: Train Epoch: 3 [6400 /60730 (11%)]	Loss: 0.064304 | F1-score: 0.96 | Elapsed: 3.01s
WARNING:root: [*] Fri Dec 23 10:45:19 2022: Train Epoch: 3 [12800/60730 (21%)]	Loss: 0.109085 | F1-score: 0.96 | Elapsed: 3.00s
WARNING:root: [*] Fri Dec 23 10:45:22 2022: Train Epoch: 3 [19200/60730 (32%)]	Loss: 0.136744 | F1-score: 0.96 | Elapsed: 3.08s
WARNING:root: [*] Fri Dec 23 10:45:25 2022: Train Epoch: 3 [25600/60730 (42%)]	Loss: 0.146083 | F1-score: 0.96 | Elapsed: 3.10s
WARNING:root: [*] Fri Dec 23 10:45:28 2022: Train Epoch: 3 [32000/60730 (53%)]	Loss: 0.072318 | F1-score: 0.96 | Elapsed: 3.02s
WARNING:root: [*] Fri Dec 23 10:45:32 2022: Train Epoch: 3 [38400/60730 (63%)]	Loss: 0.114757 | F1-score: 0.96 | Elapsed: 3.13s
WARNING:root: [*] Fri Dec 23 10:45:35 2022: Train Epoch: 3 [44800/60730 (74%)]	Loss: 0.154377 | F1-score: 0.96 | Elapsed: 3.13s
WARNING:root: [*] Fri Dec 23 10:45:38 2022: Train Epoch: 3 [51200/60730 (84%)]	Loss: 0.097720 | F1-score: 0.96 | Elapsed: 3.16s
WARNING:root: [*] Fri Dec 23 10:45:41 2022: Train Epoch: 3 [57600/60730 (95%)]	Loss: 0.154702 | F1-score: 0.96 | Elapsed: 3.14s
WARNING:root: [*] Fri Dec 23 10:45:43 2022:    3    | Tr.loss: 0.132703 | Tr.F1.:   0.96    |   29.28  s
WARNING:root:
        [!] Fri Dec 23 10:45:43 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671788743-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671788743-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671788743-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671788743-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 60731, Validation set size: 30365
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 10:45:47 2022: Train Epoch: 1 [  0  /60731 (0 %)]	Loss: 0.705500 | F1-score: 0.00 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 10:45:50 2022: Train Epoch: 1 [6400 /60731 (11%)]	Loss: 0.357164 | F1-score: 0.89 | Elapsed: 2.89s
WARNING:root: [*] Fri Dec 23 10:45:53 2022: Train Epoch: 1 [12800/60731 (21%)]	Loss: 0.207245 | F1-score: 0.92 | Elapsed: 2.85s
WARNING:root: [*] Fri Dec 23 10:45:56 2022: Train Epoch: 1 [19200/60731 (32%)]	Loss: 0.178153 | F1-score: 0.93 | Elapsed: 2.96s
WARNING:root: [*] Fri Dec 23 10:45:59 2022: Train Epoch: 1 [25600/60731 (42%)]	Loss: 0.121144 | F1-score: 0.94 | Elapsed: 2.88s
WARNING:root: [*] Fri Dec 23 10:46:02 2022: Train Epoch: 1 [32000/60731 (53%)]	Loss: 0.216538 | F1-score: 0.94 | Elapsed: 2.91s
WARNING:root: [*] Fri Dec 23 10:46:04 2022: Train Epoch: 1 [38400/60731 (63%)]	Loss: 0.202688 | F1-score: 0.94 | Elapsed: 2.91s
WARNING:root: [*] Fri Dec 23 10:46:07 2022: Train Epoch: 1 [44800/60731 (74%)]	Loss: 0.300387 | F1-score: 0.94 | Elapsed: 2.96s
WARNING:root: [*] Fri Dec 23 10:46:10 2022: Train Epoch: 1 [51200/60731 (84%)]	Loss: 0.267848 | F1-score: 0.95 | Elapsed: 2.88s
WARNING:root: [*] Fri Dec 23 10:46:13 2022: Train Epoch: 1 [57600/60731 (95%)]	Loss: 0.142604 | F1-score: 0.95 | Elapsed: 2.87s
WARNING:root: [*] Fri Dec 23 10:46:15 2022:    1    | Tr.loss: 0.201258 | Tr.F1.:   0.95    |   27.56  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 10:46:15 2022: Train Epoch: 2 [  0  /60731 (0 %)]	Loss: 0.217034 | F1-score: 0.94 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 10:46:18 2022: Train Epoch: 2 [6400 /60731 (11%)]	Loss: 0.195391 | F1-score: 0.96 | Elapsed: 2.97s
WARNING:root: [*] Fri Dec 23 10:46:21 2022: Train Epoch: 2 [12800/60731 (21%)]	Loss: 0.152922 | F1-score: 0.96 | Elapsed: 2.95s
WARNING:root: [*] Fri Dec 23 10:46:23 2022: Train Epoch: 2 [19200/60731 (32%)]	Loss: 0.077621 | F1-score: 0.96 | Elapsed: 2.81s
WARNING:root: [*] Fri Dec 23 10:46:26 2022: Train Epoch: 2 [25600/60731 (42%)]	Loss: 0.258641 | F1-score: 0.96 | Elapsed: 2.83s
WARNING:root: [*] Fri Dec 23 10:46:29 2022: Train Epoch: 2 [32000/60731 (53%)]	Loss: 0.086700 | F1-score: 0.96 | Elapsed: 2.88s
WARNING:root: [*] Fri Dec 23 10:46:32 2022: Train Epoch: 2 [38400/60731 (63%)]	Loss: 0.204024 | F1-score: 0.96 | Elapsed: 2.94s
WARNING:root: [*] Fri Dec 23 10:46:35 2022: Train Epoch: 2 [44800/60731 (74%)]	Loss: 0.082589 | F1-score: 0.96 | Elapsed: 2.96s
WARNING:root: [*] Fri Dec 23 10:46:38 2022: Train Epoch: 2 [51200/60731 (84%)]	Loss: 0.103578 | F1-score: 0.96 | Elapsed: 2.90s
WARNING:root: [*] Fri Dec 23 10:46:41 2022: Train Epoch: 2 [57600/60731 (95%)]	Loss: 0.066232 | F1-score: 0.96 | Elapsed: 2.86s
WARNING:root: [*] Fri Dec 23 10:46:42 2022:    2    | Tr.loss: 0.144673 | Tr.F1.:   0.96    |   27.49  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 10:46:42 2022: Train Epoch: 3 [  0  /60731 (0 %)]	Loss: 0.150621 | F1-score: 0.96 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 10:46:45 2022: Train Epoch: 3 [6400 /60731 (11%)]	Loss: 0.216930 | F1-score: 0.96 | Elapsed: 2.90s
WARNING:root: [*] Fri Dec 23 10:46:48 2022: Train Epoch: 3 [12800/60731 (21%)]	Loss: 0.135946 | F1-score: 0.96 | Elapsed: 2.92s
WARNING:root: [*] Fri Dec 23 10:46:51 2022: Train Epoch: 3 [19200/60731 (32%)]	Loss: 0.107905 | F1-score: 0.97 | Elapsed: 2.95s
WARNING:root: [*] Fri Dec 23 10:46:54 2022: Train Epoch: 3 [25600/60731 (42%)]	Loss: 0.227285 | F1-score: 0.96 | Elapsed: 2.81s
WARNING:root: [*] Fri Dec 23 10:46:57 2022: Train Epoch: 3 [32000/60731 (53%)]	Loss: 0.146122 | F1-score: 0.96 | Elapsed: 2.85s
WARNING:root: [*] Fri Dec 23 10:46:59 2022: Train Epoch: 3 [38400/60731 (63%)]	Loss: 0.076256 | F1-score: 0.96 | Elapsed: 2.83s
WARNING:root: [*] Fri Dec 23 10:47:02 2022: Train Epoch: 3 [44800/60731 (74%)]	Loss: 0.072886 | F1-score: 0.96 | Elapsed: 2.88s
WARNING:root: [*] Fri Dec 23 10:47:05 2022: Train Epoch: 3 [51200/60731 (84%)]	Loss: 0.134804 | F1-score: 0.96 | Elapsed: 2.90s
WARNING:root: [*] Fri Dec 23 10:47:08 2022: Train Epoch: 3 [57600/60731 (95%)]	Loss: 0.122377 | F1-score: 0.96 | Elapsed: 2.96s
WARNING:root: [*] Fri Dec 23 10:47:10 2022:    3    | Tr.loss: 0.131489 | Tr.F1.:   0.96    |   27.47  s
WARNING:root:
        [!] Fri Dec 23 10:47:10 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671788830-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671788830-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671788830-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671788830-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 60731, Validation set size: 30365
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 10:47:14 2022: Train Epoch: 1 [  0  /60731 (0 %)]	Loss: 0.699655 | F1-score: 0.21 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 10:47:17 2022: Train Epoch: 1 [6400 /60731 (11%)]	Loss: 0.268062 | F1-score: 0.91 | Elapsed: 2.85s
WARNING:root: [*] Fri Dec 23 10:47:20 2022: Train Epoch: 1 [12800/60731 (21%)]	Loss: 0.162824 | F1-score: 0.93 | Elapsed: 2.83s
WARNING:root: [*] Fri Dec 23 10:47:23 2022: Train Epoch: 1 [19200/60731 (32%)]	Loss: 0.225635 | F1-score: 0.94 | Elapsed: 2.83s
WARNING:root: [*] Fri Dec 23 10:47:26 2022: Train Epoch: 1 [25600/60731 (42%)]	Loss: 0.174585 | F1-score: 0.94 | Elapsed: 2.96s
WARNING:root: [*] Fri Dec 23 10:47:29 2022: Train Epoch: 1 [32000/60731 (53%)]	Loss: 0.234808 | F1-score: 0.94 | Elapsed: 2.97s
WARNING:root: [*] Fri Dec 23 10:47:32 2022: Train Epoch: 1 [38400/60731 (63%)]	Loss: 0.153293 | F1-score: 0.94 | Elapsed: 3.01s
WARNING:root: [*] Fri Dec 23 10:47:34 2022: Train Epoch: 1 [44800/60731 (74%)]	Loss: 0.151233 | F1-score: 0.95 | Elapsed: 2.93s
WARNING:root: [*] Fri Dec 23 10:47:37 2022: Train Epoch: 1 [51200/60731 (84%)]	Loss: 0.205821 | F1-score: 0.95 | Elapsed: 2.92s
WARNING:root: [*] Fri Dec 23 10:47:40 2022: Train Epoch: 1 [57600/60731 (95%)]	Loss: 0.074818 | F1-score: 0.95 | Elapsed: 3.00s
WARNING:root: [*] Fri Dec 23 10:47:42 2022:    1    | Tr.loss: 0.194369 | Tr.F1.:   0.95    |   27.75  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 10:47:42 2022: Train Epoch: 2 [  0  /60731 (0 %)]	Loss: 0.159707 | F1-score: 0.94 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 10:47:45 2022: Train Epoch: 2 [6400 /60731 (11%)]	Loss: 0.202961 | F1-score: 0.96 | Elapsed: 2.95s
WARNING:root: [*] Fri Dec 23 10:47:48 2022: Train Epoch: 2 [12800/60731 (21%)]	Loss: 0.264347 | F1-score: 0.96 | Elapsed: 2.84s
WARNING:root: [*] Fri Dec 23 10:47:50 2022: Train Epoch: 2 [19200/60731 (32%)]	Loss: 0.148752 | F1-score: 0.96 | Elapsed: 2.83s
WARNING:root: [*] Fri Dec 23 10:47:53 2022: Train Epoch: 2 [25600/60731 (42%)]	Loss: 0.246197 | F1-score: 0.96 | Elapsed: 2.84s
WARNING:root: [*] Fri Dec 23 10:47:56 2022: Train Epoch: 2 [32000/60731 (53%)]	Loss: 0.194803 | F1-score: 0.96 | Elapsed: 2.81s
WARNING:root: [*] Fri Dec 23 10:47:59 2022: Train Epoch: 2 [38400/60731 (63%)]	Loss: 0.157322 | F1-score: 0.96 | Elapsed: 2.84s
WARNING:root: [*] Fri Dec 23 10:48:02 2022: Train Epoch: 2 [44800/60731 (74%)]	Loss: 0.172174 | F1-score: 0.96 | Elapsed: 2.82s
WARNING:root: [*] Fri Dec 23 10:48:05 2022: Train Epoch: 2 [51200/60731 (84%)]	Loss: 0.157114 | F1-score: 0.96 | Elapsed: 2.84s
WARNING:root: [*] Fri Dec 23 10:48:07 2022: Train Epoch: 2 [57600/60731 (95%)]	Loss: 0.193139 | F1-score: 0.96 | Elapsed: 2.87s
WARNING:root: [*] Fri Dec 23 10:48:09 2022:    2    | Tr.loss: 0.143340 | Tr.F1.:   0.96    |   27.04  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 10:48:09 2022: Train Epoch: 3 [  0  /60731 (0 %)]	Loss: 0.185855 | F1-score: 0.94 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 10:48:12 2022: Train Epoch: 3 [6400 /60731 (11%)]	Loss: 0.100310 | F1-score: 0.96 | Elapsed: 2.86s
WARNING:root: [*] Fri Dec 23 10:48:15 2022: Train Epoch: 3 [12800/60731 (21%)]	Loss: 0.079515 | F1-score: 0.96 | Elapsed: 2.84s
WARNING:root: [*] Fri Dec 23 10:48:17 2022: Train Epoch: 3 [19200/60731 (32%)]	Loss: 0.106421 | F1-score: 0.96 | Elapsed: 2.83s
WARNING:root: [*] Fri Dec 23 10:48:20 2022: Train Epoch: 3 [25600/60731 (42%)]	Loss: 0.164498 | F1-score: 0.96 | Elapsed: 2.83s
WARNING:root: [*] Fri Dec 23 10:48:23 2022: Train Epoch: 3 [32000/60731 (53%)]	Loss: 0.097762 | F1-score: 0.96 | Elapsed: 2.83s
WARNING:root: [*] Fri Dec 23 10:48:26 2022: Train Epoch: 3 [38400/60731 (63%)]	Loss: 0.052479 | F1-score: 0.96 | Elapsed: 2.82s
WARNING:root: [*] Fri Dec 23 10:48:29 2022: Train Epoch: 3 [44800/60731 (74%)]	Loss: 0.233226 | F1-score: 0.96 | Elapsed: 2.86s
WARNING:root: [*] Fri Dec 23 10:48:32 2022: Train Epoch: 3 [51200/60731 (84%)]	Loss: 0.071591 | F1-score: 0.96 | Elapsed: 2.82s
WARNING:root: [*] Fri Dec 23 10:48:34 2022: Train Epoch: 3 [57600/60731 (95%)]	Loss: 0.168061 | F1-score: 0.97 | Elapsed: 2.84s
WARNING:root: [*] Fri Dec 23 10:48:36 2022:    3    | Tr.loss: 0.131081 | Tr.F1.:   0.97    |   26.96  s
WARNING:root:
        [!] Fri Dec 23 10:48:36 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671788916-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671788916-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671788916-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\trainingFiles\trainingFiles_1671788916-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\Cnn1DLSTM_VocabSize_maxLen\metrics_trainSize_91096_ep_3_cv_3_maxLen_512_vocabSize_500_embeddingDim_64_lstmHidden_128_lstmLayers_1_lstmDropout_0_lstmBidirectional_True_batchNormConv_False_hiddenNeurons_256_128_batchNormFFNN_False.json
WARNING:root: [!] Average epoch time: 27.82s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.2899 -- F1: 0.4490
	FPR:  0.001 -- TPR: 0.5721 -- F1: 0.7273
	FPR:   0.01 -- TPR: 0.6787 -- F1: 0.8074
	FPR:    0.1 -- TPR: 0.9725 -- F1: 0.9670

