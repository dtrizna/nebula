WARNING:root: [!] Using device: cuda:0 | Dataset size: 91096
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 2000, 'dModel': 32, 'nHeads': 8, 'dHidden': 64, 'nLayers': 2, 'numClasses': 1, 'hiddenNeurons': [64], 'layerNorm': False, 'dropout': 0.5}
WARNING:root: [!] Fold 1/3 | Train set size: 60730, Validation set size: 30366
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Thu Dec 22 16:49:58 2022: Train Epoch: 1 [  0  /60730 (0 %)]	Loss: 0.692827 | F1-score: 0.56 | Elapsed: 1.44s
WARNING:root: [*] Thu Dec 22 16:50:04 2022: Train Epoch: 1 [6400 /60730 (11%)]	Loss: 0.496759 | F1-score: 0.83 | Elapsed: 5.70s
WARNING:root: [*] Thu Dec 22 16:50:10 2022: Train Epoch: 1 [12800/60730 (21%)]	Loss: 0.424841 | F1-score: 0.86 | Elapsed: 6.31s
WARNING:root: [*] Thu Dec 22 16:50:17 2022: Train Epoch: 1 [19200/60730 (32%)]	Loss: 0.433469 | F1-score: 0.87 | Elapsed: 6.44s
WARNING:root: [*] Thu Dec 22 16:50:23 2022: Train Epoch: 1 [25600/60730 (42%)]	Loss: 0.508868 | F1-score: 0.88 | Elapsed: 6.64s
WARNING:root: [*] Thu Dec 22 16:50:30 2022: Train Epoch: 1 [32000/60730 (53%)]	Loss: 0.459502 | F1-score: 0.88 | Elapsed: 6.86s
WARNING:root: [*] Thu Dec 22 16:50:37 2022: Train Epoch: 1 [38400/60730 (63%)]	Loss: 0.357744 | F1-score: 0.88 | Elapsed: 6.76s
WARNING:root: [*] Thu Dec 22 16:50:42 2022: Train Epoch: 1 [44800/60730 (74%)]	Loss: 0.411558 | F1-score: 0.89 | Elapsed: 5.14s
WARNING:root: [*] Thu Dec 22 16:50:47 2022: Train Epoch: 1 [51200/60730 (84%)]	Loss: 0.327851 | F1-score: 0.89 | Elapsed: 4.71s
WARNING:root: [*] Thu Dec 22 16:50:51 2022: Train Epoch: 1 [57600/60730 (95%)]	Loss: 0.276037 | F1-score: 0.89 | Elapsed: 4.64s
WARNING:root: [*] Thu Dec 22 16:50:54 2022:    1    | Tr.loss: 0.410500 | Tr.F1.:   0.89    |   56.95  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Thu Dec 22 16:50:54 2022: Train Epoch: 2 [  0  /60730 (0 %)]	Loss: 0.445538 | F1-score: 0.86 | Elapsed: 0.06s
WARNING:root: [*] Thu Dec 22 16:50:59 2022: Train Epoch: 2 [6400 /60730 (11%)]	Loss: 0.376472 | F1-score: 0.91 | Elapsed: 4.76s
WARNING:root: [*] Thu Dec 22 16:51:03 2022: Train Epoch: 2 [12800/60730 (21%)]	Loss: 0.285549 | F1-score: 0.92 | Elapsed: 4.76s
WARNING:root: [*] Thu Dec 22 16:51:08 2022: Train Epoch: 2 [19200/60730 (32%)]	Loss: 0.334520 | F1-score: 0.92 | Elapsed: 4.95s
WARNING:root: [*] Thu Dec 22 16:51:13 2022: Train Epoch: 2 [25600/60730 (42%)]	Loss: 0.405961 | F1-score: 0.92 | Elapsed: 5.03s
WARNING:root: [*] Thu Dec 22 16:51:19 2022: Train Epoch: 2 [32000/60730 (53%)]	Loss: 0.249046 | F1-score: 0.92 | Elapsed: 5.94s
WARNING:root: [*] Thu Dec 22 16:51:25 2022: Train Epoch: 2 [38400/60730 (63%)]	Loss: 0.286996 | F1-score: 0.92 | Elapsed: 5.95s
WARNING:root: [*] Thu Dec 22 16:51:31 2022: Train Epoch: 2 [44800/60730 (74%)]	Loss: 0.221612 | F1-score: 0.92 | Elapsed: 5.94s
WARNING:root: [*] Thu Dec 22 16:51:37 2022: Train Epoch: 2 [51200/60730 (84%)]	Loss: 0.173940 | F1-score: 0.92 | Elapsed: 5.94s
WARNING:root: [*] Thu Dec 22 16:51:43 2022: Train Epoch: 2 [57600/60730 (95%)]	Loss: 0.342406 | F1-score: 0.92 | Elapsed: 5.97s
WARNING:root: [*] Thu Dec 22 16:51:46 2022:    2    | Tr.loss: 0.294760 | Tr.F1.:   0.92    |   52.16  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Thu Dec 22 16:51:46 2022: Train Epoch: 3 [  0  /60730 (0 %)]	Loss: 0.144763 | F1-score: 0.97 | Elapsed: 0.07s
WARNING:root: [*] Thu Dec 22 16:51:52 2022: Train Epoch: 3 [6400 /60730 (11%)]	Loss: 0.307189 | F1-score: 0.94 | Elapsed: 5.97s
WARNING:root: [*] Thu Dec 22 16:51:58 2022: Train Epoch: 3 [12800/60730 (21%)]	Loss: 0.118484 | F1-score: 0.94 | Elapsed: 5.98s
WARNING:root: [*] Thu Dec 22 16:52:04 2022: Train Epoch: 3 [19200/60730 (32%)]	Loss: 0.147679 | F1-score: 0.94 | Elapsed: 5.97s
WARNING:root: [*] Thu Dec 22 16:52:10 2022: Train Epoch: 3 [25600/60730 (42%)]	Loss: 0.297900 | F1-score: 0.94 | Elapsed: 6.00s
WARNING:root: [*] Thu Dec 22 16:52:16 2022: Train Epoch: 3 [32000/60730 (53%)]	Loss: 0.122809 | F1-score: 0.94 | Elapsed: 5.97s
WARNING:root: [*] Thu Dec 22 16:52:22 2022: Train Epoch: 3 [38400/60730 (63%)]	Loss: 0.271645 | F1-score: 0.94 | Elapsed: 5.98s
WARNING:root: [*] Thu Dec 22 16:52:28 2022: Train Epoch: 3 [44800/60730 (74%)]	Loss: 0.268029 | F1-score: 0.94 | Elapsed: 5.98s
WARNING:root: [*] Thu Dec 22 16:52:34 2022: Train Epoch: 3 [51200/60730 (84%)]	Loss: 0.174589 | F1-score: 0.94 | Elapsed: 5.99s
WARNING:root: [*] Thu Dec 22 16:52:40 2022: Train Epoch: 3 [57600/60730 (95%)]	Loss: 0.223524 | F1-score: 0.94 | Elapsed: 6.00s
WARNING:root: [*] Thu Dec 22 16:52:43 2022:    3    | Tr.loss: 0.248212 | Tr.F1.:   0.94    |   56.78  s
WARNING:root:
        [!] Thu Dec 22 16:52:43 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\trainingFiles\trainingFiles_1671724363-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\trainingFiles\trainingFiles_1671724363-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\trainingFiles\trainingFiles_1671724363-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\trainingFiles\trainingFiles_1671724363-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 60731, Validation set size: 30365
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Thu Dec 22 16:52:51 2022: Train Epoch: 1 [  0  /60731 (0 %)]	Loss: 0.716840 | F1-score: 0.33 | Elapsed: 0.05s
WARNING:root: [*] Thu Dec 22 16:52:57 2022: Train Epoch: 1 [6400 /60731 (11%)]	Loss: 0.461531 | F1-score: 0.83 | Elapsed: 5.97s
WARNING:root: [*] Thu Dec 22 16:53:03 2022: Train Epoch: 1 [12800/60731 (21%)]	Loss: 0.395673 | F1-score: 0.86 | Elapsed: 5.94s
WARNING:root: [*] Thu Dec 22 16:53:09 2022: Train Epoch: 1 [19200/60731 (32%)]	Loss: 0.374207 | F1-score: 0.87 | Elapsed: 5.94s
WARNING:root: [*] Thu Dec 22 16:53:15 2022: Train Epoch: 1 [25600/60731 (42%)]	Loss: 0.279780 | F1-score: 0.87 | Elapsed: 5.93s
WARNING:root: [*] Thu Dec 22 16:53:20 2022: Train Epoch: 1 [32000/60731 (53%)]	Loss: 0.318417 | F1-score: 0.88 | Elapsed: 5.94s
WARNING:root: [*] Thu Dec 22 16:53:26 2022: Train Epoch: 1 [38400/60731 (63%)]	Loss: 0.406718 | F1-score: 0.88 | Elapsed: 5.99s
WARNING:root: [*] Thu Dec 22 16:53:32 2022: Train Epoch: 1 [44800/60731 (74%)]	Loss: 0.323661 | F1-score: 0.88 | Elapsed: 6.02s
WARNING:root: [*] Thu Dec 22 16:53:38 2022: Train Epoch: 1 [51200/60731 (84%)]	Loss: 0.354169 | F1-score: 0.89 | Elapsed: 6.01s
WARNING:root: [*] Thu Dec 22 16:53:44 2022: Train Epoch: 1 [57600/60731 (95%)]	Loss: 0.295369 | F1-score: 0.89 | Elapsed: 5.96s
WARNING:root: [*] Thu Dec 22 16:53:47 2022:    1    | Tr.loss: 0.402915 | Tr.F1.:   0.89    |   56.61  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Thu Dec 22 16:53:47 2022: Train Epoch: 2 [  0  /60731 (0 %)]	Loss: 0.259153 | F1-score: 0.94 | Elapsed: 0.06s
WARNING:root: [*] Thu Dec 22 16:53:53 2022: Train Epoch: 2 [6400 /60731 (11%)]	Loss: 0.411404 | F1-score: 0.92 | Elapsed: 5.96s
WARNING:root: [*] Thu Dec 22 16:53:59 2022: Train Epoch: 2 [12800/60731 (21%)]	Loss: 0.320672 | F1-score: 0.92 | Elapsed: 5.94s
WARNING:root: [*] Thu Dec 22 16:54:05 2022: Train Epoch: 2 [19200/60731 (32%)]	Loss: 0.292859 | F1-score: 0.92 | Elapsed: 5.92s
WARNING:root: [*] Thu Dec 22 16:54:11 2022: Train Epoch: 2 [25600/60731 (42%)]	Loss: 0.281623 | F1-score: 0.92 | Elapsed: 5.94s
WARNING:root: [*] Thu Dec 22 16:54:17 2022: Train Epoch: 2 [32000/60731 (53%)]	Loss: 0.324924 | F1-score: 0.92 | Elapsed: 5.98s
WARNING:root: [*] Thu Dec 22 16:54:23 2022: Train Epoch: 2 [38400/60731 (63%)]	Loss: 0.307283 | F1-score: 0.92 | Elapsed: 5.93s
WARNING:root: [*] Thu Dec 22 16:54:29 2022: Train Epoch: 2 [44800/60731 (74%)]	Loss: 0.219912 | F1-score: 0.92 | Elapsed: 5.95s
WARNING:root: [*] Thu Dec 22 16:54:35 2022: Train Epoch: 2 [51200/60731 (84%)]	Loss: 0.318547 | F1-score: 0.92 | Elapsed: 5.93s
WARNING:root: [*] Thu Dec 22 16:54:41 2022: Train Epoch: 2 [57600/60731 (95%)]	Loss: 0.339209 | F1-score: 0.93 | Elapsed: 5.94s
WARNING:root: [*] Thu Dec 22 16:54:44 2022:    2    | Tr.loss: 0.291062 | Tr.F1.:   0.93    |   56.41  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Thu Dec 22 16:54:44 2022: Train Epoch: 3 [  0  /60731 (0 %)]	Loss: 0.214411 | F1-score: 0.95 | Elapsed: 0.08s
WARNING:root: [*] Thu Dec 22 16:54:50 2022: Train Epoch: 3 [6400 /60731 (11%)]	Loss: 0.314332 | F1-score: 0.93 | Elapsed: 5.96s
WARNING:root: [*] Thu Dec 22 16:54:56 2022: Train Epoch: 3 [12800/60731 (21%)]	Loss: 0.191018 | F1-score: 0.93 | Elapsed: 5.94s
WARNING:root: [*] Thu Dec 22 16:55:02 2022: Train Epoch: 3 [19200/60731 (32%)]	Loss: 0.264025 | F1-score: 0.93 | Elapsed: 5.92s
WARNING:root: [*] Thu Dec 22 16:55:08 2022: Train Epoch: 3 [25600/60731 (42%)]	Loss: 0.274730 | F1-score: 0.94 | Elapsed: 5.94s
WARNING:root: [*] Thu Dec 22 16:55:13 2022: Train Epoch: 3 [32000/60731 (53%)]	Loss: 0.218008 | F1-score: 0.94 | Elapsed: 5.95s
WARNING:root: [*] Thu Dec 22 16:55:19 2022: Train Epoch: 3 [38400/60731 (63%)]	Loss: 0.216061 | F1-score: 0.94 | Elapsed: 5.94s
WARNING:root: [*] Thu Dec 22 16:55:25 2022: Train Epoch: 3 [44800/60731 (74%)]	Loss: 0.148410 | F1-score: 0.94 | Elapsed: 5.95s
WARNING:root: [*] Thu Dec 22 16:55:31 2022: Train Epoch: 3 [51200/60731 (84%)]	Loss: 0.295508 | F1-score: 0.94 | Elapsed: 5.95s
WARNING:root: [*] Thu Dec 22 16:55:37 2022: Train Epoch: 3 [57600/60731 (95%)]	Loss: 0.262769 | F1-score: 0.94 | Elapsed: 5.94s
WARNING:root: [*] Thu Dec 22 16:55:40 2022:    3    | Tr.loss: 0.256541 | Tr.F1.:   0.94    |   56.43  s
WARNING:root:
        [!] Thu Dec 22 16:55:40 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\trainingFiles\trainingFiles_1671724540-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\trainingFiles\trainingFiles_1671724540-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\trainingFiles\trainingFiles_1671724540-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\trainingFiles\trainingFiles_1671724540-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 60731, Validation set size: 30365
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Thu Dec 22 16:55:48 2022: Train Epoch: 1 [  0  /60731 (0 %)]	Loss: 0.699063 | F1-score: 0.62 | Elapsed: 0.07s
WARNING:root: [*] Thu Dec 22 16:55:54 2022: Train Epoch: 1 [6400 /60731 (11%)]	Loss: 0.559944 | F1-score: 0.83 | Elapsed: 5.94s
WARNING:root: [*] Thu Dec 22 16:56:00 2022: Train Epoch: 1 [12800/60731 (21%)]	Loss: 0.408965 | F1-score: 0.85 | Elapsed: 5.97s
WARNING:root: [*] Thu Dec 22 16:56:06 2022: Train Epoch: 1 [19200/60731 (32%)]	Loss: 0.391095 | F1-score: 0.87 | Elapsed: 5.96s
WARNING:root: [*] Thu Dec 22 16:56:12 2022: Train Epoch: 1 [25600/60731 (42%)]	Loss: 0.351208 | F1-score: 0.87 | Elapsed: 5.94s
WARNING:root: [*] Thu Dec 22 16:56:18 2022: Train Epoch: 1 [32000/60731 (53%)]	Loss: 0.402276 | F1-score: 0.88 | Elapsed: 5.94s
WARNING:root: [*] Thu Dec 22 16:56:24 2022: Train Epoch: 1 [38400/60731 (63%)]	Loss: 0.257098 | F1-score: 0.88 | Elapsed: 5.96s
WARNING:root: [*] Thu Dec 22 16:56:30 2022: Train Epoch: 1 [44800/60731 (74%)]	Loss: 0.467300 | F1-score: 0.88 | Elapsed: 5.94s
WARNING:root: [*] Thu Dec 22 16:56:36 2022: Train Epoch: 1 [51200/60731 (84%)]	Loss: 0.455133 | F1-score: 0.88 | Elapsed: 5.95s
WARNING:root: [*] Thu Dec 22 16:56:42 2022: Train Epoch: 1 [57600/60731 (95%)]	Loss: 0.261090 | F1-score: 0.88 | Elapsed: 5.94s
WARNING:root: [*] Thu Dec 22 16:56:45 2022:    1    | Tr.loss: 0.425892 | Tr.F1.:   0.89    |   56.43  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Thu Dec 22 16:56:45 2022: Train Epoch: 2 [  0  /60731 (0 %)]	Loss: 0.393860 | F1-score: 0.93 | Elapsed: 0.07s
WARNING:root: [*] Thu Dec 22 16:56:51 2022: Train Epoch: 2 [6400 /60731 (11%)]	Loss: 0.414793 | F1-score: 0.91 | Elapsed: 5.94s
WARNING:root: [*] Thu Dec 22 16:56:56 2022: Train Epoch: 2 [12800/60731 (21%)]	Loss: 0.297074 | F1-score: 0.91 | Elapsed: 5.94s
WARNING:root: [*] Thu Dec 22 16:57:02 2022: Train Epoch: 2 [19200/60731 (32%)]	Loss: 0.227997 | F1-score: 0.91 | Elapsed: 5.94s
WARNING:root: [*] Thu Dec 22 16:57:08 2022: Train Epoch: 2 [25600/60731 (42%)]	Loss: 0.258097 | F1-score: 0.91 | Elapsed: 5.92s
WARNING:root: [*] Thu Dec 22 16:57:14 2022: Train Epoch: 2 [32000/60731 (53%)]	Loss: 0.253623 | F1-score: 0.92 | Elapsed: 5.94s
WARNING:root: [*] Thu Dec 22 16:57:20 2022: Train Epoch: 2 [38400/60731 (63%)]	Loss: 0.232347 | F1-score: 0.92 | Elapsed: 5.92s
WARNING:root: [*] Thu Dec 22 16:57:26 2022: Train Epoch: 2 [44800/60731 (74%)]	Loss: 0.295935 | F1-score: 0.92 | Elapsed: 5.95s
WARNING:root: [*] Thu Dec 22 16:57:32 2022: Train Epoch: 2 [51200/60731 (84%)]	Loss: 0.269147 | F1-score: 0.92 | Elapsed: 5.95s
WARNING:root: [*] Thu Dec 22 16:57:38 2022: Train Epoch: 2 [57600/60731 (95%)]	Loss: 0.338711 | F1-score: 0.92 | Elapsed: 5.94s
WARNING:root: [*] Thu Dec 22 16:57:41 2022:    2    | Tr.loss: 0.311174 | Tr.F1.:   0.92    |   56.39  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Thu Dec 22 16:57:41 2022: Train Epoch: 3 [  0  /60731 (0 %)]	Loss: 0.188629 | F1-score: 0.97 | Elapsed: 0.08s
WARNING:root: [*] Thu Dec 22 16:57:47 2022: Train Epoch: 3 [6400 /60731 (11%)]	Loss: 0.288086 | F1-score: 0.93 | Elapsed: 5.95s
WARNING:root: [*] Thu Dec 22 16:57:53 2022: Train Epoch: 3 [12800/60731 (21%)]	Loss: 0.294476 | F1-score: 0.93 | Elapsed: 5.94s
WARNING:root: [*] Thu Dec 22 16:57:59 2022: Train Epoch: 3 [19200/60731 (32%)]	Loss: 0.315351 | F1-score: 0.93 | Elapsed: 5.99s
WARNING:root: [*] Thu Dec 22 16:58:05 2022: Train Epoch: 3 [25600/60731 (42%)]	Loss: 0.236892 | F1-score: 0.93 | Elapsed: 5.97s
WARNING:root: [*] Thu Dec 22 16:58:11 2022: Train Epoch: 3 [32000/60731 (53%)]	Loss: 0.305988 | F1-score: 0.93 | Elapsed: 5.97s
WARNING:root: [*] Thu Dec 22 16:58:17 2022: Train Epoch: 3 [38400/60731 (63%)]	Loss: 0.190443 | F1-score: 0.93 | Elapsed: 5.95s
WARNING:root: [*] Thu Dec 22 16:58:23 2022: Train Epoch: 3 [44800/60731 (74%)]	Loss: 0.399620 | F1-score: 0.93 | Elapsed: 5.94s
WARNING:root: [*] Thu Dec 22 16:58:29 2022: Train Epoch: 3 [51200/60731 (84%)]	Loss: 0.126090 | F1-score: 0.93 | Elapsed: 5.95s
WARNING:root: [*] Thu Dec 22 16:58:35 2022: Train Epoch: 3 [57600/60731 (95%)]	Loss: 0.260455 | F1-score: 0.93 | Elapsed: 5.95s
WARNING:root: [*] Thu Dec 22 16:58:37 2022:    3    | Tr.loss: 0.264308 | Tr.F1.:   0.93    |   56.56  s
WARNING:root:
        [!] Thu Dec 22 16:58:37 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\trainingFiles\trainingFiles_1671724717-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\trainingFiles\trainingFiles_1671724717-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\trainingFiles\trainingFiles_1671724717-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\trainingFiles\trainingFiles_1671724717-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\metrics_trainSize_91096_ep_3_cv_3_vocabSize_2000_dModel_32_nHeads_8_dHidden_64_nLayers_2_numClasses_1_hiddenNeurons_64_layerNorm_False_dropout_0.5.json
WARNING:root: [!] Average epoch time: 56.08s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.0202 -- F1: 0.0383
	FPR:  0.001 -- TPR: 0.0936 -- F1: 0.1704
	FPR:   0.01 -- TPR: 0.3135 -- F1: 0.4718
	FPR:    0.1 -- TPR: 0.6654 -- F1: 0.7734

WARNING:root: [!] Using device: cuda:0 | Dataset size: 91096
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 2000, 'dModel': 32, 'nHeads': 8, 'dHidden': 128, 'nLayers': 2, 'numClasses': 1, 'hiddenNeurons': [64], 'layerNorm': False, 'dropout': 0.5}
WARNING:root: [!] Fold 1/3 | Train set size: 60730, Validation set size: 30366
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Thu Dec 22 16:59:16 2022: Train Epoch: 1 [  0  /60730 (0 %)]	Loss: 0.685640 | F1-score: 0.73 | Elapsed: 0.37s
WARNING:root: [*] Thu Dec 22 16:59:22 2022: Train Epoch: 1 [6400 /60730 (11%)]	Loss: 0.568096 | F1-score: 0.84 | Elapsed: 6.32s
WARNING:root: [*] Thu Dec 22 16:59:28 2022: Train Epoch: 1 [12800/60730 (21%)]	Loss: 0.328995 | F1-score: 0.86 | Elapsed: 6.32s
WARNING:root: [*] Thu Dec 22 16:59:35 2022: Train Epoch: 1 [19200/60730 (32%)]	Loss: 0.438187 | F1-score: 0.87 | Elapsed: 6.33s
WARNING:root: [*] Thu Dec 22 16:59:41 2022: Train Epoch: 1 [25600/60730 (42%)]	Loss: 0.343037 | F1-score: 0.88 | Elapsed: 6.35s
WARNING:root: [*] Thu Dec 22 16:59:47 2022: Train Epoch: 1 [32000/60730 (53%)]	Loss: 0.442038 | F1-score: 0.88 | Elapsed: 6.31s
WARNING:root: [*] Thu Dec 22 16:59:54 2022: Train Epoch: 1 [38400/60730 (63%)]	Loss: 0.360980 | F1-score: 0.88 | Elapsed: 6.33s
WARNING:root: [*] Thu Dec 22 17:00:00 2022: Train Epoch: 1 [44800/60730 (74%)]	Loss: 0.265795 | F1-score: 0.89 | Elapsed: 6.33s
WARNING:root: [*] Thu Dec 22 17:00:06 2022: Train Epoch: 1 [51200/60730 (84%)]	Loss: 0.470771 | F1-score: 0.89 | Elapsed: 6.34s
WARNING:root: [*] Thu Dec 22 17:00:13 2022: Train Epoch: 1 [57600/60730 (95%)]	Loss: 0.399048 | F1-score: 0.89 | Elapsed: 6.33s
WARNING:root: [*] Thu Dec 22 17:00:16 2022:    1    | Tr.loss: 0.411058 | Tr.F1.:   0.89    |   60.35  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Thu Dec 22 17:00:16 2022: Train Epoch: 2 [  0  /60730 (0 %)]	Loss: 0.526104 | F1-score: 0.83 | Elapsed: 0.08s
WARNING:root: [*] Thu Dec 22 17:00:22 2022: Train Epoch: 2 [6400 /60730 (11%)]	Loss: 0.420040 | F1-score: 0.91 | Elapsed: 6.32s
WARNING:root: [*] Thu Dec 22 17:00:29 2022: Train Epoch: 2 [12800/60730 (21%)]	Loss: 0.521957 | F1-score: 0.91 | Elapsed: 6.33s
WARNING:root: [*] Thu Dec 22 17:00:35 2022: Train Epoch: 2 [19200/60730 (32%)]	Loss: 0.252216 | F1-score: 0.92 | Elapsed: 6.30s
WARNING:root: [*] Thu Dec 22 17:00:41 2022: Train Epoch: 2 [25600/60730 (42%)]	Loss: 0.255193 | F1-score: 0.92 | Elapsed: 6.28s
WARNING:root: [*] Thu Dec 22 17:00:47 2022: Train Epoch: 2 [32000/60730 (53%)]	Loss: 0.322800 | F1-score: 0.92 | Elapsed: 6.30s
WARNING:root: [*] Thu Dec 22 17:00:54 2022: Train Epoch: 2 [38400/60730 (63%)]	Loss: 0.311425 | F1-score: 0.92 | Elapsed: 6.27s
WARNING:root: [*] Thu Dec 22 17:01:00 2022: Train Epoch: 2 [44800/60730 (74%)]	Loss: 0.145828 | F1-score: 0.92 | Elapsed: 6.28s
WARNING:root: [*] Thu Dec 22 17:01:06 2022: Train Epoch: 2 [51200/60730 (84%)]	Loss: 0.304811 | F1-score: 0.92 | Elapsed: 6.27s
WARNING:root: [*] Thu Dec 22 17:01:12 2022: Train Epoch: 2 [57600/60730 (95%)]	Loss: 0.289622 | F1-score: 0.92 | Elapsed: 6.28s
WARNING:root: [*] Thu Dec 22 17:01:15 2022:    2    | Tr.loss: 0.297653 | Tr.F1.:   0.92    |   59.72  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Thu Dec 22 17:01:16 2022: Train Epoch: 3 [  0  /60730 (0 %)]	Loss: 0.258417 | F1-score: 0.90 | Elapsed: 0.07s
WARNING:root: [*] Thu Dec 22 17:01:22 2022: Train Epoch: 3 [6400 /60730 (11%)]	Loss: 0.240695 | F1-score: 0.93 | Elapsed: 6.28s
WARNING:root: [*] Thu Dec 22 17:01:28 2022: Train Epoch: 3 [12800/60730 (21%)]	Loss: 0.550932 | F1-score: 0.93 | Elapsed: 6.27s
WARNING:root: [*] Thu Dec 22 17:01:34 2022: Train Epoch: 3 [19200/60730 (32%)]	Loss: 0.206336 | F1-score: 0.93 | Elapsed: 6.28s
WARNING:root: [*] Thu Dec 22 17:01:41 2022: Train Epoch: 3 [25600/60730 (42%)]	Loss: 0.331722 | F1-score: 0.93 | Elapsed: 6.28s
WARNING:root: [*] Thu Dec 22 17:01:47 2022: Train Epoch: 3 [32000/60730 (53%)]	Loss: 0.224866 | F1-score: 0.93 | Elapsed: 6.27s
WARNING:root: [*] Thu Dec 22 17:01:53 2022: Train Epoch: 3 [38400/60730 (63%)]	Loss: 0.217060 | F1-score: 0.93 | Elapsed: 6.28s
WARNING:root: [*] Thu Dec 22 17:02:00 2022: Train Epoch: 3 [44800/60730 (74%)]	Loss: 0.149910 | F1-score: 0.93 | Elapsed: 6.28s
WARNING:root: [*] Thu Dec 22 17:02:06 2022: Train Epoch: 3 [51200/60730 (84%)]	Loss: 0.315200 | F1-score: 0.94 | Elapsed: 6.27s
WARNING:root: [*] Thu Dec 22 17:02:12 2022: Train Epoch: 3 [57600/60730 (95%)]	Loss: 0.249931 | F1-score: 0.94 | Elapsed: 6.28s
WARNING:root: [*] Thu Dec 22 17:02:15 2022:    3    | Tr.loss: 0.260398 | Tr.F1.:   0.94    |   59.59  s
WARNING:root:
        [!] Thu Dec 22 17:02:15 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\trainingFiles\trainingFiles_1671724935-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\trainingFiles\trainingFiles_1671724935-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\trainingFiles\trainingFiles_1671724935-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\trainingFiles\trainingFiles_1671724935-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 60731, Validation set size: 30365
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Thu Dec 22 17:02:24 2022: Train Epoch: 1 [  0  /60731 (0 %)]	Loss: 0.697117 | F1-score: 0.57 | Elapsed: 0.07s
WARNING:root: [*] Thu Dec 22 17:02:30 2022: Train Epoch: 1 [6400 /60731 (11%)]	Loss: 0.495428 | F1-score: 0.83 | Elapsed: 6.27s
WARNING:root: [*] Thu Dec 22 17:02:36 2022: Train Epoch: 1 [12800/60731 (21%)]	Loss: 0.409472 | F1-score: 0.86 | Elapsed: 6.27s
WARNING:root: [*] Thu Dec 22 17:02:43 2022: Train Epoch: 1 [19200/60731 (32%)]	Loss: 0.333771 | F1-score: 0.87 | Elapsed: 6.26s
WARNING:root: [*] Thu Dec 22 17:02:49 2022: Train Epoch: 1 [25600/60731 (42%)]	Loss: 0.497350 | F1-score: 0.88 | Elapsed: 6.28s
WARNING:root: [*] Thu Dec 22 17:02:55 2022: Train Epoch: 1 [32000/60731 (53%)]	Loss: 0.386097 | F1-score: 0.88 | Elapsed: 6.27s
WARNING:root: [*] Thu Dec 22 17:03:01 2022: Train Epoch: 1 [38400/60731 (63%)]	Loss: 0.426545 | F1-score: 0.88 | Elapsed: 6.28s
WARNING:root: [*] Thu Dec 22 17:03:08 2022: Train Epoch: 1 [44800/60731 (74%)]	Loss: 0.408516 | F1-score: 0.88 | Elapsed: 6.28s
WARNING:root: [*] Thu Dec 22 17:03:14 2022: Train Epoch: 1 [51200/60731 (84%)]	Loss: 0.344164 | F1-score: 0.89 | Elapsed: 6.29s
WARNING:root: [*] Thu Dec 22 17:03:20 2022: Train Epoch: 1 [57600/60731 (95%)]	Loss: 0.386873 | F1-score: 0.89 | Elapsed: 6.26s
WARNING:root: [*] Thu Dec 22 17:03:23 2022:    1    | Tr.loss: 0.420200 | Tr.F1.:   0.89    |   59.55  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Thu Dec 22 17:03:23 2022: Train Epoch: 2 [  0  /60731 (0 %)]	Loss: 0.286911 | F1-score: 0.92 | Elapsed: 0.07s
WARNING:root: [*] Thu Dec 22 17:03:30 2022: Train Epoch: 2 [6400 /60731 (11%)]	Loss: 0.191071 | F1-score: 0.92 | Elapsed: 6.27s
WARNING:root: [*] Thu Dec 22 17:03:36 2022: Train Epoch: 2 [12800/60731 (21%)]	Loss: 0.273694 | F1-score: 0.92 | Elapsed: 6.28s
WARNING:root: [*] Thu Dec 22 17:03:42 2022: Train Epoch: 2 [19200/60731 (32%)]	Loss: 0.305620 | F1-score: 0.92 | Elapsed: 6.27s
WARNING:root: [*] Thu Dec 22 17:03:48 2022: Train Epoch: 2 [25600/60731 (42%)]	Loss: 0.280142 | F1-score: 0.92 | Elapsed: 6.27s
WARNING:root: [*] Thu Dec 22 17:03:55 2022: Train Epoch: 2 [32000/60731 (53%)]	Loss: 0.251124 | F1-score: 0.92 | Elapsed: 6.29s
WARNING:root: [*] Thu Dec 22 17:04:01 2022: Train Epoch: 2 [38400/60731 (63%)]	Loss: 0.234950 | F1-score: 0.92 | Elapsed: 6.27s
WARNING:root: [*] Thu Dec 22 17:04:07 2022: Train Epoch: 2 [44800/60731 (74%)]	Loss: 0.306169 | F1-score: 0.92 | Elapsed: 6.29s
WARNING:root: [*] Thu Dec 22 17:04:14 2022: Train Epoch: 2 [51200/60731 (84%)]	Loss: 0.201946 | F1-score: 0.92 | Elapsed: 6.27s
WARNING:root: [*] Thu Dec 22 17:04:20 2022: Train Epoch: 2 [57600/60731 (95%)]	Loss: 0.192876 | F1-score: 0.92 | Elapsed: 6.28s
WARNING:root: [*] Thu Dec 22 17:04:23 2022:    2    | Tr.loss: 0.300040 | Tr.F1.:   0.92    |   59.58  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Thu Dec 22 17:04:23 2022: Train Epoch: 3 [  0  /60731 (0 %)]	Loss: 0.153792 | F1-score: 0.97 | Elapsed: 0.07s
WARNING:root: [*] Thu Dec 22 17:04:29 2022: Train Epoch: 3 [6400 /60731 (11%)]	Loss: 0.211050 | F1-score: 0.94 | Elapsed: 6.29s
WARNING:root: [*] Thu Dec 22 17:04:35 2022: Train Epoch: 3 [12800/60731 (21%)]	Loss: 0.211841 | F1-score: 0.93 | Elapsed: 6.27s
WARNING:root: [*] Thu Dec 22 17:04:42 2022: Train Epoch: 3 [19200/60731 (32%)]	Loss: 0.372069 | F1-score: 0.93 | Elapsed: 6.28s
WARNING:root: [*] Thu Dec 22 17:04:48 2022: Train Epoch: 3 [25600/60731 (42%)]	Loss: 0.239778 | F1-score: 0.93 | Elapsed: 6.28s
WARNING:root: [*] Thu Dec 22 17:04:54 2022: Train Epoch: 3 [32000/60731 (53%)]	Loss: 0.300238 | F1-score: 0.93 | Elapsed: 6.29s
WARNING:root: [*] Thu Dec 22 17:05:01 2022: Train Epoch: 3 [38400/60731 (63%)]	Loss: 0.458766 | F1-score: 0.93 | Elapsed: 6.27s
WARNING:root: [*] Thu Dec 22 17:05:07 2022: Train Epoch: 3 [44800/60731 (74%)]	Loss: 0.246857 | F1-score: 0.93 | Elapsed: 6.29s
WARNING:root: [*] Thu Dec 22 17:05:13 2022: Train Epoch: 3 [51200/60731 (84%)]	Loss: 0.240250 | F1-score: 0.93 | Elapsed: 6.28s
WARNING:root: [*] Thu Dec 22 17:05:19 2022: Train Epoch: 3 [57600/60731 (95%)]	Loss: 0.292810 | F1-score: 0.93 | Elapsed: 6.28s
WARNING:root: [*] Thu Dec 22 17:05:22 2022:    3    | Tr.loss: 0.257090 | Tr.F1.:   0.94    |   59.65  s
WARNING:root:
        [!] Thu Dec 22 17:05:22 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\trainingFiles\trainingFiles_1671725122-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\trainingFiles\trainingFiles_1671725122-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\trainingFiles\trainingFiles_1671725122-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\trainingFiles\trainingFiles_1671725122-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 60731, Validation set size: 30365
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Thu Dec 22 17:05:31 2022: Train Epoch: 1 [  0  /60731 (0 %)]	Loss: 0.701799 | F1-score: 0.40 | Elapsed: 0.08s
WARNING:root: [*] Thu Dec 22 17:05:37 2022: Train Epoch: 1 [6400 /60731 (11%)]	Loss: 0.578572 | F1-score: 0.83 | Elapsed: 6.32s
WARNING:root: [*] Thu Dec 22 17:05:44 2022: Train Epoch: 1 [12800/60731 (21%)]	Loss: 0.394134 | F1-score: 0.85 | Elapsed: 6.28s
WARNING:root: [*] Thu Dec 22 17:05:50 2022: Train Epoch: 1 [19200/60731 (32%)]	Loss: 0.435201 | F1-score: 0.86 | Elapsed: 6.28s
WARNING:root: [*] Thu Dec 22 17:05:56 2022: Train Epoch: 1 [25600/60731 (42%)]	Loss: 0.428789 | F1-score: 0.87 | Elapsed: 6.29s
WARNING:root: [*] Thu Dec 22 17:06:03 2022: Train Epoch: 1 [32000/60731 (53%)]	Loss: 0.392564 | F1-score: 0.88 | Elapsed: 6.27s
WARNING:root: [*] Thu Dec 22 17:06:09 2022: Train Epoch: 1 [38400/60731 (63%)]	Loss: 0.470572 | F1-score: 0.88 | Elapsed: 6.28s
WARNING:root: [*] Thu Dec 22 17:06:15 2022: Train Epoch: 1 [44800/60731 (74%)]	Loss: 0.241165 | F1-score: 0.88 | Elapsed: 6.28s
WARNING:root: [*] Thu Dec 22 17:06:21 2022: Train Epoch: 1 [51200/60731 (84%)]	Loss: 0.440110 | F1-score: 0.89 | Elapsed: 6.27s
WARNING:root: [*] Thu Dec 22 17:06:28 2022: Train Epoch: 1 [57600/60731 (95%)]	Loss: 0.260077 | F1-score: 0.89 | Elapsed: 6.28s
WARNING:root: [*] Thu Dec 22 17:06:31 2022:    1    | Tr.loss: 0.413426 | Tr.F1.:   0.89    |   59.66  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Thu Dec 22 17:06:31 2022: Train Epoch: 2 [  0  /60731 (0 %)]	Loss: 0.324497 | F1-score: 0.90 | Elapsed: 0.07s
WARNING:root: [*] Thu Dec 22 17:06:37 2022: Train Epoch: 2 [6400 /60731 (11%)]	Loss: 0.427635 | F1-score: 0.92 | Elapsed: 6.28s
WARNING:root: [*] Thu Dec 22 17:06:43 2022: Train Epoch: 2 [12800/60731 (21%)]	Loss: 0.247358 | F1-score: 0.92 | Elapsed: 6.27s
WARNING:root: [*] Thu Dec 22 17:06:50 2022: Train Epoch: 2 [19200/60731 (32%)]	Loss: 0.119118 | F1-score: 0.92 | Elapsed: 6.26s
WARNING:root: [*] Thu Dec 22 17:06:56 2022: Train Epoch: 2 [25600/60731 (42%)]	Loss: 0.332184 | F1-score: 0.92 | Elapsed: 6.28s
WARNING:root: [*] Thu Dec 22 17:07:02 2022: Train Epoch: 2 [32000/60731 (53%)]	Loss: 0.312681 | F1-score: 0.92 | Elapsed: 6.28s
WARNING:root: [*] Thu Dec 22 17:07:08 2022: Train Epoch: 2 [38400/60731 (63%)]	Loss: 0.295115 | F1-score: 0.92 | Elapsed: 6.28s
WARNING:root: [*] Thu Dec 22 17:07:15 2022: Train Epoch: 2 [44800/60731 (74%)]	Loss: 0.482079 | F1-score: 0.92 | Elapsed: 6.28s
WARNING:root: [*] Thu Dec 22 17:07:21 2022: Train Epoch: 2 [51200/60731 (84%)]	Loss: 0.330087 | F1-score: 0.92 | Elapsed: 6.28s
WARNING:root: [*] Thu Dec 22 17:07:27 2022: Train Epoch: 2 [57600/60731 (95%)]	Loss: 0.330001 | F1-score: 0.93 | Elapsed: 6.27s
WARNING:root: [*] Thu Dec 22 17:07:30 2022:    2    | Tr.loss: 0.292573 | Tr.F1.:   0.93    |   59.58  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Thu Dec 22 17:07:30 2022: Train Epoch: 3 [  0  /60731 (0 %)]	Loss: 0.211412 | F1-score: 0.94 | Elapsed: 0.07s
WARNING:root: [*] Thu Dec 22 17:07:37 2022: Train Epoch: 3 [6400 /60731 (11%)]	Loss: 0.240179 | F1-score: 0.94 | Elapsed: 6.29s
WARNING:root: [*] Thu Dec 22 17:07:43 2022: Train Epoch: 3 [12800/60731 (21%)]	Loss: 0.181809 | F1-score: 0.94 | Elapsed: 6.30s
WARNING:root: [*] Thu Dec 22 17:07:49 2022: Train Epoch: 3 [19200/60731 (32%)]	Loss: 0.147841 | F1-score: 0.94 | Elapsed: 6.26s
WARNING:root: [*] Thu Dec 22 17:07:55 2022: Train Epoch: 3 [25600/60731 (42%)]	Loss: 0.177140 | F1-score: 0.94 | Elapsed: 6.28s
WARNING:root: [*] Thu Dec 22 17:08:02 2022: Train Epoch: 3 [32000/60731 (53%)]	Loss: 0.220060 | F1-score: 0.94 | Elapsed: 6.28s
WARNING:root: [*] Thu Dec 22 17:08:08 2022: Train Epoch: 3 [38400/60731 (63%)]	Loss: 0.345485 | F1-score: 0.94 | Elapsed: 6.30s
WARNING:root: [*] Thu Dec 22 17:08:14 2022: Train Epoch: 3 [44800/60731 (74%)]	Loss: 0.231164 | F1-score: 0.94 | Elapsed: 6.30s
WARNING:root: [*] Thu Dec 22 17:08:21 2022: Train Epoch: 3 [51200/60731 (84%)]	Loss: 0.179791 | F1-score: 0.94 | Elapsed: 6.30s
WARNING:root: [*] Thu Dec 22 17:08:27 2022: Train Epoch: 3 [57600/60731 (95%)]	Loss: 0.262255 | F1-score: 0.94 | Elapsed: 6.29s
WARNING:root: [*] Thu Dec 22 17:08:30 2022:    3    | Tr.loss: 0.254362 | Tr.F1.:   0.94    |   59.69  s
WARNING:root:
        [!] Thu Dec 22 17:08:30 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\trainingFiles\trainingFiles_1671725310-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\trainingFiles\trainingFiles_1671725310-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\trainingFiles\trainingFiles_1671725310-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\trainingFiles\trainingFiles_1671725310-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\metrics_trainSize_91096_ep_3_cv_3_vocabSize_2000_dModel_32_nHeads_8_dHidden_128_nLayers_2_numClasses_1_hiddenNeurons_64_layerNorm_False_dropout_0.5.json
WARNING:root: [!] Average epoch time: 59.71s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.0169 -- F1: 0.0321
	FPR:  0.001 -- TPR: 0.0895 -- F1: 0.1635
	FPR:   0.01 -- TPR: 0.2742 -- F1: 0.4277
	FPR:    0.1 -- TPR: 0.4951 -- F1: 0.6452

WARNING:root: [!] Using device: cuda:0 | Dataset size: 91096
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 2000, 'dModel': 32, 'nHeads': 8, 'dHidden': 192, 'nLayers': 2, 'numClasses': 1, 'hiddenNeurons': [64], 'layerNorm': False, 'dropout': 0.5}
WARNING:root: [!] Fold 1/3 | Train set size: 60730, Validation set size: 30366
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Thu Dec 22 17:09:09 2022: Train Epoch: 1 [  0  /60730 (0 %)]	Loss: 0.753101 | F1-score: 0.00 | Elapsed: 0.31s
WARNING:root: [*] Thu Dec 22 17:09:16 2022: Train Epoch: 1 [6400 /60730 (11%)]	Loss: 0.668572 | F1-score: 0.81 | Elapsed: 6.78s
WARNING:root: [*] Thu Dec 22 17:09:22 2022: Train Epoch: 1 [12800/60730 (21%)]	Loss: 0.428378 | F1-score: 0.84 | Elapsed: 6.75s
WARNING:root: [*] Thu Dec 22 17:09:29 2022: Train Epoch: 1 [19200/60730 (32%)]	Loss: 0.387444 | F1-score: 0.86 | Elapsed: 6.78s
WARNING:root: [*] Thu Dec 22 17:09:36 2022: Train Epoch: 1 [25600/60730 (42%)]	Loss: 0.426932 | F1-score: 0.86 | Elapsed: 6.77s
WARNING:root: [*] Thu Dec 22 17:09:43 2022: Train Epoch: 1 [32000/60730 (53%)]	Loss: 0.495277 | F1-score: 0.87 | Elapsed: 6.73s
WARNING:root: [*] Thu Dec 22 17:09:49 2022: Train Epoch: 1 [38400/60730 (63%)]	Loss: 0.279177 | F1-score: 0.87 | Elapsed: 6.69s
WARNING:root: [*] Thu Dec 22 17:09:56 2022: Train Epoch: 1 [44800/60730 (74%)]	Loss: 0.361262 | F1-score: 0.88 | Elapsed: 6.76s
WARNING:root: [*] Thu Dec 22 17:10:03 2022: Train Epoch: 1 [51200/60730 (84%)]	Loss: 0.210006 | F1-score: 0.88 | Elapsed: 6.77s
WARNING:root: [*] Thu Dec 22 17:10:10 2022: Train Epoch: 1 [57600/60730 (95%)]	Loss: 0.297049 | F1-score: 0.89 | Elapsed: 6.75s
WARNING:root: [*] Thu Dec 22 17:10:13 2022:    1    | Tr.loss: 0.417739 | Tr.F1.:   0.89    |   64.36  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Thu Dec 22 17:10:13 2022: Train Epoch: 2 [  0  /60730 (0 %)]	Loss: 0.334152 | F1-score: 0.89 | Elapsed: 0.07s
WARNING:root: [*] Thu Dec 22 17:10:20 2022: Train Epoch: 2 [6400 /60730 (11%)]	Loss: 0.390643 | F1-score: 0.92 | Elapsed: 6.80s
WARNING:root: [*] Thu Dec 22 17:10:27 2022: Train Epoch: 2 [12800/60730 (21%)]	Loss: 0.291972 | F1-score: 0.92 | Elapsed: 6.77s
WARNING:root: [*] Thu Dec 22 17:10:33 2022: Train Epoch: 2 [19200/60730 (32%)]	Loss: 0.242560 | F1-score: 0.92 | Elapsed: 6.77s
WARNING:root: [*] Thu Dec 22 17:10:40 2022: Train Epoch: 2 [25600/60730 (42%)]	Loss: 0.374201 | F1-score: 0.92 | Elapsed: 6.68s
WARNING:root: [*] Thu Dec 22 17:10:47 2022: Train Epoch: 2 [32000/60730 (53%)]	Loss: 0.282125 | F1-score: 0.92 | Elapsed: 6.69s
WARNING:root: [*] Thu Dec 22 17:10:53 2022: Train Epoch: 2 [38400/60730 (63%)]	Loss: 0.272643 | F1-score: 0.92 | Elapsed: 6.65s
WARNING:root: [*] Thu Dec 22 17:11:00 2022: Train Epoch: 2 [44800/60730 (74%)]	Loss: 0.192213 | F1-score: 0.92 | Elapsed: 6.65s
WARNING:root: [*] Thu Dec 22 17:11:07 2022: Train Epoch: 2 [51200/60730 (84%)]	Loss: 0.431120 | F1-score: 0.92 | Elapsed: 6.66s
WARNING:root: [*] Thu Dec 22 17:11:13 2022: Train Epoch: 2 [57600/60730 (95%)]	Loss: 0.264938 | F1-score: 0.92 | Elapsed: 6.67s
WARNING:root: [*] Thu Dec 22 17:11:17 2022:    2    | Tr.loss: 0.295848 | Tr.F1.:   0.93    |   63.63  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Thu Dec 22 17:11:17 2022: Train Epoch: 3 [  0  /60730 (0 %)]	Loss: 0.230895 | F1-score: 0.95 | Elapsed: 0.06s
WARNING:root: [*] Thu Dec 22 17:11:23 2022: Train Epoch: 3 [6400 /60730 (11%)]	Loss: 0.230677 | F1-score: 0.93 | Elapsed: 6.67s
WARNING:root: [*] Thu Dec 22 17:11:30 2022: Train Epoch: 3 [12800/60730 (21%)]	Loss: 0.188290 | F1-score: 0.93 | Elapsed: 6.66s
WARNING:root: [*] Thu Dec 22 17:11:37 2022: Train Epoch: 3 [19200/60730 (32%)]	Loss: 0.347311 | F1-score: 0.93 | Elapsed: 6.65s
WARNING:root: [*] Thu Dec 22 17:11:43 2022: Train Epoch: 3 [25600/60730 (42%)]	Loss: 0.326081 | F1-score: 0.93 | Elapsed: 6.66s
WARNING:root: [*] Thu Dec 22 17:11:50 2022: Train Epoch: 3 [32000/60730 (53%)]	Loss: 0.266161 | F1-score: 0.93 | Elapsed: 6.64s
WARNING:root: [*] Thu Dec 22 17:11:57 2022: Train Epoch: 3 [38400/60730 (63%)]	Loss: 0.203186 | F1-score: 0.93 | Elapsed: 6.68s
WARNING:root: [*] Thu Dec 22 17:12:03 2022: Train Epoch: 3 [44800/60730 (74%)]	Loss: 0.293940 | F1-score: 0.93 | Elapsed: 6.65s
WARNING:root: [*] Thu Dec 22 17:12:10 2022: Train Epoch: 3 [51200/60730 (84%)]	Loss: 0.334708 | F1-score: 0.93 | Elapsed: 6.67s
WARNING:root: [*] Thu Dec 22 17:12:17 2022: Train Epoch: 3 [57600/60730 (95%)]	Loss: 0.180038 | F1-score: 0.93 | Elapsed: 6.66s
WARNING:root: [*] Thu Dec 22 17:12:20 2022:    3    | Tr.loss: 0.258579 | Tr.F1.:   0.94    |   63.20  s
WARNING:root:
        [!] Thu Dec 22 17:12:20 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\trainingFiles\trainingFiles_1671725540-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\trainingFiles\trainingFiles_1671725540-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\trainingFiles\trainingFiles_1671725540-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\trainingFiles\trainingFiles_1671725540-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 60731, Validation set size: 30365
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Thu Dec 22 17:12:29 2022: Train Epoch: 1 [  0  /60731 (0 %)]	Loss: 0.645370 | F1-score: 0.92 | Elapsed: 0.08s
WARNING:root: [*] Thu Dec 22 17:12:36 2022: Train Epoch: 1 [6400 /60731 (11%)]	Loss: 0.528866 | F1-score: 0.84 | Elapsed: 6.65s
WARNING:root: [*] Thu Dec 22 17:12:42 2022: Train Epoch: 1 [12800/60731 (21%)]	Loss: 0.442443 | F1-score: 0.86 | Elapsed: 6.66s
WARNING:root: [*] Thu Dec 22 17:12:49 2022: Train Epoch: 1 [19200/60731 (32%)]	Loss: 0.561978 | F1-score: 0.87 | Elapsed: 6.64s
WARNING:root: [*] Thu Dec 22 17:12:56 2022: Train Epoch: 1 [25600/60731 (42%)]	Loss: 0.501264 | F1-score: 0.87 | Elapsed: 6.67s
WARNING:root: [*] Thu Dec 22 17:13:02 2022: Train Epoch: 1 [32000/60731 (53%)]	Loss: 0.363774 | F1-score: 0.88 | Elapsed: 6.66s
WARNING:root: [*] Thu Dec 22 17:13:09 2022: Train Epoch: 1 [38400/60731 (63%)]	Loss: 0.380162 | F1-score: 0.88 | Elapsed: 6.66s
WARNING:root: [*] Thu Dec 22 17:13:16 2022: Train Epoch: 1 [44800/60731 (74%)]	Loss: 0.385830 | F1-score: 0.88 | Elapsed: 6.69s
WARNING:root: [*] Thu Dec 22 17:13:22 2022: Train Epoch: 1 [51200/60731 (84%)]	Loss: 0.361293 | F1-score: 0.89 | Elapsed: 6.66s
WARNING:root: [*] Thu Dec 22 17:13:29 2022: Train Epoch: 1 [57600/60731 (95%)]	Loss: 0.356305 | F1-score: 0.89 | Elapsed: 6.66s
WARNING:root: [*] Thu Dec 22 17:13:32 2022:    1    | Tr.loss: 0.411389 | Tr.F1.:   0.89    |   63.25  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Thu Dec 22 17:13:32 2022: Train Epoch: 2 [  0  /60731 (0 %)]	Loss: 0.393257 | F1-score: 0.85 | Elapsed: 0.06s
WARNING:root: [*] Thu Dec 22 17:13:39 2022: Train Epoch: 2 [6400 /60731 (11%)]	Loss: 0.245290 | F1-score: 0.91 | Elapsed: 6.67s
WARNING:root: [*] Thu Dec 22 17:13:46 2022: Train Epoch: 2 [12800/60731 (21%)]	Loss: 0.433743 | F1-score: 0.91 | Elapsed: 6.65s
WARNING:root: [*] Thu Dec 22 17:13:52 2022: Train Epoch: 2 [19200/60731 (32%)]	Loss: 0.228419 | F1-score: 0.91 | Elapsed: 6.67s
WARNING:root: [*] Thu Dec 22 17:13:59 2022: Train Epoch: 2 [25600/60731 (42%)]	Loss: 0.238302 | F1-score: 0.92 | Elapsed: 6.66s
WARNING:root: [*] Thu Dec 22 17:14:06 2022: Train Epoch: 2 [32000/60731 (53%)]	Loss: 0.184951 | F1-score: 0.92 | Elapsed: 6.66s
WARNING:root: [*] Thu Dec 22 17:14:12 2022: Train Epoch: 2 [38400/60731 (63%)]	Loss: 0.237125 | F1-score: 0.92 | Elapsed: 6.65s
WARNING:root: [*] Thu Dec 22 17:14:19 2022: Train Epoch: 2 [44800/60731 (74%)]	Loss: 0.263367 | F1-score: 0.92 | Elapsed: 6.66s
WARNING:root: [*] Thu Dec 22 17:14:26 2022: Train Epoch: 2 [51200/60731 (84%)]	Loss: 0.242446 | F1-score: 0.92 | Elapsed: 6.68s
WARNING:root: [*] Thu Dec 22 17:14:32 2022: Train Epoch: 2 [57600/60731 (95%)]	Loss: 0.187355 | F1-score: 0.92 | Elapsed: 6.64s
WARNING:root: [*] Thu Dec 22 17:14:35 2022:    2    | Tr.loss: 0.306939 | Tr.F1.:   0.92    |   63.20  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Thu Dec 22 17:14:36 2022: Train Epoch: 3 [  0  /60731 (0 %)]	Loss: 0.253159 | F1-score: 0.95 | Elapsed: 0.08s
WARNING:root: [*] Thu Dec 22 17:14:42 2022: Train Epoch: 3 [6400 /60731 (11%)]	Loss: 0.357409 | F1-score: 0.93 | Elapsed: 6.65s
WARNING:root: [*] Thu Dec 22 17:14:49 2022: Train Epoch: 3 [12800/60731 (21%)]	Loss: 0.315777 | F1-score: 0.93 | Elapsed: 6.66s
WARNING:root: [*] Thu Dec 22 17:14:55 2022: Train Epoch: 3 [19200/60731 (32%)]	Loss: 0.333901 | F1-score: 0.93 | Elapsed: 6.66s
WARNING:root: [*] Thu Dec 22 17:15:02 2022: Train Epoch: 3 [25600/60731 (42%)]	Loss: 0.353560 | F1-score: 0.93 | Elapsed: 6.66s
WARNING:root: [*] Thu Dec 22 17:15:09 2022: Train Epoch: 3 [32000/60731 (53%)]	Loss: 0.340267 | F1-score: 0.93 | Elapsed: 6.66s
WARNING:root: [*] Thu Dec 22 17:15:15 2022: Train Epoch: 3 [38400/60731 (63%)]	Loss: 0.161554 | F1-score: 0.93 | Elapsed: 6.67s
WARNING:root: [*] Thu Dec 22 17:15:22 2022: Train Epoch: 3 [44800/60731 (74%)]	Loss: 0.405810 | F1-score: 0.93 | Elapsed: 6.39s
WARNING:root: [*] Thu Dec 22 17:15:28 2022: Train Epoch: 3 [51200/60731 (84%)]	Loss: 0.206680 | F1-score: 0.93 | Elapsed: 5.75s
WARNING:root: [*] Thu Dec 22 17:15:33 2022: Train Epoch: 3 [57600/60731 (95%)]	Loss: 0.173052 | F1-score: 0.93 | Elapsed: 5.63s
WARNING:root: [*] Thu Dec 22 17:15:36 2022:    3    | Tr.loss: 0.263052 | Tr.F1.:   0.94    |   60.56  s
WARNING:root:
        [!] Thu Dec 22 17:15:36 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\trainingFiles\trainingFiles_1671725736-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\trainingFiles\trainingFiles_1671725736-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\trainingFiles\trainingFiles_1671725736-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\trainingFiles\trainingFiles_1671725736-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 60731, Validation set size: 30365
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Thu Dec 22 17:15:43 2022: Train Epoch: 1 [  0  /60731 (0 %)]	Loss: 0.667024 | F1-score: 0.80 | Elapsed: 0.06s
WARNING:root: [*] Thu Dec 22 17:15:48 2022: Train Epoch: 1 [6400 /60731 (11%)]	Loss: 0.625706 | F1-score: 0.84 | Elapsed: 5.22s
WARNING:root: [*] Thu Dec 22 17:15:53 2022: Train Epoch: 1 [12800/60731 (21%)]	Loss: 0.529739 | F1-score: 0.86 | Elapsed: 5.38s
WARNING:root: [*] Thu Dec 22 17:15:59 2022: Train Epoch: 1 [19200/60731 (32%)]	Loss: 0.392469 | F1-score: 0.86 | Elapsed: 5.32s
WARNING:root: [*] Thu Dec 22 17:16:04 2022: Train Epoch: 1 [25600/60731 (42%)]	Loss: 0.424147 | F1-score: 0.87 | Elapsed: 5.20s
WARNING:root: [*] Thu Dec 22 17:16:09 2022: Train Epoch: 1 [32000/60731 (53%)]	Loss: 0.304850 | F1-score: 0.87 | Elapsed: 5.16s
WARNING:root: [*] Thu Dec 22 17:16:14 2022: Train Epoch: 1 [38400/60731 (63%)]	Loss: 0.303394 | F1-score: 0.88 | Elapsed: 5.18s
WARNING:root: [*] Thu Dec 22 17:16:19 2022: Train Epoch: 1 [44800/60731 (74%)]	Loss: 0.265416 | F1-score: 0.88 | Elapsed: 5.15s
WARNING:root: [*] Thu Dec 22 17:16:25 2022: Train Epoch: 1 [51200/60731 (84%)]	Loss: 0.340394 | F1-score: 0.88 | Elapsed: 5.30s
WARNING:root: [*] Thu Dec 22 17:16:30 2022: Train Epoch: 1 [57600/60731 (95%)]	Loss: 0.314819 | F1-score: 0.89 | Elapsed: 5.15s
WARNING:root: [*] Thu Dec 22 17:16:32 2022:    1    | Tr.loss: 0.423640 | Tr.F1.:   0.89    |   49.55  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Thu Dec 22 17:16:32 2022: Train Epoch: 2 [  0  /60731 (0 %)]	Loss: 0.284417 | F1-score: 0.95 | Elapsed: 0.05s
WARNING:root: [*] Thu Dec 22 17:16:39 2022: Train Epoch: 2 [6400 /60731 (11%)]	Loss: 0.247345 | F1-score: 0.90 | Elapsed: 6.59s
WARNING:root: [*] Thu Dec 22 17:16:45 2022: Train Epoch: 2 [12800/60731 (21%)]	Loss: 0.283708 | F1-score: 0.91 | Elapsed: 6.58s
WARNING:root: [*] Thu Dec 22 17:16:52 2022: Train Epoch: 2 [19200/60731 (32%)]	Loss: 0.280922 | F1-score: 0.91 | Elapsed: 6.60s
WARNING:root: [*] Thu Dec 22 17:16:59 2022: Train Epoch: 2 [25600/60731 (42%)]	Loss: 0.252857 | F1-score: 0.91 | Elapsed: 6.66s
WARNING:root: [*] Thu Dec 22 17:17:05 2022: Train Epoch: 2 [32000/60731 (53%)]	Loss: 0.414271 | F1-score: 0.92 | Elapsed: 6.67s
WARNING:root: [*] Thu Dec 22 17:17:12 2022: Train Epoch: 2 [38400/60731 (63%)]	Loss: 0.384867 | F1-score: 0.92 | Elapsed: 6.64s
WARNING:root: [*] Thu Dec 22 17:17:19 2022: Train Epoch: 2 [44800/60731 (74%)]	Loss: 0.299014 | F1-score: 0.92 | Elapsed: 6.67s
WARNING:root: [*] Thu Dec 22 17:17:25 2022: Train Epoch: 2 [51200/60731 (84%)]	Loss: 0.257980 | F1-score: 0.92 | Elapsed: 6.65s
WARNING:root: [*] Thu Dec 22 17:17:32 2022: Train Epoch: 2 [57600/60731 (95%)]	Loss: 0.376892 | F1-score: 0.92 | Elapsed: 6.66s
WARNING:root: [*] Thu Dec 22 17:17:35 2022:    2    | Tr.loss: 0.309746 | Tr.F1.:   0.92    |   62.99  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Thu Dec 22 17:17:35 2022: Train Epoch: 3 [  0  /60731 (0 %)]	Loss: 0.235367 | F1-score: 0.95 | Elapsed: 0.07s
WARNING:root: [*] Thu Dec 22 17:17:42 2022: Train Epoch: 3 [6400 /60731 (11%)]	Loss: 0.328365 | F1-score: 0.94 | Elapsed: 6.65s
WARNING:root: [*] Thu Dec 22 17:17:49 2022: Train Epoch: 3 [12800/60731 (21%)]	Loss: 0.286419 | F1-score: 0.93 | Elapsed: 6.67s
WARNING:root: [*] Thu Dec 22 17:17:55 2022: Train Epoch: 3 [19200/60731 (32%)]	Loss: 0.216874 | F1-score: 0.93 | Elapsed: 6.66s
WARNING:root: [*] Thu Dec 22 17:18:02 2022: Train Epoch: 3 [25600/60731 (42%)]	Loss: 0.293939 | F1-score: 0.93 | Elapsed: 6.66s
WARNING:root: [*] Thu Dec 22 17:18:09 2022: Train Epoch: 3 [32000/60731 (53%)]	Loss: 0.233648 | F1-score: 0.93 | Elapsed: 6.69s
WARNING:root: [*] Thu Dec 22 17:18:15 2022: Train Epoch: 3 [38400/60731 (63%)]	Loss: 0.194999 | F1-score: 0.94 | Elapsed: 6.67s
WARNING:root: [*] Thu Dec 22 17:18:22 2022: Train Epoch: 3 [44800/60731 (74%)]	Loss: 0.391488 | F1-score: 0.94 | Elapsed: 6.67s
WARNING:root: [*] Thu Dec 22 17:18:29 2022: Train Epoch: 3 [51200/60731 (84%)]	Loss: 0.202534 | F1-score: 0.94 | Elapsed: 6.68s
WARNING:root: [*] Thu Dec 22 17:18:35 2022: Train Epoch: 3 [57600/60731 (95%)]	Loss: 0.193603 | F1-score: 0.94 | Elapsed: 6.65s
WARNING:root: [*] Thu Dec 22 17:18:38 2022:    3    | Tr.loss: 0.252424 | Tr.F1.:   0.94    |   63.27  s
WARNING:root:
        [!] Thu Dec 22 17:18:38 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\trainingFiles\trainingFiles_1671725918-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\trainingFiles\trainingFiles_1671725918-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\trainingFiles\trainingFiles_1671725918-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\trainingFiles\trainingFiles_1671725918-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\metrics_trainSize_91096_ep_3_cv_3_vocabSize_2000_dModel_32_nHeads_8_dHidden_192_nLayers_2_numClasses_1_hiddenNeurons_64_layerNorm_False_dropout_0.5.json
WARNING:root: [!] Average epoch time: 61.56s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.0123 -- F1: 0.0238
	FPR:  0.001 -- TPR: 0.0434 -- F1: 0.0825
	FPR:   0.01 -- TPR: 0.2027 -- F1: 0.3298
	FPR:    0.1 -- TPR: 0.4742 -- F1: 0.6250

WARNING:root: [!] Using device: cuda:0 | Dataset size: 91096
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 2000, 'dModel': 32, 'nHeads': 8, 'dHidden': 256, 'nLayers': 2, 'numClasses': 1, 'hiddenNeurons': [64], 'layerNorm': False, 'dropout': 0.5}
WARNING:root: [!] Fold 1/3 | Train set size: 60730, Validation set size: 30366
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Thu Dec 22 17:19:18 2022: Train Epoch: 1 [  0  /60730 (0 %)]	Loss: 0.689242 | F1-score: 0.65 | Elapsed: 0.22s
WARNING:root: [*] Thu Dec 22 17:19:25 2022: Train Epoch: 1 [6400 /60730 (11%)]	Loss: 0.542531 | F1-score: 0.84 | Elapsed: 6.84s
WARNING:root: [*] Thu Dec 22 17:19:32 2022: Train Epoch: 1 [12800/60730 (21%)]	Loss: 0.433441 | F1-score: 0.85 | Elapsed: 6.82s
WARNING:root: [*] Thu Dec 22 17:19:38 2022: Train Epoch: 1 [19200/60730 (32%)]	Loss: 0.406975 | F1-score: 0.87 | Elapsed: 6.84s
WARNING:root: [*] Thu Dec 22 17:19:45 2022: Train Epoch: 1 [25600/60730 (42%)]	Loss: 0.513913 | F1-score: 0.87 | Elapsed: 6.84s
WARNING:root: [*] Thu Dec 22 17:19:52 2022: Train Epoch: 1 [32000/60730 (53%)]	Loss: 0.382740 | F1-score: 0.87 | Elapsed: 6.83s
WARNING:root: [*] Thu Dec 22 17:19:59 2022: Train Epoch: 1 [38400/60730 (63%)]	Loss: 0.279364 | F1-score: 0.88 | Elapsed: 6.82s
WARNING:root: [*] Thu Dec 22 17:20:06 2022: Train Epoch: 1 [44800/60730 (74%)]	Loss: 0.328664 | F1-score: 0.88 | Elapsed: 6.83s
WARNING:root: [*] Thu Dec 22 17:20:12 2022: Train Epoch: 1 [51200/60730 (84%)]	Loss: 0.490911 | F1-score: 0.88 | Elapsed: 6.83s
WARNING:root: [*] Thu Dec 22 17:20:19 2022: Train Epoch: 1 [57600/60730 (95%)]	Loss: 0.473222 | F1-score: 0.88 | Elapsed: 6.84s
WARNING:root: [*] Thu Dec 22 17:20:23 2022:    1    | Tr.loss: 0.436516 | Tr.F1.:   0.88    |   65.00  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Thu Dec 22 17:20:23 2022: Train Epoch: 2 [  0  /60730 (0 %)]	Loss: 0.407917 | F1-score: 0.89 | Elapsed: 0.08s
WARNING:root: [*] Thu Dec 22 17:20:30 2022: Train Epoch: 2 [6400 /60730 (11%)]	Loss: 0.391004 | F1-score: 0.90 | Elapsed: 6.83s
WARNING:root: [*] Thu Dec 22 17:20:36 2022: Train Epoch: 2 [12800/60730 (21%)]	Loss: 0.378841 | F1-score: 0.90 | Elapsed: 6.83s
WARNING:root: [*] Thu Dec 22 17:20:43 2022: Train Epoch: 2 [19200/60730 (32%)]	Loss: 0.333424 | F1-score: 0.90 | Elapsed: 6.80s
WARNING:root: [*] Thu Dec 22 17:20:50 2022: Train Epoch: 2 [25600/60730 (42%)]	Loss: 0.313566 | F1-score: 0.90 | Elapsed: 6.78s
WARNING:root: [*] Thu Dec 22 17:20:57 2022: Train Epoch: 2 [32000/60730 (53%)]	Loss: 0.429539 | F1-score: 0.90 | Elapsed: 6.78s
WARNING:root: [*] Thu Dec 22 17:21:03 2022: Train Epoch: 2 [38400/60730 (63%)]	Loss: 0.359395 | F1-score: 0.90 | Elapsed: 6.78s
WARNING:root: [*] Thu Dec 22 17:21:10 2022: Train Epoch: 2 [44800/60730 (74%)]	Loss: 0.219532 | F1-score: 0.91 | Elapsed: 6.78s
WARNING:root: [*] Thu Dec 22 17:21:17 2022: Train Epoch: 2 [51200/60730 (84%)]	Loss: 0.271525 | F1-score: 0.91 | Elapsed: 6.80s
WARNING:root: [*] Thu Dec 22 17:21:24 2022: Train Epoch: 2 [57600/60730 (95%)]	Loss: 0.216949 | F1-score: 0.91 | Elapsed: 6.77s
WARNING:root: [*] Thu Dec 22 17:21:27 2022:    2    | Tr.loss: 0.352193 | Tr.F1.:   0.91    |   64.48  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Thu Dec 22 17:21:27 2022: Train Epoch: 3 [  0  /60730 (0 %)]	Loss: 0.299981 | F1-score: 0.92 | Elapsed: 0.09s
WARNING:root: [*] Thu Dec 22 17:21:34 2022: Train Epoch: 3 [6400 /60730 (11%)]	Loss: 0.370653 | F1-score: 0.92 | Elapsed: 6.79s
WARNING:root: [*] Thu Dec 22 17:21:41 2022: Train Epoch: 3 [12800/60730 (21%)]	Loss: 0.198523 | F1-score: 0.92 | Elapsed: 6.78s
WARNING:root: [*] Thu Dec 22 17:21:48 2022: Train Epoch: 3 [19200/60730 (32%)]	Loss: 0.344737 | F1-score: 0.92 | Elapsed: 6.78s
WARNING:root: [*] Thu Dec 22 17:21:54 2022: Train Epoch: 3 [25600/60730 (42%)]	Loss: 0.365163 | F1-score: 0.92 | Elapsed: 6.79s
WARNING:root: [*] Thu Dec 22 17:22:01 2022: Train Epoch: 3 [32000/60730 (53%)]	Loss: 0.228279 | F1-score: 0.92 | Elapsed: 6.79s
WARNING:root: [*] Thu Dec 22 17:22:08 2022: Train Epoch: 3 [38400/60730 (63%)]	Loss: 0.257094 | F1-score: 0.92 | Elapsed: 6.78s
WARNING:root: [*] Thu Dec 22 17:22:15 2022: Train Epoch: 3 [44800/60730 (74%)]	Loss: 0.221745 | F1-score: 0.92 | Elapsed: 6.79s
WARNING:root: [*] Thu Dec 22 17:22:21 2022: Train Epoch: 3 [51200/60730 (84%)]	Loss: 0.192284 | F1-score: 0.92 | Elapsed: 6.78s
WARNING:root: [*] Thu Dec 22 17:22:28 2022: Train Epoch: 3 [57600/60730 (95%)]	Loss: 0.478065 | F1-score: 0.92 | Elapsed: 6.80s
WARNING:root: [*] Thu Dec 22 17:22:32 2022:    3    | Tr.loss: 0.295401 | Tr.F1.:   0.92    |   64.43  s
WARNING:root:
        [!] Thu Dec 22 17:22:32 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\trainingFiles\trainingFiles_1671726152-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\trainingFiles\trainingFiles_1671726152-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\trainingFiles\trainingFiles_1671726152-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\trainingFiles\trainingFiles_1671726152-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 60731, Validation set size: 30365
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Thu Dec 22 17:22:41 2022: Train Epoch: 1 [  0  /60731 (0 %)]	Loss: 0.697053 | F1-score: 0.49 | Elapsed: 0.09s
WARNING:root: [*] Thu Dec 22 17:22:48 2022: Train Epoch: 1 [6400 /60731 (11%)]	Loss: 0.567517 | F1-score: 0.84 | Elapsed: 6.79s
WARNING:root: [*] Thu Dec 22 17:22:55 2022: Train Epoch: 1 [12800/60731 (21%)]	Loss: 0.417073 | F1-score: 0.86 | Elapsed: 6.78s
WARNING:root: [*] Thu Dec 22 17:23:01 2022: Train Epoch: 1 [19200/60731 (32%)]	Loss: 0.470924 | F1-score: 0.87 | Elapsed: 6.78s
WARNING:root: [*] Thu Dec 22 17:23:08 2022: Train Epoch: 1 [25600/60731 (42%)]	Loss: 0.438636 | F1-score: 0.87 | Elapsed: 6.78s
WARNING:root: [*] Thu Dec 22 17:23:15 2022: Train Epoch: 1 [32000/60731 (53%)]	Loss: 0.556855 | F1-score: 0.88 | Elapsed: 6.78s
WARNING:root: [*] Thu Dec 22 17:23:22 2022: Train Epoch: 1 [38400/60731 (63%)]	Loss: 0.356806 | F1-score: 0.88 | Elapsed: 6.78s
WARNING:root: [*] Thu Dec 22 17:23:28 2022: Train Epoch: 1 [44800/60731 (74%)]	Loss: 0.347309 | F1-score: 0.88 | Elapsed: 6.78s
WARNING:root: [*] Thu Dec 22 17:23:35 2022: Train Epoch: 1 [51200/60731 (84%)]	Loss: 0.379732 | F1-score: 0.89 | Elapsed: 6.80s
WARNING:root: [*] Thu Dec 22 17:23:42 2022: Train Epoch: 1 [57600/60731 (95%)]	Loss: 0.351110 | F1-score: 0.89 | Elapsed: 6.78s
WARNING:root: [*] Thu Dec 22 17:23:45 2022:    1    | Tr.loss: 0.420705 | Tr.F1.:   0.89    |   64.41  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Thu Dec 22 17:23:45 2022: Train Epoch: 2 [  0  /60731 (0 %)]	Loss: 0.437301 | F1-score: 0.88 | Elapsed: 0.07s
WARNING:root: [*] Thu Dec 22 17:23:52 2022: Train Epoch: 2 [6400 /60731 (11%)]	Loss: 0.251409 | F1-score: 0.92 | Elapsed: 6.78s
WARNING:root: [*] Thu Dec 22 17:23:59 2022: Train Epoch: 2 [12800/60731 (21%)]	Loss: 0.242517 | F1-score: 0.92 | Elapsed: 6.79s
WARNING:root: [*] Thu Dec 22 17:24:06 2022: Train Epoch: 2 [19200/60731 (32%)]	Loss: 0.236418 | F1-score: 0.92 | Elapsed: 6.79s
WARNING:root: [*] Thu Dec 22 17:24:13 2022: Train Epoch: 2 [25600/60731 (42%)]	Loss: 0.196038 | F1-score: 0.92 | Elapsed: 6.78s
WARNING:root: [*] Thu Dec 22 17:24:19 2022: Train Epoch: 2 [32000/60731 (53%)]	Loss: 0.445190 | F1-score: 0.92 | Elapsed: 6.77s
WARNING:root: [*] Thu Dec 22 17:24:26 2022: Train Epoch: 2 [38400/60731 (63%)]	Loss: 0.288526 | F1-score: 0.92 | Elapsed: 6.80s
WARNING:root: [*] Thu Dec 22 17:24:33 2022: Train Epoch: 2 [44800/60731 (74%)]	Loss: 0.197101 | F1-score: 0.92 | Elapsed: 6.78s
WARNING:root: [*] Thu Dec 22 17:24:40 2022: Train Epoch: 2 [51200/60731 (84%)]	Loss: 0.294187 | F1-score: 0.92 | Elapsed: 6.78s
WARNING:root: [*] Thu Dec 22 17:24:46 2022: Train Epoch: 2 [57600/60731 (95%)]	Loss: 0.313334 | F1-score: 0.92 | Elapsed: 6.78s
WARNING:root: [*] Thu Dec 22 17:24:50 2022:    2    | Tr.loss: 0.300224 | Tr.F1.:   0.92    |   64.39  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Thu Dec 22 17:24:50 2022: Train Epoch: 3 [  0  /60731 (0 %)]	Loss: 0.188743 | F1-score: 0.97 | Elapsed: 0.06s
WARNING:root: [*] Thu Dec 22 17:24:57 2022: Train Epoch: 3 [6400 /60731 (11%)]	Loss: 0.168990 | F1-score: 0.93 | Elapsed: 6.80s
WARNING:root: [*] Thu Dec 22 17:25:03 2022: Train Epoch: 3 [12800/60731 (21%)]	Loss: 0.307615 | F1-score: 0.93 | Elapsed: 6.80s
WARNING:root: [*] Thu Dec 22 17:25:10 2022: Train Epoch: 3 [19200/60731 (32%)]	Loss: 0.263414 | F1-score: 0.93 | Elapsed: 6.76s
WARNING:root: [*] Thu Dec 22 17:25:17 2022: Train Epoch: 3 [25600/60731 (42%)]	Loss: 0.165828 | F1-score: 0.93 | Elapsed: 6.80s
WARNING:root: [*] Thu Dec 22 17:25:24 2022: Train Epoch: 3 [32000/60731 (53%)]	Loss: 0.291834 | F1-score: 0.93 | Elapsed: 6.81s
WARNING:root: [*] Thu Dec 22 17:25:31 2022: Train Epoch: 3 [38400/60731 (63%)]	Loss: 0.299024 | F1-score: 0.93 | Elapsed: 6.77s
WARNING:root: [*] Thu Dec 22 17:25:37 2022: Train Epoch: 3 [44800/60731 (74%)]	Loss: 0.287788 | F1-score: 0.94 | Elapsed: 6.79s
WARNING:root: [*] Thu Dec 22 17:25:44 2022: Train Epoch: 3 [51200/60731 (84%)]	Loss: 0.140558 | F1-score: 0.94 | Elapsed: 6.80s
WARNING:root: [*] Thu Dec 22 17:25:51 2022: Train Epoch: 3 [57600/60731 (95%)]	Loss: 0.220918 | F1-score: 0.94 | Elapsed: 6.78s
WARNING:root: [*] Thu Dec 22 17:25:54 2022:    3    | Tr.loss: 0.258270 | Tr.F1.:   0.94    |   64.45  s
WARNING:root:
        [!] Thu Dec 22 17:25:54 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\trainingFiles\trainingFiles_1671726354-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\trainingFiles\trainingFiles_1671726354-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\trainingFiles\trainingFiles_1671726354-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\trainingFiles\trainingFiles_1671726354-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 60731, Validation set size: 30365
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Thu Dec 22 17:26:04 2022: Train Epoch: 1 [  0  /60731 (0 %)]	Loss: 0.744220 | F1-score: 0.00 | Elapsed: 0.07s
WARNING:root: [*] Thu Dec 22 17:26:10 2022: Train Epoch: 1 [6400 /60731 (11%)]	Loss: 0.501710 | F1-score: 0.82 | Elapsed: 6.79s
WARNING:root: [*] Thu Dec 22 17:26:17 2022: Train Epoch: 1 [12800/60731 (21%)]	Loss: 0.317413 | F1-score: 0.85 | Elapsed: 6.80s
WARNING:root: [*] Thu Dec 22 17:26:24 2022: Train Epoch: 1 [19200/60731 (32%)]	Loss: 0.373439 | F1-score: 0.86 | Elapsed: 6.77s
WARNING:root: [*] Thu Dec 22 17:26:31 2022: Train Epoch: 1 [25600/60731 (42%)]	Loss: 0.321050 | F1-score: 0.87 | Elapsed: 6.78s
WARNING:root: [*] Thu Dec 22 17:26:38 2022: Train Epoch: 1 [32000/60731 (53%)]	Loss: 0.351367 | F1-score: 0.87 | Elapsed: 6.80s
WARNING:root: [*] Thu Dec 22 17:26:44 2022: Train Epoch: 1 [38400/60731 (63%)]	Loss: 0.466282 | F1-score: 0.87 | Elapsed: 6.80s
WARNING:root: [*] Thu Dec 22 17:26:51 2022: Train Epoch: 1 [44800/60731 (74%)]	Loss: 0.477832 | F1-score: 0.88 | Elapsed: 6.79s
WARNING:root: [*] Thu Dec 22 17:26:58 2022: Train Epoch: 1 [51200/60731 (84%)]	Loss: 0.433951 | F1-score: 0.88 | Elapsed: 6.81s
WARNING:root: [*] Thu Dec 22 17:27:05 2022: Train Epoch: 1 [57600/60731 (95%)]	Loss: 0.344784 | F1-score: 0.88 | Elapsed: 6.79s
WARNING:root: [*] Thu Dec 22 17:27:08 2022:    1    | Tr.loss: 0.440037 | Tr.F1.:   0.88    |   64.47  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Thu Dec 22 17:27:08 2022: Train Epoch: 2 [  0  /60731 (0 %)]	Loss: 0.336738 | F1-score: 0.89 | Elapsed: 0.07s
WARNING:root: [*] Thu Dec 22 17:27:15 2022: Train Epoch: 2 [6400 /60731 (11%)]	Loss: 0.429714 | F1-score: 0.91 | Elapsed: 6.80s
WARNING:root: [*] Thu Dec 22 17:27:22 2022: Train Epoch: 2 [12800/60731 (21%)]	Loss: 0.363279 | F1-score: 0.90 | Elapsed: 6.77s
WARNING:root: [*] Thu Dec 22 17:27:28 2022: Train Epoch: 2 [19200/60731 (32%)]	Loss: 0.365324 | F1-score: 0.91 | Elapsed: 6.80s
WARNING:root: [*] Thu Dec 22 17:27:35 2022: Train Epoch: 2 [25600/60731 (42%)]	Loss: 0.354451 | F1-score: 0.91 | Elapsed: 6.80s
WARNING:root: [*] Thu Dec 22 17:27:42 2022: Train Epoch: 2 [32000/60731 (53%)]	Loss: 0.449120 | F1-score: 0.91 | Elapsed: 6.78s
WARNING:root: [*] Thu Dec 22 17:27:49 2022: Train Epoch: 2 [38400/60731 (63%)]	Loss: 0.516694 | F1-score: 0.91 | Elapsed: 6.79s
WARNING:root: [*] Thu Dec 22 17:27:56 2022: Train Epoch: 2 [44800/60731 (74%)]	Loss: 0.503231 | F1-score: 0.91 | Elapsed: 6.79s
WARNING:root: [*] Thu Dec 22 17:28:02 2022: Train Epoch: 2 [51200/60731 (84%)]	Loss: 0.271753 | F1-score: 0.91 | Elapsed: 6.80s
WARNING:root: [*] Thu Dec 22 17:28:09 2022: Train Epoch: 2 [57600/60731 (95%)]	Loss: 0.325150 | F1-score: 0.91 | Elapsed: 6.82s
WARNING:root: [*] Thu Dec 22 17:28:13 2022:    2    | Tr.loss: 0.349469 | Tr.F1.:   0.91    |   64.47  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Thu Dec 22 17:28:13 2022: Train Epoch: 3 [  0  /60731 (0 %)]	Loss: 0.351327 | F1-score: 0.88 | Elapsed: 0.07s
WARNING:root: [*] Thu Dec 22 17:28:19 2022: Train Epoch: 3 [6400 /60731 (11%)]	Loss: 0.301874 | F1-score: 0.92 | Elapsed: 6.81s
WARNING:root: [*] Thu Dec 22 17:28:26 2022: Train Epoch: 3 [12800/60731 (21%)]	Loss: 0.293553 | F1-score: 0.92 | Elapsed: 6.80s
WARNING:root: [*] Thu Dec 22 17:28:33 2022: Train Epoch: 3 [19200/60731 (32%)]	Loss: 0.253749 | F1-score: 0.92 | Elapsed: 6.80s
WARNING:root: [*] Thu Dec 22 17:28:40 2022: Train Epoch: 3 [25600/60731 (42%)]	Loss: 0.257349 | F1-score: 0.92 | Elapsed: 6.79s
WARNING:root: [*] Thu Dec 22 17:28:47 2022: Train Epoch: 3 [32000/60731 (53%)]	Loss: 0.245717 | F1-score: 0.92 | Elapsed: 6.77s
WARNING:root: [*] Thu Dec 22 17:28:53 2022: Train Epoch: 3 [38400/60731 (63%)]	Loss: 0.367100 | F1-score: 0.92 | Elapsed: 6.80s
WARNING:root: [*] Thu Dec 22 17:29:00 2022: Train Epoch: 3 [44800/60731 (74%)]	Loss: 0.348650 | F1-score: 0.92 | Elapsed: 6.79s
WARNING:root: [*] Thu Dec 22 17:29:07 2022: Train Epoch: 3 [51200/60731 (84%)]	Loss: 0.243697 | F1-score: 0.92 | Elapsed: 6.78s
WARNING:root: [*] Thu Dec 22 17:29:14 2022: Train Epoch: 3 [57600/60731 (95%)]	Loss: 0.279802 | F1-score: 0.92 | Elapsed: 7.11s
WARNING:root: [*] Thu Dec 22 17:29:17 2022:    3    | Tr.loss: 0.296731 | Tr.F1.:   0.93    |   64.10  s
WARNING:root:
        [!] Thu Dec 22 17:29:17 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\trainingFiles\trainingFiles_1671726557-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\trainingFiles\trainingFiles_1671726557-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\trainingFiles\trainingFiles_1671726557-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\trainingFiles\trainingFiles_1671726557-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\TransformerHiddenDim\metrics_trainSize_91096_ep_3_cv_3_vocabSize_2000_dModel_32_nHeads_8_dHidden_256_nLayers_2_numClasses_1_hiddenNeurons_64_layerNorm_False_dropout_0.5.json
WARNING:root: [!] Average epoch time: 64.47s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.0277 -- F1: 0.0521
	FPR:  0.001 -- TPR: 0.1167 -- F1: 0.2062
	FPR:   0.01 -- TPR: 0.2586 -- F1: 0.4021
	FPR:    0.1 -- TPR: 0.6416 -- F1: 0.7605

