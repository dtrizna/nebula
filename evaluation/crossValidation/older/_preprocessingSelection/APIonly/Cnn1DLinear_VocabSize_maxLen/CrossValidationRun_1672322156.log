WARNING:root: [!] Starting valiation of file 0/16
WARNING:root: [!] Skipping maxLen_1024_vocabSize_1000_ as it already exists
WARNING:root: [!] Starting valiation of file 1/16
WARNING:root: [!] Skipping maxLen_2048_vocabSize_1000_ as it already exists
WARNING:root: [!] Starting valiation of file 2/16
WARNING:root: [!] Skipping maxLen_256_vocabSize_1000_ as it already exists
WARNING:root: [!] Starting valiation of file 3/16
WARNING:root: [!] Skipping maxLen_512_vocabSize_1000_ as it already exists
WARNING:root: [!] Starting valiation of file 4/16
WARNING:root: [!] Skipping maxLen_1024_vocabSize_1500_ as it already exists
WARNING:root: [!] Starting valiation of file 5/16
WARNING:root: [!] Skipping maxLen_2048_vocabSize_1500_ as it already exists
WARNING:root: [!] Starting valiation of file 6/16
WARNING:root: [!] Skipping maxLen_256_vocabSize_1500_ as it already exists
WARNING:root: [!] Starting valiation of file 7/16
WARNING:root: [!] Skipping maxLen_512_vocabSize_1500_ as it already exists
WARNING:root: [!] Starting valiation of file 8/16
WARNING:root: [!] Skipping maxLen_1024_vocabSize_2000_ as it already exists
WARNING:root: [!] Starting valiation of file 9/16
WARNING:root: [!] Skipping maxLen_2048_vocabSize_2000_ as it already exists
WARNING:root: [!] Starting valiation of file 10/16
WARNING:root: [!] Skipping maxLen_256_vocabSize_2000_ as it already exists
WARNING:root: [!] Starting valiation of file 11/16
WARNING:root: [!] Skipping maxLen_512_vocabSize_2000_ as it already exists
WARNING:root: [!] Starting valiation of file 12/16
WARNING:root: [!] Running Cross Validation with vocabSize: 500 | maxLen: 1024
WARNING:root: [!] Using device: cuda:0 | Dataset size: 76126
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 500, 'embeddingDim': 64, 'hiddenNeurons': [512, 256, 128], 'batchNormConv': False, 'batchNormFFNN': False, 'filterSizes': [2, 3, 4, 5]}
WARNING:root: [!] Fold 1/3 | Train set size: 50750, Validation set size: 25376
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Thu Dec 29 14:56:02 2022: Train Epoch: 1 [  0  /50750 (0 %)]	Loss: 0.712863 | FPR 0.001 -- TPR 0.0227 | F1 0.0444 | Elapsed: 3.00s
WARNING:root: [*] Thu Dec 29 14:56:09 2022: Train Epoch: 1 [6400 /50750 (13%)]	Loss: 0.163599 | FPR 0.001 -- TPR 0.9756 | F1 0.9877 | Elapsed: 6.93s
WARNING:root: [*] Thu Dec 29 14:56:16 2022: Train Epoch: 1 [12800/50750 (25%)]	Loss: 0.297972 | FPR 0.001 -- TPR 0.8378 | F1 0.9118 | Elapsed: 6.61s
WARNING:root: [*] Thu Dec 29 14:56:23 2022: Train Epoch: 1 [19200/50750 (38%)]	Loss: 0.130235 | FPR 0.001 -- TPR 0.9149 | F1 0.9556 | Elapsed: 6.99s
WARNING:root: [*] Thu Dec 29 14:56:30 2022: Train Epoch: 1 [25600/50750 (50%)]	Loss: 0.160262 | FPR 0.001 -- TPR 0.7949 | F1 0.8857 | Elapsed: 6.79s
WARNING:root: [*] Thu Dec 29 14:56:36 2022: Train Epoch: 1 [32000/50750 (63%)]	Loss: 0.048269 | FPR 0.001 -- TPR 1.0000 | F1 1.0000 | Elapsed: 6.80s
WARNING:root: [*] Thu Dec 29 14:56:44 2022: Train Epoch: 1 [38400/50750 (76%)]	Loss: 0.112276 | FPR 0.001 -- TPR 0.8837 | F1 0.9383 | Elapsed: 7.57s
WARNING:root: [*] Thu Dec 29 14:56:51 2022: Train Epoch: 1 [44800/50750 (88%)]	Loss: 0.167467 | FPR 0.001 -- TPR 0.9333 | F1 0.9655 | Elapsed: 6.72s
WARNING:root: [*] Thu Dec 29 14:56:58 2022:    1    | Tr.loss: 0.181879 | FPR 0.001 -- TPR: 0.82 |  F1: 0.88 | Elapsed:   58.48  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Thu Dec 29 14:56:58 2022: Train Epoch: 2 [  0  /50750 (0 %)]	Loss: 0.081165 | FPR 0.001 -- TPR 0.9574 | F1 0.9783 | Elapsed: 0.10s
WARNING:root: [*] Thu Dec 29 14:57:05 2022: Train Epoch: 2 [6400 /50750 (13%)]	Loss: 0.037175 | FPR 0.001 -- TPR 1.0000 | F1 1.0000 | Elapsed: 7.01s
WARNING:root: [*] Thu Dec 29 14:57:12 2022: Train Epoch: 2 [12800/50750 (25%)]	Loss: 0.072764 | FPR 0.001 -- TPR 0.9737 | F1 0.9867 | Elapsed: 6.58s
WARNING:root: [*] Thu Dec 29 14:57:19 2022: Train Epoch: 2 [19200/50750 (38%)]	Loss: 0.113633 | FPR 0.001 -- TPR 0.9118 | F1 0.9538 | Elapsed: 7.10s
WARNING:root: [*] Thu Dec 29 14:57:25 2022: Train Epoch: 2 [25600/50750 (50%)]	Loss: 0.062019 | FPR 0.001 -- TPR 0.9762 | F1 0.9880 | Elapsed: 6.65s
WARNING:root: [*] Thu Dec 29 14:57:31 2022: Train Epoch: 2 [32000/50750 (63%)]	Loss: 0.059364 | FPR 0.001 -- TPR 1.0000 | F1 1.0000 | Elapsed: 5.78s
WARNING:root: [*] Thu Dec 29 14:57:37 2022: Train Epoch: 2 [38400/50750 (76%)]	Loss: 0.060874 | FPR 0.001 -- TPR 0.9565 | F1 0.9778 | Elapsed: 6.03s
WARNING:root: [*] Thu Dec 29 14:57:42 2022: Train Epoch: 2 [44800/50750 (88%)]	Loss: 0.060996 | FPR 0.001 -- TPR 0.9574 | F1 0.9783 | Elapsed: 5.14s
WARNING:root: [*] Thu Dec 29 14:57:47 2022:    2    | Tr.loss: 0.106689 | FPR 0.001 -- TPR: 0.92 |  F1: 0.96 | Elapsed:   48.97  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Thu Dec 29 14:57:47 2022: Train Epoch: 3 [  0  /50750 (0 %)]	Loss: 0.033412 | FPR 0.001 -- TPR 1.0000 | F1 1.0000 | Elapsed: 0.06s
WARNING:root: [*] Thu Dec 29 14:57:52 2022: Train Epoch: 3 [6400 /50750 (13%)]	Loss: 0.071616 | FPR 0.001 -- TPR 0.9512 | F1 0.9750 | Elapsed: 5.36s
WARNING:root: [*] Thu Dec 29 14:57:57 2022: Train Epoch: 3 [12800/50750 (25%)]	Loss: 0.075139 | FPR 0.001 -- TPR 0.9730 | F1 0.9863 | Elapsed: 5.23s
WARNING:root: [*] Thu Dec 29 14:58:04 2022: Train Epoch: 3 [19200/50750 (38%)]	Loss: 0.051137 | FPR 0.001 -- TPR 1.0000 | F1 1.0000 | Elapsed: 6.14s
WARNING:root: [*] Thu Dec 29 14:58:10 2022: Train Epoch: 3 [25600/50750 (50%)]	Loss: 0.242567 | FPR 0.001 -- TPR 0.7105 | F1 0.8308 | Elapsed: 6.19s
WARNING:root: [*] Thu Dec 29 14:58:15 2022: Train Epoch: 3 [32000/50750 (63%)]	Loss: 0.077183 | FPR 0.001 -- TPR 0.9211 | F1 0.9589 | Elapsed: 5.47s
WARNING:root: [*] Thu Dec 29 14:58:21 2022: Train Epoch: 3 [38400/50750 (76%)]	Loss: 0.101211 | FPR 0.001 -- TPR 0.9796 | F1 0.9897 | Elapsed: 5.36s
WARNING:root: [*] Thu Dec 29 14:58:26 2022: Train Epoch: 3 [44800/50750 (88%)]	Loss: 0.030808 | FPR 0.001 -- TPR 1.0000 | F1 1.0000 | Elapsed: 5.62s
WARNING:root: [*] Thu Dec 29 14:58:31 2022:    3    | Tr.loss: 0.094998 | FPR 0.001 -- TPR: 0.94 |  F1: 0.96 | Elapsed:   44.35  s
WARNING:root:[!] Thu Dec 29 14:58:31 2022: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672322311-model.torch
                losses    : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672322311-train_losses.npy
                duration  : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672322311-trainTime.npy
		train F1s : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672322311-trainF1s.npy
		train TPRs: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672322311-trainTPRs.npy
WARNING:root: [!] Fold 2/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Thu Dec 29 14:58:36 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.703094 | FPR 0.001 -- TPR 0.0857 | F1 0.1579 | Elapsed: 0.08s
WARNING:root: [*] Thu Dec 29 14:58:42 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.265585 | FPR 0.001 -- TPR 0.7436 | F1 0.8529 | Elapsed: 5.88s
WARNING:root: [*] Thu Dec 29 14:58:47 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.068856 | FPR 0.001 -- TPR 0.9773 | F1 0.9885 | Elapsed: 5.22s
WARNING:root: [*] Thu Dec 29 14:58:54 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.149857 | FPR 0.001 -- TPR 0.9730 | F1 0.9863 | Elapsed: 6.29s
WARNING:root: [*] Thu Dec 29 14:59:00 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.117347 | FPR 0.001 -- TPR 0.8043 | F1 0.8916 | Elapsed: 5.95s
WARNING:root: [*] Thu Dec 29 14:59:06 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.122851 | FPR 0.001 -- TPR 0.9362 | F1 0.9670 | Elapsed: 6.46s
WARNING:root: [*] Thu Dec 29 14:59:12 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.263628 | FPR 0.001 -- TPR 0.6842 | F1 0.8125 | Elapsed: 6.19s
WARNING:root: [*] Thu Dec 29 14:59:18 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.072941 | FPR 0.001 -- TPR 0.9524 | F1 0.9756 | Elapsed: 5.52s
WARNING:root: [*] Thu Dec 29 14:59:24 2022:    1    | Tr.loss: 0.179212 | FPR 0.001 -- TPR: 0.82 |  F1: 0.88 | Elapsed:   47.50  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Thu Dec 29 14:59:24 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.181447 | FPR 0.001 -- TPR 0.8776 | F1 0.9348 | Elapsed: 0.08s
WARNING:root: [*] Thu Dec 29 14:59:29 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.152488 | FPR 0.001 -- TPR 0.9024 | F1 0.9487 | Elapsed: 5.67s
WARNING:root: [*] Thu Dec 29 14:59:35 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.118724 | FPR 0.001 -- TPR 0.9048 | F1 0.9500 | Elapsed: 5.60s
WARNING:root: [*] Thu Dec 29 14:59:41 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.150243 | FPR 0.001 -- TPR 0.8810 | F1 0.9367 | Elapsed: 5.54s
WARNING:root: [*] Thu Dec 29 14:59:46 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.058369 | FPR 0.001 -- TPR 0.9756 | F1 0.9877 | Elapsed: 5.62s
WARNING:root: [*] Thu Dec 29 14:59:52 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.062363 | FPR 0.001 -- TPR 0.9756 | F1 0.9877 | Elapsed: 6.25s
WARNING:root: [*] Thu Dec 29 14:59:58 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.050770 | FPR 0.001 -- TPR 1.0000 | F1 1.0000 | Elapsed: 5.84s
WARNING:root: [*] Thu Dec 29 15:00:04 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.051845 | FPR 0.001 -- TPR 1.0000 | F1 1.0000 | Elapsed: 5.81s
WARNING:root: [*] Thu Dec 29 15:00:09 2022:    2    | Tr.loss: 0.105621 | FPR 0.001 -- TPR: 0.92 |  F1: 0.96 | Elapsed:   45.17  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Thu Dec 29 15:00:09 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.096945 | FPR 0.001 -- TPR 0.9762 | F1 0.9880 | Elapsed: 0.07s
WARNING:root: [*] Thu Dec 29 15:00:15 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.057598 | FPR 0.001 -- TPR 1.0000 | F1 1.0000 | Elapsed: 5.84s
WARNING:root: [*] Thu Dec 29 15:00:21 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.072379 | FPR 0.001 -- TPR 0.9706 | F1 0.9851 | Elapsed: 6.33s
WARNING:root: [*] Thu Dec 29 15:00:27 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.070957 | FPR 0.001 -- TPR 1.0000 | F1 1.0000 | Elapsed: 5.60s
WARNING:root: [*] Thu Dec 29 15:00:33 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.135783 | FPR 0.001 -- TPR 0.9535 | F1 0.9762 | Elapsed: 6.16s
WARNING:root: [*] Thu Dec 29 15:00:39 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.201991 | FPR 0.001 -- TPR 0.6596 | F1 0.7949 | Elapsed: 6.37s
WARNING:root: [*] Thu Dec 29 15:00:45 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.075777 | FPR 0.001 -- TPR 0.9524 | F1 0.9756 | Elapsed: 5.81s
WARNING:root: [*] Thu Dec 29 15:00:51 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.207873 | FPR 0.001 -- TPR 0.7907 | F1 0.8831 | Elapsed: 5.58s
WARNING:root: [*] Thu Dec 29 15:00:56 2022:    3    | Tr.loss: 0.094667 | FPR 0.001 -- TPR: 0.94 |  F1: 0.97 | Elapsed:   47.38  s
WARNING:root:[!] Thu Dec 29 15:00:56 2022: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672322456-model.torch
                losses    : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672322456-train_losses.npy
                duration  : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672322456-trainTime.npy
		train F1s : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672322456-trainF1s.npy
		train TPRs: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672322456-trainTPRs.npy
WARNING:root: [!] Fold 3/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Thu Dec 29 15:01:01 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.687283 | FPR 0.001 -- TPR 0.0233 | F1 0.0455 | Elapsed: 0.08s
WARNING:root: [*] Thu Dec 29 15:01:07 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.166660 | FPR 0.001 -- TPR 0.9268 | F1 0.9620 | Elapsed: 6.01s
WARNING:root: [*] Thu Dec 29 15:01:12 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.198360 | FPR 0.001 -- TPR 0.8750 | F1 0.9333 | Elapsed: 5.11s
WARNING:root: [*] Thu Dec 29 15:01:18 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.197056 | FPR 0.001 -- TPR 0.8958 | F1 0.9451 | Elapsed: 5.33s
WARNING:root: [*] Thu Dec 29 15:01:23 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.134476 | FPR 0.001 -- TPR 0.7843 | F1 0.8791 | Elapsed: 5.03s
WARNING:root: [*] Thu Dec 29 15:01:28 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.155009 | FPR 0.001 -- TPR 0.7333 | F1 0.8462 | Elapsed: 4.99s
WARNING:root: [*] Thu Dec 29 15:01:33 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.154228 | FPR 0.001 -- TPR 0.8750 | F1 0.9333 | Elapsed: 5.09s
WARNING:root: [*] Thu Dec 29 15:01:38 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.086491 | FPR 0.001 -- TPR 0.9783 | F1 0.9890 | Elapsed: 5.31s
WARNING:root: [*] Thu Dec 29 15:01:43 2022:    1    | Tr.loss: 0.175916 | FPR 0.001 -- TPR: 0.82 |  F1: 0.88 | Elapsed:   41.93  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Thu Dec 29 15:01:43 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.055161 | FPR 0.001 -- TPR 0.9773 | F1 0.9885 | Elapsed: 0.07s
WARNING:root: [*] Thu Dec 29 15:01:49 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.094152 | FPR 0.001 -- TPR 0.9318 | F1 0.9647 | Elapsed: 5.65s
WARNING:root: [*] Thu Dec 29 15:01:55 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.145505 | FPR 0.001 -- TPR 0.9375 | F1 0.9677 | Elapsed: 6.21s
WARNING:root: [*] Thu Dec 29 15:02:00 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.100321 | FPR 0.001 -- TPR 0.8958 | F1 0.9451 | Elapsed: 5.35s
WARNING:root: [*] Thu Dec 29 15:02:06 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.119306 | FPR 0.001 -- TPR 0.8140 | F1 0.8974 | Elapsed: 5.31s
WARNING:root: [*] Thu Dec 29 15:02:11 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.051565 | FPR 0.001 -- TPR 1.0000 | F1 1.0000 | Elapsed: 5.20s
WARNING:root: [*] Thu Dec 29 15:02:16 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.085506 | FPR 0.001 -- TPR 0.9231 | F1 0.9600 | Elapsed: 5.11s
WARNING:root: [*] Thu Dec 29 15:02:21 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.063365 | FPR 0.001 -- TPR 0.9524 | F1 0.9756 | Elapsed: 5.22s
WARNING:root: [*] Thu Dec 29 15:02:26 2022:    2    | Tr.loss: 0.105121 | FPR 0.001 -- TPR: 0.92 |  F1: 0.96 | Elapsed:   43.42  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Thu Dec 29 15:02:27 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.066549 | FPR 0.001 -- TPR 0.9524 | F1 0.9756 | Elapsed: 0.07s
WARNING:root: [*] Thu Dec 29 15:02:32 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.059045 | FPR 0.001 -- TPR 1.0000 | F1 1.0000 | Elapsed: 5.15s
WARNING:root: [*] Thu Dec 29 15:02:37 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.089213 | FPR 0.001 -- TPR 0.9545 | F1 0.9767 | Elapsed: 5.27s
WARNING:root: [*] Thu Dec 29 15:02:43 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.115067 | FPR 0.001 -- TPR 0.8500 | F1 0.9189 | Elapsed: 6.37s
WARNING:root: [*] Thu Dec 29 15:02:50 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.067159 | FPR 0.001 -- TPR 0.9024 | F1 0.9487 | Elapsed: 6.35s
WARNING:root: [*] Thu Dec 29 15:02:56 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.129219 | FPR 0.001 -- TPR 0.9512 | F1 0.9750 | Elapsed: 6.36s
WARNING:root: [*] Thu Dec 29 15:03:02 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.031928 | FPR 0.001 -- TPR 1.0000 | F1 1.0000 | Elapsed: 5.89s
WARNING:root: [*] Thu Dec 29 15:03:08 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.138168 | FPR 0.001 -- TPR 0.7826 | F1 0.8780 | Elapsed: 6.46s
WARNING:root: [*] Thu Dec 29 15:03:14 2022:    3    | Tr.loss: 0.094187 | FPR 0.001 -- TPR: 0.94 |  F1: 0.97 | Elapsed:   47.64  s
WARNING:root:[!] Thu Dec 29 15:03:14 2022: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672322594-model.torch
                losses    : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672322594-train_losses.npy
                duration  : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672322594-trainTime.npy
		train F1s : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672322594-trainF1s.npy
		train TPRs: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672322594-trainTPRs.npy
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\metrics_trainSize_76126_ep_3_cv_3_maxLen_1024_vocabSize_500_embeddingDim_64_hiddenNeurons_512_256_128_batchNormConv_False_batchNormFFNN_False_filterSizes_2_3_4_5.json
WARNING:root: [!] Average epoch time: 47.20s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.4441 -- F1: 0.6126
	FPR:  0.001 -- TPR: 0.7607 -- F1: 0.8637
	FPR:   0.01 -- TPR: 0.9050 -- F1: 0.9479
	FPR:    0.1 -- TPR: 0.9879 -- F1: 0.9709

WARNING:root: [!] Starting valiation of file 13/16
WARNING:root: [!] Running Cross Validation with vocabSize: 500 | maxLen: 2048
WARNING:root: [!] Using device: cuda:0 | Dataset size: 76126
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 500, 'embeddingDim': 64, 'hiddenNeurons': [512, 256, 128], 'batchNormConv': False, 'batchNormFFNN': False, 'filterSizes': [2, 3, 4, 5]}
WARNING:root: [!] Fold 1/3 | Train set size: 50750, Validation set size: 25376
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Thu Dec 29 15:03:20 2022: Train Epoch: 1 [  0  /50750 (0 %)]	Loss: 0.707064 | FPR 0.001 -- TPR 0.0833 | F1 0.1538 | Elapsed: 0.12s
WARNING:root: [*] Thu Dec 29 15:03:29 2022: Train Epoch: 1 [6400 /50750 (13%)]	Loss: 0.191299 | FPR 0.001 -- TPR 0.9024 | F1 0.9487 | Elapsed: 8.77s
WARNING:root: [*] Thu Dec 29 15:03:38 2022: Train Epoch: 1 [12800/50750 (25%)]	Loss: 0.214823 | FPR 0.001 -- TPR 0.8222 | F1 0.9024 | Elapsed: 9.12s
WARNING:root: [*] Thu Dec 29 15:03:47 2022: Train Epoch: 1 [19200/50750 (38%)]	Loss: 0.220577 | FPR 0.001 -- TPR 0.8372 | F1 0.9114 | Elapsed: 9.15s
WARNING:root: [*] Thu Dec 29 15:03:56 2022: Train Epoch: 1 [25600/50750 (50%)]	Loss: 0.081221 | FPR 0.001 -- TPR 0.9592 | F1 0.9792 | Elapsed: 9.42s
WARNING:root: [*] Thu Dec 29 15:04:06 2022: Train Epoch: 1 [32000/50750 (63%)]	Loss: 0.081068 | FPR 0.001 -- TPR 0.9737 | F1 0.9867 | Elapsed: 9.35s
WARNING:root: [*] Thu Dec 29 15:04:15 2022: Train Epoch: 1 [38400/50750 (76%)]	Loss: 0.143443 | FPR 0.001 -- TPR 0.9143 | F1 0.9552 | Elapsed: 9.45s
WARNING:root: [*] Thu Dec 29 15:04:24 2022: Train Epoch: 1 [44800/50750 (88%)]	Loss: 0.148078 | FPR 0.001 -- TPR 0.8636 | F1 0.9268 | Elapsed: 9.25s
WARNING:root: [*] Thu Dec 29 15:04:33 2022:    1    | Tr.loss: 0.178876 | FPR 0.001 -- TPR: 0.82 |  F1: 0.88 | Elapsed:   73.29  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Thu Dec 29 15:04:33 2022: Train Epoch: 2 [  0  /50750 (0 %)]	Loss: 0.163450 | FPR 0.001 -- TPR 0.8750 | F1 0.9333 | Elapsed: 0.12s
WARNING:root: [*] Thu Dec 29 15:04:42 2022: Train Epoch: 2 [6400 /50750 (13%)]	Loss: 0.191910 | FPR 0.001 -- TPR 0.9250 | F1 0.9610 | Elapsed: 9.14s
WARNING:root: [*] Thu Dec 29 15:04:51 2022: Train Epoch: 2 [12800/50750 (25%)]	Loss: 0.240537 | FPR 0.001 -- TPR 0.5778 | F1 0.7324 | Elapsed: 9.15s
WARNING:root: [*] Thu Dec 29 15:05:01 2022: Train Epoch: 2 [19200/50750 (38%)]	Loss: 0.027635 | FPR 0.001 -- TPR 1.0000 | F1 1.0000 | Elapsed: 9.11s
WARNING:root: [*] Thu Dec 29 15:05:10 2022: Train Epoch: 2 [25600/50750 (50%)]	Loss: 0.146338 | FPR 0.001 -- TPR 0.9130 | F1 0.9545 | Elapsed: 9.61s
WARNING:root: [*] Thu Dec 29 15:05:20 2022: Train Epoch: 2 [32000/50750 (63%)]	Loss: 0.087780 | FPR 0.001 -- TPR 0.9512 | F1 0.9750 | Elapsed: 9.57s
WARNING:root: [*] Thu Dec 29 15:05:29 2022: Train Epoch: 2 [38400/50750 (76%)]	Loss: 0.174058 | FPR 0.001 -- TPR 0.8684 | F1 0.9296 | Elapsed: 9.38s
WARNING:root: [*] Thu Dec 29 15:05:38 2022: Train Epoch: 2 [44800/50750 (88%)]	Loss: 0.115635 | FPR 0.001 -- TPR 0.9211 | F1 0.9589 | Elapsed: 9.09s
WARNING:root: [*] Thu Dec 29 15:05:47 2022:    2    | Tr.loss: 0.104802 | FPR 0.001 -- TPR: 0.92 |  F1: 0.96 | Elapsed:   73.62  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Thu Dec 29 15:05:47 2022: Train Epoch: 3 [  0  /50750 (0 %)]	Loss: 0.172694 | FPR 0.001 -- TPR 0.6136 | F1 0.7606 | Elapsed: 0.11s
WARNING:root: [*] Thu Dec 29 15:05:55 2022: Train Epoch: 3 [6400 /50750 (13%)]	Loss: 0.085562 | FPR 0.001 -- TPR 0.9730 | F1 0.9863 | Elapsed: 8.79s
WARNING:root: [*] Thu Dec 29 15:06:05 2022: Train Epoch: 3 [12800/50750 (25%)]	Loss: 0.176779 | FPR 0.001 -- TPR 0.8889 | F1 0.9412 | Elapsed: 9.05s
WARNING:root: [*] Thu Dec 29 15:06:13 2022: Train Epoch: 3 [19200/50750 (38%)]	Loss: 0.038424 | FPR 0.001 -- TPR 1.0000 | F1 1.0000 | Elapsed: 8.49s
WARNING:root: [*] Thu Dec 29 15:06:22 2022: Train Epoch: 3 [25600/50750 (50%)]	Loss: 0.127159 | FPR 0.001 -- TPR 0.8571 | F1 0.9231 | Elapsed: 8.85s
WARNING:root: [*] Thu Dec 29 15:06:30 2022: Train Epoch: 3 [32000/50750 (63%)]	Loss: 0.063167 | FPR 0.001 -- TPR 0.9744 | F1 0.9870 | Elapsed: 8.60s
WARNING:root: [*] Thu Dec 29 15:06:39 2022: Train Epoch: 3 [38400/50750 (76%)]	Loss: 0.182416 | FPR 0.001 -- TPR 0.9286 | F1 0.9630 | Elapsed: 8.32s
WARNING:root: [*] Thu Dec 29 15:06:49 2022: Train Epoch: 3 [44800/50750 (88%)]	Loss: 0.142951 | FPR 0.001 -- TPR 0.8810 | F1 0.9367 | Elapsed: 10.11s
WARNING:root: [*] Thu Dec 29 15:06:58 2022:    3    | Tr.loss: 0.092731 | FPR 0.001 -- TPR: 0.94 |  F1: 0.97 | Elapsed:   71.72  s
WARNING:root:[!] Thu Dec 29 15:06:58 2022: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672322818-model.torch
                losses    : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672322818-train_losses.npy
                duration  : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672322818-trainTime.npy
		train F1s : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672322818-trainF1s.npy
		train TPRs: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672322818-trainTPRs.npy
WARNING:root: [!] Fold 2/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Thu Dec 29 15:07:08 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.696986 | FPR 0.001 -- TPR 0.0000 | F1 0.0000 | Elapsed: 0.11s
WARNING:root: [*] Thu Dec 29 15:07:17 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.226082 | FPR 0.001 -- TPR 0.8372 | F1 0.9114 | Elapsed: 9.32s
WARNING:root: [*] Thu Dec 29 15:07:27 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.168729 | FPR 0.001 -- TPR 0.9268 | F1 0.9620 | Elapsed: 9.80s
WARNING:root: [*] Thu Dec 29 15:07:37 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.181753 | FPR 0.001 -- TPR 0.9792 | F1 0.9895 | Elapsed: 9.90s
WARNING:root: [*] Thu Dec 29 15:07:47 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.152937 | FPR 0.001 -- TPR 0.7045 | F1 0.8267 | Elapsed: 9.51s
WARNING:root: [*] Thu Dec 29 15:07:55 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.089270 | FPR 0.001 -- TPR 1.0000 | F1 1.0000 | Elapsed: 8.48s
WARNING:root: [*] Thu Dec 29 15:08:04 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.133765 | FPR 0.001 -- TPR 0.9348 | F1 0.9663 | Elapsed: 9.12s
WARNING:root: [*] Thu Dec 29 15:08:13 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.048346 | FPR 0.001 -- TPR 1.0000 | F1 1.0000 | Elapsed: 8.55s
WARNING:root: [*] Thu Dec 29 15:08:21 2022:    1    | Tr.loss: 0.178554 | FPR 0.001 -- TPR: 0.81 |  F1: 0.88 | Elapsed:   72.57  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Thu Dec 29 15:08:21 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.090292 | FPR 0.001 -- TPR 0.9783 | F1 0.9890 | Elapsed: 0.11s
WARNING:root: [*] Thu Dec 29 15:08:30 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.122224 | FPR 0.001 -- TPR 0.9111 | F1 0.9535 | Elapsed: 8.95s
WARNING:root: [*] Thu Dec 29 15:08:38 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.105182 | FPR 0.001 -- TPR 0.9394 | F1 0.9688 | Elapsed: 8.79s
WARNING:root: [*] Thu Dec 29 15:08:47 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.115274 | FPR 0.001 -- TPR 0.9318 | F1 0.9647 | Elapsed: 8.51s
WARNING:root: [*] Thu Dec 29 15:08:56 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.085997 | FPR 0.001 -- TPR 0.9512 | F1 0.9750 | Elapsed: 9.11s
WARNING:root: [*] Thu Dec 29 15:09:05 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.049095 | FPR 0.001 -- TPR 1.0000 | F1 1.0000 | Elapsed: 9.15s
WARNING:root: [*] Thu Dec 29 15:09:14 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.129002 | FPR 0.001 -- TPR 0.9512 | F1 0.9750 | Elapsed: 8.63s
WARNING:root: [*] Thu Dec 29 15:09:23 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.297514 | FPR 0.001 -- TPR 0.6486 | F1 0.7869 | Elapsed: 9.02s
WARNING:root: [*] Thu Dec 29 15:09:31 2022:    2    | Tr.loss: 0.108728 | FPR 0.001 -- TPR: 0.92 |  F1: 0.96 | Elapsed:   70.82  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Thu Dec 29 15:09:32 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.102385 | FPR 0.001 -- TPR 0.8684 | F1 0.9296 | Elapsed: 0.11s
WARNING:root: [*] Thu Dec 29 15:09:40 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.148055 | FPR 0.001 -- TPR 0.9130 | F1 0.9545 | Elapsed: 8.65s
WARNING:root: [*] Thu Dec 29 15:09:50 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.031182 | FPR 0.001 -- TPR 1.0000 | F1 1.0000 | Elapsed: 9.53s
WARNING:root: [*] Thu Dec 29 15:09:59 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.089565 | FPR 0.001 -- TPR 0.9545 | F1 0.9767 | Elapsed: 9.28s
WARNING:root: [*] Thu Dec 29 15:10:08 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.127943 | FPR 0.001 -- TPR 0.9000 | F1 0.9474 | Elapsed: 9.30s
WARNING:root: [*] Thu Dec 29 15:10:18 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.186359 | FPR 0.001 -- TPR 0.6818 | F1 0.8108 | Elapsed: 9.56s
WARNING:root: [*] Thu Dec 29 15:10:27 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.106605 | FPR 0.001 -- TPR 0.9149 | F1 0.9556 | Elapsed: 9.61s
WARNING:root: [*] Thu Dec 29 15:10:37 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.200144 | FPR 0.001 -- TPR 0.9167 | F1 0.9565 | Elapsed: 9.32s
WARNING:root: [*] Thu Dec 29 15:10:45 2022:    3    | Tr.loss: 0.096819 | FPR 0.001 -- TPR: 0.93 |  F1: 0.96 | Elapsed:   73.83  s
WARNING:root:[!] Thu Dec 29 15:10:45 2022: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672323045-model.torch
                losses    : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672323045-train_losses.npy
                duration  : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672323045-trainTime.npy
		train F1s : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672323045-trainF1s.npy
		train TPRs: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672323045-trainTPRs.npy
WARNING:root: [!] Fold 3/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Thu Dec 29 15:10:55 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.699195 | FPR 0.001 -- TPR 0.0408 | F1 0.0784 | Elapsed: 0.11s
WARNING:root: [*] Thu Dec 29 15:11:03 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.254845 | FPR 0.001 -- TPR 0.4889 | F1 0.6567 | Elapsed: 8.82s
WARNING:root: [*] Thu Dec 29 15:11:13 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.209286 | FPR 0.001 -- TPR 0.9459 | F1 0.9722 | Elapsed: 9.17s
WARNING:root: [*] Thu Dec 29 15:11:22 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.232587 | FPR 0.001 -- TPR 0.5641 | F1 0.7213 | Elapsed: 9.22s
WARNING:root: [*] Thu Dec 29 15:11:31 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.219190 | FPR 0.001 -- TPR 0.6750 | F1 0.8060 | Elapsed: 9.44s
WARNING:root: [*] Thu Dec 29 15:11:40 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.124271 | FPR 0.001 -- TPR 0.9500 | F1 0.9744 | Elapsed: 9.12s
WARNING:root: [*] Thu Dec 29 15:11:49 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.135090 | FPR 0.001 -- TPR 0.9444 | F1 0.9714 | Elapsed: 8.91s
WARNING:root: [*] Thu Dec 29 15:11:59 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.118874 | FPR 0.001 -- TPR 0.8421 | F1 0.9143 | Elapsed: 9.34s
WARNING:root: [*] Thu Dec 29 15:12:07 2022:    1    | Tr.loss: 0.180414 | FPR 0.001 -- TPR: 0.81 |  F1: 0.87 | Elapsed:   72.61  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Thu Dec 29 15:12:07 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.198784 | FPR 0.001 -- TPR 0.5854 | F1 0.7385 | Elapsed: 0.11s
WARNING:root: [*] Thu Dec 29 15:12:17 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.186118 | FPR 0.001 -- TPR 0.7619 | F1 0.8649 | Elapsed: 9.58s
WARNING:root: [*] Thu Dec 29 15:12:26 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.039765 | FPR 0.001 -- TPR 1.0000 | F1 1.0000 | Elapsed: 9.73s
WARNING:root: [*] Thu Dec 29 15:12:36 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.109515 | FPR 0.001 -- TPR 0.9024 | F1 0.9487 | Elapsed: 9.58s
WARNING:root: [*] Thu Dec 29 15:12:46 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.061698 | FPR 0.001 -- TPR 0.9487 | F1 0.9737 | Elapsed: 9.53s
WARNING:root: [*] Thu Dec 29 15:12:55 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.098347 | FPR 0.001 -- TPR 0.9362 | F1 0.9670 | Elapsed: 9.53s
WARNING:root: [*] Thu Dec 29 15:13:05 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.088532 | FPR 0.001 -- TPR 0.9474 | F1 0.9730 | Elapsed: 9.63s
WARNING:root: [*] Thu Dec 29 15:13:14 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.134343 | FPR 0.001 -- TPR 0.9310 | F1 0.9643 | Elapsed: 9.37s
WARNING:root: [*] Thu Dec 29 15:13:23 2022:    2    | Tr.loss: 0.106358 | FPR 0.001 -- TPR: 0.92 |  F1: 0.96 | Elapsed:   75.77  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Thu Dec 29 15:13:23 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.063374 | FPR 0.001 -- TPR 1.0000 | F1 1.0000 | Elapsed: 0.11s
WARNING:root: [*] Thu Dec 29 15:13:33 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.053329 | FPR 0.001 -- TPR 0.9744 | F1 0.9870 | Elapsed: 9.84s
WARNING:root: [*] Thu Dec 29 15:13:42 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.080528 | FPR 0.001 -- TPR 1.0000 | F1 1.0000 | Elapsed: 9.59s
WARNING:root: [*] Thu Dec 29 15:13:52 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.334681 | FPR 0.001 -- TPR 0.8043 | F1 0.8916 | Elapsed: 9.62s
WARNING:root: [*] Thu Dec 29 15:14:02 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.087604 | FPR 0.001 -- TPR 0.9318 | F1 0.9647 | Elapsed: 9.70s
WARNING:root: [*] Thu Dec 29 15:14:11 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.340601 | FPR 0.001 -- TPR 0.7105 | F1 0.8308 | Elapsed: 9.28s
WARNING:root: [*] Thu Dec 29 15:14:20 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.038509 | FPR 0.001 -- TPR 0.9796 | F1 0.9897 | Elapsed: 8.81s
WARNING:root: [*] Thu Dec 29 15:14:29 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.063122 | FPR 0.001 -- TPR 1.0000 | F1 1.0000 | Elapsed: 8.80s
WARNING:root: [*] Thu Dec 29 15:14:37 2022:    3    | Tr.loss: 0.095111 | FPR 0.001 -- TPR: 0.94 |  F1: 0.97 | Elapsed:   74.09  s
WARNING:root:[!] Thu Dec 29 15:14:37 2022: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672323277-model.torch
                losses    : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672323277-train_losses.npy
                duration  : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672323277-trainTime.npy
		train F1s : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672323277-trainF1s.npy
		train TPRs: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672323277-trainTPRs.npy
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\metrics_trainSize_76126_ep_3_cv_3_maxLen_2048_vocabSize_500_embeddingDim_64_hiddenNeurons_512_256_128_batchNormConv_False_batchNormFFNN_False_filterSizes_2_3_4_5.json
WARNING:root: [!] Average epoch time: 73.15s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.4518 -- F1: 0.6192
	FPR:  0.001 -- TPR: 0.7734 -- F1: 0.8691
	FPR:   0.01 -- TPR: 0.9121 -- F1: 0.9516
	FPR:    0.1 -- TPR: 0.9870 -- F1: 0.9711

WARNING:root: [!] Starting valiation of file 14/16
WARNING:root: [!] Running Cross Validation with vocabSize: 500 | maxLen: 256
WARNING:root: [!] Using device: cuda:0 | Dataset size: 76126
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 500, 'embeddingDim': 64, 'hiddenNeurons': [512, 256, 128], 'batchNormConv': False, 'batchNormFFNN': False, 'filterSizes': [2, 3, 4, 5]}
WARNING:root: [!] Fold 1/3 | Train set size: 50750, Validation set size: 25376
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Thu Dec 29 15:14:46 2022: Train Epoch: 1 [  0  /50750 (0 %)]	Loss: 0.686606 | FPR 0.001 -- TPR 0.0435 | F1 0.0833 | Elapsed: 0.03s
WARNING:root: [*] Thu Dec 29 15:14:49 2022: Train Epoch: 1 [6400 /50750 (13%)]	Loss: 0.218502 | FPR 0.001 -- TPR 0.8205 | F1 0.9014 | Elapsed: 3.40s
WARNING:root: [*] Thu Dec 29 15:14:52 2022: Train Epoch: 1 [12800/50750 (25%)]	Loss: 0.175969 | FPR 0.001 -- TPR 0.8043 | F1 0.8916 | Elapsed: 2.92s
WARNING:root: [*] Thu Dec 29 15:14:55 2022: Train Epoch: 1 [19200/50750 (38%)]	Loss: 0.177341 | FPR 0.001 -- TPR 0.8958 | F1 0.9451 | Elapsed: 2.60s
WARNING:root: [*] Thu Dec 29 15:14:58 2022: Train Epoch: 1 [25600/50750 (50%)]	Loss: 0.163861 | FPR 0.001 -- TPR 0.9118 | F1 0.9538 | Elapsed: 2.84s
WARNING:root: [*] Thu Dec 29 15:15:00 2022: Train Epoch: 1 [32000/50750 (63%)]	Loss: 0.090511 | FPR 0.001 -- TPR 0.9111 | F1 0.9535 | Elapsed: 2.67s
WARNING:root: [*] Thu Dec 29 15:15:03 2022: Train Epoch: 1 [38400/50750 (76%)]	Loss: 0.131366 | FPR 0.001 -- TPR 0.8108 | F1 0.8955 | Elapsed: 2.57s
WARNING:root: [*] Thu Dec 29 15:15:06 2022: Train Epoch: 1 [44800/50750 (88%)]	Loss: 0.062305 | FPR 0.001 -- TPR 0.9730 | F1 0.9863 | Elapsed: 2.71s
WARNING:root: [*] Thu Dec 29 15:15:08 2022:    1    | Tr.loss: 0.192940 | FPR 0.001 -- TPR: 0.80 |  F1: 0.87 | Elapsed:   22.21  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Thu Dec 29 15:15:08 2022: Train Epoch: 2 [  0  /50750 (0 %)]	Loss: 0.087490 | FPR 0.001 -- TPR 0.9767 | F1 0.9882 | Elapsed: 0.04s
WARNING:root: [*] Thu Dec 29 15:15:11 2022: Train Epoch: 2 [6400 /50750 (13%)]	Loss: 0.262059 | FPR 0.001 -- TPR 0.9250 | F1 0.9610 | Elapsed: 3.29s
WARNING:root: [*] Thu Dec 29 15:15:14 2022: Train Epoch: 2 [12800/50750 (25%)]	Loss: 0.033984 | FPR 0.001 -- TPR 1.0000 | F1 1.0000 | Elapsed: 2.85s
WARNING:root: [*] Thu Dec 29 15:15:17 2022: Train Epoch: 2 [19200/50750 (38%)]	Loss: 0.197489 | FPR 0.001 -- TPR 0.8205 | F1 0.9014 | Elapsed: 2.75s
WARNING:root: [*] Thu Dec 29 15:15:19 2022: Train Epoch: 2 [25600/50750 (50%)]	Loss: 0.077752 | FPR 0.001 -- TPR 0.9767 | F1 0.9882 | Elapsed: 2.34s
WARNING:root: [*] Thu Dec 29 15:15:22 2022: Train Epoch: 2 [32000/50750 (63%)]	Loss: 0.107168 | FPR 0.001 -- TPR 0.9574 | F1 0.9783 | Elapsed: 2.46s
WARNING:root: [*] Thu Dec 29 15:15:24 2022: Train Epoch: 2 [38400/50750 (76%)]	Loss: 0.070678 | FPR 0.001 -- TPR 1.0000 | F1 1.0000 | Elapsed: 2.34s
WARNING:root: [*] Thu Dec 29 15:15:27 2022: Train Epoch: 2 [44800/50750 (88%)]	Loss: 0.167345 | FPR 0.001 -- TPR 0.7805 | F1 0.8767 | Elapsed: 2.40s
WARNING:root: [*] Thu Dec 29 15:15:29 2022:    2    | Tr.loss: 0.125825 | FPR 0.001 -- TPR: 0.90 |  F1: 0.94 | Elapsed:   20.89  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Thu Dec 29 15:15:29 2022: Train Epoch: 3 [  0  /50750 (0 %)]	Loss: 0.105141 | FPR 0.001 -- TPR 0.9111 | F1 0.9535 | Elapsed: 0.04s
WARNING:root: [*] Thu Dec 29 15:15:31 2022: Train Epoch: 3 [6400 /50750 (13%)]	Loss: 0.136346 | FPR 0.001 -- TPR 0.9535 | F1 0.9762 | Elapsed: 2.43s
WARNING:root: [*] Thu Dec 29 15:15:34 2022: Train Epoch: 3 [12800/50750 (25%)]	Loss: 0.094137 | FPR 0.001 -- TPR 0.9762 | F1 0.9880 | Elapsed: 2.46s
WARNING:root: [*] Thu Dec 29 15:15:36 2022: Train Epoch: 3 [19200/50750 (38%)]	Loss: 0.248382 | FPR 0.001 -- TPR 0.9737 | F1 0.9867 | Elapsed: 2.32s
WARNING:root: [*] Thu Dec 29 15:15:39 2022: Train Epoch: 3 [25600/50750 (50%)]	Loss: 0.074517 | FPR 0.001 -- TPR 1.0000 | F1 1.0000 | Elapsed: 2.48s
WARNING:root: [*] Thu Dec 29 15:15:41 2022: Train Epoch: 3 [32000/50750 (63%)]	Loss: 0.063691 | FPR 0.001 -- TPR 0.9773 | F1 0.9885 | Elapsed: 2.39s
WARNING:root: [*] Thu Dec 29 15:15:43 2022: Train Epoch: 3 [38400/50750 (76%)]	Loss: 0.121201 | FPR 0.001 -- TPR 0.9778 | F1 0.9888 | Elapsed: 2.36s
WARNING:root: [*] Thu Dec 29 15:15:46 2022: Train Epoch: 3 [44800/50750 (88%)]	Loss: 0.037902 | FPR 0.001 -- TPR 0.9796 | F1 0.9897 | Elapsed: 2.32s
WARNING:root: [*] Thu Dec 29 15:15:48 2022:    3    | Tr.loss: 0.113746 | FPR 0.001 -- TPR: 0.92 |  F1: 0.95 | Elapsed:   19.05  s
WARNING:root:[!] Thu Dec 29 15:15:48 2022: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672323348-model.torch
                losses    : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672323348-train_losses.npy
                duration  : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672323348-trainTime.npy
		train F1s : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672323348-trainF1s.npy
		train TPRs: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672323348-trainTPRs.npy
WARNING:root: [!] Fold 2/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Thu Dec 29 15:15:51 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.704713 | FPR 0.001 -- TPR 0.0952 | F1 0.1739 | Elapsed: 0.03s
WARNING:root: [*] Thu Dec 29 15:15:53 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.310233 | FPR 0.001 -- TPR 0.5625 | F1 0.7200 | Elapsed: 2.43s
WARNING:root: [*] Thu Dec 29 15:15:55 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.258948 | FPR 0.001 -- TPR 0.8750 | F1 0.9333 | Elapsed: 2.50s
WARNING:root: [*] Thu Dec 29 15:15:58 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.154848 | FPR 0.001 -- TPR 0.9091 | F1 0.9524 | Elapsed: 2.37s
WARNING:root: [*] Thu Dec 29 15:16:00 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.215735 | FPR 0.001 -- TPR 0.8636 | F1 0.9268 | Elapsed: 2.31s
WARNING:root: [*] Thu Dec 29 15:16:02 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.274928 | FPR 0.001 -- TPR 0.8140 | F1 0.8974 | Elapsed: 2.30s
WARNING:root: [*] Thu Dec 29 15:16:05 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.144790 | FPR 0.001 -- TPR 0.8222 | F1 0.9024 | Elapsed: 2.31s
WARNING:root: [*] Thu Dec 29 15:16:07 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.192857 | FPR 0.001 -- TPR 0.8333 | F1 0.9091 | Elapsed: 2.29s
WARNING:root: [*] Thu Dec 29 15:16:09 2022:    1    | Tr.loss: 0.196872 | FPR 0.001 -- TPR: 0.78 |  F1: 0.85 | Elapsed:   18.69  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Thu Dec 29 15:16:09 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.189550 | FPR 0.001 -- TPR 0.8140 | F1 0.8974 | Elapsed: 0.04s
WARNING:root: [*] Thu Dec 29 15:16:12 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.065090 | FPR 0.001 -- TPR 0.9767 | F1 0.9882 | Elapsed: 2.41s
WARNING:root: [*] Thu Dec 29 15:16:14 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.108799 | FPR 0.001 -- TPR 0.9773 | F1 0.9885 | Elapsed: 2.39s
WARNING:root: [*] Thu Dec 29 15:16:16 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.158101 | FPR 0.001 -- TPR 0.8810 | F1 0.9367 | Elapsed: 2.38s
WARNING:root: [*] Thu Dec 29 15:16:19 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.096389 | FPR 0.001 -- TPR 0.9565 | F1 0.9778 | Elapsed: 2.39s
WARNING:root: [*] Thu Dec 29 15:16:21 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.156446 | FPR 0.001 -- TPR 0.9091 | F1 0.9524 | Elapsed: 2.36s
WARNING:root: [*] Thu Dec 29 15:16:23 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.057849 | FPR 0.001 -- TPR 0.9756 | F1 0.9877 | Elapsed: 2.32s
WARNING:root: [*] Thu Dec 29 15:16:26 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.168249 | FPR 0.001 -- TPR 0.8810 | F1 0.9367 | Elapsed: 2.33s
WARNING:root: [*] Thu Dec 29 15:16:28 2022:    2    | Tr.loss: 0.126947 | FPR 0.001 -- TPR: 0.90 |  F1: 0.94 | Elapsed:   19.03  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Thu Dec 29 15:16:28 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.147174 | FPR 0.001 -- TPR 0.9500 | F1 0.9744 | Elapsed: 0.03s
WARNING:root: [*] Thu Dec 29 15:16:31 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.242763 | FPR 0.001 -- TPR 0.4651 | F1 0.6349 | Elapsed: 2.49s
WARNING:root: [*] Thu Dec 29 15:16:33 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.150184 | FPR 0.001 -- TPR 0.8889 | F1 0.9412 | Elapsed: 2.45s
WARNING:root: [*] Thu Dec 29 15:16:36 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.084223 | FPR 0.001 -- TPR 0.9756 | F1 0.9877 | Elapsed: 2.34s
WARNING:root: [*] Thu Dec 29 15:16:38 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.118793 | FPR 0.001 -- TPR 0.9767 | F1 0.9882 | Elapsed: 2.35s
WARNING:root: [*] Thu Dec 29 15:16:40 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.153457 | FPR 0.001 -- TPR 0.8298 | F1 0.9070 | Elapsed: 2.37s
WARNING:root: [*] Thu Dec 29 15:16:43 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.082933 | FPR 0.001 -- TPR 0.9020 | F1 0.9485 | Elapsed: 2.47s
WARNING:root: [*] Thu Dec 29 15:16:45 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.099399 | FPR 0.001 -- TPR 0.8684 | F1 0.9296 | Elapsed: 2.37s
WARNING:root: [*] Thu Dec 29 15:16:47 2022:    3    | Tr.loss: 0.115322 | FPR 0.001 -- TPR: 0.91 |  F1: 0.95 | Elapsed:   19.10  s
WARNING:root:[!] Thu Dec 29 15:16:47 2022: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672323407-model.torch
                losses    : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672323407-train_losses.npy
                duration  : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672323407-trainTime.npy
		train F1s : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672323407-trainF1s.npy
		train TPRs: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672323407-trainTPRs.npy
WARNING:root: [!] Fold 3/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Thu Dec 29 15:16:50 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.708297 | FPR 0.001 -- TPR 0.0000 | F1 0.0000 | Elapsed: 0.03s
WARNING:root: [*] Thu Dec 29 15:16:52 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.181819 | FPR 0.001 -- TPR 0.8889 | F1 0.9412 | Elapsed: 2.40s
WARNING:root: [*] Thu Dec 29 15:16:55 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.277157 | FPR 0.001 -- TPR 0.3750 | F1 0.5455 | Elapsed: 2.35s
WARNING:root: [*] Thu Dec 29 15:16:57 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.241690 | FPR 0.001 -- TPR 0.4500 | F1 0.6207 | Elapsed: 2.50s
WARNING:root: [*] Thu Dec 29 15:17:00 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.195630 | FPR 0.001 -- TPR 0.8750 | F1 0.9333 | Elapsed: 2.40s
WARNING:root: [*] Thu Dec 29 15:17:02 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.137962 | FPR 0.001 -- TPR 0.8958 | F1 0.9451 | Elapsed: 2.38s
WARNING:root: [*] Thu Dec 29 15:17:04 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.084721 | FPR 0.001 -- TPR 0.9545 | F1 0.9767 | Elapsed: 2.41s
WARNING:root: [*] Thu Dec 29 15:17:07 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.060484 | FPR 0.001 -- TPR 0.9792 | F1 0.9895 | Elapsed: 2.37s
WARNING:root: [*] Thu Dec 29 15:17:09 2022:    1    | Tr.loss: 0.195719 | FPR 0.001 -- TPR: 0.79 |  F1: 0.86 | Elapsed:   19.04  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Thu Dec 29 15:17:09 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.128120 | FPR 0.001 -- TPR 0.8837 | F1 0.9383 | Elapsed: 0.03s
WARNING:root: [*] Thu Dec 29 15:17:11 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.142070 | FPR 0.001 -- TPR 0.8462 | F1 0.9167 | Elapsed: 2.40s
WARNING:root: [*] Thu Dec 29 15:17:14 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.187135 | FPR 0.001 -- TPR 0.8378 | F1 0.9118 | Elapsed: 2.33s
WARNING:root: [*] Thu Dec 29 15:17:16 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.128507 | FPR 0.001 -- TPR 0.9250 | F1 0.9610 | Elapsed: 2.29s
WARNING:root: [*] Thu Dec 29 15:17:18 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.247585 | FPR 0.001 -- TPR 0.8000 | F1 0.8889 | Elapsed: 2.39s
WARNING:root: [*] Thu Dec 29 15:17:21 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.094110 | FPR 0.001 -- TPR 0.9767 | F1 0.9882 | Elapsed: 2.44s
WARNING:root: [*] Thu Dec 29 15:17:23 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.066815 | FPR 0.001 -- TPR 0.9762 | F1 0.9880 | Elapsed: 2.47s
WARNING:root: [*] Thu Dec 29 15:17:26 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.106957 | FPR 0.001 -- TPR 0.9750 | F1 0.9873 | Elapsed: 2.38s
WARNING:root: [*] Thu Dec 29 15:17:28 2022:    2    | Tr.loss: 0.127650 | FPR 0.001 -- TPR: 0.89 |  F1: 0.94 | Elapsed:   18.85  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Thu Dec 29 15:17:28 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.131039 | FPR 0.001 -- TPR 0.8974 | F1 0.9459 | Elapsed: 0.04s
WARNING:root: [*] Thu Dec 29 15:17:30 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.122607 | FPR 0.001 -- TPR 0.8936 | F1 0.9438 | Elapsed: 2.46s
WARNING:root: [*] Thu Dec 29 15:17:33 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.203769 | FPR 0.001 -- TPR 0.8723 | F1 0.9318 | Elapsed: 2.31s
WARNING:root: [*] Thu Dec 29 15:17:35 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.079455 | FPR 0.001 -- TPR 1.0000 | F1 1.0000 | Elapsed: 2.35s
WARNING:root: [*] Thu Dec 29 15:17:38 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.122202 | FPR 0.001 -- TPR 0.9792 | F1 0.9895 | Elapsed: 2.60s
WARNING:root: [*] Thu Dec 29 15:17:40 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.077134 | FPR 0.001 -- TPR 0.9318 | F1 0.9647 | Elapsed: 2.56s
WARNING:root: [*] Thu Dec 29 15:17:43 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.168738 | FPR 0.001 -- TPR 0.9592 | F1 0.9792 | Elapsed: 2.51s
WARNING:root: [*] Thu Dec 29 15:17:45 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.154958 | FPR 0.001 -- TPR 0.7021 | F1 0.8250 | Elapsed: 2.58s
WARNING:root: [*] Thu Dec 29 15:17:48 2022:    3    | Tr.loss: 0.116820 | FPR 0.001 -- TPR: 0.91 |  F1: 0.95 | Elapsed:   19.78  s
WARNING:root:[!] Thu Dec 29 15:17:48 2022: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672323468-model.torch
                losses    : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672323468-train_losses.npy
                duration  : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672323468-trainTime.npy
		train F1s : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672323468-trainF1s.npy
		train TPRs: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672323468-trainTPRs.npy
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\metrics_trainSize_76126_ep_3_cv_3_maxLen_256_vocabSize_500_embeddingDim_64_hiddenNeurons_512_256_128_batchNormConv_False_batchNormFFNN_False_filterSizes_2_3_4_5.json
WARNING:root: [!] Average epoch time: 19.63s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.3010 -- F1: 0.4566
	FPR:  0.001 -- TPR: 0.7255 -- F1: 0.8391
	FPR:   0.01 -- TPR: 0.8977 -- F1: 0.9437
	FPR:    0.1 -- TPR: 0.9759 -- F1: 0.9655

WARNING:root: [!] Starting valiation of file 15/16
WARNING:root: [!] Running Cross Validation with vocabSize: 500 | maxLen: 512
WARNING:root: [!] Using device: cuda:0 | Dataset size: 76126
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 500, 'embeddingDim': 64, 'hiddenNeurons': [512, 256, 128], 'batchNormConv': False, 'batchNormFFNN': False, 'filterSizes': [2, 3, 4, 5]}
WARNING:root: [!] Fold 1/3 | Train set size: 50750, Validation set size: 25376
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Thu Dec 29 15:17:50 2022: Train Epoch: 1 [  0  /50750 (0 %)]	Loss: 0.675011 | FPR 0.001 -- TPR 0.0488 | F1 0.0930 | Elapsed: 0.04s
WARNING:root: [*] Thu Dec 29 15:17:54 2022: Train Epoch: 1 [6400 /50750 (13%)]	Loss: 0.276386 | FPR 0.001 -- TPR 0.3409 | F1 0.5085 | Elapsed: 3.81s
WARNING:root: [*] Thu Dec 29 15:17:58 2022: Train Epoch: 1 [12800/50750 (25%)]	Loss: 0.178278 | FPR 0.001 -- TPR 0.9762 | F1 0.9880 | Elapsed: 4.13s
WARNING:root: [*] Thu Dec 29 15:18:02 2022: Train Epoch: 1 [19200/50750 (38%)]	Loss: 0.212612 | FPR 0.001 -- TPR 0.8333 | F1 0.9091 | Elapsed: 3.61s
WARNING:root: [*] Thu Dec 29 15:18:06 2022: Train Epoch: 1 [25600/50750 (50%)]	Loss: 0.170952 | FPR 0.001 -- TPR 0.9048 | F1 0.9500 | Elapsed: 4.15s
WARNING:root: [*] Thu Dec 29 15:18:10 2022: Train Epoch: 1 [32000/50750 (63%)]	Loss: 0.282886 | FPR 0.001 -- TPR 0.8372 | F1 0.9114 | Elapsed: 3.91s
WARNING:root: [*] Thu Dec 29 15:18:14 2022: Train Epoch: 1 [38400/50750 (76%)]	Loss: 0.181894 | FPR 0.001 -- TPR 0.8667 | F1 0.9286 | Elapsed: 3.52s
WARNING:root: [*] Thu Dec 29 15:18:17 2022: Train Epoch: 1 [44800/50750 (88%)]	Loss: 0.200860 | FPR 0.001 -- TPR 0.8605 | F1 0.9250 | Elapsed: 3.44s
WARNING:root: [*] Thu Dec 29 15:18:20 2022:    1    | Tr.loss: 0.177276 | FPR 0.001 -- TPR: 0.82 |  F1: 0.88 | Elapsed:   29.73  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Thu Dec 29 15:18:20 2022: Train Epoch: 2 [  0  /50750 (0 %)]	Loss: 0.068174 | FPR 0.001 -- TPR 1.0000 | F1 1.0000 | Elapsed: 0.04s
WARNING:root: [*] Thu Dec 29 15:18:24 2022: Train Epoch: 2 [6400 /50750 (13%)]	Loss: 0.131350 | FPR 0.001 -- TPR 0.8889 | F1 0.9412 | Elapsed: 3.64s
WARNING:root: [*] Thu Dec 29 15:18:27 2022: Train Epoch: 2 [12800/50750 (25%)]	Loss: 0.166858 | FPR 0.001 -- TPR 0.8182 | F1 0.9000 | Elapsed: 3.39s
WARNING:root: [*] Thu Dec 29 15:18:31 2022: Train Epoch: 2 [19200/50750 (38%)]	Loss: 0.076653 | FPR 0.001 -- TPR 0.9783 | F1 0.9890 | Elapsed: 3.41s
WARNING:root: [*] Thu Dec 29 15:18:35 2022: Train Epoch: 2 [25600/50750 (50%)]	Loss: 0.056982 | FPR 0.001 -- TPR 0.9767 | F1 0.9882 | Elapsed: 4.07s
WARNING:root: [*] Thu Dec 29 15:18:38 2022: Train Epoch: 2 [32000/50750 (63%)]	Loss: 0.066998 | FPR 0.001 -- TPR 1.0000 | F1 1.0000 | Elapsed: 3.56s
WARNING:root: [*] Thu Dec 29 15:18:42 2022: Train Epoch: 2 [38400/50750 (76%)]	Loss: 0.150897 | FPR 0.001 -- TPR 0.8913 | F1 0.9425 | Elapsed: 3.57s
WARNING:root: [*] Thu Dec 29 15:18:45 2022: Train Epoch: 2 [44800/50750 (88%)]	Loss: 0.087837 | FPR 0.001 -- TPR 0.9792 | F1 0.9895 | Elapsed: 3.42s
WARNING:root: [*] Thu Dec 29 15:18:48 2022:    2    | Tr.loss: 0.105222 | FPR 0.001 -- TPR: 0.93 |  F1: 0.96 | Elapsed:   28.26  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Thu Dec 29 15:18:48 2022: Train Epoch: 3 [  0  /50750 (0 %)]	Loss: 0.110211 | FPR 0.001 -- TPR 0.8571 | F1 0.9231 | Elapsed: 0.05s
WARNING:root: [*] Thu Dec 29 15:18:52 2022: Train Epoch: 3 [6400 /50750 (13%)]	Loss: 0.193972 | FPR 0.001 -- TPR 0.8182 | F1 0.9000 | Elapsed: 3.55s
WARNING:root: [*] Thu Dec 29 15:18:56 2022: Train Epoch: 3 [12800/50750 (25%)]	Loss: 0.154942 | FPR 0.001 -- TPR 0.9286 | F1 0.9630 | Elapsed: 3.69s
WARNING:root: [*] Thu Dec 29 15:18:59 2022: Train Epoch: 3 [19200/50750 (38%)]	Loss: 0.118906 | FPR 0.001 -- TPR 0.9808 | F1 0.9903 | Elapsed: 3.43s
WARNING:root: [*] Thu Dec 29 15:19:03 2022: Train Epoch: 3 [25600/50750 (50%)]	Loss: 0.087714 | FPR 0.001 -- TPR 0.9730 | F1 0.9863 | Elapsed: 3.35s
WARNING:root: [*] Thu Dec 29 15:19:06 2022: Train Epoch: 3 [32000/50750 (63%)]	Loss: 0.059736 | FPR 0.001 -- TPR 1.0000 | F1 1.0000 | Elapsed: 3.42s
WARNING:root: [*] Thu Dec 29 15:19:09 2022: Train Epoch: 3 [38400/50750 (76%)]	Loss: 0.093127 | FPR 0.001 -- TPR 0.9524 | F1 0.9756 | Elapsed: 3.37s
WARNING:root: [*] Thu Dec 29 15:19:13 2022: Train Epoch: 3 [44800/50750 (88%)]	Loss: 0.137044 | FPR 0.001 -- TPR 0.9545 | F1 0.9767 | Elapsed: 3.58s
WARNING:root: [*] Thu Dec 29 15:19:16 2022:    3    | Tr.loss: 0.095410 | FPR 0.001 -- TPR: 0.93 |  F1: 0.96 | Elapsed:   28.02  s
WARNING:root:[!] Thu Dec 29 15:19:16 2022: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672323556-model.torch
                losses    : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672323556-train_losses.npy
                duration  : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672323556-trainTime.npy
		train F1s : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672323556-trainF1s.npy
		train TPRs: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672323556-trainTPRs.npy
WARNING:root: [!] Fold 2/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Thu Dec 29 15:19:20 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.700018 | FPR 0.001 -- TPR 0.0256 | F1 0.0500 | Elapsed: 0.04s
WARNING:root: [*] Thu Dec 29 15:19:24 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.317546 | FPR 0.001 -- TPR 0.8000 | F1 0.8889 | Elapsed: 3.84s
WARNING:root: [*] Thu Dec 29 15:19:28 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.173421 | FPR 0.001 -- TPR 0.9524 | F1 0.9756 | Elapsed: 3.43s
WARNING:root: [*] Thu Dec 29 15:19:31 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.116940 | FPR 0.001 -- TPR 0.9556 | F1 0.9773 | Elapsed: 3.28s
WARNING:root: [*] Thu Dec 29 15:19:34 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.149860 | FPR 0.001 -- TPR 0.9348 | F1 0.9663 | Elapsed: 3.35s
WARNING:root: [*] Thu Dec 29 15:19:38 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.079560 | FPR 0.001 -- TPR 0.9545 | F1 0.9767 | Elapsed: 3.55s
WARNING:root: [*] Thu Dec 29 15:19:42 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.138458 | FPR 0.001 -- TPR 0.8049 | F1 0.8919 | Elapsed: 3.82s
WARNING:root: [*] Thu Dec 29 15:19:46 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.054398 | FPR 0.001 -- TPR 0.9574 | F1 0.9783 | Elapsed: 4.23s
WARNING:root: [*] Thu Dec 29 15:19:50 2022:    1    | Tr.loss: 0.175082 | FPR 0.001 -- TPR: 0.83 |  F1: 0.89 | Elapsed:   29.37  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Thu Dec 29 15:19:50 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.081435 | FPR 0.001 -- TPR 1.0000 | F1 1.0000 | Elapsed: 0.04s
WARNING:root: [*] Thu Dec 29 15:19:53 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.075069 | FPR 0.001 -- TPR 0.9048 | F1 0.9500 | Elapsed: 3.55s
WARNING:root: [*] Thu Dec 29 15:19:57 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.054867 | FPR 0.001 -- TPR 1.0000 | F1 1.0000 | Elapsed: 3.60s
WARNING:root: [*] Thu Dec 29 15:20:00 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.120291 | FPR 0.001 -- TPR 0.8837 | F1 0.9383 | Elapsed: 3.47s
WARNING:root: [*] Thu Dec 29 15:20:04 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.097281 | FPR 0.001 -- TPR 0.8605 | F1 0.9250 | Elapsed: 3.30s
WARNING:root: [*] Thu Dec 29 15:20:07 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.083626 | FPR 0.001 -- TPR 0.9773 | F1 0.9885 | Elapsed: 3.29s
WARNING:root: [*] Thu Dec 29 15:20:10 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.116761 | FPR 0.001 -- TPR 0.9787 | F1 0.9892 | Elapsed: 3.38s
WARNING:root: [*] Thu Dec 29 15:20:14 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.021163 | FPR 0.001 -- TPR 1.0000 | F1 1.0000 | Elapsed: 3.49s
WARNING:root: [*] Thu Dec 29 15:20:17 2022:    2    | Tr.loss: 0.106642 | FPR 0.001 -- TPR: 0.92 |  F1: 0.96 | Elapsed:   27.14  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Thu Dec 29 15:20:17 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.084794 | FPR 0.001 -- TPR 0.9429 | F1 0.9706 | Elapsed: 0.04s
WARNING:root: [*] Thu Dec 29 15:20:20 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.049733 | FPR 0.001 -- TPR 1.0000 | F1 1.0000 | Elapsed: 3.42s
WARNING:root: [*] Thu Dec 29 15:20:24 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.064119 | FPR 0.001 -- TPR 1.0000 | F1 1.0000 | Elapsed: 3.36s
WARNING:root: [*] Thu Dec 29 15:20:27 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.041358 | FPR 0.001 -- TPR 1.0000 | F1 1.0000 | Elapsed: 3.27s
WARNING:root: [*] Thu Dec 29 15:20:30 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.048237 | FPR 0.001 -- TPR 0.9535 | F1 0.9762 | Elapsed: 3.40s
WARNING:root: [*] Thu Dec 29 15:20:34 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.056278 | FPR 0.001 -- TPR 1.0000 | F1 1.0000 | Elapsed: 3.66s
WARNING:root: [*] Thu Dec 29 15:20:37 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.096529 | FPR 0.001 -- TPR 0.9535 | F1 0.9762 | Elapsed: 3.38s
WARNING:root: [*] Thu Dec 29 15:20:41 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.087098 | FPR 0.001 -- TPR 0.9524 | F1 0.9756 | Elapsed: 3.37s
WARNING:root: [*] Thu Dec 29 15:20:44 2022:    3    | Tr.loss: 0.094039 | FPR 0.001 -- TPR: 0.94 |  F1: 0.96 | Elapsed:   27.28  s
WARNING:root:[!] Thu Dec 29 15:20:44 2022: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672323644-model.torch
                losses    : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672323644-train_losses.npy
                duration  : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672323644-trainTime.npy
		train F1s : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672323644-trainF1s.npy
		train TPRs: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672323644-trainTPRs.npy
WARNING:root: [!] Fold 3/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Thu Dec 29 15:20:48 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.703596 | FPR 0.001 -- TPR 0.0833 | F1 0.1538 | Elapsed: 0.04s
WARNING:root: [*] Thu Dec 29 15:20:51 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.135319 | FPR 0.001 -- TPR 0.8571 | F1 0.9231 | Elapsed: 3.36s
WARNING:root: [*] Thu Dec 29 15:20:55 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.138155 | FPR 0.001 -- TPR 0.8478 | F1 0.9176 | Elapsed: 3.39s
WARNING:root: [*] Thu Dec 29 15:20:58 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.237183 | FPR 0.001 -- TPR 0.4048 | F1 0.5763 | Elapsed: 3.48s
WARNING:root: [*] Thu Dec 29 15:21:02 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.092431 | FPR 0.001 -- TPR 0.9302 | F1 0.9639 | Elapsed: 3.31s
WARNING:root: [*] Thu Dec 29 15:21:05 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.111865 | FPR 0.001 -- TPR 0.9615 | F1 0.9804 | Elapsed: 3.42s
WARNING:root: [*] Thu Dec 29 15:21:09 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.125875 | FPR 0.001 -- TPR 0.9487 | F1 0.9737 | Elapsed: 3.56s
WARNING:root: [*] Thu Dec 29 15:21:12 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.132978 | FPR 0.001 -- TPR 0.7500 | F1 0.8571 | Elapsed: 3.64s
WARNING:root: [*] Thu Dec 29 15:21:15 2022:    1    | Tr.loss: 0.174389 | FPR 0.001 -- TPR: 0.82 |  F1: 0.88 | Elapsed:   27.49  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Thu Dec 29 15:21:16 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.136456 | FPR 0.001 -- TPR 0.8750 | F1 0.9333 | Elapsed: 0.05s
WARNING:root: [*] Thu Dec 29 15:21:19 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.159728 | FPR 0.001 -- TPR 0.9200 | F1 0.9583 | Elapsed: 3.33s
WARNING:root: [*] Thu Dec 29 15:21:22 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.096925 | FPR 0.001 -- TPR 0.9268 | F1 0.9620 | Elapsed: 3.28s
WARNING:root: [*] Thu Dec 29 15:21:25 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.126392 | FPR 0.001 -- TPR 0.8837 | F1 0.9383 | Elapsed: 3.30s
WARNING:root: [*] Thu Dec 29 15:21:29 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.145801 | FPR 0.001 -- TPR 0.8936 | F1 0.9438 | Elapsed: 3.27s
WARNING:root: [*] Thu Dec 29 15:21:32 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.055556 | FPR 0.001 -- TPR 0.9535 | F1 0.9762 | Elapsed: 3.25s
WARNING:root: [*] Thu Dec 29 15:21:35 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.216856 | FPR 0.001 -- TPR 0.9268 | F1 0.9620 | Elapsed: 3.26s
WARNING:root: [*] Thu Dec 29 15:21:38 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.120246 | FPR 0.001 -- TPR 0.9333 | F1 0.9655 | Elapsed: 3.28s
WARNING:root: [*] Thu Dec 29 15:21:42 2022:    2    | Tr.loss: 0.104231 | FPR 0.001 -- TPR: 0.92 |  F1: 0.96 | Elapsed:   26.11  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Thu Dec 29 15:21:42 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.121962 | FPR 0.001 -- TPR 0.8837 | F1 0.9383 | Elapsed: 0.05s
WARNING:root: [*] Thu Dec 29 15:21:46 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.267340 | FPR 0.001 -- TPR 0.7143 | F1 0.8333 | Elapsed: 4.10s
WARNING:root: [*] Thu Dec 29 15:21:49 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.069708 | FPR 0.001 -- TPR 0.9756 | F1 0.9877 | Elapsed: 3.64s
WARNING:root: [*] Thu Dec 29 15:21:53 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.148900 | FPR 0.001 -- TPR 0.8500 | F1 0.9189 | Elapsed: 3.44s
WARNING:root: [*] Thu Dec 29 15:21:56 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.133677 | FPR 0.001 -- TPR 0.7907 | F1 0.8831 | Elapsed: 3.42s
WARNING:root: [*] Thu Dec 29 15:22:00 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.039658 | FPR 0.001 -- TPR 1.0000 | F1 1.0000 | Elapsed: 3.55s
WARNING:root: [*] Thu Dec 29 15:22:03 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.056300 | FPR 0.001 -- TPR 0.9796 | F1 0.9897 | Elapsed: 3.71s
WARNING:root: [*] Thu Dec 29 15:22:07 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.066812 | FPR 0.001 -- TPR 0.9787 | F1 0.9892 | Elapsed: 3.45s
WARNING:root: [*] Thu Dec 29 15:22:10 2022:    3    | Tr.loss: 0.093007 | FPR 0.001 -- TPR: 0.94 |  F1: 0.96 | Elapsed:   28.44  s
WARNING:root:[!] Thu Dec 29 15:22:10 2022: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672323730-model.torch
                losses    : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672323730-train_losses.npy
                duration  : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672323730-trainTime.npy
		train F1s : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672323730-trainF1s.npy
		train TPRs: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1672323730-trainTPRs.npy
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation\APIonly\Cnn1DLinear_VocabSize_maxLen\metrics_trainSize_76126_ep_3_cv_3_maxLen_512_vocabSize_500_embeddingDim_64_hiddenNeurons_512_256_128_batchNormConv_False_batchNormFFNN_False_filterSizes_2_3_4_5.json
WARNING:root: [!] Average epoch time: 27.98s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.4019 -- F1: 0.5720
	FPR:  0.001 -- TPR: 0.7985 -- F1: 0.8874
	FPR:   0.01 -- TPR: 0.9096 -- F1: 0.9503
	FPR:    0.1 -- TPR: 0.9873 -- F1: 0.9710

