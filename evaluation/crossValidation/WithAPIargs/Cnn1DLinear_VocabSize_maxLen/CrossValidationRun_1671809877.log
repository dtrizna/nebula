WARNING:root: [!] Using vocabSize: 10000 | maxLen: 1024
WARNING:root: [!] Using device: cuda:0 | Dataset size: 76126
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 10000, 'embeddingDim': 64, 'hiddenNeurons': [512, 256, 128], 'batchNormConv': False, 'batchNormFFNN': False, 'filterSizes': [2, 3, 4, 5]}
WARNING:root: [!] Fold 1/3 | Train set size: 50750, Validation set size: 25376
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 16:38:00 2022: Train Epoch: 1 [  0  /50750 (0 %)]	Loss: 0.709707 | F1-score: 0.55 | Elapsed: 2.74s
WARNING:root: [*] Fri Dec 23 16:38:04 2022: Train Epoch: 1 [6400 /50750 (13%)]	Loss: 0.229782 | F1-score: 0.87 | Elapsed: 3.98s
WARNING:root: [*] Fri Dec 23 16:38:08 2022: Train Epoch: 1 [12800/50750 (25%)]	Loss: 0.198241 | F1-score: 0.91 | Elapsed: 3.86s
WARNING:root: [*] Fri Dec 23 16:38:12 2022: Train Epoch: 1 [19200/50750 (38%)]	Loss: 0.079341 | F1-score: 0.93 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 16:38:15 2022: Train Epoch: 1 [25600/50750 (50%)]	Loss: 0.120714 | F1-score: 0.94 | Elapsed: 3.89s
WARNING:root: [*] Fri Dec 23 16:38:19 2022: Train Epoch: 1 [32000/50750 (63%)]	Loss: 0.044769 | F1-score: 0.94 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 16:38:23 2022: Train Epoch: 1 [38400/50750 (76%)]	Loss: 0.089055 | F1-score: 0.95 | Elapsed: 3.96s
WARNING:root: [*] Fri Dec 23 16:38:27 2022: Train Epoch: 1 [44800/50750 (88%)]	Loss: 0.084246 | F1-score: 0.95 | Elapsed: 4.04s
WARNING:root: [*] Fri Dec 23 16:38:31 2022:    1    | Tr.loss: 0.152963 | Tr.F1.:   0.96    |   33.97  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 16:38:31 2022: Train Epoch: 2 [  0  /50750 (0 %)]	Loss: 0.032858 | F1-score: 1.00 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 16:38:35 2022: Train Epoch: 2 [6400 /50750 (13%)]	Loss: 0.080554 | F1-score: 0.98 | Elapsed: 4.02s
WARNING:root: [*] Fri Dec 23 16:38:39 2022: Train Epoch: 2 [12800/50750 (25%)]	Loss: 0.011696 | F1-score: 0.98 | Elapsed: 4.01s
WARNING:root: [*] Fri Dec 23 16:38:43 2022: Train Epoch: 2 [19200/50750 (38%)]	Loss: 0.104056 | F1-score: 0.98 | Elapsed: 4.00s
WARNING:root: [*] Fri Dec 23 16:38:47 2022: Train Epoch: 2 [25600/50750 (50%)]	Loss: 0.143680 | F1-score: 0.98 | Elapsed: 4.00s
WARNING:root: [*] Fri Dec 23 16:38:51 2022: Train Epoch: 2 [32000/50750 (63%)]	Loss: 0.070383 | F1-score: 0.98 | Elapsed: 4.00s
WARNING:root: [*] Fri Dec 23 16:38:55 2022: Train Epoch: 2 [38400/50750 (76%)]	Loss: 0.149323 | F1-score: 0.98 | Elapsed: 4.03s
WARNING:root: [*] Fri Dec 23 16:38:59 2022: Train Epoch: 2 [44800/50750 (88%)]	Loss: 0.047629 | F1-score: 0.98 | Elapsed: 4.01s
WARNING:root: [*] Fri Dec 23 16:39:03 2022:    2    | Tr.loss: 0.072698 | Tr.F1.:   0.98    |   31.82  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 16:39:03 2022: Train Epoch: 3 [  0  /50750 (0 %)]	Loss: 0.038623 | F1-score: 0.99 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 16:39:07 2022: Train Epoch: 3 [6400 /50750 (13%)]	Loss: 0.046838 | F1-score: 0.99 | Elapsed: 4.04s
WARNING:root: [*] Fri Dec 23 16:39:11 2022: Train Epoch: 3 [12800/50750 (25%)]	Loss: 0.034665 | F1-score: 0.98 | Elapsed: 4.00s
WARNING:root: [*] Fri Dec 23 16:39:15 2022: Train Epoch: 3 [19200/50750 (38%)]	Loss: 0.016167 | F1-score: 0.98 | Elapsed: 4.01s
WARNING:root: [*] Fri Dec 23 16:39:19 2022: Train Epoch: 3 [25600/50750 (50%)]	Loss: 0.101825 | F1-score: 0.98 | Elapsed: 4.00s
WARNING:root: [*] Fri Dec 23 16:39:23 2022: Train Epoch: 3 [32000/50750 (63%)]	Loss: 0.030150 | F1-score: 0.98 | Elapsed: 4.04s
WARNING:root: [*] Fri Dec 23 16:39:27 2022: Train Epoch: 3 [38400/50750 (76%)]	Loss: 0.060396 | F1-score: 0.98 | Elapsed: 4.06s
WARNING:root: [*] Fri Dec 23 16:39:31 2022: Train Epoch: 3 [44800/50750 (88%)]	Loss: 0.056362 | F1-score: 0.98 | Elapsed: 4.04s
WARNING:root: [*] Fri Dec 23 16:39:35 2022:    3    | Tr.loss: 0.058683 | Tr.F1.:   0.98    |   32.07  s
WARNING:root:
        [!] Fri Dec 23 16:39:35 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671809975-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671809975-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671809975-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671809975-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 16:39:39 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.722044 | F1-score: 0.34 | Elapsed: 0.05s
WARNING:root: [*] Fri Dec 23 16:39:43 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.283556 | F1-score: 0.87 | Elapsed: 3.96s
WARNING:root: [*] Fri Dec 23 16:39:47 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.109164 | F1-score: 0.91 | Elapsed: 3.94s
WARNING:root: [*] Fri Dec 23 16:39:51 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.135850 | F1-score: 0.93 | Elapsed: 3.94s
WARNING:root: [*] Fri Dec 23 16:39:55 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.079279 | F1-score: 0.94 | Elapsed: 3.97s
WARNING:root: [*] Fri Dec 23 16:39:59 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.036645 | F1-score: 0.95 | Elapsed: 3.94s
WARNING:root: [*] Fri Dec 23 16:40:03 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.050411 | F1-score: 0.95 | Elapsed: 3.99s
WARNING:root: [*] Fri Dec 23 16:40:07 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.087363 | F1-score: 0.95 | Elapsed: 4.02s
WARNING:root: [*] Fri Dec 23 16:40:11 2022:    1    | Tr.loss: 0.150644 | Tr.F1.:   0.96    |   31.51  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 16:40:11 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.036595 | F1-score: 1.00 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 16:40:15 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.266306 | F1-score: 0.98 | Elapsed: 4.03s
WARNING:root: [*] Fri Dec 23 16:40:19 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.149756 | F1-score: 0.98 | Elapsed: 4.01s
WARNING:root: [*] Fri Dec 23 16:40:23 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.288958 | F1-score: 0.98 | Elapsed: 4.01s
WARNING:root: [*] Fri Dec 23 16:40:27 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.120911 | F1-score: 0.98 | Elapsed: 4.03s
WARNING:root: [*] Fri Dec 23 16:40:31 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.131665 | F1-score: 0.98 | Elapsed: 4.05s
WARNING:root: [*] Fri Dec 23 16:40:35 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.025132 | F1-score: 0.98 | Elapsed: 4.01s
WARNING:root: [*] Fri Dec 23 16:40:39 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.073397 | F1-score: 0.98 | Elapsed: 4.04s
WARNING:root: [*] Fri Dec 23 16:40:43 2022:    2    | Tr.loss: 0.074502 | Tr.F1.:   0.98    |   31.94  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 16:40:43 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.141060 | F1-score: 0.96 | Elapsed: 0.05s
WARNING:root: [*] Fri Dec 23 16:40:47 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.074292 | F1-score: 0.98 | Elapsed: 4.04s
WARNING:root: [*] Fri Dec 23 16:40:51 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.223433 | F1-score: 0.98 | Elapsed: 4.02s
WARNING:root: [*] Fri Dec 23 16:40:55 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.078630 | F1-score: 0.98 | Elapsed: 4.04s
WARNING:root: [*] Fri Dec 23 16:40:59 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.074593 | F1-score: 0.98 | Elapsed: 4.02s
WARNING:root: [*] Fri Dec 23 16:41:03 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.116152 | F1-score: 0.98 | Elapsed: 4.05s
WARNING:root: [*] Fri Dec 23 16:41:07 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.093180 | F1-score: 0.98 | Elapsed: 4.05s
WARNING:root: [*] Fri Dec 23 16:41:11 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.015380 | F1-score: 0.98 | Elapsed: 4.04s
WARNING:root: [*] Fri Dec 23 16:41:15 2022:    3    | Tr.loss: 0.061744 | Tr.F1.:   0.98    |   32.01  s
WARNING:root:
        [!] Fri Dec 23 16:41:15 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671810075-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671810075-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671810075-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671810075-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 16:41:20 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.700749 | F1-score: 0.40 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 16:41:24 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.293655 | F1-score: 0.86 | Elapsed: 4.04s
WARNING:root: [*] Fri Dec 23 16:41:28 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.146098 | F1-score: 0.91 | Elapsed: 4.02s
WARNING:root: [*] Fri Dec 23 16:41:32 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.203090 | F1-score: 0.93 | Elapsed: 4.02s
WARNING:root: [*] Fri Dec 23 16:41:36 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.060551 | F1-score: 0.94 | Elapsed: 4.01s
WARNING:root: [*] Fri Dec 23 16:41:40 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.118201 | F1-score: 0.94 | Elapsed: 4.07s
WARNING:root: [*] Fri Dec 23 16:41:44 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.101312 | F1-score: 0.95 | Elapsed: 4.08s
WARNING:root: [*] Fri Dec 23 16:41:48 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.061295 | F1-score: 0.95 | Elapsed: 4.06s
WARNING:root: [*] Fri Dec 23 16:41:52 2022:    1    | Tr.loss: 0.150085 | Tr.F1.:   0.96    |   32.10  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 16:41:52 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.077106 | F1-score: 0.98 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 16:41:56 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.053373 | F1-score: 0.98 | Elapsed: 4.08s
WARNING:root: [*] Fri Dec 23 16:42:00 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.104549 | F1-score: 0.98 | Elapsed: 4.06s
WARNING:root: [*] Fri Dec 23 16:42:04 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.016179 | F1-score: 0.98 | Elapsed: 4.05s
WARNING:root: [*] Fri Dec 23 16:42:08 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.045822 | F1-score: 0.98 | Elapsed: 4.09s
WARNING:root: [*] Fri Dec 23 16:42:12 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.218345 | F1-score: 0.98 | Elapsed: 4.07s
WARNING:root: [*] Fri Dec 23 16:42:16 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.137977 | F1-score: 0.98 | Elapsed: 4.06s
WARNING:root: [*] Fri Dec 23 16:42:20 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.048105 | F1-score: 0.98 | Elapsed: 4.09s
WARNING:root: [*] Fri Dec 23 16:42:24 2022:    2    | Tr.loss: 0.071174 | Tr.F1.:   0.98    |   32.33  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 16:42:24 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.013506 | F1-score: 1.00 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 16:42:28 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.047256 | F1-score: 0.98 | Elapsed: 4.12s
WARNING:root: [*] Fri Dec 23 16:42:32 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.065747 | F1-score: 0.98 | Elapsed: 4.09s
WARNING:root: [*] Fri Dec 23 16:42:36 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.006046 | F1-score: 0.98 | Elapsed: 4.07s
WARNING:root: [*] Fri Dec 23 16:42:40 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.019598 | F1-score: 0.98 | Elapsed: 4.10s
WARNING:root: [*] Fri Dec 23 16:42:45 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.047098 | F1-score: 0.98 | Elapsed: 4.10s
WARNING:root: [*] Fri Dec 23 16:42:49 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.083948 | F1-score: 0.98 | Elapsed: 4.12s
WARNING:root: [*] Fri Dec 23 16:42:53 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.065938 | F1-score: 0.98 | Elapsed: 4.06s
WARNING:root: [*] Fri Dec 23 16:42:56 2022:    3    | Tr.loss: 0.059559 | Tr.F1.:   0.98    |   32.43  s
WARNING:root:
        [!] Fri Dec 23 16:42:56 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671810176-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671810176-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671810176-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671810176-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\metrics_trainSize_76126_ep_3_cv_3_maxLen_1024_vocabSize_10000_embeddingDim_64_hiddenNeurons_512_256_128_batchNormConv_False_batchNormFFNN_False_filterSizes_2_3_4_5.json
WARNING:root: [!] Average epoch time: 32.24s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.6803 -- F1: 0.8062
	FPR:  0.001 -- TPR: 0.9151 -- F1: 0.9554
	FPR:   0.01 -- TPR: 0.9688 -- F1: 0.9820
	FPR:    0.1 -- TPR: 0.9953 -- F1: 0.9743

WARNING:root: [!] Using vocabSize: 10000 | maxLen: 2048
WARNING:root: [!] Using device: cuda:0 | Dataset size: 76126
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 10000, 'embeddingDim': 64, 'hiddenNeurons': [512, 256, 128], 'batchNormConv': False, 'batchNormFFNN': False, 'filterSizes': [2, 3, 4, 5]}
WARNING:root: [!] Fold 1/3 | Train set size: 50750, Validation set size: 25376
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 16:43:32 2022: Train Epoch: 1 [  0  /50750 (0 %)]	Loss: 0.693106 | F1-score: 0.61 | Elapsed: 0.31s
WARNING:root: [*] Fri Dec 23 16:43:39 2022: Train Epoch: 1 [6400 /50750 (13%)]	Loss: 0.218923 | F1-score: 0.88 | Elapsed: 7.31s
WARNING:root: [*] Fri Dec 23 16:43:47 2022: Train Epoch: 1 [12800/50750 (25%)]	Loss: 0.125322 | F1-score: 0.91 | Elapsed: 7.28s
WARNING:root: [*] Fri Dec 23 16:43:54 2022: Train Epoch: 1 [19200/50750 (38%)]	Loss: 0.144076 | F1-score: 0.93 | Elapsed: 7.32s
WARNING:root: [*] Fri Dec 23 16:44:01 2022: Train Epoch: 1 [25600/50750 (50%)]	Loss: 0.058756 | F1-score: 0.94 | Elapsed: 7.34s
WARNING:root: [*] Fri Dec 23 16:44:09 2022: Train Epoch: 1 [32000/50750 (63%)]	Loss: 0.076435 | F1-score: 0.95 | Elapsed: 7.34s
WARNING:root: [*] Fri Dec 23 16:44:16 2022: Train Epoch: 1 [38400/50750 (76%)]	Loss: 0.047502 | F1-score: 0.95 | Elapsed: 7.37s
WARNING:root: [*] Fri Dec 23 16:44:23 2022: Train Epoch: 1 [44800/50750 (88%)]	Loss: 0.063667 | F1-score: 0.96 | Elapsed: 7.36s
WARNING:root: [*] Fri Dec 23 16:44:30 2022:    1    | Tr.loss: 0.148409 | Tr.F1.:   0.96    |   58.40  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 16:44:30 2022: Train Epoch: 2 [  0  /50750 (0 %)]	Loss: 0.068444 | F1-score: 0.98 | Elapsed: 0.09s
WARNING:root: [*] Fri Dec 23 16:44:38 2022: Train Epoch: 2 [6400 /50750 (13%)]	Loss: 0.148812 | F1-score: 0.98 | Elapsed: 7.36s
WARNING:root: [*] Fri Dec 23 16:44:45 2022: Train Epoch: 2 [12800/50750 (25%)]	Loss: 0.069723 | F1-score: 0.98 | Elapsed: 7.39s
WARNING:root: [*] Fri Dec 23 16:44:52 2022: Train Epoch: 2 [19200/50750 (38%)]	Loss: 0.061658 | F1-score: 0.98 | Elapsed: 7.37s
WARNING:root: [*] Fri Dec 23 16:45:00 2022: Train Epoch: 2 [25600/50750 (50%)]	Loss: 0.063044 | F1-score: 0.98 | Elapsed: 7.39s
WARNING:root: [*] Fri Dec 23 16:45:07 2022: Train Epoch: 2 [32000/50750 (63%)]	Loss: 0.082463 | F1-score: 0.98 | Elapsed: 7.36s
WARNING:root: [*] Fri Dec 23 16:45:14 2022: Train Epoch: 2 [38400/50750 (76%)]	Loss: 0.007393 | F1-score: 0.98 | Elapsed: 7.37s
WARNING:root: [*] Fri Dec 23 16:45:22 2022: Train Epoch: 2 [44800/50750 (88%)]	Loss: 0.040278 | F1-score: 0.98 | Elapsed: 7.40s
WARNING:root: [*] Fri Dec 23 16:45:29 2022:    2    | Tr.loss: 0.066064 | Tr.F1.:   0.98    |   58.54  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 16:45:29 2022: Train Epoch: 3 [  0  /50750 (0 %)]	Loss: 0.054987 | F1-score: 0.99 | Elapsed: 0.07s
WARNING:root: [*] Fri Dec 23 16:45:36 2022: Train Epoch: 3 [6400 /50750 (13%)]	Loss: 0.035392 | F1-score: 0.99 | Elapsed: 7.40s
WARNING:root: [*] Fri Dec 23 16:45:43 2022: Train Epoch: 3 [12800/50750 (25%)]	Loss: 0.081673 | F1-score: 0.99 | Elapsed: 7.40s
WARNING:root: [*] Fri Dec 23 16:45:51 2022: Train Epoch: 3 [19200/50750 (38%)]	Loss: 0.038654 | F1-score: 0.99 | Elapsed: 7.36s
WARNING:root: [*] Fri Dec 23 16:45:58 2022: Train Epoch: 3 [25600/50750 (50%)]	Loss: 0.067631 | F1-score: 0.99 | Elapsed: 7.35s
WARNING:root: [*] Fri Dec 23 16:46:05 2022: Train Epoch: 3 [32000/50750 (63%)]	Loss: 0.263621 | F1-score: 0.99 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 16:46:13 2022: Train Epoch: 3 [38400/50750 (76%)]	Loss: 0.108110 | F1-score: 0.99 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 16:46:20 2022: Train Epoch: 3 [44800/50750 (88%)]	Loss: 0.001668 | F1-score: 0.99 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 16:46:27 2022:    3    | Tr.loss: 0.056335 | Tr.F1.:   0.99    |   57.97  s
WARNING:root:
        [!] Fri Dec 23 16:46:27 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671810387-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671810387-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671810387-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671810387-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 16:46:36 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.660744 | F1-score: 0.82 | Elapsed: 0.08s
WARNING:root: [*] Fri Dec 23 16:46:43 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.262436 | F1-score: 0.87 | Elapsed: 7.26s
WARNING:root: [*] Fri Dec 23 16:46:50 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.138586 | F1-score: 0.91 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 16:46:57 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.113132 | F1-score: 0.93 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 16:47:05 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.076328 | F1-score: 0.94 | Elapsed: 7.26s
WARNING:root: [*] Fri Dec 23 16:47:12 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.146884 | F1-score: 0.95 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 16:47:19 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.130479 | F1-score: 0.95 | Elapsed: 7.26s
WARNING:root: [*] Fri Dec 23 16:47:26 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.079944 | F1-score: 0.96 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 16:47:33 2022:    1    | Tr.loss: 0.147052 | Tr.F1.:   0.96    |   57.49  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 16:47:33 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.068168 | F1-score: 0.98 | Elapsed: 0.08s
WARNING:root: [*] Fri Dec 23 16:47:40 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.059182 | F1-score: 0.98 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 16:47:48 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.072599 | F1-score: 0.98 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 16:47:55 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.044107 | F1-score: 0.98 | Elapsed: 7.26s
WARNING:root: [*] Fri Dec 23 16:48:02 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.051809 | F1-score: 0.98 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 16:48:09 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.042484 | F1-score: 0.98 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 16:48:16 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.057081 | F1-score: 0.98 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 16:48:24 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.041215 | F1-score: 0.98 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 16:48:30 2022:    2    | Tr.loss: 0.072342 | Tr.F1.:   0.98    |   57.45  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 16:48:30 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.030826 | F1-score: 0.99 | Elapsed: 0.07s
WARNING:root: [*] Fri Dec 23 16:48:38 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.080629 | F1-score: 0.98 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 16:48:45 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.061838 | F1-score: 0.98 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 16:48:52 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.025416 | F1-score: 0.99 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 16:48:59 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.095928 | F1-score: 0.99 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 16:49:07 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.018641 | F1-score: 0.99 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 16:49:14 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.025110 | F1-score: 0.99 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 16:49:21 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.147019 | F1-score: 0.98 | Elapsed: 7.22s
WARNING:root: [*] Fri Dec 23 16:49:28 2022:    3    | Tr.loss: 0.058246 | Tr.F1.:   0.98    |   57.40  s
WARNING:root:
        [!] Fri Dec 23 16:49:28 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671810568-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671810568-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671810568-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671810568-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 16:49:37 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.712021 | F1-score: 0.24 | Elapsed: 0.10s
WARNING:root: [*] Fri Dec 23 16:49:44 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.197355 | F1-score: 0.86 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 16:49:51 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.223636 | F1-score: 0.91 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 16:49:59 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.039805 | F1-score: 0.92 | Elapsed: 7.26s
WARNING:root: [*] Fri Dec 23 16:50:06 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.166227 | F1-score: 0.94 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 16:50:13 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.262329 | F1-score: 0.94 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 16:50:20 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.039885 | F1-score: 0.95 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 16:50:27 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.127438 | F1-score: 0.95 | Elapsed: 7.27s
WARNING:root: [*] Fri Dec 23 16:50:34 2022:    1    | Tr.loss: 0.155338 | Tr.F1.:   0.96    |   57.48  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 16:50:34 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.102613 | F1-score: 0.95 | Elapsed: 0.09s
WARNING:root: [*] Fri Dec 23 16:50:41 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.100817 | F1-score: 0.98 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 16:50:49 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.042687 | F1-score: 0.98 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 16:50:56 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.146842 | F1-score: 0.98 | Elapsed: 7.22s
WARNING:root: [*] Fri Dec 23 16:51:03 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.022877 | F1-score: 0.98 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 16:51:10 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.019210 | F1-score: 0.98 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 16:51:18 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.006000 | F1-score: 0.98 | Elapsed: 7.26s
WARNING:root: [*] Fri Dec 23 16:51:25 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.054170 | F1-score: 0.98 | Elapsed: 7.26s
WARNING:root: [*] Fri Dec 23 16:51:32 2022:    2    | Tr.loss: 0.065699 | Tr.F1.:   0.98    |   57.46  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 16:51:32 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.108777 | F1-score: 0.98 | Elapsed: 0.08s
WARNING:root: [*] Fri Dec 23 16:51:39 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.034179 | F1-score: 0.98 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 16:51:46 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.039689 | F1-score: 0.98 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 16:51:53 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.030258 | F1-score: 0.98 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 16:52:01 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.052164 | F1-score: 0.98 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 16:52:08 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.033294 | F1-score: 0.98 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 16:52:15 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.049635 | F1-score: 0.99 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 16:52:22 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.038162 | F1-score: 0.99 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 16:52:29 2022:    3    | Tr.loss: 0.054268 | Tr.F1.:   0.99    |   57.40  s
WARNING:root:
        [!] Fri Dec 23 16:52:29 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671810749-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671810749-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671810749-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671810749-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\metrics_trainSize_76126_ep_3_cv_3_maxLen_2048_vocabSize_10000_embeddingDim_64_hiddenNeurons_512_256_128_batchNormConv_False_batchNormFFNN_False_filterSizes_2_3_4_5.json
WARNING:root: [!] Average epoch time: 57.73s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.7248 -- F1: 0.8371
	FPR:  0.001 -- TPR: 0.9411 -- F1: 0.9694
	FPR:   0.01 -- TPR: 0.9746 -- F1: 0.9849
	FPR:    0.1 -- TPR: 0.9962 -- F1: 0.9747

WARNING:root: [!] Using vocabSize: 10000 | maxLen: 4096
WARNING:root: [!] Using device: cuda:0 | Dataset size: 76126
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 10000, 'embeddingDim': 64, 'hiddenNeurons': [512, 256, 128], 'batchNormConv': False, 'batchNormFFNN': False, 'filterSizes': [2, 3, 4, 5]}
WARNING:root: [!] Fold 1/3 | Train set size: 50750, Validation set size: 25376
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 16:53:09 2022: Train Epoch: 1 [  0  /50750 (0 %)]	Loss: 0.697236 | F1-score: 0.63 | Elapsed: 0.43s
WARNING:root: [*] Fri Dec 23 16:53:23 2022: Train Epoch: 1 [6400 /50750 (13%)]	Loss: 0.134167 | F1-score: 0.88 | Elapsed: 14.17s
WARNING:root: [*] Fri Dec 23 16:53:38 2022: Train Epoch: 1 [12800/50750 (25%)]	Loss: 0.296782 | F1-score: 0.91 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 16:53:52 2022: Train Epoch: 1 [19200/50750 (38%)]	Loss: 0.070632 | F1-score: 0.93 | Elapsed: 14.19s
WARNING:root: [*] Fri Dec 23 16:54:06 2022: Train Epoch: 1 [25600/50750 (50%)]	Loss: 0.111047 | F1-score: 0.94 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 16:54:20 2022: Train Epoch: 1 [32000/50750 (63%)]	Loss: 0.444922 | F1-score: 0.95 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 16:54:34 2022: Train Epoch: 1 [38400/50750 (76%)]	Loss: 0.060649 | F1-score: 0.95 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 16:54:49 2022: Train Epoch: 1 [44800/50750 (88%)]	Loss: 0.093137 | F1-score: 0.96 | Elapsed: 14.24s
WARNING:root: [*] Fri Dec 23 16:55:02 2022:    1    | Tr.loss: 0.147549 | Tr.F1.:   0.96    |  112.97  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 16:55:02 2022: Train Epoch: 2 [  0  /50750 (0 %)]	Loss: 0.072495 | F1-score: 0.97 | Elapsed: 0.15s
WARNING:root: [*] Fri Dec 23 16:55:16 2022: Train Epoch: 2 [6400 /50750 (13%)]	Loss: 0.108588 | F1-score: 0.98 | Elapsed: 14.28s
WARNING:root: [*] Fri Dec 23 16:55:30 2022: Train Epoch: 2 [12800/50750 (25%)]	Loss: 0.021994 | F1-score: 0.98 | Elapsed: 14.28s
WARNING:root: [*] Fri Dec 23 16:55:45 2022: Train Epoch: 2 [19200/50750 (38%)]	Loss: 0.042303 | F1-score: 0.98 | Elapsed: 14.29s
WARNING:root: [*] Fri Dec 23 16:55:59 2022: Train Epoch: 2 [25600/50750 (50%)]	Loss: 0.064068 | F1-score: 0.98 | Elapsed: 14.27s
WARNING:root: [*] Fri Dec 23 16:56:13 2022: Train Epoch: 2 [32000/50750 (63%)]	Loss: 0.062951 | F1-score: 0.98 | Elapsed: 14.27s
WARNING:root: [*] Fri Dec 23 16:56:28 2022: Train Epoch: 2 [38400/50750 (76%)]	Loss: 0.032189 | F1-score: 0.98 | Elapsed: 14.35s
WARNING:root: [*] Fri Dec 23 16:56:42 2022: Train Epoch: 2 [44800/50750 (88%)]	Loss: 0.037318 | F1-score: 0.98 | Elapsed: 14.35s
WARNING:root: [*] Fri Dec 23 16:56:55 2022:    2    | Tr.loss: 0.065760 | Tr.F1.:   0.98    |  113.41  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 16:56:55 2022: Train Epoch: 3 [  0  /50750 (0 %)]	Loss: 0.010092 | F1-score: 1.00 | Elapsed: 0.14s
WARNING:root: [*] Fri Dec 23 16:57:10 2022: Train Epoch: 3 [6400 /50750 (13%)]	Loss: 0.071117 | F1-score: 0.99 | Elapsed: 14.33s
WARNING:root: [*] Fri Dec 23 16:57:24 2022: Train Epoch: 3 [12800/50750 (25%)]	Loss: 0.030251 | F1-score: 0.99 | Elapsed: 14.30s
WARNING:root: [*] Fri Dec 23 16:57:38 2022: Train Epoch: 3 [19200/50750 (38%)]	Loss: 0.052166 | F1-score: 0.99 | Elapsed: 14.31s
WARNING:root: [*] Fri Dec 23 16:57:53 2022: Train Epoch: 3 [25600/50750 (50%)]	Loss: 0.076744 | F1-score: 0.99 | Elapsed: 14.30s
WARNING:root: [*] Fri Dec 23 16:58:07 2022: Train Epoch: 3 [32000/50750 (63%)]	Loss: 0.008832 | F1-score: 0.99 | Elapsed: 14.30s
WARNING:root: [*] Fri Dec 23 16:58:21 2022: Train Epoch: 3 [38400/50750 (76%)]	Loss: 0.005627 | F1-score: 0.99 | Elapsed: 14.31s
WARNING:root: [*] Fri Dec 23 16:58:36 2022: Train Epoch: 3 [44800/50750 (88%)]	Loss: 0.208651 | F1-score: 0.99 | Elapsed: 14.32s
WARNING:root: [*] Fri Dec 23 16:58:49 2022:    3    | Tr.loss: 0.054035 | Tr.F1.:   0.99    |  113.48  s
WARNING:root:
        [!] Fri Dec 23 16:58:49 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671811129-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671811129-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671811129-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671811129-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 16:59:06 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.661817 | F1-score: 0.80 | Elapsed: 0.19s
WARNING:root: [*] Fri Dec 23 16:59:21 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.417057 | F1-score: 0.87 | Elapsed: 14.30s
WARNING:root: [*] Fri Dec 23 16:59:35 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.188328 | F1-score: 0.91 | Elapsed: 14.33s
WARNING:root: [*] Fri Dec 23 16:59:49 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.234631 | F1-score: 0.93 | Elapsed: 14.33s
WARNING:root: [*] Fri Dec 23 17:00:04 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.150577 | F1-score: 0.94 | Elapsed: 14.33s
WARNING:root: [*] Fri Dec 23 17:00:18 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.080938 | F1-score: 0.95 | Elapsed: 14.31s
WARNING:root: [*] Fri Dec 23 17:00:32 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.205876 | F1-score: 0.95 | Elapsed: 14.32s
WARNING:root: [*] Fri Dec 23 17:00:47 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.050151 | F1-score: 0.96 | Elapsed: 14.31s
WARNING:root: [*] Fri Dec 23 17:01:00 2022:    1    | Tr.loss: 0.150708 | Tr.F1.:   0.96    |  113.61  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 17:01:00 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.032404 | F1-score: 1.00 | Elapsed: 0.16s
WARNING:root: [*] Fri Dec 23 17:01:14 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.079487 | F1-score: 0.98 | Elapsed: 14.32s
WARNING:root: [*] Fri Dec 23 17:01:29 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.022578 | F1-score: 0.98 | Elapsed: 14.31s
WARNING:root: [*] Fri Dec 23 17:01:43 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.090090 | F1-score: 0.98 | Elapsed: 14.32s
WARNING:root: [*] Fri Dec 23 17:01:57 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.051176 | F1-score: 0.98 | Elapsed: 14.31s
WARNING:root: [*] Fri Dec 23 17:02:12 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.016480 | F1-score: 0.98 | Elapsed: 14.30s
WARNING:root: [*] Fri Dec 23 17:02:26 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.023161 | F1-score: 0.98 | Elapsed: 14.30s
WARNING:root: [*] Fri Dec 23 17:02:40 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.054628 | F1-score: 0.98 | Elapsed: 14.31s
WARNING:root: [*] Fri Dec 23 17:02:53 2022:    2    | Tr.loss: 0.068909 | Tr.F1.:   0.98    |  113.51  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 17:02:54 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.074203 | F1-score: 0.99 | Elapsed: 0.15s
WARNING:root: [*] Fri Dec 23 17:03:08 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.108368 | F1-score: 0.99 | Elapsed: 14.31s
WARNING:root: [*] Fri Dec 23 17:03:22 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.038746 | F1-score: 0.99 | Elapsed: 14.30s
WARNING:root: [*] Fri Dec 23 17:03:36 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.067176 | F1-score: 0.99 | Elapsed: 14.29s
WARNING:root: [*] Fri Dec 23 17:03:51 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.063593 | F1-score: 0.99 | Elapsed: 14.31s
WARNING:root: [*] Fri Dec 23 17:04:05 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.046707 | F1-score: 0.99 | Elapsed: 14.29s
WARNING:root: [*] Fri Dec 23 17:04:19 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.012234 | F1-score: 0.99 | Elapsed: 14.31s
WARNING:root: [*] Fri Dec 23 17:04:34 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.083527 | F1-score: 0.99 | Elapsed: 14.31s
WARNING:root: [*] Fri Dec 23 17:04:47 2022:    3    | Tr.loss: 0.057336 | Tr.F1.:   0.99    |  113.43  s
WARNING:root:
        [!] Fri Dec 23 17:04:47 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671811487-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671811487-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671811487-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671811487-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 17:05:05 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.688680 | F1-score: 0.57 | Elapsed: 0.18s
WARNING:root: [*] Fri Dec 23 17:05:19 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.241058 | F1-score: 0.87 | Elapsed: 14.32s
WARNING:root: [*] Fri Dec 23 17:05:33 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.124322 | F1-score: 0.91 | Elapsed: 14.32s
WARNING:root: [*] Fri Dec 23 17:05:48 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.043192 | F1-score: 0.93 | Elapsed: 14.31s
WARNING:root: [*] Fri Dec 23 17:06:02 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.106062 | F1-score: 0.94 | Elapsed: 14.31s
WARNING:root: [*] Fri Dec 23 17:06:16 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.162112 | F1-score: 0.95 | Elapsed: 14.32s
WARNING:root: [*] Fri Dec 23 17:06:31 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.037113 | F1-score: 0.95 | Elapsed: 14.30s
WARNING:root: [*] Fri Dec 23 17:06:45 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.141423 | F1-score: 0.96 | Elapsed: 14.32s
WARNING:root: [*] Fri Dec 23 17:06:58 2022:    1    | Tr.loss: 0.147591 | Tr.F1.:   0.96    |  113.55  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 17:06:58 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.165131 | F1-score: 0.96 | Elapsed: 0.15s
WARNING:root: [*] Fri Dec 23 17:07:12 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.152859 | F1-score: 0.98 | Elapsed: 14.32s
WARNING:root: [*] Fri Dec 23 17:07:27 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.061692 | F1-score: 0.98 | Elapsed: 14.32s
WARNING:root: [*] Fri Dec 23 17:07:41 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.091940 | F1-score: 0.98 | Elapsed: 14.31s
WARNING:root: [*] Fri Dec 23 17:07:55 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.025053 | F1-score: 0.98 | Elapsed: 14.29s
WARNING:root: [*] Fri Dec 23 17:08:10 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.047912 | F1-score: 0.98 | Elapsed: 14.32s
WARNING:root: [*] Fri Dec 23 17:08:24 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.109132 | F1-score: 0.98 | Elapsed: 14.31s
WARNING:root: [*] Fri Dec 23 17:08:38 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.016089 | F1-score: 0.98 | Elapsed: 14.31s
WARNING:root: [*] Fri Dec 23 17:08:52 2022:    2    | Tr.loss: 0.066785 | Tr.F1.:   0.98    |  113.50  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 17:08:52 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.044314 | F1-score: 0.99 | Elapsed: 0.14s
WARNING:root: [*] Fri Dec 23 17:09:06 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.011666 | F1-score: 0.99 | Elapsed: 14.33s
WARNING:root: [*] Fri Dec 23 17:09:20 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.021128 | F1-score: 0.99 | Elapsed: 14.37s
WARNING:root: [*] Fri Dec 23 17:09:35 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.063560 | F1-score: 0.99 | Elapsed: 14.39s
WARNING:root: [*] Fri Dec 23 17:09:49 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.067545 | F1-score: 0.99 | Elapsed: 14.39s
WARNING:root: [*] Fri Dec 23 17:10:04 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.060565 | F1-score: 0.99 | Elapsed: 14.44s
WARNING:root: [*] Fri Dec 23 17:10:18 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.042447 | F1-score: 0.99 | Elapsed: 14.38s
WARNING:root: [*] Fri Dec 23 17:10:32 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.112379 | F1-score: 0.99 | Elapsed: 14.40s
WARNING:root: [*] Fri Dec 23 17:10:46 2022:    3    | Tr.loss: 0.052507 | Tr.F1.:   0.99    |  114.09  s
WARNING:root:
        [!] Fri Dec 23 17:10:46 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671811846-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671811846-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671811846-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671811846-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\metrics_trainSize_76126_ep_3_cv_3_maxLen_4096_vocabSize_10000_embeddingDim_64_hiddenNeurons_512_256_128_batchNormConv_False_batchNormFFNN_False_filterSizes_2_3_4_5.json
WARNING:root: [!] Average epoch time: 113.50s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.6255 -- F1: 0.7623
	FPR:  0.001 -- TPR: 0.9198 -- F1: 0.9579
	FPR:   0.01 -- TPR: 0.9736 -- F1: 0.9845
	FPR:    0.1 -- TPR: 0.9963 -- F1: 0.9748

WARNING:root: [!] Using vocabSize: 10000 | maxLen: 512
WARNING:root: [!] Using device: cuda:0 | Dataset size: 76126
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 10000, 'embeddingDim': 64, 'hiddenNeurons': [512, 256, 128], 'batchNormConv': False, 'batchNormFFNN': False, 'filterSizes': [2, 3, 4, 5]}
WARNING:root: [!] Fold 1/3 | Train set size: 50750, Validation set size: 25376
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 17:11:33 2022: Train Epoch: 1 [  0  /50750 (0 %)]	Loss: 0.725085 | F1-score: 0.24 | Elapsed: 0.17s
WARNING:root: [*] Fri Dec 23 17:11:35 2022: Train Epoch: 1 [6400 /50750 (13%)]	Loss: 0.241201 | F1-score: 0.88 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 17:11:38 2022: Train Epoch: 1 [12800/50750 (25%)]	Loss: 0.114907 | F1-score: 0.92 | Elapsed: 2.48s
WARNING:root: [*] Fri Dec 23 17:11:40 2022: Train Epoch: 1 [19200/50750 (38%)]	Loss: 0.147507 | F1-score: 0.93 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 17:11:42 2022: Train Epoch: 1 [25600/50750 (50%)]	Loss: 0.144713 | F1-score: 0.94 | Elapsed: 2.35s
WARNING:root: [*] Fri Dec 23 17:11:45 2022: Train Epoch: 1 [32000/50750 (63%)]	Loss: 0.098838 | F1-score: 0.95 | Elapsed: 2.36s
WARNING:root: [*] Fri Dec 23 17:11:47 2022: Train Epoch: 1 [38400/50750 (76%)]	Loss: 0.118534 | F1-score: 0.95 | Elapsed: 2.32s
WARNING:root: [*] Fri Dec 23 17:11:49 2022: Train Epoch: 1 [44800/50750 (88%)]	Loss: 0.143068 | F1-score: 0.95 | Elapsed: 2.33s
WARNING:root: [*] Fri Dec 23 17:11:52 2022:    1    | Tr.loss: 0.155892 | Tr.F1.:   0.95    |   18.70  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 17:11:52 2022: Train Epoch: 2 [  0  /50750 (0 %)]	Loss: 0.085153 | F1-score: 0.98 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 17:11:54 2022: Train Epoch: 2 [6400 /50750 (13%)]	Loss: 0.020695 | F1-score: 0.98 | Elapsed: 2.34s
WARNING:root: [*] Fri Dec 23 17:11:56 2022: Train Epoch: 2 [12800/50750 (25%)]	Loss: 0.187186 | F1-score: 0.97 | Elapsed: 2.35s
WARNING:root: [*] Fri Dec 23 17:11:59 2022: Train Epoch: 2 [19200/50750 (38%)]	Loss: 0.121327 | F1-score: 0.98 | Elapsed: 2.30s
WARNING:root: [*] Fri Dec 23 17:12:01 2022: Train Epoch: 2 [25600/50750 (50%)]	Loss: 0.266685 | F1-score: 0.98 | Elapsed: 2.32s
WARNING:root: [*] Fri Dec 23 17:12:03 2022: Train Epoch: 2 [32000/50750 (63%)]	Loss: 0.094329 | F1-score: 0.98 | Elapsed: 2.34s
WARNING:root: [*] Fri Dec 23 17:12:06 2022: Train Epoch: 2 [38400/50750 (76%)]	Loss: 0.024746 | F1-score: 0.98 | Elapsed: 2.44s
WARNING:root: [*] Fri Dec 23 17:12:08 2022: Train Epoch: 2 [44800/50750 (88%)]	Loss: 0.110415 | F1-score: 0.98 | Elapsed: 2.38s
WARNING:root: [*] Fri Dec 23 17:12:10 2022:    2    | Tr.loss: 0.079128 | Tr.F1.:   0.98    |   18.67  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 17:12:10 2022: Train Epoch: 3 [  0  /50750 (0 %)]	Loss: 0.068106 | F1-score: 0.98 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 17:12:13 2022: Train Epoch: 3 [6400 /50750 (13%)]	Loss: 0.023183 | F1-score: 0.98 | Elapsed: 2.36s
WARNING:root: [*] Fri Dec 23 17:12:15 2022: Train Epoch: 3 [12800/50750 (25%)]	Loss: 0.054763 | F1-score: 0.98 | Elapsed: 2.34s
WARNING:root: [*] Fri Dec 23 17:12:17 2022: Train Epoch: 3 [19200/50750 (38%)]	Loss: 0.039534 | F1-score: 0.98 | Elapsed: 2.34s
WARNING:root: [*] Fri Dec 23 17:12:20 2022: Train Epoch: 3 [25600/50750 (50%)]	Loss: 0.024209 | F1-score: 0.98 | Elapsed: 2.36s
WARNING:root: [*] Fri Dec 23 17:12:22 2022: Train Epoch: 3 [32000/50750 (63%)]	Loss: 0.050436 | F1-score: 0.98 | Elapsed: 2.34s
WARNING:root: [*] Fri Dec 23 17:12:24 2022: Train Epoch: 3 [38400/50750 (76%)]	Loss: 0.197727 | F1-score: 0.98 | Elapsed: 2.31s
WARNING:root: [*] Fri Dec 23 17:12:27 2022: Train Epoch: 3 [44800/50750 (88%)]	Loss: 0.043200 | F1-score: 0.98 | Elapsed: 2.30s
WARNING:root: [*] Fri Dec 23 17:12:29 2022:    3    | Tr.loss: 0.064960 | Tr.F1.:   0.98    |   18.50  s
WARNING:root:
        [!] Fri Dec 23 17:12:29 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671811949-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671811949-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671811949-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671811949-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 17:12:31 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.701106 | F1-score: 0.43 | Elapsed: 0.02s
WARNING:root: [*] Fri Dec 23 17:12:34 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.094909 | F1-score: 0.87 | Elapsed: 2.32s
WARNING:root: [*] Fri Dec 23 17:12:36 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.149394 | F1-score: 0.91 | Elapsed: 2.26s
WARNING:root: [*] Fri Dec 23 17:12:38 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.066949 | F1-score: 0.93 | Elapsed: 2.28s
WARNING:root: [*] Fri Dec 23 17:12:40 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.122635 | F1-score: 0.94 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 17:12:43 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.056760 | F1-score: 0.95 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 17:12:45 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.112091 | F1-score: 0.95 | Elapsed: 2.28s
WARNING:root: [*] Fri Dec 23 17:12:47 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.101053 | F1-score: 0.95 | Elapsed: 2.29s
WARNING:root: [*] Fri Dec 23 17:12:49 2022:    1    | Tr.loss: 0.157625 | Tr.F1.:   0.95    |   18.07  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 17:12:49 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.074020 | F1-score: 0.98 | Elapsed: 0.02s
WARNING:root: [*] Fri Dec 23 17:12:52 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.093151 | F1-score: 0.98 | Elapsed: 2.29s
WARNING:root: [*] Fri Dec 23 17:12:54 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.058606 | F1-score: 0.98 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 17:12:56 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.041348 | F1-score: 0.98 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 17:12:58 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.057422 | F1-score: 0.98 | Elapsed: 2.29s
WARNING:root: [*] Fri Dec 23 17:13:01 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.098041 | F1-score: 0.98 | Elapsed: 2.28s
WARNING:root: [*] Fri Dec 23 17:13:03 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.065518 | F1-score: 0.98 | Elapsed: 2.29s
WARNING:root: [*] Fri Dec 23 17:13:05 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.009200 | F1-score: 0.98 | Elapsed: 2.29s
WARNING:root: [*] Fri Dec 23 17:13:07 2022:    2    | Tr.loss: 0.078701 | Tr.F1.:   0.98    |   18.10  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 17:13:07 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.132752 | F1-score: 0.96 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 17:13:10 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.065823 | F1-score: 0.98 | Elapsed: 2.30s
WARNING:root: [*] Fri Dec 23 17:13:12 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.135454 | F1-score: 0.98 | Elapsed: 2.28s
WARNING:root: [*] Fri Dec 23 17:13:14 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.010893 | F1-score: 0.98 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 17:13:17 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.177038 | F1-score: 0.98 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 17:13:19 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.034688 | F1-score: 0.98 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 17:13:21 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.055765 | F1-score: 0.98 | Elapsed: 2.28s
WARNING:root: [*] Fri Dec 23 17:13:23 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.017498 | F1-score: 0.98 | Elapsed: 2.28s
WARNING:root: [*] Fri Dec 23 17:13:25 2022:    3    | Tr.loss: 0.062211 | Tr.F1.:   0.98    |   18.07  s
WARNING:root:
        [!] Fri Dec 23 17:13:25 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671812005-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671812005-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671812005-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671812005-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 17:13:28 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.703477 | F1-score: 0.48 | Elapsed: 0.02s
WARNING:root: [*] Fri Dec 23 17:13:30 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.262717 | F1-score: 0.88 | Elapsed: 2.32s
WARNING:root: [*] Fri Dec 23 17:13:32 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.271400 | F1-score: 0.92 | Elapsed: 2.30s
WARNING:root: [*] Fri Dec 23 17:13:35 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.074362 | F1-score: 0.93 | Elapsed: 2.32s
WARNING:root: [*] Fri Dec 23 17:13:37 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.140533 | F1-score: 0.94 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 17:13:39 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.079016 | F1-score: 0.95 | Elapsed: 2.30s
WARNING:root: [*] Fri Dec 23 17:13:42 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.032878 | F1-score: 0.95 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 17:13:44 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.048899 | F1-score: 0.95 | Elapsed: 2.29s
WARNING:root: [*] Fri Dec 23 17:13:46 2022:    1    | Tr.loss: 0.154275 | Tr.F1.:   0.96    |   18.19  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 17:13:46 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.061596 | F1-score: 0.99 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 17:13:48 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.030393 | F1-score: 0.98 | Elapsed: 2.28s
WARNING:root: [*] Fri Dec 23 17:13:51 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.151455 | F1-score: 0.98 | Elapsed: 2.30s
WARNING:root: [*] Fri Dec 23 17:13:53 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.033804 | F1-score: 0.98 | Elapsed: 2.29s
WARNING:root: [*] Fri Dec 23 17:13:55 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.044192 | F1-score: 0.98 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 17:13:58 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.047968 | F1-score: 0.98 | Elapsed: 2.28s
WARNING:root: [*] Fri Dec 23 17:14:00 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.035125 | F1-score: 0.98 | Elapsed: 2.29s
WARNING:root: [*] Fri Dec 23 17:14:02 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.081001 | F1-score: 0.98 | Elapsed: 2.28s
WARNING:root: [*] Fri Dec 23 17:14:04 2022:    2    | Tr.loss: 0.079290 | Tr.F1.:   0.98    |   18.15  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 17:14:04 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.233014 | F1-score: 0.97 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 17:14:07 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.080480 | F1-score: 0.98 | Elapsed: 2.29s
WARNING:root: [*] Fri Dec 23 17:14:09 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.138788 | F1-score: 0.98 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 17:14:11 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.055762 | F1-score: 0.98 | Elapsed: 2.28s
WARNING:root: [*] Fri Dec 23 17:14:13 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.053068 | F1-score: 0.98 | Elapsed: 2.30s
WARNING:root: [*] Fri Dec 23 17:14:16 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.072947 | F1-score: 0.98 | Elapsed: 2.28s
WARNING:root: [*] Fri Dec 23 17:14:18 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.036484 | F1-score: 0.98 | Elapsed: 2.28s
WARNING:root: [*] Fri Dec 23 17:14:20 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.060288 | F1-score: 0.98 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 17:14:22 2022:    3    | Tr.loss: 0.063638 | Tr.F1.:   0.98    |   18.15  s
WARNING:root:
        [!] Fri Dec 23 17:14:22 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671812062-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671812062-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671812062-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671812062-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\metrics_trainSize_76126_ep_3_cv_3_maxLen_512_vocabSize_10000_embeddingDim_64_hiddenNeurons_512_256_128_batchNormConv_False_batchNormFFNN_False_filterSizes_2_3_4_5.json
WARNING:root: [!] Average epoch time: 18.29s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.6780 -- F1: 0.8005
	FPR:  0.001 -- TPR: 0.9114 -- F1: 0.9534
	FPR:   0.01 -- TPR: 0.9717 -- F1: 0.9833
	FPR:    0.1 -- TPR: 0.9940 -- F1: 0.9736

WARNING:root: [!] Using vocabSize: 1000 | maxLen: 1024
WARNING:root: [!] Using device: cuda:0 | Dataset size: 76126
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 1000, 'embeddingDim': 64, 'hiddenNeurons': [512, 256, 128], 'batchNormConv': False, 'batchNormFFNN': False, 'filterSizes': [2, 3, 4, 5]}
WARNING:root: [!] Fold 1/3 | Train set size: 50750, Validation set size: 25376
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 17:14:55 2022: Train Epoch: 1 [  0  /50750 (0 %)]	Loss: 0.689173 | F1-score: 0.61 | Elapsed: 0.31s
WARNING:root: [*] Fri Dec 23 17:14:59 2022: Train Epoch: 1 [6400 /50750 (13%)]	Loss: 0.194266 | F1-score: 0.87 | Elapsed: 3.89s
WARNING:root: [*] Fri Dec 23 17:15:03 2022: Train Epoch: 1 [12800/50750 (25%)]	Loss: 0.133164 | F1-score: 0.90 | Elapsed: 3.83s
WARNING:root: [*] Fri Dec 23 17:15:07 2022: Train Epoch: 1 [19200/50750 (38%)]	Loss: 0.198097 | F1-score: 0.92 | Elapsed: 3.83s
WARNING:root: [*] Fri Dec 23 17:15:11 2022: Train Epoch: 1 [25600/50750 (50%)]	Loss: 0.145831 | F1-score: 0.93 | Elapsed: 3.85s
WARNING:root: [*] Fri Dec 23 17:15:15 2022: Train Epoch: 1 [32000/50750 (63%)]	Loss: 0.266151 | F1-score: 0.93 | Elapsed: 3.86s
WARNING:root: [*] Fri Dec 23 17:15:18 2022: Train Epoch: 1 [38400/50750 (76%)]	Loss: 0.086044 | F1-score: 0.94 | Elapsed: 3.87s
WARNING:root: [*] Fri Dec 23 17:15:22 2022: Train Epoch: 1 [44800/50750 (88%)]	Loss: 0.114308 | F1-score: 0.94 | Elapsed: 3.91s
WARNING:root: [*] Fri Dec 23 17:15:26 2022:    1    | Tr.loss: 0.199709 | Tr.F1.:   0.94    |   30.93  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 17:15:26 2022: Train Epoch: 2 [  0  /50750 (0 %)]	Loss: 0.134707 | F1-score: 0.97 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 17:15:30 2022: Train Epoch: 2 [6400 /50750 (13%)]	Loss: 0.049361 | F1-score: 0.96 | Elapsed: 3.91s
WARNING:root: [*] Fri Dec 23 17:15:34 2022: Train Epoch: 2 [12800/50750 (25%)]	Loss: 0.149382 | F1-score: 0.96 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 17:15:38 2022: Train Epoch: 2 [19200/50750 (38%)]	Loss: 0.141408 | F1-score: 0.96 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 17:15:42 2022: Train Epoch: 2 [25600/50750 (50%)]	Loss: 0.101704 | F1-score: 0.96 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 17:15:45 2022: Train Epoch: 2 [32000/50750 (63%)]	Loss: 0.087552 | F1-score: 0.96 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 17:15:49 2022: Train Epoch: 2 [38400/50750 (76%)]	Loss: 0.111090 | F1-score: 0.96 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 17:15:53 2022: Train Epoch: 2 [44800/50750 (88%)]	Loss: 0.078694 | F1-score: 0.96 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 17:15:57 2022:    2    | Tr.loss: 0.112293 | Tr.F1.:   0.96    |   30.92  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 17:15:57 2022: Train Epoch: 3 [  0  /50750 (0 %)]	Loss: 0.090517 | F1-score: 0.98 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 17:16:01 2022: Train Epoch: 3 [6400 /50750 (13%)]	Loss: 0.083267 | F1-score: 0.97 | Elapsed: 3.92s
WARNING:root: [*] Fri Dec 23 17:16:05 2022: Train Epoch: 3 [12800/50750 (25%)]	Loss: 0.101657 | F1-score: 0.97 | Elapsed: 3.91s
WARNING:root: [*] Fri Dec 23 17:16:09 2022: Train Epoch: 3 [19200/50750 (38%)]	Loss: 0.039682 | F1-score: 0.97 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 17:16:13 2022: Train Epoch: 3 [25600/50750 (50%)]	Loss: 0.068242 | F1-score: 0.97 | Elapsed: 3.92s
WARNING:root: [*] Fri Dec 23 17:16:16 2022: Train Epoch: 3 [32000/50750 (63%)]	Loss: 0.046683 | F1-score: 0.97 | Elapsed: 3.89s
WARNING:root: [*] Fri Dec 23 17:16:20 2022: Train Epoch: 3 [38400/50750 (76%)]	Loss: 0.122849 | F1-score: 0.97 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 17:16:24 2022: Train Epoch: 3 [44800/50750 (88%)]	Loss: 0.165440 | F1-score: 0.97 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 17:16:28 2022:    3    | Tr.loss: 0.098356 | Tr.F1.:   0.97    |   30.97  s
WARNING:root:
        [!] Fri Dec 23 17:16:28 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671812188-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671812188-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671812188-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671812188-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 17:16:32 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.682470 | F1-score: 0.64 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 17:16:36 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.281286 | F1-score: 0.87 | Elapsed: 3.94s
WARNING:root: [*] Fri Dec 23 17:16:40 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.163502 | F1-score: 0.90 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 17:16:44 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.174246 | F1-score: 0.92 | Elapsed: 3.92s
WARNING:root: [*] Fri Dec 23 17:16:48 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.118616 | F1-score: 0.93 | Elapsed: 3.91s
WARNING:root: [*] Fri Dec 23 17:16:52 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.080369 | F1-score: 0.93 | Elapsed: 3.91s
WARNING:root: [*] Fri Dec 23 17:16:56 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.311831 | F1-score: 0.94 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 17:17:00 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.219333 | F1-score: 0.94 | Elapsed: 3.94s
WARNING:root: [*] Fri Dec 23 17:17:04 2022:    1    | Tr.loss: 0.197552 | Tr.F1.:   0.94    |   31.07  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 17:17:04 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.117089 | F1-score: 0.96 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 17:17:07 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.076511 | F1-score: 0.96 | Elapsed: 3.93s
WARNING:root: [*] Fri Dec 23 17:17:11 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.080056 | F1-score: 0.96 | Elapsed: 3.91s
WARNING:root: [*] Fri Dec 23 17:17:15 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.227773 | F1-score: 0.96 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 17:17:19 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.117341 | F1-score: 0.96 | Elapsed: 3.94s
WARNING:root: [*] Fri Dec 23 17:17:23 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.089443 | F1-score: 0.96 | Elapsed: 3.91s
WARNING:root: [*] Fri Dec 23 17:17:27 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.167610 | F1-score: 0.96 | Elapsed: 3.91s
WARNING:root: [*] Fri Dec 23 17:17:31 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.093702 | F1-score: 0.96 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 17:17:35 2022:    2    | Tr.loss: 0.114422 | Tr.F1.:   0.96    |   31.07  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 17:17:35 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.072400 | F1-score: 0.98 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 17:17:39 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.185113 | F1-score: 0.97 | Elapsed: 3.95s
WARNING:root: [*] Fri Dec 23 17:17:42 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.074480 | F1-score: 0.97 | Elapsed: 3.92s
WARNING:root: [*] Fri Dec 23 17:17:46 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.072921 | F1-score: 0.97 | Elapsed: 3.91s
WARNING:root: [*] Fri Dec 23 17:17:50 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.113977 | F1-score: 0.97 | Elapsed: 3.91s
WARNING:root: [*] Fri Dec 23 17:17:54 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.131404 | F1-score: 0.97 | Elapsed: 3.93s
WARNING:root: [*] Fri Dec 23 17:17:58 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.099004 | F1-score: 0.97 | Elapsed: 3.92s
WARNING:root: [*] Fri Dec 23 17:18:02 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.163275 | F1-score: 0.97 | Elapsed: 3.94s
WARNING:root: [*] Fri Dec 23 17:18:06 2022:    3    | Tr.loss: 0.099571 | Tr.F1.:   0.97    |   31.14  s
WARNING:root:
        [!] Fri Dec 23 17:18:06 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671812286-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671812286-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671812286-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671812286-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 17:18:10 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.678656 | F1-score: 0.80 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 17:18:14 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.239065 | F1-score: 0.87 | Elapsed: 3.94s
WARNING:root: [*] Fri Dec 23 17:18:18 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.168825 | F1-score: 0.91 | Elapsed: 3.92s
WARNING:root: [*] Fri Dec 23 17:18:22 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.226121 | F1-score: 0.92 | Elapsed: 3.93s
WARNING:root: [*] Fri Dec 23 17:18:26 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.205652 | F1-score: 0.93 | Elapsed: 3.93s
WARNING:root: [*] Fri Dec 23 17:18:30 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.128341 | F1-score: 0.93 | Elapsed: 3.91s
WARNING:root: [*] Fri Dec 23 17:18:34 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.125371 | F1-score: 0.94 | Elapsed: 3.92s
WARNING:root: [*] Fri Dec 23 17:18:38 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.095470 | F1-score: 0.94 | Elapsed: 3.93s
WARNING:root: [*] Fri Dec 23 17:18:41 2022:    1    | Tr.loss: 0.195026 | Tr.F1.:   0.94    |   31.15  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 17:18:42 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.137072 | F1-score: 0.97 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 17:18:45 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.180120 | F1-score: 0.97 | Elapsed: 3.93s
WARNING:root: [*] Fri Dec 23 17:18:49 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.105565 | F1-score: 0.96 | Elapsed: 3.91s
WARNING:root: [*] Fri Dec 23 17:18:53 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.066916 | F1-score: 0.96 | Elapsed: 3.93s
WARNING:root: [*] Fri Dec 23 17:18:57 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.137058 | F1-score: 0.96 | Elapsed: 3.91s
WARNING:root: [*] Fri Dec 23 17:19:01 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.057484 | F1-score: 0.96 | Elapsed: 3.92s
WARNING:root: [*] Fri Dec 23 17:19:05 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.176424 | F1-score: 0.96 | Elapsed: 3.93s
WARNING:root: [*] Fri Dec 23 17:19:09 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.068925 | F1-score: 0.96 | Elapsed: 3.93s
WARNING:root: [*] Fri Dec 23 17:19:13 2022:    2    | Tr.loss: 0.114263 | Tr.F1.:   0.96    |   31.13  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 17:19:13 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.056729 | F1-score: 0.98 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 17:19:17 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.141169 | F1-score: 0.97 | Elapsed: 3.93s
WARNING:root: [*] Fri Dec 23 17:19:20 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.264206 | F1-score: 0.97 | Elapsed: 3.93s
WARNING:root: [*] Fri Dec 23 17:19:24 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.074913 | F1-score: 0.97 | Elapsed: 3.91s
WARNING:root: [*] Fri Dec 23 17:19:28 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.136200 | F1-score: 0.97 | Elapsed: 3.94s
WARNING:root: [*] Fri Dec 23 17:19:32 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.158531 | F1-score: 0.97 | Elapsed: 3.93s
WARNING:root: [*] Fri Dec 23 17:19:36 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.085050 | F1-score: 0.97 | Elapsed: 3.95s
WARNING:root: [*] Fri Dec 23 17:19:40 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.225107 | F1-score: 0.97 | Elapsed: 3.92s
WARNING:root: [*] Fri Dec 23 17:19:44 2022:    3    | Tr.loss: 0.099855 | Tr.F1.:   0.97    |   31.14  s
WARNING:root:
        [!] Fri Dec 23 17:19:44 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671812384-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671812384-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671812384-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671812384-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\metrics_trainSize_76126_ep_3_cv_3_maxLen_1024_vocabSize_1000_embeddingDim_64_hiddenNeurons_512_256_128_batchNormConv_False_batchNormFFNN_False_filterSizes_2_3_4_5.json
WARNING:root: [!] Average epoch time: 31.06s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.2962 -- F1: 0.4370
	FPR:  0.001 -- TPR: 0.8441 -- F1: 0.9150
	FPR:   0.01 -- TPR: 0.9338 -- F1: 0.9635
	FPR:    0.1 -- TPR: 0.9836 -- F1: 0.9688

WARNING:root: [!] Using vocabSize: 1000 | maxLen: 2048
WARNING:root: [!] Using device: cuda:0 | Dataset size: 76126
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 1000, 'embeddingDim': 64, 'hiddenNeurons': [512, 256, 128], 'batchNormConv': False, 'batchNormFFNN': False, 'filterSizes': [2, 3, 4, 5]}
WARNING:root: [!] Fold 1/3 | Train set size: 50750, Validation set size: 25376
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 17:20:19 2022: Train Epoch: 1 [  0  /50750 (0 %)]	Loss: 0.706344 | F1-score: 0.35 | Elapsed: 0.39s
WARNING:root: [*] Fri Dec 23 17:20:26 2022: Train Epoch: 1 [6400 /50750 (13%)]	Loss: 0.288845 | F1-score: 0.87 | Elapsed: 7.12s
WARNING:root: [*] Fri Dec 23 17:20:33 2022: Train Epoch: 1 [12800/50750 (25%)]	Loss: 0.261691 | F1-score: 0.90 | Elapsed: 7.09s
WARNING:root: [*] Fri Dec 23 17:20:41 2022: Train Epoch: 1 [19200/50750 (38%)]	Loss: 0.118049 | F1-score: 0.92 | Elapsed: 7.15s
WARNING:root: [*] Fri Dec 23 17:20:48 2022: Train Epoch: 1 [25600/50750 (50%)]	Loss: 0.260591 | F1-score: 0.93 | Elapsed: 7.15s
WARNING:root: [*] Fri Dec 23 17:20:55 2022: Train Epoch: 1 [32000/50750 (63%)]	Loss: 0.129108 | F1-score: 0.93 | Elapsed: 7.16s
WARNING:root: [*] Fri Dec 23 17:21:02 2022: Train Epoch: 1 [38400/50750 (76%)]	Loss: 0.041208 | F1-score: 0.94 | Elapsed: 7.18s
WARNING:root: [*] Fri Dec 23 17:21:09 2022: Train Epoch: 1 [44800/50750 (88%)]	Loss: 0.132378 | F1-score: 0.94 | Elapsed: 7.21s
WARNING:root: [*] Fri Dec 23 17:21:16 2022:    1    | Tr.loss: 0.191558 | Tr.F1.:   0.94    |   57.07  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 17:21:16 2022: Train Epoch: 2 [  0  /50750 (0 %)]	Loss: 0.047546 | F1-score: 0.99 | Elapsed: 0.07s
WARNING:root: [*] Fri Dec 23 17:21:23 2022: Train Epoch: 2 [6400 /50750 (13%)]	Loss: 0.076504 | F1-score: 0.97 | Elapsed: 7.19s
WARNING:root: [*] Fri Dec 23 17:21:30 2022: Train Epoch: 2 [12800/50750 (25%)]	Loss: 0.031605 | F1-score: 0.97 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 17:21:38 2022: Train Epoch: 2 [19200/50750 (38%)]	Loss: 0.060892 | F1-score: 0.97 | Elapsed: 7.22s
WARNING:root: [*] Fri Dec 23 17:21:45 2022: Train Epoch: 2 [25600/50750 (50%)]	Loss: 0.046141 | F1-score: 0.97 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 17:21:52 2022: Train Epoch: 2 [32000/50750 (63%)]	Loss: 0.069279 | F1-score: 0.97 | Elapsed: 7.22s
WARNING:root: [*] Fri Dec 23 17:21:59 2022: Train Epoch: 2 [38400/50750 (76%)]	Loss: 0.061974 | F1-score: 0.97 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 17:22:07 2022: Train Epoch: 2 [44800/50750 (88%)]	Loss: 0.113698 | F1-score: 0.97 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 17:22:13 2022:    2    | Tr.loss: 0.106337 | Tr.F1.:   0.97    |   57.29  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 17:22:13 2022: Train Epoch: 3 [  0  /50750 (0 %)]	Loss: 0.110895 | F1-score: 0.94 | Elapsed: 0.07s
WARNING:root: [*] Fri Dec 23 17:22:20 2022: Train Epoch: 3 [6400 /50750 (13%)]	Loss: 0.053993 | F1-score: 0.97 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 17:22:28 2022: Train Epoch: 3 [12800/50750 (25%)]	Loss: 0.090974 | F1-score: 0.97 | Elapsed: 7.22s
WARNING:root: [*] Fri Dec 23 17:22:35 2022: Train Epoch: 3 [19200/50750 (38%)]	Loss: 0.053665 | F1-score: 0.97 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 17:22:42 2022: Train Epoch: 3 [25600/50750 (50%)]	Loss: 0.053131 | F1-score: 0.97 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 17:22:49 2022: Train Epoch: 3 [32000/50750 (63%)]	Loss: 0.214836 | F1-score: 0.97 | Elapsed: 7.22s
WARNING:root: [*] Fri Dec 23 17:22:57 2022: Train Epoch: 3 [38400/50750 (76%)]	Loss: 0.040015 | F1-score: 0.97 | Elapsed: 7.21s
WARNING:root: [*] Fri Dec 23 17:23:04 2022: Train Epoch: 3 [44800/50750 (88%)]	Loss: 0.079864 | F1-score: 0.97 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 17:23:10 2022:    3    | Tr.loss: 0.089217 | Tr.F1.:   0.97    |   57.33  s
WARNING:root:
        [!] Fri Dec 23 17:23:10 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671812590-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671812590-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671812590-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671812590-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 17:23:19 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.693191 | F1-score: 0.54 | Elapsed: 0.08s
WARNING:root: [*] Fri Dec 23 17:23:27 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.267372 | F1-score: 0.86 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 17:23:34 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.163846 | F1-score: 0.90 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 17:23:41 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.067568 | F1-score: 0.92 | Elapsed: 7.26s
WARNING:root: [*] Fri Dec 23 17:23:48 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.103429 | F1-score: 0.93 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 17:23:56 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.139305 | F1-score: 0.93 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 17:24:03 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.134206 | F1-score: 0.94 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 17:24:10 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.067845 | F1-score: 0.94 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 17:24:17 2022:    1    | Tr.loss: 0.187594 | Tr.F1.:   0.94    |   57.41  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 17:24:17 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.081722 | F1-score: 0.96 | Elapsed: 0.08s
WARNING:root: [*] Fri Dec 23 17:24:24 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.071324 | F1-score: 0.97 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 17:24:31 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.144776 | F1-score: 0.97 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 17:24:39 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.120419 | F1-score: 0.97 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 17:24:46 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.082897 | F1-score: 0.97 | Elapsed: 7.22s
WARNING:root: [*] Fri Dec 23 17:24:53 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.112369 | F1-score: 0.97 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 17:25:00 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.090660 | F1-score: 0.97 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 17:25:07 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.053690 | F1-score: 0.97 | Elapsed: 7.26s
WARNING:root: [*] Fri Dec 23 17:25:14 2022:    2    | Tr.loss: 0.101540 | Tr.F1.:   0.97    |   57.44  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 17:25:14 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.091422 | F1-score: 0.98 | Elapsed: 0.08s
WARNING:root: [*] Fri Dec 23 17:25:22 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.150052 | F1-score: 0.97 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 17:25:29 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.112271 | F1-score: 0.97 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 17:25:36 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.085993 | F1-score: 0.97 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 17:25:43 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.163959 | F1-score: 0.97 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 17:25:50 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.067794 | F1-score: 0.97 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 17:25:58 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.077449 | F1-score: 0.97 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 17:26:05 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.087207 | F1-score: 0.97 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 17:26:12 2022:    3    | Tr.loss: 0.086968 | Tr.F1.:   0.97    |   57.47  s
WARNING:root:
        [!] Fri Dec 23 17:26:12 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671812772-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671812772-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671812772-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671812772-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 17:26:21 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.644502 | F1-score: 0.84 | Elapsed: 0.10s
WARNING:root: [*] Fri Dec 23 17:26:28 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.252281 | F1-score: 0.87 | Elapsed: 7.26s
WARNING:root: [*] Fri Dec 23 17:26:35 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.285572 | F1-score: 0.90 | Elapsed: 7.26s
WARNING:root: [*] Fri Dec 23 17:26:42 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.177576 | F1-score: 0.92 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 17:26:50 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.092526 | F1-score: 0.93 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 17:26:57 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.162776 | F1-score: 0.93 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 17:27:04 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.202586 | F1-score: 0.94 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 17:27:11 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.041048 | F1-score: 0.94 | Elapsed: 7.22s
WARNING:root: [*] Fri Dec 23 17:27:18 2022:    1    | Tr.loss: 0.189578 | Tr.F1.:   0.94    |   57.49  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 17:27:18 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.292736 | F1-score: 0.92 | Elapsed: 0.09s
WARNING:root: [*] Fri Dec 23 17:27:25 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.101243 | F1-score: 0.96 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 17:27:33 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.079587 | F1-score: 0.97 | Elapsed: 7.26s
WARNING:root: [*] Fri Dec 23 17:27:40 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.071881 | F1-score: 0.97 | Elapsed: 7.32s
WARNING:root: [*] Fri Dec 23 17:27:47 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.086799 | F1-score: 0.97 | Elapsed: 7.31s
WARNING:root: [*] Fri Dec 23 17:27:55 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.271433 | F1-score: 0.97 | Elapsed: 7.33s
WARNING:root: [*] Fri Dec 23 17:28:02 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.194860 | F1-score: 0.97 | Elapsed: 7.32s
WARNING:root: [*] Fri Dec 23 17:28:09 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.024337 | F1-score: 0.97 | Elapsed: 7.33s
WARNING:root: [*] Fri Dec 23 17:28:16 2022:    2    | Tr.loss: 0.103910 | Tr.F1.:   0.97    |   57.93  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 17:28:16 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.109874 | F1-score: 0.95 | Elapsed: 0.08s
WARNING:root: [*] Fri Dec 23 17:28:23 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.043813 | F1-score: 0.97 | Elapsed: 7.30s
WARNING:root: [*] Fri Dec 23 17:28:31 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.059795 | F1-score: 0.97 | Elapsed: 7.32s
WARNING:root: [*] Fri Dec 23 17:28:38 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.091051 | F1-score: 0.97 | Elapsed: 7.31s
WARNING:root: [*] Fri Dec 23 17:28:45 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.163851 | F1-score: 0.97 | Elapsed: 7.31s
WARNING:root: [*] Fri Dec 23 17:28:53 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.078637 | F1-score: 0.97 | Elapsed: 7.30s
WARNING:root: [*] Fri Dec 23 17:29:00 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.112054 | F1-score: 0.97 | Elapsed: 7.32s
WARNING:root: [*] Fri Dec 23 17:29:07 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.095800 | F1-score: 0.97 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 17:29:14 2022:    3    | Tr.loss: 0.086109 | Tr.F1.:   0.97    |   57.85  s
WARNING:root:
        [!] Fri Dec 23 17:29:14 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671812954-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671812954-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671812954-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671812954-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\metrics_trainSize_76126_ep_3_cv_3_maxLen_2048_vocabSize_1000_embeddingDim_64_hiddenNeurons_512_256_128_batchNormConv_False_batchNormFFNN_False_filterSizes_2_3_4_5.json
WARNING:root: [!] Average epoch time: 57.48s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.3573 -- F1: 0.4584
	FPR:  0.001 -- TPR: 0.8526 -- F1: 0.9202
	FPR:   0.01 -- TPR: 0.9343 -- F1: 0.9638
	FPR:    0.1 -- TPR: 0.9878 -- F1: 0.9709

WARNING:root: [!] Using vocabSize: 1000 | maxLen: 4096
WARNING:root: [!] Using device: cuda:0 | Dataset size: 76126
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 1000, 'embeddingDim': 64, 'hiddenNeurons': [512, 256, 128], 'batchNormConv': False, 'batchNormFFNN': False, 'filterSizes': [2, 3, 4, 5]}
WARNING:root: [!] Fold 1/3 | Train set size: 50750, Validation set size: 25376
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 17:29:54 2022: Train Epoch: 1 [  0  /50750 (0 %)]	Loss: 0.656067 | F1-score: 0.78 | Elapsed: 0.43s
WARNING:root: [*] Fri Dec 23 17:30:08 2022: Train Epoch: 1 [6400 /50750 (13%)]	Loss: 0.188605 | F1-score: 0.88 | Elapsed: 14.12s
WARNING:root: [*] Fri Dec 23 17:30:22 2022: Train Epoch: 1 [12800/50750 (25%)]	Loss: 0.174369 | F1-score: 0.91 | Elapsed: 14.18s
WARNING:root: [*] Fri Dec 23 17:30:37 2022: Train Epoch: 1 [19200/50750 (38%)]	Loss: 0.157793 | F1-score: 0.92 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 17:30:51 2022: Train Epoch: 1 [25600/50750 (50%)]	Loss: 0.276402 | F1-score: 0.93 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 17:31:05 2022: Train Epoch: 1 [32000/50750 (63%)]	Loss: 0.060481 | F1-score: 0.93 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 17:31:19 2022: Train Epoch: 1 [38400/50750 (76%)]	Loss: 0.176450 | F1-score: 0.94 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 17:31:33 2022: Train Epoch: 1 [44800/50750 (88%)]	Loss: 0.196683 | F1-score: 0.94 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 17:31:46 2022:    1    | Tr.loss: 0.185789 | Tr.F1.:   0.95    |  112.91  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 17:31:47 2022: Train Epoch: 2 [  0  /50750 (0 %)]	Loss: 0.078520 | F1-score: 0.98 | Elapsed: 0.14s
WARNING:root: [*] Fri Dec 23 17:32:01 2022: Train Epoch: 2 [6400 /50750 (13%)]	Loss: 0.058195 | F1-score: 0.97 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 17:32:15 2022: Train Epoch: 2 [12800/50750 (25%)]	Loss: 0.087050 | F1-score: 0.97 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 17:32:29 2022: Train Epoch: 2 [19200/50750 (38%)]	Loss: 0.072411 | F1-score: 0.97 | Elapsed: 14.20s
WARNING:root: [*] Fri Dec 23 17:32:43 2022: Train Epoch: 2 [25600/50750 (50%)]	Loss: 0.125774 | F1-score: 0.97 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 17:32:58 2022: Train Epoch: 2 [32000/50750 (63%)]	Loss: 0.117652 | F1-score: 0.97 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 17:33:12 2022: Train Epoch: 2 [38400/50750 (76%)]	Loss: 0.077403 | F1-score: 0.97 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 17:33:26 2022: Train Epoch: 2 [44800/50750 (88%)]	Loss: 0.070130 | F1-score: 0.97 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 17:33:39 2022:    2    | Tr.loss: 0.104043 | Tr.F1.:   0.97    |  112.72  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 17:33:39 2022: Train Epoch: 3 [  0  /50750 (0 %)]	Loss: 0.137567 | F1-score: 0.96 | Elapsed: 0.14s
WARNING:root: [*] Fri Dec 23 17:33:54 2022: Train Epoch: 3 [6400 /50750 (13%)]	Loss: 0.146686 | F1-score: 0.97 | Elapsed: 14.25s
WARNING:root: [*] Fri Dec 23 17:34:08 2022: Train Epoch: 3 [12800/50750 (25%)]	Loss: 0.031485 | F1-score: 0.97 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 17:34:22 2022: Train Epoch: 3 [19200/50750 (38%)]	Loss: 0.105785 | F1-score: 0.97 | Elapsed: 14.20s
WARNING:root: [*] Fri Dec 23 17:34:36 2022: Train Epoch: 3 [25600/50750 (50%)]	Loss: 0.160956 | F1-score: 0.97 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 17:34:50 2022: Train Epoch: 3 [32000/50750 (63%)]	Loss: 0.075330 | F1-score: 0.97 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 17:35:05 2022: Train Epoch: 3 [38400/50750 (76%)]	Loss: 0.063916 | F1-score: 0.97 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 17:35:19 2022: Train Epoch: 3 [44800/50750 (88%)]	Loss: 0.063760 | F1-score: 0.97 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 17:35:32 2022:    3    | Tr.loss: 0.088304 | Tr.F1.:   0.97    |  112.71  s
WARNING:root:
        [!] Fri Dec 23 17:35:32 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671813332-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671813332-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671813332-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671813332-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 17:35:50 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.721547 | F1-score: 0.31 | Elapsed: 0.16s
WARNING:root: [*] Fri Dec 23 17:36:04 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.268310 | F1-score: 0.86 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 17:36:18 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.244003 | F1-score: 0.90 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 17:36:32 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.256904 | F1-score: 0.92 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 17:36:47 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.082075 | F1-score: 0.93 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 17:37:01 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.093334 | F1-score: 0.93 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 17:37:15 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.192752 | F1-score: 0.94 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 17:37:29 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.155945 | F1-score: 0.94 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 17:37:42 2022:    1    | Tr.loss: 0.188209 | Tr.F1.:   0.94    |  112.78  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 17:37:42 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.064180 | F1-score: 0.98 | Elapsed: 0.15s
WARNING:root: [*] Fri Dec 23 17:37:57 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.122508 | F1-score: 0.97 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 17:38:11 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.061371 | F1-score: 0.97 | Elapsed: 14.20s
WARNING:root: [*] Fri Dec 23 17:38:25 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.158402 | F1-score: 0.97 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 17:38:39 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.055969 | F1-score: 0.97 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 17:38:53 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.075108 | F1-score: 0.97 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 17:39:08 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.051526 | F1-score: 0.97 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 17:39:22 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.045855 | F1-score: 0.97 | Elapsed: 14.25s
WARNING:root: [*] Fri Dec 23 17:39:35 2022:    2    | Tr.loss: 0.102470 | Tr.F1.:   0.97    |  112.78  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 17:39:35 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.080682 | F1-score: 0.98 | Elapsed: 0.16s
WARNING:root: [*] Fri Dec 23 17:39:49 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.044200 | F1-score: 0.97 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 17:40:04 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.112513 | F1-score: 0.97 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 17:40:18 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.111685 | F1-score: 0.97 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 17:40:32 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.106397 | F1-score: 0.97 | Elapsed: 14.24s
WARNING:root: [*] Fri Dec 23 17:40:46 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.047338 | F1-score: 0.97 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 17:41:01 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.032295 | F1-score: 0.97 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 17:41:15 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.025168 | F1-score: 0.97 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 17:41:28 2022:    3    | Tr.loss: 0.087005 | Tr.F1.:   0.97    |  112.80  s
WARNING:root:
        [!] Fri Dec 23 17:41:28 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671813688-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671813688-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671813688-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671813688-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 17:41:46 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.710573 | F1-score: 0.38 | Elapsed: 0.16s
WARNING:root: [*] Fri Dec 23 17:42:00 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.291672 | F1-score: 0.88 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 17:42:14 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.236634 | F1-score: 0.91 | Elapsed: 14.24s
WARNING:root: [*] Fri Dec 23 17:42:28 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.119371 | F1-score: 0.92 | Elapsed: 14.20s
WARNING:root: [*] Fri Dec 23 17:42:42 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.128368 | F1-score: 0.93 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 17:42:57 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.096749 | F1-score: 0.94 | Elapsed: 14.25s
WARNING:root: [*] Fri Dec 23 17:43:11 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.089877 | F1-score: 0.94 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 17:43:25 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.251177 | F1-score: 0.94 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 17:43:38 2022:    1    | Tr.loss: 0.186622 | Tr.F1.:   0.95    |  112.80  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 17:43:38 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.148553 | F1-score: 0.96 | Elapsed: 0.14s
WARNING:root: [*] Fri Dec 23 17:43:53 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.096627 | F1-score: 0.97 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 17:44:07 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.085985 | F1-score: 0.97 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 17:44:21 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.107648 | F1-score: 0.97 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 17:44:35 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.108293 | F1-score: 0.97 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 17:44:49 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.095465 | F1-score: 0.97 | Elapsed: 14.26s
WARNING:root: [*] Fri Dec 23 17:45:04 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.076525 | F1-score: 0.97 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 17:45:18 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.060326 | F1-score: 0.97 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 17:45:31 2022:    2    | Tr.loss: 0.103063 | Tr.F1.:   0.97    |  112.81  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 17:45:31 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.087581 | F1-score: 0.97 | Elapsed: 0.15s
WARNING:root: [*] Fri Dec 23 17:45:45 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.027045 | F1-score: 0.97 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 17:46:00 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.119323 | F1-score: 0.97 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 17:46:14 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.031364 | F1-score: 0.97 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 17:46:28 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.193855 | F1-score: 0.97 | Elapsed: 14.20s
WARNING:root: [*] Fri Dec 23 17:46:42 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.075803 | F1-score: 0.97 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 17:46:56 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.061236 | F1-score: 0.97 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 17:47:11 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.155562 | F1-score: 0.97 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 17:47:24 2022:    3    | Tr.loss: 0.088334 | Tr.F1.:   0.97    |  112.72  s
WARNING:root:
        [!] Fri Dec 23 17:47:24 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671814044-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671814044-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671814044-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671814044-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\metrics_trainSize_76126_ep_3_cv_3_maxLen_4096_vocabSize_1000_embeddingDim_64_hiddenNeurons_512_256_128_batchNormConv_False_batchNormFFNN_False_filterSizes_2_3_4_5.json
WARNING:root: [!] Average epoch time: 112.78s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.4772 -- F1: 0.6456
	FPR:  0.001 -- TPR: 0.8535 -- F1: 0.9207
	FPR:   0.01 -- TPR: 0.9447 -- F1: 0.9693
	FPR:    0.1 -- TPR: 0.9923 -- F1: 0.9733

WARNING:root: [!] Using vocabSize: 1000 | maxLen: 512
WARNING:root: [!] Using device: cuda:0 | Dataset size: 76126
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 1000, 'embeddingDim': 64, 'hiddenNeurons': [512, 256, 128], 'batchNormConv': False, 'batchNormFFNN': False, 'filterSizes': [2, 3, 4, 5]}
WARNING:root: [!] Fold 1/3 | Train set size: 50750, Validation set size: 25376
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 17:48:11 2022: Train Epoch: 1 [  0  /50750 (0 %)]	Loss: 0.699164 | F1-score: 0.61 | Elapsed: 0.20s
WARNING:root: [*] Fri Dec 23 17:48:13 2022: Train Epoch: 1 [6400 /50750 (13%)]	Loss: 0.300275 | F1-score: 0.88 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 17:48:15 2022: Train Epoch: 1 [12800/50750 (25%)]	Loss: 0.320393 | F1-score: 0.91 | Elapsed: 2.20s
WARNING:root: [*] Fri Dec 23 17:48:18 2022: Train Epoch: 1 [19200/50750 (38%)]	Loss: 0.187867 | F1-score: 0.92 | Elapsed: 2.21s
WARNING:root: [*] Fri Dec 23 17:48:20 2022: Train Epoch: 1 [25600/50750 (50%)]	Loss: 0.142107 | F1-score: 0.93 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 17:48:22 2022: Train Epoch: 1 [32000/50750 (63%)]	Loss: 0.105812 | F1-score: 0.93 | Elapsed: 2.22s
WARNING:root: [*] Fri Dec 23 17:48:24 2022: Train Epoch: 1 [38400/50750 (76%)]	Loss: 0.128014 | F1-score: 0.94 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 17:48:27 2022: Train Epoch: 1 [44800/50750 (88%)]	Loss: 0.042618 | F1-score: 0.94 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 17:48:29 2022:    1    | Tr.loss: 0.201331 | Tr.F1.:   0.94    |   17.84  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 17:48:29 2022: Train Epoch: 2 [  0  /50750 (0 %)]	Loss: 0.101196 | F1-score: 0.98 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 17:48:31 2022: Train Epoch: 2 [6400 /50750 (13%)]	Loss: 0.095758 | F1-score: 0.96 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 17:48:33 2022: Train Epoch: 2 [12800/50750 (25%)]	Loss: 0.192461 | F1-score: 0.96 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 17:48:35 2022: Train Epoch: 2 [19200/50750 (38%)]	Loss: 0.109465 | F1-score: 0.96 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 17:48:38 2022: Train Epoch: 2 [25600/50750 (50%)]	Loss: 0.186431 | F1-score: 0.96 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 17:48:40 2022: Train Epoch: 2 [32000/50750 (63%)]	Loss: 0.073668 | F1-score: 0.96 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 17:48:42 2022: Train Epoch: 2 [38400/50750 (76%)]	Loss: 0.074980 | F1-score: 0.96 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 17:48:44 2022: Train Epoch: 2 [44800/50750 (88%)]	Loss: 0.084109 | F1-score: 0.96 | Elapsed: 2.26s
WARNING:root: [*] Fri Dec 23 17:48:47 2022:    2    | Tr.loss: 0.121632 | Tr.F1.:   0.96    |   17.92  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 17:48:47 2022: Train Epoch: 3 [  0  /50750 (0 %)]	Loss: 0.166211 | F1-score: 0.98 | Elapsed: 0.02s
WARNING:root: [*] Fri Dec 23 17:48:49 2022: Train Epoch: 3 [6400 /50750 (13%)]	Loss: 0.105840 | F1-score: 0.96 | Elapsed: 2.29s
WARNING:root: [*] Fri Dec 23 17:48:51 2022: Train Epoch: 3 [12800/50750 (25%)]	Loss: 0.075688 | F1-score: 0.96 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 17:48:53 2022: Train Epoch: 3 [19200/50750 (38%)]	Loss: 0.162165 | F1-score: 0.96 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 17:48:56 2022: Train Epoch: 3 [25600/50750 (50%)]	Loss: 0.209361 | F1-score: 0.96 | Elapsed: 2.26s
WARNING:root: [*] Fri Dec 23 17:48:58 2022: Train Epoch: 3 [32000/50750 (63%)]	Loss: 0.088967 | F1-score: 0.96 | Elapsed: 2.26s
WARNING:root: [*] Fri Dec 23 17:49:00 2022: Train Epoch: 3 [38400/50750 (76%)]	Loss: 0.138412 | F1-score: 0.96 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 17:49:02 2022: Train Epoch: 3 [44800/50750 (88%)]	Loss: 0.293405 | F1-score: 0.96 | Elapsed: 2.26s
WARNING:root: [*] Fri Dec 23 17:49:05 2022:    3    | Tr.loss: 0.108619 | Tr.F1.:   0.96    |   17.94  s
WARNING:root:
        [!] Fri Dec 23 17:49:05 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671814145-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671814145-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671814145-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671814145-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 17:49:07 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.715813 | F1-score: 0.39 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 17:49:09 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.407095 | F1-score: 0.87 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 17:49:12 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.202984 | F1-score: 0.90 | Elapsed: 2.26s
WARNING:root: [*] Fri Dec 23 17:49:14 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.188233 | F1-score: 0.92 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 17:49:16 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.328606 | F1-score: 0.92 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 17:49:18 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.090935 | F1-score: 0.93 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 17:49:21 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.121601 | F1-score: 0.93 | Elapsed: 2.28s
WARNING:root: [*] Fri Dec 23 17:49:23 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.110554 | F1-score: 0.94 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 17:49:25 2022:    1    | Tr.loss: 0.205007 | Tr.F1.:   0.94    |   17.97  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 17:49:25 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.080546 | F1-score: 0.99 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 17:49:27 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.142119 | F1-score: 0.96 | Elapsed: 2.29s
WARNING:root: [*] Fri Dec 23 17:49:30 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.143214 | F1-score: 0.96 | Elapsed: 2.26s
WARNING:root: [*] Fri Dec 23 17:49:32 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.151676 | F1-score: 0.96 | Elapsed: 2.26s
WARNING:root: [*] Fri Dec 23 17:49:34 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.138931 | F1-score: 0.96 | Elapsed: 2.26s
WARNING:root: [*] Fri Dec 23 17:49:36 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.041646 | F1-score: 0.96 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 17:49:39 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.077247 | F1-score: 0.96 | Elapsed: 2.26s
WARNING:root: [*] Fri Dec 23 17:49:41 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.078644 | F1-score: 0.96 | Elapsed: 2.28s
WARNING:root: [*] Fri Dec 23 17:49:43 2022:    2    | Tr.loss: 0.121329 | Tr.F1.:   0.96    |   17.99  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 17:49:43 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.087173 | F1-score: 0.99 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 17:49:45 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.182368 | F1-score: 0.97 | Elapsed: 2.28s
WARNING:root: [*] Fri Dec 23 17:49:48 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.082830 | F1-score: 0.97 | Elapsed: 2.29s
WARNING:root: [*] Fri Dec 23 17:49:50 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.079968 | F1-score: 0.96 | Elapsed: 2.28s
WARNING:root: [*] Fri Dec 23 17:49:52 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.094374 | F1-score: 0.96 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 17:49:54 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.180365 | F1-score: 0.96 | Elapsed: 2.32s
WARNING:root: [*] Fri Dec 23 17:49:57 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.061618 | F1-score: 0.96 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 17:49:59 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.170353 | F1-score: 0.97 | Elapsed: 2.26s
WARNING:root: [*] Fri Dec 23 17:50:01 2022:    3    | Tr.loss: 0.107831 | Tr.F1.:   0.97    |   18.10  s
WARNING:root:
        [!] Fri Dec 23 17:50:01 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671814201-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671814201-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671814201-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671814201-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 17:50:03 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.676002 | F1-score: 0.74 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 17:50:06 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.378402 | F1-score: 0.89 | Elapsed: 2.29s
WARNING:root: [*] Fri Dec 23 17:50:08 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.196669 | F1-score: 0.91 | Elapsed: 2.26s
WARNING:root: [*] Fri Dec 23 17:50:10 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.336442 | F1-score: 0.92 | Elapsed: 2.28s
WARNING:root: [*] Fri Dec 23 17:50:13 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.074676 | F1-score: 0.93 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 17:50:15 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.153093 | F1-score: 0.94 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 17:50:17 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.189084 | F1-score: 0.94 | Elapsed: 2.30s
WARNING:root: [*] Fri Dec 23 17:50:19 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.110598 | F1-score: 0.94 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 17:50:22 2022:    1    | Tr.loss: 0.198112 | Tr.F1.:   0.94    |   18.12  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 17:50:22 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.065107 | F1-score: 0.97 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 17:50:24 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.225858 | F1-score: 0.96 | Elapsed: 2.31s
WARNING:root: [*] Fri Dec 23 17:50:26 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.091384 | F1-score: 0.96 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 17:50:28 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.055885 | F1-score: 0.96 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 17:50:31 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.178697 | F1-score: 0.96 | Elapsed: 2.28s
WARNING:root: [*] Fri Dec 23 17:50:33 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.126344 | F1-score: 0.96 | Elapsed: 2.28s
WARNING:root: [*] Fri Dec 23 17:50:35 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.102679 | F1-score: 0.96 | Elapsed: 2.26s
WARNING:root: [*] Fri Dec 23 17:50:38 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.132405 | F1-score: 0.96 | Elapsed: 2.26s
WARNING:root: [*] Fri Dec 23 17:50:40 2022:    2    | Tr.loss: 0.122516 | Tr.F1.:   0.96    |   18.08  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 17:50:40 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.096566 | F1-score: 0.96 | Elapsed: 0.02s
WARNING:root: [*] Fri Dec 23 17:50:42 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.103873 | F1-score: 0.97 | Elapsed: 2.29s
WARNING:root: [*] Fri Dec 23 17:50:44 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.063597 | F1-score: 0.97 | Elapsed: 2.26s
WARNING:root: [*] Fri Dec 23 17:50:46 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.085913 | F1-score: 0.96 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 17:50:49 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.163397 | F1-score: 0.96 | Elapsed: 2.29s
WARNING:root: [*] Fri Dec 23 17:50:51 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.093837 | F1-score: 0.97 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 17:50:53 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.229478 | F1-score: 0.97 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 17:50:56 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.122232 | F1-score: 0.97 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 17:50:58 2022:    3    | Tr.loss: 0.107926 | Tr.F1.:   0.97    |   18.02  s
WARNING:root:
        [!] Fri Dec 23 17:50:58 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671814258-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671814258-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671814258-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671814258-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\metrics_trainSize_76126_ep_3_cv_3_maxLen_512_vocabSize_1000_embeddingDim_64_hiddenNeurons_512_256_128_batchNormConv_False_batchNormFFNN_False_filterSizes_2_3_4_5.json
WARNING:root: [!] Average epoch time: 18.00s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.3871 -- F1: 0.5524
	FPR:  0.001 -- TPR: 0.8352 -- F1: 0.9098
	FPR:   0.01 -- TPR: 0.9268 -- F1: 0.9597
	FPR:    0.1 -- TPR: 0.9790 -- F1: 0.9663

WARNING:root: [!] Using vocabSize: 15000 | maxLen: 1024
WARNING:root: [!] Using device: cuda:0 | Dataset size: 76126
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 15000, 'embeddingDim': 64, 'hiddenNeurons': [512, 256, 128], 'batchNormConv': False, 'batchNormFFNN': False, 'filterSizes': [2, 3, 4, 5]}
WARNING:root: [!] Fold 1/3 | Train set size: 50750, Validation set size: 25376
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 17:51:30 2022: Train Epoch: 1 [  0  /50750 (0 %)]	Loss: 0.702048 | F1-score: 0.62 | Elapsed: 0.20s
WARNING:root: [*] Fri Dec 23 17:51:34 2022: Train Epoch: 1 [6400 /50750 (13%)]	Loss: 0.273952 | F1-score: 0.87 | Elapsed: 3.86s
WARNING:root: [*] Fri Dec 23 17:51:38 2022: Train Epoch: 1 [12800/50750 (25%)]	Loss: 0.238261 | F1-score: 0.91 | Elapsed: 3.82s
WARNING:root: [*] Fri Dec 23 17:51:42 2022: Train Epoch: 1 [19200/50750 (38%)]	Loss: 0.119466 | F1-score: 0.93 | Elapsed: 3.83s
WARNING:root: [*] Fri Dec 23 17:51:46 2022: Train Epoch: 1 [25600/50750 (50%)]	Loss: 0.127617 | F1-score: 0.94 | Elapsed: 3.86s
WARNING:root: [*] Fri Dec 23 17:51:50 2022: Train Epoch: 1 [32000/50750 (63%)]	Loss: 0.044707 | F1-score: 0.95 | Elapsed: 3.86s
WARNING:root: [*] Fri Dec 23 17:51:54 2022: Train Epoch: 1 [38400/50750 (76%)]	Loss: 0.026470 | F1-score: 0.95 | Elapsed: 3.87s
WARNING:root: [*] Fri Dec 23 17:51:58 2022: Train Epoch: 1 [44800/50750 (88%)]	Loss: 0.080876 | F1-score: 0.96 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 17:52:01 2022:    1    | Tr.loss: 0.145484 | Tr.F1.:   0.96    |   30.79  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 17:52:01 2022: Train Epoch: 2 [  0  /50750 (0 %)]	Loss: 0.034660 | F1-score: 0.99 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 17:52:05 2022: Train Epoch: 2 [6400 /50750 (13%)]	Loss: 0.084640 | F1-score: 0.98 | Elapsed: 3.91s
WARNING:root: [*] Fri Dec 23 17:52:09 2022: Train Epoch: 2 [12800/50750 (25%)]	Loss: 0.031264 | F1-score: 0.98 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 17:52:13 2022: Train Epoch: 2 [19200/50750 (38%)]	Loss: 0.025938 | F1-score: 0.98 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 17:52:17 2022: Train Epoch: 2 [25600/50750 (50%)]	Loss: 0.149389 | F1-score: 0.98 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 17:52:21 2022: Train Epoch: 2 [32000/50750 (63%)]	Loss: 0.012147 | F1-score: 0.98 | Elapsed: 3.92s
WARNING:root: [*] Fri Dec 23 17:52:25 2022: Train Epoch: 2 [38400/50750 (76%)]	Loss: 0.020741 | F1-score: 0.98 | Elapsed: 3.89s
WARNING:root: [*] Fri Dec 23 17:52:28 2022: Train Epoch: 2 [44800/50750 (88%)]	Loss: 0.080911 | F1-score: 0.98 | Elapsed: 3.92s
WARNING:root: [*] Fri Dec 23 17:52:32 2022:    2    | Tr.loss: 0.065903 | Tr.F1.:   0.98    |   31.00  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 17:52:32 2022: Train Epoch: 3 [  0  /50750 (0 %)]	Loss: 0.047276 | F1-score: 0.99 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 17:52:36 2022: Train Epoch: 3 [6400 /50750 (13%)]	Loss: 0.091461 | F1-score: 0.99 | Elapsed: 3.91s
WARNING:root: [*] Fri Dec 23 17:52:40 2022: Train Epoch: 3 [12800/50750 (25%)]	Loss: 0.133963 | F1-score: 0.99 | Elapsed: 3.91s
WARNING:root: [*] Fri Dec 23 17:52:44 2022: Train Epoch: 3 [19200/50750 (38%)]	Loss: 0.165874 | F1-score: 0.99 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 17:52:48 2022: Train Epoch: 3 [25600/50750 (50%)]	Loss: 0.060315 | F1-score: 0.99 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 17:52:52 2022: Train Epoch: 3 [32000/50750 (63%)]	Loss: 0.023961 | F1-score: 0.99 | Elapsed: 3.91s
WARNING:root: [*] Fri Dec 23 17:52:56 2022: Train Epoch: 3 [38400/50750 (76%)]	Loss: 0.026724 | F1-score: 0.99 | Elapsed: 3.91s
WARNING:root: [*] Fri Dec 23 17:53:00 2022: Train Epoch: 3 [44800/50750 (88%)]	Loss: 0.040870 | F1-score: 0.99 | Elapsed: 3.99s
WARNING:root: [*] Fri Dec 23 17:53:03 2022:    3    | Tr.loss: 0.050833 | Tr.F1.:   0.99    |   31.21  s
WARNING:root:
        [!] Fri Dec 23 17:53:03 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671814383-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671814383-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671814383-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671814383-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 17:53:08 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.681175 | F1-score: 0.65 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 17:53:12 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.053406 | F1-score: 0.86 | Elapsed: 4.03s
WARNING:root: [*] Fri Dec 23 17:53:16 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.109709 | F1-score: 0.90 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 17:53:20 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.097055 | F1-score: 0.92 | Elapsed: 3.93s
WARNING:root: [*] Fri Dec 23 17:53:24 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.116702 | F1-score: 0.94 | Elapsed: 3.93s
WARNING:root: [*] Fri Dec 23 17:53:28 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.103323 | F1-score: 0.94 | Elapsed: 3.93s
WARNING:root: [*] Fri Dec 23 17:53:32 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.015105 | F1-score: 0.95 | Elapsed: 3.93s
WARNING:root: [*] Fri Dec 23 17:53:36 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.104831 | F1-score: 0.95 | Elapsed: 3.91s
WARNING:root: [*] Fri Dec 23 17:53:39 2022:    1    | Tr.loss: 0.151271 | Tr.F1.:   0.96    |   31.21  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 17:53:39 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.026808 | F1-score: 1.00 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 17:53:43 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.100599 | F1-score: 0.99 | Elapsed: 3.94s
WARNING:root: [*] Fri Dec 23 17:53:47 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.050875 | F1-score: 0.98 | Elapsed: 3.93s
WARNING:root: [*] Fri Dec 23 17:53:51 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.070586 | F1-score: 0.98 | Elapsed: 3.92s
WARNING:root: [*] Fri Dec 23 17:53:55 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.062011 | F1-score: 0.98 | Elapsed: 3.93s
WARNING:root: [*] Fri Dec 23 17:53:59 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.058909 | F1-score: 0.98 | Elapsed: 3.93s
WARNING:root: [*] Fri Dec 23 17:54:03 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.110061 | F1-score: 0.98 | Elapsed: 3.91s
WARNING:root: [*] Fri Dec 23 17:54:07 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.172135 | F1-score: 0.98 | Elapsed: 3.91s
WARNING:root: [*] Fri Dec 23 17:54:10 2022:    2    | Tr.loss: 0.064270 | Tr.F1.:   0.98    |   31.13  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 17:54:10 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.053956 | F1-score: 0.99 | Elapsed: 0.05s
WARNING:root: [*] Fri Dec 23 17:54:14 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.034477 | F1-score: 0.99 | Elapsed: 3.92s
WARNING:root: [*] Fri Dec 23 17:54:18 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.020875 | F1-score: 0.99 | Elapsed: 3.92s
WARNING:root: [*] Fri Dec 23 17:54:22 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.034892 | F1-score: 0.99 | Elapsed: 3.91s
WARNING:root: [*] Fri Dec 23 17:54:26 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.050518 | F1-score: 0.99 | Elapsed: 3.92s
WARNING:root: [*] Fri Dec 23 17:54:30 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.014320 | F1-score: 0.99 | Elapsed: 3.93s
WARNING:root: [*] Fri Dec 23 17:54:34 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.053188 | F1-score: 0.99 | Elapsed: 3.92s
WARNING:root: [*] Fri Dec 23 17:54:38 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.090808 | F1-score: 0.99 | Elapsed: 3.92s
WARNING:root: [*] Fri Dec 23 17:54:41 2022:    3    | Tr.loss: 0.054629 | Tr.F1.:   0.99    |   31.11  s
WARNING:root:
        [!] Fri Dec 23 17:54:41 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671814481-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671814481-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671814481-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671814481-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 17:54:46 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.701815 | F1-score: 0.47 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 17:54:50 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.220633 | F1-score: 0.87 | Elapsed: 3.94s
WARNING:root: [*] Fri Dec 23 17:54:54 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.112043 | F1-score: 0.92 | Elapsed: 3.94s
WARNING:root: [*] Fri Dec 23 17:54:58 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.037577 | F1-score: 0.93 | Elapsed: 3.93s
WARNING:root: [*] Fri Dec 23 17:55:02 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.061269 | F1-score: 0.94 | Elapsed: 3.93s
WARNING:root: [*] Fri Dec 23 17:55:06 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.102221 | F1-score: 0.95 | Elapsed: 3.93s
WARNING:root: [*] Fri Dec 23 17:55:10 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.120699 | F1-score: 0.95 | Elapsed: 3.95s
WARNING:root: [*] Fri Dec 23 17:55:14 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.049270 | F1-score: 0.96 | Elapsed: 3.92s
WARNING:root: [*] Fri Dec 23 17:55:17 2022:    1    | Tr.loss: 0.144757 | Tr.F1.:   0.96    |   31.20  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 17:55:17 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.055723 | F1-score: 1.00 | Elapsed: 0.05s
WARNING:root: [*] Fri Dec 23 17:55:21 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.028648 | F1-score: 0.98 | Elapsed: 3.95s
WARNING:root: [*] Fri Dec 23 17:55:25 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.079733 | F1-score: 0.98 | Elapsed: 3.92s
WARNING:root: [*] Fri Dec 23 17:55:29 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.017495 | F1-score: 0.98 | Elapsed: 3.92s
WARNING:root: [*] Fri Dec 23 17:55:33 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.017946 | F1-score: 0.98 | Elapsed: 3.92s
WARNING:root: [*] Fri Dec 23 17:55:37 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.074555 | F1-score: 0.98 | Elapsed: 3.94s
WARNING:root: [*] Fri Dec 23 17:55:41 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.019535 | F1-score: 0.98 | Elapsed: 3.92s
WARNING:root: [*] Fri Dec 23 17:55:45 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.017082 | F1-score: 0.98 | Elapsed: 3.92s
WARNING:root: [*] Fri Dec 23 17:55:48 2022:    2    | Tr.loss: 0.064278 | Tr.F1.:   0.98    |   31.18  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 17:55:48 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.005991 | F1-score: 1.00 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 17:55:52 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.071018 | F1-score: 0.99 | Elapsed: 3.93s
WARNING:root: [*] Fri Dec 23 17:55:56 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.049912 | F1-score: 0.99 | Elapsed: 3.92s
WARNING:root: [*] Fri Dec 23 17:56:00 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.103064 | F1-score: 0.99 | Elapsed: 3.92s
WARNING:root: [*] Fri Dec 23 17:56:04 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.060621 | F1-score: 0.99 | Elapsed: 3.92s
WARNING:root: [*] Fri Dec 23 17:56:08 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.078355 | F1-score: 0.99 | Elapsed: 3.92s
WARNING:root: [*] Fri Dec 23 17:56:12 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.078817 | F1-score: 0.99 | Elapsed: 3.91s
WARNING:root: [*] Fri Dec 23 17:56:16 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.032482 | F1-score: 0.99 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 17:56:19 2022:    3    | Tr.loss: 0.051816 | Tr.F1.:   0.99    |   31.10  s
WARNING:root:
        [!] Fri Dec 23 17:56:20 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671814579-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671814579-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671814579-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671814579-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\metrics_trainSize_76126_ep_3_cv_3_maxLen_1024_vocabSize_15000_embeddingDim_64_hiddenNeurons_512_256_128_batchNormConv_False_batchNormFFNN_False_filterSizes_2_3_4_5.json
WARNING:root: [!] Average epoch time: 31.10s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.2259 -- F1: 0.2693
	FPR:  0.001 -- TPR: 0.9198 -- F1: 0.9578
	FPR:   0.01 -- TPR: 0.9791 -- F1: 0.9871
	FPR:    0.1 -- TPR: 0.9953 -- F1: 0.9744

WARNING:root: [!] Using vocabSize: 15000 | maxLen: 2048
WARNING:root: [!] Using device: cuda:0 | Dataset size: 76126
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 15000, 'embeddingDim': 64, 'hiddenNeurons': [512, 256, 128], 'batchNormConv': False, 'batchNormFFNN': False, 'filterSizes': [2, 3, 4, 5]}
WARNING:root: [!] Fold 1/3 | Train set size: 50750, Validation set size: 25376
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 17:56:55 2022: Train Epoch: 1 [  0  /50750 (0 %)]	Loss: 0.727194 | F1-score: 0.24 | Elapsed: 0.31s
WARNING:root: [*] Fri Dec 23 17:57:02 2022: Train Epoch: 1 [6400 /50750 (13%)]	Loss: 0.213874 | F1-score: 0.87 | Elapsed: 7.11s
WARNING:root: [*] Fri Dec 23 17:57:09 2022: Train Epoch: 1 [12800/50750 (25%)]	Loss: 0.121608 | F1-score: 0.92 | Elapsed: 7.11s
WARNING:root: [*] Fri Dec 23 17:57:16 2022: Train Epoch: 1 [19200/50750 (38%)]	Loss: 0.113747 | F1-score: 0.93 | Elapsed: 7.15s
WARNING:root: [*] Fri Dec 23 17:57:23 2022: Train Epoch: 1 [25600/50750 (50%)]	Loss: 0.036937 | F1-score: 0.94 | Elapsed: 7.17s
WARNING:root: [*] Fri Dec 23 17:57:31 2022: Train Epoch: 1 [32000/50750 (63%)]	Loss: 0.077532 | F1-score: 0.95 | Elapsed: 7.19s
WARNING:root: [*] Fri Dec 23 17:57:38 2022: Train Epoch: 1 [38400/50750 (76%)]	Loss: 0.088450 | F1-score: 0.95 | Elapsed: 7.18s
WARNING:root: [*] Fri Dec 23 17:57:45 2022: Train Epoch: 1 [44800/50750 (88%)]	Loss: 0.056862 | F1-score: 0.96 | Elapsed: 7.18s
WARNING:root: [*] Fri Dec 23 17:57:52 2022:    1    | Tr.loss: 0.138013 | Tr.F1.:   0.96    |   57.05  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 17:57:52 2022: Train Epoch: 2 [  0  /50750 (0 %)]	Loss: 0.055008 | F1-score: 0.99 | Elapsed: 0.07s
WARNING:root: [*] Fri Dec 23 17:57:59 2022: Train Epoch: 2 [6400 /50750 (13%)]	Loss: 0.006752 | F1-score: 0.99 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 17:58:06 2022: Train Epoch: 2 [12800/50750 (25%)]	Loss: 0.098435 | F1-score: 0.99 | Elapsed: 7.22s
WARNING:root: [*] Fri Dec 23 17:58:13 2022: Train Epoch: 2 [19200/50750 (38%)]	Loss: 0.129098 | F1-score: 0.98 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 17:58:21 2022: Train Epoch: 2 [25600/50750 (50%)]	Loss: 0.047462 | F1-score: 0.98 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 17:58:28 2022: Train Epoch: 2 [32000/50750 (63%)]	Loss: 0.041354 | F1-score: 0.99 | Elapsed: 7.22s
WARNING:root: [*] Fri Dec 23 17:58:35 2022: Train Epoch: 2 [38400/50750 (76%)]	Loss: 0.017126 | F1-score: 0.99 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 17:58:42 2022: Train Epoch: 2 [44800/50750 (88%)]	Loss: 0.054111 | F1-score: 0.99 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 17:58:49 2022:    2    | Tr.loss: 0.062445 | Tr.F1.:   0.99    |   57.34  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 17:58:49 2022: Train Epoch: 3 [  0  /50750 (0 %)]	Loss: 0.083289 | F1-score: 0.96 | Elapsed: 0.09s
WARNING:root: [*] Fri Dec 23 17:58:56 2022: Train Epoch: 3 [6400 /50750 (13%)]	Loss: 0.030196 | F1-score: 0.99 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 17:59:04 2022: Train Epoch: 3 [12800/50750 (25%)]	Loss: 0.077388 | F1-score: 0.99 | Elapsed: 7.27s
WARNING:root: [*] Fri Dec 23 17:59:11 2022: Train Epoch: 3 [19200/50750 (38%)]	Loss: 0.048672 | F1-score: 0.99 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 17:59:18 2022: Train Epoch: 3 [25600/50750 (50%)]	Loss: 0.014773 | F1-score: 0.99 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 17:59:25 2022: Train Epoch: 3 [32000/50750 (63%)]	Loss: 0.120936 | F1-score: 0.99 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 17:59:33 2022: Train Epoch: 3 [38400/50750 (76%)]	Loss: 0.029674 | F1-score: 0.99 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 17:59:40 2022: Train Epoch: 3 [44800/50750 (88%)]	Loss: 0.026029 | F1-score: 0.99 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 17:59:46 2022:    3    | Tr.loss: 0.049623 | Tr.F1.:   0.99    |   57.50  s
WARNING:root:
        [!] Fri Dec 23 17:59:46 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671814786-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671814786-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671814786-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671814786-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 17:59:55 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.735195 | F1-score: 0.20 | Elapsed: 0.11s
WARNING:root: [*] Fri Dec 23 18:00:03 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.142514 | F1-score: 0.86 | Elapsed: 7.28s
WARNING:root: [*] Fri Dec 23 18:00:10 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.121335 | F1-score: 0.91 | Elapsed: 7.26s
WARNING:root: [*] Fri Dec 23 18:00:17 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.025916 | F1-score: 0.93 | Elapsed: 7.27s
WARNING:root: [*] Fri Dec 23 18:00:24 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.079094 | F1-score: 0.94 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 18:00:32 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.044033 | F1-score: 0.95 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 18:00:39 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.033998 | F1-score: 0.95 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 18:00:46 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.096960 | F1-score: 0.96 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 18:00:53 2022:    1    | Tr.loss: 0.145809 | Tr.F1.:   0.96    |   57.60  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 18:00:53 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.054662 | F1-score: 0.99 | Elapsed: 0.07s
WARNING:root: [*] Fri Dec 23 18:01:00 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.042670 | F1-score: 0.98 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 18:01:07 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.019096 | F1-score: 0.98 | Elapsed: 7.26s
WARNING:root: [*] Fri Dec 23 18:01:15 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.020746 | F1-score: 0.99 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 18:01:22 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.040758 | F1-score: 0.98 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 18:01:29 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.096662 | F1-score: 0.99 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 18:01:36 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.051823 | F1-score: 0.98 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 18:01:44 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.033862 | F1-score: 0.98 | Elapsed: 7.26s
WARNING:root: [*] Fri Dec 23 18:01:50 2022:    2    | Tr.loss: 0.060959 | Tr.F1.:   0.99    |   57.48  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 18:01:50 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.018747 | F1-score: 1.00 | Elapsed: 0.07s
WARNING:root: [*] Fri Dec 23 18:01:58 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.023195 | F1-score: 0.99 | Elapsed: 7.26s
WARNING:root: [*] Fri Dec 23 18:02:05 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.062769 | F1-score: 0.99 | Elapsed: 7.26s
WARNING:root: [*] Fri Dec 23 18:02:12 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.045635 | F1-score: 0.99 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 18:02:19 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.047808 | F1-score: 0.99 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 18:02:27 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.009789 | F1-score: 0.99 | Elapsed: 7.26s
WARNING:root: [*] Fri Dec 23 18:02:34 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.021920 | F1-score: 0.99 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 18:02:41 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.012288 | F1-score: 0.99 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 18:02:48 2022:    3    | Tr.loss: 0.050034 | Tr.F1.:   0.99    |   57.50  s
WARNING:root:
        [!] Fri Dec 23 18:02:48 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671814968-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671814968-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671814968-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671814968-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 18:02:57 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.710323 | F1-score: 0.39 | Elapsed: 0.10s
WARNING:root: [*] Fri Dec 23 18:03:04 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.129018 | F1-score: 0.88 | Elapsed: 7.28s
WARNING:root: [*] Fri Dec 23 18:03:11 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.229085 | F1-score: 0.92 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 18:03:19 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.027255 | F1-score: 0.93 | Elapsed: 7.27s
WARNING:root: [*] Fri Dec 23 18:03:26 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.118124 | F1-score: 0.94 | Elapsed: 7.26s
WARNING:root: [*] Fri Dec 23 18:03:33 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.039022 | F1-score: 0.95 | Elapsed: 7.26s
WARNING:root: [*] Fri Dec 23 18:03:40 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.045336 | F1-score: 0.96 | Elapsed: 7.26s
WARNING:root: [*] Fri Dec 23 18:03:48 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.069341 | F1-score: 0.96 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 18:03:54 2022:    1    | Tr.loss: 0.137539 | Tr.F1.:   0.96    |   57.60  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 18:03:54 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.136894 | F1-score: 0.98 | Elapsed: 0.08s
WARNING:root: [*] Fri Dec 23 18:04:02 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.008694 | F1-score: 0.99 | Elapsed: 7.26s
WARNING:root: [*] Fri Dec 23 18:04:09 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.037174 | F1-score: 0.98 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 18:04:16 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.114436 | F1-score: 0.98 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 18:04:23 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.088166 | F1-score: 0.98 | Elapsed: 7.26s
WARNING:root: [*] Fri Dec 23 18:04:31 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.024199 | F1-score: 0.98 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 18:04:38 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.142783 | F1-score: 0.99 | Elapsed: 7.26s
WARNING:root: [*] Fri Dec 23 18:04:45 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.055682 | F1-score: 0.99 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 18:04:52 2022:    2    | Tr.loss: 0.060758 | Tr.F1.:   0.99    |   57.54  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 18:04:52 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.040968 | F1-score: 1.00 | Elapsed: 0.09s
WARNING:root: [*] Fri Dec 23 18:04:59 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.038869 | F1-score: 0.99 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 18:05:06 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.228187 | F1-score: 0.99 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 18:05:14 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.037575 | F1-score: 0.99 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 18:05:21 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.020617 | F1-score: 0.99 | Elapsed: 7.27s
WARNING:root: [*] Fri Dec 23 18:05:28 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.009931 | F1-score: 0.99 | Elapsed: 7.26s
WARNING:root: [*] Fri Dec 23 18:05:36 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.032527 | F1-score: 0.99 | Elapsed: 7.27s
WARNING:root: [*] Fri Dec 23 18:05:43 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.029564 | F1-score: 0.99 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 18:05:49 2022:    3    | Tr.loss: 0.049436 | Tr.F1.:   0.99    |   57.55  s
WARNING:root:
        [!] Fri Dec 23 18:05:49 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671815149-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671815149-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671815149-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671815149-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\metrics_trainSize_76126_ep_3_cv_3_maxLen_2048_vocabSize_15000_embeddingDim_64_hiddenNeurons_512_256_128_batchNormConv_False_batchNormFFNN_False_filterSizes_2_3_4_5.json
WARNING:root: [!] Average epoch time: 57.46s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.5342 -- F1: 0.6951
	FPR:  0.001 -- TPR: 0.9494 -- F1: 0.9738
	FPR:   0.01 -- TPR: 0.9815 -- F1: 0.9884
	FPR:    0.1 -- TPR: 0.9964 -- F1: 0.9749

WARNING:root: [!] Using vocabSize: 15000 | maxLen: 4096
WARNING:root: [!] Using device: cuda:0 | Dataset size: 76126
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 15000, 'embeddingDim': 64, 'hiddenNeurons': [512, 256, 128], 'batchNormConv': False, 'batchNormFFNN': False, 'filterSizes': [2, 3, 4, 5]}
WARNING:root: [!] Fold 1/3 | Train set size: 50750, Validation set size: 25376
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 18:06:30 2022: Train Epoch: 1 [  0  /50750 (0 %)]	Loss: 0.691301 | F1-score: 0.69 | Elapsed: 0.37s
WARNING:root: [*] Fri Dec 23 18:06:44 2022: Train Epoch: 1 [6400 /50750 (13%)]	Loss: 0.192863 | F1-score: 0.87 | Elapsed: 14.19s
WARNING:root: [*] Fri Dec 23 18:06:58 2022: Train Epoch: 1 [12800/50750 (25%)]	Loss: 0.095532 | F1-score: 0.91 | Elapsed: 14.19s
WARNING:root: [*] Fri Dec 23 18:07:12 2022: Train Epoch: 1 [19200/50750 (38%)]	Loss: 0.186858 | F1-score: 0.93 | Elapsed: 14.20s
WARNING:root: [*] Fri Dec 23 18:07:26 2022: Train Epoch: 1 [25600/50750 (50%)]	Loss: 0.031401 | F1-score: 0.94 | Elapsed: 14.20s
WARNING:root: [*] Fri Dec 23 18:07:40 2022: Train Epoch: 1 [32000/50750 (63%)]	Loss: 0.036339 | F1-score: 0.95 | Elapsed: 14.20s
WARNING:root: [*] Fri Dec 23 18:07:55 2022: Train Epoch: 1 [38400/50750 (76%)]	Loss: 0.107689 | F1-score: 0.95 | Elapsed: 14.20s
WARNING:root: [*] Fri Dec 23 18:08:09 2022: Train Epoch: 1 [44800/50750 (88%)]	Loss: 0.067034 | F1-score: 0.96 | Elapsed: 14.24s
WARNING:root: [*] Fri Dec 23 18:08:22 2022:    1    | Tr.loss: 0.141306 | Tr.F1.:   0.96    |  112.93  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 18:08:22 2022: Train Epoch: 2 [  0  /50750 (0 %)]	Loss: 0.053852 | F1-score: 0.99 | Elapsed: 0.14s
WARNING:root: [*] Fri Dec 23 18:08:37 2022: Train Epoch: 2 [6400 /50750 (13%)]	Loss: 0.020408 | F1-score: 0.98 | Elapsed: 14.32s
WARNING:root: [*] Fri Dec 23 18:08:51 2022: Train Epoch: 2 [12800/50750 (25%)]	Loss: 0.111585 | F1-score: 0.98 | Elapsed: 14.29s
WARNING:root: [*] Fri Dec 23 18:09:05 2022: Train Epoch: 2 [19200/50750 (38%)]	Loss: 0.050746 | F1-score: 0.98 | Elapsed: 14.33s
WARNING:root: [*] Fri Dec 23 18:09:19 2022: Train Epoch: 2 [25600/50750 (50%)]	Loss: 0.048271 | F1-score: 0.98 | Elapsed: 14.30s
WARNING:root: [*] Fri Dec 23 18:09:34 2022: Train Epoch: 2 [32000/50750 (63%)]	Loss: 0.044627 | F1-score: 0.98 | Elapsed: 14.32s
WARNING:root: [*] Fri Dec 23 18:09:48 2022: Train Epoch: 2 [38400/50750 (76%)]	Loss: 0.173640 | F1-score: 0.99 | Elapsed: 14.33s
WARNING:root: [*] Fri Dec 23 18:10:02 2022: Train Epoch: 2 [44800/50750 (88%)]	Loss: 0.030850 | F1-score: 0.99 | Elapsed: 14.32s
WARNING:root: [*] Fri Dec 23 18:10:16 2022:    2    | Tr.loss: 0.061460 | Tr.F1.:   0.99    |  113.54  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 18:10:16 2022: Train Epoch: 3 [  0  /50750 (0 %)]	Loss: 0.014669 | F1-score: 1.00 | Elapsed: 0.14s
WARNING:root: [*] Fri Dec 23 18:10:30 2022: Train Epoch: 3 [6400 /50750 (13%)]	Loss: 0.001750 | F1-score: 0.99 | Elapsed: 14.36s
WARNING:root: [*] Fri Dec 23 18:10:44 2022: Train Epoch: 3 [12800/50750 (25%)]	Loss: 0.002101 | F1-score: 0.99 | Elapsed: 14.31s
WARNING:root: [*] Fri Dec 23 18:10:59 2022: Train Epoch: 3 [19200/50750 (38%)]	Loss: 0.037824 | F1-score: 0.99 | Elapsed: 14.31s
WARNING:root: [*] Fri Dec 23 18:11:13 2022: Train Epoch: 3 [25600/50750 (50%)]	Loss: 0.047415 | F1-score: 0.99 | Elapsed: 14.33s
WARNING:root: [*] Fri Dec 23 18:11:27 2022: Train Epoch: 3 [32000/50750 (63%)]	Loss: 0.019016 | F1-score: 0.99 | Elapsed: 14.33s
WARNING:root: [*] Fri Dec 23 18:11:42 2022: Train Epoch: 3 [38400/50750 (76%)]	Loss: 0.097169 | F1-score: 0.99 | Elapsed: 14.35s
WARNING:root: [*] Fri Dec 23 18:11:56 2022: Train Epoch: 3 [44800/50750 (88%)]	Loss: 0.071714 | F1-score: 0.99 | Elapsed: 14.34s
WARNING:root: [*] Fri Dec 23 18:12:09 2022:    3    | Tr.loss: 0.050476 | Tr.F1.:   0.99    |  113.66  s
WARNING:root:
        [!] Fri Dec 23 18:12:09 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671815529-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671815529-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671815529-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671815529-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 18:12:27 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.676330 | F1-score: 0.63 | Elapsed: 0.17s
WARNING:root: [*] Fri Dec 23 18:12:41 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.231002 | F1-score: 0.87 | Elapsed: 14.36s
WARNING:root: [*] Fri Dec 23 18:12:56 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.147503 | F1-score: 0.91 | Elapsed: 14.35s
WARNING:root: [*] Fri Dec 23 18:13:10 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.047613 | F1-score: 0.93 | Elapsed: 14.35s
WARNING:root: [*] Fri Dec 23 18:13:24 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.093206 | F1-score: 0.94 | Elapsed: 14.34s
WARNING:root: [*] Fri Dec 23 18:13:39 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.087136 | F1-score: 0.95 | Elapsed: 14.35s
WARNING:root: [*] Fri Dec 23 18:13:53 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.091939 | F1-score: 0.95 | Elapsed: 14.35s
WARNING:root: [*] Fri Dec 23 18:14:07 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.029330 | F1-score: 0.96 | Elapsed: 14.35s
WARNING:root: [*] Fri Dec 23 18:14:21 2022:    1    | Tr.loss: 0.145604 | Tr.F1.:   0.96    |  113.83  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 18:14:21 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.084261 | F1-score: 0.98 | Elapsed: 0.15s
WARNING:root: [*] Fri Dec 23 18:14:35 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.032466 | F1-score: 0.98 | Elapsed: 14.36s
WARNING:root: [*] Fri Dec 23 18:14:50 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.142949 | F1-score: 0.98 | Elapsed: 14.36s
WARNING:root: [*] Fri Dec 23 18:15:04 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.039998 | F1-score: 0.98 | Elapsed: 14.34s
WARNING:root: [*] Fri Dec 23 18:15:18 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.048959 | F1-score: 0.98 | Elapsed: 14.36s
WARNING:root: [*] Fri Dec 23 18:15:33 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.062589 | F1-score: 0.98 | Elapsed: 14.35s
WARNING:root: [*] Fri Dec 23 18:15:47 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.068332 | F1-score: 0.98 | Elapsed: 14.34s
WARNING:root: [*] Fri Dec 23 18:16:01 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.045799 | F1-score: 0.98 | Elapsed: 14.33s
WARNING:root: [*] Fri Dec 23 18:16:14 2022:    2    | Tr.loss: 0.063495 | Tr.F1.:   0.98    |  113.80  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 18:16:15 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.016082 | F1-score: 1.00 | Elapsed: 0.14s
WARNING:root: [*] Fri Dec 23 18:16:29 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.003545 | F1-score: 0.99 | Elapsed: 14.35s
WARNING:root: [*] Fri Dec 23 18:16:43 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.005540 | F1-score: 0.99 | Elapsed: 14.34s
WARNING:root: [*] Fri Dec 23 18:16:58 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.034122 | F1-score: 0.99 | Elapsed: 14.33s
WARNING:root: [*] Fri Dec 23 18:17:12 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.037894 | F1-score: 0.99 | Elapsed: 14.34s
WARNING:root: [*] Fri Dec 23 18:17:26 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.032243 | F1-score: 0.99 | Elapsed: 14.35s
WARNING:root: [*] Fri Dec 23 18:17:41 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.054086 | F1-score: 0.99 | Elapsed: 14.35s
WARNING:root: [*] Fri Dec 23 18:17:55 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.013968 | F1-score: 0.99 | Elapsed: 14.33s
WARNING:root: [*] Fri Dec 23 18:18:08 2022:    3    | Tr.loss: 0.053749 | Tr.F1.:   0.99    |  113.76  s
WARNING:root:
        [!] Fri Dec 23 18:18:08 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671815888-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671815888-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671815888-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671815888-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 18:18:26 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.705968 | F1-score: 0.52 | Elapsed: 0.14s
WARNING:root: [*] Fri Dec 23 18:18:40 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.201854 | F1-score: 0.87 | Elapsed: 14.35s
WARNING:root: [*] Fri Dec 23 18:18:55 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.120216 | F1-score: 0.92 | Elapsed: 14.35s
WARNING:root: [*] Fri Dec 23 18:19:09 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.228673 | F1-score: 0.93 | Elapsed: 14.36s
WARNING:root: [*] Fri Dec 23 18:19:23 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.065590 | F1-score: 0.94 | Elapsed: 14.36s
WARNING:root: [*] Fri Dec 23 18:19:38 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.096622 | F1-score: 0.95 | Elapsed: 14.35s
WARNING:root: [*] Fri Dec 23 18:19:52 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.061091 | F1-score: 0.95 | Elapsed: 14.34s
WARNING:root: [*] Fri Dec 23 18:20:06 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.013460 | F1-score: 0.96 | Elapsed: 14.35s
WARNING:root: [*] Fri Dec 23 18:20:20 2022:    1    | Tr.loss: 0.139680 | Tr.F1.:   0.96    |  113.81  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 18:20:20 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.097754 | F1-score: 0.98 | Elapsed: 0.15s
WARNING:root: [*] Fri Dec 23 18:20:34 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.029820 | F1-score: 0.98 | Elapsed: 14.34s
WARNING:root: [*] Fri Dec 23 18:20:49 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.023955 | F1-score: 0.98 | Elapsed: 14.35s
WARNING:root: [*] Fri Dec 23 18:21:03 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.003699 | F1-score: 0.98 | Elapsed: 14.34s
WARNING:root: [*] Fri Dec 23 18:21:17 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.017466 | F1-score: 0.98 | Elapsed: 14.33s
WARNING:root: [*] Fri Dec 23 18:21:32 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.130081 | F1-score: 0.98 | Elapsed: 14.34s
WARNING:root: [*] Fri Dec 23 18:21:46 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.014954 | F1-score: 0.99 | Elapsed: 14.36s
WARNING:root: [*] Fri Dec 23 18:22:00 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.123487 | F1-score: 0.98 | Elapsed: 14.35s
WARNING:root: [*] Fri Dec 23 18:22:13 2022:    2    | Tr.loss: 0.060006 | Tr.F1.:   0.99    |  113.77  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 18:22:14 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.030402 | F1-score: 0.99 | Elapsed: 0.14s
WARNING:root: [*] Fri Dec 23 18:22:28 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.020058 | F1-score: 0.99 | Elapsed: 14.36s
WARNING:root: [*] Fri Dec 23 18:22:42 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.028895 | F1-score: 0.99 | Elapsed: 14.31s
WARNING:root: [*] Fri Dec 23 18:22:57 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.075002 | F1-score: 0.99 | Elapsed: 14.35s
WARNING:root: [*] Fri Dec 23 18:23:11 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.008212 | F1-score: 0.99 | Elapsed: 14.34s
WARNING:root: [*] Fri Dec 23 18:23:25 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.023836 | F1-score: 0.99 | Elapsed: 14.35s
WARNING:root: [*] Fri Dec 23 18:23:40 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.011411 | F1-score: 0.99 | Elapsed: 14.34s
WARNING:root: [*] Fri Dec 23 18:23:54 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.084722 | F1-score: 0.99 | Elapsed: 14.34s
WARNING:root: [*] Fri Dec 23 18:24:07 2022:    3    | Tr.loss: 0.049914 | Tr.F1.:   0.99    |  113.72  s
WARNING:root:
        [!] Fri Dec 23 18:24:07 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671816247-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671816247-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671816247-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671816247-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\metrics_trainSize_76126_ep_3_cv_3_maxLen_4096_vocabSize_15000_embeddingDim_64_hiddenNeurons_512_256_128_batchNormConv_False_batchNormFFNN_False_filterSizes_2_3_4_5.json
WARNING:root: [!] Average epoch time: 113.65s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.6637 -- F1: 0.7926
	FPR:  0.001 -- TPR: 0.9422 -- F1: 0.9700
	FPR:   0.01 -- TPR: 0.9811 -- F1: 0.9882
	FPR:    0.1 -- TPR: 0.9968 -- F1: 0.9752

WARNING:root: [!] Using vocabSize: 15000 | maxLen: 512
WARNING:root: [!] Using device: cuda:0 | Dataset size: 76126
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 15000, 'embeddingDim': 64, 'hiddenNeurons': [512, 256, 128], 'batchNormConv': False, 'batchNormFFNN': False, 'filterSizes': [2, 3, 4, 5]}
WARNING:root: [!] Fold 1/3 | Train set size: 50750, Validation set size: 25376
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 18:24:55 2022: Train Epoch: 1 [  0  /50750 (0 %)]	Loss: 0.715936 | F1-score: 0.20 | Elapsed: 0.19s
WARNING:root: [*] Fri Dec 23 18:24:57 2022: Train Epoch: 1 [6400 /50750 (13%)]	Loss: 0.301661 | F1-score: 0.87 | Elapsed: 2.38s
WARNING:root: [*] Fri Dec 23 18:24:59 2022: Train Epoch: 1 [12800/50750 (25%)]	Loss: 0.084900 | F1-score: 0.91 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 18:25:01 2022: Train Epoch: 1 [19200/50750 (38%)]	Loss: 0.194251 | F1-score: 0.93 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 18:25:04 2022: Train Epoch: 1 [25600/50750 (50%)]	Loss: 0.087816 | F1-score: 0.94 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 18:25:06 2022: Train Epoch: 1 [32000/50750 (63%)]	Loss: 0.098231 | F1-score: 0.95 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 18:25:08 2022: Train Epoch: 1 [38400/50750 (76%)]	Loss: 0.048623 | F1-score: 0.95 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 18:25:10 2022: Train Epoch: 1 [44800/50750 (88%)]	Loss: 0.051535 | F1-score: 0.95 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 18:25:12 2022:    1    | Tr.loss: 0.147124 | Tr.F1.:   0.96    |   18.03  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 18:25:12 2022: Train Epoch: 2 [  0  /50750 (0 %)]	Loss: 0.020614 | F1-score: 1.00 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 18:25:15 2022: Train Epoch: 2 [6400 /50750 (13%)]	Loss: 0.053373 | F1-score: 0.98 | Elapsed: 2.28s
WARNING:root: [*] Fri Dec 23 18:25:17 2022: Train Epoch: 2 [12800/50750 (25%)]	Loss: 0.027586 | F1-score: 0.98 | Elapsed: 2.26s
WARNING:root: [*] Fri Dec 23 18:25:19 2022: Train Epoch: 2 [19200/50750 (38%)]	Loss: 0.068477 | F1-score: 0.98 | Elapsed: 2.26s
WARNING:root: [*] Fri Dec 23 18:25:22 2022: Train Epoch: 2 [25600/50750 (50%)]	Loss: 0.065880 | F1-score: 0.98 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 18:25:24 2022: Train Epoch: 2 [32000/50750 (63%)]	Loss: 0.038159 | F1-score: 0.98 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 18:25:26 2022: Train Epoch: 2 [38400/50750 (76%)]	Loss: 0.046743 | F1-score: 0.98 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 18:25:28 2022: Train Epoch: 2 [44800/50750 (88%)]	Loss: 0.046894 | F1-score: 0.98 | Elapsed: 2.26s
WARNING:root: [*] Fri Dec 23 18:25:30 2022:    2    | Tr.loss: 0.066255 | Tr.F1.:   0.98    |   17.97  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 18:25:30 2022: Train Epoch: 3 [  0  /50750 (0 %)]	Loss: 0.119597 | F1-score: 0.98 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 18:25:33 2022: Train Epoch: 3 [6400 /50750 (13%)]	Loss: 0.061187 | F1-score: 0.99 | Elapsed: 2.29s
WARNING:root: [*] Fri Dec 23 18:25:35 2022: Train Epoch: 3 [12800/50750 (25%)]	Loss: 0.011308 | F1-score: 0.99 | Elapsed: 2.26s
WARNING:root: [*] Fri Dec 23 18:25:37 2022: Train Epoch: 3 [19200/50750 (38%)]	Loss: 0.037144 | F1-score: 0.99 | Elapsed: 2.26s
WARNING:root: [*] Fri Dec 23 18:25:39 2022: Train Epoch: 3 [25600/50750 (50%)]	Loss: 0.010584 | F1-score: 0.99 | Elapsed: 2.26s
WARNING:root: [*] Fri Dec 23 18:25:42 2022: Train Epoch: 3 [32000/50750 (63%)]	Loss: 0.063865 | F1-score: 0.99 | Elapsed: 2.28s
WARNING:root: [*] Fri Dec 23 18:25:44 2022: Train Epoch: 3 [38400/50750 (76%)]	Loss: 0.015253 | F1-score: 0.99 | Elapsed: 2.26s
WARNING:root: [*] Fri Dec 23 18:25:46 2022: Train Epoch: 3 [44800/50750 (88%)]	Loss: 0.054036 | F1-score: 0.99 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 18:25:48 2022:    3    | Tr.loss: 0.053828 | Tr.F1.:   0.99    |   17.99  s
WARNING:root:
        [!] Fri Dec 23 18:25:48 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671816348-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671816348-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671816348-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671816348-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 18:25:51 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.710919 | F1-score: 0.26 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 18:25:53 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.259614 | F1-score: 0.87 | Elapsed: 2.28s
WARNING:root: [*] Fri Dec 23 18:25:55 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.241524 | F1-score: 0.91 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 18:25:58 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.093517 | F1-score: 0.93 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 18:26:00 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.052334 | F1-score: 0.94 | Elapsed: 2.29s
WARNING:root: [*] Fri Dec 23 18:26:02 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.024249 | F1-score: 0.94 | Elapsed: 2.28s
WARNING:root: [*] Fri Dec 23 18:26:04 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.057196 | F1-score: 0.95 | Elapsed: 2.26s
WARNING:root: [*] Fri Dec 23 18:26:07 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.056241 | F1-score: 0.95 | Elapsed: 2.28s
WARNING:root: [*] Fri Dec 23 18:26:09 2022:    1    | Tr.loss: 0.153569 | Tr.F1.:   0.96    |   18.05  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 18:26:09 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.082899 | F1-score: 0.99 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 18:26:11 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.079853 | F1-score: 0.98 | Elapsed: 2.29s
WARNING:root: [*] Fri Dec 23 18:26:13 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.032031 | F1-score: 0.98 | Elapsed: 2.26s
WARNING:root: [*] Fri Dec 23 18:26:16 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.092794 | F1-score: 0.98 | Elapsed: 2.26s
WARNING:root: [*] Fri Dec 23 18:26:18 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.133976 | F1-score: 0.98 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 18:26:20 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.076603 | F1-score: 0.98 | Elapsed: 2.28s
WARNING:root: [*] Fri Dec 23 18:26:23 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.049226 | F1-score: 0.98 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 18:26:25 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.119774 | F1-score: 0.98 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 18:26:27 2022:    2    | Tr.loss: 0.068410 | Tr.F1.:   0.98    |   18.01  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 18:26:27 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.111652 | F1-score: 0.98 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 18:26:29 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.062789 | F1-score: 0.99 | Elapsed: 2.29s
WARNING:root: [*] Fri Dec 23 18:26:31 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.111960 | F1-score: 0.99 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 18:26:34 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.052908 | F1-score: 0.99 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 18:26:36 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.013231 | F1-score: 0.99 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 18:26:38 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.059898 | F1-score: 0.99 | Elapsed: 2.29s
WARNING:root: [*] Fri Dec 23 18:26:41 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.018157 | F1-score: 0.99 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 18:26:43 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.021911 | F1-score: 0.99 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 18:26:45 2022:    3    | Tr.loss: 0.057474 | Tr.F1.:   0.99    |   18.06  s
WARNING:root:
        [!] Fri Dec 23 18:26:45 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671816405-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671816405-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671816405-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671816405-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 18:26:47 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.739585 | F1-score: 0.25 | Elapsed: 0.02s
WARNING:root: [*] Fri Dec 23 18:26:50 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.198364 | F1-score: 0.88 | Elapsed: 2.33s
WARNING:root: [*] Fri Dec 23 18:26:52 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.095273 | F1-score: 0.92 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 18:26:54 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.102866 | F1-score: 0.93 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 18:26:57 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.132912 | F1-score: 0.94 | Elapsed: 2.29s
WARNING:root: [*] Fri Dec 23 18:26:59 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.070477 | F1-score: 0.95 | Elapsed: 2.28s
WARNING:root: [*] Fri Dec 23 18:27:01 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.088605 | F1-score: 0.95 | Elapsed: 2.30s
WARNING:root: [*] Fri Dec 23 18:27:03 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.122841 | F1-score: 0.96 | Elapsed: 2.26s
WARNING:root: [*] Fri Dec 23 18:27:06 2022:    1    | Tr.loss: 0.148397 | Tr.F1.:   0.96    |   18.13  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 18:27:06 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.033681 | F1-score: 0.99 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 18:27:08 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.120675 | F1-score: 0.98 | Elapsed: 2.30s
WARNING:root: [*] Fri Dec 23 18:27:10 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.105483 | F1-score: 0.98 | Elapsed: 2.29s
WARNING:root: [*] Fri Dec 23 18:27:12 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.052415 | F1-score: 0.98 | Elapsed: 2.26s
WARNING:root: [*] Fri Dec 23 18:27:15 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.023879 | F1-score: 0.98 | Elapsed: 2.30s
WARNING:root: [*] Fri Dec 23 18:27:17 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.044497 | F1-score: 0.98 | Elapsed: 2.29s
WARNING:root: [*] Fri Dec 23 18:27:19 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.026829 | F1-score: 0.98 | Elapsed: 2.29s
WARNING:root: [*] Fri Dec 23 18:27:22 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.093759 | F1-score: 0.98 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 18:27:24 2022:    2    | Tr.loss: 0.068388 | Tr.F1.:   0.98    |   18.12  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 18:27:24 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.003625 | F1-score: 1.00 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 18:27:26 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.036639 | F1-score: 0.99 | Elapsed: 2.29s
WARNING:root: [*] Fri Dec 23 18:27:28 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.060153 | F1-score: 0.99 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 18:27:31 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.019093 | F1-score: 0.99 | Elapsed: 2.29s
WARNING:root: [*] Fri Dec 23 18:27:33 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.052396 | F1-score: 0.99 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 18:27:35 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.094100 | F1-score: 0.99 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 18:27:37 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.014975 | F1-score: 0.99 | Elapsed: 2.29s
WARNING:root: [*] Fri Dec 23 18:27:40 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.053960 | F1-score: 0.99 | Elapsed: 2.28s
WARNING:root: [*] Fri Dec 23 18:27:42 2022:    3    | Tr.loss: 0.054791 | Tr.F1.:   0.99    |   18.11  s
WARNING:root:
        [!] Fri Dec 23 18:27:42 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671816462-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671816462-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671816462-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671816462-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\metrics_trainSize_76126_ep_3_cv_3_maxLen_512_vocabSize_15000_embeddingDim_64_hiddenNeurons_512_256_128_batchNormConv_False_batchNormFFNN_False_filterSizes_2_3_4_5.json
WARNING:root: [!] Average epoch time: 18.05s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.5746 -- F1: 0.7280
	FPR:  0.001 -- TPR: 0.9191 -- F1: 0.9575
	FPR:   0.01 -- TPR: 0.9784 -- F1: 0.9868
	FPR:    0.1 -- TPR: 0.9951 -- F1: 0.9744

WARNING:root: [!] Using vocabSize: 1500 | maxLen: 1024
WARNING:root: [!] Using device: cuda:0 | Dataset size: 76126
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 1500, 'embeddingDim': 64, 'hiddenNeurons': [512, 256, 128], 'batchNormConv': False, 'batchNormFFNN': False, 'filterSizes': [2, 3, 4, 5]}
WARNING:root: [!] Fold 1/3 | Train set size: 50750, Validation set size: 25376
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 18:28:15 2022: Train Epoch: 1 [  0  /50750 (0 %)]	Loss: 0.706567 | F1-score: 0.39 | Elapsed: 0.31s
WARNING:root: [*] Fri Dec 23 18:28:19 2022: Train Epoch: 1 [6400 /50750 (13%)]	Loss: 0.330542 | F1-score: 0.86 | Elapsed: 3.88s
WARNING:root: [*] Fri Dec 23 18:28:22 2022: Train Epoch: 1 [12800/50750 (25%)]	Loss: 0.255176 | F1-score: 0.90 | Elapsed: 3.82s
WARNING:root: [*] Fri Dec 23 18:28:26 2022: Train Epoch: 1 [19200/50750 (38%)]	Loss: 0.104895 | F1-score: 0.91 | Elapsed: 3.84s
WARNING:root: [*] Fri Dec 23 18:28:30 2022: Train Epoch: 1 [25600/50750 (50%)]	Loss: 0.022573 | F1-score: 0.92 | Elapsed: 3.87s
WARNING:root: [*] Fri Dec 23 18:28:34 2022: Train Epoch: 1 [32000/50750 (63%)]	Loss: 0.234728 | F1-score: 0.93 | Elapsed: 3.85s
WARNING:root: [*] Fri Dec 23 18:28:38 2022: Train Epoch: 1 [38400/50750 (76%)]	Loss: 0.062494 | F1-score: 0.93 | Elapsed: 3.87s
WARNING:root: [*] Fri Dec 23 18:28:42 2022: Train Epoch: 1 [44800/50750 (88%)]	Loss: 0.145806 | F1-score: 0.94 | Elapsed: 3.89s
WARNING:root: [*] Fri Dec 23 18:28:45 2022:    1    | Tr.loss: 0.193519 | Tr.F1.:   0.94    |   30.93  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 18:28:45 2022: Train Epoch: 2 [  0  /50750 (0 %)]	Loss: 0.131799 | F1-score: 0.95 | Elapsed: 0.05s
WARNING:root: [*] Fri Dec 23 18:28:49 2022: Train Epoch: 2 [6400 /50750 (13%)]	Loss: 0.091410 | F1-score: 0.96 | Elapsed: 3.92s
WARNING:root: [*] Fri Dec 23 18:28:53 2022: Train Epoch: 2 [12800/50750 (25%)]	Loss: 0.121539 | F1-score: 0.96 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 18:28:57 2022: Train Epoch: 2 [19200/50750 (38%)]	Loss: 0.157472 | F1-score: 0.96 | Elapsed: 3.88s
WARNING:root: [*] Fri Dec 23 18:29:01 2022: Train Epoch: 2 [25600/50750 (50%)]	Loss: 0.198302 | F1-score: 0.96 | Elapsed: 3.91s
WARNING:root: [*] Fri Dec 23 18:29:05 2022: Train Epoch: 2 [32000/50750 (63%)]	Loss: 0.166674 | F1-score: 0.96 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 18:29:09 2022: Train Epoch: 2 [38400/50750 (76%)]	Loss: 0.075997 | F1-score: 0.96 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 18:29:13 2022: Train Epoch: 2 [44800/50750 (88%)]	Loss: 0.119853 | F1-score: 0.96 | Elapsed: 3.91s
WARNING:root: [*] Fri Dec 23 18:29:16 2022:    2    | Tr.loss: 0.112267 | Tr.F1.:   0.96    |   30.96  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 18:29:16 2022: Train Epoch: 3 [  0  /50750 (0 %)]	Loss: 0.067309 | F1-score: 0.97 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 18:29:20 2022: Train Epoch: 3 [6400 /50750 (13%)]	Loss: 0.127931 | F1-score: 0.97 | Elapsed: 3.93s
WARNING:root: [*] Fri Dec 23 18:29:24 2022: Train Epoch: 3 [12800/50750 (25%)]	Loss: 0.075589 | F1-score: 0.97 | Elapsed: 3.91s
WARNING:root: [*] Fri Dec 23 18:29:28 2022: Train Epoch: 3 [19200/50750 (38%)]	Loss: 0.111390 | F1-score: 0.97 | Elapsed: 3.93s
WARNING:root: [*] Fri Dec 23 18:29:32 2022: Train Epoch: 3 [25600/50750 (50%)]	Loss: 0.065326 | F1-score: 0.97 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 18:29:36 2022: Train Epoch: 3 [32000/50750 (63%)]	Loss: 0.160312 | F1-score: 0.97 | Elapsed: 3.91s
WARNING:root: [*] Fri Dec 23 18:29:40 2022: Train Epoch: 3 [38400/50750 (76%)]	Loss: 0.081597 | F1-score: 0.97 | Elapsed: 3.93s
WARNING:root: [*] Fri Dec 23 18:29:44 2022: Train Epoch: 3 [44800/50750 (88%)]	Loss: 0.100862 | F1-score: 0.97 | Elapsed: 3.91s
WARNING:root: [*] Fri Dec 23 18:29:47 2022:    3    | Tr.loss: 0.095393 | Tr.F1.:   0.97    |   31.05  s
WARNING:root:
        [!] Fri Dec 23 18:29:47 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671816587-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671816587-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671816587-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671816587-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 18:29:52 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.715138 | F1-score: 0.24 | Elapsed: 0.05s
WARNING:root: [*] Fri Dec 23 18:29:56 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.198302 | F1-score: 0.86 | Elapsed: 3.96s
WARNING:root: [*] Fri Dec 23 18:30:00 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.270377 | F1-score: 0.90 | Elapsed: 3.91s
WARNING:root: [*] Fri Dec 23 18:30:04 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.228389 | F1-score: 0.92 | Elapsed: 3.93s
WARNING:root: [*] Fri Dec 23 18:30:08 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.229363 | F1-score: 0.92 | Elapsed: 3.91s
WARNING:root: [*] Fri Dec 23 18:30:12 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.144088 | F1-score: 0.93 | Elapsed: 3.94s
WARNING:root: [*] Fri Dec 23 18:30:16 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.133589 | F1-score: 0.94 | Elapsed: 3.92s
WARNING:root: [*] Fri Dec 23 18:30:19 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.109783 | F1-score: 0.94 | Elapsed: 3.91s
WARNING:root: [*] Fri Dec 23 18:30:23 2022:    1    | Tr.loss: 0.194359 | Tr.F1.:   0.94    |   31.20  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 18:30:23 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.105756 | F1-score: 0.97 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 18:30:27 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.244045 | F1-score: 0.96 | Elapsed: 3.94s
WARNING:root: [*] Fri Dec 23 18:30:31 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.140819 | F1-score: 0.97 | Elapsed: 3.91s
WARNING:root: [*] Fri Dec 23 18:30:35 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.074957 | F1-score: 0.97 | Elapsed: 3.94s
WARNING:root: [*] Fri Dec 23 18:30:39 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.052643 | F1-score: 0.96 | Elapsed: 3.91s
WARNING:root: [*] Fri Dec 23 18:30:43 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.086409 | F1-score: 0.96 | Elapsed: 3.93s
WARNING:root: [*] Fri Dec 23 18:30:47 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.175065 | F1-score: 0.96 | Elapsed: 3.92s
WARNING:root: [*] Fri Dec 23 18:30:51 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.133861 | F1-score: 0.96 | Elapsed: 3.92s
WARNING:root: [*] Fri Dec 23 18:30:54 2022:    2    | Tr.loss: 0.117000 | Tr.F1.:   0.96    |   31.12  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 18:30:54 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.056359 | F1-score: 0.98 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 18:30:58 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.125075 | F1-score: 0.97 | Elapsed: 3.94s
WARNING:root: [*] Fri Dec 23 18:31:02 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.048020 | F1-score: 0.97 | Elapsed: 3.92s
WARNING:root: [*] Fri Dec 23 18:31:06 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.221996 | F1-score: 0.97 | Elapsed: 3.92s
WARNING:root: [*] Fri Dec 23 18:31:10 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.054175 | F1-score: 0.97 | Elapsed: 3.92s
WARNING:root: [*] Fri Dec 23 18:31:14 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.115306 | F1-score: 0.97 | Elapsed: 3.93s
WARNING:root: [*] Fri Dec 23 18:31:18 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.140434 | F1-score: 0.97 | Elapsed: 3.91s
WARNING:root: [*] Fri Dec 23 18:31:22 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.163883 | F1-score: 0.97 | Elapsed: 3.94s
WARNING:root: [*] Fri Dec 23 18:31:25 2022:    3    | Tr.loss: 0.100005 | Tr.F1.:   0.97    |   31.15  s
WARNING:root:
        [!] Fri Dec 23 18:31:25 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671816685-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671816685-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671816685-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671816685-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 18:31:30 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.700454 | F1-score: 0.30 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 18:31:34 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.394740 | F1-score: 0.86 | Elapsed: 3.95s
WARNING:root: [*] Fri Dec 23 18:31:38 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.058512 | F1-score: 0.90 | Elapsed: 3.92s
WARNING:root: [*] Fri Dec 23 18:31:42 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.115610 | F1-score: 0.91 | Elapsed: 3.93s
WARNING:root: [*] Fri Dec 23 18:31:46 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.149669 | F1-score: 0.93 | Elapsed: 3.92s
WARNING:root: [*] Fri Dec 23 18:31:50 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.139040 | F1-score: 0.93 | Elapsed: 3.94s
WARNING:root: [*] Fri Dec 23 18:31:54 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.215074 | F1-score: 0.94 | Elapsed: 3.93s
WARNING:root: [*] Fri Dec 23 18:31:58 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.186789 | F1-score: 0.94 | Elapsed: 3.91s
WARNING:root: [*] Fri Dec 23 18:32:01 2022:    1    | Tr.loss: 0.197531 | Tr.F1.:   0.94    |   31.18  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 18:32:01 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.070602 | F1-score: 0.97 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 18:32:05 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.050204 | F1-score: 0.97 | Elapsed: 3.94s
WARNING:root: [*] Fri Dec 23 18:32:09 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.136881 | F1-score: 0.96 | Elapsed: 3.92s
WARNING:root: [*] Fri Dec 23 18:32:13 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.125484 | F1-score: 0.96 | Elapsed: 3.93s
WARNING:root: [*] Fri Dec 23 18:32:17 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.171451 | F1-score: 0.96 | Elapsed: 3.93s
WARNING:root: [*] Fri Dec 23 18:32:21 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.066711 | F1-score: 0.96 | Elapsed: 3.92s
WARNING:root: [*] Fri Dec 23 18:32:25 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.043361 | F1-score: 0.96 | Elapsed: 3.92s
WARNING:root: [*] Fri Dec 23 18:32:29 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.126107 | F1-score: 0.96 | Elapsed: 3.92s
WARNING:root: [*] Fri Dec 23 18:32:32 2022:    2    | Tr.loss: 0.113504 | Tr.F1.:   0.96    |   31.14  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 18:32:32 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.129148 | F1-score: 0.95 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 18:32:36 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.104312 | F1-score: 0.97 | Elapsed: 3.94s
WARNING:root: [*] Fri Dec 23 18:32:40 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.067457 | F1-score: 0.97 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 18:32:44 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.062746 | F1-score: 0.97 | Elapsed: 3.93s
WARNING:root: [*] Fri Dec 23 18:32:48 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.066233 | F1-score: 0.97 | Elapsed: 3.94s
WARNING:root: [*] Fri Dec 23 18:32:52 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.138481 | F1-score: 0.97 | Elapsed: 3.94s
WARNING:root: [*] Fri Dec 23 18:32:56 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.056139 | F1-score: 0.97 | Elapsed: 3.93s
WARNING:root: [*] Fri Dec 23 18:33:00 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.107602 | F1-score: 0.97 | Elapsed: 3.93s
WARNING:root: [*] Fri Dec 23 18:33:03 2022:    3    | Tr.loss: 0.097781 | Tr.F1.:   0.97    |   31.16  s
WARNING:root:
        [!] Fri Dec 23 18:33:03 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671816783-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671816783-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671816783-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671816783-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\metrics_trainSize_76126_ep_3_cv_3_maxLen_1024_vocabSize_1500_embeddingDim_64_hiddenNeurons_512_256_128_batchNormConv_False_batchNormFFNN_False_filterSizes_2_3_4_5.json
WARNING:root: [!] Average epoch time: 31.10s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.3970 -- F1: 0.5671
	FPR:  0.001 -- TPR: 0.8433 -- F1: 0.9144
	FPR:   0.01 -- TPR: 0.9308 -- F1: 0.9618
	FPR:    0.1 -- TPR: 0.9854 -- F1: 0.9693

WARNING:root: [!] Using vocabSize: 1500 | maxLen: 2048
WARNING:root: [!] Using device: cuda:0 | Dataset size: 76126
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 1500, 'embeddingDim': 64, 'hiddenNeurons': [512, 256, 128], 'batchNormConv': False, 'batchNormFFNN': False, 'filterSizes': [2, 3, 4, 5]}
WARNING:root: [!] Fold 1/3 | Train set size: 50750, Validation set size: 25376
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 18:33:39 2022: Train Epoch: 1 [  0  /50750 (0 %)]	Loss: 0.695267 | F1-score: 0.73 | Elapsed: 0.33s
WARNING:root: [*] Fri Dec 23 18:33:46 2022: Train Epoch: 1 [6400 /50750 (13%)]	Loss: 0.252856 | F1-score: 0.87 | Elapsed: 7.08s
WARNING:root: [*] Fri Dec 23 18:33:53 2022: Train Epoch: 1 [12800/50750 (25%)]	Loss: 0.353415 | F1-score: 0.90 | Elapsed: 7.10s
WARNING:root: [*] Fri Dec 23 18:34:00 2022: Train Epoch: 1 [19200/50750 (38%)]	Loss: 0.150964 | F1-score: 0.92 | Elapsed: 7.13s
WARNING:root: [*] Fri Dec 23 18:34:07 2022: Train Epoch: 1 [25600/50750 (50%)]	Loss: 0.218472 | F1-score: 0.93 | Elapsed: 7.17s
WARNING:root: [*] Fri Dec 23 18:34:15 2022: Train Epoch: 1 [32000/50750 (63%)]	Loss: 0.054231 | F1-score: 0.93 | Elapsed: 7.18s
WARNING:root: [*] Fri Dec 23 18:34:22 2022: Train Epoch: 1 [38400/50750 (76%)]	Loss: 0.170888 | F1-score: 0.94 | Elapsed: 7.19s
WARNING:root: [*] Fri Dec 23 18:34:29 2022: Train Epoch: 1 [44800/50750 (88%)]	Loss: 0.055583 | F1-score: 0.94 | Elapsed: 7.19s
WARNING:root: [*] Fri Dec 23 18:34:36 2022:    1    | Tr.loss: 0.189855 | Tr.F1.:   0.94    |   56.99  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 18:34:36 2022: Train Epoch: 2 [  0  /50750 (0 %)]	Loss: 0.169154 | F1-score: 0.94 | Elapsed: 0.07s
WARNING:root: [*] Fri Dec 23 18:34:43 2022: Train Epoch: 2 [6400 /50750 (13%)]	Loss: 0.033855 | F1-score: 0.97 | Elapsed: 7.21s
WARNING:root: [*] Fri Dec 23 18:34:50 2022: Train Epoch: 2 [12800/50750 (25%)]	Loss: 0.091592 | F1-score: 0.97 | Elapsed: 7.22s
WARNING:root: [*] Fri Dec 23 18:34:57 2022: Train Epoch: 2 [19200/50750 (38%)]	Loss: 0.029231 | F1-score: 0.97 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 18:35:04 2022: Train Epoch: 2 [25600/50750 (50%)]	Loss: 0.127441 | F1-score: 0.97 | Elapsed: 7.22s
WARNING:root: [*] Fri Dec 23 18:35:12 2022: Train Epoch: 2 [32000/50750 (63%)]	Loss: 0.080240 | F1-score: 0.97 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 18:35:19 2022: Train Epoch: 2 [38400/50750 (76%)]	Loss: 0.187274 | F1-score: 0.97 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 18:35:26 2022: Train Epoch: 2 [44800/50750 (88%)]	Loss: 0.173120 | F1-score: 0.97 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 18:35:33 2022:    2    | Tr.loss: 0.102081 | Tr.F1.:   0.97    |   57.31  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 18:35:33 2022: Train Epoch: 3 [  0  /50750 (0 %)]	Loss: 0.093833 | F1-score: 0.98 | Elapsed: 0.07s
WARNING:root: [*] Fri Dec 23 18:35:40 2022: Train Epoch: 3 [6400 /50750 (13%)]	Loss: 0.065286 | F1-score: 0.98 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 18:35:47 2022: Train Epoch: 3 [12800/50750 (25%)]	Loss: 0.175606 | F1-score: 0.97 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 18:35:55 2022: Train Epoch: 3 [19200/50750 (38%)]	Loss: 0.105139 | F1-score: 0.97 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 18:36:02 2022: Train Epoch: 3 [25600/50750 (50%)]	Loss: 0.046995 | F1-score: 0.97 | Elapsed: 7.22s
WARNING:root: [*] Fri Dec 23 18:36:09 2022: Train Epoch: 3 [32000/50750 (63%)]	Loss: 0.106596 | F1-score: 0.97 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 18:36:16 2022: Train Epoch: 3 [38400/50750 (76%)]	Loss: 0.184938 | F1-score: 0.97 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 18:36:24 2022: Train Epoch: 3 [44800/50750 (88%)]	Loss: 0.085369 | F1-score: 0.97 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 18:36:30 2022:    3    | Tr.loss: 0.087716 | Tr.F1.:   0.97    |   57.40  s
WARNING:root:
        [!] Fri Dec 23 18:36:30 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671816990-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671816990-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671816990-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671816990-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 18:36:39 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.696363 | F1-score: 0.61 | Elapsed: 0.11s
WARNING:root: [*] Fri Dec 23 18:36:46 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.277016 | F1-score: 0.86 | Elapsed: 7.26s
WARNING:root: [*] Fri Dec 23 18:36:54 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.180533 | F1-score: 0.89 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 18:37:01 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.242912 | F1-score: 0.91 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 18:37:08 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.149760 | F1-score: 0.92 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 18:37:15 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.075494 | F1-score: 0.93 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 18:37:23 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.248711 | F1-score: 0.94 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 18:37:30 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.188396 | F1-score: 0.94 | Elapsed: 7.26s
WARNING:root: [*] Fri Dec 23 18:37:37 2022:    1    | Tr.loss: 0.188531 | Tr.F1.:   0.94    |   57.48  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 18:37:37 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.216308 | F1-score: 0.92 | Elapsed: 0.09s
WARNING:root: [*] Fri Dec 23 18:37:44 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.022700 | F1-score: 0.97 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 18:37:51 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.124765 | F1-score: 0.97 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 18:37:58 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.158714 | F1-score: 0.97 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 18:38:06 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.153038 | F1-score: 0.97 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 18:38:13 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.066827 | F1-score: 0.97 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 18:38:20 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.055995 | F1-score: 0.97 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 18:38:27 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.023779 | F1-score: 0.97 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 18:38:34 2022:    2    | Tr.loss: 0.103005 | Tr.F1.:   0.97    |   57.45  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 18:38:34 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.131742 | F1-score: 0.99 | Elapsed: 0.07s
WARNING:root: [*] Fri Dec 23 18:38:41 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.047422 | F1-score: 0.97 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 18:38:49 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.056324 | F1-score: 0.97 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 18:38:56 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.026548 | F1-score: 0.97 | Elapsed: 7.26s
WARNING:root: [*] Fri Dec 23 18:39:03 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.148030 | F1-score: 0.97 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 18:39:10 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.120719 | F1-score: 0.97 | Elapsed: 7.27s
WARNING:root: [*] Fri Dec 23 18:39:18 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.033512 | F1-score: 0.97 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 18:39:25 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.052823 | F1-score: 0.97 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 18:39:31 2022:    3    | Tr.loss: 0.088384 | Tr.F1.:   0.97    |   57.45  s
WARNING:root:
        [!] Fri Dec 23 18:39:31 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671817171-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671817171-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671817171-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671817171-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 18:39:40 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.722286 | F1-score: 0.28 | Elapsed: 0.11s
WARNING:root: [*] Fri Dec 23 18:39:48 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.238790 | F1-score: 0.87 | Elapsed: 7.26s
WARNING:root: [*] Fri Dec 23 18:39:55 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.309140 | F1-score: 0.90 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 18:40:02 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.134463 | F1-score: 0.92 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 18:40:09 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.149003 | F1-score: 0.93 | Elapsed: 7.27s
WARNING:root: [*] Fri Dec 23 18:40:17 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.073813 | F1-score: 0.93 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 18:40:24 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.102818 | F1-score: 0.94 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 18:40:31 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.103926 | F1-score: 0.94 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 18:40:38 2022:    1    | Tr.loss: 0.184155 | Tr.F1.:   0.94    |   57.55  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 18:40:38 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.232455 | F1-score: 0.89 | Elapsed: 0.08s
WARNING:root: [*] Fri Dec 23 18:40:45 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.084225 | F1-score: 0.97 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 18:40:52 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.080536 | F1-score: 0.97 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 18:41:00 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.204552 | F1-score: 0.97 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 18:41:07 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.065883 | F1-score: 0.97 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 18:41:14 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.089760 | F1-score: 0.97 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 18:41:21 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.191019 | F1-score: 0.97 | Elapsed: 7.26s
WARNING:root: [*] Fri Dec 23 18:41:29 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.065108 | F1-score: 0.97 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 18:41:35 2022:    2    | Tr.loss: 0.099521 | Tr.F1.:   0.97    |   57.45  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 18:41:35 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.087482 | F1-score: 0.98 | Elapsed: 0.07s
WARNING:root: [*] Fri Dec 23 18:41:43 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.045208 | F1-score: 0.98 | Elapsed: 7.26s
WARNING:root: [*] Fri Dec 23 18:41:50 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.037340 | F1-score: 0.98 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 18:41:57 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.319110 | F1-score: 0.98 | Elapsed: 7.26s
WARNING:root: [*] Fri Dec 23 18:42:04 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.169123 | F1-score: 0.97 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 18:42:12 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.048531 | F1-score: 0.97 | Elapsed: 7.26s
WARNING:root: [*] Fri Dec 23 18:42:19 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.174143 | F1-score: 0.97 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 18:42:26 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.177138 | F1-score: 0.97 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 18:42:33 2022:    3    | Tr.loss: 0.085179 | Tr.F1.:   0.97    |   57.47  s
WARNING:root:
        [!] Fri Dec 23 18:42:33 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671817353-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671817353-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671817353-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671817353-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\metrics_trainSize_76126_ep_3_cv_3_maxLen_2048_vocabSize_1500_embeddingDim_64_hiddenNeurons_512_256_128_batchNormConv_False_batchNormFFNN_False_filterSizes_2_3_4_5.json
WARNING:root: [!] Average epoch time: 57.39s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.4130 -- F1: 0.5819
	FPR:  0.001 -- TPR: 0.8778 -- F1: 0.9346
	FPR:   0.01 -- TPR: 0.9494 -- F1: 0.9717
	FPR:    0.1 -- TPR: 0.9897 -- F1: 0.9715

WARNING:root: [!] Using vocabSize: 1500 | maxLen: 4096
WARNING:root: [!] Using device: cuda:0 | Dataset size: 76126
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 1500, 'embeddingDim': 64, 'hiddenNeurons': [512, 256, 128], 'batchNormConv': False, 'batchNormFFNN': False, 'filterSizes': [2, 3, 4, 5]}
WARNING:root: [!] Fold 1/3 | Train set size: 50750, Validation set size: 25376
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 18:43:13 2022: Train Epoch: 1 [  0  /50750 (0 %)]	Loss: 0.718313 | F1-score: 0.35 | Elapsed: 0.35s
WARNING:root: [*] Fri Dec 23 18:43:27 2022: Train Epoch: 1 [6400 /50750 (13%)]	Loss: 0.212123 | F1-score: 0.87 | Elapsed: 14.03s
WARNING:root: [*] Fri Dec 23 18:43:42 2022: Train Epoch: 1 [12800/50750 (25%)]	Loss: 0.332072 | F1-score: 0.90 | Elapsed: 14.18s
WARNING:root: [*] Fri Dec 23 18:43:56 2022: Train Epoch: 1 [19200/50750 (38%)]	Loss: 0.114256 | F1-score: 0.92 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 18:44:10 2022: Train Epoch: 1 [25600/50750 (50%)]	Loss: 0.228026 | F1-score: 0.93 | Elapsed: 14.20s
WARNING:root: [*] Fri Dec 23 18:44:24 2022: Train Epoch: 1 [32000/50750 (63%)]	Loss: 0.102877 | F1-score: 0.93 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 18:44:38 2022: Train Epoch: 1 [38400/50750 (76%)]	Loss: 0.061280 | F1-score: 0.94 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 18:44:53 2022: Train Epoch: 1 [44800/50750 (88%)]	Loss: 0.229251 | F1-score: 0.94 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 18:45:06 2022:    1    | Tr.loss: 0.185552 | Tr.F1.:   0.94    |  112.71  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 18:45:06 2022: Train Epoch: 2 [  0  /50750 (0 %)]	Loss: 0.178741 | F1-score: 0.95 | Elapsed: 0.15s
WARNING:root: [*] Fri Dec 23 18:45:20 2022: Train Epoch: 2 [6400 /50750 (13%)]	Loss: 0.099044 | F1-score: 0.97 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 18:45:34 2022: Train Epoch: 2 [12800/50750 (25%)]	Loss: 0.167179 | F1-score: 0.97 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 18:45:48 2022: Train Epoch: 2 [19200/50750 (38%)]	Loss: 0.065489 | F1-score: 0.97 | Elapsed: 14.20s
WARNING:root: [*] Fri Dec 23 18:46:03 2022: Train Epoch: 2 [25600/50750 (50%)]	Loss: 0.159120 | F1-score: 0.97 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 18:46:17 2022: Train Epoch: 2 [32000/50750 (63%)]	Loss: 0.114567 | F1-score: 0.97 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 18:46:31 2022: Train Epoch: 2 [38400/50750 (76%)]	Loss: 0.044962 | F1-score: 0.97 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 18:46:45 2022: Train Epoch: 2 [44800/50750 (88%)]	Loss: 0.184599 | F1-score: 0.97 | Elapsed: 14.20s
WARNING:root: [*] Fri Dec 23 18:46:58 2022:    2    | Tr.loss: 0.101492 | Tr.F1.:   0.97    |  112.74  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 18:46:59 2022: Train Epoch: 3 [  0  /50750 (0 %)]	Loss: 0.021079 | F1-score: 1.00 | Elapsed: 0.15s
WARNING:root: [*] Fri Dec 23 18:47:13 2022: Train Epoch: 3 [6400 /50750 (13%)]	Loss: 0.162127 | F1-score: 0.97 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 18:47:27 2022: Train Epoch: 3 [12800/50750 (25%)]	Loss: 0.081095 | F1-score: 0.97 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 18:47:41 2022: Train Epoch: 3 [19200/50750 (38%)]	Loss: 0.083976 | F1-score: 0.97 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 18:47:55 2022: Train Epoch: 3 [25600/50750 (50%)]	Loss: 0.104175 | F1-score: 0.97 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 18:48:10 2022: Train Epoch: 3 [32000/50750 (63%)]	Loss: 0.052145 | F1-score: 0.97 | Elapsed: 14.25s
WARNING:root: [*] Fri Dec 23 18:48:24 2022: Train Epoch: 3 [38400/50750 (76%)]	Loss: 0.046158 | F1-score: 0.97 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 18:48:38 2022: Train Epoch: 3 [44800/50750 (88%)]	Loss: 0.078298 | F1-score: 0.97 | Elapsed: 14.25s
WARNING:root: [*] Fri Dec 23 18:48:51 2022:    3    | Tr.loss: 0.084265 | Tr.F1.:   0.97    |  112.84  s
WARNING:root:
        [!] Fri Dec 23 18:48:51 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671817731-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671817731-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671817731-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671817731-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 18:49:09 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.705218 | F1-score: 0.42 | Elapsed: 0.19s
WARNING:root: [*] Fri Dec 23 18:49:23 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.256965 | F1-score: 0.87 | Elapsed: 14.24s
WARNING:root: [*] Fri Dec 23 18:49:37 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.093029 | F1-score: 0.90 | Elapsed: 14.25s
WARNING:root: [*] Fri Dec 23 18:49:52 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.081460 | F1-score: 0.92 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 18:50:06 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.144210 | F1-score: 0.93 | Elapsed: 14.25s
WARNING:root: [*] Fri Dec 23 18:50:20 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.140434 | F1-score: 0.94 | Elapsed: 14.27s
WARNING:root: [*] Fri Dec 23 18:50:34 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.132169 | F1-score: 0.94 | Elapsed: 14.25s
WARNING:root: [*] Fri Dec 23 18:50:49 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.141576 | F1-score: 0.94 | Elapsed: 14.28s
WARNING:root: [*] Fri Dec 23 18:51:02 2022:    1    | Tr.loss: 0.184028 | Tr.F1.:   0.95    |  113.09  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 18:51:02 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.175692 | F1-score: 0.97 | Elapsed: 0.14s
WARNING:root: [*] Fri Dec 23 18:51:16 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.114894 | F1-score: 0.97 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 18:51:30 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.084251 | F1-score: 0.97 | Elapsed: 14.26s
WARNING:root: [*] Fri Dec 23 18:51:45 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.078204 | F1-score: 0.97 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 18:51:59 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.154912 | F1-score: 0.97 | Elapsed: 14.25s
WARNING:root: [*] Fri Dec 23 18:52:13 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.077220 | F1-score: 0.97 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 18:52:27 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.214400 | F1-score: 0.97 | Elapsed: 14.27s
WARNING:root: [*] Fri Dec 23 18:52:42 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.049571 | F1-score: 0.97 | Elapsed: 14.26s
WARNING:root: [*] Fri Dec 23 18:52:55 2022:    2    | Tr.loss: 0.102275 | Tr.F1.:   0.97    |  112.94  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 18:52:55 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.085163 | F1-score: 0.97 | Elapsed: 0.16s
WARNING:root: [*] Fri Dec 23 18:53:09 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.049505 | F1-score: 0.97 | Elapsed: 14.30s
WARNING:root: [*] Fri Dec 23 18:53:23 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.108467 | F1-score: 0.97 | Elapsed: 14.28s
WARNING:root: [*] Fri Dec 23 18:53:38 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.055853 | F1-score: 0.97 | Elapsed: 14.27s
WARNING:root: [*] Fri Dec 23 18:53:52 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.112444 | F1-score: 0.97 | Elapsed: 14.24s
WARNING:root: [*] Fri Dec 23 18:54:06 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.022032 | F1-score: 0.97 | Elapsed: 14.25s
WARNING:root: [*] Fri Dec 23 18:54:20 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.086664 | F1-score: 0.97 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 18:54:35 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.046872 | F1-score: 0.97 | Elapsed: 14.24s
WARNING:root: [*] Fri Dec 23 18:54:48 2022:    3    | Tr.loss: 0.087438 | Tr.F1.:   0.97    |  113.08  s
WARNING:root:
        [!] Fri Dec 23 18:54:48 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671818088-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671818088-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671818088-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671818088-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 18:55:05 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.702576 | F1-score: 0.57 | Elapsed: 0.18s
WARNING:root: [*] Fri Dec 23 18:55:20 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.253247 | F1-score: 0.86 | Elapsed: 14.24s
WARNING:root: [*] Fri Dec 23 18:55:34 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.115425 | F1-score: 0.90 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 18:55:48 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.072320 | F1-score: 0.92 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 18:56:02 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.244263 | F1-score: 0.93 | Elapsed: 14.25s
WARNING:root: [*] Fri Dec 23 18:56:17 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.115870 | F1-score: 0.93 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 18:56:31 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.020379 | F1-score: 0.94 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 18:56:45 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.094387 | F1-score: 0.94 | Elapsed: 14.24s
WARNING:root: [*] Fri Dec 23 18:56:58 2022:    1    | Tr.loss: 0.188980 | Tr.F1.:   0.94    |  112.91  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 18:56:58 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.061980 | F1-score: 0.98 | Elapsed: 0.14s
WARNING:root: [*] Fri Dec 23 18:57:13 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.074332 | F1-score: 0.97 | Elapsed: 14.24s
WARNING:root: [*] Fri Dec 23 18:57:27 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.062029 | F1-score: 0.97 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 18:57:41 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.135785 | F1-score: 0.97 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 18:57:55 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.073805 | F1-score: 0.97 | Elapsed: 14.24s
WARNING:root: [*] Fri Dec 23 18:58:09 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.158044 | F1-score: 0.97 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 18:58:24 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.041314 | F1-score: 0.97 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 18:58:38 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.033672 | F1-score: 0.97 | Elapsed: 14.25s
WARNING:root: [*] Fri Dec 23 18:58:51 2022:    2    | Tr.loss: 0.103501 | Tr.F1.:   0.97    |  112.86  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 18:58:51 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.095666 | F1-score: 0.96 | Elapsed: 0.16s
WARNING:root: [*] Fri Dec 23 18:59:05 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.062045 | F1-score: 0.97 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 18:59:20 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.100651 | F1-score: 0.97 | Elapsed: 14.27s
WARNING:root: [*] Fri Dec 23 18:59:34 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.140295 | F1-score: 0.97 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 18:59:48 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.015246 | F1-score: 0.97 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 19:00:02 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.084349 | F1-score: 0.97 | Elapsed: 14.26s
WARNING:root: [*] Fri Dec 23 19:00:17 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.083263 | F1-score: 0.97 | Elapsed: 14.25s
WARNING:root: [*] Fri Dec 23 19:00:31 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.073509 | F1-score: 0.97 | Elapsed: 14.24s
WARNING:root: [*] Fri Dec 23 19:00:44 2022:    3    | Tr.loss: 0.086816 | Tr.F1.:   0.97    |  112.96  s
WARNING:root:
        [!] Fri Dec 23 19:00:44 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671818444-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671818444-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671818444-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671818444-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\metrics_trainSize_76126_ep_3_cv_3_maxLen_4096_vocabSize_1500_embeddingDim_64_hiddenNeurons_512_256_128_batchNormConv_False_batchNormFFNN_False_filterSizes_2_3_4_5.json
WARNING:root: [!] Average epoch time: 112.90s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.4730 -- F1: 0.6404
	FPR:  0.001 -- TPR: 0.8647 -- F1: 0.9259
	FPR:   0.01 -- TPR: 0.9473 -- F1: 0.9707
	FPR:    0.1 -- TPR: 0.9910 -- F1: 0.9721

WARNING:root: [!] Using vocabSize: 1500 | maxLen: 512
WARNING:root: [!] Using device: cuda:0 | Dataset size: 76126
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 1500, 'embeddingDim': 64, 'hiddenNeurons': [512, 256, 128], 'batchNormConv': False, 'batchNormFFNN': False, 'filterSizes': [2, 3, 4, 5]}
WARNING:root: [!] Fold 1/3 | Train set size: 50750, Validation set size: 25376
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 19:01:31 2022: Train Epoch: 1 [  0  /50750 (0 %)]	Loss: 0.637424 | F1-score: 0.84 | Elapsed: 0.20s
WARNING:root: [*] Fri Dec 23 19:01:34 2022: Train Epoch: 1 [6400 /50750 (13%)]	Loss: 0.353556 | F1-score: 0.89 | Elapsed: 2.21s
WARNING:root: [*] Fri Dec 23 19:01:36 2022: Train Epoch: 1 [12800/50750 (25%)]	Loss: 0.173589 | F1-score: 0.91 | Elapsed: 2.18s
WARNING:root: [*] Fri Dec 23 19:01:38 2022: Train Epoch: 1 [19200/50750 (38%)]	Loss: 0.145476 | F1-score: 0.92 | Elapsed: 2.17s
WARNING:root: [*] Fri Dec 23 19:01:40 2022: Train Epoch: 1 [25600/50750 (50%)]	Loss: 0.170097 | F1-score: 0.93 | Elapsed: 2.20s
WARNING:root: [*] Fri Dec 23 19:01:42 2022: Train Epoch: 1 [32000/50750 (63%)]	Loss: 0.209484 | F1-score: 0.93 | Elapsed: 2.19s
WARNING:root: [*] Fri Dec 23 19:01:44 2022: Train Epoch: 1 [38400/50750 (76%)]	Loss: 0.119623 | F1-score: 0.94 | Elapsed: 2.20s
WARNING:root: [*] Fri Dec 23 19:01:47 2022: Train Epoch: 1 [44800/50750 (88%)]	Loss: 0.361419 | F1-score: 0.94 | Elapsed: 2.22s
WARNING:root: [*] Fri Dec 23 19:01:49 2022:    1    | Tr.loss: 0.196773 | Tr.F1.:   0.94    |   17.60  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 19:01:49 2022: Train Epoch: 2 [  0  /50750 (0 %)]	Loss: 0.146041 | F1-score: 0.95 | Elapsed: 0.01s
WARNING:root: [*] Fri Dec 23 19:01:51 2022: Train Epoch: 2 [6400 /50750 (13%)]	Loss: 0.100429 | F1-score: 0.96 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 19:01:53 2022: Train Epoch: 2 [12800/50750 (25%)]	Loss: 0.065363 | F1-score: 0.96 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 19:01:55 2022: Train Epoch: 2 [19200/50750 (38%)]	Loss: 0.148519 | F1-score: 0.96 | Elapsed: 2.22s
WARNING:root: [*] Fri Dec 23 19:01:58 2022: Train Epoch: 2 [25600/50750 (50%)]	Loss: 0.144048 | F1-score: 0.96 | Elapsed: 2.21s
WARNING:root: [*] Fri Dec 23 19:02:00 2022: Train Epoch: 2 [32000/50750 (63%)]	Loss: 0.198333 | F1-score: 0.96 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 19:02:02 2022: Train Epoch: 2 [38400/50750 (76%)]	Loss: 0.117521 | F1-score: 0.96 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 19:02:04 2022: Train Epoch: 2 [44800/50750 (88%)]	Loss: 0.095961 | F1-score: 0.96 | Elapsed: 2.22s
WARNING:root: [*] Fri Dec 23 19:02:06 2022:    2    | Tr.loss: 0.120848 | Tr.F1.:   0.96    |   17.65  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 19:02:06 2022: Train Epoch: 3 [  0  /50750 (0 %)]	Loss: 0.082188 | F1-score: 0.98 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 19:02:09 2022: Train Epoch: 3 [6400 /50750 (13%)]	Loss: 0.102446 | F1-score: 0.96 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 19:02:11 2022: Train Epoch: 3 [12800/50750 (25%)]	Loss: 0.193818 | F1-score: 0.97 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 19:02:13 2022: Train Epoch: 3 [19200/50750 (38%)]	Loss: 0.109945 | F1-score: 0.97 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 19:02:15 2022: Train Epoch: 3 [25600/50750 (50%)]	Loss: 0.063377 | F1-score: 0.97 | Elapsed: 2.22s
WARNING:root: [*] Fri Dec 23 19:02:18 2022: Train Epoch: 3 [32000/50750 (63%)]	Loss: 0.070106 | F1-score: 0.97 | Elapsed: 2.21s
WARNING:root: [*] Fri Dec 23 19:02:20 2022: Train Epoch: 3 [38400/50750 (76%)]	Loss: 0.042319 | F1-score: 0.97 | Elapsed: 2.22s
WARNING:root: [*] Fri Dec 23 19:02:22 2022: Train Epoch: 3 [44800/50750 (88%)]	Loss: 0.036990 | F1-score: 0.97 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 19:02:24 2022:    3    | Tr.loss: 0.105419 | Tr.F1.:   0.97    |   17.70  s
WARNING:root:
        [!] Fri Dec 23 19:02:24 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671818544-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671818544-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671818544-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671818544-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 19:02:27 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.702194 | F1-score: 0.46 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 19:02:29 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.297671 | F1-score: 0.88 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 19:02:31 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.216371 | F1-score: 0.91 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 19:02:33 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.241901 | F1-score: 0.92 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 19:02:35 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.163867 | F1-score: 0.93 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 19:02:38 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.043561 | F1-score: 0.93 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 19:02:40 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.238752 | F1-score: 0.94 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 19:02:42 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.138860 | F1-score: 0.94 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 19:02:44 2022:    1    | Tr.loss: 0.200427 | Tr.F1.:   0.94    |   17.74  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 19:02:44 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.245538 | F1-score: 0.96 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 19:02:46 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.131734 | F1-score: 0.96 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 19:02:49 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.133508 | F1-score: 0.96 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 19:02:51 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.107833 | F1-score: 0.96 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 19:02:53 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.076527 | F1-score: 0.96 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 19:02:55 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.174075 | F1-score: 0.96 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 19:02:58 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.056050 | F1-score: 0.96 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 19:03:00 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.151360 | F1-score: 0.96 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 19:03:02 2022:    2    | Tr.loss: 0.120266 | Tr.F1.:   0.96    |   17.79  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 19:03:02 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.078506 | F1-score: 0.96 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 19:03:04 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.165462 | F1-score: 0.96 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 19:03:07 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.051137 | F1-score: 0.97 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 19:03:09 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.079564 | F1-score: 0.97 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 19:03:11 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.041839 | F1-score: 0.97 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 19:03:13 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.160905 | F1-score: 0.97 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 19:03:15 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.041832 | F1-score: 0.97 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 19:03:18 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.098783 | F1-score: 0.97 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 19:03:20 2022:    3    | Tr.loss: 0.103436 | Tr.F1.:   0.97    |   17.78  s
WARNING:root:
        [!] Fri Dec 23 19:03:20 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671818600-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671818600-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671818600-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671818600-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 19:03:22 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.731663 | F1-score: 0.22 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 19:03:25 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.202465 | F1-score: 0.89 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 19:03:27 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.198658 | F1-score: 0.91 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 19:03:29 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.106295 | F1-score: 0.92 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 19:03:31 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.297961 | F1-score: 0.93 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 19:03:33 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.051698 | F1-score: 0.93 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 19:03:36 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.115237 | F1-score: 0.94 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 19:03:38 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.169443 | F1-score: 0.94 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 19:03:40 2022:    1    | Tr.loss: 0.199648 | Tr.F1.:   0.94    |   17.84  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 19:03:40 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.110782 | F1-score: 0.97 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 19:03:42 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.055560 | F1-score: 0.96 | Elapsed: 2.26s
WARNING:root: [*] Fri Dec 23 19:03:45 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.238764 | F1-score: 0.96 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 19:03:47 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.089799 | F1-score: 0.96 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 19:03:49 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.209895 | F1-score: 0.96 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 19:03:51 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.196553 | F1-score: 0.96 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 19:03:54 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.169837 | F1-score: 0.96 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 19:03:56 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.072057 | F1-score: 0.96 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 19:03:58 2022:    2    | Tr.loss: 0.124332 | Tr.F1.:   0.96    |   17.80  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 19:03:58 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.104415 | F1-score: 0.97 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 19:04:00 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.157140 | F1-score: 0.97 | Elapsed: 2.26s
WARNING:root: [*] Fri Dec 23 19:04:02 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.153487 | F1-score: 0.97 | Elapsed: 2.22s
WARNING:root: [*] Fri Dec 23 19:04:05 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.102047 | F1-score: 0.97 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 19:04:07 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.157834 | F1-score: 0.97 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 19:04:09 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.035417 | F1-score: 0.97 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 19:04:11 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.064418 | F1-score: 0.97 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 19:04:14 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.120015 | F1-score: 0.97 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 19:04:16 2022:    3    | Tr.loss: 0.106714 | Tr.F1.:   0.97    |   17.83  s
WARNING:root:
        [!] Fri Dec 23 19:04:16 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671818656-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671818656-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671818656-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671818656-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\metrics_trainSize_76126_ep_3_cv_3_maxLen_512_vocabSize_1500_embeddingDim_64_hiddenNeurons_512_256_128_batchNormConv_False_batchNormFFNN_False_filterSizes_2_3_4_5.json
WARNING:root: [!] Average epoch time: 17.75s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.4361 -- F1: 0.6049
	FPR:  0.001 -- TPR: 0.8103 -- F1: 0.8946
	FPR:   0.01 -- TPR: 0.9222 -- F1: 0.9573
	FPR:    0.1 -- TPR: 0.9824 -- F1: 0.9680

WARNING:root: [!] Using vocabSize: 2000 | maxLen: 1024
WARNING:root: [!] Using device: cuda:0 | Dataset size: 76126
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 2000, 'embeddingDim': 64, 'hiddenNeurons': [512, 256, 128], 'batchNormConv': False, 'batchNormFFNN': False, 'filterSizes': [2, 3, 4, 5]}
WARNING:root: [!] Fold 1/3 | Train set size: 50750, Validation set size: 25376
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 19:04:49 2022: Train Epoch: 1 [  0  /50750 (0 %)]	Loss: 0.693019 | F1-score: 0.67 | Elapsed: 0.31s
WARNING:root: [*] Fri Dec 23 19:04:52 2022: Train Epoch: 1 [6400 /50750 (13%)]	Loss: 0.216738 | F1-score: 0.87 | Elapsed: 3.82s
WARNING:root: [*] Fri Dec 23 19:04:56 2022: Train Epoch: 1 [12800/50750 (25%)]	Loss: 0.237986 | F1-score: 0.91 | Elapsed: 3.79s
WARNING:root: [*] Fri Dec 23 19:05:00 2022: Train Epoch: 1 [19200/50750 (38%)]	Loss: 0.167426 | F1-score: 0.92 | Elapsed: 3.80s
WARNING:root: [*] Fri Dec 23 19:05:04 2022: Train Epoch: 1 [25600/50750 (50%)]	Loss: 0.166559 | F1-score: 0.93 | Elapsed: 3.80s
WARNING:root: [*] Fri Dec 23 19:05:08 2022: Train Epoch: 1 [32000/50750 (63%)]	Loss: 0.059804 | F1-score: 0.93 | Elapsed: 3.82s
WARNING:root: [*] Fri Dec 23 19:05:11 2022: Train Epoch: 1 [38400/50750 (76%)]	Loss: 0.071557 | F1-score: 0.94 | Elapsed: 3.84s
WARNING:root: [*] Fri Dec 23 19:05:15 2022: Train Epoch: 1 [44800/50750 (88%)]	Loss: 0.127161 | F1-score: 0.94 | Elapsed: 3.85s
WARNING:root: [*] Fri Dec 23 19:05:19 2022:    1    | Tr.loss: 0.187727 | Tr.F1.:   0.94    |   30.60  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 19:05:19 2022: Train Epoch: 2 [  0  /50750 (0 %)]	Loss: 0.218189 | F1-score: 0.91 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 19:05:23 2022: Train Epoch: 2 [6400 /50750 (13%)]	Loss: 0.073425 | F1-score: 0.96 | Elapsed: 3.89s
WARNING:root: [*] Fri Dec 23 19:05:27 2022: Train Epoch: 2 [12800/50750 (25%)]	Loss: 0.043603 | F1-score: 0.97 | Elapsed: 3.86s
WARNING:root: [*] Fri Dec 23 19:05:31 2022: Train Epoch: 2 [19200/50750 (38%)]	Loss: 0.111292 | F1-score: 0.97 | Elapsed: 3.86s
WARNING:root: [*] Fri Dec 23 19:05:34 2022: Train Epoch: 2 [25600/50750 (50%)]	Loss: 0.042364 | F1-score: 0.97 | Elapsed: 3.86s
WARNING:root: [*] Fri Dec 23 19:05:38 2022: Train Epoch: 2 [32000/50750 (63%)]	Loss: 0.079184 | F1-score: 0.97 | Elapsed: 3.86s
WARNING:root: [*] Fri Dec 23 19:05:42 2022: Train Epoch: 2 [38400/50750 (76%)]	Loss: 0.071722 | F1-score: 0.97 | Elapsed: 3.87s
WARNING:root: [*] Fri Dec 23 19:05:46 2022: Train Epoch: 2 [44800/50750 (88%)]	Loss: 0.134885 | F1-score: 0.97 | Elapsed: 3.84s
WARNING:root: [*] Fri Dec 23 19:05:50 2022:    2    | Tr.loss: 0.105460 | Tr.F1.:   0.97    |   30.67  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 19:05:50 2022: Train Epoch: 3 [  0  /50750 (0 %)]	Loss: 0.157794 | F1-score: 0.97 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 19:05:53 2022: Train Epoch: 3 [6400 /50750 (13%)]	Loss: 0.081029 | F1-score: 0.97 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 19:05:57 2022: Train Epoch: 3 [12800/50750 (25%)]	Loss: 0.070972 | F1-score: 0.97 | Elapsed: 3.87s
WARNING:root: [*] Fri Dec 23 19:06:01 2022: Train Epoch: 3 [19200/50750 (38%)]	Loss: 0.137759 | F1-score: 0.97 | Elapsed: 3.85s
WARNING:root: [*] Fri Dec 23 19:06:05 2022: Train Epoch: 3 [25600/50750 (50%)]	Loss: 0.102856 | F1-score: 0.97 | Elapsed: 3.87s
WARNING:root: [*] Fri Dec 23 19:06:09 2022: Train Epoch: 3 [32000/50750 (63%)]	Loss: 0.186329 | F1-score: 0.97 | Elapsed: 3.85s
WARNING:root: [*] Fri Dec 23 19:06:13 2022: Train Epoch: 3 [38400/50750 (76%)]	Loss: 0.271581 | F1-score: 0.97 | Elapsed: 3.89s
WARNING:root: [*] Fri Dec 23 19:06:17 2022: Train Epoch: 3 [44800/50750 (88%)]	Loss: 0.071682 | F1-score: 0.97 | Elapsed: 3.86s
WARNING:root: [*] Fri Dec 23 19:06:20 2022:    3    | Tr.loss: 0.092153 | Tr.F1.:   0.97    |   30.70  s
WARNING:root:
        [!] Fri Dec 23 19:06:20 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671818780-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671818780-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671818780-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671818780-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 19:06:25 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.659535 | F1-score: 0.80 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 19:06:29 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.294036 | F1-score: 0.88 | Elapsed: 3.88s
WARNING:root: [*] Fri Dec 23 19:06:33 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.257837 | F1-score: 0.91 | Elapsed: 3.85s
WARNING:root: [*] Fri Dec 23 19:06:37 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.121051 | F1-score: 0.92 | Elapsed: 3.89s
WARNING:root: [*] Fri Dec 23 19:06:40 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.159586 | F1-score: 0.93 | Elapsed: 3.88s
WARNING:root: [*] Fri Dec 23 19:06:44 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.129262 | F1-score: 0.94 | Elapsed: 3.87s
WARNING:root: [*] Fri Dec 23 19:06:48 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.206736 | F1-score: 0.94 | Elapsed: 3.88s
WARNING:root: [*] Fri Dec 23 19:06:52 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.207565 | F1-score: 0.94 | Elapsed: 3.87s
WARNING:root: [*] Fri Dec 23 19:06:56 2022:    1    | Tr.loss: 0.187145 | Tr.F1.:   0.95    |   30.76  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 19:06:56 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.075118 | F1-score: 0.98 | Elapsed: 0.05s
WARNING:root: [*] Fri Dec 23 19:07:00 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.160163 | F1-score: 0.97 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 19:07:03 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.246241 | F1-score: 0.97 | Elapsed: 3.88s
WARNING:root: [*] Fri Dec 23 19:07:07 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.085983 | F1-score: 0.96 | Elapsed: 3.87s
WARNING:root: [*] Fri Dec 23 19:07:11 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.126342 | F1-score: 0.97 | Elapsed: 3.89s
WARNING:root: [*] Fri Dec 23 19:07:15 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.090875 | F1-score: 0.97 | Elapsed: 3.88s
WARNING:root: [*] Fri Dec 23 19:07:19 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.089651 | F1-score: 0.97 | Elapsed: 3.87s
WARNING:root: [*] Fri Dec 23 19:07:23 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.055166 | F1-score: 0.97 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 19:07:26 2022:    2    | Tr.loss: 0.108462 | Tr.F1.:   0.97    |   30.82  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 19:07:26 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.026518 | F1-score: 1.00 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 19:07:30 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.080457 | F1-score: 0.97 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 19:07:34 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.042432 | F1-score: 0.97 | Elapsed: 3.88s
WARNING:root: [*] Fri Dec 23 19:07:38 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.038737 | F1-score: 0.97 | Elapsed: 3.89s
WARNING:root: [*] Fri Dec 23 19:07:42 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.163806 | F1-score: 0.97 | Elapsed: 3.87s
WARNING:root: [*] Fri Dec 23 19:07:46 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.056599 | F1-score: 0.97 | Elapsed: 3.87s
WARNING:root: [*] Fri Dec 23 19:07:50 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.092312 | F1-score: 0.97 | Elapsed: 3.89s
WARNING:root: [*] Fri Dec 23 19:07:54 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.020624 | F1-score: 0.97 | Elapsed: 3.88s
WARNING:root: [*] Fri Dec 23 19:07:57 2022:    3    | Tr.loss: 0.093285 | Tr.F1.:   0.97    |   30.79  s
WARNING:root:
        [!] Fri Dec 23 19:07:57 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671818877-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671818877-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671818877-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671818877-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 19:08:02 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.692365 | F1-score: 0.56 | Elapsed: 0.05s
WARNING:root: [*] Fri Dec 23 19:08:06 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.233894 | F1-score: 0.88 | Elapsed: 3.91s
WARNING:root: [*] Fri Dec 23 19:08:10 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.181876 | F1-score: 0.91 | Elapsed: 3.91s
WARNING:root: [*] Fri Dec 23 19:08:14 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.266315 | F1-score: 0.92 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 19:08:17 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.139380 | F1-score: 0.93 | Elapsed: 3.87s
WARNING:root: [*] Fri Dec 23 19:08:21 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.132945 | F1-score: 0.93 | Elapsed: 3.88s
WARNING:root: [*] Fri Dec 23 19:08:25 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.090868 | F1-score: 0.94 | Elapsed: 3.88s
WARNING:root: [*] Fri Dec 23 19:08:29 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.122684 | F1-score: 0.94 | Elapsed: 3.89s
WARNING:root: [*] Fri Dec 23 19:08:33 2022:    1    | Tr.loss: 0.185110 | Tr.F1.:   0.94    |   30.87  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 19:08:33 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.133170 | F1-score: 0.94 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 19:08:37 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.158569 | F1-score: 0.96 | Elapsed: 3.89s
WARNING:root: [*] Fri Dec 23 19:08:41 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.132760 | F1-score: 0.96 | Elapsed: 3.88s
WARNING:root: [*] Fri Dec 23 19:08:44 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.135460 | F1-score: 0.96 | Elapsed: 3.88s
WARNING:root: [*] Fri Dec 23 19:08:48 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.056213 | F1-score: 0.97 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 19:08:52 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.104219 | F1-score: 0.97 | Elapsed: 3.88s
WARNING:root: [*] Fri Dec 23 19:08:56 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.166327 | F1-score: 0.97 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 19:09:00 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.053346 | F1-score: 0.97 | Elapsed: 3.89s
WARNING:root: [*] Fri Dec 23 19:09:04 2022:    2    | Tr.loss: 0.103307 | Tr.F1.:   0.97    |   30.86  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 19:09:04 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.049125 | F1-score: 0.99 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 19:09:08 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.161974 | F1-score: 0.97 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 19:09:11 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.052254 | F1-score: 0.97 | Elapsed: 3.88s
WARNING:root: [*] Fri Dec 23 19:09:15 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.055684 | F1-score: 0.97 | Elapsed: 3.91s
WARNING:root: [*] Fri Dec 23 19:09:19 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.101657 | F1-score: 0.97 | Elapsed: 3.88s
WARNING:root: [*] Fri Dec 23 19:09:23 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.177809 | F1-score: 0.97 | Elapsed: 3.89s
WARNING:root: [*] Fri Dec 23 19:09:27 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.029181 | F1-score: 0.97 | Elapsed: 3.89s
WARNING:root: [*] Fri Dec 23 19:09:31 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.092874 | F1-score: 0.97 | Elapsed: 3.87s
WARNING:root: [*] Fri Dec 23 19:09:34 2022:    3    | Tr.loss: 0.090465 | Tr.F1.:   0.97    |   30.85  s
WARNING:root:
        [!] Fri Dec 23 19:09:34 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671818974-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671818974-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671818974-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671818974-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\metrics_trainSize_76126_ep_3_cv_3_maxLen_1024_vocabSize_2000_embeddingDim_64_hiddenNeurons_512_256_128_batchNormConv_False_batchNormFFNN_False_filterSizes_2_3_4_5.json
WARNING:root: [!] Average epoch time: 30.77s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.3385 -- F1: 0.5044
	FPR:  0.001 -- TPR: 0.8235 -- F1: 0.9013
	FPR:   0.01 -- TPR: 0.9371 -- F1: 0.9652
	FPR:    0.1 -- TPR: 0.9874 -- F1: 0.9703

WARNING:root: [!] Using vocabSize: 2000 | maxLen: 2048
WARNING:root: [!] Using device: cuda:0 | Dataset size: 76126
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 2000, 'embeddingDim': 64, 'hiddenNeurons': [512, 256, 128], 'batchNormConv': False, 'batchNormFFNN': False, 'filterSizes': [2, 3, 4, 5]}
WARNING:root: [!] Fold 1/3 | Train set size: 50750, Validation set size: 25376
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 19:10:10 2022: Train Epoch: 1 [  0  /50750 (0 %)]	Loss: 0.732527 | F1-score: 0.09 | Elapsed: 0.29s
WARNING:root: [*] Fri Dec 23 19:10:17 2022: Train Epoch: 1 [6400 /50750 (13%)]	Loss: 0.266115 | F1-score: 0.86 | Elapsed: 7.07s
WARNING:root: [*] Fri Dec 23 19:10:24 2022: Train Epoch: 1 [12800/50750 (25%)]	Loss: 0.105223 | F1-score: 0.90 | Elapsed: 7.10s
WARNING:root: [*] Fri Dec 23 19:10:31 2022: Train Epoch: 1 [19200/50750 (38%)]	Loss: 0.210474 | F1-score: 0.92 | Elapsed: 7.11s
WARNING:root: [*] Fri Dec 23 19:10:38 2022: Train Epoch: 1 [25600/50750 (50%)]	Loss: 0.123428 | F1-score: 0.93 | Elapsed: 7.15s
WARNING:root: [*] Fri Dec 23 19:10:45 2022: Train Epoch: 1 [32000/50750 (63%)]	Loss: 0.151450 | F1-score: 0.94 | Elapsed: 7.20s
WARNING:root: [*] Fri Dec 23 19:10:53 2022: Train Epoch: 1 [38400/50750 (76%)]	Loss: 0.167782 | F1-score: 0.94 | Elapsed: 7.19s
WARNING:root: [*] Fri Dec 23 19:11:00 2022: Train Epoch: 1 [44800/50750 (88%)]	Loss: 0.148594 | F1-score: 0.94 | Elapsed: 7.19s
WARNING:root: [*] Fri Dec 23 19:11:06 2022:    1    | Tr.loss: 0.181811 | Tr.F1.:   0.95    |   56.91  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 19:11:06 2022: Train Epoch: 2 [  0  /50750 (0 %)]	Loss: 0.137409 | F1-score: 0.96 | Elapsed: 0.08s
WARNING:root: [*] Fri Dec 23 19:11:14 2022: Train Epoch: 2 [6400 /50750 (13%)]	Loss: 0.213172 | F1-score: 0.97 | Elapsed: 7.21s
WARNING:root: [*] Fri Dec 23 19:11:21 2022: Train Epoch: 2 [12800/50750 (25%)]	Loss: 0.059305 | F1-score: 0.97 | Elapsed: 7.21s
WARNING:root: [*] Fri Dec 23 19:11:28 2022: Train Epoch: 2 [19200/50750 (38%)]	Loss: 0.069886 | F1-score: 0.97 | Elapsed: 7.20s
WARNING:root: [*] Fri Dec 23 19:11:35 2022: Train Epoch: 2 [25600/50750 (50%)]	Loss: 0.118476 | F1-score: 0.97 | Elapsed: 7.21s
WARNING:root: [*] Fri Dec 23 19:11:42 2022: Train Epoch: 2 [32000/50750 (63%)]	Loss: 0.146041 | F1-score: 0.97 | Elapsed: 7.20s
WARNING:root: [*] Fri Dec 23 19:11:50 2022: Train Epoch: 2 [38400/50750 (76%)]	Loss: 0.125530 | F1-score: 0.97 | Elapsed: 7.20s
WARNING:root: [*] Fri Dec 23 19:11:57 2022: Train Epoch: 2 [44800/50750 (88%)]	Loss: 0.065092 | F1-score: 0.97 | Elapsed: 7.21s
WARNING:root: [*] Fri Dec 23 19:12:03 2022:    2    | Tr.loss: 0.095589 | Tr.F1.:   0.97    |   57.15  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 19:12:04 2022: Train Epoch: 3 [  0  /50750 (0 %)]	Loss: 0.042662 | F1-score: 0.99 | Elapsed: 0.08s
WARNING:root: [*] Fri Dec 23 19:12:11 2022: Train Epoch: 3 [6400 /50750 (13%)]	Loss: 0.019946 | F1-score: 0.98 | Elapsed: 7.21s
WARNING:root: [*] Fri Dec 23 19:12:18 2022: Train Epoch: 3 [12800/50750 (25%)]	Loss: 0.070406 | F1-score: 0.98 | Elapsed: 7.21s
WARNING:root: [*] Fri Dec 23 19:12:25 2022: Train Epoch: 3 [19200/50750 (38%)]	Loss: 0.045104 | F1-score: 0.98 | Elapsed: 7.22s
WARNING:root: [*] Fri Dec 23 19:12:32 2022: Train Epoch: 3 [25600/50750 (50%)]	Loss: 0.116128 | F1-score: 0.98 | Elapsed: 7.19s
WARNING:root: [*] Fri Dec 23 19:12:40 2022: Train Epoch: 3 [32000/50750 (63%)]	Loss: 0.042459 | F1-score: 0.98 | Elapsed: 7.22s
WARNING:root: [*] Fri Dec 23 19:12:47 2022: Train Epoch: 3 [38400/50750 (76%)]	Loss: 0.040845 | F1-score: 0.98 | Elapsed: 7.22s
WARNING:root: [*] Fri Dec 23 19:12:54 2022: Train Epoch: 3 [44800/50750 (88%)]	Loss: 0.204564 | F1-score: 0.98 | Elapsed: 7.22s
WARNING:root: [*] Fri Dec 23 19:13:01 2022:    3    | Tr.loss: 0.082096 | Tr.F1.:   0.98    |   57.20  s
WARNING:root:
        [!] Fri Dec 23 19:13:01 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671819181-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671819181-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671819181-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671819181-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 19:13:10 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.685331 | F1-score: 0.69 | Elapsed: 0.11s
WARNING:root: [*] Fri Dec 23 19:13:17 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.217793 | F1-score: 0.87 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 19:13:24 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.163527 | F1-score: 0.90 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 19:13:31 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.192987 | F1-score: 0.92 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 19:13:38 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.063557 | F1-score: 0.93 | Elapsed: 7.22s
WARNING:root: [*] Fri Dec 23 19:13:46 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.095524 | F1-score: 0.93 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 19:13:53 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.075039 | F1-score: 0.94 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 19:14:00 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.123948 | F1-score: 0.94 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 19:14:07 2022:    1    | Tr.loss: 0.181728 | Tr.F1.:   0.95    |   57.38  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 19:14:07 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.092043 | F1-score: 0.99 | Elapsed: 0.07s
WARNING:root: [*] Fri Dec 23 19:14:14 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.135368 | F1-score: 0.97 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 19:14:21 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.123390 | F1-score: 0.97 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 19:14:29 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.043731 | F1-score: 0.97 | Elapsed: 7.22s
WARNING:root: [*] Fri Dec 23 19:14:36 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.173933 | F1-score: 0.97 | Elapsed: 7.22s
WARNING:root: [*] Fri Dec 23 19:14:43 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.089217 | F1-score: 0.97 | Elapsed: 7.21s
WARNING:root: [*] Fri Dec 23 19:14:50 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.198088 | F1-score: 0.97 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 19:14:58 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.039585 | F1-score: 0.97 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 19:15:04 2022:    2    | Tr.loss: 0.100318 | Tr.F1.:   0.97    |   57.31  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 19:15:04 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.047162 | F1-score: 0.97 | Elapsed: 0.09s
WARNING:root: [*] Fri Dec 23 19:15:11 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.215687 | F1-score: 0.98 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 19:15:19 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.060266 | F1-score: 0.97 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 19:15:26 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.014737 | F1-score: 0.98 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 19:15:33 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.047137 | F1-score: 0.98 | Elapsed: 7.21s
WARNING:root: [*] Fri Dec 23 19:15:40 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.063881 | F1-score: 0.98 | Elapsed: 7.22s
WARNING:root: [*] Fri Dec 23 19:15:48 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.072174 | F1-score: 0.98 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 19:15:55 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.058492 | F1-score: 0.98 | Elapsed: 7.22s
WARNING:root: [*] Fri Dec 23 19:16:01 2022:    3    | Tr.loss: 0.083783 | Tr.F1.:   0.98    |   57.33  s
WARNING:root:
        [!] Fri Dec 23 19:16:02 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671819361-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671819361-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671819361-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671819361-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 19:16:10 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.696197 | F1-score: 0.56 | Elapsed: 0.11s
WARNING:root: [*] Fri Dec 23 19:16:18 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.159901 | F1-score: 0.87 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 19:16:25 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.319580 | F1-score: 0.90 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 19:16:32 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.143883 | F1-score: 0.92 | Elapsed: 7.22s
WARNING:root: [*] Fri Dec 23 19:16:39 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.067560 | F1-score: 0.93 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 19:16:47 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.125966 | F1-score: 0.94 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 19:16:54 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.036399 | F1-score: 0.94 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 19:17:01 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.143103 | F1-score: 0.94 | Elapsed: 7.21s
WARNING:root: [*] Fri Dec 23 19:17:08 2022:    1    | Tr.loss: 0.179787 | Tr.F1.:   0.95    |   57.42  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 19:17:08 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.085626 | F1-score: 0.98 | Elapsed: 0.07s
WARNING:root: [*] Fri Dec 23 19:17:15 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.051264 | F1-score: 0.97 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 19:17:22 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.044748 | F1-score: 0.97 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 19:17:30 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.119498 | F1-score: 0.97 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 19:17:37 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.146894 | F1-score: 0.97 | Elapsed: 7.21s
WARNING:root: [*] Fri Dec 23 19:17:44 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.077530 | F1-score: 0.97 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 19:17:51 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.051778 | F1-score: 0.97 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 19:17:58 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.081298 | F1-score: 0.97 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 19:18:05 2022:    2    | Tr.loss: 0.094852 | Tr.F1.:   0.97    |   57.38  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 19:18:05 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.184527 | F1-score: 0.97 | Elapsed: 0.07s
WARNING:root: [*] Fri Dec 23 19:18:12 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.078694 | F1-score: 0.97 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 19:18:20 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.127773 | F1-score: 0.97 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 19:18:27 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.080410 | F1-score: 0.97 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 19:18:34 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.198582 | F1-score: 0.97 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 19:18:41 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.052872 | F1-score: 0.97 | Elapsed: 7.22s
WARNING:root: [*] Fri Dec 23 19:18:49 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.102408 | F1-score: 0.97 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 19:18:56 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.038252 | F1-score: 0.98 | Elapsed: 7.22s
WARNING:root: [*] Fri Dec 23 19:19:02 2022:    3    | Tr.loss: 0.078247 | Tr.F1.:   0.98    |   57.34  s
WARNING:root:
        [!] Fri Dec 23 19:19:02 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671819542-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671819542-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671819542-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671819542-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\metrics_trainSize_76126_ep_3_cv_3_maxLen_2048_vocabSize_2000_embeddingDim_64_hiddenNeurons_512_256_128_batchNormConv_False_batchNormFFNN_False_filterSizes_2_3_4_5.json
WARNING:root: [!] Average epoch time: 57.27s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.2512 -- F1: 0.3625
	FPR:  0.001 -- TPR: 0.8535 -- F1: 0.9204
	FPR:   0.01 -- TPR: 0.9476 -- F1: 0.9708
	FPR:    0.1 -- TPR: 0.9929 -- F1: 0.9733

WARNING:root: [!] Using vocabSize: 2000 | maxLen: 4096
WARNING:root: [!] Using device: cuda:0 | Dataset size: 76126
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 2000, 'embeddingDim': 64, 'hiddenNeurons': [512, 256, 128], 'batchNormConv': False, 'batchNormFFNN': False, 'filterSizes': [2, 3, 4, 5]}
WARNING:root: [!] Fold 1/3 | Train set size: 50750, Validation set size: 25376
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 19:19:43 2022: Train Epoch: 1 [  0  /50750 (0 %)]	Loss: 0.685043 | F1-score: 0.72 | Elapsed: 0.46s
WARNING:root: [*] Fri Dec 23 19:19:57 2022: Train Epoch: 1 [6400 /50750 (13%)]	Loss: 0.210092 | F1-score: 0.87 | Elapsed: 14.16s
WARNING:root: [*] Fri Dec 23 19:20:11 2022: Train Epoch: 1 [12800/50750 (25%)]	Loss: 0.126901 | F1-score: 0.91 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 19:20:25 2022: Train Epoch: 1 [19200/50750 (38%)]	Loss: 0.189855 | F1-score: 0.92 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 19:20:39 2022: Train Epoch: 1 [25600/50750 (50%)]	Loss: 0.081178 | F1-score: 0.93 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 19:20:54 2022: Train Epoch: 1 [32000/50750 (63%)]	Loss: 0.194918 | F1-score: 0.94 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 19:21:08 2022: Train Epoch: 1 [38400/50750 (76%)]	Loss: 0.131206 | F1-score: 0.94 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 19:21:22 2022: Train Epoch: 1 [44800/50750 (88%)]	Loss: 0.207537 | F1-score: 0.95 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 19:21:35 2022:    1    | Tr.loss: 0.178529 | Tr.F1.:   0.95    |  113.00  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 19:21:35 2022: Train Epoch: 2 [  0  /50750 (0 %)]	Loss: 0.074194 | F1-score: 0.97 | Elapsed: 0.13s
WARNING:root: [*] Fri Dec 23 19:21:49 2022: Train Epoch: 2 [6400 /50750 (13%)]	Loss: 0.131988 | F1-score: 0.97 | Elapsed: 14.24s
WARNING:root: [*] Fri Dec 23 19:22:04 2022: Train Epoch: 2 [12800/50750 (25%)]	Loss: 0.070820 | F1-score: 0.97 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 19:22:18 2022: Train Epoch: 2 [19200/50750 (38%)]	Loss: 0.082583 | F1-score: 0.97 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 19:22:32 2022: Train Epoch: 2 [25600/50750 (50%)]	Loss: 0.141573 | F1-score: 0.97 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 19:22:46 2022: Train Epoch: 2 [32000/50750 (63%)]	Loss: 0.135423 | F1-score: 0.97 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 19:23:01 2022: Train Epoch: 2 [38400/50750 (76%)]	Loss: 0.047413 | F1-score: 0.97 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 19:23:15 2022: Train Epoch: 2 [44800/50750 (88%)]	Loss: 0.062328 | F1-score: 0.97 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 19:23:28 2022:    2    | Tr.loss: 0.093746 | Tr.F1.:   0.97    |  112.79  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 19:23:28 2022: Train Epoch: 3 [  0  /50750 (0 %)]	Loss: 0.046908 | F1-score: 0.99 | Elapsed: 0.14s
WARNING:root: [*] Fri Dec 23 19:23:42 2022: Train Epoch: 3 [6400 /50750 (13%)]	Loss: 0.067736 | F1-score: 0.97 | Elapsed: 14.25s
WARNING:root: [*] Fri Dec 23 19:23:57 2022: Train Epoch: 3 [12800/50750 (25%)]	Loss: 0.133360 | F1-score: 0.97 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 19:24:11 2022: Train Epoch: 3 [19200/50750 (38%)]	Loss: 0.077242 | F1-score: 0.97 | Elapsed: 14.20s
WARNING:root: [*] Fri Dec 23 19:24:25 2022: Train Epoch: 3 [25600/50750 (50%)]	Loss: 0.108693 | F1-score: 0.97 | Elapsed: 14.24s
WARNING:root: [*] Fri Dec 23 19:24:39 2022: Train Epoch: 3 [32000/50750 (63%)]	Loss: 0.058576 | F1-score: 0.97 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 19:24:53 2022: Train Epoch: 3 [38400/50750 (76%)]	Loss: 0.180812 | F1-score: 0.98 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 19:25:08 2022: Train Epoch: 3 [44800/50750 (88%)]	Loss: 0.084026 | F1-score: 0.97 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 19:25:21 2022:    3    | Tr.loss: 0.080303 | Tr.F1.:   0.98    |  112.85  s
WARNING:root:
        [!] Fri Dec 23 19:25:21 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671819921-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671819921-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671819921-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671819921-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 19:25:38 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.687796 | F1-score: 0.71 | Elapsed: 0.16s
WARNING:root: [*] Fri Dec 23 19:25:53 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.248096 | F1-score: 0.87 | Elapsed: 14.26s
WARNING:root: [*] Fri Dec 23 19:26:07 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.261417 | F1-score: 0.90 | Elapsed: 14.27s
WARNING:root: [*] Fri Dec 23 19:26:21 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.105807 | F1-score: 0.92 | Elapsed: 14.25s
WARNING:root: [*] Fri Dec 23 19:26:36 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.235597 | F1-score: 0.93 | Elapsed: 14.26s
WARNING:root: [*] Fri Dec 23 19:26:50 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.180148 | F1-score: 0.94 | Elapsed: 14.26s
WARNING:root: [*] Fri Dec 23 19:27:04 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.200735 | F1-score: 0.94 | Elapsed: 14.24s
WARNING:root: [*] Fri Dec 23 19:27:18 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.017651 | F1-score: 0.94 | Elapsed: 14.25s
WARNING:root: [*] Fri Dec 23 19:27:31 2022:    1    | Tr.loss: 0.181568 | Tr.F1.:   0.95    |  113.09  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 19:27:32 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.051577 | F1-score: 0.99 | Elapsed: 0.14s
WARNING:root: [*] Fri Dec 23 19:27:46 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.116754 | F1-score: 0.97 | Elapsed: 14.27s
WARNING:root: [*] Fri Dec 23 19:28:00 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.069156 | F1-score: 0.97 | Elapsed: 14.28s
WARNING:root: [*] Fri Dec 23 19:28:14 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.040732 | F1-score: 0.97 | Elapsed: 14.25s
WARNING:root: [*] Fri Dec 23 19:28:29 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.099350 | F1-score: 0.97 | Elapsed: 14.27s
WARNING:root: [*] Fri Dec 23 19:28:43 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.083247 | F1-score: 0.97 | Elapsed: 14.26s
WARNING:root: [*] Fri Dec 23 19:28:57 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.164722 | F1-score: 0.97 | Elapsed: 14.25s
WARNING:root: [*] Fri Dec 23 19:29:11 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.140271 | F1-score: 0.97 | Elapsed: 14.24s
WARNING:root: [*] Fri Dec 23 19:29:24 2022:    2    | Tr.loss: 0.097479 | Tr.F1.:   0.97    |  113.06  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 19:29:25 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.068679 | F1-score: 0.98 | Elapsed: 0.14s
WARNING:root: [*] Fri Dec 23 19:29:39 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.124031 | F1-score: 0.98 | Elapsed: 14.26s
WARNING:root: [*] Fri Dec 23 19:29:53 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.090832 | F1-score: 0.98 | Elapsed: 14.27s
WARNING:root: [*] Fri Dec 23 19:30:07 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.090660 | F1-score: 0.98 | Elapsed: 14.26s
WARNING:root: [*] Fri Dec 23 19:30:22 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.016209 | F1-score: 0.98 | Elapsed: 14.26s
WARNING:root: [*] Fri Dec 23 19:30:36 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.083749 | F1-score: 0.98 | Elapsed: 14.24s
WARNING:root: [*] Fri Dec 23 19:30:50 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.039389 | F1-score: 0.98 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 19:31:04 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.082244 | F1-score: 0.98 | Elapsed: 14.27s
WARNING:root: [*] Fri Dec 23 19:31:17 2022:    3    | Tr.loss: 0.082521 | Tr.F1.:   0.98    |  113.03  s
WARNING:root:
        [!] Fri Dec 23 19:31:18 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671820277-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671820277-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671820277-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671820277-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 19:31:35 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.688773 | F1-score: 0.64 | Elapsed: 0.16s
WARNING:root: [*] Fri Dec 23 19:31:49 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.161882 | F1-score: 0.88 | Elapsed: 14.25s
WARNING:root: [*] Fri Dec 23 19:32:04 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.152160 | F1-score: 0.91 | Elapsed: 14.24s
WARNING:root: [*] Fri Dec 23 19:32:18 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.049890 | F1-score: 0.92 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 19:32:32 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.178665 | F1-score: 0.93 | Elapsed: 14.28s
WARNING:root: [*] Fri Dec 23 19:32:46 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.162443 | F1-score: 0.94 | Elapsed: 14.26s
WARNING:root: [*] Fri Dec 23 19:33:01 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.241680 | F1-score: 0.94 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 19:33:15 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.067483 | F1-score: 0.95 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 19:33:28 2022:    1    | Tr.loss: 0.177862 | Tr.F1.:   0.95    |  112.98  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 19:33:28 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.091998 | F1-score: 0.98 | Elapsed: 0.14s
WARNING:root: [*] Fri Dec 23 19:33:42 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.158917 | F1-score: 0.97 | Elapsed: 14.25s
WARNING:root: [*] Fri Dec 23 19:33:57 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.094003 | F1-score: 0.97 | Elapsed: 14.25s
WARNING:root: [*] Fri Dec 23 19:34:11 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.067656 | F1-score: 0.97 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 19:34:25 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.061345 | F1-score: 0.97 | Elapsed: 14.25s
WARNING:root: [*] Fri Dec 23 19:34:39 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.055244 | F1-score: 0.97 | Elapsed: 14.24s
WARNING:root: [*] Fri Dec 23 19:34:54 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.080103 | F1-score: 0.97 | Elapsed: 14.26s
WARNING:root: [*] Fri Dec 23 19:35:08 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.078687 | F1-score: 0.97 | Elapsed: 14.28s
WARNING:root: [*] Fri Dec 23 19:35:21 2022:    2    | Tr.loss: 0.095488 | Tr.F1.:   0.97    |  113.02  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 19:35:21 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.057246 | F1-score: 0.98 | Elapsed: 0.14s
WARNING:root: [*] Fri Dec 23 19:35:35 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.044733 | F1-score: 0.97 | Elapsed: 14.27s
WARNING:root: [*] Fri Dec 23 19:35:50 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.231787 | F1-score: 0.98 | Elapsed: 14.26s
WARNING:root: [*] Fri Dec 23 19:36:04 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.070526 | F1-score: 0.98 | Elapsed: 14.24s
WARNING:root: [*] Fri Dec 23 19:36:18 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.046556 | F1-score: 0.98 | Elapsed: 14.24s
WARNING:root: [*] Fri Dec 23 19:36:32 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.045587 | F1-score: 0.98 | Elapsed: 14.26s
WARNING:root: [*] Fri Dec 23 19:36:47 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.154928 | F1-score: 0.98 | Elapsed: 14.24s
WARNING:root: [*] Fri Dec 23 19:37:01 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.025121 | F1-score: 0.98 | Elapsed: 14.25s
WARNING:root: [*] Fri Dec 23 19:37:14 2022:    3    | Tr.loss: 0.081134 | Tr.F1.:   0.98    |  113.01  s
WARNING:root:
        [!] Fri Dec 23 19:37:14 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671820634-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671820634-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671820634-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671820634-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\metrics_trainSize_76126_ep_3_cv_3_maxLen_4096_vocabSize_2000_embeddingDim_64_hiddenNeurons_512_256_128_batchNormConv_False_batchNormFFNN_False_filterSizes_2_3_4_5.json
WARNING:root: [!] Average epoch time: 112.98s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.4463 -- F1: 0.6103
	FPR:  0.001 -- TPR: 0.8588 -- F1: 0.9234
	FPR:   0.01 -- TPR: 0.9481 -- F1: 0.9711
	FPR:    0.1 -- TPR: 0.9908 -- F1: 0.9720

WARNING:root: [!] Using vocabSize: 2000 | maxLen: 512
WARNING:root: [!] Using device: cuda:0 | Dataset size: 76126
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 2000, 'embeddingDim': 64, 'hiddenNeurons': [512, 256, 128], 'batchNormConv': False, 'batchNormFFNN': False, 'filterSizes': [2, 3, 4, 5]}
WARNING:root: [!] Fold 1/3 | Train set size: 50750, Validation set size: 25376
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 19:38:02 2022: Train Epoch: 1 [  0  /50750 (0 %)]	Loss: 0.706314 | F1-score: 0.54 | Elapsed: 0.20s
WARNING:root: [*] Fri Dec 23 19:38:04 2022: Train Epoch: 1 [6400 /50750 (13%)]	Loss: 0.209422 | F1-score: 0.88 | Elapsed: 2.38s
WARNING:root: [*] Fri Dec 23 19:38:06 2022: Train Epoch: 1 [12800/50750 (25%)]	Loss: 0.168032 | F1-score: 0.91 | Elapsed: 2.19s
WARNING:root: [*] Fri Dec 23 19:38:09 2022: Train Epoch: 1 [19200/50750 (38%)]	Loss: 0.172562 | F1-score: 0.92 | Elapsed: 2.20s
WARNING:root: [*] Fri Dec 23 19:38:11 2022: Train Epoch: 1 [25600/50750 (50%)]	Loss: 0.073868 | F1-score: 0.93 | Elapsed: 2.21s
WARNING:root: [*] Fri Dec 23 19:38:13 2022: Train Epoch: 1 [32000/50750 (63%)]	Loss: 0.173113 | F1-score: 0.93 | Elapsed: 2.22s
WARNING:root: [*] Fri Dec 23 19:38:15 2022: Train Epoch: 1 [38400/50750 (76%)]	Loss: 0.194956 | F1-score: 0.94 | Elapsed: 2.21s
WARNING:root: [*] Fri Dec 23 19:38:17 2022: Train Epoch: 1 [44800/50750 (88%)]	Loss: 0.198864 | F1-score: 0.94 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 19:38:20 2022:    1    | Tr.loss: 0.198176 | Tr.F1.:   0.94    |   17.89  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 19:38:20 2022: Train Epoch: 2 [  0  /50750 (0 %)]	Loss: 0.119466 | F1-score: 0.94 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 19:38:22 2022: Train Epoch: 2 [6400 /50750 (13%)]	Loss: 0.042102 | F1-score: 0.96 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 19:38:24 2022: Train Epoch: 2 [12800/50750 (25%)]	Loss: 0.127323 | F1-score: 0.96 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 19:38:26 2022: Train Epoch: 2 [19200/50750 (38%)]	Loss: 0.155240 | F1-score: 0.96 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 19:38:28 2022: Train Epoch: 2 [25600/50750 (50%)]	Loss: 0.076972 | F1-score: 0.96 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 19:38:31 2022: Train Epoch: 2 [32000/50750 (63%)]	Loss: 0.071802 | F1-score: 0.96 | Elapsed: 2.22s
WARNING:root: [*] Fri Dec 23 19:38:33 2022: Train Epoch: 2 [38400/50750 (76%)]	Loss: 0.180744 | F1-score: 0.96 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 19:38:35 2022: Train Epoch: 2 [44800/50750 (88%)]	Loss: 0.061789 | F1-score: 0.97 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 19:38:37 2022:    2    | Tr.loss: 0.114086 | Tr.F1.:   0.96    |   17.72  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 19:38:37 2022: Train Epoch: 3 [  0  /50750 (0 %)]	Loss: 0.052900 | F1-score: 0.98 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 19:38:39 2022: Train Epoch: 3 [6400 /50750 (13%)]	Loss: 0.133449 | F1-score: 0.97 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 19:38:42 2022: Train Epoch: 3 [12800/50750 (25%)]	Loss: 0.053894 | F1-score: 0.97 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 19:38:44 2022: Train Epoch: 3 [19200/50750 (38%)]	Loss: 0.311915 | F1-score: 0.97 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 19:38:46 2022: Train Epoch: 3 [25600/50750 (50%)]	Loss: 0.059239 | F1-score: 0.97 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 19:38:48 2022: Train Epoch: 3 [32000/50750 (63%)]	Loss: 0.081271 | F1-score: 0.97 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 19:38:51 2022: Train Epoch: 3 [38400/50750 (76%)]	Loss: 0.040206 | F1-score: 0.97 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 19:38:53 2022: Train Epoch: 3 [44800/50750 (88%)]	Loss: 0.086143 | F1-score: 0.97 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 19:38:55 2022:    3    | Tr.loss: 0.096842 | Tr.F1.:   0.97    |   17.73  s
WARNING:root:
        [!] Fri Dec 23 19:38:55 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671820735-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671820735-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671820735-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671820735-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 19:38:57 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.743372 | F1-score: 0.15 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 19:39:00 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.152925 | F1-score: 0.87 | Elapsed: 2.28s
WARNING:root: [*] Fri Dec 23 19:39:02 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.171898 | F1-score: 0.91 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 19:39:04 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.180282 | F1-score: 0.92 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 19:39:06 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.336787 | F1-score: 0.93 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 19:39:09 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.127334 | F1-score: 0.93 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 19:39:11 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.121230 | F1-score: 0.94 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 19:39:13 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.102441 | F1-score: 0.94 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 19:39:15 2022:    1    | Tr.loss: 0.190943 | Tr.F1.:   0.94    |   17.81  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 19:39:15 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.155584 | F1-score: 0.94 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 19:39:17 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.193347 | F1-score: 0.97 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 19:39:20 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.092123 | F1-score: 0.97 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 19:39:22 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.219769 | F1-score: 0.97 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 19:39:24 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.108768 | F1-score: 0.97 | Elapsed: 2.26s
WARNING:root: [*] Fri Dec 23 19:39:26 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.131059 | F1-score: 0.97 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 19:39:29 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.110407 | F1-score: 0.97 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 19:39:31 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.057399 | F1-score: 0.97 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 19:39:33 2022:    2    | Tr.loss: 0.116641 | Tr.F1.:   0.96    |   17.85  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 19:39:33 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.061231 | F1-score: 0.99 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 19:39:35 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.032918 | F1-score: 0.97 | Elapsed: 2.28s
WARNING:root: [*] Fri Dec 23 19:39:38 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.077918 | F1-score: 0.97 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 19:39:40 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.116429 | F1-score: 0.97 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 19:39:42 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.161606 | F1-score: 0.97 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 19:39:44 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.118101 | F1-score: 0.97 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 19:39:47 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.061939 | F1-score: 0.97 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 19:39:49 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.115840 | F1-score: 0.97 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 19:39:51 2022:    3    | Tr.loss: 0.100322 | Tr.F1.:   0.97    |   17.85  s
WARNING:root:
        [!] Fri Dec 23 19:39:51 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671820791-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671820791-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671820791-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671820791-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 19:39:53 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.713735 | F1-score: 0.50 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 19:39:56 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.248403 | F1-score: 0.88 | Elapsed: 2.30s
WARNING:root: [*] Fri Dec 23 19:39:58 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.177603 | F1-score: 0.91 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 19:40:00 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.132841 | F1-score: 0.92 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 19:40:02 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.166616 | F1-score: 0.93 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 19:40:05 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.072020 | F1-score: 0.94 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 19:40:07 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.058916 | F1-score: 0.94 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 19:40:09 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.057891 | F1-score: 0.94 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 19:40:11 2022:    1    | Tr.loss: 0.187985 | Tr.F1.:   0.95    |   17.90  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 19:40:11 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.022019 | F1-score: 1.00 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 19:40:13 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.123650 | F1-score: 0.97 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 19:40:16 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.149895 | F1-score: 0.96 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 19:40:18 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.085389 | F1-score: 0.96 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 19:40:20 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.044479 | F1-score: 0.96 | Elapsed: 2.29s
WARNING:root: [*] Fri Dec 23 19:40:22 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.070660 | F1-score: 0.97 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 19:40:25 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.111998 | F1-score: 0.97 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 19:40:27 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.142878 | F1-score: 0.97 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 19:40:29 2022:    2    | Tr.loss: 0.112608 | Tr.F1.:   0.97    |   17.93  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 19:40:29 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.061494 | F1-score: 0.99 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 19:40:31 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.177111 | F1-score: 0.97 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 19:40:34 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.134399 | F1-score: 0.97 | Elapsed: 2.26s
WARNING:root: [*] Fri Dec 23 19:40:36 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.174692 | F1-score: 0.97 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 19:40:38 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.032707 | F1-score: 0.97 | Elapsed: 2.26s
WARNING:root: [*] Fri Dec 23 19:40:40 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.232520 | F1-score: 0.97 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 19:40:43 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.035975 | F1-score: 0.97 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 19:40:45 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.120199 | F1-score: 0.97 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 19:40:47 2022:    3    | Tr.loss: 0.098587 | Tr.F1.:   0.97    |   17.86  s
WARNING:root:
        [!] Fri Dec 23 19:40:47 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671820847-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671820847-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671820847-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671820847-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\metrics_trainSize_76126_ep_3_cv_3_maxLen_512_vocabSize_2000_embeddingDim_64_hiddenNeurons_512_256_128_batchNormConv_False_batchNormFFNN_False_filterSizes_2_3_4_5.json
WARNING:root: [!] Average epoch time: 17.84s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.4214 -- F1: 0.5813
	FPR:  0.001 -- TPR: 0.8419 -- F1: 0.9133
	FPR:   0.01 -- TPR: 0.9254 -- F1: 0.9589
	FPR:    0.1 -- TPR: 0.9854 -- F1: 0.9694

WARNING:root: [!] Using vocabSize: 2500 | maxLen: 1024
WARNING:root: [!] Using device: cuda:0 | Dataset size: 76126
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 2500, 'embeddingDim': 64, 'hiddenNeurons': [512, 256, 128], 'batchNormConv': False, 'batchNormFFNN': False, 'filterSizes': [2, 3, 4, 5]}
WARNING:root: [!] Fold 1/3 | Train set size: 50750, Validation set size: 25376
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 19:41:20 2022: Train Epoch: 1 [  0  /50750 (0 %)]	Loss: 0.753062 | F1-score: 0.29 | Elapsed: 0.24s
WARNING:root: [*] Fri Dec 23 19:41:24 2022: Train Epoch: 1 [6400 /50750 (13%)]	Loss: 0.275521 | F1-score: 0.87 | Elapsed: 3.82s
WARNING:root: [*] Fri Dec 23 19:41:27 2022: Train Epoch: 1 [12800/50750 (25%)]	Loss: 0.149279 | F1-score: 0.91 | Elapsed: 3.80s
WARNING:root: [*] Fri Dec 23 19:41:31 2022: Train Epoch: 1 [19200/50750 (38%)]	Loss: 0.068491 | F1-score: 0.92 | Elapsed: 3.81s
WARNING:root: [*] Fri Dec 23 19:41:35 2022: Train Epoch: 1 [25600/50750 (50%)]	Loss: 0.102222 | F1-score: 0.93 | Elapsed: 3.81s
WARNING:root: [*] Fri Dec 23 19:41:39 2022: Train Epoch: 1 [32000/50750 (63%)]	Loss: 0.134894 | F1-score: 0.94 | Elapsed: 3.83s
WARNING:root: [*] Fri Dec 23 19:41:43 2022: Train Epoch: 1 [38400/50750 (76%)]	Loss: 0.110733 | F1-score: 0.94 | Elapsed: 3.84s
WARNING:root: [*] Fri Dec 23 19:41:47 2022: Train Epoch: 1 [44800/50750 (88%)]	Loss: 0.227207 | F1-score: 0.94 | Elapsed: 3.83s
WARNING:root: [*] Fri Dec 23 19:41:50 2022:    1    | Tr.loss: 0.179423 | Tr.F1.:   0.95    |   30.54  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 19:41:50 2022: Train Epoch: 2 [  0  /50750 (0 %)]	Loss: 0.096638 | F1-score: 0.98 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 19:41:54 2022: Train Epoch: 2 [6400 /50750 (13%)]	Loss: 0.096825 | F1-score: 0.97 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 19:41:58 2022: Train Epoch: 2 [12800/50750 (25%)]	Loss: 0.041271 | F1-score: 0.97 | Elapsed: 3.86s
WARNING:root: [*] Fri Dec 23 19:42:02 2022: Train Epoch: 2 [19200/50750 (38%)]	Loss: 0.109998 | F1-score: 0.97 | Elapsed: 3.86s
WARNING:root: [*] Fri Dec 23 19:42:06 2022: Train Epoch: 2 [25600/50750 (50%)]	Loss: 0.064090 | F1-score: 0.97 | Elapsed: 3.86s
WARNING:root: [*] Fri Dec 23 19:42:09 2022: Train Epoch: 2 [32000/50750 (63%)]	Loss: 0.083263 | F1-score: 0.97 | Elapsed: 3.86s
WARNING:root: [*] Fri Dec 23 19:42:13 2022: Train Epoch: 2 [38400/50750 (76%)]	Loss: 0.129702 | F1-score: 0.97 | Elapsed: 3.88s
WARNING:root: [*] Fri Dec 23 19:42:17 2022: Train Epoch: 2 [44800/50750 (88%)]	Loss: 0.104994 | F1-score: 0.97 | Elapsed: 3.88s
WARNING:root: [*] Fri Dec 23 19:42:21 2022:    2    | Tr.loss: 0.097266 | Tr.F1.:   0.97    |   30.68  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 19:42:21 2022: Train Epoch: 3 [  0  /50750 (0 %)]	Loss: 0.073022 | F1-score: 0.97 | Elapsed: 0.05s
WARNING:root: [*] Fri Dec 23 19:42:25 2022: Train Epoch: 3 [6400 /50750 (13%)]	Loss: 0.074924 | F1-score: 0.98 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 19:42:29 2022: Train Epoch: 3 [12800/50750 (25%)]	Loss: 0.084103 | F1-score: 0.97 | Elapsed: 3.86s
WARNING:root: [*] Fri Dec 23 19:42:32 2022: Train Epoch: 3 [19200/50750 (38%)]	Loss: 0.076842 | F1-score: 0.97 | Elapsed: 3.87s
WARNING:root: [*] Fri Dec 23 19:42:36 2022: Train Epoch: 3 [25600/50750 (50%)]	Loss: 0.144351 | F1-score: 0.97 | Elapsed: 3.86s
WARNING:root: [*] Fri Dec 23 19:42:40 2022: Train Epoch: 3 [32000/50750 (63%)]	Loss: 0.182387 | F1-score: 0.97 | Elapsed: 3.87s
WARNING:root: [*] Fri Dec 23 19:42:44 2022: Train Epoch: 3 [38400/50750 (76%)]	Loss: 0.056270 | F1-score: 0.97 | Elapsed: 3.88s
WARNING:root: [*] Fri Dec 23 19:42:48 2022: Train Epoch: 3 [44800/50750 (88%)]	Loss: 0.085712 | F1-score: 0.97 | Elapsed: 3.86s
WARNING:root: [*] Fri Dec 23 19:42:51 2022:    3    | Tr.loss: 0.086992 | Tr.F1.:   0.97    |   30.71  s
WARNING:root:
        [!] Fri Dec 23 19:42:51 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671820971-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671820971-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671820971-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671820971-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 19:42:56 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.709736 | F1-score: 0.31 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 19:43:00 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.249916 | F1-score: 0.87 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 19:43:04 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.260736 | F1-score: 0.90 | Elapsed: 3.88s
WARNING:root: [*] Fri Dec 23 19:43:08 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.267580 | F1-score: 0.92 | Elapsed: 3.89s
WARNING:root: [*] Fri Dec 23 19:43:12 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.061421 | F1-score: 0.93 | Elapsed: 3.87s
WARNING:root: [*] Fri Dec 23 19:43:16 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.111179 | F1-score: 0.93 | Elapsed: 3.89s
WARNING:root: [*] Fri Dec 23 19:43:19 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.078974 | F1-score: 0.94 | Elapsed: 3.87s
WARNING:root: [*] Fri Dec 23 19:43:23 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.227673 | F1-score: 0.94 | Elapsed: 3.87s
WARNING:root: [*] Fri Dec 23 19:43:27 2022:    1    | Tr.loss: 0.180381 | Tr.F1.:   0.95    |   30.81  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 19:43:27 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.111258 | F1-score: 0.93 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 19:43:31 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.129439 | F1-score: 0.97 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 19:43:35 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.085825 | F1-score: 0.97 | Elapsed: 3.87s
WARNING:root: [*] Fri Dec 23 19:43:39 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.094842 | F1-score: 0.97 | Elapsed: 3.87s
WARNING:root: [*] Fri Dec 23 19:43:42 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.052593 | F1-score: 0.97 | Elapsed: 3.89s
WARNING:root: [*] Fri Dec 23 19:43:46 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.104682 | F1-score: 0.97 | Elapsed: 3.87s
WARNING:root: [*] Fri Dec 23 19:43:50 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.052743 | F1-score: 0.97 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 19:43:54 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.109103 | F1-score: 0.97 | Elapsed: 3.88s
WARNING:root: [*] Fri Dec 23 19:43:58 2022:    2    | Tr.loss: 0.104720 | Tr.F1.:   0.97    |   30.82  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 19:43:58 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.097246 | F1-score: 0.97 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 19:44:02 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.036798 | F1-score: 0.97 | Elapsed: 3.89s
WARNING:root: [*] Fri Dec 23 19:44:06 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.075209 | F1-score: 0.97 | Elapsed: 3.88s
WARNING:root: [*] Fri Dec 23 19:44:09 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.043823 | F1-score: 0.97 | Elapsed: 3.87s
WARNING:root: [*] Fri Dec 23 19:44:13 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.125033 | F1-score: 0.97 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 19:44:17 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.158770 | F1-score: 0.97 | Elapsed: 3.89s
WARNING:root: [*] Fri Dec 23 19:44:21 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.199449 | F1-score: 0.97 | Elapsed: 3.88s
WARNING:root: [*] Fri Dec 23 19:44:25 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.183855 | F1-score: 0.97 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 19:44:29 2022:    3    | Tr.loss: 0.088198 | Tr.F1.:   0.97    |   30.83  s
WARNING:root:
        [!] Fri Dec 23 19:44:29 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671821069-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671821069-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671821069-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671821069-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 19:44:33 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.695847 | F1-score: 0.67 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 19:44:37 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.356751 | F1-score: 0.87 | Elapsed: 3.91s
WARNING:root: [*] Fri Dec 23 19:44:41 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.169666 | F1-score: 0.91 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 19:44:45 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.222385 | F1-score: 0.92 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 19:44:49 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.084927 | F1-score: 0.93 | Elapsed: 3.96s
WARNING:root: [*] Fri Dec 23 19:44:53 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.109854 | F1-score: 0.94 | Elapsed: 3.94s
WARNING:root: [*] Fri Dec 23 19:44:57 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.116561 | F1-score: 0.94 | Elapsed: 3.88s
WARNING:root: [*] Fri Dec 23 19:45:01 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.142989 | F1-score: 0.94 | Elapsed: 3.91s
WARNING:root: [*] Fri Dec 23 19:45:04 2022:    1    | Tr.loss: 0.183832 | Tr.F1.:   0.95    |   31.02  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 19:45:04 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.047034 | F1-score: 1.00 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 19:45:08 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.060161 | F1-score: 0.97 | Elapsed: 3.91s
WARNING:root: [*] Fri Dec 23 19:45:12 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.091636 | F1-score: 0.97 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 19:45:16 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.260383 | F1-score: 0.97 | Elapsed: 3.89s
WARNING:root: [*] Fri Dec 23 19:45:20 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.130744 | F1-score: 0.97 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 19:45:24 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.039311 | F1-score: 0.97 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 19:45:28 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.091172 | F1-score: 0.97 | Elapsed: 3.89s
WARNING:root: [*] Fri Dec 23 19:45:31 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.052705 | F1-score: 0.97 | Elapsed: 3.89s
WARNING:root: [*] Fri Dec 23 19:45:35 2022:    2    | Tr.loss: 0.099960 | Tr.F1.:   0.97    |   30.93  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 19:45:35 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.071523 | F1-score: 0.97 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 19:45:39 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.053099 | F1-score: 0.97 | Elapsed: 3.92s
WARNING:root: [*] Fri Dec 23 19:45:43 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.103443 | F1-score: 0.97 | Elapsed: 3.93s
WARNING:root: [*] Fri Dec 23 19:45:47 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.084932 | F1-score: 0.97 | Elapsed: 3.89s
WARNING:root: [*] Fri Dec 23 19:45:51 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.111717 | F1-score: 0.97 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 19:45:55 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.071531 | F1-score: 0.97 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 19:45:59 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.087670 | F1-score: 0.97 | Elapsed: 3.88s
WARNING:root: [*] Fri Dec 23 19:46:02 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.075575 | F1-score: 0.97 | Elapsed: 3.89s
WARNING:root: [*] Fri Dec 23 19:46:06 2022:    3    | Tr.loss: 0.086911 | Tr.F1.:   0.97    |   30.94  s
WARNING:root:
        [!] Fri Dec 23 19:46:06 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671821166-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671821166-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671821166-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671821166-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\metrics_trainSize_76126_ep_3_cv_3_maxLen_1024_vocabSize_2500_embeddingDim_64_hiddenNeurons_512_256_128_batchNormConv_False_batchNormFFNN_False_filterSizes_2_3_4_5.json
WARNING:root: [!] Average epoch time: 30.81s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.4357 -- F1: 0.5892
	FPR:  0.001 -- TPR: 0.8391 -- F1: 0.9111
	FPR:   0.01 -- TPR: 0.9440 -- F1: 0.9690
	FPR:    0.1 -- TPR: 0.9909 -- F1: 0.9721

WARNING:root: [!] Using vocabSize: 2500 | maxLen: 2048
WARNING:root: [!] Using device: cuda:0 | Dataset size: 76126
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 2500, 'embeddingDim': 64, 'hiddenNeurons': [512, 256, 128], 'batchNormConv': False, 'batchNormFFNN': False, 'filterSizes': [2, 3, 4, 5]}
WARNING:root: [!] Fold 1/3 | Train set size: 50750, Validation set size: 25376
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 19:46:42 2022: Train Epoch: 1 [  0  /50750 (0 %)]	Loss: 0.721852 | F1-score: 0.47 | Elapsed: 0.34s
WARNING:root: [*] Fri Dec 23 19:46:49 2022: Train Epoch: 1 [6400 /50750 (13%)]	Loss: 0.349204 | F1-score: 0.86 | Elapsed: 7.07s
WARNING:root: [*] Fri Dec 23 19:46:56 2022: Train Epoch: 1 [12800/50750 (25%)]	Loss: 0.219187 | F1-score: 0.90 | Elapsed: 7.10s
WARNING:root: [*] Fri Dec 23 19:47:03 2022: Train Epoch: 1 [19200/50750 (38%)]	Loss: 0.122913 | F1-score: 0.92 | Elapsed: 7.14s
WARNING:root: [*] Fri Dec 23 19:47:10 2022: Train Epoch: 1 [25600/50750 (50%)]	Loss: 0.116097 | F1-score: 0.93 | Elapsed: 7.15s
WARNING:root: [*] Fri Dec 23 19:47:17 2022: Train Epoch: 1 [32000/50750 (63%)]	Loss: 0.134393 | F1-score: 0.93 | Elapsed: 7.18s
WARNING:root: [*] Fri Dec 23 19:47:25 2022: Train Epoch: 1 [38400/50750 (76%)]	Loss: 0.132110 | F1-score: 0.94 | Elapsed: 7.19s
WARNING:root: [*] Fri Dec 23 19:47:32 2022: Train Epoch: 1 [44800/50750 (88%)]	Loss: 0.125428 | F1-score: 0.94 | Elapsed: 7.18s
WARNING:root: [*] Fri Dec 23 19:47:38 2022:    1    | Tr.loss: 0.177198 | Tr.F1.:   0.95    |   56.95  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 19:47:39 2022: Train Epoch: 2 [  0  /50750 (0 %)]	Loss: 0.037079 | F1-score: 0.99 | Elapsed: 0.08s
WARNING:root: [*] Fri Dec 23 19:47:46 2022: Train Epoch: 2 [6400 /50750 (13%)]	Loss: 0.027538 | F1-score: 0.97 | Elapsed: 7.20s
WARNING:root: [*] Fri Dec 23 19:47:53 2022: Train Epoch: 2 [12800/50750 (25%)]	Loss: 0.028189 | F1-score: 0.97 | Elapsed: 7.21s
WARNING:root: [*] Fri Dec 23 19:48:00 2022: Train Epoch: 2 [19200/50750 (38%)]	Loss: 0.066928 | F1-score: 0.97 | Elapsed: 7.19s
WARNING:root: [*] Fri Dec 23 19:48:07 2022: Train Epoch: 2 [25600/50750 (50%)]	Loss: 0.092985 | F1-score: 0.97 | Elapsed: 7.19s
WARNING:root: [*] Fri Dec 23 19:48:15 2022: Train Epoch: 2 [32000/50750 (63%)]	Loss: 0.088796 | F1-score: 0.97 | Elapsed: 7.21s
WARNING:root: [*] Fri Dec 23 19:48:22 2022: Train Epoch: 2 [38400/50750 (76%)]	Loss: 0.092855 | F1-score: 0.97 | Elapsed: 7.20s
WARNING:root: [*] Fri Dec 23 19:48:29 2022: Train Epoch: 2 [44800/50750 (88%)]	Loss: 0.067745 | F1-score: 0.97 | Elapsed: 7.21s
WARNING:root: [*] Fri Dec 23 19:48:36 2022:    2    | Tr.loss: 0.090355 | Tr.F1.:   0.97    |   57.13  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 19:48:36 2022: Train Epoch: 3 [  0  /50750 (0 %)]	Loss: 0.037099 | F1-score: 0.98 | Elapsed: 0.08s
WARNING:root: [*] Fri Dec 23 19:48:43 2022: Train Epoch: 3 [6400 /50750 (13%)]	Loss: 0.057821 | F1-score: 0.98 | Elapsed: 7.21s
WARNING:root: [*] Fri Dec 23 19:48:50 2022: Train Epoch: 3 [12800/50750 (25%)]	Loss: 0.134798 | F1-score: 0.98 | Elapsed: 7.21s
WARNING:root: [*] Fri Dec 23 19:48:57 2022: Train Epoch: 3 [19200/50750 (38%)]	Loss: 0.041148 | F1-score: 0.98 | Elapsed: 7.21s
WARNING:root: [*] Fri Dec 23 19:49:05 2022: Train Epoch: 3 [25600/50750 (50%)]	Loss: 0.150264 | F1-score: 0.98 | Elapsed: 7.22s
WARNING:root: [*] Fri Dec 23 19:49:12 2022: Train Epoch: 3 [32000/50750 (63%)]	Loss: 0.056963 | F1-score: 0.98 | Elapsed: 7.22s
WARNING:root: [*] Fri Dec 23 19:49:19 2022: Train Epoch: 3 [38400/50750 (76%)]	Loss: 0.107941 | F1-score: 0.98 | Elapsed: 7.22s
WARNING:root: [*] Fri Dec 23 19:49:26 2022: Train Epoch: 3 [44800/50750 (88%)]	Loss: 0.136213 | F1-score: 0.98 | Elapsed: 7.22s
WARNING:root: [*] Fri Dec 23 19:49:33 2022:    3    | Tr.loss: 0.075690 | Tr.F1.:   0.98    |   57.23  s
WARNING:root:
        [!] Fri Dec 23 19:49:33 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671821373-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671821373-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671821373-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671821373-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 19:49:42 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.710481 | F1-score: 0.51 | Elapsed: 0.09s
WARNING:root: [*] Fri Dec 23 19:49:49 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.198382 | F1-score: 0.88 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 19:49:56 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.232010 | F1-score: 0.91 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 19:50:03 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.131513 | F1-score: 0.92 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 19:50:11 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.082669 | F1-score: 0.93 | Elapsed: 7.22s
WARNING:root: [*] Fri Dec 23 19:50:18 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.079711 | F1-score: 0.94 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 19:50:25 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.106848 | F1-score: 0.94 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 19:50:32 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.023003 | F1-score: 0.95 | Elapsed: 7.22s
WARNING:root: [*] Fri Dec 23 19:50:39 2022:    1    | Tr.loss: 0.175355 | Tr.F1.:   0.95    |   57.36  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 19:50:39 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.067784 | F1-score: 0.99 | Elapsed: 0.07s
WARNING:root: [*] Fri Dec 23 19:50:46 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.043966 | F1-score: 0.97 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 19:50:54 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.174271 | F1-score: 0.97 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 19:51:01 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.075007 | F1-score: 0.97 | Elapsed: 7.22s
WARNING:root: [*] Fri Dec 23 19:51:08 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.153830 | F1-score: 0.97 | Elapsed: 7.22s
WARNING:root: [*] Fri Dec 23 19:51:15 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.120813 | F1-score: 0.97 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 19:51:22 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.106344 | F1-score: 0.97 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 19:51:30 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.068562 | F1-score: 0.97 | Elapsed: 7.22s
WARNING:root: [*] Fri Dec 23 19:51:36 2022:    2    | Tr.loss: 0.091886 | Tr.F1.:   0.97    |   57.35  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 19:51:36 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.055764 | F1-score: 0.98 | Elapsed: 0.07s
WARNING:root: [*] Fri Dec 23 19:51:44 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.047688 | F1-score: 0.98 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 19:51:51 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.027923 | F1-score: 0.98 | Elapsed: 7.21s
WARNING:root: [*] Fri Dec 23 19:51:58 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.042862 | F1-score: 0.98 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 19:52:05 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.110563 | F1-score: 0.98 | Elapsed: 7.21s
WARNING:root: [*] Fri Dec 23 19:52:13 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.228848 | F1-score: 0.98 | Elapsed: 7.20s
WARNING:root: [*] Fri Dec 23 19:52:20 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.064433 | F1-score: 0.98 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 19:52:27 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.104056 | F1-score: 0.98 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 19:52:34 2022:    3    | Tr.loss: 0.075580 | Tr.F1.:   0.98    |   57.29  s
WARNING:root:
        [!] Fri Dec 23 19:52:34 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671821554-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671821554-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671821554-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671821554-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 19:52:43 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.695737 | F1-score: 0.58 | Elapsed: 0.11s
WARNING:root: [*] Fri Dec 23 19:52:50 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.227668 | F1-score: 0.87 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 19:52:57 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.159199 | F1-score: 0.90 | Elapsed: 7.22s
WARNING:root: [*] Fri Dec 23 19:53:04 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.111136 | F1-score: 0.92 | Elapsed: 7.31s
WARNING:root: [*] Fri Dec 23 19:53:12 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.071308 | F1-score: 0.93 | Elapsed: 7.29s
WARNING:root: [*] Fri Dec 23 19:53:19 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.198713 | F1-score: 0.94 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 19:53:26 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.071057 | F1-score: 0.94 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 19:53:33 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.098868 | F1-score: 0.94 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 19:53:40 2022:    1    | Tr.loss: 0.178382 | Tr.F1.:   0.95    |   57.51  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 19:53:40 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.078290 | F1-score: 0.98 | Elapsed: 0.07s
WARNING:root: [*] Fri Dec 23 19:53:47 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.119110 | F1-score: 0.97 | Elapsed: 7.22s
WARNING:root: [*] Fri Dec 23 19:53:55 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.013568 | F1-score: 0.97 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 19:54:02 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.046951 | F1-score: 0.97 | Elapsed: 7.21s
WARNING:root: [*] Fri Dec 23 19:54:09 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.186674 | F1-score: 0.97 | Elapsed: 7.21s
WARNING:root: [*] Fri Dec 23 19:54:16 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.077601 | F1-score: 0.97 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 19:54:23 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.072538 | F1-score: 0.97 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 19:54:31 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.138584 | F1-score: 0.97 | Elapsed: 7.22s
WARNING:root: [*] Fri Dec 23 19:54:37 2022:    2    | Tr.loss: 0.092686 | Tr.F1.:   0.97    |   57.28  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 19:54:37 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.116571 | F1-score: 0.98 | Elapsed: 0.07s
WARNING:root: [*] Fri Dec 23 19:54:45 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.093321 | F1-score: 0.98 | Elapsed: 7.20s
WARNING:root: [*] Fri Dec 23 19:54:52 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.076331 | F1-score: 0.98 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 19:54:59 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.083267 | F1-score: 0.98 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 19:55:06 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.099417 | F1-score: 0.98 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 19:55:13 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.038195 | F1-score: 0.98 | Elapsed: 7.22s
WARNING:root: [*] Fri Dec 23 19:55:21 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.054958 | F1-score: 0.98 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 19:55:28 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.065389 | F1-score: 0.98 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 19:55:35 2022:    3    | Tr.loss: 0.077933 | Tr.F1.:   0.98    |   57.32  s
WARNING:root:
        [!] Fri Dec 23 19:55:35 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671821735-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671821735-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671821735-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671821735-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\metrics_trainSize_76126_ep_3_cv_3_maxLen_2048_vocabSize_2500_embeddingDim_64_hiddenNeurons_512_256_128_batchNormConv_False_batchNormFFNN_False_filterSizes_2_3_4_5.json
WARNING:root: [!] Average epoch time: 57.27s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.3918 -- F1: 0.5603
	FPR:  0.001 -- TPR: 0.8350 -- F1: 0.9080
	FPR:   0.01 -- TPR: 0.9460 -- F1: 0.9699
	FPR:    0.1 -- TPR: 0.9927 -- F1: 0.9732

WARNING:root: [!] Using vocabSize: 2500 | maxLen: 4096
WARNING:root: [!] Using device: cuda:0 | Dataset size: 76126
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 2500, 'embeddingDim': 64, 'hiddenNeurons': [512, 256, 128], 'batchNormConv': False, 'batchNormFFNN': False, 'filterSizes': [2, 3, 4, 5]}
WARNING:root: [!] Fold 1/3 | Train set size: 50750, Validation set size: 25376
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 19:56:15 2022: Train Epoch: 1 [  0  /50750 (0 %)]	Loss: 0.677553 | F1-score: 0.72 | Elapsed: 0.44s
WARNING:root: [*] Fri Dec 23 19:56:29 2022: Train Epoch: 1 [6400 /50750 (13%)]	Loss: 0.452829 | F1-score: 0.87 | Elapsed: 14.13s
WARNING:root: [*] Fri Dec 23 19:56:43 2022: Train Epoch: 1 [12800/50750 (25%)]	Loss: 0.221486 | F1-score: 0.90 | Elapsed: 14.20s
WARNING:root: [*] Fri Dec 23 19:56:57 2022: Train Epoch: 1 [19200/50750 (38%)]	Loss: 0.102193 | F1-score: 0.92 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 19:57:11 2022: Train Epoch: 1 [25600/50750 (50%)]	Loss: 0.073732 | F1-score: 0.93 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 19:57:26 2022: Train Epoch: 1 [32000/50750 (63%)]	Loss: 0.150794 | F1-score: 0.94 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 19:57:40 2022: Train Epoch: 1 [38400/50750 (76%)]	Loss: 0.077300 | F1-score: 0.94 | Elapsed: 14.20s
WARNING:root: [*] Fri Dec 23 19:57:54 2022: Train Epoch: 1 [44800/50750 (88%)]	Loss: 0.115891 | F1-score: 0.94 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 19:58:07 2022:    1    | Tr.loss: 0.181119 | Tr.F1.:   0.95    |  112.93  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 19:58:07 2022: Train Epoch: 2 [  0  /50750 (0 %)]	Loss: 0.093849 | F1-score: 0.99 | Elapsed: 0.13s
WARNING:root: [*] Fri Dec 23 19:58:21 2022: Train Epoch: 2 [6400 /50750 (13%)]	Loss: 0.136457 | F1-score: 0.97 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 19:58:36 2022: Train Epoch: 2 [12800/50750 (25%)]	Loss: 0.214403 | F1-score: 0.97 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 19:58:50 2022: Train Epoch: 2 [19200/50750 (38%)]	Loss: 0.144645 | F1-score: 0.97 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 19:59:04 2022: Train Epoch: 2 [25600/50750 (50%)]	Loss: 0.150212 | F1-score: 0.97 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 19:59:18 2022: Train Epoch: 2 [32000/50750 (63%)]	Loss: 0.097482 | F1-score: 0.97 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 19:59:33 2022: Train Epoch: 2 [38400/50750 (76%)]	Loss: 0.051874 | F1-score: 0.97 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 19:59:47 2022: Train Epoch: 2 [44800/50750 (88%)]	Loss: 0.073607 | F1-score: 0.97 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 20:00:00 2022:    2    | Tr.loss: 0.091129 | Tr.F1.:   0.97    |  112.70  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 20:00:00 2022: Train Epoch: 3 [  0  /50750 (0 %)]	Loss: 0.089147 | F1-score: 0.96 | Elapsed: 0.14s
WARNING:root: [*] Fri Dec 23 20:00:14 2022: Train Epoch: 3 [6400 /50750 (13%)]	Loss: 0.101012 | F1-score: 0.98 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 20:00:28 2022: Train Epoch: 3 [12800/50750 (25%)]	Loss: 0.016925 | F1-score: 0.98 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 20:00:43 2022: Train Epoch: 3 [19200/50750 (38%)]	Loss: 0.090530 | F1-score: 0.98 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 20:00:57 2022: Train Epoch: 3 [25600/50750 (50%)]	Loss: 0.191088 | F1-score: 0.98 | Elapsed: 14.20s
WARNING:root: [*] Fri Dec 23 20:01:11 2022: Train Epoch: 3 [32000/50750 (63%)]	Loss: 0.143380 | F1-score: 0.98 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 20:01:25 2022: Train Epoch: 3 [38400/50750 (76%)]	Loss: 0.024980 | F1-score: 0.98 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 20:01:39 2022: Train Epoch: 3 [44800/50750 (88%)]	Loss: 0.069920 | F1-score: 0.98 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 20:01:53 2022:    3    | Tr.loss: 0.074636 | Tr.F1.:   0.98    |  112.73  s
WARNING:root:
        [!] Fri Dec 23 20:01:53 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671822113-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671822113-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671822113-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671822113-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 20:02:10 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.697622 | F1-score: 0.57 | Elapsed: 0.16s
WARNING:root: [*] Fri Dec 23 20:02:24 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.199641 | F1-score: 0.87 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 20:02:39 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.242729 | F1-score: 0.91 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 20:02:53 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.137175 | F1-score: 0.92 | Elapsed: 14.24s
WARNING:root: [*] Fri Dec 23 20:03:07 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.111329 | F1-score: 0.93 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 20:03:21 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.116863 | F1-score: 0.94 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 20:03:36 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.111025 | F1-score: 0.94 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 20:03:50 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.099393 | F1-score: 0.95 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 20:04:03 2022:    1    | Tr.loss: 0.172385 | Tr.F1.:   0.95    |  112.81  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 20:04:03 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.250689 | F1-score: 0.94 | Elapsed: 0.15s
WARNING:root: [*] Fri Dec 23 20:04:17 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.050773 | F1-score: 0.98 | Elapsed: 14.27s
WARNING:root: [*] Fri Dec 23 20:04:32 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.058870 | F1-score: 0.98 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 20:04:46 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.088818 | F1-score: 0.98 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 20:05:00 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.067006 | F1-score: 0.97 | Elapsed: 14.24s
WARNING:root: [*] Fri Dec 23 20:05:14 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.064817 | F1-score: 0.97 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 20:05:28 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.059680 | F1-score: 0.97 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 20:05:43 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.054947 | F1-score: 0.97 | Elapsed: 14.24s
WARNING:root: [*] Fri Dec 23 20:05:56 2022:    2    | Tr.loss: 0.089551 | Tr.F1.:   0.97    |  112.86  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 20:05:56 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.084573 | F1-score: 0.98 | Elapsed: 0.13s
WARNING:root: [*] Fri Dec 23 20:06:10 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.056730 | F1-score: 0.97 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 20:06:24 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.055914 | F1-score: 0.97 | Elapsed: 14.24s
WARNING:root: [*] Fri Dec 23 20:06:39 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.071487 | F1-score: 0.98 | Elapsed: 14.25s
WARNING:root: [*] Fri Dec 23 20:06:53 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.010683 | F1-score: 0.98 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 20:07:07 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.078207 | F1-score: 0.98 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 20:07:21 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.176984 | F1-score: 0.98 | Elapsed: 14.25s
WARNING:root: [*] Fri Dec 23 20:07:36 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.074893 | F1-score: 0.98 | Elapsed: 14.24s
WARNING:root: [*] Fri Dec 23 20:07:49 2022:    3    | Tr.loss: 0.076744 | Tr.F1.:   0.98    |  112.88  s
WARNING:root:
        [!] Fri Dec 23 20:07:49 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671822469-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671822469-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671822469-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671822469-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 20:08:06 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.696861 | F1-score: 0.56 | Elapsed: 0.17s
WARNING:root: [*] Fri Dec 23 20:08:20 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.245563 | F1-score: 0.87 | Elapsed: 14.25s
WARNING:root: [*] Fri Dec 23 20:08:35 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.143395 | F1-score: 0.90 | Elapsed: 14.25s
WARNING:root: [*] Fri Dec 23 20:08:49 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.201704 | F1-score: 0.92 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 20:09:03 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.042380 | F1-score: 0.93 | Elapsed: 14.20s
WARNING:root: [*] Fri Dec 23 20:09:17 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.120951 | F1-score: 0.94 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 20:09:32 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.258497 | F1-score: 0.94 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 20:09:46 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.102787 | F1-score: 0.95 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 20:09:59 2022:    1    | Tr.loss: 0.175683 | Tr.F1.:   0.95    |  112.86  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 20:09:59 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.068748 | F1-score: 0.99 | Elapsed: 0.14s
WARNING:root: [*] Fri Dec 23 20:10:13 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.043406 | F1-score: 0.97 | Elapsed: 14.24s
WARNING:root: [*] Fri Dec 23 20:10:28 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.090386 | F1-score: 0.97 | Elapsed: 14.24s
WARNING:root: [*] Fri Dec 23 20:10:42 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.078788 | F1-score: 0.97 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 20:10:56 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.098619 | F1-score: 0.97 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 20:11:10 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.074860 | F1-score: 0.97 | Elapsed: 14.25s
WARNING:root: [*] Fri Dec 23 20:11:24 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.127656 | F1-score: 0.97 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 20:11:39 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.268150 | F1-score: 0.97 | Elapsed: 14.20s
WARNING:root: [*] Fri Dec 23 20:11:52 2022:    2    | Tr.loss: 0.092095 | Tr.F1.:   0.97    |  112.83  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 20:11:52 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.090252 | F1-score: 0.96 | Elapsed: 0.14s
WARNING:root: [*] Fri Dec 23 20:12:06 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.247080 | F1-score: 0.98 | Elapsed: 14.25s
WARNING:root: [*] Fri Dec 23 20:12:20 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.029905 | F1-score: 0.98 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 20:12:35 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.088895 | F1-score: 0.98 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 20:12:49 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.090804 | F1-score: 0.98 | Elapsed: 14.24s
WARNING:root: [*] Fri Dec 23 20:13:03 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.060464 | F1-score: 0.98 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 20:13:17 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.050170 | F1-score: 0.98 | Elapsed: 14.24s
WARNING:root: [*] Fri Dec 23 20:13:32 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.075300 | F1-score: 0.98 | Elapsed: 14.26s
WARNING:root: [*] Fri Dec 23 20:13:45 2022:    3    | Tr.loss: 0.076010 | Tr.F1.:   0.98    |  112.88  s
WARNING:root:
        [!] Fri Dec 23 20:13:45 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671822825-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671822825-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671822825-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671822825-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\metrics_trainSize_76126_ep_3_cv_3_maxLen_4096_vocabSize_2500_embeddingDim_64_hiddenNeurons_512_256_128_batchNormConv_False_batchNormFFNN_False_filterSizes_2_3_4_5.json
WARNING:root: [!] Average epoch time: 112.83s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.4123 -- F1: 0.5713
	FPR:  0.001 -- TPR: 0.8747 -- F1: 0.9327
	FPR:   0.01 -- TPR: 0.9550 -- F1: 0.9746
	FPR:    0.1 -- TPR: 0.9947 -- F1: 0.9739

WARNING:root: [!] Using vocabSize: 2500 | maxLen: 512
WARNING:root: [!] Using device: cuda:0 | Dataset size: 76126
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 2500, 'embeddingDim': 64, 'hiddenNeurons': [512, 256, 128], 'batchNormConv': False, 'batchNormFFNN': False, 'filterSizes': [2, 3, 4, 5]}
WARNING:root: [!] Fold 1/3 | Train set size: 50750, Validation set size: 25376
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 20:14:32 2022: Train Epoch: 1 [  0  /50750 (0 %)]	Loss: 0.684616 | F1-score: 0.62 | Elapsed: 0.21s
WARNING:root: [*] Fri Dec 23 20:14:34 2022: Train Epoch: 1 [6400 /50750 (13%)]	Loss: 0.219883 | F1-score: 0.89 | Elapsed: 2.29s
WARNING:root: [*] Fri Dec 23 20:14:36 2022: Train Epoch: 1 [12800/50750 (25%)]	Loss: 0.162547 | F1-score: 0.92 | Elapsed: 2.20s
WARNING:root: [*] Fri Dec 23 20:14:39 2022: Train Epoch: 1 [19200/50750 (38%)]	Loss: 0.141563 | F1-score: 0.93 | Elapsed: 2.19s
WARNING:root: [*] Fri Dec 23 20:14:41 2022: Train Epoch: 1 [25600/50750 (50%)]	Loss: 0.133617 | F1-score: 0.93 | Elapsed: 2.19s
WARNING:root: [*] Fri Dec 23 20:14:43 2022: Train Epoch: 1 [32000/50750 (63%)]	Loss: 0.126985 | F1-score: 0.94 | Elapsed: 2.21s
WARNING:root: [*] Fri Dec 23 20:14:45 2022: Train Epoch: 1 [38400/50750 (76%)]	Loss: 0.119349 | F1-score: 0.94 | Elapsed: 2.21s
WARNING:root: [*] Fri Dec 23 20:14:47 2022: Train Epoch: 1 [44800/50750 (88%)]	Loss: 0.228287 | F1-score: 0.94 | Elapsed: 2.21s
WARNING:root: [*] Fri Dec 23 20:14:50 2022:    1    | Tr.loss: 0.185671 | Tr.F1.:   0.95    |   17.77  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 20:14:50 2022: Train Epoch: 2 [  0  /50750 (0 %)]	Loss: 0.061157 | F1-score: 0.99 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 20:14:52 2022: Train Epoch: 2 [6400 /50750 (13%)]	Loss: 0.099172 | F1-score: 0.97 | Elapsed: 2.22s
WARNING:root: [*] Fri Dec 23 20:14:54 2022: Train Epoch: 2 [12800/50750 (25%)]	Loss: 0.099765 | F1-score: 0.96 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 20:14:56 2022: Train Epoch: 2 [19200/50750 (38%)]	Loss: 0.160620 | F1-score: 0.97 | Elapsed: 2.22s
WARNING:root: [*] Fri Dec 23 20:14:58 2022: Train Epoch: 2 [25600/50750 (50%)]	Loss: 0.137955 | F1-score: 0.96 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 20:15:01 2022: Train Epoch: 2 [32000/50750 (63%)]	Loss: 0.088294 | F1-score: 0.96 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 20:15:03 2022: Train Epoch: 2 [38400/50750 (76%)]	Loss: 0.042915 | F1-score: 0.96 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 20:15:05 2022: Train Epoch: 2 [44800/50750 (88%)]	Loss: 0.068437 | F1-score: 0.97 | Elapsed: 2.22s
WARNING:root: [*] Fri Dec 23 20:15:07 2022:    2    | Tr.loss: 0.109232 | Tr.F1.:   0.97    |   17.69  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 20:15:07 2022: Train Epoch: 3 [  0  /50750 (0 %)]	Loss: 0.098149 | F1-score: 0.97 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 20:15:09 2022: Train Epoch: 3 [6400 /50750 (13%)]	Loss: 0.182980 | F1-score: 0.97 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 20:15:12 2022: Train Epoch: 3 [12800/50750 (25%)]	Loss: 0.121288 | F1-score: 0.97 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 20:15:14 2022: Train Epoch: 3 [19200/50750 (38%)]	Loss: 0.071982 | F1-score: 0.97 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 20:15:16 2022: Train Epoch: 3 [25600/50750 (50%)]	Loss: 0.066588 | F1-score: 0.97 | Elapsed: 2.22s
WARNING:root: [*] Fri Dec 23 20:15:18 2022: Train Epoch: 3 [32000/50750 (63%)]	Loss: 0.097748 | F1-score: 0.97 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 20:15:21 2022: Train Epoch: 3 [38400/50750 (76%)]	Loss: 0.051347 | F1-score: 0.97 | Elapsed: 2.28s
WARNING:root: [*] Fri Dec 23 20:15:23 2022: Train Epoch: 3 [44800/50750 (88%)]	Loss: 0.105304 | F1-score: 0.97 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 20:15:25 2022:    3    | Tr.loss: 0.095372 | Tr.F1.:   0.97    |   17.75  s
WARNING:root:
        [!] Fri Dec 23 20:15:25 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671822925-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671822925-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671822925-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671822925-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 20:15:27 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.736989 | F1-score: 0.28 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 20:15:30 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.212135 | F1-score: 0.88 | Elapsed: 2.29s
WARNING:root: [*] Fri Dec 23 20:15:32 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.136061 | F1-score: 0.91 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 20:15:34 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.152192 | F1-score: 0.92 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 20:15:36 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.131668 | F1-score: 0.93 | Elapsed: 2.26s
WARNING:root: [*] Fri Dec 23 20:15:39 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.292383 | F1-score: 0.93 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 20:15:41 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.072001 | F1-score: 0.94 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 20:15:43 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.192759 | F1-score: 0.94 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 20:15:45 2022:    1    | Tr.loss: 0.191245 | Tr.F1.:   0.94    |   17.84  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 20:15:45 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.219597 | F1-score: 0.94 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 20:15:48 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.093053 | F1-score: 0.96 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 20:15:50 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.041794 | F1-score: 0.96 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 20:15:52 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.171089 | F1-score: 0.96 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 20:15:54 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.133548 | F1-score: 0.96 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 20:15:56 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.147583 | F1-score: 0.96 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 20:15:59 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.094399 | F1-score: 0.96 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 20:16:01 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.134901 | F1-score: 0.97 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 20:16:03 2022:    2    | Tr.loss: 0.110788 | Tr.F1.:   0.97    |   17.78  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 20:16:03 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.073587 | F1-score: 0.97 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 20:16:05 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.160528 | F1-score: 0.97 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 20:16:08 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.048648 | F1-score: 0.97 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 20:16:10 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.168887 | F1-score: 0.97 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 20:16:12 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.115621 | F1-score: 0.97 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 20:16:14 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.113992 | F1-score: 0.97 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 20:16:17 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.079539 | F1-score: 0.97 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 20:16:19 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.026097 | F1-score: 0.97 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 20:16:21 2022:    3    | Tr.loss: 0.097240 | Tr.F1.:   0.97    |   17.83  s
WARNING:root:
        [!] Fri Dec 23 20:16:21 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671822981-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671822981-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671822981-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671822981-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 20:16:23 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.671247 | F1-score: 0.76 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 20:16:26 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.362759 | F1-score: 0.89 | Elapsed: 2.28s
WARNING:root: [*] Fri Dec 23 20:16:28 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.199199 | F1-score: 0.91 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 20:16:30 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.233946 | F1-score: 0.92 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 20:16:32 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.080901 | F1-score: 0.93 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 20:16:35 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.095750 | F1-score: 0.94 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 20:16:37 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.165663 | F1-score: 0.94 | Elapsed: 2.26s
WARNING:root: [*] Fri Dec 23 20:16:39 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.142852 | F1-score: 0.94 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 20:16:41 2022:    1    | Tr.loss: 0.188124 | Tr.F1.:   0.95    |   17.87  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 20:16:41 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.135492 | F1-score: 0.97 | Elapsed: 0.02s
WARNING:root: [*] Fri Dec 23 20:16:43 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.052668 | F1-score: 0.97 | Elapsed: 2.26s
WARNING:root: [*] Fri Dec 23 20:16:46 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.075410 | F1-score: 0.97 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 20:16:48 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.059095 | F1-score: 0.97 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 20:16:50 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.167048 | F1-score: 0.97 | Elapsed: 2.27s
WARNING:root: [*] Fri Dec 23 20:16:52 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.018969 | F1-score: 0.97 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 20:16:55 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.105284 | F1-score: 0.97 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 20:16:57 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.056051 | F1-score: 0.97 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 20:16:59 2022:    2    | Tr.loss: 0.108903 | Tr.F1.:   0.97    |   17.84  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 20:16:59 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.040066 | F1-score: 0.99 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 20:17:01 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.042379 | F1-score: 0.97 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 20:17:03 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.159210 | F1-score: 0.97 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 20:17:06 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.129053 | F1-score: 0.97 | Elapsed: 2.26s
WARNING:root: [*] Fri Dec 23 20:17:08 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.083289 | F1-score: 0.97 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 20:17:10 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.058756 | F1-score: 0.97 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 20:17:12 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.033267 | F1-score: 0.97 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 20:17:15 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.099608 | F1-score: 0.97 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 20:17:17 2022:    3    | Tr.loss: 0.094365 | Tr.F1.:   0.97    |   17.83  s
WARNING:root:
        [!] Fri Dec 23 20:17:17 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671823037-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671823037-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671823037-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671823037-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\metrics_trainSize_76126_ep_3_cv_3_maxLen_512_vocabSize_2500_embeddingDim_64_hiddenNeurons_512_256_128_batchNormConv_False_batchNormFFNN_False_filterSizes_2_3_4_5.json
WARNING:root: [!] Average epoch time: 17.80s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.5496 -- F1: 0.7081
	FPR:  0.001 -- TPR: 0.8712 -- F1: 0.9308
	FPR:   0.01 -- TPR: 0.9361 -- F1: 0.9647
	FPR:    0.1 -- TPR: 0.9856 -- F1: 0.9695

WARNING:root: [!] Using vocabSize: 5000 | maxLen: 1024
WARNING:root: [!] Using device: cuda:0 | Dataset size: 76126
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 5000, 'embeddingDim': 64, 'hiddenNeurons': [512, 256, 128], 'batchNormConv': False, 'batchNormFFNN': False, 'filterSizes': [2, 3, 4, 5]}
WARNING:root: [!] Fold 1/3 | Train set size: 50750, Validation set size: 25376
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 20:17:50 2022: Train Epoch: 1 [  0  /50750 (0 %)]	Loss: 0.724568 | F1-score: 0.34 | Elapsed: 0.35s
WARNING:root: [*] Fri Dec 23 20:17:54 2022: Train Epoch: 1 [6400 /50750 (13%)]	Loss: 0.156042 | F1-score: 0.85 | Elapsed: 3.81s
WARNING:root: [*] Fri Dec 23 20:17:58 2022: Train Epoch: 1 [12800/50750 (25%)]	Loss: 0.242683 | F1-score: 0.90 | Elapsed: 3.78s
WARNING:root: [*] Fri Dec 23 20:18:02 2022: Train Epoch: 1 [19200/50750 (38%)]	Loss: 0.089921 | F1-score: 0.92 | Elapsed: 3.81s
WARNING:root: [*] Fri Dec 23 20:18:05 2022: Train Epoch: 1 [25600/50750 (50%)]	Loss: 0.107888 | F1-score: 0.93 | Elapsed: 3.80s
WARNING:root: [*] Fri Dec 23 20:18:09 2022: Train Epoch: 1 [32000/50750 (63%)]	Loss: 0.071816 | F1-score: 0.93 | Elapsed: 3.82s
WARNING:root: [*] Fri Dec 23 20:18:13 2022: Train Epoch: 1 [38400/50750 (76%)]	Loss: 0.029743 | F1-score: 0.94 | Elapsed: 3.84s
WARNING:root: [*] Fri Dec 23 20:18:17 2022: Train Epoch: 1 [44800/50750 (88%)]	Loss: 0.114159 | F1-score: 0.94 | Elapsed: 3.85s
WARNING:root: [*] Fri Dec 23 20:18:21 2022:    1    | Tr.loss: 0.175413 | Tr.F1.:   0.95    |   30.62  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 20:18:21 2022: Train Epoch: 2 [  0  /50750 (0 %)]	Loss: 0.063618 | F1-score: 0.98 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 20:18:24 2022: Train Epoch: 2 [6400 /50750 (13%)]	Loss: 0.101468 | F1-score: 0.97 | Elapsed: 3.87s
WARNING:root: [*] Fri Dec 23 20:18:28 2022: Train Epoch: 2 [12800/50750 (25%)]	Loss: 0.060925 | F1-score: 0.97 | Elapsed: 3.84s
WARNING:root: [*] Fri Dec 23 20:18:32 2022: Train Epoch: 2 [19200/50750 (38%)]	Loss: 0.179924 | F1-score: 0.97 | Elapsed: 3.86s
WARNING:root: [*] Fri Dec 23 20:18:36 2022: Train Epoch: 2 [25600/50750 (50%)]	Loss: 0.158626 | F1-score: 0.97 | Elapsed: 3.85s
WARNING:root: [*] Fri Dec 23 20:18:40 2022: Train Epoch: 2 [32000/50750 (63%)]	Loss: 0.082201 | F1-score: 0.97 | Elapsed: 3.87s
WARNING:root: [*] Fri Dec 23 20:18:44 2022: Train Epoch: 2 [38400/50750 (76%)]	Loss: 0.232359 | F1-score: 0.97 | Elapsed: 3.87s
WARNING:root: [*] Fri Dec 23 20:18:48 2022: Train Epoch: 2 [44800/50750 (88%)]	Loss: 0.049625 | F1-score: 0.97 | Elapsed: 3.87s
WARNING:root: [*] Fri Dec 23 20:18:51 2022:    2    | Tr.loss: 0.088765 | Tr.F1.:   0.97    |   30.65  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 20:18:51 2022: Train Epoch: 3 [  0  /50750 (0 %)]	Loss: 0.124447 | F1-score: 0.98 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 20:18:55 2022: Train Epoch: 3 [6400 /50750 (13%)]	Loss: 0.165018 | F1-score: 0.98 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 20:18:59 2022: Train Epoch: 3 [12800/50750 (25%)]	Loss: 0.051061 | F1-score: 0.98 | Elapsed: 3.87s
WARNING:root: [*] Fri Dec 23 20:19:03 2022: Train Epoch: 3 [19200/50750 (38%)]	Loss: 0.050737 | F1-score: 0.98 | Elapsed: 3.87s
WARNING:root: [*] Fri Dec 23 20:19:07 2022: Train Epoch: 3 [25600/50750 (50%)]	Loss: 0.072856 | F1-score: 0.98 | Elapsed: 3.85s
WARNING:root: [*] Fri Dec 23 20:19:11 2022: Train Epoch: 3 [32000/50750 (63%)]	Loss: 0.095011 | F1-score: 0.98 | Elapsed: 3.86s
WARNING:root: [*] Fri Dec 23 20:19:14 2022: Train Epoch: 3 [38400/50750 (76%)]	Loss: 0.043779 | F1-score: 0.98 | Elapsed: 3.88s
WARNING:root: [*] Fri Dec 23 20:19:18 2022: Train Epoch: 3 [44800/50750 (88%)]	Loss: 0.069589 | F1-score: 0.98 | Elapsed: 3.87s
WARNING:root: [*] Fri Dec 23 20:19:22 2022:    3    | Tr.loss: 0.075520 | Tr.F1.:   0.98    |   30.69  s
WARNING:root:
        [!] Fri Dec 23 20:19:22 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671823162-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671823162-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671823162-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671823162-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 20:19:27 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.686918 | F1-score: 0.65 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 20:19:30 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.123211 | F1-score: 0.86 | Elapsed: 3.94s
WARNING:root: [*] Fri Dec 23 20:19:34 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.159281 | F1-score: 0.91 | Elapsed: 3.87s
WARNING:root: [*] Fri Dec 23 20:19:38 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.060766 | F1-score: 0.92 | Elapsed: 3.88s
WARNING:root: [*] Fri Dec 23 20:19:42 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.081239 | F1-score: 0.93 | Elapsed: 3.87s
WARNING:root: [*] Fri Dec 23 20:19:46 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.008993 | F1-score: 0.94 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 20:19:50 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.089655 | F1-score: 0.94 | Elapsed: 3.88s
WARNING:root: [*] Fri Dec 23 20:19:54 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.066729 | F1-score: 0.95 | Elapsed: 3.91s
WARNING:root: [*] Fri Dec 23 20:19:57 2022:    1    | Tr.loss: 0.170032 | Tr.F1.:   0.95    |   30.89  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 20:19:57 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.161125 | F1-score: 0.94 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 20:20:01 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.188612 | F1-score: 0.97 | Elapsed: 3.87s
WARNING:root: [*] Fri Dec 23 20:20:05 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.031993 | F1-score: 0.97 | Elapsed: 3.88s
WARNING:root: [*] Fri Dec 23 20:20:09 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.048010 | F1-score: 0.97 | Elapsed: 3.88s
WARNING:root: [*] Fri Dec 23 20:20:13 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.112097 | F1-score: 0.97 | Elapsed: 3.88s
WARNING:root: [*] Fri Dec 23 20:20:17 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.070858 | F1-score: 0.97 | Elapsed: 3.87s
WARNING:root: [*] Fri Dec 23 20:20:21 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.073720 | F1-score: 0.97 | Elapsed: 3.88s
WARNING:root: [*] Fri Dec 23 20:20:25 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.035038 | F1-score: 0.97 | Elapsed: 3.89s
WARNING:root: [*] Fri Dec 23 20:20:28 2022:    2    | Tr.loss: 0.089920 | Tr.F1.:   0.97    |   30.77  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 20:20:28 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.167735 | F1-score: 0.95 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 20:20:32 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.034071 | F1-score: 0.98 | Elapsed: 3.89s
WARNING:root: [*] Fri Dec 23 20:20:36 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.073076 | F1-score: 0.98 | Elapsed: 3.88s
WARNING:root: [*] Fri Dec 23 20:20:40 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.079606 | F1-score: 0.97 | Elapsed: 3.88s
WARNING:root: [*] Fri Dec 23 20:20:44 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.054144 | F1-score: 0.98 | Elapsed: 3.89s
WARNING:root: [*] Fri Dec 23 20:20:48 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.018799 | F1-score: 0.98 | Elapsed: 3.91s
WARNING:root: [*] Fri Dec 23 20:20:51 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.071904 | F1-score: 0.98 | Elapsed: 3.85s
WARNING:root: [*] Fri Dec 23 20:20:55 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.058167 | F1-score: 0.98 | Elapsed: 3.87s
WARNING:root: [*] Fri Dec 23 20:20:59 2022:    3    | Tr.loss: 0.078642 | Tr.F1.:   0.98    |   30.79  s
WARNING:root:
        [!] Fri Dec 23 20:20:59 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671823259-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671823259-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671823259-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671823259-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 20:21:04 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.687654 | F1-score: 0.72 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 20:21:07 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.276174 | F1-score: 0.88 | Elapsed: 3.93s
WARNING:root: [*] Fri Dec 23 20:21:11 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.213692 | F1-score: 0.91 | Elapsed: 3.88s
WARNING:root: [*] Fri Dec 23 20:21:15 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.173881 | F1-score: 0.93 | Elapsed: 3.89s
WARNING:root: [*] Fri Dec 23 20:21:19 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.103334 | F1-score: 0.94 | Elapsed: 3.88s
WARNING:root: [*] Fri Dec 23 20:21:23 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.052401 | F1-score: 0.94 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 20:21:27 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.135678 | F1-score: 0.95 | Elapsed: 3.89s
WARNING:root: [*] Fri Dec 23 20:21:31 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.011769 | F1-score: 0.95 | Elapsed: 3.89s
WARNING:root: [*] Fri Dec 23 20:21:34 2022:    1    | Tr.loss: 0.167368 | Tr.F1.:   0.95    |   30.90  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 20:21:34 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.083902 | F1-score: 0.97 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 20:21:38 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.132992 | F1-score: 0.97 | Elapsed: 3.92s
WARNING:root: [*] Fri Dec 23 20:21:42 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.032937 | F1-score: 0.97 | Elapsed: 3.88s
WARNING:root: [*] Fri Dec 23 20:21:46 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.091071 | F1-score: 0.97 | Elapsed: 3.89s
WARNING:root: [*] Fri Dec 23 20:21:50 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.089116 | F1-score: 0.97 | Elapsed: 3.89s
WARNING:root: [*] Fri Dec 23 20:21:54 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.136368 | F1-score: 0.97 | Elapsed: 3.88s
WARNING:root: [*] Fri Dec 23 20:21:58 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.066515 | F1-score: 0.97 | Elapsed: 3.89s
WARNING:root: [*] Fri Dec 23 20:22:02 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.041931 | F1-score: 0.97 | Elapsed: 3.89s
WARNING:root: [*] Fri Dec 23 20:22:05 2022:    2    | Tr.loss: 0.091431 | Tr.F1.:   0.97    |   30.87  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 20:22:05 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.138899 | F1-score: 0.97 | Elapsed: 0.04s
WARNING:root: [*] Fri Dec 23 20:22:09 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.037050 | F1-score: 0.98 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 20:22:13 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.080634 | F1-score: 0.98 | Elapsed: 3.91s
WARNING:root: [*] Fri Dec 23 20:22:17 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.066324 | F1-score: 0.98 | Elapsed: 3.88s
WARNING:root: [*] Fri Dec 23 20:22:21 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.065081 | F1-score: 0.98 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 20:22:25 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.045500 | F1-score: 0.98 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 20:22:29 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.051136 | F1-score: 0.98 | Elapsed: 3.87s
WARNING:root: [*] Fri Dec 23 20:22:33 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.059781 | F1-score: 0.98 | Elapsed: 3.90s
WARNING:root: [*] Fri Dec 23 20:22:36 2022:    3    | Tr.loss: 0.074917 | Tr.F1.:   0.98    |   30.89  s
WARNING:root:
        [!] Fri Dec 23 20:22:36 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671823356-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671823356-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671823356-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671823356-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\metrics_trainSize_76126_ep_3_cv_3_maxLen_1024_vocabSize_5000_embeddingDim_64_hiddenNeurons_512_256_128_batchNormConv_False_batchNormFFNN_False_filterSizes_2_3_4_5.json
WARNING:root: [!] Average epoch time: 30.79s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.5600 -- F1: 0.7061
	FPR:  0.001 -- TPR: 0.9100 -- F1: 0.9526
	FPR:   0.01 -- TPR: 0.9554 -- F1: 0.9750
	FPR:    0.1 -- TPR: 0.9938 -- F1: 0.9736

WARNING:root: [!] Using vocabSize: 5000 | maxLen: 2048
WARNING:root: [!] Using device: cuda:0 | Dataset size: 76126
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 5000, 'embeddingDim': 64, 'hiddenNeurons': [512, 256, 128], 'batchNormConv': False, 'batchNormFFNN': False, 'filterSizes': [2, 3, 4, 5]}
WARNING:root: [!] Fold 1/3 | Train set size: 50750, Validation set size: 25376
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 20:23:12 2022: Train Epoch: 1 [  0  /50750 (0 %)]	Loss: 0.716727 | F1-score: 0.46 | Elapsed: 0.32s
WARNING:root: [*] Fri Dec 23 20:23:19 2022: Train Epoch: 1 [6400 /50750 (13%)]	Loss: 0.125752 | F1-score: 0.87 | Elapsed: 7.08s
WARNING:root: [*] Fri Dec 23 20:23:26 2022: Train Epoch: 1 [12800/50750 (25%)]	Loss: 0.113786 | F1-score: 0.91 | Elapsed: 7.09s
WARNING:root: [*] Fri Dec 23 20:23:33 2022: Train Epoch: 1 [19200/50750 (38%)]	Loss: 0.256296 | F1-score: 0.92 | Elapsed: 7.11s
WARNING:root: [*] Fri Dec 23 20:23:40 2022: Train Epoch: 1 [25600/50750 (50%)]	Loss: 0.172972 | F1-score: 0.93 | Elapsed: 7.16s
WARNING:root: [*] Fri Dec 23 20:23:47 2022: Train Epoch: 1 [32000/50750 (63%)]	Loss: 0.160643 | F1-score: 0.94 | Elapsed: 7.18s
WARNING:root: [*] Fri Dec 23 20:23:54 2022: Train Epoch: 1 [38400/50750 (76%)]	Loss: 0.077688 | F1-score: 0.95 | Elapsed: 7.20s
WARNING:root: [*] Fri Dec 23 20:24:02 2022: Train Epoch: 1 [44800/50750 (88%)]	Loss: 0.072723 | F1-score: 0.95 | Elapsed: 7.20s
WARNING:root: [*] Fri Dec 23 20:24:08 2022:    1    | Tr.loss: 0.165422 | Tr.F1.:   0.95    |   56.96  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 20:24:08 2022: Train Epoch: 2 [  0  /50750 (0 %)]	Loss: 0.088517 | F1-score: 0.97 | Elapsed: 0.07s
WARNING:root: [*] Fri Dec 23 20:24:15 2022: Train Epoch: 2 [6400 /50750 (13%)]	Loss: 0.023548 | F1-score: 0.97 | Elapsed: 7.21s
WARNING:root: [*] Fri Dec 23 20:24:23 2022: Train Epoch: 2 [12800/50750 (25%)]	Loss: 0.058534 | F1-score: 0.97 | Elapsed: 7.18s
WARNING:root: [*] Fri Dec 23 20:24:30 2022: Train Epoch: 2 [19200/50750 (38%)]	Loss: 0.151816 | F1-score: 0.97 | Elapsed: 7.19s
WARNING:root: [*] Fri Dec 23 20:24:37 2022: Train Epoch: 2 [25600/50750 (50%)]	Loss: 0.115388 | F1-score: 0.98 | Elapsed: 7.20s
WARNING:root: [*] Fri Dec 23 20:24:44 2022: Train Epoch: 2 [32000/50750 (63%)]	Loss: 0.060940 | F1-score: 0.98 | Elapsed: 7.22s
WARNING:root: [*] Fri Dec 23 20:24:51 2022: Train Epoch: 2 [38400/50750 (76%)]	Loss: 0.078791 | F1-score: 0.98 | Elapsed: 7.20s
WARNING:root: [*] Fri Dec 23 20:24:59 2022: Train Epoch: 2 [44800/50750 (88%)]	Loss: 0.050556 | F1-score: 0.98 | Elapsed: 7.20s
WARNING:root: [*] Fri Dec 23 20:25:05 2022:    2    | Tr.loss: 0.079735 | Tr.F1.:   0.98    |   57.12  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 20:25:05 2022: Train Epoch: 3 [  0  /50750 (0 %)]	Loss: 0.037095 | F1-score: 0.99 | Elapsed: 0.07s
WARNING:root: [*] Fri Dec 23 20:25:13 2022: Train Epoch: 3 [6400 /50750 (13%)]	Loss: 0.063211 | F1-score: 0.98 | Elapsed: 7.20s
WARNING:root: [*] Fri Dec 23 20:25:20 2022: Train Epoch: 3 [12800/50750 (25%)]	Loss: 0.152302 | F1-score: 0.98 | Elapsed: 7.22s
WARNING:root: [*] Fri Dec 23 20:25:27 2022: Train Epoch: 3 [19200/50750 (38%)]	Loss: 0.025186 | F1-score: 0.98 | Elapsed: 7.18s
WARNING:root: [*] Fri Dec 23 20:25:34 2022: Train Epoch: 3 [25600/50750 (50%)]	Loss: 0.078068 | F1-score: 0.98 | Elapsed: 7.21s
WARNING:root: [*] Fri Dec 23 20:25:41 2022: Train Epoch: 3 [32000/50750 (63%)]	Loss: 0.033036 | F1-score: 0.98 | Elapsed: 7.22s
WARNING:root: [*] Fri Dec 23 20:25:49 2022: Train Epoch: 3 [38400/50750 (76%)]	Loss: 0.084934 | F1-score: 0.98 | Elapsed: 7.19s
WARNING:root: [*] Fri Dec 23 20:25:56 2022: Train Epoch: 3 [44800/50750 (88%)]	Loss: 0.063246 | F1-score: 0.98 | Elapsed: 7.21s
WARNING:root: [*] Fri Dec 23 20:26:02 2022:    3    | Tr.loss: 0.065594 | Tr.F1.:   0.98    |   57.15  s
WARNING:root:
        [!] Fri Dec 23 20:26:02 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671823562-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671823562-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671823562-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671823562-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 20:26:11 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.690427 | F1-score: 0.64 | Elapsed: 0.10s
WARNING:root: [*] Fri Dec 23 20:26:19 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.238508 | F1-score: 0.86 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 20:26:26 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.146872 | F1-score: 0.90 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 20:26:33 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.083738 | F1-score: 0.92 | Elapsed: 7.22s
WARNING:root: [*] Fri Dec 23 20:26:40 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.071491 | F1-score: 0.93 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 20:26:48 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.091459 | F1-score: 0.94 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 20:26:55 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.147167 | F1-score: 0.95 | Elapsed: 7.22s
WARNING:root: [*] Fri Dec 23 20:27:02 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.103844 | F1-score: 0.95 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 20:27:09 2022:    1    | Tr.loss: 0.163752 | Tr.F1.:   0.95    |   57.38  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 20:27:09 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.047195 | F1-score: 0.99 | Elapsed: 0.07s
WARNING:root: [*] Fri Dec 23 20:27:16 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.061218 | F1-score: 0.98 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 20:27:23 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.054625 | F1-score: 0.98 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 20:27:30 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.052749 | F1-score: 0.98 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 20:27:38 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.109143 | F1-score: 0.98 | Elapsed: 7.20s
WARNING:root: [*] Fri Dec 23 20:27:45 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.044530 | F1-score: 0.98 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 20:27:52 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.080577 | F1-score: 0.98 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 20:27:59 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.026003 | F1-score: 0.98 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 20:28:06 2022:    2    | Tr.loss: 0.080945 | Tr.F1.:   0.98    |   57.43  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 20:28:06 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.027023 | F1-score: 1.00 | Elapsed: 0.08s
WARNING:root: [*] Fri Dec 23 20:28:13 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.150653 | F1-score: 0.98 | Elapsed: 7.28s
WARNING:root: [*] Fri Dec 23 20:28:21 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.087917 | F1-score: 0.98 | Elapsed: 7.28s
WARNING:root: [*] Fri Dec 23 20:28:28 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.032143 | F1-score: 0.98 | Elapsed: 7.27s
WARNING:root: [*] Fri Dec 23 20:28:35 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.046172 | F1-score: 0.98 | Elapsed: 7.28s
WARNING:root: [*] Fri Dec 23 20:28:42 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.053067 | F1-score: 0.98 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 20:28:50 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.077024 | F1-score: 0.98 | Elapsed: 7.22s
WARNING:root: [*] Fri Dec 23 20:28:57 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.012635 | F1-score: 0.98 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 20:29:04 2022:    3    | Tr.loss: 0.070045 | Tr.F1.:   0.98    |   57.56  s
WARNING:root:
        [!] Fri Dec 23 20:29:04 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671823744-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671823744-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671823744-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671823744-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 20:29:13 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.707508 | F1-score: 0.46 | Elapsed: 0.10s
WARNING:root: [*] Fri Dec 23 20:29:20 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.174808 | F1-score: 0.87 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 20:29:27 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.093048 | F1-score: 0.91 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 20:29:34 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.038344 | F1-score: 0.93 | Elapsed: 7.23s
WARNING:root: [*] Fri Dec 23 20:29:42 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.165059 | F1-score: 0.94 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 20:29:49 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.083344 | F1-score: 0.94 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 20:29:56 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.226630 | F1-score: 0.95 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 20:30:03 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.037898 | F1-score: 0.95 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 20:30:10 2022:    1    | Tr.loss: 0.159683 | Tr.F1.:   0.95    |   57.45  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 20:30:10 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.093390 | F1-score: 0.95 | Elapsed: 0.07s
WARNING:root: [*] Fri Dec 23 20:30:17 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.032453 | F1-score: 0.97 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 20:30:24 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.169415 | F1-score: 0.97 | Elapsed: 7.27s
WARNING:root: [*] Fri Dec 23 20:30:32 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.073140 | F1-score: 0.98 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 20:30:39 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.085072 | F1-score: 0.98 | Elapsed: 7.21s
WARNING:root: [*] Fri Dec 23 20:30:46 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.181791 | F1-score: 0.98 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 20:30:53 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.009657 | F1-score: 0.98 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 20:31:01 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.044472 | F1-score: 0.98 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 20:31:07 2022:    2    | Tr.loss: 0.080754 | Tr.F1.:   0.98    |   57.44  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 20:31:07 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.145991 | F1-score: 0.95 | Elapsed: 0.08s
WARNING:root: [*] Fri Dec 23 20:31:15 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.094144 | F1-score: 0.98 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 20:31:22 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.031150 | F1-score: 0.98 | Elapsed: 7.26s
WARNING:root: [*] Fri Dec 23 20:31:29 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.046151 | F1-score: 0.98 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 20:31:36 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.038917 | F1-score: 0.98 | Elapsed: 7.22s
WARNING:root: [*] Fri Dec 23 20:31:44 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.094591 | F1-score: 0.98 | Elapsed: 7.24s
WARNING:root: [*] Fri Dec 23 20:31:51 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.044434 | F1-score: 0.98 | Elapsed: 7.22s
WARNING:root: [*] Fri Dec 23 20:31:58 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.046822 | F1-score: 0.98 | Elapsed: 7.25s
WARNING:root: [*] Fri Dec 23 20:32:05 2022:    3    | Tr.loss: 0.067166 | Tr.F1.:   0.98    |   57.45  s
WARNING:root:
        [!] Fri Dec 23 20:32:05 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671823925-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671823925-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671823925-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671823925-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\metrics_trainSize_76126_ep_3_cv_3_maxLen_2048_vocabSize_5000_embeddingDim_64_hiddenNeurons_512_256_128_batchNormConv_False_batchNormFFNN_False_filterSizes_2_3_4_5.json
WARNING:root: [!] Average epoch time: 57.33s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.6001 -- F1: 0.7369
	FPR:  0.001 -- TPR: 0.8662 -- F1: 0.9268
	FPR:   0.01 -- TPR: 0.9628 -- F1: 0.9787
	FPR:    0.1 -- TPR: 0.9944 -- F1: 0.9739

WARNING:root: [!] Using vocabSize: 5000 | maxLen: 4096
WARNING:root: [!] Using device: cuda:0 | Dataset size: 76126
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 5000, 'embeddingDim': 64, 'hiddenNeurons': [512, 256, 128], 'batchNormConv': False, 'batchNormFFNN': False, 'filterSizes': [2, 3, 4, 5]}
WARNING:root: [!] Fold 1/3 | Train set size: 50750, Validation set size: 25376
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 20:32:45 2022: Train Epoch: 1 [  0  /50750 (0 %)]	Loss: 0.686765 | F1-score: 0.62 | Elapsed: 0.33s
WARNING:root: [*] Fri Dec 23 20:32:59 2022: Train Epoch: 1 [6400 /50750 (13%)]	Loss: 0.153159 | F1-score: 0.86 | Elapsed: 14.13s
WARNING:root: [*] Fri Dec 23 20:33:13 2022: Train Epoch: 1 [12800/50750 (25%)]	Loss: 0.163793 | F1-score: 0.90 | Elapsed: 14.24s
WARNING:root: [*] Fri Dec 23 20:33:27 2022: Train Epoch: 1 [19200/50750 (38%)]	Loss: 0.201450 | F1-score: 0.92 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 20:33:42 2022: Train Epoch: 1 [25600/50750 (50%)]	Loss: 0.051178 | F1-score: 0.93 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 20:33:56 2022: Train Epoch: 1 [32000/50750 (63%)]	Loss: 0.146317 | F1-score: 0.94 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 20:34:10 2022: Train Epoch: 1 [38400/50750 (76%)]	Loss: 0.130328 | F1-score: 0.94 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 20:34:24 2022: Train Epoch: 1 [44800/50750 (88%)]	Loss: 0.090447 | F1-score: 0.95 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 20:34:37 2022:    1    | Tr.loss: 0.166291 | Tr.F1.:   0.95    |  112.89  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 20:34:37 2022: Train Epoch: 2 [  0  /50750 (0 %)]	Loss: 0.124910 | F1-score: 0.98 | Elapsed: 0.13s
WARNING:root: [*] Fri Dec 23 20:34:52 2022: Train Epoch: 2 [6400 /50750 (13%)]	Loss: 0.027681 | F1-score: 0.97 | Elapsed: 14.25s
WARNING:root: [*] Fri Dec 23 20:35:06 2022: Train Epoch: 2 [12800/50750 (25%)]	Loss: 0.129473 | F1-score: 0.97 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 20:35:20 2022: Train Epoch: 2 [19200/50750 (38%)]	Loss: 0.083511 | F1-score: 0.98 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 20:35:34 2022: Train Epoch: 2 [25600/50750 (50%)]	Loss: 0.107910 | F1-score: 0.98 | Elapsed: 14.24s
WARNING:root: [*] Fri Dec 23 20:35:49 2022: Train Epoch: 2 [32000/50750 (63%)]	Loss: 0.099959 | F1-score: 0.98 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 20:36:03 2022: Train Epoch: 2 [38400/50750 (76%)]	Loss: 0.060268 | F1-score: 0.98 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 20:36:17 2022: Train Epoch: 2 [44800/50750 (88%)]	Loss: 0.073549 | F1-score: 0.98 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 20:36:30 2022:    2    | Tr.loss: 0.081768 | Tr.F1.:   0.98    |  112.78  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 20:36:30 2022: Train Epoch: 3 [  0  /50750 (0 %)]	Loss: 0.031327 | F1-score: 1.00 | Elapsed: 0.14s
WARNING:root: [*] Fri Dec 23 20:36:44 2022: Train Epoch: 3 [6400 /50750 (13%)]	Loss: 0.059032 | F1-score: 0.98 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 20:36:59 2022: Train Epoch: 3 [12800/50750 (25%)]	Loss: 0.013050 | F1-score: 0.98 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 20:37:13 2022: Train Epoch: 3 [19200/50750 (38%)]	Loss: 0.046396 | F1-score: 0.98 | Elapsed: 14.20s
WARNING:root: [*] Fri Dec 23 20:37:27 2022: Train Epoch: 3 [25600/50750 (50%)]	Loss: 0.022698 | F1-score: 0.98 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 20:37:41 2022: Train Epoch: 3 [32000/50750 (63%)]	Loss: 0.137395 | F1-score: 0.98 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 20:37:56 2022: Train Epoch: 3 [38400/50750 (76%)]	Loss: 0.041835 | F1-score: 0.98 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 20:38:10 2022: Train Epoch: 3 [44800/50750 (88%)]	Loss: 0.071477 | F1-score: 0.98 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 20:38:23 2022:    3    | Tr.loss: 0.066490 | Tr.F1.:   0.98    |  112.76  s
WARNING:root:
        [!] Fri Dec 23 20:38:23 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671824303-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671824303-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671824303-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671824303-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 20:38:41 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.680861 | F1-score: 0.68 | Elapsed: 0.14s
WARNING:root: [*] Fri Dec 23 20:38:55 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.228697 | F1-score: 0.87 | Elapsed: 14.25s
WARNING:root: [*] Fri Dec 23 20:39:09 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.223856 | F1-score: 0.91 | Elapsed: 14.24s
WARNING:root: [*] Fri Dec 23 20:39:23 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.185030 | F1-score: 0.92 | Elapsed: 14.25s
WARNING:root: [*] Fri Dec 23 20:39:38 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.062488 | F1-score: 0.93 | Elapsed: 14.25s
WARNING:root: [*] Fri Dec 23 20:39:52 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.151215 | F1-score: 0.94 | Elapsed: 14.25s
WARNING:root: [*] Fri Dec 23 20:40:06 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.129386 | F1-score: 0.94 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 20:40:20 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.112164 | F1-score: 0.95 | Elapsed: 14.24s
WARNING:root: [*] Fri Dec 23 20:40:33 2022:    1    | Tr.loss: 0.168583 | Tr.F1.:   0.95    |  112.94  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 20:40:33 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.047260 | F1-score: 0.99 | Elapsed: 0.16s
WARNING:root: [*] Fri Dec 23 20:40:48 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.059063 | F1-score: 0.97 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 20:41:02 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.069589 | F1-score: 0.98 | Elapsed: 14.24s
WARNING:root: [*] Fri Dec 23 20:41:16 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.063559 | F1-score: 0.98 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 20:41:30 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.248585 | F1-score: 0.98 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 20:41:45 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.032710 | F1-score: 0.98 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 20:41:59 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.029895 | F1-score: 0.98 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 20:42:13 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.042815 | F1-score: 0.98 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 20:42:26 2022:    2    | Tr.loss: 0.083205 | Tr.F1.:   0.98    |  112.80  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 20:42:26 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.029024 | F1-score: 0.99 | Elapsed: 0.14s
WARNING:root: [*] Fri Dec 23 20:42:40 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.032828 | F1-score: 0.98 | Elapsed: 14.24s
WARNING:root: [*] Fri Dec 23 20:42:55 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.012675 | F1-score: 0.98 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 20:43:09 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.092157 | F1-score: 0.98 | Elapsed: 14.21s
WARNING:root: [*] Fri Dec 23 20:43:23 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.142288 | F1-score: 0.98 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 20:43:37 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.073975 | F1-score: 0.98 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 20:43:52 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.058761 | F1-score: 0.98 | Elapsed: 14.20s
WARNING:root: [*] Fri Dec 23 20:44:06 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.143053 | F1-score: 0.98 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 20:44:19 2022:    3    | Tr.loss: 0.069884 | Tr.F1.:   0.98    |  112.80  s
WARNING:root:
        [!] Fri Dec 23 20:44:19 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671824659-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671824659-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671824659-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671824659-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 20:44:37 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.702224 | F1-score: 0.47 | Elapsed: 0.14s
WARNING:root: [*] Fri Dec 23 20:44:51 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.177136 | F1-score: 0.87 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 20:45:05 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.194952 | F1-score: 0.91 | Elapsed: 14.24s
WARNING:root: [*] Fri Dec 23 20:45:19 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.128530 | F1-score: 0.92 | Elapsed: 14.24s
WARNING:root: [*] Fri Dec 23 20:45:33 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.176558 | F1-score: 0.94 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 20:45:48 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.191902 | F1-score: 0.94 | Elapsed: 14.26s
WARNING:root: [*] Fri Dec 23 20:46:02 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.082555 | F1-score: 0.95 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 20:46:16 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.065269 | F1-score: 0.95 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 20:46:29 2022:    1    | Tr.loss: 0.162098 | Tr.F1.:   0.95    |  112.90  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 20:46:29 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.122709 | F1-score: 0.97 | Elapsed: 0.15s
WARNING:root: [*] Fri Dec 23 20:46:44 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.060602 | F1-score: 0.98 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 20:46:58 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.077768 | F1-score: 0.98 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 20:47:12 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.050240 | F1-score: 0.98 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 20:47:26 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.056554 | F1-score: 0.98 | Elapsed: 14.25s
WARNING:root: [*] Fri Dec 23 20:47:41 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.231193 | F1-score: 0.98 | Elapsed: 14.23s
WARNING:root: [*] Fri Dec 23 20:47:55 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.061671 | F1-score: 0.98 | Elapsed: 14.25s
WARNING:root: [*] Fri Dec 23 20:48:09 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.132156 | F1-score: 0.98 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 20:48:22 2022:    2    | Tr.loss: 0.079760 | Tr.F1.:   0.98    |  112.87  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 20:48:22 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.042566 | F1-score: 1.00 | Elapsed: 0.14s
WARNING:root: [*] Fri Dec 23 20:48:37 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.063043 | F1-score: 0.98 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 20:48:51 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.055602 | F1-score: 0.98 | Elapsed: 14.25s
WARNING:root: [*] Fri Dec 23 20:49:05 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.038756 | F1-score: 0.98 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 20:49:19 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.030445 | F1-score: 0.98 | Elapsed: 14.25s
WARNING:root: [*] Fri Dec 23 20:49:33 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.042477 | F1-score: 0.98 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 20:49:48 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.141526 | F1-score: 0.98 | Elapsed: 14.24s
WARNING:root: [*] Fri Dec 23 20:50:02 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.134915 | F1-score: 0.98 | Elapsed: 14.22s
WARNING:root: [*] Fri Dec 23 20:50:15 2022:    3    | Tr.loss: 0.067342 | Tr.F1.:   0.98    |  112.87  s
WARNING:root:
        [!] Fri Dec 23 20:50:15 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671825015-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671825015-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671825015-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671825015-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\metrics_trainSize_76126_ep_3_cv_3_maxLen_4096_vocabSize_5000_embeddingDim_64_hiddenNeurons_512_256_128_batchNormConv_False_batchNormFFNN_False_filterSizes_2_3_4_5.json
WARNING:root: [!] Average epoch time: 112.85s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.5372 -- F1: 0.6877
	FPR:  0.001 -- TPR: 0.8965 -- F1: 0.9451
	FPR:   0.01 -- TPR: 0.9595 -- F1: 0.9771
	FPR:    0.1 -- TPR: 0.9952 -- F1: 0.9746

WARNING:root: [!] Using vocabSize: 5000 | maxLen: 512
WARNING:root: [!] Using device: cuda:0 | Dataset size: 76126
WARNING:root: [!] Epochs per fold: 3 | Model config: {'vocabSize': 5000, 'embeddingDim': 64, 'hiddenNeurons': [512, 256, 128], 'batchNormConv': False, 'batchNormFFNN': False, 'filterSizes': [2, 3, 4, 5]}
WARNING:root: [!] Fold 1/3 | Train set size: 50750, Validation set size: 25376
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 20:51:03 2022: Train Epoch: 1 [  0  /50750 (0 %)]	Loss: 0.695090 | F1-score: 0.52 | Elapsed: 0.21s
WARNING:root: [*] Fri Dec 23 20:51:05 2022: Train Epoch: 1 [6400 /50750 (13%)]	Loss: 0.254080 | F1-score: 0.87 | Elapsed: 2.33s
WARNING:root: [*] Fri Dec 23 20:51:07 2022: Train Epoch: 1 [12800/50750 (25%)]	Loss: 0.220258 | F1-score: 0.91 | Elapsed: 2.15s
WARNING:root: [*] Fri Dec 23 20:51:09 2022: Train Epoch: 1 [19200/50750 (38%)]	Loss: 0.040832 | F1-score: 0.93 | Elapsed: 2.16s
WARNING:root: [*] Fri Dec 23 20:51:12 2022: Train Epoch: 1 [25600/50750 (50%)]	Loss: 0.118716 | F1-score: 0.93 | Elapsed: 2.19s
WARNING:root: [*] Fri Dec 23 20:51:14 2022: Train Epoch: 1 [32000/50750 (63%)]	Loss: 0.209346 | F1-score: 0.94 | Elapsed: 2.19s
WARNING:root: [*] Fri Dec 23 20:51:16 2022: Train Epoch: 1 [38400/50750 (76%)]	Loss: 0.249216 | F1-score: 0.94 | Elapsed: 2.19s
WARNING:root: [*] Fri Dec 23 20:51:18 2022: Train Epoch: 1 [44800/50750 (88%)]	Loss: 0.129422 | F1-score: 0.95 | Elapsed: 2.18s
WARNING:root: [*] Fri Dec 23 20:51:20 2022:    1    | Tr.loss: 0.170605 | Tr.F1.:   0.95    |   17.65  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 20:51:20 2022: Train Epoch: 2 [  0  /50750 (0 %)]	Loss: 0.177309 | F1-score: 0.93 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 20:51:23 2022: Train Epoch: 2 [6400 /50750 (13%)]	Loss: 0.107886 | F1-score: 0.97 | Elapsed: 2.22s
WARNING:root: [*] Fri Dec 23 20:51:25 2022: Train Epoch: 2 [12800/50750 (25%)]	Loss: 0.145978 | F1-score: 0.97 | Elapsed: 2.21s
WARNING:root: [*] Fri Dec 23 20:51:27 2022: Train Epoch: 2 [19200/50750 (38%)]	Loss: 0.184992 | F1-score: 0.97 | Elapsed: 2.21s
WARNING:root: [*] Fri Dec 23 20:51:29 2022: Train Epoch: 2 [25600/50750 (50%)]	Loss: 0.087663 | F1-score: 0.97 | Elapsed: 2.21s
WARNING:root: [*] Fri Dec 23 20:51:31 2022: Train Epoch: 2 [32000/50750 (63%)]	Loss: 0.138361 | F1-score: 0.97 | Elapsed: 2.22s
WARNING:root: [*] Fri Dec 23 20:51:34 2022: Train Epoch: 2 [38400/50750 (76%)]	Loss: 0.063913 | F1-score: 0.97 | Elapsed: 2.21s
WARNING:root: [*] Fri Dec 23 20:51:36 2022: Train Epoch: 2 [44800/50750 (88%)]	Loss: 0.013009 | F1-score: 0.97 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 20:51:38 2022:    2    | Tr.loss: 0.094534 | Tr.F1.:   0.97    |   17.58  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 20:51:38 2022: Train Epoch: 3 [  0  /50750 (0 %)]	Loss: 0.099365 | F1-score: 0.98 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 20:51:40 2022: Train Epoch: 3 [6400 /50750 (13%)]	Loss: 0.051349 | F1-score: 0.98 | Elapsed: 2.22s
WARNING:root: [*] Fri Dec 23 20:51:42 2022: Train Epoch: 3 [12800/50750 (25%)]	Loss: 0.072258 | F1-score: 0.98 | Elapsed: 2.22s
WARNING:root: [*] Fri Dec 23 20:51:45 2022: Train Epoch: 3 [19200/50750 (38%)]	Loss: 0.074547 | F1-score: 0.98 | Elapsed: 2.22s
WARNING:root: [*] Fri Dec 23 20:51:47 2022: Train Epoch: 3 [25600/50750 (50%)]	Loss: 0.102189 | F1-score: 0.98 | Elapsed: 2.20s
WARNING:root: [*] Fri Dec 23 20:51:49 2022: Train Epoch: 3 [32000/50750 (63%)]	Loss: 0.143338 | F1-score: 0.98 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 20:51:51 2022: Train Epoch: 3 [38400/50750 (76%)]	Loss: 0.038456 | F1-score: 0.98 | Elapsed: 2.21s
WARNING:root: [*] Fri Dec 23 20:51:53 2022: Train Epoch: 3 [44800/50750 (88%)]	Loss: 0.126158 | F1-score: 0.98 | Elapsed: 2.21s
WARNING:root: [*] Fri Dec 23 20:51:55 2022:    3    | Tr.loss: 0.081456 | Tr.F1.:   0.98    |   17.61  s
WARNING:root:
        [!] Fri Dec 23 20:51:55 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671825115-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671825115-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671825115-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671825115-duration.pickle
WARNING:root: [!] Fold 2/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 20:51:58 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.732292 | F1-score: 0.13 | Elapsed: 0.02s
WARNING:root: [*] Fri Dec 23 20:52:00 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.197324 | F1-score: 0.86 | Elapsed: 2.26s
WARNING:root: [*] Fri Dec 23 20:52:02 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.099501 | F1-score: 0.90 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 20:52:05 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.123704 | F1-score: 0.92 | Elapsed: 2.22s
WARNING:root: [*] Fri Dec 23 20:52:07 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.138014 | F1-score: 0.93 | Elapsed: 2.22s
WARNING:root: [*] Fri Dec 23 20:52:09 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.143006 | F1-score: 0.94 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 20:52:11 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.063268 | F1-score: 0.94 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 20:52:14 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.233124 | F1-score: 0.94 | Elapsed: 2.22s
WARNING:root: [*] Fri Dec 23 20:52:16 2022:    1    | Tr.loss: 0.176413 | Tr.F1.:   0.95    |   17.69  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 20:52:16 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.110936 | F1-score: 0.93 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 20:52:18 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.123809 | F1-score: 0.97 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 20:52:20 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.085800 | F1-score: 0.97 | Elapsed: 2.22s
WARNING:root: [*] Fri Dec 23 20:52:22 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.087518 | F1-score: 0.97 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 20:52:24 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.088781 | F1-score: 0.97 | Elapsed: 2.21s
WARNING:root: [*] Fri Dec 23 20:52:27 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.213741 | F1-score: 0.97 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 20:52:29 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.037157 | F1-score: 0.97 | Elapsed: 2.22s
WARNING:root: [*] Fri Dec 23 20:52:31 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.030967 | F1-score: 0.97 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 20:52:33 2022:    2    | Tr.loss: 0.098335 | Tr.F1.:   0.97    |   17.67  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 20:52:33 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.098854 | F1-score: 0.97 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 20:52:35 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.078352 | F1-score: 0.97 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 20:52:38 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.046646 | F1-score: 0.97 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 20:52:40 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.099421 | F1-score: 0.97 | Elapsed: 2.22s
WARNING:root: [*] Fri Dec 23 20:52:42 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.113784 | F1-score: 0.97 | Elapsed: 2.22s
WARNING:root: [*] Fri Dec 23 20:52:44 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.182775 | F1-score: 0.97 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 20:52:47 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.078754 | F1-score: 0.97 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 20:52:49 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.103034 | F1-score: 0.97 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 20:52:51 2022:    3    | Tr.loss: 0.084667 | Tr.F1.:   0.97    |   17.68  s
WARNING:root:
        [!] Fri Dec 23 20:52:51 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671825171-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671825171-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671825171-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671825171-duration.pickle
WARNING:root: [!] Fold 3/3 | Train set size: 50751, Validation set size: 25375
WARNING:root: [*] Started epoch: 1
WARNING:root: [*] Fri Dec 23 20:52:53 2022: Train Epoch: 1 [  0  /50751 (0 %)]	Loss: 0.704971 | F1-score: 0.53 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 20:52:56 2022: Train Epoch: 1 [6400 /50751 (13%)]	Loss: 0.300407 | F1-score: 0.88 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 20:52:58 2022: Train Epoch: 1 [12800/50751 (25%)]	Loss: 0.079565 | F1-score: 0.91 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 20:53:00 2022: Train Epoch: 1 [19200/50751 (38%)]	Loss: 0.111051 | F1-score: 0.92 | Elapsed: 2.36s
WARNING:root: [*] Fri Dec 23 20:53:03 2022: Train Epoch: 1 [25600/50751 (50%)]	Loss: 0.231421 | F1-score: 0.93 | Elapsed: 2.31s
WARNING:root: [*] Fri Dec 23 20:53:05 2022: Train Epoch: 1 [32000/50751 (63%)]	Loss: 0.079088 | F1-score: 0.94 | Elapsed: 2.34s
WARNING:root: [*] Fri Dec 23 20:53:07 2022: Train Epoch: 1 [38400/50751 (76%)]	Loss: 0.086843 | F1-score: 0.94 | Elapsed: 2.31s
WARNING:root: [*] Fri Dec 23 20:53:09 2022: Train Epoch: 1 [44800/50751 (88%)]	Loss: 0.091226 | F1-score: 0.95 | Elapsed: 2.31s
WARNING:root: [*] Fri Dec 23 20:53:12 2022:    1    | Tr.loss: 0.174930 | Tr.F1.:   0.95    |   18.24  s
WARNING:root: [*] Started epoch: 2
WARNING:root: [*] Fri Dec 23 20:53:12 2022: Train Epoch: 2 [  0  /50751 (0 %)]	Loss: 0.118680 | F1-score: 0.97 | Elapsed: 0.03s
WARNING:root: [*] Fri Dec 23 20:53:14 2022: Train Epoch: 2 [6400 /50751 (13%)]	Loss: 0.043629 | F1-score: 0.97 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 20:53:16 2022: Train Epoch: 2 [12800/50751 (25%)]	Loss: 0.103091 | F1-score: 0.97 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 20:53:18 2022: Train Epoch: 2 [19200/50751 (38%)]	Loss: 0.111888 | F1-score: 0.97 | Elapsed: 2.22s
WARNING:root: [*] Fri Dec 23 20:53:21 2022: Train Epoch: 2 [25600/50751 (50%)]	Loss: 0.057007 | F1-score: 0.97 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 20:53:23 2022: Train Epoch: 2 [32000/50751 (63%)]	Loss: 0.118998 | F1-score: 0.97 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 20:53:25 2022: Train Epoch: 2 [38400/50751 (76%)]	Loss: 0.295311 | F1-score: 0.97 | Elapsed: 2.22s
WARNING:root: [*] Fri Dec 23 20:53:27 2022: Train Epoch: 2 [44800/50751 (88%)]	Loss: 0.024068 | F1-score: 0.97 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 20:53:29 2022:    2    | Tr.loss: 0.099662 | Tr.F1.:   0.97    |   17.75  s
WARNING:root: [*] Started epoch: 3
WARNING:root: [*] Fri Dec 23 20:53:29 2022: Train Epoch: 3 [  0  /50751 (0 %)]	Loss: 0.083973 | F1-score: 0.97 | Elapsed: 0.02s
WARNING:root: [*] Fri Dec 23 20:53:32 2022: Train Epoch: 3 [6400 /50751 (13%)]	Loss: 0.039274 | F1-score: 0.98 | Elapsed: 2.26s
WARNING:root: [*] Fri Dec 23 20:53:34 2022: Train Epoch: 3 [12800/50751 (25%)]	Loss: 0.093171 | F1-score: 0.98 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 20:53:36 2022: Train Epoch: 3 [19200/50751 (38%)]	Loss: 0.046335 | F1-score: 0.98 | Elapsed: 2.22s
WARNING:root: [*] Fri Dec 23 20:53:38 2022: Train Epoch: 3 [25600/50751 (50%)]	Loss: 0.072265 | F1-score: 0.98 | Elapsed: 2.25s
WARNING:root: [*] Fri Dec 23 20:53:41 2022: Train Epoch: 3 [32000/50751 (63%)]	Loss: 0.114635 | F1-score: 0.97 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 20:53:43 2022: Train Epoch: 3 [38400/50751 (76%)]	Loss: 0.085644 | F1-score: 0.97 | Elapsed: 2.24s
WARNING:root: [*] Fri Dec 23 20:53:45 2022: Train Epoch: 3 [44800/50751 (88%)]	Loss: 0.083790 | F1-score: 0.97 | Elapsed: 2.23s
WARNING:root: [*] Fri Dec 23 20:53:47 2022:    3    | Tr.loss: 0.083725 | Tr.F1.:   0.97    |   17.74  s
WARNING:root:
        [!] Fri Dec 23 20:53:47 2022: Dumped results:
                model: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671825227-model.torch
                train loss list: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671825227-train_losses.pickle
                train metrics : C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671825227-train_metrics.pickle
                duration: C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\trainingFiles\trainingFiles_1671825227-duration.pickle
WARNING:root: [!] Metrics saved to C:\Users\dtrizna\Code\nebula\evaluation\crossValidation_WithAPIargs\Cnn1DLinear_VocabSize_maxLen\metrics_trainSize_76126_ep_3_cv_3_maxLen_512_vocabSize_5000_embeddingDim_64_hiddenNeurons_512_256_128_batchNormConv_False_batchNormFFNN_False_filterSizes_2_3_4_5.json
WARNING:root: [!] Average epoch time: 17.73s | Mean values over 3 folds:
	FPR: 0.0001 -- TPR: 0.5348 -- F1: 0.6952
	FPR:  0.001 -- TPR: 0.8920 -- F1: 0.9426
	FPR:   0.01 -- TPR: 0.9434 -- F1: 0.9686
	FPR:    0.1 -- TPR: 0.9916 -- F1: 0.9724

