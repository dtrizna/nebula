01/23/2023 04:15:33 PM  [!] Cross-Validation config: 50000 vocab size, 512 maxLen, None train_limit, speakeasy_trainset_BPE train_folder, 42 random_state, 16 batchSize, 2000 optim_step_size
01/23/2023 04:15:34 PM  [!] Using device: cuda:0 | Dataset size: 76126
01/23/2023 04:15:34 PM  [!] Epochs per fold: 3 | Model config: {'vocabSize': 50000, 'maxLen': 512, 'dModel': 64, 'nHeads': 8, 'dHidden': 256, 'nLayers': 1, 'numClasses': 1, 'hiddenNeurons': [64], 'layerNorm': False, 'dropout': 0.3}
01/23/2023 04:15:34 PM  [!] Fold 1/2 | Train set size: 38063, Validation set size: 38063
01/23/2023 04:15:34 PM  [*] Started epoch: 1
01/23/2023 04:15:38 PM  [*] Mon Jan 23 16:15:38 2023: Train Epoch: 1 [  0  /38063 (0 %)]	Loss: 2.197678 | FPR 0.001 -- TPR 0.1111 | F1 0.2000 | Elapsed: 3.32s
01/23/2023 04:15:41 PM  [*] Mon Jan 23 16:15:41 2023: Train Epoch: 1 [1600 /38063 (4 %)]	Loss: 0.605756 | FPR 0.001 -- TPR 0.4122 | F1 0.5352 | Elapsed: 3.60s
01/23/2023 04:15:45 PM  [*] Mon Jan 23 16:15:45 2023: Train Epoch: 1 [3200 /38063 (8 %)]	Loss: 0.307120 | FPR 0.001 -- TPR 0.6193 | F1 0.7281 | Elapsed: 3.96s
01/23/2023 04:15:50 PM  [*] Mon Jan 23 16:15:50 2023: Train Epoch: 1 [4800 /38063 (13%)]	Loss: 0.288167 | FPR 0.001 -- TPR 0.6766 | F1 0.7831 | Elapsed: 4.54s
01/23/2023 04:15:54 PM  [*] Mon Jan 23 16:15:54 2023: Train Epoch: 1 [6400 /38063 (17%)]	Loss: 0.476307 | FPR 0.001 -- TPR 0.6218 | F1 0.7317 | Elapsed: 4.49s
01/23/2023 04:15:58 PM  [*] Mon Jan 23 16:15:58 2023: Train Epoch: 1 [8000 /38063 (21%)]	Loss: 0.298854 | FPR 0.001 -- TPR 0.7294 | F1 0.8258 | Elapsed: 4.15s
01/23/2023 04:16:02 PM  [*] Mon Jan 23 16:16:02 2023: Train Epoch: 1 [9600 /38063 (25%)]	Loss: 0.248017 | FPR 0.001 -- TPR 0.7486 | F1 0.8181 | Elapsed: 4.21s
01/23/2023 04:16:07 PM  [*] Mon Jan 23 16:16:07 2023: Train Epoch: 1 [11200/38063 (29%)]	Loss: 0.529920 | FPR 0.001 -- TPR 0.7496 | F1 0.8298 | Elapsed: 4.31s
01/23/2023 04:16:12 PM  [*] Mon Jan 23 16:16:12 2023: Train Epoch: 1 [12800/38063 (34%)]	Loss: 0.281190 | FPR 0.001 -- TPR 0.7765 | F1 0.8606 | Elapsed: 5.20s
01/23/2023 04:16:16 PM  [*] Mon Jan 23 16:16:16 2023: Train Epoch: 1 [14400/38063 (38%)]	Loss: 0.094331 | FPR 0.001 -- TPR 0.8313 | F1 0.8931 | Elapsed: 4.09s
01/23/2023 04:16:20 PM  [*] Mon Jan 23 16:16:20 2023: Train Epoch: 1 [16000/38063 (42%)]	Loss: 0.345238 | FPR 0.001 -- TPR 0.8318 | F1 0.8961 | Elapsed: 3.57s
01/23/2023 04:16:23 PM  [*] Mon Jan 23 16:16:23 2023: Train Epoch: 1 [17600/38063 (46%)]	Loss: 0.143652 | FPR 0.001 -- TPR 0.8047 | F1 0.8779 | Elapsed: 3.55s
01/23/2023 04:16:27 PM  [*] Mon Jan 23 16:16:27 2023: Train Epoch: 1 [19200/38063 (50%)]	Loss: 0.118205 | FPR 0.001 -- TPR 0.8364 | F1 0.8982 | Elapsed: 4.15s
01/23/2023 04:16:31 PM  [*] Mon Jan 23 16:16:31 2023: Train Epoch: 1 [20800/38063 (55%)]	Loss: 0.584265 | FPR 0.001 -- TPR 0.8472 | F1 0.8941 | Elapsed: 3.90s
01/23/2023 04:16:35 PM  [*] Mon Jan 23 16:16:35 2023: Train Epoch: 1 [22400/38063 (59%)]	Loss: 0.328854 | FPR 0.001 -- TPR 0.8668 | F1 0.9152 | Elapsed: 4.03s
01/23/2023 04:16:39 PM  [*] Mon Jan 23 16:16:39 2023: Train Epoch: 1 [24000/38063 (63%)]	Loss: 0.247877 | FPR 0.001 -- TPR 0.8469 | F1 0.9029 | Elapsed: 3.73s
01/23/2023 04:16:43 PM  [*] Mon Jan 23 16:16:43 2023: Train Epoch: 1 [25600/38063 (67%)]	Loss: 0.106380 | FPR 0.001 -- TPR 0.8554 | F1 0.9083 | Elapsed: 4.00s
01/23/2023 04:16:47 PM  [*] Mon Jan 23 16:16:47 2023: Train Epoch: 1 [27200/38063 (71%)]	Loss: 0.262352 | FPR 0.001 -- TPR 0.8843 | F1 0.9303 | Elapsed: 3.95s
01/23/2023 04:16:51 PM  [*] Mon Jan 23 16:16:51 2023: Train Epoch: 1 [28800/38063 (76%)]	Loss: 0.093360 | FPR 0.001 -- TPR 0.8743 | F1 0.9179 | Elapsed: 3.70s
01/23/2023 04:16:55 PM  [*] Mon Jan 23 16:16:55 2023: Train Epoch: 1 [30400/38063 (80%)]	Loss: 0.316538 | FPR 0.001 -- TPR 0.8947 | F1 0.9380 | Elapsed: 4.07s
01/23/2023 04:16:59 PM [!] Learning rate: 2.5e-05
01/23/2023 04:16:59 PM  [*] Mon Jan 23 16:16:59 2023: Train Epoch: 1 [32000/38063 (84%)]	Loss: 0.033967 | FPR 0.001 -- TPR 0.9131 | F1 0.9503 | Elapsed: 3.87s
01/23/2023 04:17:02 PM  [*] Mon Jan 23 16:17:02 2023: Train Epoch: 1 [33600/38063 (88%)]	Loss: 0.110011 | FPR 0.001 -- TPR 0.8963 | F1 0.9385 | Elapsed: 3.84s
01/23/2023 04:17:06 PM  [*] Mon Jan 23 16:17:06 2023: Train Epoch: 1 [35200/38063 (92%)]	Loss: 0.370022 | FPR 0.001 -- TPR 0.9064 | F1 0.9458 | Elapsed: 3.75s
01/23/2023 04:17:10 PM  [*] Mon Jan 23 16:17:10 2023: Train Epoch: 1 [36800/38063 (97%)]	Loss: 0.332282 | FPR 0.001 -- TPR 0.8868 | F1 0.9335 | Elapsed: 3.44s
01/23/2023 04:17:13 PM  [*] Mon Jan 23 16:17:13 2023:    1    | Tr.loss: 0.295563 | FPR 0.001 -- TPR: 0.80 |  F1: 0.87 | Elapsed:   98.42  s
01/23/2023 04:17:13 PM  [*] Started epoch: 2
01/23/2023 04:17:13 PM  [*] Mon Jan 23 16:17:13 2023: Train Epoch: 2 [  0  /38063 (0 %)]	Loss: 0.174210 | FPR 0.001 -- TPR 1.0000 | F1 1.0000 | Elapsed: 0.06s
01/23/2023 04:17:17 PM  [*] Mon Jan 23 16:17:17 2023: Train Epoch: 2 [1600 /38063 (4 %)]	Loss: 0.173663 | FPR 0.001 -- TPR 0.9339 | F1 0.9620 | Elapsed: 4.15s
01/23/2023 04:17:21 PM  [*] Mon Jan 23 16:17:21 2023: Train Epoch: 2 [3200 /38063 (8 %)]	Loss: 0.250677 | FPR 0.001 -- TPR 0.9326 | F1 0.9615 | Elapsed: 3.87s
01/23/2023 04:17:24 PM  [*] Mon Jan 23 16:17:24 2023: Train Epoch: 2 [4800 /38063 (13%)]	Loss: 0.282540 | FPR 0.001 -- TPR 0.9150 | F1 0.9499 | Elapsed: 3.59s
01/23/2023 04:17:28 PM  [*] Mon Jan 23 16:17:28 2023: Train Epoch: 2 [6400 /38063 (17%)]	Loss: 0.131196 | FPR 0.001 -- TPR 0.9328 | F1 0.9508 | Elapsed: 3.97s
01/23/2023 04:17:32 PM  [*] Mon Jan 23 16:17:32 2023: Train Epoch: 2 [8000 /38063 (21%)]	Loss: 0.036700 | FPR 0.001 -- TPR 0.9510 | F1 0.9721 | Elapsed: 3.72s
01/23/2023 04:17:36 PM  [*] Mon Jan 23 16:17:36 2023: Train Epoch: 2 [9600 /38063 (25%)]	Loss: 0.241976 | FPR 0.001 -- TPR 0.9295 | F1 0.9591 | Elapsed: 3.60s
01/23/2023 04:17:40 PM  [*] Mon Jan 23 16:17:40 2023: Train Epoch: 2 [11200/38063 (29%)]	Loss: 0.090755 | FPR 0.001 -- TPR 0.9319 | F1 0.9613 | Elapsed: 3.99s
01/23/2023 04:17:43 PM  [*] Mon Jan 23 16:17:43 2023: Train Epoch: 2 [12800/38063 (34%)]	Loss: 0.127200 | FPR 0.001 -- TPR 0.9385 | F1 0.9646 | Elapsed: 3.80s
01/23/2023 04:17:47 PM  [*] Mon Jan 23 16:17:47 2023: Train Epoch: 2 [14400/38063 (38%)]	Loss: 0.047560 | FPR 0.001 -- TPR 0.9296 | F1 0.9484 | Elapsed: 3.61s
01/23/2023 04:17:51 PM  [*] Mon Jan 23 16:17:51 2023: Train Epoch: 2 [16000/38063 (42%)]	Loss: 0.186280 | FPR 0.001 -- TPR 0.9269 | F1 0.9583 | Elapsed: 3.73s
01/23/2023 04:17:55 PM  [*] Mon Jan 23 16:17:55 2023: Train Epoch: 2 [17600/38063 (46%)]	Loss: 0.204887 | FPR 0.001 -- TPR 0.9494 | F1 0.9711 | Elapsed: 3.89s
01/23/2023 04:17:58 PM  [*] Mon Jan 23 16:17:58 2023: Train Epoch: 2 [19200/38063 (50%)]	Loss: 0.128901 | FPR 0.001 -- TPR 0.9389 | F1 0.9655 | Elapsed: 3.87s
01/23/2023 04:18:02 PM  [*] Mon Jan 23 16:18:02 2023: Train Epoch: 2 [20800/38063 (55%)]	Loss: 0.113038 | FPR 0.001 -- TPR 0.9277 | F1 0.9494 | Elapsed: 3.46s
01/23/2023 04:18:06 PM  [*] Mon Jan 23 16:18:06 2023: Train Epoch: 2 [22400/38063 (59%)]	Loss: 0.052474 | FPR 0.001 -- TPR 0.9269 | F1 0.9579 | Elapsed: 3.71s
01/23/2023 04:18:09 PM  [*] Mon Jan 23 16:18:09 2023: Train Epoch: 2 [24000/38063 (63%)]	Loss: 0.105298 | FPR 0.001 -- TPR 0.9297 | F1 0.9597 | Elapsed: 3.53s
01/23/2023 04:18:13 PM  [*] Mon Jan 23 16:18:13 2023: Train Epoch: 2 [25600/38063 (67%)]	Loss: 0.244464 | FPR 0.001 -- TPR 0.9495 | F1 0.9696 | Elapsed: 3.54s
01/23/2023 04:18:13 PM [!] Learning rate: 2.5e-06
01/23/2023 04:18:16 PM  [*] Mon Jan 23 16:18:16 2023: Train Epoch: 2 [27200/38063 (71%)]	Loss: 0.356860 | FPR 0.001 -- TPR 0.9526 | F1 0.9732 | Elapsed: 3.56s
01/23/2023 04:18:20 PM  [*] Mon Jan 23 16:18:20 2023: Train Epoch: 2 [28800/38063 (76%)]	Loss: 0.081203 | FPR 0.001 -- TPR 0.9189 | F1 0.9516 | Elapsed: 3.64s
01/23/2023 04:18:23 PM  [*] Mon Jan 23 16:18:23 2023: Train Epoch: 2 [30400/38063 (80%)]	Loss: 0.438533 | FPR 0.001 -- TPR 0.9269 | F1 0.9564 | Elapsed: 3.53s
01/23/2023 04:18:27 PM  [*] Mon Jan 23 16:18:27 2023: Train Epoch: 2 [32000/38063 (84%)]	Loss: 0.170502 | FPR 0.001 -- TPR 0.9505 | F1 0.9713 | Elapsed: 3.63s
01/23/2023 04:18:31 PM  [*] Mon Jan 23 16:18:31 2023: Train Epoch: 2 [33600/38063 (88%)]	Loss: 0.120656 | FPR 0.001 -- TPR 0.9382 | F1 0.9545 | Elapsed: 3.52s
01/23/2023 04:18:35 PM  [*] Mon Jan 23 16:18:35 2023: Train Epoch: 2 [35200/38063 (92%)]	Loss: 0.075488 | FPR 0.001 -- TPR 0.9464 | F1 0.9689 | Elapsed: 4.24s
01/23/2023 04:18:39 PM  [*] Mon Jan 23 16:18:39 2023: Train Epoch: 2 [36800/38063 (97%)]	Loss: 0.241353 | FPR 0.001 -- TPR 0.9495 | F1 0.9718 | Elapsed: 3.71s
01/23/2023 04:18:42 PM  [*] Mon Jan 23 16:18:42 2023:    2    | Tr.loss: 0.158481 | FPR 0.001 -- TPR: 0.94 |  F1: 0.96 | Elapsed:   89.19  s
01/23/2023 04:18:42 PM  [*] Started epoch: 3
01/23/2023 04:18:42 PM  [*] Mon Jan 23 16:18:42 2023: Train Epoch: 3 [  0  /38063 (0 %)]	Loss: 0.154056 | FPR 0.001 -- TPR 1.0000 | F1 1.0000 | Elapsed: 0.04s
01/23/2023 04:18:46 PM  [*] Mon Jan 23 16:18:46 2023: Train Epoch: 3 [1600 /38063 (4 %)]	Loss: 0.037350 | FPR 0.001 -- TPR 0.9261 | F1 0.9472 | Elapsed: 4.06s
01/23/2023 04:18:50 PM  [*] Mon Jan 23 16:18:50 2023: Train Epoch: 3 [3200 /38063 (8 %)]	Loss: 0.162805 | FPR 0.001 -- TPR 0.9335 | F1 0.9625 | Elapsed: 4.13s
01/23/2023 04:18:54 PM  [*] Mon Jan 23 16:18:54 2023: Train Epoch: 3 [4800 /38063 (13%)]	Loss: 0.146024 | FPR 0.001 -- TPR 0.9291 | F1 0.9590 | Elapsed: 3.85s
01/23/2023 04:18:58 PM  [*] Mon Jan 23 16:18:58 2023: Train Epoch: 3 [6400 /38063 (17%)]	Loss: 0.164466 | FPR 0.001 -- TPR 0.9429 | F1 0.9673 | Elapsed: 3.70s
01/23/2023 04:19:01 PM  [*] Mon Jan 23 16:19:01 2023: Train Epoch: 3 [8000 /38063 (21%)]	Loss: 0.150675 | FPR 0.001 -- TPR 0.9371 | F1 0.9641 | Elapsed: 3.81s
01/23/2023 04:19:05 PM  [*] Mon Jan 23 16:19:05 2023: Train Epoch: 3 [9600 /38063 (25%)]	Loss: 0.245131 | FPR 0.001 -- TPR 0.9327 | F1 0.9615 | Elapsed: 3.72s
01/23/2023 04:19:09 PM  [*] Mon Jan 23 16:19:09 2023: Train Epoch: 3 [11200/38063 (29%)]	Loss: 0.198463 | FPR 0.001 -- TPR 0.9504 | F1 0.9723 | Elapsed: 3.60s
01/23/2023 04:19:12 PM  [*] Mon Jan 23 16:19:12 2023: Train Epoch: 3 [12800/38063 (34%)]	Loss: 0.043631 | FPR 0.001 -- TPR 0.9431 | F1 0.9677 | Elapsed: 3.74s
01/23/2023 04:19:16 PM  [*] Mon Jan 23 16:19:16 2023: Train Epoch: 3 [14400/38063 (38%)]	Loss: 0.209714 | FPR 0.001 -- TPR 0.9353 | F1 0.9626 | Elapsed: 3.78s
01/23/2023 04:19:20 PM  [*] Mon Jan 23 16:19:20 2023: Train Epoch: 3 [16000/38063 (42%)]	Loss: 0.047831 | FPR 0.001 -- TPR 0.9469 | F1 0.9702 | Elapsed: 3.65s
01/23/2023 04:19:24 PM  [*] Mon Jan 23 16:19:24 2023: Train Epoch: 3 [17600/38063 (46%)]	Loss: 0.117019 | FPR 0.001 -- TPR 0.9463 | F1 0.9693 | Elapsed: 3.77s
01/23/2023 04:19:27 PM  [*] Mon Jan 23 16:19:27 2023: Train Epoch: 3 [19200/38063 (50%)]	Loss: 0.054034 | FPR 0.001 -- TPR 0.9594 | F1 0.9774 | Elapsed: 3.64s
01/23/2023 04:19:29 PM [!] Learning rate: 2.5000000000000004e-07
01/23/2023 04:19:31 PM  [*] Mon Jan 23 16:19:31 2023: Train Epoch: 3 [20800/38063 (55%)]	Loss: 0.041607 | FPR 0.001 -- TPR 0.9313 | F1 0.9578 | Elapsed: 3.64s
01/23/2023 04:19:35 PM  [*] Mon Jan 23 16:19:35 2023: Train Epoch: 3 [22400/38063 (59%)]	Loss: 0.148993 | FPR 0.001 -- TPR 0.9458 | F1 0.9688 | Elapsed: 3.67s
01/23/2023 04:19:38 PM  [*] Mon Jan 23 16:19:38 2023: Train Epoch: 3 [24000/38063 (63%)]	Loss: 0.023457 | FPR 0.001 -- TPR 0.9572 | F1 0.9759 | Elapsed: 3.70s
01/23/2023 04:19:42 PM  [*] Mon Jan 23 16:19:42 2023: Train Epoch: 3 [25600/38063 (67%)]	Loss: 0.249609 | FPR 0.001 -- TPR 0.9499 | F1 0.9719 | Elapsed: 3.72s
01/23/2023 04:19:46 PM  [*] Mon Jan 23 16:19:46 2023: Train Epoch: 3 [27200/38063 (71%)]	Loss: 0.447109 | FPR 0.001 -- TPR 0.9507 | F1 0.9729 | Elapsed: 3.80s
01/23/2023 04:19:50 PM  [*] Mon Jan 23 16:19:50 2023: Train Epoch: 3 [28800/38063 (76%)]	Loss: 0.038744 | FPR 0.001 -- TPR 0.9440 | F1 0.9487 | Elapsed: 3.71s
01/23/2023 04:19:53 PM  [*] Mon Jan 23 16:19:53 2023: Train Epoch: 3 [30400/38063 (80%)]	Loss: 0.096627 | FPR 0.001 -- TPR 0.9305 | F1 0.9597 | Elapsed: 3.64s
01/23/2023 04:19:57 PM  [*] Mon Jan 23 16:19:57 2023: Train Epoch: 3 [32000/38063 (84%)]	Loss: 0.268792 | FPR 0.001 -- TPR 0.9415 | F1 0.9660 | Elapsed: 3.78s
01/23/2023 04:20:01 PM  [*] Mon Jan 23 16:20:01 2023: Train Epoch: 3 [33600/38063 (88%)]	Loss: 0.231562 | FPR 0.001 -- TPR 0.9543 | F1 0.9752 | Elapsed: 3.72s
01/23/2023 04:20:04 PM  [*] Mon Jan 23 16:20:04 2023: Train Epoch: 3 [35200/38063 (92%)]	Loss: 0.094103 | FPR 0.001 -- TPR 0.9373 | F1 0.9431 | Elapsed: 3.68s
01/23/2023 04:20:08 PM  [*] Mon Jan 23 16:20:08 2023: Train Epoch: 3 [36800/38063 (97%)]	Loss: 0.050121 | FPR 0.001 -- TPR 0.9310 | F1 0.9500 | Elapsed: 3.71s
01/23/2023 04:20:11 PM  [*] Mon Jan 23 16:20:11 2023:    3    | Tr.loss: 0.149009 | FPR 0.001 -- TPR: 0.94 |  F1: 0.96 | Elapsed:   89.28  s
01/23/2023 04:20:11 PM [!] Mon Jan 23 16:20:11 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\crossValidation\Transformer_512_BPE\nLayers\trainingFiles\trainingFiles_1674487211-model.torch
                losses    : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\crossValidation\Transformer_512_BPE\nLayers\trainingFiles\trainingFiles_1674487211-train_losses.npy
                duration  : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\crossValidation\Transformer_512_BPE\nLayers\trainingFiles\trainingFiles_1674487211-trainTime.npy
		train F1s : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\crossValidation\Transformer_512_BPE\nLayers\trainingFiles\trainingFiles_1674487211-trainF1s.npy
		train TPRs: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\crossValidation\Transformer_512_BPE\nLayers\trainingFiles\trainingFiles_1674487211-trainTPRs.npy
01/23/2023 04:20:11 PM  [!] Evaluating model on validation set...
01/23/2023 04:20:11 PM  [*] Predicting batch: 0/2379
01/23/2023 04:20:12 PM  [*] Predicting batch: 100/2379
01/23/2023 04:20:13 PM  [*] Predicting batch: 200/2379
01/23/2023 04:20:13 PM  [*] Predicting batch: 300/2379
01/23/2023 04:20:14 PM  [*] Predicting batch: 400/2379
01/23/2023 04:20:14 PM  [*] Predicting batch: 500/2379
01/23/2023 04:20:15 PM  [*] Predicting batch: 600/2379
01/23/2023 04:20:16 PM  [*] Predicting batch: 700/2379
01/23/2023 04:20:16 PM  [*] Predicting batch: 800/2379
01/23/2023 04:20:17 PM  [*] Predicting batch: 900/2379
01/23/2023 04:20:18 PM  [*] Predicting batch: 1000/2379
01/23/2023 04:20:18 PM  [*] Predicting batch: 1100/2379
01/23/2023 04:20:19 PM  [*] Predicting batch: 1200/2379
01/23/2023 04:20:20 PM  [*] Predicting batch: 1300/2379
01/23/2023 04:20:20 PM  [*] Predicting batch: 1400/2379
01/23/2023 04:20:21 PM  [*] Predicting batch: 1500/2379
01/23/2023 04:20:22 PM  [*] Predicting batch: 1600/2379
01/23/2023 04:20:22 PM  [*] Predicting batch: 1700/2379
01/23/2023 04:20:23 PM  [*] Predicting batch: 1800/2379
01/23/2023 04:20:24 PM  [*] Predicting batch: 1900/2379
01/23/2023 04:20:24 PM  [*] Predicting batch: 2000/2379
01/23/2023 04:20:25 PM  [*] Predicting batch: 2100/2379
01/23/2023 04:20:26 PM  [*] Predicting batch: 2200/2379
01/23/2023 04:20:26 PM  [*] Predicting batch: 2300/2379
01/23/2023 04:20:27 PM  [!] This fold metrics on validation set:
01/23/2023 04:20:27 PM  [!] FPR: 0.0001 | TPR: 0.3324535186119629 | F1: 0.4989950187887791
01/23/2023 04:20:27 PM  [!] FPR: 0.0003 | TPR: 0.6320692465939526 | F1: 0.7745065398335315
01/23/2023 04:20:27 PM  [!] FPR: 0.001 | TPR: 0.7438186546597834 | F1: 0.8528639458809917
01/23/2023 04:20:27 PM  [!] FPR: 0.003 | TPR: 0.7905523425066956 | F1: 0.8823376510852141
01/23/2023 04:20:27 PM  [!] FPR: 0.01 | TPR: 0.8495904980010092 | F1: 0.9163143132247665
01/23/2023 04:20:27 PM  [!] FPR: 0.03 | TPR: 0.9180996002018399 | F1: 0.9502249718785153
01/23/2023 04:20:27 PM  [!] FPR: 0.1 | TPR: 0.9703062531537476 | F1: 0.9616464704750914
01/23/2023 04:20:27 PM  [!] Fold 2/2 | Train set size: 38063, Validation set size: 38063
01/23/2023 04:20:27 PM  [*] Started epoch: 1
01/23/2023 04:20:27 PM  [*] Mon Jan 23 16:20:27 2023: Train Epoch: 1 [  0  /38063 (0 %)]	Loss: 3.204576 | FPR 0.001 -- TPR 0.0000 | F1 0.0000 | Elapsed: 0.07s
01/23/2023 04:20:32 PM  [*] Mon Jan 23 16:20:32 2023: Train Epoch: 1 [1600 /38063 (4 %)]	Loss: 0.543680 | FPR 0.001 -- TPR 0.4207 | F1 0.5320 | Elapsed: 4.26s
01/23/2023 04:20:35 PM  [*] Mon Jan 23 16:20:35 2023: Train Epoch: 1 [3200 /38063 (8 %)]	Loss: 1.069739 | FPR 0.001 -- TPR 0.5309 | F1 0.6463 | Elapsed: 3.63s
01/23/2023 04:20:40 PM  [*] Mon Jan 23 16:20:40 2023: Train Epoch: 1 [4800 /38063 (13%)]	Loss: 0.597278 | FPR 0.001 -- TPR 0.5793 | F1 0.6862 | Elapsed: 4.26s
01/23/2023 04:20:43 PM  [*] Mon Jan 23 16:20:43 2023: Train Epoch: 1 [6400 /38063 (17%)]	Loss: 0.435977 | FPR 0.001 -- TPR 0.6723 | F1 0.7783 | Elapsed: 3.72s
01/23/2023 04:20:47 PM  [*] Mon Jan 23 16:20:47 2023: Train Epoch: 1 [8000 /38063 (21%)]	Loss: 0.285453 | FPR 0.001 -- TPR 0.6808 | F1 0.7887 | Elapsed: 4.01s
01/23/2023 04:20:51 PM  [*] Mon Jan 23 16:20:51 2023: Train Epoch: 1 [9600 /38063 (25%)]	Loss: 0.484588 | FPR 0.001 -- TPR 0.6768 | F1 0.7822 | Elapsed: 3.61s
01/23/2023 04:20:55 PM  [*] Mon Jan 23 16:20:55 2023: Train Epoch: 1 [11200/38063 (29%)]	Loss: 0.527503 | FPR 0.001 -- TPR 0.7107 | F1 0.8102 | Elapsed: 3.89s
01/23/2023 04:20:59 PM  [*] Mon Jan 23 16:20:59 2023: Train Epoch: 1 [12800/38063 (34%)]	Loss: 0.332154 | FPR 0.001 -- TPR 0.7792 | F1 0.8572 | Elapsed: 4.27s
01/23/2023 04:21:03 PM  [*] Mon Jan 23 16:21:03 2023: Train Epoch: 1 [14400/38063 (38%)]	Loss: 0.105189 | FPR 0.001 -- TPR 0.8289 | F1 0.8954 | Elapsed: 3.67s
01/23/2023 04:21:06 PM  [*] Mon Jan 23 16:21:06 2023: Train Epoch: 1 [16000/38063 (42%)]	Loss: 0.207208 | FPR 0.001 -- TPR 0.8401 | F1 0.9032 | Elapsed: 3.43s
01/23/2023 04:21:10 PM  [*] Mon Jan 23 16:21:10 2023: Train Epoch: 1 [17600/38063 (46%)]	Loss: 0.177788 | FPR 0.001 -- TPR 0.7845 | F1 0.8560 | Elapsed: 3.63s
01/23/2023 04:21:13 PM  [*] Mon Jan 23 16:21:13 2023: Train Epoch: 1 [19200/38063 (50%)]	Loss: 0.464977 | FPR 0.001 -- TPR 0.7948 | F1 0.8685 | Elapsed: 3.57s
01/23/2023 04:21:17 PM  [*] Mon Jan 23 16:21:17 2023: Train Epoch: 1 [20800/38063 (55%)]	Loss: 0.319969 | FPR 0.001 -- TPR 0.8469 | F1 0.8989 | Elapsed: 3.54s
01/23/2023 04:21:21 PM  [*] Mon Jan 23 16:21:21 2023: Train Epoch: 1 [22400/38063 (59%)]	Loss: 0.129183 | FPR 0.001 -- TPR 0.8578 | F1 0.9142 | Elapsed: 3.58s
01/23/2023 04:21:24 PM  [*] Mon Jan 23 16:21:24 2023: Train Epoch: 1 [24000/38063 (63%)]	Loss: 0.174644 | FPR 0.001 -- TPR 0.8805 | F1 0.9285 | Elapsed: 3.56s
01/23/2023 04:21:28 PM  [*] Mon Jan 23 16:21:28 2023: Train Epoch: 1 [25600/38063 (67%)]	Loss: 0.848668 | FPR 0.001 -- TPR 0.8902 | F1 0.9352 | Elapsed: 3.47s
01/23/2023 04:21:31 PM  [*] Mon Jan 23 16:21:31 2023: Train Epoch: 1 [27200/38063 (71%)]	Loss: 0.114246 | FPR 0.001 -- TPR 0.8698 | F1 0.9224 | Elapsed: 3.47s
01/23/2023 04:21:35 PM  [*] Mon Jan 23 16:21:35 2023: Train Epoch: 1 [28800/38063 (76%)]	Loss: 0.187431 | FPR 0.001 -- TPR 0.8915 | F1 0.9357 | Elapsed: 3.55s
01/23/2023 04:21:38 PM  [*] Mon Jan 23 16:21:38 2023: Train Epoch: 1 [30400/38063 (80%)]	Loss: 0.192865 | FPR 0.001 -- TPR 0.8872 | F1 0.9333 | Elapsed: 3.56s
01/23/2023 04:21:42 PM [!] Learning rate: 2.5e-05
01/23/2023 04:21:42 PM  [*] Mon Jan 23 16:21:42 2023: Train Epoch: 1 [32000/38063 (84%)]	Loss: 0.168573 | FPR 0.001 -- TPR 0.9010 | F1 0.9414 | Elapsed: 3.49s
01/23/2023 04:21:45 PM  [*] Mon Jan 23 16:21:45 2023: Train Epoch: 1 [33600/38063 (88%)]	Loss: 0.318774 | FPR 0.001 -- TPR 0.9164 | F1 0.9513 | Elapsed: 3.74s
01/23/2023 04:21:49 PM  [*] Mon Jan 23 16:21:49 2023: Train Epoch: 1 [35200/38063 (92%)]	Loss: 0.302232 | FPR 0.001 -- TPR 0.9027 | F1 0.9430 | Elapsed: 3.63s
01/23/2023 04:21:53 PM  [*] Mon Jan 23 16:21:53 2023: Train Epoch: 1 [36800/38063 (97%)]	Loss: 0.516301 | FPR 0.001 -- TPR 0.8658 | F1 0.9176 | Elapsed: 3.67s
01/23/2023 04:21:56 PM  [*] Mon Jan 23 16:21:56 2023:    1    | Tr.loss: 0.303710 | FPR 0.001 -- TPR: 0.79 |  F1: 0.86 | Elapsed:   88.09  s
01/23/2023 04:21:56 PM  [*] Started epoch: 2
01/23/2023 04:21:56 PM  [*] Mon Jan 23 16:21:56 2023: Train Epoch: 2 [  0  /38063 (0 %)]	Loss: 0.365520 | FPR 0.001 -- TPR 0.7778 | F1 0.8750 | Elapsed: 0.04s
01/23/2023 04:21:59 PM  [*] Mon Jan 23 16:21:59 2023: Train Epoch: 2 [1600 /38063 (4 %)]	Loss: 0.648718 | FPR 0.001 -- TPR 0.9337 | F1 0.9519 | Elapsed: 3.82s
01/23/2023 04:22:03 PM  [*] Mon Jan 23 16:22:03 2023: Train Epoch: 2 [3200 /38063 (8 %)]	Loss: 0.242242 | FPR 0.001 -- TPR 0.9082 | F1 0.9412 | Elapsed: 3.59s
01/23/2023 04:22:07 PM  [*] Mon Jan 23 16:22:07 2023: Train Epoch: 2 [4800 /38063 (13%)]	Loss: 0.185005 | FPR 0.001 -- TPR 0.9089 | F1 0.9357 | Elapsed: 3.53s
01/23/2023 04:22:10 PM  [*] Mon Jan 23 16:22:10 2023: Train Epoch: 2 [6400 /38063 (17%)]	Loss: 0.246932 | FPR 0.001 -- TPR 0.9240 | F1 0.9552 | Elapsed: 3.43s
01/23/2023 04:22:14 PM  [*] Mon Jan 23 16:22:14 2023: Train Epoch: 2 [8000 /38063 (21%)]	Loss: 0.102050 | FPR 0.001 -- TPR 0.9316 | F1 0.9619 | Elapsed: 3.56s
01/23/2023 04:22:17 PM  [*] Mon Jan 23 16:22:17 2023: Train Epoch: 2 [9600 /38063 (25%)]	Loss: 0.213408 | FPR 0.001 -- TPR 0.9249 | F1 0.9571 | Elapsed: 3.48s
01/23/2023 04:22:21 PM  [*] Mon Jan 23 16:22:21 2023: Train Epoch: 2 [11200/38063 (29%)]	Loss: 0.267460 | FPR 0.001 -- TPR 0.9221 | F1 0.9427 | Elapsed: 3.54s
01/23/2023 04:22:24 PM  [*] Mon Jan 23 16:22:24 2023: Train Epoch: 2 [12800/38063 (34%)]	Loss: 0.075241 | FPR 0.001 -- TPR 0.8974 | F1 0.9393 | Elapsed: 3.61s
01/23/2023 04:22:28 PM  [*] Mon Jan 23 16:22:28 2023: Train Epoch: 2 [14400/38063 (38%)]	Loss: 0.232753 | FPR 0.001 -- TPR 0.9080 | F1 0.9455 | Elapsed: 3.54s
01/23/2023 04:22:31 PM  [*] Mon Jan 23 16:22:31 2023: Train Epoch: 2 [16000/38063 (42%)]	Loss: 0.056656 | FPR 0.001 -- TPR 0.9487 | F1 0.9622 | Elapsed: 3.62s
01/23/2023 04:22:35 PM  [*] Mon Jan 23 16:22:35 2023: Train Epoch: 2 [17600/38063 (46%)]	Loss: 0.104184 | FPR 0.001 -- TPR 0.9385 | F1 0.9661 | Elapsed: 3.67s
01/23/2023 04:22:39 PM  [*] Mon Jan 23 16:22:39 2023: Train Epoch: 2 [19200/38063 (50%)]	Loss: 0.105700 | FPR 0.001 -- TPR 0.9154 | F1 0.9503 | Elapsed: 3.65s
01/23/2023 04:22:42 PM  [*] Mon Jan 23 16:22:42 2023: Train Epoch: 2 [20800/38063 (55%)]	Loss: 0.270073 | FPR 0.001 -- TPR 0.9125 | F1 0.9472 | Elapsed: 3.65s
01/23/2023 04:22:46 PM  [*] Mon Jan 23 16:22:46 2023: Train Epoch: 2 [22400/38063 (59%)]	Loss: 0.143889 | FPR 0.001 -- TPR 0.9430 | F1 0.9565 | Elapsed: 3.58s
01/23/2023 04:22:50 PM  [*] Mon Jan 23 16:22:50 2023: Train Epoch: 2 [24000/38063 (63%)]	Loss: 0.091362 | FPR 0.001 -- TPR 0.9455 | F1 0.9682 | Elapsed: 3.70s
01/23/2023 04:22:53 PM  [*] Mon Jan 23 16:22:53 2023: Train Epoch: 2 [25600/38063 (67%)]	Loss: 0.392199 | FPR 0.001 -- TPR 0.9281 | F1 0.9596 | Elapsed: 3.52s
01/23/2023 04:22:54 PM [!] Learning rate: 2.5e-06
01/23/2023 04:22:57 PM  [*] Mon Jan 23 16:22:57 2023: Train Epoch: 2 [27200/38063 (71%)]	Loss: 0.024028 | FPR 0.001 -- TPR 0.9335 | F1 0.9599 | Elapsed: 3.60s
01/23/2023 04:23:00 PM  [*] Mon Jan 23 16:23:00 2023: Train Epoch: 2 [28800/38063 (76%)]	Loss: 0.038494 | FPR 0.001 -- TPR 0.9314 | F1 0.9618 | Elapsed: 3.55s
01/23/2023 04:23:04 PM  [*] Mon Jan 23 16:23:04 2023: Train Epoch: 2 [30400/38063 (80%)]	Loss: 0.420707 | FPR 0.001 -- TPR 0.9460 | F1 0.9700 | Elapsed: 3.54s
01/23/2023 04:23:07 PM  [*] Mon Jan 23 16:23:07 2023: Train Epoch: 2 [32000/38063 (84%)]	Loss: 0.222770 | FPR 0.001 -- TPR 0.9378 | F1 0.9641 | Elapsed: 3.63s
01/23/2023 04:23:11 PM  [*] Mon Jan 23 16:23:11 2023: Train Epoch: 2 [33600/38063 (88%)]	Loss: 0.257140 | FPR 0.001 -- TPR 0.9418 | F1 0.9669 | Elapsed: 3.46s
01/23/2023 04:23:15 PM  [*] Mon Jan 23 16:23:15 2023: Train Epoch: 2 [35200/38063 (92%)]	Loss: 0.170548 | FPR 0.001 -- TPR 0.9252 | F1 0.9577 | Elapsed: 3.89s
01/23/2023 04:23:18 PM  [*] Mon Jan 23 16:23:18 2023: Train Epoch: 2 [36800/38063 (97%)]	Loss: 0.086789 | FPR 0.001 -- TPR 0.9305 | F1 0.9599 | Elapsed: 3.71s
01/23/2023 04:23:21 PM  [*] Mon Jan 23 16:23:21 2023:    2    | Tr.loss: 0.171143 | FPR 0.001 -- TPR: 0.93 |  F1: 0.96 | Elapsed:   85.66  s
01/23/2023 04:23:21 PM  [*] Started epoch: 3
01/23/2023 04:23:21 PM  [*] Mon Jan 23 16:23:21 2023: Train Epoch: 3 [  0  /38063 (0 %)]	Loss: 0.122673 | FPR 0.001 -- TPR 1.0000 | F1 1.0000 | Elapsed: 0.06s
01/23/2023 04:23:25 PM  [*] Mon Jan 23 16:23:25 2023: Train Epoch: 3 [1600 /38063 (4 %)]	Loss: 0.110045 | FPR 0.001 -- TPR 0.9322 | F1 0.9603 | Elapsed: 3.42s
01/23/2023 04:23:28 PM  [*] Mon Jan 23 16:23:28 2023: Train Epoch: 3 [3200 /38063 (8 %)]	Loss: 0.202872 | FPR 0.001 -- TPR 0.9229 | F1 0.9552 | Elapsed: 3.36s
01/23/2023 04:23:31 PM  [*] Mon Jan 23 16:23:31 2023: Train Epoch: 3 [4800 /38063 (13%)]	Loss: 0.101340 | FPR 0.001 -- TPR 0.9358 | F1 0.9624 | Elapsed: 3.47s
01/23/2023 04:23:35 PM  [*] Mon Jan 23 16:23:35 2023: Train Epoch: 3 [6400 /38063 (17%)]	Loss: 0.102684 | FPR 0.001 -- TPR 0.9470 | F1 0.9705 | Elapsed: 3.38s
01/23/2023 04:23:38 PM  [*] Mon Jan 23 16:23:38 2023: Train Epoch: 3 [8000 /38063 (21%)]	Loss: 0.047956 | FPR 0.001 -- TPR 0.9424 | F1 0.9667 | Elapsed: 3.43s
01/23/2023 04:23:42 PM  [*] Mon Jan 23 16:23:42 2023: Train Epoch: 3 [9600 /38063 (25%)]	Loss: 0.125285 | FPR 0.001 -- TPR 0.9564 | F1 0.9751 | Elapsed: 3.25s
01/23/2023 04:23:45 PM  [*] Mon Jan 23 16:23:45 2023: Train Epoch: 3 [11200/38063 (29%)]	Loss: 0.109344 | FPR 0.001 -- TPR 0.9322 | F1 0.9610 | Elapsed: 3.42s
01/23/2023 04:23:48 PM  [*] Mon Jan 23 16:23:48 2023: Train Epoch: 3 [12800/38063 (34%)]	Loss: 0.089670 | FPR 0.001 -- TPR 0.9325 | F1 0.9594 | Elapsed: 3.31s
01/23/2023 04:23:52 PM  [*] Mon Jan 23 16:23:52 2023: Train Epoch: 3 [14400/38063 (38%)]	Loss: 0.066939 | FPR 0.001 -- TPR 0.9233 | F1 0.9557 | Elapsed: 3.57s
01/23/2023 04:23:56 PM  [*] Mon Jan 23 16:23:56 2023: Train Epoch: 3 [16000/38063 (42%)]	Loss: 0.074732 | FPR 0.001 -- TPR 0.9325 | F1 0.9625 | Elapsed: 4.35s
01/23/2023 04:24:00 PM  [*] Mon Jan 23 16:24:00 2023: Train Epoch: 3 [17600/38063 (46%)]	Loss: 0.073213 | FPR 0.001 -- TPR 0.9294 | F1 0.9600 | Elapsed: 4.01s
01/23/2023 04:24:04 PM  [*] Mon Jan 23 16:24:04 2023: Train Epoch: 3 [19200/38063 (50%)]	Loss: 0.024616 | FPR 0.001 -- TPR 0.9312 | F1 0.9607 | Elapsed: 3.30s
01/23/2023 04:24:05 PM [!] Learning rate: 2.5000000000000004e-07
01/23/2023 04:24:08 PM  [*] Mon Jan 23 16:24:08 2023: Train Epoch: 3 [20800/38063 (55%)]	Loss: 0.160097 | FPR 0.001 -- TPR 0.9480 | F1 0.9712 | Elapsed: 4.29s
01/23/2023 04:24:13 PM  [*] Mon Jan 23 16:24:13 2023: Train Epoch: 3 [22400/38063 (59%)]	Loss: 0.141971 | FPR 0.001 -- TPR 0.9416 | F1 0.9576 | Elapsed: 5.32s
01/23/2023 04:24:18 PM  [*] Mon Jan 23 16:24:18 2023: Train Epoch: 3 [24000/38063 (63%)]	Loss: 0.098835 | FPR 0.001 -- TPR 0.9283 | F1 0.9592 | Elapsed: 5.13s
01/23/2023 04:24:24 PM  [*] Mon Jan 23 16:24:24 2023: Train Epoch: 3 [25600/38063 (67%)]	Loss: 0.099989 | FPR 0.001 -- TPR 0.9511 | F1 0.9731 | Elapsed: 5.38s
01/23/2023 04:24:27 PM  [*] Mon Jan 23 16:24:27 2023: Train Epoch: 3 [27200/38063 (71%)]	Loss: 0.116920 | FPR 0.001 -- TPR 0.9507 | F1 0.9732 | Elapsed: 3.67s
01/23/2023 04:24:31 PM  [*] Mon Jan 23 16:24:31 2023: Train Epoch: 3 [28800/38063 (76%)]	Loss: 0.084235 | FPR 0.001 -- TPR 0.9367 | F1 0.9643 | Elapsed: 3.73s
01/23/2023 04:24:35 PM  [*] Mon Jan 23 16:24:35 2023: Train Epoch: 3 [30400/38063 (80%)]	Loss: 0.185454 | FPR 0.001 -- TPR 0.9428 | F1 0.9578 | Elapsed: 3.77s
01/23/2023 04:24:39 PM  [*] Mon Jan 23 16:24:39 2023: Train Epoch: 3 [32000/38063 (84%)]	Loss: 0.181142 | FPR 0.001 -- TPR 0.9361 | F1 0.9639 | Elapsed: 4.21s
01/23/2023 04:24:43 PM  [*] Mon Jan 23 16:24:43 2023: Train Epoch: 3 [33600/38063 (88%)]	Loss: 0.113126 | FPR 0.001 -- TPR 0.9281 | F1 0.9587 | Elapsed: 3.89s
01/23/2023 04:24:47 PM  [*] Mon Jan 23 16:24:47 2023: Train Epoch: 3 [35200/38063 (92%)]	Loss: 0.217300 | FPR 0.001 -- TPR 0.9133 | F1 0.9496 | Elapsed: 3.90s
01/23/2023 04:24:50 PM  [*] Mon Jan 23 16:24:50 2023: Train Epoch: 3 [36800/38063 (97%)]	Loss: 0.322258 | FPR 0.001 -- TPR 0.9095 | F1 0.9367 | Elapsed: 3.57s
01/23/2023 04:24:53 PM  [*] Mon Jan 23 16:24:53 2023:    3    | Tr.loss: 0.162423 | FPR 0.001 -- TPR: 0.94 |  F1: 0.96 | Elapsed:   91.99  s
01/23/2023 04:24:53 PM [!] Mon Jan 23 16:24:53 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\crossValidation\Transformer_512_BPE\nLayers\trainingFiles\trainingFiles_1674487493-model.torch
                losses    : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\crossValidation\Transformer_512_BPE\nLayers\trainingFiles\trainingFiles_1674487493-train_losses.npy
                duration  : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\crossValidation\Transformer_512_BPE\nLayers\trainingFiles\trainingFiles_1674487493-trainTime.npy
		train F1s : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\crossValidation\Transformer_512_BPE\nLayers\trainingFiles\trainingFiles_1674487493-trainF1s.npy
		train TPRs: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\crossValidation\Transformer_512_BPE\nLayers\trainingFiles\trainingFiles_1674487493-trainTPRs.npy
01/23/2023 04:24:53 PM  [!] Evaluating model on validation set...
01/23/2023 04:24:53 PM  [*] Predicting batch: 0/2379
01/23/2023 04:24:54 PM  [*] Predicting batch: 100/2379
01/23/2023 04:24:55 PM  [*] Predicting batch: 200/2379
01/23/2023 04:24:55 PM  [*] Predicting batch: 300/2379
01/23/2023 04:24:56 PM  [*] Predicting batch: 400/2379
01/23/2023 04:24:56 PM  [*] Predicting batch: 500/2379
01/23/2023 04:24:57 PM  [*] Predicting batch: 600/2379
01/23/2023 04:24:58 PM  [*] Predicting batch: 700/2379
01/23/2023 04:24:58 PM  [*] Predicting batch: 800/2379
01/23/2023 04:24:59 PM  [*] Predicting batch: 900/2379
01/23/2023 04:24:59 PM  [*] Predicting batch: 1000/2379
01/23/2023 04:25:00 PM  [*] Predicting batch: 1100/2379
01/23/2023 04:25:01 PM  [*] Predicting batch: 1200/2379
01/23/2023 04:25:01 PM  [*] Predicting batch: 1300/2379
01/23/2023 04:25:02 PM  [*] Predicting batch: 1400/2379
01/23/2023 04:25:02 PM  [*] Predicting batch: 1500/2379
01/23/2023 04:25:03 PM  [*] Predicting batch: 1600/2379
01/23/2023 04:25:04 PM  [*] Predicting batch: 1700/2379
01/23/2023 04:25:04 PM  [*] Predicting batch: 1800/2379
01/23/2023 04:25:05 PM  [*] Predicting batch: 1900/2379
01/23/2023 04:25:05 PM  [*] Predicting batch: 2000/2379
01/23/2023 04:25:06 PM  [*] Predicting batch: 2100/2379
01/23/2023 04:25:07 PM  [*] Predicting batch: 2200/2379
01/23/2023 04:25:07 PM  [*] Predicting batch: 2300/2379
01/23/2023 04:25:08 PM  [!] This fold metrics on validation set:
01/23/2023 04:25:08 PM  [!] FPR: 0.0001 | TPR: 0.34396044999805364 | F1: 0.5118461449342524
01/23/2023 04:25:08 PM  [!] FPR: 0.0003 | TPR: 0.6334228658180544 | F1: 0.7755218758936231
01/23/2023 04:25:08 PM  [!] FPR: 0.001 | TPR: 0.7115496905290202 | F1: 0.8312414733969985
01/23/2023 04:25:08 PM  [!] FPR: 0.003 | TPR: 0.8027949706099887 | F1: 0.8899005372284191
01/23/2023 04:25:08 PM  [!] FPR: 0.01 | TPR: 0.8695550624781034 | F1: 0.9278504672897196
01/23/2023 04:25:08 PM  [!] FPR: 0.03 | TPR: 0.912452800809685 | F1: 0.9470707070707071
01/23/2023 04:25:08 PM  [!] FPR: 0.1 | TPR: 0.9583868581883296 | F1: 0.9552817926084005
01/23/2023 04:25:08 PM  [!] Metrics saved to C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\crossValidation\Transformer_512_BPE\nLayers\metrics_trainSize_76126_ep_3_cv_2_vocabSize_50000_maxLen_512_dModel_64_nHeads_8_dHidden_256_nLayers_1_numClasses_1_hiddenNeurons_64_layerNorm_False_dropout_0.3.json
01/23/2023 04:25:08 PM  [!] Average epoch time: 90.44s | Mean values over 2 folds:
	FPR: 0.0001 -- TPR: 0.3382 -- F1: 0.5054
	FPR: 0.0003 -- TPR: 0.6327 -- F1: 0.7750
	FPR:  0.001 -- TPR: 0.7277 -- F1: 0.8421
	FPR:  0.003 -- TPR: 0.7967 -- F1: 0.8861
	FPR:   0.01 -- TPR: 0.8596 -- F1: 0.9221
	FPR:   0.03 -- TPR: 0.9153 -- F1: 0.9486
	FPR:    0.1 -- TPR: 0.9643 -- F1: 0.9585

01/23/2023 04:25:38 PM  [!] Using device: cuda:0 | Dataset size: 76126
01/23/2023 04:25:38 PM  [!] Epochs per fold: 3 | Model config: {'vocabSize': 50000, 'maxLen': 512, 'dModel': 64, 'nHeads': 8, 'dHidden': 256, 'nLayers': 2, 'numClasses': 1, 'hiddenNeurons': [64], 'layerNorm': False, 'dropout': 0.3}
01/23/2023 04:25:38 PM  [!] Fold 1/2 | Train set size: 38063, Validation set size: 38063
01/23/2023 04:25:38 PM  [*] Started epoch: 1
01/23/2023 04:25:39 PM  [*] Mon Jan 23 16:25:39 2023: Train Epoch: 1 [  0  /38063 (0 %)]	Loss: 2.130592 | FPR 0.001 -- TPR 0.0000 | F1 0.0000 | Elapsed: 0.25s
01/23/2023 04:25:44 PM  [*] Mon Jan 23 16:25:44 2023: Train Epoch: 1 [1600 /38063 (4 %)]	Loss: 0.441488 | FPR 0.001 -- TPR 0.3798 | F1 0.4971 | Elapsed: 5.21s
01/23/2023 04:25:49 PM  [*] Mon Jan 23 16:25:49 2023: Train Epoch: 1 [3200 /38063 (8 %)]	Loss: 0.484133 | FPR 0.001 -- TPR 0.5460 | F1 0.6661 | Elapsed: 5.39s
01/23/2023 04:25:55 PM  [*] Mon Jan 23 16:25:55 2023: Train Epoch: 1 [4800 /38063 (13%)]	Loss: 0.500350 | FPR 0.001 -- TPR 0.6146 | F1 0.7302 | Elapsed: 5.60s
01/23/2023 04:26:00 PM  [*] Mon Jan 23 16:26:00 2023: Train Epoch: 1 [6400 /38063 (17%)]	Loss: 0.412207 | FPR 0.001 -- TPR 0.6620 | F1 0.7649 | Elapsed: 5.14s
01/23/2023 04:26:05 PM  [*] Mon Jan 23 16:26:05 2023: Train Epoch: 1 [8000 /38063 (21%)]	Loss: 0.206541 | FPR 0.001 -- TPR 0.7243 | F1 0.8192 | Elapsed: 5.52s
01/23/2023 04:26:11 PM  [*] Mon Jan 23 16:26:11 2023: Train Epoch: 1 [9600 /38063 (25%)]	Loss: 0.205086 | FPR 0.001 -- TPR 0.7477 | F1 0.8350 | Elapsed: 5.59s
01/23/2023 04:26:17 PM  [*] Mon Jan 23 16:26:17 2023: Train Epoch: 1 [11200/38063 (29%)]	Loss: 0.440684 | FPR 0.001 -- TPR 0.7539 | F1 0.8427 | Elapsed: 5.55s
01/23/2023 04:26:22 PM  [*] Mon Jan 23 16:26:22 2023: Train Epoch: 1 [12800/38063 (34%)]	Loss: 0.391657 | FPR 0.001 -- TPR 0.7832 | F1 0.8637 | Elapsed: 5.48s
01/23/2023 04:26:27 PM  [*] Mon Jan 23 16:26:27 2023: Train Epoch: 1 [14400/38063 (38%)]	Loss: 0.565017 | FPR 0.001 -- TPR 0.8243 | F1 0.8953 | Elapsed: 5.46s
01/23/2023 04:26:33 PM  [*] Mon Jan 23 16:26:33 2023: Train Epoch: 1 [16000/38063 (42%)]	Loss: 0.368641 | FPR 0.001 -- TPR 0.8028 | F1 0.8731 | Elapsed: 5.49s
01/23/2023 04:26:39 PM  [*] Mon Jan 23 16:26:39 2023: Train Epoch: 1 [17600/38063 (46%)]	Loss: 0.389837 | FPR 0.001 -- TPR 0.8369 | F1 0.9004 | Elapsed: 5.73s
01/23/2023 04:26:44 PM  [*] Mon Jan 23 16:26:44 2023: Train Epoch: 1 [19200/38063 (50%)]	Loss: 0.153485 | FPR 0.001 -- TPR 0.8525 | F1 0.9120 | Elapsed: 5.40s
01/23/2023 04:26:49 PM  [*] Mon Jan 23 16:26:49 2023: Train Epoch: 1 [20800/38063 (55%)]	Loss: 0.159038 | FPR 0.001 -- TPR 0.8715 | F1 0.9226 | Elapsed: 5.27s
01/23/2023 04:26:55 PM  [*] Mon Jan 23 16:26:55 2023: Train Epoch: 1 [22400/38063 (59%)]	Loss: 0.252959 | FPR 0.001 -- TPR 0.8603 | F1 0.9167 | Elapsed: 5.41s
01/23/2023 04:27:00 PM  [*] Mon Jan 23 16:27:00 2023: Train Epoch: 1 [24000/38063 (63%)]	Loss: 0.135764 | FPR 0.001 -- TPR 0.8532 | F1 0.9104 | Elapsed: 5.58s
01/23/2023 04:27:06 PM  [*] Mon Jan 23 16:27:06 2023: Train Epoch: 1 [25600/38063 (67%)]	Loss: 0.174570 | FPR 0.001 -- TPR 0.8780 | F1 0.9281 | Elapsed: 5.37s
01/23/2023 04:27:11 PM  [*] Mon Jan 23 16:27:11 2023: Train Epoch: 1 [27200/38063 (71%)]	Loss: 0.275865 | FPR 0.001 -- TPR 0.9074 | F1 0.9372 | Elapsed: 5.57s
01/23/2023 04:27:17 PM  [*] Mon Jan 23 16:27:17 2023: Train Epoch: 1 [28800/38063 (76%)]	Loss: 0.105610 | FPR 0.001 -- TPR 0.8962 | F1 0.9381 | Elapsed: 5.49s
01/23/2023 04:27:22 PM  [*] Mon Jan 23 16:27:22 2023: Train Epoch: 1 [30400/38063 (80%)]	Loss: 0.144177 | FPR 0.001 -- TPR 0.9147 | F1 0.9496 | Elapsed: 5.46s
01/23/2023 04:27:28 PM [!] Learning rate: 2.5e-05
01/23/2023 04:27:28 PM  [*] Mon Jan 23 16:27:28 2023: Train Epoch: 1 [32000/38063 (84%)]	Loss: 0.325832 | FPR 0.001 -- TPR 0.8983 | F1 0.9394 | Elapsed: 5.98s
01/23/2023 04:27:34 PM  [*] Mon Jan 23 16:27:34 2023: Train Epoch: 1 [33600/38063 (88%)]	Loss: 0.074702 | FPR 0.001 -- TPR 0.9156 | F1 0.9501 | Elapsed: 5.68s
01/23/2023 04:27:39 PM  [*] Mon Jan 23 16:27:39 2023: Train Epoch: 1 [35200/38063 (92%)]	Loss: 0.197041 | FPR 0.001 -- TPR 0.9119 | F1 0.9472 | Elapsed: 5.47s
01/23/2023 04:27:45 PM  [*] Mon Jan 23 16:27:45 2023: Train Epoch: 1 [36800/38063 (97%)]	Loss: 0.197233 | FPR 0.001 -- TPR 0.9250 | F1 0.9569 | Elapsed: 5.44s
01/23/2023 04:27:49 PM  [*] Mon Jan 23 16:27:49 2023:    1    | Tr.loss: 0.294508 | FPR 0.001 -- TPR: 0.80 |  F1: 0.87 | Elapsed:  130.66  s
01/23/2023 04:27:49 PM  [*] Started epoch: 2
01/23/2023 04:27:49 PM  [*] Mon Jan 23 16:27:49 2023: Train Epoch: 2 [  0  /38063 (0 %)]	Loss: 0.363353 | FPR 0.001 -- TPR 0.8333 | F1 0.9091 | Elapsed: 0.08s
01/23/2023 04:27:54 PM  [*] Mon Jan 23 16:27:54 2023: Train Epoch: 2 [1600 /38063 (4 %)]	Loss: 0.273609 | FPR 0.001 -- TPR 0.9575 | F1 0.9768 | Elapsed: 5.44s
01/23/2023 04:28:00 PM  [*] Mon Jan 23 16:28:00 2023: Train Epoch: 2 [3200 /38063 (8 %)]	Loss: 0.050619 | FPR 0.001 -- TPR 0.9503 | F1 0.9718 | Elapsed: 5.23s
01/23/2023 04:28:05 PM  [*] Mon Jan 23 16:28:05 2023: Train Epoch: 2 [4800 /38063 (13%)]	Loss: 0.297326 | FPR 0.001 -- TPR 0.9284 | F1 0.9595 | Elapsed: 5.18s
01/23/2023 04:28:11 PM  [*] Mon Jan 23 16:28:11 2023: Train Epoch: 2 [6400 /38063 (17%)]	Loss: 0.453253 | FPR 0.001 -- TPR 0.9398 | F1 0.9670 | Elapsed: 5.85s
01/23/2023 04:28:16 PM  [*] Mon Jan 23 16:28:16 2023: Train Epoch: 2 [8000 /38063 (21%)]	Loss: 0.081241 | FPR 0.001 -- TPR 0.9122 | F1 0.9461 | Elapsed: 5.64s
01/23/2023 04:28:22 PM  [*] Mon Jan 23 16:28:22 2023: Train Epoch: 2 [9600 /38063 (25%)]	Loss: 0.128048 | FPR 0.001 -- TPR 0.9320 | F1 0.9615 | Elapsed: 5.37s
01/23/2023 04:28:27 PM  [*] Mon Jan 23 16:28:27 2023: Train Epoch: 2 [11200/38063 (29%)]	Loss: 0.011150 | FPR 0.001 -- TPR 0.9387 | F1 0.9648 | Elapsed: 5.51s
01/23/2023 04:28:33 PM  [*] Mon Jan 23 16:28:33 2023: Train Epoch: 2 [12800/38063 (34%)]	Loss: 0.173157 | FPR 0.001 -- TPR 0.9195 | F1 0.9444 | Elapsed: 5.56s
01/23/2023 04:28:38 PM  [*] Mon Jan 23 16:28:38 2023: Train Epoch: 2 [14400/38063 (38%)]	Loss: 0.108018 | FPR 0.001 -- TPR 0.9202 | F1 0.9432 | Elapsed: 5.39s
01/23/2023 04:28:44 PM  [*] Mon Jan 23 16:28:44 2023: Train Epoch: 2 [16000/38063 (42%)]	Loss: 0.343224 | FPR 0.001 -- TPR 0.9351 | F1 0.9629 | Elapsed: 5.45s
01/23/2023 04:28:49 PM  [*] Mon Jan 23 16:28:49 2023: Train Epoch: 2 [17600/38063 (46%)]	Loss: 0.133425 | FPR 0.001 -- TPR 0.9407 | F1 0.9665 | Elapsed: 5.19s
01/23/2023 04:28:54 PM  [*] Mon Jan 23 16:28:54 2023: Train Epoch: 2 [19200/38063 (50%)]	Loss: 0.153487 | FPR 0.001 -- TPR 0.9498 | F1 0.9625 | Elapsed: 5.34s
01/23/2023 04:29:00 PM  [*] Mon Jan 23 16:29:00 2023: Train Epoch: 2 [20800/38063 (55%)]	Loss: 0.151689 | FPR 0.001 -- TPR 0.9370 | F1 0.9625 | Elapsed: 5.34s
01/23/2023 04:29:05 PM  [*] Mon Jan 23 16:29:05 2023: Train Epoch: 2 [22400/38063 (59%)]	Loss: 0.098234 | FPR 0.001 -- TPR 0.9229 | F1 0.9565 | Elapsed: 5.35s
01/23/2023 04:29:10 PM  [*] Mon Jan 23 16:29:10 2023: Train Epoch: 2 [24000/38063 (63%)]	Loss: 0.357809 | FPR 0.001 -- TPR 0.9473 | F1 0.9701 | Elapsed: 5.56s
01/23/2023 04:29:16 PM  [*] Mon Jan 23 16:29:16 2023: Train Epoch: 2 [25600/38063 (67%)]	Loss: 0.386738 | FPR 0.001 -- TPR 0.9252 | F1 0.9573 | Elapsed: 5.41s
01/23/2023 04:29:17 PM [!] Learning rate: 2.5e-06
01/23/2023 04:29:21 PM  [*] Mon Jan 23 16:29:21 2023: Train Epoch: 2 [27200/38063 (71%)]	Loss: 0.112247 | FPR 0.001 -- TPR 0.9458 | F1 0.9689 | Elapsed: 5.28s
01/23/2023 04:29:26 PM  [*] Mon Jan 23 16:29:26 2023: Train Epoch: 2 [28800/38063 (76%)]	Loss: 0.115652 | FPR 0.001 -- TPR 0.9296 | F1 0.9597 | Elapsed: 5.23s
01/23/2023 04:29:32 PM  [*] Mon Jan 23 16:29:32 2023: Train Epoch: 2 [30400/38063 (80%)]	Loss: 0.132287 | FPR 0.001 -- TPR 0.9474 | F1 0.9696 | Elapsed: 5.61s
01/23/2023 04:29:37 PM  [*] Mon Jan 23 16:29:37 2023: Train Epoch: 2 [32000/38063 (84%)]	Loss: 0.113707 | FPR 0.001 -- TPR 0.9174 | F1 0.9463 | Elapsed: 5.22s
01/23/2023 04:29:43 PM  [*] Mon Jan 23 16:29:43 2023: Train Epoch: 2 [33600/38063 (88%)]	Loss: 0.102356 | FPR 0.001 -- TPR 0.9312 | F1 0.9588 | Elapsed: 5.51s
01/23/2023 04:29:48 PM  [*] Mon Jan 23 16:29:48 2023: Train Epoch: 2 [35200/38063 (92%)]	Loss: 0.018476 | FPR 0.001 -- TPR 0.9311 | F1 0.9611 | Elapsed: 5.27s
01/23/2023 04:29:53 PM  [*] Mon Jan 23 16:29:53 2023: Train Epoch: 2 [36800/38063 (97%)]	Loss: 0.070054 | FPR 0.001 -- TPR 0.9461 | F1 0.9678 | Elapsed: 5.19s
01/23/2023 04:29:57 PM  [*] Mon Jan 23 16:29:57 2023:    2    | Tr.loss: 0.161576 | FPR 0.001 -- TPR: 0.94 |  F1: 0.96 | Elapsed:  128.40  s
01/23/2023 04:29:57 PM  [*] Started epoch: 3
01/23/2023 04:29:57 PM  [*] Mon Jan 23 16:29:57 2023: Train Epoch: 3 [  0  /38063 (0 %)]	Loss: 0.053420 | FPR 0.001 -- TPR 1.0000 | F1 1.0000 | Elapsed: 0.10s
01/23/2023 04:30:03 PM  [*] Mon Jan 23 16:30:03 2023: Train Epoch: 3 [1600 /38063 (4 %)]	Loss: 0.115897 | FPR 0.001 -- TPR 0.9571 | F1 0.9765 | Elapsed: 5.28s
01/23/2023 04:30:08 PM  [*] Mon Jan 23 16:30:08 2023: Train Epoch: 3 [3200 /38063 (8 %)]	Loss: 0.129003 | FPR 0.001 -- TPR 0.9477 | F1 0.9694 | Elapsed: 5.51s
01/23/2023 04:30:13 PM  [*] Mon Jan 23 16:30:13 2023: Train Epoch: 3 [4800 /38063 (13%)]	Loss: 0.097963 | FPR 0.001 -- TPR 0.9382 | F1 0.9658 | Elapsed: 5.24s
01/23/2023 04:30:19 PM  [*] Mon Jan 23 16:30:19 2023: Train Epoch: 3 [6400 /38063 (17%)]	Loss: 0.202170 | FPR 0.001 -- TPR 0.9342 | F1 0.9626 | Elapsed: 5.28s
01/23/2023 04:30:24 PM  [*] Mon Jan 23 16:30:24 2023: Train Epoch: 3 [8000 /38063 (21%)]	Loss: 0.207237 | FPR 0.001 -- TPR 0.9409 | F1 0.9678 | Elapsed: 5.51s
01/23/2023 04:30:30 PM  [*] Mon Jan 23 16:30:30 2023: Train Epoch: 3 [9600 /38063 (25%)]	Loss: 0.156825 | FPR 0.001 -- TPR 0.9244 | F1 0.9544 | Elapsed: 5.48s
01/23/2023 04:30:35 PM  [*] Mon Jan 23 16:30:35 2023: Train Epoch: 3 [11200/38063 (29%)]	Loss: 0.116644 | FPR 0.001 -- TPR 0.9401 | F1 0.9654 | Elapsed: 5.31s
01/23/2023 04:30:40 PM  [*] Mon Jan 23 16:30:40 2023: Train Epoch: 3 [12800/38063 (34%)]	Loss: 0.068853 | FPR 0.001 -- TPR 0.9543 | F1 0.9747 | Elapsed: 5.18s
01/23/2023 04:30:46 PM  [*] Mon Jan 23 16:30:46 2023: Train Epoch: 3 [14400/38063 (38%)]	Loss: 0.019520 | FPR 0.001 -- TPR 0.9365 | F1 0.9632 | Elapsed: 5.34s
01/23/2023 04:30:51 PM  [*] Mon Jan 23 16:30:51 2023: Train Epoch: 3 [16000/38063 (42%)]	Loss: 0.038839 | FPR 0.001 -- TPR 0.9429 | F1 0.9575 | Elapsed: 5.27s
01/23/2023 04:30:56 PM  [*] Mon Jan 23 16:30:56 2023: Train Epoch: 3 [17600/38063 (46%)]	Loss: 0.063667 | FPR 0.001 -- TPR 0.9520 | F1 0.9727 | Elapsed: 5.35s
01/23/2023 04:31:02 PM  [*] Mon Jan 23 16:31:02 2023: Train Epoch: 3 [19200/38063 (50%)]	Loss: 0.049884 | FPR 0.001 -- TPR 0.9486 | F1 0.9704 | Elapsed: 5.45s
01/23/2023 04:31:04 PM [!] Learning rate: 2.5000000000000004e-07
01/23/2023 04:31:07 PM  [*] Mon Jan 23 16:31:07 2023: Train Epoch: 3 [20800/38063 (55%)]	Loss: 0.089104 | FPR 0.001 -- TPR 0.9580 | F1 0.9769 | Elapsed: 5.28s
01/23/2023 04:31:12 PM  [*] Mon Jan 23 16:31:12 2023: Train Epoch: 3 [22400/38063 (59%)]	Loss: 0.139763 | FPR 0.001 -- TPR 0.9417 | F1 0.9672 | Elapsed: 5.26s
01/23/2023 04:31:18 PM  [*] Mon Jan 23 16:31:18 2023: Train Epoch: 3 [24000/38063 (63%)]	Loss: 0.078380 | FPR 0.001 -- TPR 0.9345 | F1 0.9630 | Elapsed: 5.40s
01/23/2023 04:31:23 PM  [*] Mon Jan 23 16:31:23 2023: Train Epoch: 3 [25600/38063 (67%)]	Loss: 0.596576 | FPR 0.001 -- TPR 0.9549 | F1 0.9748 | Elapsed: 5.48s
01/23/2023 04:31:28 PM  [*] Mon Jan 23 16:31:28 2023: Train Epoch: 3 [27200/38063 (71%)]	Loss: 0.091251 | FPR 0.001 -- TPR 0.9553 | F1 0.9754 | Elapsed: 5.27s
01/23/2023 04:31:34 PM  [*] Mon Jan 23 16:31:34 2023: Train Epoch: 3 [28800/38063 (76%)]	Loss: 0.007743 | FPR 0.001 -- TPR 0.9549 | F1 0.9751 | Elapsed: 5.50s
01/23/2023 04:31:39 PM  [*] Mon Jan 23 16:31:39 2023: Train Epoch: 3 [30400/38063 (80%)]	Loss: 0.423684 | FPR 0.001 -- TPR 0.9509 | F1 0.9726 | Elapsed: 5.34s
01/23/2023 04:31:44 PM  [*] Mon Jan 23 16:31:44 2023: Train Epoch: 3 [32000/38063 (84%)]	Loss: 0.196528 | FPR 0.001 -- TPR 0.9400 | F1 0.9661 | Elapsed: 5.19s
01/23/2023 04:31:50 PM  [*] Mon Jan 23 16:31:50 2023: Train Epoch: 3 [33600/38063 (88%)]	Loss: 0.340582 | FPR 0.001 -- TPR 0.9413 | F1 0.9666 | Elapsed: 5.32s
01/23/2023 04:31:55 PM  [*] Mon Jan 23 16:31:55 2023: Train Epoch: 3 [35200/38063 (92%)]	Loss: 0.112138 | FPR 0.001 -- TPR 0.9487 | F1 0.9702 | Elapsed: 5.44s
01/23/2023 04:32:00 PM  [*] Mon Jan 23 16:32:00 2023: Train Epoch: 3 [36800/38063 (97%)]	Loss: 0.019134 | FPR 0.001 -- TPR 0.9513 | F1 0.9726 | Elapsed: 5.33s
01/23/2023 04:32:05 PM  [*] Mon Jan 23 16:32:05 2023:    3    | Tr.loss: 0.150302 | FPR 0.001 -- TPR: 0.95 |  F1: 0.97 | Elapsed:  127.18  s
01/23/2023 04:32:05 PM [!] Mon Jan 23 16:32:05 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\crossValidation\Transformer_512_BPE\nLayers\trainingFiles\trainingFiles_1674487925-model.torch
                losses    : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\crossValidation\Transformer_512_BPE\nLayers\trainingFiles\trainingFiles_1674487925-train_losses.npy
                duration  : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\crossValidation\Transformer_512_BPE\nLayers\trainingFiles\trainingFiles_1674487925-trainTime.npy
		train F1s : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\crossValidation\Transformer_512_BPE\nLayers\trainingFiles\trainingFiles_1674487925-trainF1s.npy
		train TPRs: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\crossValidation\Transformer_512_BPE\nLayers\trainingFiles\trainingFiles_1674487925-trainTPRs.npy
01/23/2023 04:32:05 PM  [!] Evaluating model on validation set...
01/23/2023 04:32:05 PM  [*] Predicting batch: 0/2379
01/23/2023 04:32:06 PM  [*] Predicting batch: 100/2379
01/23/2023 04:32:06 PM  [*] Predicting batch: 200/2379
01/23/2023 04:32:07 PM  [*] Predicting batch: 300/2379
01/23/2023 04:32:08 PM  [*] Predicting batch: 400/2379
01/23/2023 04:32:09 PM  [*] Predicting batch: 500/2379
01/23/2023 04:32:10 PM  [*] Predicting batch: 600/2379
01/23/2023 04:32:11 PM  [*] Predicting batch: 700/2379
01/23/2023 04:32:12 PM  [*] Predicting batch: 800/2379
01/23/2023 04:32:12 PM  [*] Predicting batch: 900/2379
01/23/2023 04:32:13 PM  [*] Predicting batch: 1000/2379
01/23/2023 04:32:14 PM  [*] Predicting batch: 1100/2379
01/23/2023 04:32:15 PM  [*] Predicting batch: 1200/2379
01/23/2023 04:32:16 PM  [*] Predicting batch: 1300/2379
01/23/2023 04:32:16 PM  [*] Predicting batch: 1400/2379
01/23/2023 04:32:17 PM  [*] Predicting batch: 1500/2379
01/23/2023 04:32:18 PM  [*] Predicting batch: 1600/2379
01/23/2023 04:32:19 PM  [*] Predicting batch: 1700/2379
01/23/2023 04:32:20 PM  [*] Predicting batch: 1800/2379
01/23/2023 04:32:21 PM  [*] Predicting batch: 1900/2379
01/23/2023 04:32:21 PM  [*] Predicting batch: 2000/2379
01/23/2023 04:32:22 PM  [*] Predicting batch: 2100/2379
01/23/2023 04:32:23 PM  [*] Predicting batch: 2200/2379
01/23/2023 04:32:24 PM  [*] Predicting batch: 2300/2379
01/23/2023 04:32:25 PM  [!] This fold metrics on validation set:
01/23/2023 04:32:25 PM  [!] FPR: 0.0001 | TPR: 0.29934402049450765 | F1: 0.46074799856613696
01/23/2023 04:32:25 PM  [!] FPR: 0.0003 | TPR: 0.5539339362651865 | F1: 0.7128905762169992
01/23/2023 04:32:25 PM  [!] FPR: 0.001 | TPR: 0.7596165042890968 | F1: 0.8631602161208513
01/23/2023 04:32:25 PM  [!] FPR: 0.003 | TPR: 0.8368590614447076 | F1: 0.9104921978926921
01/23/2023 04:32:25 PM  [!] FPR: 0.01 | TPR: 0.8731126033458836 | F1: 0.9298883836295989
01/23/2023 04:32:25 PM  [!] FPR: 0.03 | TPR: 0.9150331871288282 | F1: 0.9485755673587639
01/23/2023 04:32:25 PM  [!] FPR: 0.1 | TPR: 0.9675503629235725 | F1: 0.9602265066738573
01/23/2023 04:32:25 PM  [!] Fold 2/2 | Train set size: 38063, Validation set size: 38063
01/23/2023 04:32:25 PM  [*] Started epoch: 1
01/23/2023 04:32:25 PM  [*] Mon Jan 23 16:32:25 2023: Train Epoch: 1 [  0  /38063 (0 %)]	Loss: 1.880715 | FPR 0.001 -- TPR 0.0000 | F1 0.0000 | Elapsed: 0.10s
01/23/2023 04:32:31 PM  [*] Mon Jan 23 16:32:31 2023: Train Epoch: 1 [1600 /38063 (4 %)]	Loss: 0.424224 | FPR 0.001 -- TPR 0.3764 | F1 0.4841 | Elapsed: 5.42s
01/23/2023 04:32:36 PM  [*] Mon Jan 23 16:32:36 2023: Train Epoch: 1 [3200 /38063 (8 %)]	Loss: 0.387689 | FPR 0.001 -- TPR 0.4798 | F1 0.6060 | Elapsed: 5.21s
01/23/2023 04:32:41 PM  [*] Mon Jan 23 16:32:41 2023: Train Epoch: 1 [4800 /38063 (13%)]	Loss: 0.268772 | FPR 0.001 -- TPR 0.5961 | F1 0.7121 | Elapsed: 5.43s
01/23/2023 04:32:47 PM  [*] Mon Jan 23 16:32:47 2023: Train Epoch: 1 [6400 /38063 (17%)]	Loss: 0.595867 | FPR 0.001 -- TPR 0.6829 | F1 0.7746 | Elapsed: 5.58s
01/23/2023 04:32:52 PM  [*] Mon Jan 23 16:32:52 2023: Train Epoch: 1 [8000 /38063 (21%)]	Loss: 0.190268 | FPR 0.001 -- TPR 0.6851 | F1 0.7845 | Elapsed: 5.46s
01/23/2023 04:32:58 PM  [*] Mon Jan 23 16:32:58 2023: Train Epoch: 1 [9600 /38063 (25%)]	Loss: 0.204442 | FPR 0.001 -- TPR 0.7200 | F1 0.8160 | Elapsed: 5.30s
01/23/2023 04:33:03 PM  [*] Mon Jan 23 16:33:03 2023: Train Epoch: 1 [11200/38063 (29%)]	Loss: 0.203336 | FPR 0.001 -- TPR 0.7269 | F1 0.8112 | Elapsed: 5.29s
01/23/2023 04:33:08 PM  [*] Mon Jan 23 16:33:08 2023: Train Epoch: 1 [12800/38063 (34%)]	Loss: 0.569093 | FPR 0.001 -- TPR 0.7793 | F1 0.8488 | Elapsed: 5.19s
01/23/2023 04:33:14 PM  [*] Mon Jan 23 16:33:14 2023: Train Epoch: 1 [14400/38063 (38%)]	Loss: 0.482062 | FPR 0.001 -- TPR 0.7998 | F1 0.8700 | Elapsed: 5.48s
01/23/2023 04:33:19 PM  [*] Mon Jan 23 16:33:19 2023: Train Epoch: 1 [16000/38063 (42%)]	Loss: 0.486338 | FPR 0.001 -- TPR 0.7967 | F1 0.8729 | Elapsed: 5.46s
01/23/2023 04:33:25 PM  [*] Mon Jan 23 16:33:25 2023: Train Epoch: 1 [17600/38063 (46%)]	Loss: 0.279263 | FPR 0.001 -- TPR 0.8064 | F1 0.8785 | Elapsed: 5.50s
01/23/2023 04:33:31 PM  [*] Mon Jan 23 16:33:31 2023: Train Epoch: 1 [19200/38063 (50%)]	Loss: 0.179771 | FPR 0.001 -- TPR 0.8081 | F1 0.8710 | Elapsed: 6.19s
01/23/2023 04:33:37 PM  [*] Mon Jan 23 16:33:37 2023: Train Epoch: 1 [20800/38063 (55%)]	Loss: 0.403258 | FPR 0.001 -- TPR 0.8226 | F1 0.8921 | Elapsed: 6.12s
01/23/2023 04:33:43 PM  [*] Mon Jan 23 16:33:43 2023: Train Epoch: 1 [22400/38063 (59%)]	Loss: 0.210147 | FPR 0.001 -- TPR 0.8522 | F1 0.9095 | Elapsed: 5.61s
01/23/2023 04:33:48 PM  [*] Mon Jan 23 16:33:48 2023: Train Epoch: 1 [24000/38063 (63%)]	Loss: 0.089262 | FPR 0.001 -- TPR 0.8349 | F1 0.9000 | Elapsed: 5.37s
01/23/2023 04:33:53 PM  [*] Mon Jan 23 16:33:53 2023: Train Epoch: 1 [25600/38063 (67%)]	Loss: 0.201342 | FPR 0.001 -- TPR 0.8947 | F1 0.9381 | Elapsed: 5.47s
01/23/2023 04:33:59 PM  [*] Mon Jan 23 16:33:59 2023: Train Epoch: 1 [27200/38063 (71%)]	Loss: 0.485709 | FPR 0.001 -- TPR 0.8735 | F1 0.9256 | Elapsed: 5.50s
01/23/2023 04:34:04 PM  [*] Mon Jan 23 16:34:04 2023: Train Epoch: 1 [28800/38063 (76%)]	Loss: 0.100237 | FPR 0.001 -- TPR 0.8850 | F1 0.9287 | Elapsed: 5.46s
01/23/2023 04:34:10 PM  [*] Mon Jan 23 16:34:10 2023: Train Epoch: 1 [30400/38063 (80%)]	Loss: 0.484107 | FPR 0.001 -- TPR 0.9122 | F1 0.9479 | Elapsed: 5.66s
01/23/2023 04:34:15 PM [!] Learning rate: 2.5e-05
01/23/2023 04:34:15 PM  [*] Mon Jan 23 16:34:15 2023: Train Epoch: 1 [32000/38063 (84%)]	Loss: 0.507104 | FPR 0.001 -- TPR 0.8896 | F1 0.9350 | Elapsed: 5.40s
01/23/2023 04:34:21 PM  [*] Mon Jan 23 16:34:21 2023: Train Epoch: 1 [33600/38063 (88%)]	Loss: 0.166209 | FPR 0.001 -- TPR 0.9015 | F1 0.9399 | Elapsed: 5.55s
01/23/2023 04:34:27 PM  [*] Mon Jan 23 16:34:27 2023: Train Epoch: 1 [35200/38063 (92%)]	Loss: 0.304873 | FPR 0.001 -- TPR 0.8792 | F1 0.9270 | Elapsed: 5.51s
01/23/2023 04:34:32 PM  [*] Mon Jan 23 16:34:32 2023: Train Epoch: 1 [36800/38063 (97%)]	Loss: 0.225469 | FPR 0.001 -- TPR 0.8989 | F1 0.9398 | Elapsed: 5.57s
01/23/2023 04:34:36 PM  [*] Mon Jan 23 16:34:36 2023:    1    | Tr.loss: 0.312342 | FPR 0.001 -- TPR: 0.78 |  F1: 0.85 | Elapsed:  131.00  s
01/23/2023 04:34:36 PM  [*] Started epoch: 2
01/23/2023 04:34:36 PM  [*] Mon Jan 23 16:34:36 2023: Train Epoch: 2 [  0  /38063 (0 %)]	Loss: 0.310512 | FPR 0.001 -- TPR 0.8462 | F1 0.9167 | Elapsed: 0.07s
01/23/2023 04:34:42 PM  [*] Mon Jan 23 16:34:42 2023: Train Epoch: 2 [1600 /38063 (4 %)]	Loss: 0.080031 | FPR 0.001 -- TPR 0.9362 | F1 0.9634 | Elapsed: 5.36s
01/23/2023 04:34:47 PM  [*] Mon Jan 23 16:34:47 2023: Train Epoch: 2 [3200 /38063 (8 %)]	Loss: 0.523063 | FPR 0.001 -- TPR 0.9255 | F1 0.9568 | Elapsed: 5.53s
01/23/2023 04:34:52 PM  [*] Mon Jan 23 16:34:52 2023: Train Epoch: 2 [4800 /38063 (13%)]	Loss: 0.016581 | FPR 0.001 -- TPR 0.9018 | F1 0.9388 | Elapsed: 5.25s
01/23/2023 04:34:58 PM  [*] Mon Jan 23 16:34:58 2023: Train Epoch: 2 [6400 /38063 (17%)]	Loss: 0.197986 | FPR 0.001 -- TPR 0.9280 | F1 0.9490 | Elapsed: 5.54s
01/23/2023 04:35:03 PM  [*] Mon Jan 23 16:35:03 2023: Train Epoch: 2 [8000 /38063 (21%)]	Loss: 0.017235 | FPR 0.001 -- TPR 0.9236 | F1 0.9569 | Elapsed: 5.23s
01/23/2023 04:35:09 PM  [*] Mon Jan 23 16:35:09 2023: Train Epoch: 2 [9600 /38063 (25%)]	Loss: 0.321666 | FPR 0.001 -- TPR 0.9130 | F1 0.9495 | Elapsed: 5.42s
01/23/2023 04:35:14 PM  [*] Mon Jan 23 16:35:14 2023: Train Epoch: 2 [11200/38063 (29%)]	Loss: 0.066438 | FPR 0.001 -- TPR 0.8929 | F1 0.9347 | Elapsed: 5.41s
01/23/2023 04:35:19 PM  [*] Mon Jan 23 16:35:19 2023: Train Epoch: 2 [12800/38063 (34%)]	Loss: 0.047119 | FPR 0.001 -- TPR 0.9274 | F1 0.9592 | Elapsed: 5.35s
01/23/2023 04:35:25 PM  [*] Mon Jan 23 16:35:25 2023: Train Epoch: 2 [14400/38063 (38%)]	Loss: 0.070378 | FPR 0.001 -- TPR 0.9172 | F1 0.9508 | Elapsed: 5.39s
01/23/2023 04:35:30 PM  [*] Mon Jan 23 16:35:30 2023: Train Epoch: 2 [16000/38063 (42%)]	Loss: 0.084841 | FPR 0.001 -- TPR 0.9339 | F1 0.9612 | Elapsed: 5.27s
01/23/2023 04:35:35 PM  [*] Mon Jan 23 16:35:35 2023: Train Epoch: 2 [17600/38063 (46%)]	Loss: 0.220870 | FPR 0.001 -- TPR 0.9340 | F1 0.9625 | Elapsed: 5.34s
01/23/2023 04:35:41 PM  [*] Mon Jan 23 16:35:41 2023: Train Epoch: 2 [19200/38063 (50%)]	Loss: 0.041191 | FPR 0.001 -- TPR 0.9445 | F1 0.9687 | Elapsed: 5.29s
01/23/2023 04:35:46 PM  [*] Mon Jan 23 16:35:46 2023: Train Epoch: 2 [20800/38063 (55%)]	Loss: 0.204989 | FPR 0.001 -- TPR 0.9251 | F1 0.9551 | Elapsed: 5.46s
01/23/2023 04:35:52 PM  [*] Mon Jan 23 16:35:52 2023: Train Epoch: 2 [22400/38063 (59%)]	Loss: 0.351172 | FPR 0.001 -- TPR 0.9439 | F1 0.9680 | Elapsed: 5.39s
01/23/2023 04:35:57 PM  [*] Mon Jan 23 16:35:57 2023: Train Epoch: 2 [24000/38063 (63%)]	Loss: 0.064891 | FPR 0.001 -- TPR 0.9350 | F1 0.9624 | Elapsed: 5.34s
01/23/2023 04:36:02 PM  [*] Mon Jan 23 16:36:02 2023: Train Epoch: 2 [25600/38063 (67%)]	Loss: 0.137850 | FPR 0.001 -- TPR 0.9474 | F1 0.9695 | Elapsed: 5.30s
01/23/2023 04:36:03 PM [!] Learning rate: 2.5e-06
01/23/2023 04:36:08 PM  [*] Mon Jan 23 16:36:08 2023: Train Epoch: 2 [27200/38063 (71%)]	Loss: 0.201296 | FPR 0.001 -- TPR 0.9210 | F1 0.9549 | Elapsed: 5.31s
01/23/2023 04:36:13 PM  [*] Mon Jan 23 16:36:13 2023: Train Epoch: 2 [28800/38063 (76%)]	Loss: 0.157884 | FPR 0.001 -- TPR 0.9100 | F1 0.9465 | Elapsed: 5.21s
01/23/2023 04:36:18 PM  [*] Mon Jan 23 16:36:18 2023: Train Epoch: 2 [30400/38063 (80%)]	Loss: 0.292284 | FPR 0.001 -- TPR 0.9321 | F1 0.9514 | Elapsed: 5.53s
01/23/2023 04:36:24 PM  [*] Mon Jan 23 16:36:24 2023: Train Epoch: 2 [32000/38063 (84%)]	Loss: 0.120757 | FPR 0.001 -- TPR 0.9287 | F1 0.9589 | Elapsed: 5.37s
01/23/2023 04:36:29 PM  [*] Mon Jan 23 16:36:29 2023: Train Epoch: 2 [33600/38063 (88%)]	Loss: 0.152954 | FPR 0.001 -- TPR 0.9340 | F1 0.9610 | Elapsed: 5.38s
01/23/2023 04:36:34 PM  [*] Mon Jan 23 16:36:34 2023: Train Epoch: 2 [35200/38063 (92%)]	Loss: 0.212939 | FPR 0.001 -- TPR 0.9047 | F1 0.9416 | Elapsed: 5.35s
01/23/2023 04:36:40 PM  [*] Mon Jan 23 16:36:40 2023: Train Epoch: 2 [36800/38063 (97%)]	Loss: 0.292587 | FPR 0.001 -- TPR 0.9169 | F1 0.9493 | Elapsed: 5.36s
01/23/2023 04:36:44 PM  [*] Mon Jan 23 16:36:44 2023:    2    | Tr.loss: 0.170762 | FPR 0.001 -- TPR: 0.93 |  F1: 0.96 | Elapsed:  127.57  s
01/23/2023 04:36:44 PM  [*] Started epoch: 3
01/23/2023 04:36:44 PM  [*] Mon Jan 23 16:36:44 2023: Train Epoch: 3 [  0  /38063 (0 %)]	Loss: 0.254046 | FPR 0.001 -- TPR 0.9091 | F1 0.9524 | Elapsed: 0.08s
01/23/2023 04:36:50 PM  [*] Mon Jan 23 16:36:50 2023: Train Epoch: 3 [1600 /38063 (4 %)]	Loss: 0.178906 | FPR 0.001 -- TPR 0.9370 | F1 0.9615 | Elapsed: 5.65s
01/23/2023 04:36:55 PM  [*] Mon Jan 23 16:36:55 2023: Train Epoch: 3 [3200 /38063 (8 %)]	Loss: 0.106263 | FPR 0.001 -- TPR 0.9359 | F1 0.9628 | Elapsed: 5.52s
01/23/2023 04:37:00 PM  [*] Mon Jan 23 16:37:00 2023: Train Epoch: 3 [4800 /38063 (13%)]	Loss: 0.134513 | FPR 0.001 -- TPR 0.9384 | F1 0.9558 | Elapsed: 5.27s
01/23/2023 04:37:06 PM  [*] Mon Jan 23 16:37:06 2023: Train Epoch: 3 [6400 /38063 (17%)]	Loss: 0.258827 | FPR 0.001 -- TPR 0.9314 | F1 0.9601 | Elapsed: 5.24s
01/23/2023 04:37:11 PM  [*] Mon Jan 23 16:37:11 2023: Train Epoch: 3 [8000 /38063 (21%)]	Loss: 0.247432 | FPR 0.001 -- TPR 0.9133 | F1 0.9451 | Elapsed: 5.37s
01/23/2023 04:37:16 PM  [*] Mon Jan 23 16:37:16 2023: Train Epoch: 3 [9600 /38063 (25%)]	Loss: 0.125784 | FPR 0.001 -- TPR 0.9322 | F1 0.9620 | Elapsed: 5.36s
01/23/2023 04:37:22 PM  [*] Mon Jan 23 16:37:22 2023: Train Epoch: 3 [11200/38063 (29%)]	Loss: 0.081980 | FPR 0.001 -- TPR 0.9355 | F1 0.9634 | Elapsed: 5.49s
01/23/2023 04:37:27 PM  [*] Mon Jan 23 16:37:27 2023: Train Epoch: 3 [12800/38063 (34%)]	Loss: 0.081036 | FPR 0.001 -- TPR 0.9415 | F1 0.9662 | Elapsed: 5.25s
01/23/2023 04:37:32 PM  [*] Mon Jan 23 16:37:32 2023: Train Epoch: 3 [14400/38063 (38%)]	Loss: 0.149686 | FPR 0.001 -- TPR 0.9126 | F1 0.9473 | Elapsed: 5.39s
01/23/2023 04:37:38 PM  [*] Mon Jan 23 16:37:38 2023: Train Epoch: 3 [16000/38063 (42%)]	Loss: 0.137089 | FPR 0.001 -- TPR 0.9311 | F1 0.9506 | Elapsed: 5.65s
01/23/2023 04:37:43 PM  [*] Mon Jan 23 16:37:43 2023: Train Epoch: 3 [17600/38063 (46%)]	Loss: 0.245546 | FPR 0.001 -- TPR 0.9418 | F1 0.9668 | Elapsed: 5.31s
01/23/2023 04:37:49 PM  [*] Mon Jan 23 16:37:49 2023: Train Epoch: 3 [19200/38063 (50%)]	Loss: 0.143999 | FPR 0.001 -- TPR 0.9291 | F1 0.9584 | Elapsed: 5.48s
01/23/2023 04:37:51 PM [!] Learning rate: 2.5000000000000004e-07
01/23/2023 04:37:54 PM  [*] Mon Jan 23 16:37:54 2023: Train Epoch: 3 [20800/38063 (55%)]	Loss: 0.131362 | FPR 0.001 -- TPR 0.9354 | F1 0.9617 | Elapsed: 5.24s
01/23/2023 04:37:59 PM  [*] Mon Jan 23 16:37:59 2023: Train Epoch: 3 [22400/38063 (59%)]	Loss: 0.217620 | FPR 0.001 -- TPR 0.9325 | F1 0.9513 | Elapsed: 5.26s
01/23/2023 04:38:05 PM  [*] Mon Jan 23 16:38:05 2023: Train Epoch: 3 [24000/38063 (63%)]	Loss: 0.071835 | FPR 0.001 -- TPR 0.9377 | F1 0.9639 | Elapsed: 5.25s
01/23/2023 04:38:10 PM  [*] Mon Jan 23 16:38:10 2023: Train Epoch: 3 [25600/38063 (67%)]	Loss: 0.097918 | FPR 0.001 -- TPR 0.9204 | F1 0.9529 | Elapsed: 5.53s
01/23/2023 04:38:15 PM  [*] Mon Jan 23 16:38:15 2023: Train Epoch: 3 [27200/38063 (71%)]	Loss: 0.265121 | FPR 0.001 -- TPR 0.9250 | F1 0.9569 | Elapsed: 5.34s
01/23/2023 04:38:21 PM  [*] Mon Jan 23 16:38:21 2023: Train Epoch: 3 [28800/38063 (76%)]	Loss: 0.066074 | FPR 0.001 -- TPR 0.9292 | F1 0.9591 | Elapsed: 5.26s
01/23/2023 04:38:26 PM  [*] Mon Jan 23 16:38:26 2023: Train Epoch: 3 [30400/38063 (80%)]	Loss: 0.219074 | FPR 0.001 -- TPR 0.9215 | F1 0.9530 | Elapsed: 5.13s
01/23/2023 04:38:31 PM  [*] Mon Jan 23 16:38:31 2023: Train Epoch: 3 [32000/38063 (84%)]	Loss: 0.133868 | FPR 0.001 -- TPR 0.9294 | F1 0.9486 | Elapsed: 5.36s
01/23/2023 04:38:37 PM  [*] Mon Jan 23 16:38:37 2023: Train Epoch: 3 [33600/38063 (88%)]	Loss: 0.048480 | FPR 0.001 -- TPR 0.9295 | F1 0.9569 | Elapsed: 5.33s
01/23/2023 04:38:42 PM  [*] Mon Jan 23 16:38:42 2023: Train Epoch: 3 [35200/38063 (92%)]	Loss: 0.139655 | FPR 0.001 -- TPR 0.9279 | F1 0.9585 | Elapsed: 5.24s
01/23/2023 04:38:47 PM  [*] Mon Jan 23 16:38:47 2023: Train Epoch: 3 [36800/38063 (97%)]	Loss: 0.054548 | FPR 0.001 -- TPR 0.9495 | F1 0.9724 | Elapsed: 5.25s
01/23/2023 04:38:51 PM  [*] Mon Jan 23 16:38:51 2023:    3    | Tr.loss: 0.161902 | FPR 0.001 -- TPR: 0.93 |  F1: 0.96 | Elapsed:  127.42  s
01/23/2023 04:38:51 PM [!] Mon Jan 23 16:38:51 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\crossValidation\Transformer_512_BPE\nLayers\trainingFiles\trainingFiles_1674488331-model.torch
                losses    : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\crossValidation\Transformer_512_BPE\nLayers\trainingFiles\trainingFiles_1674488331-train_losses.npy
                duration  : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\crossValidation\Transformer_512_BPE\nLayers\trainingFiles\trainingFiles_1674488331-trainTime.npy
		train F1s : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\crossValidation\Transformer_512_BPE\nLayers\trainingFiles\trainingFiles_1674488331-trainF1s.npy
		train TPRs: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\crossValidation\Transformer_512_BPE\nLayers\trainingFiles\trainingFiles_1674488331-trainTPRs.npy
01/23/2023 04:38:51 PM  [!] Evaluating model on validation set...
01/23/2023 04:38:51 PM  [*] Predicting batch: 0/2379
01/23/2023 04:38:52 PM  [*] Predicting batch: 100/2379
01/23/2023 04:38:53 PM  [*] Predicting batch: 200/2379
01/23/2023 04:38:54 PM  [*] Predicting batch: 300/2379
01/23/2023 04:38:55 PM  [*] Predicting batch: 400/2379
01/23/2023 04:38:55 PM  [*] Predicting batch: 500/2379
01/23/2023 04:38:56 PM  [*] Predicting batch: 600/2379
01/23/2023 04:38:57 PM  [*] Predicting batch: 700/2379
01/23/2023 04:38:58 PM  [*] Predicting batch: 800/2379
01/23/2023 04:38:59 PM  [*] Predicting batch: 900/2379
01/23/2023 04:39:00 PM  [*] Predicting batch: 1000/2379
01/23/2023 04:39:00 PM  [*] Predicting batch: 1100/2379
01/23/2023 04:39:01 PM  [*] Predicting batch: 1200/2379
01/23/2023 04:39:02 PM  [*] Predicting batch: 1300/2379
01/23/2023 04:39:03 PM  [*] Predicting batch: 1400/2379
01/23/2023 04:39:04 PM  [*] Predicting batch: 1500/2379
01/23/2023 04:39:05 PM  [*] Predicting batch: 1600/2379
01/23/2023 04:39:05 PM  [*] Predicting batch: 1700/2379
01/23/2023 04:39:06 PM  [*] Predicting batch: 1800/2379
01/23/2023 04:39:07 PM  [*] Predicting batch: 1900/2379
01/23/2023 04:39:08 PM  [*] Predicting batch: 2000/2379
01/23/2023 04:39:09 PM  [*] Predicting batch: 2100/2379
01/23/2023 04:39:09 PM  [*] Predicting batch: 2200/2379
01/23/2023 04:39:10 PM  [*] Predicting batch: 2300/2379
01/23/2023 04:39:11 PM  [!] This fold metrics on validation set:
01/23/2023 04:39:11 PM  [!] FPR: 0.0001 | TPR: 0.37634785316672503 | F1: 0.5468635103795464
01/23/2023 04:39:11 PM  [!] FPR: 0.0003 | TPR: 0.6125189769940441 | F1: 0.7596495039467014
01/23/2023 04:39:11 PM  [!] FPR: 0.001 | TPR: 0.708240881311067 | F1: 0.8289782435357101
01/23/2023 04:39:11 PM  [!] FPR: 0.003 | TPR: 0.7796333060843162 | F1: 0.8754644402675176
01/23/2023 04:39:11 PM  [!] FPR: 0.01 | TPR: 0.8570594417844214 | F1: 0.9206548328419997
01/23/2023 04:39:11 PM  [!] FPR: 0.03 | TPR: 0.911246058624314 | F1: 0.9464108835836584
01/23/2023 04:39:11 PM  [!] FPR: 0.1 | TPR: 0.9703764257075013 | F1: 0.9614687391522352
01/23/2023 04:39:11 PM  [!] Metrics saved to C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\crossValidation\Transformer_512_BPE\nLayers\metrics_trainSize_76126_ep_3_cv_2_vocabSize_50000_maxLen_512_dModel_64_nHeads_8_dHidden_256_nLayers_2_numClasses_1_hiddenNeurons_64_layerNorm_False_dropout_0.3.json
01/23/2023 04:39:11 PM  [!] Average epoch time: 128.71s | Mean values over 2 folds:
	FPR: 0.0001 -- TPR: 0.3378 -- F1: 0.5038
	FPR: 0.0003 -- TPR: 0.5832 -- F1: 0.7363
	FPR:  0.001 -- TPR: 0.7339 -- F1: 0.8461
	FPR:  0.003 -- TPR: 0.8082 -- F1: 0.8930
	FPR:   0.01 -- TPR: 0.8651 -- F1: 0.9253
	FPR:   0.03 -- TPR: 0.9131 -- F1: 0.9475
	FPR:    0.1 -- TPR: 0.9690 -- F1: 0.9608

01/23/2023 04:39:41 PM  [!] Using device: cuda:0 | Dataset size: 76126
01/23/2023 04:39:41 PM  [!] Epochs per fold: 3 | Model config: {'vocabSize': 50000, 'maxLen': 512, 'dModel': 64, 'nHeads': 8, 'dHidden': 256, 'nLayers': 4, 'numClasses': 1, 'hiddenNeurons': [64], 'layerNorm': False, 'dropout': 0.3}
01/23/2023 04:39:41 PM  [!] Fold 1/2 | Train set size: 38063, Validation set size: 38063
01/23/2023 04:39:41 PM  [*] Started epoch: 1
01/23/2023 04:39:42 PM  [*] Mon Jan 23 16:39:42 2023: Train Epoch: 1 [  0  /38063 (0 %)]	Loss: 2.276289 | FPR 0.001 -- TPR 0.0000 | F1 0.0000 | Elapsed: 0.23s
01/23/2023 04:39:51 PM  [*] Mon Jan 23 16:39:51 2023: Train Epoch: 1 [1600 /38063 (4 %)]	Loss: 0.478390 | FPR 0.001 -- TPR 0.2789 | F1 0.3811 | Elapsed: 9.44s
01/23/2023 04:40:00 PM  [*] Mon Jan 23 16:40:00 2023: Train Epoch: 1 [3200 /38063 (8 %)]	Loss: 0.323984 | FPR 0.001 -- TPR 0.4143 | F1 0.5381 | Elapsed: 9.10s
01/23/2023 04:40:09 PM  [*] Mon Jan 23 16:40:09 2023: Train Epoch: 1 [4800 /38063 (13%)]	Loss: 0.702528 | FPR 0.001 -- TPR 0.5195 | F1 0.6486 | Elapsed: 9.08s
01/23/2023 04:40:19 PM  [*] Mon Jan 23 16:40:19 2023: Train Epoch: 1 [6400 /38063 (17%)]	Loss: 0.664045 | FPR 0.001 -- TPR 0.6148 | F1 0.7281 | Elapsed: 9.22s
01/23/2023 04:40:28 PM  [*] Mon Jan 23 16:40:28 2023: Train Epoch: 1 [8000 /38063 (21%)]	Loss: 0.731221 | FPR 0.001 -- TPR 0.6046 | F1 0.7147 | Elapsed: 9.52s
01/23/2023 04:40:37 PM  [*] Mon Jan 23 16:40:37 2023: Train Epoch: 1 [9600 /38063 (25%)]	Loss: 0.365105 | FPR 0.001 -- TPR 0.6700 | F1 0.7650 | Elapsed: 9.17s
01/23/2023 04:40:46 PM  [*] Mon Jan 23 16:40:46 2023: Train Epoch: 1 [11200/38063 (29%)]	Loss: 0.224502 | FPR 0.001 -- TPR 0.7362 | F1 0.8302 | Elapsed: 9.13s
01/23/2023 04:40:56 PM  [*] Mon Jan 23 16:40:56 2023: Train Epoch: 1 [12800/38063 (34%)]	Loss: 0.379670 | FPR 0.001 -- TPR 0.7157 | F1 0.8102 | Elapsed: 9.35s
01/23/2023 04:41:05 PM  [*] Mon Jan 23 16:41:05 2023: Train Epoch: 1 [14400/38063 (38%)]	Loss: 0.257127 | FPR 0.001 -- TPR 0.7712 | F1 0.8575 | Elapsed: 9.59s
01/23/2023 04:41:15 PM  [*] Mon Jan 23 16:41:15 2023: Train Epoch: 1 [16000/38063 (42%)]	Loss: 0.361738 | FPR 0.001 -- TPR 0.7641 | F1 0.8492 | Elapsed: 9.30s
01/23/2023 04:41:24 PM  [*] Mon Jan 23 16:41:24 2023: Train Epoch: 1 [17600/38063 (46%)]	Loss: 0.413946 | FPR 0.001 -- TPR 0.7395 | F1 0.8323 | Elapsed: 9.25s
01/23/2023 04:41:33 PM  [*] Mon Jan 23 16:41:33 2023: Train Epoch: 1 [19200/38063 (50%)]	Loss: 0.301372 | FPR 0.001 -- TPR 0.8016 | F1 0.8721 | Elapsed: 9.07s
01/23/2023 04:41:42 PM  [*] Mon Jan 23 16:41:42 2023: Train Epoch: 1 [20800/38063 (55%)]	Loss: 0.342036 | FPR 0.001 -- TPR 0.8158 | F1 0.8869 | Elapsed: 9.21s
01/23/2023 04:41:51 PM  [*] Mon Jan 23 16:41:51 2023: Train Epoch: 1 [22400/38063 (59%)]	Loss: 0.136205 | FPR 0.001 -- TPR 0.8178 | F1 0.8859 | Elapsed: 9.23s
01/23/2023 04:42:01 PM  [*] Mon Jan 23 16:42:01 2023: Train Epoch: 1 [24000/38063 (63%)]	Loss: 0.432601 | FPR 0.001 -- TPR 0.8231 | F1 0.8899 | Elapsed: 9.62s
01/23/2023 04:42:10 PM  [*] Mon Jan 23 16:42:10 2023: Train Epoch: 1 [25600/38063 (67%)]	Loss: 0.245901 | FPR 0.001 -- TPR 0.8477 | F1 0.9047 | Elapsed: 9.49s
01/23/2023 04:42:20 PM  [*] Mon Jan 23 16:42:20 2023: Train Epoch: 1 [27200/38063 (71%)]	Loss: 0.306086 | FPR 0.001 -- TPR 0.8609 | F1 0.9146 | Elapsed: 9.50s
01/23/2023 04:42:29 PM  [*] Mon Jan 23 16:42:29 2023: Train Epoch: 1 [28800/38063 (76%)]	Loss: 0.437961 | FPR 0.001 -- TPR 0.8779 | F1 0.9195 | Elapsed: 9.46s
01/23/2023 04:42:39 PM  [*] Mon Jan 23 16:42:39 2023: Train Epoch: 1 [30400/38063 (80%)]	Loss: 0.905268 | FPR 0.001 -- TPR 0.8625 | F1 0.9120 | Elapsed: 9.33s
01/23/2023 04:42:48 PM [!] Learning rate: 2.5e-05
01/23/2023 04:42:48 PM  [*] Mon Jan 23 16:42:48 2023: Train Epoch: 1 [32000/38063 (84%)]	Loss: 0.118496 | FPR 0.001 -- TPR 0.8768 | F1 0.9280 | Elapsed: 9.47s
01/23/2023 04:42:58 PM  [*] Mon Jan 23 16:42:58 2023: Train Epoch: 1 [33600/38063 (88%)]	Loss: 0.251790 | FPR 0.001 -- TPR 0.8793 | F1 0.9187 | Elapsed: 9.34s
01/23/2023 04:43:07 PM  [*] Mon Jan 23 16:43:07 2023: Train Epoch: 1 [35200/38063 (92%)]	Loss: 0.191098 | FPR 0.001 -- TPR 0.8865 | F1 0.9341 | Elapsed: 9.63s
01/23/2023 04:43:18 PM  [*] Mon Jan 23 16:43:18 2023: Train Epoch: 1 [36800/38063 (97%)]	Loss: 0.100598 | FPR 0.001 -- TPR 0.8836 | F1 0.9309 | Elapsed: 10.74s
01/23/2023 04:43:27 PM  [*] Mon Jan 23 16:43:27 2023:    1    | Tr.loss: 0.340144 | FPR 0.001 -- TPR: 0.75 |  F1: 0.82 | Elapsed:  225.28  s
01/23/2023 04:43:27 PM  [*] Started epoch: 2
01/23/2023 04:43:27 PM  [*] Mon Jan 23 16:43:27 2023: Train Epoch: 2 [  0  /38063 (0 %)]	Loss: 0.371346 | FPR 0.001 -- TPR 0.8182 | F1 0.9000 | Elapsed: 0.13s
01/23/2023 04:43:36 PM  [*] Mon Jan 23 16:43:36 2023: Train Epoch: 2 [1600 /38063 (4 %)]	Loss: 0.281259 | FPR 0.001 -- TPR 0.9016 | F1 0.9424 | Elapsed: 9.23s
01/23/2023 04:43:45 PM  [*] Mon Jan 23 16:43:45 2023: Train Epoch: 2 [3200 /38063 (8 %)]	Loss: 0.222127 | FPR 0.001 -- TPR 0.9016 | F1 0.9326 | Elapsed: 9.27s
01/23/2023 04:43:55 PM  [*] Mon Jan 23 16:43:55 2023: Train Epoch: 2 [4800 /38063 (13%)]	Loss: 0.377439 | FPR 0.001 -- TPR 0.9049 | F1 0.9454 | Elapsed: 9.58s
01/23/2023 04:44:05 PM  [*] Mon Jan 23 16:44:05 2023: Train Epoch: 2 [6400 /38063 (17%)]	Loss: 0.078005 | FPR 0.001 -- TPR 0.9118 | F1 0.9483 | Elapsed: 9.82s
01/23/2023 04:44:15 PM  [*] Mon Jan 23 16:44:15 2023: Train Epoch: 2 [8000 /38063 (21%)]	Loss: 0.292876 | FPR 0.001 -- TPR 0.9183 | F1 0.9541 | Elapsed: 9.79s
01/23/2023 04:44:24 PM  [*] Mon Jan 23 16:44:24 2023: Train Epoch: 2 [9600 /38063 (25%)]	Loss: 0.089884 | FPR 0.001 -- TPR 0.9200 | F1 0.9448 | Elapsed: 9.60s
01/23/2023 04:44:34 PM  [*] Mon Jan 23 16:44:34 2023: Train Epoch: 2 [11200/38063 (29%)]	Loss: 0.148063 | FPR 0.001 -- TPR 0.9082 | F1 0.9455 | Elapsed: 9.63s
01/23/2023 04:44:43 PM  [*] Mon Jan 23 16:44:43 2023: Train Epoch: 2 [12800/38063 (34%)]	Loss: 0.169549 | FPR 0.001 -- TPR 0.9163 | F1 0.9521 | Elapsed: 9.50s
01/23/2023 04:44:53 PM  [*] Mon Jan 23 16:44:53 2023: Train Epoch: 2 [14400/38063 (38%)]	Loss: 0.440848 | FPR 0.001 -- TPR 0.9181 | F1 0.9532 | Elapsed: 9.41s
01/23/2023 04:45:02 PM  [*] Mon Jan 23 16:45:02 2023: Train Epoch: 2 [16000/38063 (42%)]	Loss: 0.146923 | FPR 0.001 -- TPR 0.9119 | F1 0.9479 | Elapsed: 9.73s
01/23/2023 04:45:12 PM  [*] Mon Jan 23 16:45:12 2023: Train Epoch: 2 [17600/38063 (46%)]	Loss: 0.210828 | FPR 0.001 -- TPR 0.8920 | F1 0.9350 | Elapsed: 9.23s
01/23/2023 04:45:21 PM  [*] Mon Jan 23 16:45:21 2023: Train Epoch: 2 [19200/38063 (50%)]	Loss: 0.211069 | FPR 0.001 -- TPR 0.9155 | F1 0.9510 | Elapsed: 9.63s
01/23/2023 04:45:31 PM  [*] Mon Jan 23 16:45:31 2023: Train Epoch: 2 [20800/38063 (55%)]	Loss: 0.148117 | FPR 0.001 -- TPR 0.9211 | F1 0.9539 | Elapsed: 9.71s
01/23/2023 04:45:40 PM  [*] Mon Jan 23 16:45:40 2023: Train Epoch: 2 [22400/38063 (59%)]	Loss: 0.248500 | FPR 0.001 -- TPR 0.9098 | F1 0.9465 | Elapsed: 9.26s
01/23/2023 04:45:50 PM  [*] Mon Jan 23 16:45:50 2023: Train Epoch: 2 [24000/38063 (63%)]	Loss: 0.226205 | FPR 0.001 -- TPR 0.8991 | F1 0.9408 | Elapsed: 9.52s
01/23/2023 04:46:00 PM  [*] Mon Jan 23 16:46:00 2023: Train Epoch: 2 [25600/38063 (67%)]	Loss: 0.078243 | FPR 0.001 -- TPR 0.9122 | F1 0.9473 | Elapsed: 9.75s
01/23/2023 04:46:01 PM [!] Learning rate: 2.5e-06
01/23/2023 04:46:09 PM  [*] Mon Jan 23 16:46:09 2023: Train Epoch: 2 [27200/38063 (71%)]	Loss: 0.053927 | FPR 0.001 -- TPR 0.9241 | F1 0.9566 | Elapsed: 9.14s
01/23/2023 04:46:18 PM  [*] Mon Jan 23 16:46:18 2023: Train Epoch: 2 [28800/38063 (76%)]	Loss: 0.464664 | FPR 0.001 -- TPR 0.8927 | F1 0.9329 | Elapsed: 9.09s
01/23/2023 04:46:27 PM  [*] Mon Jan 23 16:46:27 2023: Train Epoch: 2 [30400/38063 (80%)]	Loss: 0.096488 | FPR 0.001 -- TPR 0.9241 | F1 0.9573 | Elapsed: 9.48s
01/23/2023 04:46:36 PM  [*] Mon Jan 23 16:46:36 2023: Train Epoch: 2 [32000/38063 (84%)]	Loss: 0.091973 | FPR 0.001 -- TPR 0.9249 | F1 0.9566 | Elapsed: 9.21s
01/23/2023 04:46:46 PM  [*] Mon Jan 23 16:46:46 2023: Train Epoch: 2 [33600/38063 (88%)]	Loss: 0.391780 | FPR 0.001 -- TPR 0.9206 | F1 0.9543 | Elapsed: 9.09s
01/23/2023 04:46:55 PM  [*] Mon Jan 23 16:46:55 2023: Train Epoch: 2 [35200/38063 (92%)]	Loss: 0.209450 | FPR 0.001 -- TPR 0.9353 | F1 0.9623 | Elapsed: 9.02s
01/23/2023 04:47:04 PM  [*] Mon Jan 23 16:47:04 2023: Train Epoch: 2 [36800/38063 (97%)]	Loss: 0.160021 | FPR 0.001 -- TPR 0.9146 | F1 0.9514 | Elapsed: 9.65s
01/23/2023 04:47:11 PM  [*] Mon Jan 23 16:47:11 2023:    2    | Tr.loss: 0.193490 | FPR 0.001 -- TPR: 0.91 |  F1: 0.95 | Elapsed:  224.74  s
01/23/2023 04:47:11 PM  [*] Started epoch: 3
01/23/2023 04:47:12 PM  [*] Mon Jan 23 16:47:12 2023: Train Epoch: 3 [  0  /38063 (0 %)]	Loss: 0.540630 | FPR 0.001 -- TPR 0.7500 | F1 0.8571 | Elapsed: 0.11s
01/23/2023 04:47:21 PM  [*] Mon Jan 23 16:47:21 2023: Train Epoch: 3 [1600 /38063 (4 %)]	Loss: 0.057503 | FPR 0.001 -- TPR 0.9369 | F1 0.9549 | Elapsed: 9.44s
01/23/2023 04:47:30 PM  [*] Mon Jan 23 16:47:30 2023: Train Epoch: 3 [3200 /38063 (8 %)]	Loss: 0.081544 | FPR 0.001 -- TPR 0.9024 | F1 0.9334 | Elapsed: 9.43s
01/23/2023 04:47:41 PM  [*] Mon Jan 23 16:47:41 2023: Train Epoch: 3 [4800 /38063 (13%)]	Loss: 0.403924 | FPR 0.001 -- TPR 0.9138 | F1 0.9510 | Elapsed: 10.50s
01/23/2023 04:47:51 PM  [*] Mon Jan 23 16:47:51 2023: Train Epoch: 3 [6400 /38063 (17%)]	Loss: 0.362211 | FPR 0.001 -- TPR 0.9303 | F1 0.9591 | Elapsed: 9.70s
01/23/2023 04:48:00 PM  [*] Mon Jan 23 16:48:00 2023: Train Epoch: 3 [8000 /38063 (21%)]	Loss: 0.157568 | FPR 0.001 -- TPR 0.9370 | F1 0.9649 | Elapsed: 9.33s
01/23/2023 04:48:09 PM  [*] Mon Jan 23 16:48:09 2023: Train Epoch: 3 [9600 /38063 (25%)]	Loss: 0.156142 | FPR 0.001 -- TPR 0.9213 | F1 0.9534 | Elapsed: 9.39s
01/23/2023 04:48:19 PM  [*] Mon Jan 23 16:48:19 2023: Train Epoch: 3 [11200/38063 (29%)]	Loss: 0.236165 | FPR 0.001 -- TPR 0.9141 | F1 0.9511 | Elapsed: 9.51s
01/23/2023 04:48:28 PM  [*] Mon Jan 23 16:48:28 2023: Train Epoch: 3 [12800/38063 (34%)]	Loss: 0.146178 | FPR 0.001 -- TPR 0.9036 | F1 0.9440 | Elapsed: 9.56s
01/23/2023 04:48:38 PM  [*] Mon Jan 23 16:48:38 2023: Train Epoch: 3 [14400/38063 (38%)]	Loss: 0.235273 | FPR 0.001 -- TPR 0.9086 | F1 0.9476 | Elapsed: 9.53s
01/23/2023 04:48:47 PM  [*] Mon Jan 23 16:48:47 2023: Train Epoch: 3 [16000/38063 (42%)]	Loss: 0.140523 | FPR 0.001 -- TPR 0.9129 | F1 0.9405 | Elapsed: 9.41s
01/23/2023 04:48:57 PM  [*] Mon Jan 23 16:48:57 2023: Train Epoch: 3 [17600/38063 (46%)]	Loss: 0.187180 | FPR 0.001 -- TPR 0.9245 | F1 0.9561 | Elapsed: 9.33s
01/23/2023 04:49:06 PM  [*] Mon Jan 23 16:49:06 2023: Train Epoch: 3 [19200/38063 (50%)]	Loss: 0.194978 | FPR 0.001 -- TPR 0.9279 | F1 0.9581 | Elapsed: 9.28s
01/23/2023 04:49:10 PM [!] Learning rate: 2.5000000000000004e-07
01/23/2023 04:49:15 PM  [*] Mon Jan 23 16:49:15 2023: Train Epoch: 3 [20800/38063 (55%)]	Loss: 0.135643 | FPR 0.001 -- TPR 0.8961 | F1 0.9388 | Elapsed: 9.42s
01/23/2023 04:49:25 PM  [*] Mon Jan 23 16:49:25 2023: Train Epoch: 3 [22400/38063 (59%)]	Loss: 0.394859 | FPR 0.001 -- TPR 0.9078 | F1 0.9379 | Elapsed: 9.32s
01/23/2023 04:49:34 PM  [*] Mon Jan 23 16:49:34 2023: Train Epoch: 3 [24000/38063 (63%)]	Loss: 0.074391 | FPR 0.001 -- TPR 0.9134 | F1 0.9488 | Elapsed: 9.36s
01/23/2023 04:49:43 PM  [*] Mon Jan 23 16:49:43 2023: Train Epoch: 3 [25600/38063 (67%)]	Loss: 0.113682 | FPR 0.001 -- TPR 0.9143 | F1 0.9496 | Elapsed: 9.23s
01/23/2023 04:49:53 PM  [*] Mon Jan 23 16:49:53 2023: Train Epoch: 3 [27200/38063 (71%)]	Loss: 0.119708 | FPR 0.001 -- TPR 0.9091 | F1 0.9462 | Elapsed: 9.30s
01/23/2023 04:50:02 PM  [*] Mon Jan 23 16:50:02 2023: Train Epoch: 3 [28800/38063 (76%)]	Loss: 0.229824 | FPR 0.001 -- TPR 0.9175 | F1 0.9528 | Elapsed: 9.10s
01/23/2023 04:50:11 PM  [*] Mon Jan 23 16:50:11 2023: Train Epoch: 3 [30400/38063 (80%)]	Loss: 0.081214 | FPR 0.001 -- TPR 0.9227 | F1 0.9557 | Elapsed: 9.31s
01/23/2023 04:50:21 PM  [*] Mon Jan 23 16:50:21 2023: Train Epoch: 3 [32000/38063 (84%)]	Loss: 0.116666 | FPR 0.001 -- TPR 0.9290 | F1 0.9589 | Elapsed: 9.53s
01/23/2023 04:50:30 PM  [*] Mon Jan 23 16:50:30 2023: Train Epoch: 3 [33600/38063 (88%)]	Loss: 0.273367 | FPR 0.001 -- TPR 0.8941 | F1 0.9381 | Elapsed: 9.42s
01/23/2023 04:50:39 PM  [*] Mon Jan 23 16:50:39 2023: Train Epoch: 3 [35200/38063 (92%)]	Loss: 0.167837 | FPR 0.001 -- TPR 0.9500 | F1 0.9720 | Elapsed: 9.15s
01/23/2023 04:50:48 PM  [*] Mon Jan 23 16:50:48 2023: Train Epoch: 3 [36800/38063 (97%)]	Loss: 0.413404 | FPR 0.001 -- TPR 0.9270 | F1 0.9565 | Elapsed: 9.08s
01/23/2023 04:50:55 PM  [*] Mon Jan 23 16:50:55 2023:    3    | Tr.loss: 0.183361 | FPR 0.001 -- TPR: 0.92 |  F1: 0.95 | Elapsed:  223.83  s
01/23/2023 04:50:55 PM [!] Mon Jan 23 16:50:55 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\crossValidation\Transformer_512_BPE\nLayers\trainingFiles\trainingFiles_1674489055-model.torch
                losses    : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\crossValidation\Transformer_512_BPE\nLayers\trainingFiles\trainingFiles_1674489055-train_losses.npy
                duration  : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\crossValidation\Transformer_512_BPE\nLayers\trainingFiles\trainingFiles_1674489055-trainTime.npy
		train F1s : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\crossValidation\Transformer_512_BPE\nLayers\trainingFiles\trainingFiles_1674489055-trainF1s.npy
		train TPRs: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\crossValidation\Transformer_512_BPE\nLayers\trainingFiles\trainingFiles_1674489055-trainTPRs.npy
01/23/2023 04:50:55 PM  [!] Evaluating model on validation set...
01/23/2023 04:50:55 PM  [*] Predicting batch: 0/2379
01/23/2023 04:50:57 PM  [*] Predicting batch: 100/2379
01/23/2023 04:50:58 PM  [*] Predicting batch: 200/2379
01/23/2023 04:51:00 PM  [*] Predicting batch: 300/2379
01/23/2023 04:51:01 PM  [*] Predicting batch: 400/2379
01/23/2023 04:51:03 PM  [*] Predicting batch: 500/2379
01/23/2023 04:51:04 PM  [*] Predicting batch: 600/2379
01/23/2023 04:51:06 PM  [*] Predicting batch: 700/2379
01/23/2023 04:51:07 PM  [*] Predicting batch: 800/2379
01/23/2023 04:51:09 PM  [*] Predicting batch: 900/2379
01/23/2023 04:51:10 PM  [*] Predicting batch: 1000/2379
01/23/2023 04:51:11 PM  [*] Predicting batch: 1100/2379
01/23/2023 04:51:13 PM  [*] Predicting batch: 1200/2379
01/23/2023 04:51:14 PM  [*] Predicting batch: 1300/2379
01/23/2023 04:51:16 PM  [*] Predicting batch: 1400/2379
01/23/2023 04:51:17 PM  [*] Predicting batch: 1500/2379
01/23/2023 04:51:19 PM  [*] Predicting batch: 1600/2379
01/23/2023 04:51:20 PM  [*] Predicting batch: 1700/2379
01/23/2023 04:51:22 PM  [*] Predicting batch: 1800/2379
01/23/2023 04:51:23 PM  [*] Predicting batch: 1900/2379
01/23/2023 04:51:25 PM  [*] Predicting batch: 2000/2379
01/23/2023 04:51:26 PM  [*] Predicting batch: 2100/2379
01/23/2023 04:51:28 PM  [*] Predicting batch: 2200/2379
01/23/2023 04:51:29 PM  [*] Predicting batch: 2300/2379
01/23/2023 04:51:30 PM  [!] This fold metrics on validation set:
01/23/2023 04:51:31 PM  [!] FPR: 0.0001 | TPR: 0.3606334665993867 | F1: 0.5300813008130082
01/23/2023 04:51:31 PM  [!] FPR: 0.0003 | TPR: 0.4747894266972014 | F1: 0.6438233591241644
01/23/2023 04:51:31 PM  [!] FPR: 0.001 | TPR: 0.6150293055932927 | F1: 0.7614127823161941
01/23/2023 04:51:31 PM  [!] FPR: 0.003 | TPR: 0.6966191825486162 | F1: 0.8205093037077676
01/23/2023 04:51:31 PM  [!] FPR: 0.01 | TPR: 0.786554360905174 | F1: 0.8781798483206934
01/23/2023 04:51:31 PM  [!] FPR: 0.03 | TPR: 0.8792066141365524 | F1: 0.9286431748764938
01/23/2023 04:51:31 PM  [!] FPR: 0.1 | TPR: 0.9459302099910725 | F1: 0.9489505860363693
01/23/2023 04:51:31 PM  [!] Fold 2/2 | Train set size: 38063, Validation set size: 38063
01/23/2023 04:51:31 PM  [*] Started epoch: 1
01/23/2023 04:51:31 PM  [*] Mon Jan 23 16:51:31 2023: Train Epoch: 1 [  0  /38063 (0 %)]	Loss: 1.707710 | FPR 0.001 -- TPR 0.0909 | F1 0.1667 | Elapsed: 0.11s
01/23/2023 04:51:41 PM  [*] Mon Jan 23 16:51:41 2023: Train Epoch: 1 [1600 /38063 (4 %)]	Loss: 0.663401 | FPR 0.001 -- TPR 0.3179 | F1 0.4282 | Elapsed: 9.43s
01/23/2023 04:51:50 PM  [*] Mon Jan 23 16:51:50 2023: Train Epoch: 1 [3200 /38063 (8 %)]	Loss: 0.602587 | FPR 0.001 -- TPR 0.3922 | F1 0.5109 | Elapsed: 9.08s
01/23/2023 04:51:59 PM  [*] Mon Jan 23 16:51:59 2023: Train Epoch: 1 [4800 /38063 (13%)]	Loss: 0.252680 | FPR 0.001 -- TPR 0.5402 | F1 0.6454 | Elapsed: 9.07s
01/23/2023 04:52:08 PM  [*] Mon Jan 23 16:52:08 2023: Train Epoch: 1 [6400 /38063 (17%)]	Loss: 0.304495 | FPR 0.001 -- TPR 0.5998 | F1 0.7201 | Elapsed: 9.27s
01/23/2023 04:52:17 PM  [*] Mon Jan 23 16:52:17 2023: Train Epoch: 1 [8000 /38063 (21%)]	Loss: 0.216610 | FPR 0.001 -- TPR 0.6629 | F1 0.7676 | Elapsed: 9.24s
01/23/2023 04:52:27 PM  [*] Mon Jan 23 16:52:27 2023: Train Epoch: 1 [9600 /38063 (25%)]	Loss: 0.352654 | FPR 0.001 -- TPR 0.6351 | F1 0.7457 | Elapsed: 9.14s
01/23/2023 04:52:36 PM  [*] Mon Jan 23 16:52:36 2023: Train Epoch: 1 [11200/38063 (29%)]	Loss: 0.366000 | FPR 0.001 -- TPR 0.7017 | F1 0.8003 | Elapsed: 9.42s
01/23/2023 04:52:46 PM  [*] Mon Jan 23 16:52:46 2023: Train Epoch: 1 [12800/38063 (34%)]	Loss: 0.166402 | FPR 0.001 -- TPR 0.7599 | F1 0.8355 | Elapsed: 10.44s
01/23/2023 04:52:56 PM  [*] Mon Jan 23 16:52:56 2023: Train Epoch: 1 [14400/38063 (38%)]	Loss: 0.526817 | FPR 0.001 -- TPR 0.7307 | F1 0.8198 | Elapsed: 9.89s
01/23/2023 04:53:06 PM  [*] Mon Jan 23 16:53:06 2023: Train Epoch: 1 [16000/38063 (42%)]	Loss: 0.298719 | FPR 0.001 -- TPR 0.8037 | F1 0.8755 | Elapsed: 9.84s
01/23/2023 04:53:16 PM  [*] Mon Jan 23 16:53:16 2023: Train Epoch: 1 [17600/38063 (46%)]	Loss: 0.462382 | FPR 0.001 -- TPR 0.7835 | F1 0.8615 | Elapsed: 10.33s
01/23/2023 04:53:26 PM  [*] Mon Jan 23 16:53:26 2023: Train Epoch: 1 [19200/38063 (50%)]	Loss: 0.102140 | FPR 0.001 -- TPR 0.8175 | F1 0.8897 | Elapsed: 9.79s
01/23/2023 04:53:36 PM  [*] Mon Jan 23 16:53:36 2023: Train Epoch: 1 [20800/38063 (55%)]	Loss: 0.171337 | FPR 0.001 -- TPR 0.8130 | F1 0.8813 | Elapsed: 9.90s
01/23/2023 04:53:46 PM  [*] Mon Jan 23 16:53:46 2023: Train Epoch: 1 [22400/38063 (59%)]	Loss: 0.115595 | FPR 0.001 -- TPR 0.8495 | F1 0.9074 | Elapsed: 9.42s
01/23/2023 04:53:55 PM  [*] Mon Jan 23 16:53:55 2023: Train Epoch: 1 [24000/38063 (63%)]	Loss: 0.236821 | FPR 0.001 -- TPR 0.8222 | F1 0.8891 | Elapsed: 9.01s
01/23/2023 04:54:04 PM  [*] Mon Jan 23 16:54:04 2023: Train Epoch: 1 [25600/38063 (67%)]	Loss: 0.207859 | FPR 0.001 -- TPR 0.8270 | F1 0.8926 | Elapsed: 8.98s
01/23/2023 04:54:12 PM  [*] Mon Jan 23 16:54:12 2023: Train Epoch: 1 [27200/38063 (71%)]	Loss: 0.195180 | FPR 0.001 -- TPR 0.8637 | F1 0.9146 | Elapsed: 8.86s
01/23/2023 04:54:22 PM  [*] Mon Jan 23 16:54:22 2023: Train Epoch: 1 [28800/38063 (76%)]	Loss: 0.158256 | FPR 0.001 -- TPR 0.8499 | F1 0.9034 | Elapsed: 9.38s
01/23/2023 04:54:32 PM  [*] Mon Jan 23 16:54:32 2023: Train Epoch: 1 [30400/38063 (80%)]	Loss: 0.607749 | FPR 0.001 -- TPR 0.8789 | F1 0.9191 | Elapsed: 10.12s
01/23/2023 04:54:42 PM [!] Learning rate: 2.5e-05
01/23/2023 04:54:42 PM  [*] Mon Jan 23 16:54:42 2023: Train Epoch: 1 [32000/38063 (84%)]	Loss: 0.037007 | FPR 0.001 -- TPR 0.8478 | F1 0.8936 | Elapsed: 9.85s
01/23/2023 04:54:52 PM  [*] Mon Jan 23 16:54:52 2023: Train Epoch: 1 [33600/38063 (88%)]	Loss: 0.165251 | FPR 0.001 -- TPR 0.8896 | F1 0.9337 | Elapsed: 10.24s
01/23/2023 04:55:01 PM  [*] Mon Jan 23 16:55:01 2023: Train Epoch: 1 [35200/38063 (92%)]	Loss: 0.177281 | FPR 0.001 -- TPR 0.9057 | F1 0.9420 | Elapsed: 9.40s
01/23/2023 04:55:11 PM  [*] Mon Jan 23 16:55:11 2023: Train Epoch: 1 [36800/38063 (97%)]	Loss: 0.294696 | FPR 0.001 -- TPR 0.9182 | F1 0.9527 | Elapsed: 9.63s
01/23/2023 04:55:19 PM  [*] Mon Jan 23 16:55:19 2023:    1    | Tr.loss: 0.331529 | FPR 0.001 -- TPR: 0.75 |  F1: 0.83 | Elapsed:  227.82  s
01/23/2023 04:55:19 PM  [*] Started epoch: 2
01/23/2023 04:55:19 PM  [*] Mon Jan 23 16:55:19 2023: Train Epoch: 2 [  0  /38063 (0 %)]	Loss: 0.111215 | FPR 0.001 -- TPR 1.0000 | F1 1.0000 | Elapsed: 0.13s
01/23/2023 04:55:29 PM  [*] Mon Jan 23 16:55:29 2023: Train Epoch: 2 [1600 /38063 (4 %)]	Loss: 0.186248 | FPR 0.001 -- TPR 0.9230 | F1 0.9456 | Elapsed: 9.76s
01/23/2023 04:55:39 PM  [*] Mon Jan 23 16:55:39 2023: Train Epoch: 2 [3200 /38063 (8 %)]	Loss: 0.312095 | FPR 0.001 -- TPR 0.9299 | F1 0.9585 | Elapsed: 9.86s
01/23/2023 04:55:48 PM  [*] Mon Jan 23 16:55:48 2023: Train Epoch: 2 [4800 /38063 (13%)]	Loss: 0.360038 | FPR 0.001 -- TPR 0.9079 | F1 0.9461 | Elapsed: 9.50s
01/23/2023 04:55:58 PM  [*] Mon Jan 23 16:55:58 2023: Train Epoch: 2 [6400 /38063 (17%)]	Loss: 0.246598 | FPR 0.001 -- TPR 0.8958 | F1 0.9193 | Elapsed: 9.73s
01/23/2023 04:56:08 PM  [*] Mon Jan 23 16:56:08 2023: Train Epoch: 2 [8000 /38063 (21%)]	Loss: 0.122323 | FPR 0.001 -- TPR 0.9245 | F1 0.9572 | Elapsed: 9.82s
01/23/2023 04:56:18 PM  [*] Mon Jan 23 16:56:18 2023: Train Epoch: 2 [9600 /38063 (25%)]	Loss: 0.284465 | FPR 0.001 -- TPR 0.9305 | F1 0.9600 | Elapsed: 10.02s
01/23/2023 04:56:27 PM  [*] Mon Jan 23 16:56:27 2023: Train Epoch: 2 [11200/38063 (29%)]	Loss: 0.142197 | FPR 0.001 -- TPR 0.9203 | F1 0.9308 | Elapsed: 9.59s
01/23/2023 04:56:37 PM  [*] Mon Jan 23 16:56:37 2023: Train Epoch: 2 [12800/38063 (34%)]	Loss: 0.135873 | FPR 0.001 -- TPR 0.9301 | F1 0.9603 | Elapsed: 9.56s
01/23/2023 04:56:47 PM  [*] Mon Jan 23 16:56:47 2023: Train Epoch: 2 [14400/38063 (38%)]	Loss: 0.144001 | FPR 0.001 -- TPR 0.8919 | F1 0.9367 | Elapsed: 9.74s
01/23/2023 04:56:56 PM  [*] Mon Jan 23 16:56:56 2023: Train Epoch: 2 [16000/38063 (42%)]	Loss: 0.197558 | FPR 0.001 -- TPR 0.9164 | F1 0.9521 | Elapsed: 9.13s
01/23/2023 04:57:05 PM  [*] Mon Jan 23 16:57:05 2023: Train Epoch: 2 [17600/38063 (46%)]	Loss: 0.127767 | FPR 0.001 -- TPR 0.9359 | F1 0.9533 | Elapsed: 9.61s
01/23/2023 04:57:15 PM  [*] Mon Jan 23 16:57:15 2023: Train Epoch: 2 [19200/38063 (50%)]	Loss: 0.118062 | FPR 0.001 -- TPR 0.9445 | F1 0.9693 | Elapsed: 9.84s
01/23/2023 04:57:25 PM  [*] Mon Jan 23 16:57:25 2023: Train Epoch: 2 [20800/38063 (55%)]	Loss: 0.125606 | FPR 0.001 -- TPR 0.9146 | F1 0.9504 | Elapsed: 9.32s
01/23/2023 04:57:34 PM  [*] Mon Jan 23 16:57:34 2023: Train Epoch: 2 [22400/38063 (59%)]	Loss: 0.107986 | FPR 0.001 -- TPR 0.9263 | F1 0.9575 | Elapsed: 9.85s
01/23/2023 04:57:40 PM  [*] Mon Jan 23 16:57:40 2023: Train Epoch: 2 [24000/38063 (63%)]	Loss: 0.098244 | FPR 0.001 -- TPR 0.9333 | F1 0.9619 | Elapsed: 5.41s
01/23/2023 04:57:45 PM  [*] Mon Jan 23 16:57:45 2023: Train Epoch: 2 [25600/38063 (67%)]	Loss: 0.253003 | FPR 0.001 -- TPR 0.9172 | F1 0.9425 | Elapsed: 5.04s
01/23/2023 04:57:46 PM [!] Learning rate: 2.5e-06
01/23/2023 04:57:50 PM  [*] Mon Jan 23 16:57:50 2023: Train Epoch: 2 [27200/38063 (71%)]	Loss: 0.022535 | FPR 0.001 -- TPR 0.9246 | F1 0.9572 | Elapsed: 4.75s
01/23/2023 04:57:54 PM  [*] Mon Jan 23 16:57:54 2023: Train Epoch: 2 [28800/38063 (76%)]	Loss: 0.037467 | FPR 0.001 -- TPR 0.9346 | F1 0.9629 | Elapsed: 4.77s
01/23/2023 04:57:59 PM  [*] Mon Jan 23 16:57:59 2023: Train Epoch: 2 [30400/38063 (80%)]	Loss: 0.117536 | FPR 0.001 -- TPR 0.9284 | F1 0.9597 | Elapsed: 4.76s
01/23/2023 04:58:04 PM  [*] Mon Jan 23 16:58:04 2023: Train Epoch: 2 [32000/38063 (84%)]	Loss: 0.169108 | FPR 0.001 -- TPR 0.9430 | F1 0.9681 | Elapsed: 5.07s
01/23/2023 04:58:09 PM  [*] Mon Jan 23 16:58:09 2023: Train Epoch: 2 [33600/38063 (88%)]	Loss: 0.259547 | FPR 0.001 -- TPR 0.9151 | F1 0.9400 | Elapsed: 4.89s
01/23/2023 04:58:14 PM  [*] Mon Jan 23 16:58:14 2023: Train Epoch: 2 [35200/38063 (92%)]	Loss: 0.048808 | FPR 0.001 -- TPR 0.9287 | F1 0.9586 | Elapsed: 4.77s
01/23/2023 04:58:19 PM  [*] Mon Jan 23 16:58:19 2023: Train Epoch: 2 [36800/38063 (97%)]	Loss: 0.252900 | FPR 0.001 -- TPR 0.9236 | F1 0.9552 | Elapsed: 4.70s
01/23/2023 04:58:22 PM  [*] Mon Jan 23 16:58:22 2023:    2    | Tr.loss: 0.177153 | FPR 0.001 -- TPR: 0.92 |  F1: 0.95 | Elapsed:  183.33  s
01/23/2023 04:58:22 PM  [*] Started epoch: 3
01/23/2023 04:58:22 PM  [*] Mon Jan 23 16:58:22 2023: Train Epoch: 3 [  0  /38063 (0 %)]	Loss: 0.486257 | FPR 0.001 -- TPR 0.8750 | F1 0.9333 | Elapsed: 0.06s
01/23/2023 04:58:27 PM  [*] Mon Jan 23 16:58:27 2023: Train Epoch: 3 [1600 /38063 (4 %)]	Loss: 0.195560 | FPR 0.001 -- TPR 0.9168 | F1 0.9429 | Elapsed: 4.75s
01/23/2023 04:58:32 PM  [*] Mon Jan 23 16:58:32 2023: Train Epoch: 3 [3200 /38063 (8 %)]	Loss: 0.147941 | FPR 0.001 -- TPR 0.9255 | F1 0.9575 | Elapsed: 4.75s
01/23/2023 04:58:37 PM  [*] Mon Jan 23 16:58:37 2023: Train Epoch: 3 [4800 /38063 (13%)]	Loss: 0.070282 | FPR 0.001 -- TPR 0.9364 | F1 0.9642 | Elapsed: 4.72s
01/23/2023 04:58:41 PM  [*] Mon Jan 23 16:58:41 2023: Train Epoch: 3 [6400 /38063 (17%)]	Loss: 0.162680 | FPR 0.001 -- TPR 0.9406 | F1 0.9671 | Elapsed: 4.72s
01/23/2023 04:58:46 PM  [*] Mon Jan 23 16:58:46 2023: Train Epoch: 3 [8000 /38063 (21%)]	Loss: 0.189412 | FPR 0.001 -- TPR 0.9377 | F1 0.9647 | Elapsed: 4.73s
01/23/2023 04:58:51 PM  [*] Mon Jan 23 16:58:51 2023: Train Epoch: 3 [9600 /38063 (25%)]	Loss: 0.125504 | FPR 0.001 -- TPR 0.9287 | F1 0.9594 | Elapsed: 4.75s
01/23/2023 04:58:56 PM  [*] Mon Jan 23 16:58:56 2023: Train Epoch: 3 [11200/38063 (29%)]	Loss: 0.077245 | FPR 0.001 -- TPR 0.9134 | F1 0.9496 | Elapsed: 4.93s
01/23/2023 04:59:00 PM  [*] Mon Jan 23 16:59:00 2023: Train Epoch: 3 [12800/38063 (34%)]	Loss: 0.095808 | FPR 0.001 -- TPR 0.9337 | F1 0.9627 | Elapsed: 4.71s
01/23/2023 04:59:05 PM  [*] Mon Jan 23 16:59:05 2023: Train Epoch: 3 [14400/38063 (38%)]	Loss: 0.068308 | FPR 0.001 -- TPR 0.9422 | F1 0.9671 | Elapsed: 4.71s
01/23/2023 04:59:10 PM  [*] Mon Jan 23 16:59:10 2023: Train Epoch: 3 [16000/38063 (42%)]	Loss: 0.178827 | FPR 0.001 -- TPR 0.9285 | F1 0.9584 | Elapsed: 4.72s
01/23/2023 04:59:15 PM  [*] Mon Jan 23 16:59:15 2023: Train Epoch: 3 [17600/38063 (46%)]	Loss: 0.108038 | FPR 0.001 -- TPR 0.9207 | F1 0.9532 | Elapsed: 4.70s
01/23/2023 04:59:19 PM  [*] Mon Jan 23 16:59:19 2023: Train Epoch: 3 [19200/38063 (50%)]	Loss: 0.173213 | FPR 0.001 -- TPR 0.9347 | F1 0.9636 | Elapsed: 4.68s
01/23/2023 04:59:21 PM [!] Learning rate: 2.5000000000000004e-07
01/23/2023 04:59:24 PM  [*] Mon Jan 23 16:59:24 2023: Train Epoch: 3 [20800/38063 (55%)]	Loss: 0.142701 | FPR 0.001 -- TPR 0.9346 | F1 0.9626 | Elapsed: 4.73s
01/23/2023 04:59:29 PM  [*] Mon Jan 23 16:59:29 2023: Train Epoch: 3 [22400/38063 (59%)]	Loss: 0.174000 | FPR 0.001 -- TPR 0.9315 | F1 0.9583 | Elapsed: 4.74s
01/23/2023 04:59:33 PM  [*] Mon Jan 23 16:59:33 2023: Train Epoch: 3 [24000/38063 (63%)]	Loss: 0.277366 | FPR 0.001 -- TPR 0.9141 | F1 0.9368 | Elapsed: 4.71s
01/23/2023 04:59:38 PM  [*] Mon Jan 23 16:59:38 2023: Train Epoch: 3 [25600/38063 (67%)]	Loss: 0.226136 | FPR 0.001 -- TPR 0.9407 | F1 0.9649 | Elapsed: 4.81s
01/23/2023 04:59:43 PM  [*] Mon Jan 23 16:59:43 2023: Train Epoch: 3 [27200/38063 (71%)]	Loss: 0.303202 | FPR 0.001 -- TPR 0.9295 | F1 0.9599 | Elapsed: 4.74s
01/23/2023 04:59:48 PM  [*] Mon Jan 23 16:59:48 2023: Train Epoch: 3 [28800/38063 (76%)]	Loss: 0.424037 | FPR 0.001 -- TPR 0.9320 | F1 0.9616 | Elapsed: 4.70s
01/23/2023 04:59:52 PM  [*] Mon Jan 23 16:59:52 2023: Train Epoch: 3 [30400/38063 (80%)]	Loss: 0.324796 | FPR 0.001 -- TPR 0.9139 | F1 0.9494 | Elapsed: 4.70s
01/23/2023 04:59:57 PM  [*] Mon Jan 23 16:59:57 2023: Train Epoch: 3 [32000/38063 (84%)]	Loss: 0.136034 | FPR 0.001 -- TPR 0.9320 | F1 0.9587 | Elapsed: 4.73s
01/23/2023 05:00:02 PM  [*] Mon Jan 23 17:00:02 2023: Train Epoch: 3 [33600/38063 (88%)]	Loss: 0.106579 | FPR 0.001 -- TPR 0.9335 | F1 0.9609 | Elapsed: 4.70s
01/23/2023 05:00:06 PM  [*] Mon Jan 23 17:00:06 2023: Train Epoch: 3 [35200/38063 (92%)]	Loss: 0.051741 | FPR 0.001 -- TPR 0.9389 | F1 0.9646 | Elapsed: 4.70s
01/23/2023 05:00:11 PM  [*] Mon Jan 23 17:00:11 2023: Train Epoch: 3 [36800/38063 (97%)]	Loss: 0.100924 | FPR 0.001 -- TPR 0.9405 | F1 0.9653 | Elapsed: 4.76s
01/23/2023 05:00:15 PM  [*] Mon Jan 23 17:00:15 2023:    3    | Tr.loss: 0.168212 | FPR 0.001 -- TPR: 0.93 |  F1: 0.96 | Elapsed:  112.68  s
01/23/2023 05:00:15 PM [!] Mon Jan 23 17:00:15 2023: Dumped results:
                model     : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\crossValidation\Transformer_512_BPE\nLayers\trainingFiles\trainingFiles_1674489615-model.torch
                losses    : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\crossValidation\Transformer_512_BPE\nLayers\trainingFiles\trainingFiles_1674489615-train_losses.npy
                duration  : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\crossValidation\Transformer_512_BPE\nLayers\trainingFiles\trainingFiles_1674489615-trainTime.npy
		train F1s : C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\crossValidation\Transformer_512_BPE\nLayers\trainingFiles\trainingFiles_1674489615-trainF1s.npy
		train TPRs: C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\crossValidation\Transformer_512_BPE\nLayers\trainingFiles\trainingFiles_1674489615-trainTPRs.npy
01/23/2023 05:00:15 PM  [!] Evaluating model on validation set...
01/23/2023 05:00:15 PM  [*] Predicting batch: 0/2379
01/23/2023 05:00:16 PM  [*] Predicting batch: 100/2379
01/23/2023 05:00:17 PM  [*] Predicting batch: 200/2379
01/23/2023 05:00:18 PM  [*] Predicting batch: 300/2379
01/23/2023 05:00:19 PM  [*] Predicting batch: 400/2379
01/23/2023 05:00:20 PM  [*] Predicting batch: 500/2379
01/23/2023 05:00:21 PM  [*] Predicting batch: 600/2379
01/23/2023 05:00:22 PM  [*] Predicting batch: 700/2379
01/23/2023 05:00:23 PM  [*] Predicting batch: 800/2379
01/23/2023 05:00:24 PM  [*] Predicting batch: 900/2379
01/23/2023 05:00:25 PM  [*] Predicting batch: 1000/2379
01/23/2023 05:00:26 PM  [*] Predicting batch: 1100/2379
01/23/2023 05:00:27 PM  [*] Predicting batch: 1200/2379
01/23/2023 05:00:28 PM  [*] Predicting batch: 1300/2379
01/23/2023 05:00:29 PM  [*] Predicting batch: 1400/2379
01/23/2023 05:00:30 PM  [*] Predicting batch: 1500/2379
01/23/2023 05:00:31 PM  [*] Predicting batch: 1600/2379
01/23/2023 05:00:32 PM  [*] Predicting batch: 1700/2379
01/23/2023 05:00:33 PM  [*] Predicting batch: 1800/2379
01/23/2023 05:00:34 PM  [*] Predicting batch: 1900/2379
01/23/2023 05:00:35 PM  [*] Predicting batch: 2000/2379
01/23/2023 05:00:37 PM  [*] Predicting batch: 2100/2379
01/23/2023 05:00:38 PM  [*] Predicting batch: 2200/2379
01/23/2023 05:00:39 PM  [*] Predicting batch: 2300/2379
01/23/2023 05:00:40 PM  [!] This fold metrics on validation set:
01/23/2023 05:00:40 PM  [!] FPR: 0.0001 | TPR: 0.3983417026742964 | F1: 0.5697185647078473
01/23/2023 05:00:40 PM  [!] FPR: 0.0003 | TPR: 0.5903694188173927 | F1: 0.7423760340692153
01/23/2023 05:00:40 PM  [!] FPR: 0.001 | TPR: 0.6419479154501927 | F1: 0.781712172923777
01/23/2023 05:00:40 PM  [!] FPR: 0.003 | TPR: 0.7184008719685469 | F1: 0.8354269935039949
01/23/2023 05:00:40 PM  [!] FPR: 0.01 | TPR: 0.8206625403869361 | F1: 0.8991533917642293
01/23/2023 05:00:40 PM  [!] FPR: 0.03 | TPR: 0.8922496009965355 | F1: 0.9359139258079664
01/23/2023 05:00:40 PM  [!] FPR: 0.1 | TPR: 0.9526645645996341 | F1: 0.9522938635744582
01/23/2023 05:00:41 PM  [!] Metrics saved to C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\crossValidation\Transformer_512_BPE\nLayers\metrics_trainSize_76126_ep_3_cv_2_vocabSize_50000_maxLen_512_dModel_64_nHeads_8_dHidden_256_nLayers_4_numClasses_1_hiddenNeurons_64_layerNorm_False_dropout_0.3.json
01/23/2023 05:00:41 PM  [!] Average epoch time: 199.61s | Mean values over 2 folds:
	FPR: 0.0001 -- TPR: 0.3795 -- F1: 0.5499
	FPR: 0.0003 -- TPR: 0.5326 -- F1: 0.6931
	FPR:  0.001 -- TPR: 0.6285 -- F1: 0.7716
	FPR:  0.003 -- TPR: 0.7075 -- F1: 0.8280
	FPR:   0.01 -- TPR: 0.8036 -- F1: 0.8887
	FPR:   0.03 -- TPR: 0.8857 -- F1: 0.9323
	FPR:    0.1 -- TPR: 0.9493 -- F1: 0.9506

01/23/2023 05:01:11 PM  [!] Using device: cuda:0 | Dataset size: 76126
01/23/2023 05:01:11 PM  [!] Epochs per fold: 3 | Model config: {'vocabSize': 50000, 'maxLen': 512, 'dModel': 64, 'nHeads': 8, 'dHidden': 256, 'nLayers': 8, 'numClasses': 1, 'hiddenNeurons': [64], 'layerNorm': False, 'dropout': 0.3}
01/23/2023 05:01:11 PM  [!] Fold 1/2 | Train set size: 38063, Validation set size: 38063
