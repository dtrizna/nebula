2023-03-16 14:45:55,145 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_backdoor
2023-03-16 14:46:01,102 WARNING Finished... Took: 5.96s
2023-03-16 14:46:01,103 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_clean
2023-03-16 14:46:02,968 WARNING Finished... Took: 1.87s
2023-03-16 14:46:02,968 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_coinminer
2023-03-16 14:46:04,716 WARNING Finished... Took: 1.75s
2023-03-16 14:46:04,716 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_dropper
2023-03-16 14:46:06,076 WARNING Finished... Took: 1.36s
2023-03-16 14:46:06,076 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_keylogger
2023-03-16 14:46:07,404 WARNING Finished... Took: 1.33s
2023-03-16 14:46:07,405 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_ransomware
2023-03-16 14:46:09,868 WARNING Finished... Took: 2.46s
2023-03-16 14:46:09,869 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_rat
2023-03-16 14:46:10,957 WARNING Finished... Took: 1.09s
2023-03-16 14:46:10,958 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_trojan
2023-03-16 14:46:12,964 WARNING Finished... Took: 2.01s
2023-03-16 14:46:12,964 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_windows_syswow64
2023-03-16 14:46:13,558 WARNING Finished... Took: 0.59s
2023-03-16 14:46:13,559 WARNING  [!] Saved Y as out_tokenizer_1678974355\nebula_whitespace_vocab_5000_seqlen_512\y_train_50.npy
2023-03-16 14:46:13,563 WARNING  [!] Saved Y names as out_tokenizer_1678974355\nebula_whitespace_vocab_5000_seqlen_512\y_names_train_50.json
2023-03-16 14:46:13,564 WARNING  [*] Initializing tokenizer training...
2023-03-16 14:46:14,071 WARNING  [*] Encoding and padding...
2023-03-16 14:46:14,594 WARNING  [!] Saved X as out_tokenizer_1678974355\nebula_whitespace_vocab_5000_seqlen_512\x_train_50.npy
2023-03-16 14:46:14,606 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_backdoor
2023-03-16 14:46:17,082 WARNING Finished... Took: 2.48s
2023-03-16 14:46:17,083 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_clean
2023-03-16 14:46:18,163 WARNING Finished... Took: 1.08s
2023-03-16 14:46:18,163 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_coinminer
2023-03-16 14:46:20,357 WARNING Finished... Took: 2.19s
2023-03-16 14:46:20,358 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_dropper
2023-03-16 14:46:20,529 WARNING Finished... Took: 0.17s
2023-03-16 14:46:20,529 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_keylogger
2023-03-16 14:46:20,789 WARNING Finished... Took: 0.26s
2023-03-16 14:46:20,789 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_ransomware
2023-03-16 14:46:31,489 WARNING Finished... Took: 10.70s
2023-03-16 14:46:31,489 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_rat
2023-03-16 14:46:32,418 WARNING Finished... Took: 0.93s
2023-03-16 14:46:32,418 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_trojan
2023-03-16 14:46:32,924 WARNING Finished... Took: 0.51s
2023-03-16 14:46:32,924 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_windows_syswow64
2023-03-16 14:46:33,486 WARNING Finished... Took: 0.56s
2023-03-16 14:46:33,487 WARNING  [!] Saved Y as out_tokenizer_1678974355\nebula_whitespace_vocab_5000_seqlen_512\y_test_50.npy
2023-03-16 14:46:33,491 WARNING  [!] Saved Y names as out_tokenizer_1678974355\nebula_whitespace_vocab_5000_seqlen_512\y_names_test_50.json
2023-03-16 14:46:33,494 WARNING  [*] Encoding and padding...
2023-03-16 14:46:33,935 WARNING  [!] Saved X as out_tokenizer_1678974355\nebula_whitespace_vocab_5000_seqlen_512\x_test_50.npy
2023-03-16 14:46:33,945 WARNING  [!!!] Starting CV over whitespace!
2023-03-16 14:46:33,954 WARNING  [!] Training time budget: 3min
2023-03-16 14:46:33,954 WARNING  [!] Model config: {'vocab_size': 5000, 'maxlen': 512, 'chunk_size': 64, 'dModel': 64, 'nHeads': 8, 'dHidden': 256, 'nLayers': 2, 'numClasses': 1, 'hiddenNeurons': [64], 'layerNorm': False, 'dropout': 0.3, 'mean_over_sequence': False, 'norm_first': True}
2023-03-16 14:46:33,956 WARNING  [1/3] Train set size: 33, Validation set size: 17
2023-03-16 14:46:33,961 WARNING  [!] Saved dataset splits to dataset_splits_1678974393.npz
2023-03-16 14:46:34,129 WARNING  [!] Iniatialized TransformerEncoderChunks. Total trainable parameters: 2.5172e6
2023-03-16 14:46:34,131 WARNING  [*] Training time budget set: 0.05 min
2023-03-16 14:46:34,133 WARNING  [*] Started epoch: 1
2023-03-16 14:46:36,179 WARNING  [*] 14:46:36: Train Epoch: 1 [  0  / 33   (0 %)] | Loss: 1.795173 | Elapsed: 2.03s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.4308
2023-03-16 14:46:36,195 WARNING  [*] Thu Mar 16 14:46:36 2023:    1    | Tr.loss: 1.795173 | Elapsed:   2.06   s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.4308
2023-03-16 14:46:36,196 WARNING  [*] Started epoch: 2
2023-03-16 14:46:36,279 WARNING  [*] 14:46:36: Train Epoch: 2 [  0  / 33   (0 %)] | Loss: 2.384584 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0500 & F1 0.0952 | AUC 0.4923
2023-03-16 14:46:36,293 WARNING  [*] Thu Mar 16 14:46:36 2023:    2    | Tr.loss: 2.384584 | Elapsed:   0.10   s | FPR 0.0003 -> TPR: 0.05 & F1: 0.10 | AUC: 0.4923
2023-03-16 14:46:36,295 WARNING  [*] Started epoch: 3
2023-03-16 14:46:36,376 WARNING  [*] 14:46:36: Train Epoch: 3 [  0  / 33   (0 %)] | Loss: 1.295975 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.1500 & F1 0.2609 | AUC 0.6269
2023-03-16 14:46:36,392 WARNING  [*] Thu Mar 16 14:46:36 2023:    3    | Tr.loss: 1.295975 | Elapsed:   0.10   s | FPR 0.0003 -> TPR: 0.15 & F1: 0.26 | AUC: 0.6269
2023-03-16 14:46:36,393 WARNING  [*] Started epoch: 4
2023-03-16 14:46:36,477 WARNING  [*] 14:46:36: Train Epoch: 4 [  0  / 33   (0 %)] | Loss: 1.760019 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.1500 & F1 0.2609 | AUC 0.6077
2023-03-16 14:46:36,491 WARNING  [*] Thu Mar 16 14:46:36 2023:    4    | Tr.loss: 1.760019 | Elapsed:   0.10   s | FPR 0.0003 -> TPR: 0.15 & F1: 0.26 | AUC: 0.6077
2023-03-16 14:46:36,492 WARNING  [*] Started epoch: 5
2023-03-16 14:46:36,575 WARNING  [*] 14:46:36: Train Epoch: 5 [  0  / 33   (0 %)] | Loss: 0.964446 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.1500 & F1 0.2609 | AUC 0.7615
2023-03-16 14:46:36,588 WARNING  [*] Thu Mar 16 14:46:36 2023:    5    | Tr.loss: 0.964446 | Elapsed:   0.10   s | FPR 0.0003 -> TPR: 0.15 & F1: 0.26 | AUC: 0.7615
2023-03-16 14:46:36,590 WARNING  [*] Started epoch: 6
2023-03-16 14:46:36,676 WARNING  [*] 14:46:36: Train Epoch: 6 [  0  / 33   (0 %)] | Loss: 0.527705 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.7500 & F1 0.8571 | AUC 0.8923
2023-03-16 14:46:36,689 WARNING  [*] Thu Mar 16 14:46:36 2023:    6    | Tr.loss: 0.527705 | Elapsed:   0.10   s | FPR 0.0003 -> TPR: 0.75 & F1: 0.86 | AUC: 0.8923
2023-03-16 14:46:36,691 WARNING  [*] Started epoch: 7
2023-03-16 14:46:36,775 WARNING  [*] 14:46:36: Train Epoch: 7 [  0  / 33   (0 %)] | Loss: 1.189596 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.1500 & F1 0.2609 | AUC 0.6885
2023-03-16 14:46:36,789 WARNING  [*] Thu Mar 16 14:46:36 2023:    7    | Tr.loss: 1.189596 | Elapsed:   0.10   s | FPR 0.0003 -> TPR: 0.15 & F1: 0.26 | AUC: 0.6885
2023-03-16 14:46:36,789 WARNING  [*] Started epoch: 8
2023-03-16 14:46:36,885 WARNING  [*] 14:46:36: Train Epoch: 8 [  0  / 33   (0 %)] | Loss: 0.753932 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.2000 & F1 0.3333 | AUC 0.7731
2023-03-16 14:46:36,901 WARNING  [*] Thu Mar 16 14:46:36 2023:    8    | Tr.loss: 0.753932 | Elapsed:   0.11   s | FPR 0.0003 -> TPR: 0.20 & F1: 0.33 | AUC: 0.7731
2023-03-16 14:46:36,902 WARNING  [*] Started epoch: 9
2023-03-16 14:46:37,001 WARNING  [*] 14:46:37: Train Epoch: 9 [  0  / 33   (0 %)] | Loss: 1.717278 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.4000 & F1 0.5714 | AUC 0.6269
2023-03-16 14:46:37,018 WARNING  [*] Thu Mar 16 14:46:37 2023:    9    | Tr.loss: 1.717278 | Elapsed:   0.12   s | FPR 0.0003 -> TPR: 0.40 & F1: 0.57 | AUC: 0.6269
2023-03-16 14:46:37,019 WARNING  [*] Started epoch: 10
2023-03-16 14:46:37,126 WARNING  [*] 14:46:37: Train Epoch: 10 [  0  / 33   (0 %)] | Loss: 1.015258 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.3500 & F1 0.5185 | AUC 0.6923
2023-03-16 14:46:37,143 WARNING  [*] Thu Mar 16 14:46:37 2023:   10    | Tr.loss: 1.015258 | Elapsed:   0.12   s | FPR 0.0003 -> TPR: 0.35 & F1: 0.52 | AUC: 0.6923
2023-03-16 14:46:37,143 WARNING  [*] Started epoch: 11
2023-03-16 14:46:37,245 WARNING  [*] 14:46:37: Train Epoch: 11 [  0  / 33   (0 %)] | Loss: 0.748458 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.6000 & F1 0.7500 | AUC 0.7962
2023-03-16 14:46:37,246 WARNING  [!] Time budget exceeded, training stopped.
2023-03-16 14:46:37,282 WARNING  [!] Thu Mar 16 14:46:37 2023: Dumped results:
                model       : 1678974393-model.torch
		train time  : 1678974393-trainTime.npy
		train losses: 1678974393-trainLosses.npy
		train AUC   : 1678974393-auc.npy
		train F1s   : 1678974393-trainF1s.npy
		train TPRs  : 1678974393-trainTPRs.npy
2023-03-16 14:46:37,286 WARNING  [!] Evaluating model on training set...
2023-03-16 14:46:37,305 WARNING  [!] This fold metrics on training set:
2023-03-16 14:46:37,308 WARNING 	AUC: 0.9192
2023-03-16 14:46:37,312 WARNING 	FPR: 0.0001 | TPR: 0.5000 | F1: 0.6667
2023-03-16 14:46:37,316 WARNING 	FPR: 0.0003 | TPR: 0.5000 | F1: 0.6667
2023-03-16 14:46:37,319 WARNING 	FPR: 0.001 | TPR: 0.5000 | F1: 0.6667
2023-03-16 14:46:37,322 WARNING 	FPR: 0.003 | TPR: 0.5000 | F1: 0.6667
2023-03-16 14:46:37,329 WARNING 	FPR: 0.01 | TPR: 0.5000 | F1: 0.6667
2023-03-16 14:46:37,333 WARNING 	FPR: 0.03 | TPR: 0.5000 | F1: 0.6667
2023-03-16 14:46:37,337 WARNING 	FPR: 0.1 | TPR: 0.6500 | F1: 0.7647
2023-03-16 14:46:37,338 WARNING  [!] Evaluating model on validation set...
2023-03-16 14:46:37,357 WARNING  [!] This fold metrics on validation set:
2023-03-16 14:46:37,359 WARNING 	AUC: 0.7833
2023-03-16 14:46:37,364 WARNING 	FPR: 0.0001 | TPR: 0.3333 | F1: 0.5000
2023-03-16 14:46:37,367 WARNING 	FPR: 0.0003 | TPR: 0.3333 | F1: 0.5000
2023-03-16 14:46:37,370 WARNING 	FPR: 0.001 | TPR: 0.3333 | F1: 0.5000
2023-03-16 14:46:37,373 WARNING 	FPR: 0.003 | TPR: 0.3333 | F1: 0.5000
2023-03-16 14:46:37,377 WARNING 	FPR: 0.01 | TPR: 0.3333 | F1: 0.5000
2023-03-16 14:46:37,381 WARNING 	FPR: 0.03 | TPR: 0.3333 | F1: 0.5000
2023-03-16 14:46:37,384 WARNING 	FPR: 0.1 | TPR: 0.3333 | F1: 0.5000
2023-03-16 14:46:37,482 WARNING  [2/3] Train set size: 33, Validation set size: 17
2023-03-16 14:46:37,505 WARNING  [!] Saved dataset splits to dataset_splits_1678974397.npz
2023-03-16 14:46:37,557 WARNING  [!] Iniatialized TransformerEncoderChunks. Total trainable parameters: 2.5172e6
2023-03-16 14:46:37,558 WARNING  [*] Training time budget set: 0.05 min
2023-03-16 14:46:37,559 WARNING  [*] Started epoch: 1
2023-03-16 14:46:37,695 WARNING  [*] 14:46:37: Train Epoch: 1 [  0  / 33   (0 %)] | Loss: 1.256911 | Elapsed: 0.12s | FPR 0.0003 -> TPR 0.0500 & F1 0.0952 | AUC 0.7154
2023-03-16 14:46:37,717 WARNING  [*] Thu Mar 16 14:46:37 2023:    1    | Tr.loss: 1.256911 | Elapsed:   0.16   s | FPR 0.0003 -> TPR: 0.05 & F1: 0.10 | AUC: 0.7154
2023-03-16 14:46:37,718 WARNING  [*] Started epoch: 2
2023-03-16 14:46:37,820 WARNING  [*] 14:46:37: Train Epoch: 2 [  0  / 33   (0 %)] | Loss: 2.115052 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.2500 & F1 0.4000 | AUC 0.6808
2023-03-16 14:46:37,837 WARNING  [*] Thu Mar 16 14:46:37 2023:    2    | Tr.loss: 2.115052 | Elapsed:   0.12   s | FPR 0.0003 -> TPR: 0.25 & F1: 0.40 | AUC: 0.6808
2023-03-16 14:46:37,837 WARNING  [*] Started epoch: 3
2023-03-16 14:46:37,937 WARNING  [*] 14:46:37: Train Epoch: 3 [  0  / 33   (0 %)] | Loss: 1.638730 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.1500 & F1 0.2609 | AUC 0.7346
2023-03-16 14:46:37,954 WARNING  [*] Thu Mar 16 14:46:37 2023:    3    | Tr.loss: 1.638730 | Elapsed:   0.12   s | FPR 0.0003 -> TPR: 0.15 & F1: 0.26 | AUC: 0.7346
2023-03-16 14:46:37,954 WARNING  [*] Started epoch: 4
2023-03-16 14:46:38,050 WARNING  [*] 14:46:38: Train Epoch: 4 [  0  / 33   (0 %)] | Loss: 1.461277 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.2500 & F1 0.4000 | AUC 0.7077
2023-03-16 14:46:38,065 WARNING  [*] Thu Mar 16 14:46:38 2023:    4    | Tr.loss: 1.461277 | Elapsed:   0.11   s | FPR 0.0003 -> TPR: 0.25 & F1: 0.40 | AUC: 0.7077
2023-03-16 14:46:38,065 WARNING  [*] Started epoch: 5
2023-03-16 14:46:38,158 WARNING  [*] 14:46:38: Train Epoch: 5 [  0  / 33   (0 %)] | Loss: 1.397723 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.1500 & F1 0.2609 | AUC 0.6808
2023-03-16 14:46:38,175 WARNING  [*] Thu Mar 16 14:46:38 2023:    5    | Tr.loss: 1.397723 | Elapsed:   0.11   s | FPR 0.0003 -> TPR: 0.15 & F1: 0.26 | AUC: 0.6808
2023-03-16 14:46:38,175 WARNING  [*] Started epoch: 6
2023-03-16 14:46:38,259 WARNING  [*] 14:46:38: Train Epoch: 6 [  0  / 33   (0 %)] | Loss: 1.875752 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.1000 & F1 0.1818 | AUC 0.5615
2023-03-16 14:46:38,274 WARNING  [*] Thu Mar 16 14:46:38 2023:    6    | Tr.loss: 1.875752 | Elapsed:   0.10   s | FPR 0.0003 -> TPR: 0.10 & F1: 0.18 | AUC: 0.5615
2023-03-16 14:46:38,274 WARNING  [*] Started epoch: 7
2023-03-16 14:46:38,362 WARNING  [*] 14:46:38: Train Epoch: 7 [  0  / 33   (0 %)] | Loss: 1.006556 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.3000 & F1 0.4615 | AUC 0.7115
2023-03-16 14:46:38,378 WARNING  [*] Thu Mar 16 14:46:38 2023:    7    | Tr.loss: 1.006556 | Elapsed:   0.10   s | FPR 0.0003 -> TPR: 0.30 & F1: 0.46 | AUC: 0.7115
2023-03-16 14:46:38,378 WARNING  [*] Started epoch: 8
2023-03-16 14:46:38,473 WARNING  [*] 14:46:38: Train Epoch: 8 [  0  / 33   (0 %)] | Loss: 0.871333 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.3000 & F1 0.4615 | AUC 0.7962
2023-03-16 14:46:38,488 WARNING  [*] Thu Mar 16 14:46:38 2023:    8    | Tr.loss: 0.871333 | Elapsed:   0.11   s | FPR 0.0003 -> TPR: 0.30 & F1: 0.46 | AUC: 0.7962
2023-03-16 14:46:38,489 WARNING  [*] Started epoch: 9
2023-03-16 14:46:38,578 WARNING  [*] 14:46:38: Train Epoch: 9 [  0  / 33   (0 %)] | Loss: 0.818730 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.6000 & F1 0.7500 | AUC 0.7654
2023-03-16 14:46:38,592 WARNING  [*] Thu Mar 16 14:46:38 2023:    9    | Tr.loss: 0.818730 | Elapsed:   0.10   s | FPR 0.0003 -> TPR: 0.60 & F1: 0.75 | AUC: 0.7654
2023-03-16 14:46:38,593 WARNING  [*] Started epoch: 10
2023-03-16 14:46:38,676 WARNING  [*] 14:46:38: Train Epoch: 10 [  0  / 33   (0 %)] | Loss: 1.776065 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.1500 & F1 0.2609 | AUC 0.5462
2023-03-16 14:46:38,691 WARNING  [*] Thu Mar 16 14:46:38 2023:   10    | Tr.loss: 1.776065 | Elapsed:   0.10   s | FPR 0.0003 -> TPR: 0.15 & F1: 0.26 | AUC: 0.5462
2023-03-16 14:46:38,691 WARNING  [*] Started epoch: 11
2023-03-16 14:46:38,779 WARNING  [*] 14:46:38: Train Epoch: 11 [  0  / 33   (0 %)] | Loss: 1.051758 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.3500 & F1 0.5185 | AUC 0.7192
2023-03-16 14:46:38,793 WARNING  [*] Thu Mar 16 14:46:38 2023:   11    | Tr.loss: 1.051758 | Elapsed:   0.10   s | FPR 0.0003 -> TPR: 0.35 & F1: 0.52 | AUC: 0.7192
2023-03-16 14:46:38,794 WARNING  [*] Started epoch: 12
2023-03-16 14:46:38,881 WARNING  [*] 14:46:38: Train Epoch: 12 [  0  / 33   (0 %)] | Loss: 0.494477 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.5000 & F1 0.6667 | AUC 0.8692
2023-03-16 14:46:38,895 WARNING  [*] Thu Mar 16 14:46:38 2023:   12    | Tr.loss: 0.494477 | Elapsed:   0.10   s | FPR 0.0003 -> TPR: 0.50 & F1: 0.67 | AUC: 0.8692
2023-03-16 14:46:38,896 WARNING  [*] Started epoch: 13
2023-03-16 14:46:38,980 WARNING  [*] 14:46:38: Train Epoch: 13 [  0  / 33   (0 %)] | Loss: 0.300970 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.7500 & F1 0.8571 | AUC 0.9423
2023-03-16 14:46:38,994 WARNING  [*] Thu Mar 16 14:46:38 2023:   13    | Tr.loss: 0.300970 | Elapsed:   0.10   s | FPR 0.0003 -> TPR: 0.75 & F1: 0.86 | AUC: 0.9423
2023-03-16 14:46:38,995 WARNING  [*] Started epoch: 14
2023-03-16 14:46:39,080 WARNING  [*] 14:46:39: Train Epoch: 14 [  0  / 33   (0 %)] | Loss: 0.491320 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.1500 & F1 0.2609 | AUC 0.8846
2023-03-16 14:46:39,094 WARNING  [*] Thu Mar 16 14:46:39 2023:   14    | Tr.loss: 0.491320 | Elapsed:   0.10   s | FPR 0.0003 -> TPR: 0.15 & F1: 0.26 | AUC: 0.8846
2023-03-16 14:46:39,095 WARNING  [*] Started epoch: 15
2023-03-16 14:46:39,178 WARNING  [*] 14:46:39: Train Epoch: 15 [  0  / 33   (0 %)] | Loss: 0.498792 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.4000 & F1 0.5714 | AUC 0.8923
2023-03-16 14:46:39,193 WARNING  [*] Thu Mar 16 14:46:39 2023:   15    | Tr.loss: 0.498792 | Elapsed:   0.10   s | FPR 0.0003 -> TPR: 0.40 & F1: 0.57 | AUC: 0.8923
2023-03-16 14:46:39,194 WARNING  [*] Started epoch: 16
2023-03-16 14:46:39,274 WARNING  [*] 14:46:39: Train Epoch: 16 [  0  / 33   (0 %)] | Loss: 0.454310 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.3500 & F1 0.5185 | AUC 0.8846
2023-03-16 14:46:39,289 WARNING  [*] Thu Mar 16 14:46:39 2023:   16    | Tr.loss: 0.454310 | Elapsed:   0.09   s | FPR 0.0003 -> TPR: 0.35 & F1: 0.52 | AUC: 0.8846
2023-03-16 14:46:39,289 WARNING  [*] Started epoch: 17
2023-03-16 14:46:39,383 WARNING  [*] 14:46:39: Train Epoch: 17 [  0  / 33   (0 %)] | Loss: 0.289657 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.8000 & F1 0.8889 | AUC 0.9692
2023-03-16 14:46:39,398 WARNING  [*] Thu Mar 16 14:46:39 2023:   17    | Tr.loss: 0.289657 | Elapsed:   0.11   s | FPR 0.0003 -> TPR: 0.80 & F1: 0.89 | AUC: 0.9692
2023-03-16 14:46:39,399 WARNING  [*] Started epoch: 18
2023-03-16 14:46:39,493 WARNING  [*] 14:46:39: Train Epoch: 18 [  0  / 33   (0 %)] | Loss: 0.419071 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.7500 & F1 0.8571 | AUC 0.9192
2023-03-16 14:46:39,508 WARNING  [*] Thu Mar 16 14:46:39 2023:   18    | Tr.loss: 0.419071 | Elapsed:   0.11   s | FPR 0.0003 -> TPR: 0.75 & F1: 0.86 | AUC: 0.9192
2023-03-16 14:46:39,508 WARNING  [*] Started epoch: 19
2023-03-16 14:46:39,596 WARNING  [*] 14:46:39: Train Epoch: 19 [  0  / 33   (0 %)] | Loss: 0.412487 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.6500 & F1 0.7879 | AUC 0.9077
2023-03-16 14:46:39,611 WARNING  [*] Thu Mar 16 14:46:39 2023:   19    | Tr.loss: 0.412487 | Elapsed:   0.10   s | FPR 0.0003 -> TPR: 0.65 & F1: 0.79 | AUC: 0.9077
2023-03-16 14:46:39,612 WARNING  [*] Started epoch: 20
2023-03-16 14:46:39,699 WARNING  [*] 14:46:39: Train Epoch: 20 [  0  / 33   (0 %)] | Loss: 0.383880 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.8000 & F1 0.8889 | AUC 0.9346
2023-03-16 14:46:39,716 WARNING  [*] Thu Mar 16 14:46:39 2023:   20    | Tr.loss: 0.383880 | Elapsed:   0.10   s | FPR 0.0003 -> TPR: 0.80 & F1: 0.89 | AUC: 0.9346
2023-03-16 14:46:39,716 WARNING  [*] Started epoch: 21
2023-03-16 14:46:39,809 WARNING  [*] 14:46:39: Train Epoch: 21 [  0  / 33   (0 %)] | Loss: 0.387500 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.6500 & F1 0.7879 | AUC 0.9231
2023-03-16 14:46:39,825 WARNING  [*] Thu Mar 16 14:46:39 2023:   21    | Tr.loss: 0.387500 | Elapsed:   0.11   s | FPR 0.0003 -> TPR: 0.65 & F1: 0.79 | AUC: 0.9231
2023-03-16 14:46:39,825 WARNING  [*] Started epoch: 22
2023-03-16 14:46:39,924 WARNING  [*] 14:46:39: Train Epoch: 22 [  0  / 33   (0 %)] | Loss: 0.339732 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.6000 & F1 0.7500 | AUC 0.9231
2023-03-16 14:46:39,939 WARNING  [*] Thu Mar 16 14:46:39 2023:   22    | Tr.loss: 0.339732 | Elapsed:   0.11   s | FPR 0.0003 -> TPR: 0.60 & F1: 0.75 | AUC: 0.9231
2023-03-16 14:46:39,940 WARNING  [*] Started epoch: 23
2023-03-16 14:46:40,029 WARNING  [*] 14:46:40: Train Epoch: 23 [  0  / 33   (0 %)] | Loss: 0.441908 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.8000 & F1 0.8889 | AUC 0.9115
2023-03-16 14:46:40,046 WARNING  [*] Thu Mar 16 14:46:40 2023:   23    | Tr.loss: 0.441908 | Elapsed:   0.10   s | FPR 0.0003 -> TPR: 0.80 & F1: 0.89 | AUC: 0.9115
2023-03-16 14:46:40,046 WARNING  [*] Started epoch: 24
2023-03-16 14:46:40,135 WARNING  [*] 14:46:40: Train Epoch: 24 [  0  / 33   (0 %)] | Loss: 0.422277 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.7000 & F1 0.8235 | AUC 0.8923
2023-03-16 14:46:40,149 WARNING  [*] Thu Mar 16 14:46:40 2023:   24    | Tr.loss: 0.422277 | Elapsed:   0.10   s | FPR 0.0003 -> TPR: 0.70 & F1: 0.82 | AUC: 0.8923
2023-03-16 14:46:40,149 WARNING  [*] Started epoch: 25
2023-03-16 14:46:40,234 WARNING  [*] 14:46:40: Train Epoch: 25 [  0  / 33   (0 %)] | Loss: 0.311273 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.8500 & F1 0.9189 | AUC 0.9385
2023-03-16 14:46:40,249 WARNING  [*] Thu Mar 16 14:46:40 2023:   25    | Tr.loss: 0.311273 | Elapsed:   0.10   s | FPR 0.0003 -> TPR: 0.85 & F1: 0.92 | AUC: 0.9385
2023-03-16 14:46:40,250 WARNING  [*] Started epoch: 26
2023-03-16 14:46:40,335 WARNING  [*] 14:46:40: Train Epoch: 26 [  0  / 33   (0 %)] | Loss: 0.380553 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.7000 & F1 0.8235 | AUC 0.9192
2023-03-16 14:46:40,351 WARNING  [*] Thu Mar 16 14:46:40 2023:   26    | Tr.loss: 0.380553 | Elapsed:   0.10   s | FPR 0.0003 -> TPR: 0.70 & F1: 0.82 | AUC: 0.9192
2023-03-16 14:46:40,352 WARNING  [*] Started epoch: 27
2023-03-16 14:46:40,441 WARNING  [*] 14:46:40: Train Epoch: 27 [  0  / 33   (0 %)] | Loss: 0.353239 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.7500 & F1 0.8571 | AUC 0.9192
2023-03-16 14:46:40,458 WARNING  [*] Thu Mar 16 14:46:40 2023:   27    | Tr.loss: 0.353239 | Elapsed:   0.11   s | FPR 0.0003 -> TPR: 0.75 & F1: 0.86 | AUC: 0.9192
2023-03-16 14:46:40,459 WARNING  [*] Started epoch: 28
2023-03-16 14:46:40,554 WARNING  [*] 14:46:40: Train Epoch: 28 [  0  / 33   (0 %)] | Loss: 0.439477 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.7500 & F1 0.8571 | AUC 0.8885
2023-03-16 14:46:40,571 WARNING  [*] Thu Mar 16 14:46:40 2023:   28    | Tr.loss: 0.439477 | Elapsed:   0.11   s | FPR 0.0003 -> TPR: 0.75 & F1: 0.86 | AUC: 0.8885
2023-03-16 14:46:40,572 WARNING  [*] Started epoch: 29
2023-03-16 14:46:40,673 WARNING  [*] 14:46:40: Train Epoch: 29 [  0  / 33   (0 %)] | Loss: 0.286949 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.8500 & F1 0.9189 | AUC 0.9577
2023-03-16 14:46:40,681 WARNING  [!] Time budget exceeded, training stopped.
2023-03-16 14:46:40,724 WARNING  [!] Thu Mar 16 14:46:40 2023: Dumped results:
                model       : 1678974397-model.torch
		train time  : 1678974397-trainTime.npy
		train losses: 1678974397-trainLosses.npy
		train AUC   : 1678974397-auc.npy
		train F1s   : 1678974397-trainF1s.npy
		train TPRs  : 1678974397-trainTPRs.npy
2023-03-16 14:46:40,726 WARNING  [!] Evaluating model on training set...
2023-03-16 14:46:40,746 WARNING  [!] This fold metrics on training set:
2023-03-16 14:46:40,749 WARNING 	AUC: 0.9962
2023-03-16 14:46:40,752 WARNING 	FPR: 0.0001 | TPR: 0.9500 | F1: 0.9744
2023-03-16 14:46:40,756 WARNING 	FPR: 0.0003 | TPR: 0.9500 | F1: 0.9744
2023-03-16 14:46:40,760 WARNING 	FPR: 0.001 | TPR: 0.9500 | F1: 0.9744
2023-03-16 14:46:40,763 WARNING 	FPR: 0.003 | TPR: 0.9500 | F1: 0.9744
2023-03-16 14:46:40,766 WARNING 	FPR: 0.01 | TPR: 0.9500 | F1: 0.9744
2023-03-16 14:46:40,770 WARNING 	FPR: 0.03 | TPR: 0.9500 | F1: 0.9744
2023-03-16 14:46:40,773 WARNING 	FPR: 0.1 | TPR: 1.0000 | F1: 0.9756
2023-03-16 14:46:40,773 WARNING  [!] Evaluating model on validation set...
2023-03-16 14:46:40,795 WARNING  [!] This fold metrics on validation set:
2023-03-16 14:46:40,798 WARNING 	AUC: 0.9000
2023-03-16 14:46:40,801 WARNING 	FPR: 0.0001 | TPR: 0.7500 | F1: 0.8571
2023-03-16 14:46:40,804 WARNING 	FPR: 0.0003 | TPR: 0.7500 | F1: 0.8571
2023-03-16 14:46:40,807 WARNING 	FPR: 0.001 | TPR: 0.7500 | F1: 0.8571
2023-03-16 14:46:40,811 WARNING 	FPR: 0.003 | TPR: 0.7500 | F1: 0.8571
2023-03-16 14:46:40,814 WARNING 	FPR: 0.01 | TPR: 0.7500 | F1: 0.8571
2023-03-16 14:46:40,817 WARNING 	FPR: 0.03 | TPR: 0.7500 | F1: 0.8571
2023-03-16 14:46:40,821 WARNING 	FPR: 0.1 | TPR: 0.7500 | F1: 0.8571
2023-03-16 14:46:40,904 WARNING  [3/3] Train set size: 34, Validation set size: 16
2023-03-16 14:46:40,909 WARNING  [!] Saved dataset splits to dataset_splits_1678974400.npz
2023-03-16 14:46:40,977 WARNING  [!] Iniatialized TransformerEncoderChunks. Total trainable parameters: 2.5172e6
2023-03-16 14:46:40,978 WARNING  [*] Training time budget set: 0.05 min
2023-03-16 14:46:40,979 WARNING  [*] Started epoch: 1
2023-03-16 14:46:41,113 WARNING  [*] 14:46:41: Train Epoch: 1 [  0  / 34   (0 %)] | Loss: 2.599529 | Elapsed: 0.12s | FPR 0.0003 -> TPR 0.0417 & F1 0.0800 | AUC 0.6583
2023-03-16 14:46:41,135 WARNING  [*] Thu Mar 16 14:46:41 2023:    1    | Tr.loss: 2.599529 | Elapsed:   0.16   s | FPR 0.0003 -> TPR: 0.04 & F1: 0.08 | AUC: 0.6583
2023-03-16 14:46:41,135 WARNING  [*] Started epoch: 2
2023-03-16 14:46:41,243 WARNING  [*] 14:46:41: Train Epoch: 2 [  0  / 34   (0 %)] | Loss: 2.402024 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.2917 & F1 0.4516 | AUC 0.6167
2023-03-16 14:46:41,259 WARNING  [*] Thu Mar 16 14:46:41 2023:    2    | Tr.loss: 2.402024 | Elapsed:   0.12   s | FPR 0.0003 -> TPR: 0.29 & F1: 0.45 | AUC: 0.6167
2023-03-16 14:46:41,260 WARNING  [*] Started epoch: 3
2023-03-16 14:46:41,353 WARNING  [*] 14:46:41: Train Epoch: 3 [  0  / 34   (0 %)] | Loss: 2.635974 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.5146
2023-03-16 14:46:41,368 WARNING  [*] Thu Mar 16 14:46:41 2023:    3    | Tr.loss: 2.635974 | Elapsed:   0.11   s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.5146
2023-03-16 14:46:41,369 WARNING  [*] Started epoch: 4
2023-03-16 14:46:41,459 WARNING  [*] 14:46:41: Train Epoch: 4 [  0  / 34   (0 %)] | Loss: 2.277167 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0417 & F1 0.0800 | AUC 0.4875
2023-03-16 14:46:41,476 WARNING  [*] Thu Mar 16 14:46:41 2023:    4    | Tr.loss: 2.277167 | Elapsed:   0.11   s | FPR 0.0003 -> TPR: 0.04 & F1: 0.08 | AUC: 0.4875
2023-03-16 14:46:41,476 WARNING  [*] Started epoch: 5
2023-03-16 14:46:41,564 WARNING  [*] 14:46:41: Train Epoch: 5 [  0  / 34   (0 %)] | Loss: 1.279716 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.6500
2023-03-16 14:46:41,581 WARNING  [*] Thu Mar 16 14:46:41 2023:    5    | Tr.loss: 1.279716 | Elapsed:   0.10   s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.6500
2023-03-16 14:46:41,581 WARNING  [*] Started epoch: 6
2023-03-16 14:46:41,668 WARNING  [*] 14:46:41: Train Epoch: 6 [  0  / 34   (0 %)] | Loss: 2.381477 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.4667
2023-03-16 14:46:41,683 WARNING  [*] Thu Mar 16 14:46:41 2023:    6    | Tr.loss: 2.381477 | Elapsed:   0.10   s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.4667
2023-03-16 14:46:41,683 WARNING  [*] Started epoch: 7
2023-03-16 14:46:41,783 WARNING  [*] 14:46:41: Train Epoch: 7 [  0  / 34   (0 %)] | Loss: 1.049365 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.6250 & F1 0.7692 | AUC 0.8833
2023-03-16 14:46:41,799 WARNING  [*] Thu Mar 16 14:46:41 2023:    7    | Tr.loss: 1.049365 | Elapsed:   0.12   s | FPR 0.0003 -> TPR: 0.62 & F1: 0.77 | AUC: 0.8833
2023-03-16 14:46:41,801 WARNING  [*] Started epoch: 8
2023-03-16 14:46:41,896 WARNING  [*] 14:46:41: Train Epoch: 8 [  0  / 34   (0 %)] | Loss: 1.300906 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0833 & F1 0.1538 | AUC 0.6958
2023-03-16 14:46:41,912 WARNING  [*] Thu Mar 16 14:46:41 2023:    8    | Tr.loss: 1.300906 | Elapsed:   0.11   s | FPR 0.0003 -> TPR: 0.08 & F1: 0.15 | AUC: 0.6958
2023-03-16 14:46:41,913 WARNING  [*] Started epoch: 9
2023-03-16 14:46:42,009 WARNING  [*] 14:46:42: Train Epoch: 9 [  0  / 34   (0 %)] | Loss: 0.713276 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.1250 & F1 0.2222 | AUC 0.7667
2023-03-16 14:46:42,025 WARNING  [*] Thu Mar 16 14:46:42 2023:    9    | Tr.loss: 0.713276 | Elapsed:   0.11   s | FPR 0.0003 -> TPR: 0.12 & F1: 0.22 | AUC: 0.7667
2023-03-16 14:46:42,025 WARNING  [*] Started epoch: 10
2023-03-16 14:46:42,114 WARNING  [*] 14:46:42: Train Epoch: 10 [  0  / 34   (0 %)] | Loss: 0.756364 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.4583 & F1 0.6286 | AUC 0.7958
2023-03-16 14:46:42,130 WARNING  [*] Thu Mar 16 14:46:42 2023:   10    | Tr.loss: 0.756364 | Elapsed:   0.10   s | FPR 0.0003 -> TPR: 0.46 & F1: 0.63 | AUC: 0.7958
2023-03-16 14:46:42,131 WARNING  [*] Started epoch: 11
2023-03-16 14:46:42,218 WARNING  [*] 14:46:42: Train Epoch: 11 [  0  / 34   (0 %)] | Loss: 0.672561 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.3750 & F1 0.5455 | AUC 0.8125
2023-03-16 14:46:42,232 WARNING  [*] Thu Mar 16 14:46:42 2023:   11    | Tr.loss: 0.672561 | Elapsed:   0.10   s | FPR 0.0003 -> TPR: 0.38 & F1: 0.55 | AUC: 0.8125
2023-03-16 14:46:42,232 WARNING  [*] Started epoch: 12
2023-03-16 14:46:42,331 WARNING  [*] 14:46:42: Train Epoch: 12 [  0  / 34   (0 %)] | Loss: 0.627324 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.5000 & F1 0.6667 | AUC 0.7875
2023-03-16 14:46:42,346 WARNING  [*] Thu Mar 16 14:46:42 2023:   12    | Tr.loss: 0.627324 | Elapsed:   0.11   s | FPR 0.0003 -> TPR: 0.50 & F1: 0.67 | AUC: 0.7875
2023-03-16 14:46:42,346 WARNING  [*] Started epoch: 13
2023-03-16 14:46:42,454 WARNING  [*] 14:46:42: Train Epoch: 13 [  0  / 34   (0 %)] | Loss: 0.696207 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.4167 & F1 0.5882 | AUC 0.8167
2023-03-16 14:46:42,472 WARNING  [*] Thu Mar 16 14:46:42 2023:   13    | Tr.loss: 0.696207 | Elapsed:   0.13   s | FPR 0.0003 -> TPR: 0.42 & F1: 0.59 | AUC: 0.8167
2023-03-16 14:46:42,473 WARNING  [*] Started epoch: 14
2023-03-16 14:46:42,575 WARNING  [*] 14:46:42: Train Epoch: 14 [  0  / 34   (0 %)] | Loss: 0.836701 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.7708
2023-03-16 14:46:42,592 WARNING  [*] Thu Mar 16 14:46:42 2023:   14    | Tr.loss: 0.836701 | Elapsed:   0.12   s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7708
2023-03-16 14:46:42,592 WARNING  [*] Started epoch: 15
2023-03-16 14:46:42,681 WARNING  [*] 14:46:42: Train Epoch: 15 [  0  / 34   (0 %)] | Loss: 0.652505 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.5000 & F1 0.6667 | AUC 0.8000
2023-03-16 14:46:42,696 WARNING  [*] Thu Mar 16 14:46:42 2023:   15    | Tr.loss: 0.652505 | Elapsed:   0.10   s | FPR 0.0003 -> TPR: 0.50 & F1: 0.67 | AUC: 0.8000
2023-03-16 14:46:42,697 WARNING  [*] Started epoch: 16
2023-03-16 14:46:42,784 WARNING  [*] 14:46:42: Train Epoch: 16 [  0  / 34   (0 %)] | Loss: 0.530200 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.3333 & F1 0.5000 | AUC 0.8375
2023-03-16 14:46:42,799 WARNING  [*] Thu Mar 16 14:46:42 2023:   16    | Tr.loss: 0.530200 | Elapsed:   0.10   s | FPR 0.0003 -> TPR: 0.33 & F1: 0.50 | AUC: 0.8375
2023-03-16 14:46:42,801 WARNING  [*] Started epoch: 17
2023-03-16 14:46:42,893 WARNING  [*] 14:46:42: Train Epoch: 17 [  0  / 34   (0 %)] | Loss: 0.706742 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.6250 & F1 0.7692 | AUC 0.8125
2023-03-16 14:46:42,909 WARNING  [*] Thu Mar 16 14:46:42 2023:   17    | Tr.loss: 0.706742 | Elapsed:   0.11   s | FPR 0.0003 -> TPR: 0.62 & F1: 0.77 | AUC: 0.8125
2023-03-16 14:46:42,910 WARNING  [*] Started epoch: 18
2023-03-16 14:46:43,002 WARNING  [*] 14:46:43: Train Epoch: 18 [  0  / 34   (0 %)] | Loss: 0.303098 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.7083 & F1 0.8293 | AUC 0.9292
2023-03-16 14:46:43,017 WARNING  [*] Thu Mar 16 14:46:43 2023:   18    | Tr.loss: 0.303098 | Elapsed:   0.11   s | FPR 0.0003 -> TPR: 0.71 & F1: 0.83 | AUC: 0.9292
2023-03-16 14:46:43,018 WARNING  [*] Started epoch: 19
2023-03-16 14:46:43,113 WARNING  [*] 14:46:43: Train Epoch: 19 [  0  / 34   (0 %)] | Loss: 0.374860 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.7083 & F1 0.8293 | AUC 0.9083
2023-03-16 14:46:43,129 WARNING  [*] Thu Mar 16 14:46:43 2023:   19    | Tr.loss: 0.374860 | Elapsed:   0.11   s | FPR 0.0003 -> TPR: 0.71 & F1: 0.83 | AUC: 0.9083
2023-03-16 14:46:43,130 WARNING  [*] Started epoch: 20
2023-03-16 14:46:43,215 WARNING  [*] 14:46:43: Train Epoch: 20 [  0  / 34   (0 %)] | Loss: 0.368623 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.7917 & F1 0.8837 | AUC 0.9042
2023-03-16 14:46:43,230 WARNING  [*] Thu Mar 16 14:46:43 2023:   20    | Tr.loss: 0.368623 | Elapsed:   0.10   s | FPR 0.0003 -> TPR: 0.79 & F1: 0.88 | AUC: 0.9042
2023-03-16 14:46:43,231 WARNING  [*] Started epoch: 21
2023-03-16 14:46:43,317 WARNING  [*] 14:46:43: Train Epoch: 21 [  0  / 34   (0 %)] | Loss: 0.550093 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.6250 & F1 0.7692 | AUC 0.8250
2023-03-16 14:46:43,332 WARNING  [*] Thu Mar 16 14:46:43 2023:   21    | Tr.loss: 0.550093 | Elapsed:   0.10   s | FPR 0.0003 -> TPR: 0.62 & F1: 0.77 | AUC: 0.8250
2023-03-16 14:46:43,333 WARNING  [*] Started epoch: 22
2023-03-16 14:46:43,415 WARNING  [*] 14:46:43: Train Epoch: 22 [  0  / 34   (0 %)] | Loss: 0.372290 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.6250 & F1 0.7692 | AUC 0.8792
2023-03-16 14:46:43,429 WARNING  [*] Thu Mar 16 14:46:43 2023:   22    | Tr.loss: 0.372290 | Elapsed:   0.10   s | FPR 0.0003 -> TPR: 0.62 & F1: 0.77 | AUC: 0.8792
2023-03-16 14:46:43,431 WARNING  [*] Started epoch: 23
2023-03-16 14:46:43,519 WARNING  [*] 14:46:43: Train Epoch: 23 [  0  / 34   (0 %)] | Loss: 0.498460 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.5833 & F1 0.7368 | AUC 0.8125
2023-03-16 14:46:43,533 WARNING  [*] Thu Mar 16 14:46:43 2023:   23    | Tr.loss: 0.498460 | Elapsed:   0.10   s | FPR 0.0003 -> TPR: 0.58 & F1: 0.74 | AUC: 0.8125
2023-03-16 14:46:43,533 WARNING  [*] Started epoch: 24
2023-03-16 14:46:43,617 WARNING  [*] 14:46:43: Train Epoch: 24 [  0  / 34   (0 %)] | Loss: 0.278554 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.5833 & F1 0.7368 | AUC 0.9417
2023-03-16 14:46:43,631 WARNING  [*] Thu Mar 16 14:46:43 2023:   24    | Tr.loss: 0.278554 | Elapsed:   0.10   s | FPR 0.0003 -> TPR: 0.58 & F1: 0.74 | AUC: 0.9417
2023-03-16 14:46:43,631 WARNING  [*] Started epoch: 25
2023-03-16 14:46:43,718 WARNING  [*] 14:46:43: Train Epoch: 25 [  0  / 34   (0 %)] | Loss: 0.292445 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.7083 & F1 0.8293 | AUC 0.9708
2023-03-16 14:46:43,734 WARNING  [*] Thu Mar 16 14:46:43 2023:   25    | Tr.loss: 0.292445 | Elapsed:   0.10   s | FPR 0.0003 -> TPR: 0.71 & F1: 0.83 | AUC: 0.9708
2023-03-16 14:46:43,734 WARNING  [*] Started epoch: 26
2023-03-16 14:46:43,820 WARNING  [*] 14:46:43: Train Epoch: 26 [  0  / 34   (0 %)] | Loss: 0.335535 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.5833 & F1 0.7368 | AUC 0.9208
2023-03-16 14:46:43,834 WARNING  [*] Thu Mar 16 14:46:43 2023:   26    | Tr.loss: 0.335535 | Elapsed:   0.10   s | FPR 0.0003 -> TPR: 0.58 & F1: 0.74 | AUC: 0.9208
2023-03-16 14:46:43,835 WARNING  [*] Started epoch: 27
2023-03-16 14:46:43,917 WARNING  [*] 14:46:43: Train Epoch: 27 [  0  / 34   (0 %)] | Loss: 0.429342 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.5000 & F1 0.6667 | AUC 0.8667
2023-03-16 14:46:43,932 WARNING  [*] Thu Mar 16 14:46:43 2023:   27    | Tr.loss: 0.429342 | Elapsed:   0.10   s | FPR 0.0003 -> TPR: 0.50 & F1: 0.67 | AUC: 0.8667
2023-03-16 14:46:43,932 WARNING  [*] Started epoch: 28
2023-03-16 14:46:44,015 WARNING  [*] 14:46:44: Train Epoch: 28 [  0  / 34   (0 %)] | Loss: 0.298365 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.7083 & F1 0.8293 | AUC 0.9583
2023-03-16 14:46:44,015 WARNING  [!] Time budget exceeded, training stopped.
2023-03-16 14:46:44,044 WARNING  [!] Thu Mar 16 14:46:44 2023: Dumped results:
                model       : 1678974400-model.torch
		train time  : 1678974400-trainTime.npy
		train losses: 1678974400-trainLosses.npy
		train AUC   : 1678974400-auc.npy
		train F1s   : 1678974400-trainF1s.npy
		train TPRs  : 1678974400-trainTPRs.npy
2023-03-16 14:46:44,047 WARNING  [!] Evaluating model on training set...
2023-03-16 14:46:44,063 WARNING  [!] This fold metrics on training set:
2023-03-16 14:46:44,065 WARNING 	AUC: 0.9750
2023-03-16 14:46:44,068 WARNING 	FPR: 0.0001 | TPR: 0.7500 | F1: 0.8571
2023-03-16 14:46:44,071 WARNING 	FPR: 0.0003 | TPR: 0.7500 | F1: 0.8571
2023-03-16 14:46:44,074 WARNING 	FPR: 0.001 | TPR: 0.7500 | F1: 0.8571
2023-03-16 14:46:44,077 WARNING 	FPR: 0.003 | TPR: 0.7500 | F1: 0.8571
2023-03-16 14:46:44,079 WARNING 	FPR: 0.01 | TPR: 0.7500 | F1: 0.8571
2023-03-16 14:46:44,082 WARNING 	FPR: 0.03 | TPR: 0.7500 | F1: 0.8571
2023-03-16 14:46:44,085 WARNING 	FPR: 0.1 | TPR: 1.0000 | F1: 0.9796
2023-03-16 14:46:44,086 WARNING  [!] Evaluating model on validation set...
2023-03-16 14:46:44,103 WARNING  [!] This fold metrics on validation set:
2023-03-16 14:46:44,105 WARNING 	AUC: 0.7188
2023-03-16 14:46:44,108 WARNING 	FPR: 0.0001 | TPR: 0.3750 | F1: 0.5455
2023-03-16 14:46:44,111 WARNING 	FPR: 0.0003 | TPR: 0.3750 | F1: 0.5455
2023-03-16 14:46:44,114 WARNING 	FPR: 0.001 | TPR: 0.3750 | F1: 0.5455
2023-03-16 14:46:44,117 WARNING 	FPR: 0.003 | TPR: 0.3750 | F1: 0.5455
2023-03-16 14:46:44,119 WARNING 	FPR: 0.01 | TPR: 0.3750 | F1: 0.5455
2023-03-16 14:46:44,121 WARNING 	FPR: 0.03 | TPR: 0.3750 | F1: 0.5455
2023-03-16 14:46:44,124 WARNING 	FPR: 0.1 | TPR: 0.3750 | F1: 0.5455
2023-03-16 14:46:44,199 WARNING  [!] Metrics saved to out_tokenizer_1678974355\cv_whitespace_lim50_r1763_t0.05\whitespace_metrics_validation.json
2023-03-16 14:46:44,204 WARNING  [!] Metrics saved to out_tokenizer_1678974355\cv_whitespace_lim50_r1763_t0.05\whitespace_metrics_training.json
2023-03-16 14:46:44,205 WARNING  [!] Average epoch time: 0.00s | Mean values over 3 folds:
	AUC: 0.8007
	FPR: 0.0001 -- TPR: 0.4861 -- F1: 0.6342
	FPR: 0.0003 -- TPR: 0.4861 -- F1: 0.6342
	FPR:  0.001 -- TPR: 0.4861 -- F1: 0.6342
	FPR:  0.003 -- TPR: 0.4861 -- F1: 0.6342
	FPR:   0.01 -- TPR: 0.4861 -- F1: 0.6342
	FPR:   0.03 -- TPR: 0.4861 -- F1: 0.6342
	FPR:    0.1 -- TPR: 0.4861 -- F1: 0.6342

2023-03-16 14:46:44,268 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_backdoor
2023-03-16 14:46:48,003 WARNING Finished... Took: 3.73s
2023-03-16 14:46:48,010 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_clean
2023-03-16 14:46:49,899 WARNING Finished... Took: 1.89s
2023-03-16 14:46:49,899 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_coinminer
2023-03-16 14:46:51,537 WARNING Finished... Took: 1.64s
2023-03-16 14:46:51,538 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_dropper
2023-03-16 14:46:52,574 WARNING Finished... Took: 1.04s
2023-03-16 14:46:52,574 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_keylogger
2023-03-16 14:46:53,709 WARNING Finished... Took: 1.14s
2023-03-16 14:46:53,709 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_ransomware
2023-03-16 14:46:55,954 WARNING Finished... Took: 2.24s
2023-03-16 14:46:55,955 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_rat
2023-03-16 14:46:56,892 WARNING Finished... Took: 0.94s
2023-03-16 14:46:56,892 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_trojan
2023-03-16 14:46:59,026 WARNING Finished... Took: 2.13s
2023-03-16 14:46:59,027 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_windows_syswow64
2023-03-16 14:46:59,538 WARNING Finished... Took: 0.51s
2023-03-16 14:46:59,539 WARNING  [!] Saved Y as out_tokenizer_1678974355\nebula_bpe_vocab_5000_seqlen_512\y_train_50.npy
2023-03-16 14:46:59,543 WARNING  [!] Saved Y names as out_tokenizer_1678974355\nebula_bpe_vocab_5000_seqlen_512\y_names_train_50.json
2023-03-16 14:46:59,543 WARNING  [!] Initialized tokenizer without pre-trained model.
	You need to train tokenizer with .train() or specify 'model_path=' during initialization!
2023-03-16 14:46:59,544 WARNING  [*] Initializing tokenizer training...
2023-03-16 14:46:59,544 WARNING  [*] Data preparation for SentencePiece tokenizer...
2023-03-16 14:47:00,269 WARNING  [*] Saving to disk...
2023-03-16 14:47:00,283 WARNING  [!] Training tokenizer with command: --input=out_tokenizer_1678974355\nebula_bpe_vocab_5000_seqlen_512\tokenizer_5000_trainset_1678974420.txt --model_prefix=out_tokenizer_1678974355\nebula_bpe_vocab_5000_seqlen_512\tokenizer_5000 --vocab_size=5000 --model_type=bpe --split_by_number=False --max_sentence_length=4192 --max_sentencepiece_length=64
2023-03-16 14:47:01,508 WARNING  [!] Loaded vocab with size 5001 from out_tokenizer_1678974355\nebula_bpe_vocab_5000_seqlen_512\tokenizer_5000.vocab
2023-03-16 14:47:01,601 WARNING  [*] Encoding and padding...
2023-03-16 14:47:03,043 WARNING  [!] Saved X as out_tokenizer_1678974355\nebula_bpe_vocab_5000_seqlen_512\x_train_50.npy
2023-03-16 14:47:03,061 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_backdoor
2023-03-16 14:47:05,898 WARNING Finished... Took: 2.84s
2023-03-16 14:47:05,898 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_clean
2023-03-16 14:47:07,234 WARNING Finished... Took: 1.34s
2023-03-16 14:47:07,234 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_coinminer
2023-03-16 14:47:09,302 WARNING Finished... Took: 2.07s
2023-03-16 14:47:09,304 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_dropper
2023-03-16 14:47:09,481 WARNING Finished... Took: 0.18s
2023-03-16 14:47:09,482 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_keylogger
2023-03-16 14:47:09,762 WARNING Finished... Took: 0.28s
2023-03-16 14:47:09,763 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_ransomware
2023-03-16 14:47:18,350 WARNING Finished... Took: 8.59s
2023-03-16 14:47:18,350 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_rat
2023-03-16 14:47:19,658 WARNING Finished... Took: 1.31s
2023-03-16 14:47:19,659 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_trojan
2023-03-16 14:47:20,309 WARNING Finished... Took: 0.65s
2023-03-16 14:47:20,311 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_windows_syswow64
2023-03-16 14:47:21,014 WARNING Finished... Took: 0.70s
2023-03-16 14:47:21,016 WARNING  [!] Saved Y as out_tokenizer_1678974355\nebula_bpe_vocab_5000_seqlen_512\y_test_50.npy
2023-03-16 14:47:21,021 WARNING  [!] Saved Y names as out_tokenizer_1678974355\nebula_bpe_vocab_5000_seqlen_512\y_names_test_50.json
2023-03-16 14:47:21,025 WARNING  [!] Successfully loaded pre-trained tokenizer model!
2023-03-16 14:47:21,030 WARNING  [!] Loaded vocab with size 5001 from out_tokenizer_1678974355\nebula_bpe_vocab_5000_seqlen_512\tokenizer_5000_vocab.json
2023-03-16 14:47:21,030 WARNING  [*] Encoding and padding...
2023-03-16 14:47:22,629 WARNING  [!] Saved X as out_tokenizer_1678974355\nebula_bpe_vocab_5000_seqlen_512\x_test_50.npy
2023-03-16 14:47:22,656 WARNING  [!!!] Starting CV over bpe!
2023-03-16 14:47:22,664 WARNING  [!] Training time budget: 3min
2023-03-16 14:47:22,664 WARNING  [!] Model config: {'vocab_size': 5001, 'maxlen': 512, 'chunk_size': 64, 'dModel': 64, 'nHeads': 8, 'dHidden': 256, 'nLayers': 2, 'numClasses': 1, 'hiddenNeurons': [64], 'layerNorm': False, 'dropout': 0.3, 'mean_over_sequence': False, 'norm_first': True}
2023-03-16 14:47:22,667 WARNING  [1/3] Train set size: 33, Validation set size: 17
2023-03-16 14:47:22,678 WARNING  [!] Saved dataset splits to dataset_splits_1678974442.npz
2023-03-16 14:47:22,802 WARNING  [!] Iniatialized TransformerEncoderChunks. Total trainable parameters: 2.5173e6
2023-03-16 14:47:22,803 WARNING  [*] Training time budget set: 0.05 min
2023-03-16 14:47:22,806 WARNING  [*] Started epoch: 1
2023-03-16 14:47:23,070 WARNING  [*] 14:47:23: Train Epoch: 1 [  0  / 33   (0 %)] | Loss: 2.499314 | Elapsed: 0.23s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.5038
2023-03-16 14:47:23,092 WARNING  [*] Thu Mar 16 14:47:23 2023:    1    | Tr.loss: 2.499314 | Elapsed:   0.29   s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.5038
2023-03-16 14:47:23,095 WARNING  [*] Started epoch: 2
2023-03-16 14:47:23,267 WARNING  [*] 14:47:23: Train Epoch: 2 [  0  / 33   (0 %)] | Loss: 1.620018 | Elapsed: 0.14s | FPR 0.0003 -> TPR 0.1000 & F1 0.1818 | AUC 0.5538
2023-03-16 14:47:23,289 WARNING  [*] Thu Mar 16 14:47:23 2023:    2    | Tr.loss: 1.620018 | Elapsed:   0.19   s | FPR 0.0003 -> TPR: 0.10 & F1: 0.18 | AUC: 0.5538
2023-03-16 14:47:23,289 WARNING  [*] Started epoch: 3
2023-03-16 14:47:23,411 WARNING  [*] 14:47:23: Train Epoch: 3 [  0  / 33   (0 %)] | Loss: 2.080883 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.3462
2023-03-16 14:47:23,437 WARNING  [*] Thu Mar 16 14:47:23 2023:    3    | Tr.loss: 2.080883 | Elapsed:   0.15   s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.3462
2023-03-16 14:47:23,437 WARNING  [*] Started epoch: 4
2023-03-16 14:47:23,545 WARNING  [*] 14:47:23: Train Epoch: 4 [  0  / 33   (0 %)] | Loss: 1.605060 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.5769
2023-03-16 14:47:23,564 WARNING  [*] Thu Mar 16 14:47:23 2023:    4    | Tr.loss: 1.605060 | Elapsed:   0.13   s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.5769
2023-03-16 14:47:23,564 WARNING  [*] Started epoch: 5
2023-03-16 14:47:23,686 WARNING  [*] 14:47:23: Train Epoch: 5 [  0  / 33   (0 %)] | Loss: 1.524657 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.6462
2023-03-16 14:47:23,706 WARNING  [*] Thu Mar 16 14:47:23 2023:    5    | Tr.loss: 1.524657 | Elapsed:   0.14   s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.6462
2023-03-16 14:47:23,707 WARNING  [*] Started epoch: 6
2023-03-16 14:47:23,812 WARNING  [*] 14:47:23: Train Epoch: 6 [  0  / 33   (0 %)] | Loss: 1.084675 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.4500 & F1 0.6207 | AUC 0.6346
2023-03-16 14:47:23,829 WARNING  [*] Thu Mar 16 14:47:23 2023:    6    | Tr.loss: 1.084675 | Elapsed:   0.12   s | FPR 0.0003 -> TPR: 0.45 & F1: 0.62 | AUC: 0.6346
2023-03-16 14:47:23,830 WARNING  [*] Started epoch: 7
2023-03-16 14:47:23,930 WARNING  [*] 14:47:23: Train Epoch: 7 [  0  / 33   (0 %)] | Loss: 0.748732 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.3500 & F1 0.5185 | AUC 0.7769
2023-03-16 14:47:23,948 WARNING  [*] Thu Mar 16 14:47:23 2023:    7    | Tr.loss: 0.748732 | Elapsed:   0.12   s | FPR 0.0003 -> TPR: 0.35 & F1: 0.52 | AUC: 0.7769
2023-03-16 14:47:23,948 WARNING  [*] Started epoch: 8
2023-03-16 14:47:24,054 WARNING  [*] 14:47:24: Train Epoch: 8 [  0  / 33   (0 %)] | Loss: 0.894881 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.2500 & F1 0.4000 | AUC 0.6462
2023-03-16 14:47:24,071 WARNING  [*] Thu Mar 16 14:47:24 2023:    8    | Tr.loss: 0.894881 | Elapsed:   0.12   s | FPR 0.0003 -> TPR: 0.25 & F1: 0.40 | AUC: 0.6462
2023-03-16 14:47:24,072 WARNING  [*] Started epoch: 9
2023-03-16 14:47:24,174 WARNING  [*] 14:47:24: Train Epoch: 9 [  0  / 33   (0 %)] | Loss: 0.756676 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.4500 & F1 0.6207 | AUC 0.7577
2023-03-16 14:47:24,191 WARNING  [*] Thu Mar 16 14:47:24 2023:    9    | Tr.loss: 0.756676 | Elapsed:   0.12   s | FPR 0.0003 -> TPR: 0.45 & F1: 0.62 | AUC: 0.7577
2023-03-16 14:47:24,192 WARNING  [*] Started epoch: 10
2023-03-16 14:47:24,296 WARNING  [*] 14:47:24: Train Epoch: 10 [  0  / 33   (0 %)] | Loss: 0.401674 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.6000 & F1 0.7500 | AUC 0.9308
2023-03-16 14:47:24,313 WARNING  [*] Thu Mar 16 14:47:24 2023:   10    | Tr.loss: 0.401674 | Elapsed:   0.12   s | FPR 0.0003 -> TPR: 0.60 & F1: 0.75 | AUC: 0.9308
2023-03-16 14:47:24,314 WARNING  [*] Started epoch: 11
2023-03-16 14:47:24,417 WARNING  [*] 14:47:24: Train Epoch: 11 [  0  / 33   (0 %)] | Loss: 0.601718 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.2000 & F1 0.3333 | AUC 0.7808
2023-03-16 14:47:24,436 WARNING  [*] Thu Mar 16 14:47:24 2023:   11    | Tr.loss: 0.601718 | Elapsed:   0.12   s | FPR 0.0003 -> TPR: 0.20 & F1: 0.33 | AUC: 0.7808
2023-03-16 14:47:24,437 WARNING  [*] Started epoch: 12
2023-03-16 14:47:24,562 WARNING  [*] 14:47:24: Train Epoch: 12 [  0  / 33   (0 %)] | Loss: 0.546009 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.4500 & F1 0.6207 | AUC 0.8115
2023-03-16 14:47:24,583 WARNING  [*] Thu Mar 16 14:47:24 2023:   12    | Tr.loss: 0.546009 | Elapsed:   0.15   s | FPR 0.0003 -> TPR: 0.45 & F1: 0.62 | AUC: 0.8115
2023-03-16 14:47:24,584 WARNING  [*] Started epoch: 13
2023-03-16 14:47:24,708 WARNING  [*] 14:47:24: Train Epoch: 13 [  0  / 33   (0 %)] | Loss: 0.370451 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.6000 & F1 0.7500 | AUC 0.8846
2023-03-16 14:47:24,726 WARNING  [*] Thu Mar 16 14:47:24 2023:   13    | Tr.loss: 0.370451 | Elapsed:   0.14   s | FPR 0.0003 -> TPR: 0.60 & F1: 0.75 | AUC: 0.8846
2023-03-16 14:47:24,727 WARNING  [*] Started epoch: 14
2023-03-16 14:47:24,839 WARNING  [*] 14:47:24: Train Epoch: 14 [  0  / 33   (0 %)] | Loss: 0.576155 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.3500 & F1 0.5185 | AUC 0.8000
2023-03-16 14:47:24,857 WARNING  [*] Thu Mar 16 14:47:24 2023:   14    | Tr.loss: 0.576155 | Elapsed:   0.13   s | FPR 0.0003 -> TPR: 0.35 & F1: 0.52 | AUC: 0.8000
2023-03-16 14:47:24,858 WARNING  [*] Started epoch: 15
2023-03-16 14:47:24,961 WARNING  [*] 14:47:24: Train Epoch: 15 [  0  / 33   (0 %)] | Loss: 0.521138 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.5500 & F1 0.7097 | AUC 0.9038
2023-03-16 14:47:24,980 WARNING  [*] Thu Mar 16 14:47:24 2023:   15    | Tr.loss: 0.521138 | Elapsed:   0.12   s | FPR 0.0003 -> TPR: 0.55 & F1: 0.71 | AUC: 0.9038
2023-03-16 14:47:24,980 WARNING  [*] Started epoch: 16
2023-03-16 14:47:25,082 WARNING  [*] 14:47:25: Train Epoch: 16 [  0  / 33   (0 %)] | Loss: 0.450055 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.6000 & F1 0.7500 | AUC 0.8885
2023-03-16 14:47:25,099 WARNING  [*] Thu Mar 16 14:47:25 2023:   16    | Tr.loss: 0.450055 | Elapsed:   0.12   s | FPR 0.0003 -> TPR: 0.60 & F1: 0.75 | AUC: 0.8885
2023-03-16 14:47:25,100 WARNING  [*] Started epoch: 17
2023-03-16 14:47:25,212 WARNING  [*] 14:47:25: Train Epoch: 17 [  0  / 33   (0 %)] | Loss: 0.425044 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.6000 & F1 0.7500 | AUC 0.8769
2023-03-16 14:47:25,230 WARNING  [*] Thu Mar 16 14:47:25 2023:   17    | Tr.loss: 0.425044 | Elapsed:   0.13   s | FPR 0.0003 -> TPR: 0.60 & F1: 0.75 | AUC: 0.8769
2023-03-16 14:47:25,231 WARNING  [*] Started epoch: 18
2023-03-16 14:47:25,336 WARNING  [*] 14:47:25: Train Epoch: 18 [  0  / 33   (0 %)] | Loss: 0.362689 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.8000 & F1 0.8889 | AUC 0.8962
2023-03-16 14:47:25,353 WARNING  [*] Thu Mar 16 14:47:25 2023:   18    | Tr.loss: 0.362689 | Elapsed:   0.12   s | FPR 0.0003 -> TPR: 0.80 & F1: 0.89 | AUC: 0.8962
2023-03-16 14:47:25,354 WARNING  [*] Started epoch: 19
2023-03-16 14:47:25,458 WARNING  [*] 14:47:25: Train Epoch: 19 [  0  / 33   (0 %)] | Loss: 0.518649 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.5000 & F1 0.6667 | AUC 0.7538
2023-03-16 14:47:25,476 WARNING  [*] Thu Mar 16 14:47:25 2023:   19    | Tr.loss: 0.518649 | Elapsed:   0.12   s | FPR 0.0003 -> TPR: 0.50 & F1: 0.67 | AUC: 0.7538
2023-03-16 14:47:25,477 WARNING  [*] Started epoch: 20
2023-03-16 14:47:25,577 WARNING  [*] 14:47:25: Train Epoch: 20 [  0  / 33   (0 %)] | Loss: 0.285569 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.8500 & F1 0.9189 | AUC 0.9577
2023-03-16 14:47:25,595 WARNING  [*] Thu Mar 16 14:47:25 2023:   20    | Tr.loss: 0.285569 | Elapsed:   0.12   s | FPR 0.0003 -> TPR: 0.85 & F1: 0.92 | AUC: 0.9577
2023-03-16 14:47:25,596 WARNING  [*] Started epoch: 21
2023-03-16 14:47:25,695 WARNING  [*] 14:47:25: Train Epoch: 21 [  0  / 33   (0 %)] | Loss: 0.388417 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.3000 & F1 0.4615 | AUC 0.8923
2023-03-16 14:47:25,713 WARNING  [*] Thu Mar 16 14:47:25 2023:   21    | Tr.loss: 0.388417 | Elapsed:   0.12   s | FPR 0.0003 -> TPR: 0.30 & F1: 0.46 | AUC: 0.8923
2023-03-16 14:47:25,714 WARNING  [*] Started epoch: 22
2023-03-16 14:47:25,813 WARNING  [*] 14:47:25: Train Epoch: 22 [  0  / 33   (0 %)] | Loss: 0.288120 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.8000 & F1 0.8889 | AUC 0.9538
2023-03-16 14:47:25,813 WARNING  [!] Time budget exceeded, training stopped.
2023-03-16 14:47:25,853 WARNING  [!] Thu Mar 16 14:47:25 2023: Dumped results:
                model       : 1678974442-model.torch
		train time  : 1678974442-trainTime.npy
		train losses: 1678974442-trainLosses.npy
		train AUC   : 1678974442-auc.npy
		train F1s   : 1678974442-trainF1s.npy
		train TPRs  : 1678974442-trainTPRs.npy
2023-03-16 14:47:25,855 WARNING  [!] Evaluating model on training set...
2023-03-16 14:47:25,876 WARNING  [!] This fold metrics on training set:
2023-03-16 14:47:25,879 WARNING 	AUC: 0.9577
2023-03-16 14:47:25,883 WARNING 	FPR: 0.0001 | TPR: 0.7000 | F1: 0.8235
2023-03-16 14:47:25,886 WARNING 	FPR: 0.0003 | TPR: 0.7000 | F1: 0.8235
2023-03-16 14:47:25,889 WARNING 	FPR: 0.001 | TPR: 0.7000 | F1: 0.8235
2023-03-16 14:47:25,893 WARNING 	FPR: 0.003 | TPR: 0.7000 | F1: 0.8235
2023-03-16 14:47:25,898 WARNING 	FPR: 0.01 | TPR: 0.7000 | F1: 0.8235
2023-03-16 14:47:25,901 WARNING 	FPR: 0.03 | TPR: 0.7000 | F1: 0.8235
2023-03-16 14:47:25,905 WARNING 	FPR: 0.1 | TPR: 0.8500 | F1: 0.8947
2023-03-16 14:47:25,906 WARNING  [!] Evaluating model on validation set...
2023-03-16 14:47:25,932 WARNING  [!] This fold metrics on validation set:
2023-03-16 14:47:25,934 WARNING 	AUC: 0.7333
2023-03-16 14:47:25,937 WARNING 	FPR: 0.0001 | TPR: 0.1667 | F1: 0.2857
2023-03-16 14:47:25,941 WARNING 	FPR: 0.0003 | TPR: 0.1667 | F1: 0.2857
2023-03-16 14:47:25,943 WARNING 	FPR: 0.001 | TPR: 0.1667 | F1: 0.2857
2023-03-16 14:47:25,946 WARNING 	FPR: 0.003 | TPR: 0.1667 | F1: 0.2857
2023-03-16 14:47:25,949 WARNING 	FPR: 0.01 | TPR: 0.1667 | F1: 0.2857
2023-03-16 14:47:25,952 WARNING 	FPR: 0.03 | TPR: 0.1667 | F1: 0.2857
2023-03-16 14:47:25,956 WARNING 	FPR: 0.1 | TPR: 0.1667 | F1: 0.2857
2023-03-16 14:47:26,035 WARNING  [2/3] Train set size: 33, Validation set size: 17
2023-03-16 14:47:26,052 WARNING  [!] Saved dataset splits to dataset_splits_1678974446.npz
2023-03-16 14:47:26,101 WARNING  [!] Iniatialized TransformerEncoderChunks. Total trainable parameters: 2.5173e6
2023-03-16 14:47:26,101 WARNING  [*] Training time budget set: 0.05 min
2023-03-16 14:47:26,103 WARNING  [*] Started epoch: 1
2023-03-16 14:47:26,272 WARNING  [*] 14:47:26: Train Epoch: 1 [  0  / 33   (0 %)] | Loss: 2.369154 | Elapsed: 0.15s | FPR 0.0003 -> TPR 0.3000 & F1 0.4615 | AUC 0.6654
2023-03-16 14:47:26,307 WARNING  [*] Thu Mar 16 14:47:26 2023:    1    | Tr.loss: 2.369154 | Elapsed:   0.20   s | FPR 0.0003 -> TPR: 0.30 & F1: 0.46 | AUC: 0.6654
2023-03-16 14:47:26,308 WARNING  [*] Started epoch: 2
2023-03-16 14:47:26,429 WARNING  [*] 14:47:26: Train Epoch: 2 [  0  / 33   (0 %)] | Loss: 3.652488 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.4442
2023-03-16 14:47:26,447 WARNING  [*] Thu Mar 16 14:47:26 2023:    2    | Tr.loss: 3.652488 | Elapsed:   0.14   s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.4442
2023-03-16 14:47:26,448 WARNING  [*] Started epoch: 3
2023-03-16 14:47:26,548 WARNING  [*] 14:47:26: Train Epoch: 3 [  0  / 33   (0 %)] | Loss: 3.238747 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.1000 & F1 0.1818 | AUC 0.4077
2023-03-16 14:47:26,565 WARNING  [*] Thu Mar 16 14:47:26 2023:    3    | Tr.loss: 3.238747 | Elapsed:   0.12   s | FPR 0.0003 -> TPR: 0.10 & F1: 0.18 | AUC: 0.4077
2023-03-16 14:47:26,566 WARNING  [*] Started epoch: 4
2023-03-16 14:47:26,661 WARNING  [*] 14:47:26: Train Epoch: 4 [  0  / 33   (0 %)] | Loss: 0.953547 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.2000 & F1 0.3333 | AUC 0.7885
2023-03-16 14:47:26,677 WARNING  [*] Thu Mar 16 14:47:26 2023:    4    | Tr.loss: 0.953547 | Elapsed:   0.11   s | FPR 0.0003 -> TPR: 0.20 & F1: 0.33 | AUC: 0.7885
2023-03-16 14:47:26,677 WARNING  [*] Started epoch: 5
2023-03-16 14:47:26,762 WARNING  [*] 14:47:26: Train Epoch: 5 [  0  / 33   (0 %)] | Loss: 1.219158 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.2500 & F1 0.4000 | AUC 0.6577
2023-03-16 14:47:26,777 WARNING  [*] Thu Mar 16 14:47:26 2023:    5    | Tr.loss: 1.219158 | Elapsed:   0.10   s | FPR 0.0003 -> TPR: 0.25 & F1: 0.40 | AUC: 0.6577
2023-03-16 14:47:26,778 WARNING  [*] Started epoch: 6
2023-03-16 14:47:26,861 WARNING  [*] 14:47:26: Train Epoch: 6 [  0  / 33   (0 %)] | Loss: 2.480536 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.1500 & F1 0.2609 | AUC 0.6808
2023-03-16 14:47:26,876 WARNING  [*] Thu Mar 16 14:47:26 2023:    6    | Tr.loss: 2.480536 | Elapsed:   0.10   s | FPR 0.0003 -> TPR: 0.15 & F1: 0.26 | AUC: 0.6808
2023-03-16 14:47:26,876 WARNING  [*] Started epoch: 7
2023-03-16 14:47:26,966 WARNING  [*] 14:47:26: Train Epoch: 7 [  0  / 33   (0 %)] | Loss: 1.550838 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.2000 & F1 0.3333 | AUC 0.7346
2023-03-16 14:47:26,981 WARNING  [*] Thu Mar 16 14:47:26 2023:    7    | Tr.loss: 1.550838 | Elapsed:   0.11   s | FPR 0.0003 -> TPR: 0.20 & F1: 0.33 | AUC: 0.7346
2023-03-16 14:47:26,981 WARNING  [*] Started epoch: 8
2023-03-16 14:47:27,075 WARNING  [*] 14:47:27: Train Epoch: 8 [  0  / 33   (0 %)] | Loss: 0.902404 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.4000 & F1 0.5714 | AUC 0.7462
2023-03-16 14:47:27,091 WARNING  [*] Thu Mar 16 14:47:27 2023:    8    | Tr.loss: 0.902404 | Elapsed:   0.11   s | FPR 0.0003 -> TPR: 0.40 & F1: 0.57 | AUC: 0.7462
2023-03-16 14:47:27,091 WARNING  [*] Started epoch: 9
2023-03-16 14:47:27,177 WARNING  [*] 14:47:27: Train Epoch: 9 [  0  / 33   (0 %)] | Loss: 0.843605 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.6000 & F1 0.7500 | AUC 0.8077
2023-03-16 14:47:27,194 WARNING  [*] Thu Mar 16 14:47:27 2023:    9    | Tr.loss: 0.843605 | Elapsed:   0.10   s | FPR 0.0003 -> TPR: 0.60 & F1: 0.75 | AUC: 0.8077
2023-03-16 14:47:27,194 WARNING  [*] Started epoch: 10
2023-03-16 14:47:27,278 WARNING  [*] 14:47:27: Train Epoch: 10 [  0  / 33   (0 %)] | Loss: 0.800296 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.3000 & F1 0.4615 | AUC 0.8192
2023-03-16 14:47:27,295 WARNING  [*] Thu Mar 16 14:47:27 2023:   10    | Tr.loss: 0.800296 | Elapsed:   0.10   s | FPR 0.0003 -> TPR: 0.30 & F1: 0.46 | AUC: 0.8192
2023-03-16 14:47:27,295 WARNING  [*] Started epoch: 11
2023-03-16 14:47:27,392 WARNING  [*] 14:47:27: Train Epoch: 11 [  0  / 33   (0 %)] | Loss: 0.870285 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.4500 & F1 0.6207 | AUC 0.8808
2023-03-16 14:47:27,411 WARNING  [*] Thu Mar 16 14:47:27 2023:   11    | Tr.loss: 0.870285 | Elapsed:   0.12   s | FPR 0.0003 -> TPR: 0.45 & F1: 0.62 | AUC: 0.8808
2023-03-16 14:47:27,411 WARNING  [*] Started epoch: 12
2023-03-16 14:47:27,503 WARNING  [*] 14:47:27: Train Epoch: 12 [  0  / 33   (0 %)] | Loss: 0.869140 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.4500 & F1 0.6207 | AUC 0.7731
2023-03-16 14:47:27,519 WARNING  [*] Thu Mar 16 14:47:27 2023:   12    | Tr.loss: 0.869140 | Elapsed:   0.11   s | FPR 0.0003 -> TPR: 0.45 & F1: 0.62 | AUC: 0.7731
2023-03-16 14:47:27,520 WARNING  [*] Started epoch: 13
2023-03-16 14:47:27,619 WARNING  [*] 14:47:27: Train Epoch: 13 [  0  / 33   (0 %)] | Loss: 0.748875 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.6000 & F1 0.7500 | AUC 0.7808
2023-03-16 14:47:27,635 WARNING  [*] Thu Mar 16 14:47:27 2023:   13    | Tr.loss: 0.748875 | Elapsed:   0.12   s | FPR 0.0003 -> TPR: 0.60 & F1: 0.75 | AUC: 0.7808
2023-03-16 14:47:27,636 WARNING  [*] Started epoch: 14
2023-03-16 14:47:27,727 WARNING  [*] 14:47:27: Train Epoch: 14 [  0  / 33   (0 %)] | Loss: 0.412864 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.7500 & F1 0.8571 | AUC 0.9038
2023-03-16 14:47:27,745 WARNING  [*] Thu Mar 16 14:47:27 2023:   14    | Tr.loss: 0.412864 | Elapsed:   0.11   s | FPR 0.0003 -> TPR: 0.75 & F1: 0.86 | AUC: 0.9038
2023-03-16 14:47:27,746 WARNING  [*] Started epoch: 15
2023-03-16 14:47:27,838 WARNING  [*] 14:47:27: Train Epoch: 15 [  0  / 33   (0 %)] | Loss: 0.694490 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.3500 & F1 0.5185 | AUC 0.8269
2023-03-16 14:47:27,854 WARNING  [*] Thu Mar 16 14:47:27 2023:   15    | Tr.loss: 0.694490 | Elapsed:   0.11   s | FPR 0.0003 -> TPR: 0.35 & F1: 0.52 | AUC: 0.8269
2023-03-16 14:47:27,855 WARNING  [*] Started epoch: 16
2023-03-16 14:47:27,944 WARNING  [*] 14:47:27: Train Epoch: 16 [  0  / 33   (0 %)] | Loss: 0.490964 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.6000 & F1 0.7500 | AUC 0.9231
2023-03-16 14:47:27,961 WARNING  [*] Thu Mar 16 14:47:27 2023:   16    | Tr.loss: 0.490964 | Elapsed:   0.11   s | FPR 0.0003 -> TPR: 0.60 & F1: 0.75 | AUC: 0.9231
2023-03-16 14:47:27,961 WARNING  [*] Started epoch: 17
2023-03-16 14:47:28,052 WARNING  [*] 14:47:28: Train Epoch: 17 [  0  / 33   (0 %)] | Loss: 0.351996 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.8500 & F1 0.9189 | AUC 0.9462
2023-03-16 14:47:28,070 WARNING  [*] Thu Mar 16 14:47:28 2023:   17    | Tr.loss: 0.351996 | Elapsed:   0.11   s | FPR 0.0003 -> TPR: 0.85 & F1: 0.92 | AUC: 0.9462
2023-03-16 14:47:28,070 WARNING  [*] Started epoch: 18
2023-03-16 14:47:28,182 WARNING  [*] 14:47:28: Train Epoch: 18 [  0  / 33   (0 %)] | Loss: 0.399174 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.8000 & F1 0.8889 | AUC 0.9192
2023-03-16 14:47:28,201 WARNING  [*] Thu Mar 16 14:47:28 2023:   18    | Tr.loss: 0.399174 | Elapsed:   0.13   s | FPR 0.0003 -> TPR: 0.80 & F1: 0.89 | AUC: 0.9192
2023-03-16 14:47:28,202 WARNING  [*] Started epoch: 19
2023-03-16 14:47:28,309 WARNING  [*] 14:47:28: Train Epoch: 19 [  0  / 33   (0 %)] | Loss: 0.368422 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.7000 & F1 0.8235 | AUC 0.9385
2023-03-16 14:47:28,327 WARNING  [*] Thu Mar 16 14:47:28 2023:   19    | Tr.loss: 0.368422 | Elapsed:   0.12   s | FPR 0.0003 -> TPR: 0.70 & F1: 0.82 | AUC: 0.9385
2023-03-16 14:47:28,327 WARNING  [*] Started epoch: 20
2023-03-16 14:47:28,422 WARNING  [*] 14:47:28: Train Epoch: 20 [  0  / 33   (0 %)] | Loss: 0.463037 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.6000 & F1 0.7500 | AUC 0.8923
2023-03-16 14:47:28,438 WARNING  [*] Thu Mar 16 14:47:28 2023:   20    | Tr.loss: 0.463037 | Elapsed:   0.11   s | FPR 0.0003 -> TPR: 0.60 & F1: 0.75 | AUC: 0.8923
2023-03-16 14:47:28,438 WARNING  [*] Started epoch: 21
2023-03-16 14:47:28,534 WARNING  [*] 14:47:28: Train Epoch: 21 [  0  / 33   (0 %)] | Loss: 0.201952 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.8000 & F1 0.8889 | AUC 0.9692
2023-03-16 14:47:28,551 WARNING  [*] Thu Mar 16 14:47:28 2023:   21    | Tr.loss: 0.201952 | Elapsed:   0.11   s | FPR 0.0003 -> TPR: 0.80 & F1: 0.89 | AUC: 0.9692
2023-03-16 14:47:28,552 WARNING  [*] Started epoch: 22
2023-03-16 14:47:28,643 WARNING  [*] 14:47:28: Train Epoch: 22 [  0  / 33   (0 %)] | Loss: 0.594959 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.6000 & F1 0.7500 | AUC 0.8192
2023-03-16 14:47:28,658 WARNING  [*] Thu Mar 16 14:47:28 2023:   22    | Tr.loss: 0.594959 | Elapsed:   0.11   s | FPR 0.0003 -> TPR: 0.60 & F1: 0.75 | AUC: 0.8192
2023-03-16 14:47:28,658 WARNING  [*] Started epoch: 23
2023-03-16 14:47:28,752 WARNING  [*] 14:47:28: Train Epoch: 23 [  0  / 33   (0 %)] | Loss: 0.387683 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.7000 & F1 0.8235 | AUC 0.8923
2023-03-16 14:47:28,769 WARNING  [*] Thu Mar 16 14:47:28 2023:   23    | Tr.loss: 0.387683 | Elapsed:   0.11   s | FPR 0.0003 -> TPR: 0.70 & F1: 0.82 | AUC: 0.8923
2023-03-16 14:47:28,769 WARNING  [*] Started epoch: 24
2023-03-16 14:47:28,871 WARNING  [*] 14:47:28: Train Epoch: 24 [  0  / 33   (0 %)] | Loss: 0.440021 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.6000 & F1 0.7500 | AUC 0.8923
2023-03-16 14:47:28,888 WARNING  [*] Thu Mar 16 14:47:28 2023:   24    | Tr.loss: 0.440021 | Elapsed:   0.12   s | FPR 0.0003 -> TPR: 0.60 & F1: 0.75 | AUC: 0.8923
2023-03-16 14:47:28,889 WARNING  [*] Started epoch: 25
2023-03-16 14:47:28,986 WARNING  [*] 14:47:28: Train Epoch: 25 [  0  / 33   (0 %)] | Loss: 0.475554 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.7500 & F1 0.8571 | AUC 0.9000
2023-03-16 14:47:29,001 WARNING  [*] Thu Mar 16 14:47:29 2023:   25    | Tr.loss: 0.475554 | Elapsed:   0.11   s | FPR 0.0003 -> TPR: 0.75 & F1: 0.86 | AUC: 0.9000
2023-03-16 14:47:29,002 WARNING  [*] Started epoch: 26
2023-03-16 14:47:29,099 WARNING  [*] 14:47:29: Train Epoch: 26 [  0  / 33   (0 %)] | Loss: 0.376117 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.5500 & F1 0.7097 | AUC 0.9115
2023-03-16 14:47:29,115 WARNING  [*] Thu Mar 16 14:47:29 2023:   26    | Tr.loss: 0.376117 | Elapsed:   0.11   s | FPR 0.0003 -> TPR: 0.55 & F1: 0.71 | AUC: 0.9115
2023-03-16 14:47:29,116 WARNING  [*] Started epoch: 27
2023-03-16 14:47:29,205 WARNING  [*] 14:47:29: Train Epoch: 27 [  0  / 33   (0 %)] | Loss: 0.262689 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.7500 & F1 0.8571 | AUC 0.9500
2023-03-16 14:47:29,205 WARNING  [!] Time budget exceeded, training stopped.
2023-03-16 14:47:29,235 WARNING  [!] Thu Mar 16 14:47:29 2023: Dumped results:
                model       : 1678974446-model.torch
		train time  : 1678974446-trainTime.npy
		train losses: 1678974446-trainLosses.npy
		train AUC   : 1678974446-auc.npy
		train F1s   : 1678974446-trainF1s.npy
		train TPRs  : 1678974446-trainTPRs.npy
2023-03-16 14:47:29,238 WARNING  [!] Evaluating model on training set...
2023-03-16 14:47:29,258 WARNING  [!] This fold metrics on training set:
2023-03-16 14:47:29,261 WARNING 	AUC: 0.9577
2023-03-16 14:47:29,263 WARNING 	FPR: 0.0001 | TPR: 0.8500 | F1: 0.9189
2023-03-16 14:47:29,267 WARNING 	FPR: 0.0003 | TPR: 0.8500 | F1: 0.9189
2023-03-16 14:47:29,270 WARNING 	FPR: 0.001 | TPR: 0.8500 | F1: 0.9189
2023-03-16 14:47:29,272 WARNING 	FPR: 0.003 | TPR: 0.8500 | F1: 0.9189
2023-03-16 14:47:29,275 WARNING 	FPR: 0.01 | TPR: 0.8500 | F1: 0.9189
2023-03-16 14:47:29,277 WARNING 	FPR: 0.03 | TPR: 0.8500 | F1: 0.9189
2023-03-16 14:47:29,280 WARNING 	FPR: 0.1 | TPR: 0.8500 | F1: 0.9189
2023-03-16 14:47:29,281 WARNING  [!] Evaluating model on validation set...
2023-03-16 14:47:29,299 WARNING  [!] This fold metrics on validation set:
2023-03-16 14:47:29,301 WARNING 	AUC: 0.7333
2023-03-16 14:47:29,305 WARNING 	FPR: 0.0001 | TPR: 0.2500 | F1: 0.4000
2023-03-16 14:47:29,308 WARNING 	FPR: 0.0003 | TPR: 0.2500 | F1: 0.4000
2023-03-16 14:47:29,311 WARNING 	FPR: 0.001 | TPR: 0.2500 | F1: 0.4000
2023-03-16 14:47:29,314 WARNING 	FPR: 0.003 | TPR: 0.2500 | F1: 0.4000
2023-03-16 14:47:29,317 WARNING 	FPR: 0.01 | TPR: 0.2500 | F1: 0.4000
2023-03-16 14:47:29,321 WARNING 	FPR: 0.03 | TPR: 0.2500 | F1: 0.4000
2023-03-16 14:47:29,324 WARNING 	FPR: 0.1 | TPR: 0.2500 | F1: 0.4000
2023-03-16 14:47:29,404 WARNING  [3/3] Train set size: 34, Validation set size: 16
2023-03-16 14:47:29,419 WARNING  [!] Saved dataset splits to dataset_splits_1678974449.npz
2023-03-16 14:47:29,499 WARNING  [!] Iniatialized TransformerEncoderChunks. Total trainable parameters: 2.5173e6
2023-03-16 14:47:29,500 WARNING  [*] Training time budget set: 0.05 min
2023-03-16 14:47:29,502 WARNING  [*] Started epoch: 1
2023-03-16 14:47:29,696 WARNING  [*] 14:47:29: Train Epoch: 1 [  0  / 34   (0 %)] | Loss: 2.326817 | Elapsed: 0.17s | FPR 0.0003 -> TPR 0.0833 & F1 0.1538 | AUC 0.4583
2023-03-16 14:47:29,723 WARNING  [*] Thu Mar 16 14:47:29 2023:    1    | Tr.loss: 2.326817 | Elapsed:   0.22   s | FPR 0.0003 -> TPR: 0.08 & F1: 0.15 | AUC: 0.4583
2023-03-16 14:47:29,724 WARNING  [*] Started epoch: 2
2023-03-16 14:47:29,899 WARNING  [*] 14:47:29: Train Epoch: 2 [  0  / 34   (0 %)] | Loss: 0.729477 | Elapsed: 0.14s | FPR 0.0003 -> TPR 0.5000 & F1 0.6667 | AUC 0.8750
2023-03-16 14:47:29,924 WARNING  [*] Thu Mar 16 14:47:29 2023:    2    | Tr.loss: 0.729477 | Elapsed:   0.20   s | FPR 0.0003 -> TPR: 0.50 & F1: 0.67 | AUC: 0.8750
2023-03-16 14:47:29,925 WARNING  [*] Started epoch: 3
2023-03-16 14:47:30,063 WARNING  [*] 14:47:30: Train Epoch: 3 [  0  / 34   (0 %)] | Loss: 0.935533 | Elapsed: 0.12s | FPR 0.0003 -> TPR 0.2083 & F1 0.3448 | AUC 0.7875
2023-03-16 14:47:30,087 WARNING  [*] Thu Mar 16 14:47:30 2023:    3    | Tr.loss: 0.935533 | Elapsed:   0.16   s | FPR 0.0003 -> TPR: 0.21 & F1: 0.34 | AUC: 0.7875
2023-03-16 14:47:30,087 WARNING  [*] Started epoch: 4
2023-03-16 14:47:30,211 WARNING  [*] 14:47:30: Train Epoch: 4 [  0  / 34   (0 %)] | Loss: 1.657584 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.2083 & F1 0.3448 | AUC 0.6750
2023-03-16 14:47:30,232 WARNING  [*] Thu Mar 16 14:47:30 2023:    4    | Tr.loss: 1.657584 | Elapsed:   0.15   s | FPR 0.0003 -> TPR: 0.21 & F1: 0.34 | AUC: 0.6750
2023-03-16 14:47:30,233 WARNING  [*] Started epoch: 5
2023-03-16 14:47:30,352 WARNING  [*] 14:47:30: Train Epoch: 5 [  0  / 34   (0 %)] | Loss: 1.038785 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.1250 & F1 0.2222 | AUC 0.7896
2023-03-16 14:47:30,374 WARNING  [*] Thu Mar 16 14:47:30 2023:    5    | Tr.loss: 1.038785 | Elapsed:   0.14   s | FPR 0.0003 -> TPR: 0.12 & F1: 0.22 | AUC: 0.7896
2023-03-16 14:47:30,375 WARNING  [*] Started epoch: 6
2023-03-16 14:47:30,492 WARNING  [*] 14:47:30: Train Epoch: 6 [  0  / 34   (0 %)] | Loss: 1.346092 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.3333 & F1 0.5000 | AUC 0.7333
2023-03-16 14:47:30,515 WARNING  [*] Thu Mar 16 14:47:30 2023:    6    | Tr.loss: 1.346092 | Elapsed:   0.14   s | FPR 0.0003 -> TPR: 0.33 & F1: 0.50 | AUC: 0.7333
2023-03-16 14:47:30,516 WARNING  [*] Started epoch: 7
2023-03-16 14:47:30,630 WARNING  [*] 14:47:30: Train Epoch: 7 [  0  / 34   (0 %)] | Loss: 1.096529 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.3333 & F1 0.5000 | AUC 0.7208
2023-03-16 14:47:30,650 WARNING  [*] Thu Mar 16 14:47:30 2023:    7    | Tr.loss: 1.096529 | Elapsed:   0.13   s | FPR 0.0003 -> TPR: 0.33 & F1: 0.50 | AUC: 0.7208
2023-03-16 14:47:30,651 WARNING  [*] Started epoch: 8
2023-03-16 14:47:30,770 WARNING  [*] 14:47:30: Train Epoch: 8 [  0  / 34   (0 %)] | Loss: 0.894110 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.4167 & F1 0.5882 | AUC 0.8542
2023-03-16 14:47:30,788 WARNING  [*] Thu Mar 16 14:47:30 2023:    8    | Tr.loss: 0.894110 | Elapsed:   0.14   s | FPR 0.0003 -> TPR: 0.42 & F1: 0.59 | AUC: 0.8542
2023-03-16 14:47:30,788 WARNING  [*] Started epoch: 9
2023-03-16 14:47:30,900 WARNING  [*] 14:47:30: Train Epoch: 9 [  0  / 34   (0 %)] | Loss: 0.730193 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.6250 & F1 0.7692 | AUC 0.8083
2023-03-16 14:47:30,917 WARNING  [*] Thu Mar 16 14:47:30 2023:    9    | Tr.loss: 0.730193 | Elapsed:   0.13   s | FPR 0.0003 -> TPR: 0.62 & F1: 0.77 | AUC: 0.8083
2023-03-16 14:47:30,917 WARNING  [*] Started epoch: 10
2023-03-16 14:47:31,039 WARNING  [*] 14:47:31: Train Epoch: 10 [  0  / 34   (0 %)] | Loss: 0.738325 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.1667 & F1 0.2857 | AUC 0.8667
2023-03-16 14:47:31,059 WARNING  [*] Thu Mar 16 14:47:31 2023:   10    | Tr.loss: 0.738325 | Elapsed:   0.14   s | FPR 0.0003 -> TPR: 0.17 & F1: 0.29 | AUC: 0.8667
2023-03-16 14:47:31,059 WARNING  [*] Started epoch: 11
2023-03-16 14:47:31,171 WARNING  [*] 14:47:31: Train Epoch: 11 [  0  / 34   (0 %)] | Loss: 1.168118 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.3750 & F1 0.5455 | AUC 0.7667
2023-03-16 14:47:31,189 WARNING  [*] Thu Mar 16 14:47:31 2023:   11    | Tr.loss: 1.168118 | Elapsed:   0.13   s | FPR 0.0003 -> TPR: 0.38 & F1: 0.55 | AUC: 0.7667
2023-03-16 14:47:31,191 WARNING  [*] Started epoch: 12
2023-03-16 14:47:31,299 WARNING  [*] 14:47:31: Train Epoch: 12 [  0  / 34   (0 %)] | Loss: 0.422811 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.7500 & F1 0.8571 | AUC 0.9333
2023-03-16 14:47:31,321 WARNING  [*] Thu Mar 16 14:47:31 2023:   12    | Tr.loss: 0.422811 | Elapsed:   0.13   s | FPR 0.0003 -> TPR: 0.75 & F1: 0.86 | AUC: 0.9333
2023-03-16 14:47:31,323 WARNING  [*] Started epoch: 13
2023-03-16 14:47:31,421 WARNING  [*] 14:47:31: Train Epoch: 13 [  0  / 34   (0 %)] | Loss: 1.005156 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.6667 & F1 0.8000 | AUC 0.9000
2023-03-16 14:47:31,438 WARNING  [*] Thu Mar 16 14:47:31 2023:   13    | Tr.loss: 1.005156 | Elapsed:   0.12   s | FPR 0.0003 -> TPR: 0.67 & F1: 0.80 | AUC: 0.9000
2023-03-16 14:47:31,439 WARNING  [*] Started epoch: 14
2023-03-16 14:47:31,548 WARNING  [*] 14:47:31: Train Epoch: 14 [  0  / 34   (0 %)] | Loss: 0.699582 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.6250 & F1 0.7692 | AUC 0.8500
2023-03-16 14:47:31,568 WARNING  [*] Thu Mar 16 14:47:31 2023:   14    | Tr.loss: 0.699582 | Elapsed:   0.13   s | FPR 0.0003 -> TPR: 0.62 & F1: 0.77 | AUC: 0.8500
2023-03-16 14:47:31,569 WARNING  [*] Started epoch: 15
2023-03-16 14:47:31,686 WARNING  [*] 14:47:31: Train Epoch: 15 [  0  / 34   (0 %)] | Loss: 0.813794 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.3333 & F1 0.5000 | AUC 0.8542
2023-03-16 14:47:31,706 WARNING  [*] Thu Mar 16 14:47:31 2023:   15    | Tr.loss: 0.813794 | Elapsed:   0.14   s | FPR 0.0003 -> TPR: 0.33 & F1: 0.50 | AUC: 0.8542
2023-03-16 14:47:31,706 WARNING  [*] Started epoch: 16
2023-03-16 14:47:31,812 WARNING  [*] 14:47:31: Train Epoch: 16 [  0  / 34   (0 %)] | Loss: 0.886708 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.7500 & F1 0.8571 | AUC 0.8625
2023-03-16 14:47:31,831 WARNING  [*] Thu Mar 16 14:47:31 2023:   16    | Tr.loss: 0.886708 | Elapsed:   0.12   s | FPR 0.0003 -> TPR: 0.75 & F1: 0.86 | AUC: 0.8625
2023-03-16 14:47:31,831 WARNING  [*] Started epoch: 17
2023-03-16 14:47:31,926 WARNING  [*] 14:47:31: Train Epoch: 17 [  0  / 34   (0 %)] | Loss: 0.753978 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.5417 & F1 0.7027 | AUC 0.8458
2023-03-16 14:47:31,942 WARNING  [*] Thu Mar 16 14:47:31 2023:   17    | Tr.loss: 0.753978 | Elapsed:   0.11   s | FPR 0.0003 -> TPR: 0.54 & F1: 0.70 | AUC: 0.8458
2023-03-16 14:47:31,943 WARNING  [*] Started epoch: 18
2023-03-16 14:47:32,038 WARNING  [*] 14:47:32: Train Epoch: 18 [  0  / 34   (0 %)] | Loss: 0.841219 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.4583 & F1 0.6286 | AUC 0.8750
2023-03-16 14:47:32,055 WARNING  [*] Thu Mar 16 14:47:32 2023:   18    | Tr.loss: 0.841219 | Elapsed:   0.11   s | FPR 0.0003 -> TPR: 0.46 & F1: 0.63 | AUC: 0.8750
2023-03-16 14:47:32,056 WARNING  [*] Started epoch: 19
2023-03-16 14:47:32,159 WARNING  [*] 14:47:32: Train Epoch: 19 [  0  / 34   (0 %)] | Loss: 0.337927 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.7083 & F1 0.8293 | AUC 0.9458
2023-03-16 14:47:32,177 WARNING  [*] Thu Mar 16 14:47:32 2023:   19    | Tr.loss: 0.337927 | Elapsed:   0.12   s | FPR 0.0003 -> TPR: 0.71 & F1: 0.83 | AUC: 0.9458
2023-03-16 14:47:32,177 WARNING  [*] Started epoch: 20
2023-03-16 14:47:32,278 WARNING  [*] 14:47:32: Train Epoch: 20 [  0  / 34   (0 %)] | Loss: 0.268698 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.8750 & F1 0.9333 | AUC 0.9667
2023-03-16 14:47:32,296 WARNING  [*] Thu Mar 16 14:47:32 2023:   20    | Tr.loss: 0.268698 | Elapsed:   0.12   s | FPR 0.0003 -> TPR: 0.88 & F1: 0.93 | AUC: 0.9667
2023-03-16 14:47:32,297 WARNING  [*] Started epoch: 21
2023-03-16 14:47:32,401 WARNING  [*] 14:47:32: Train Epoch: 21 [  0  / 34   (0 %)] | Loss: 0.071100 | Elapsed: 0.09s | FPR 0.0003 -> TPR 1.0000 & F1 1.0000 | AUC 1.0000
2023-03-16 14:47:32,417 WARNING  [*] Thu Mar 16 14:47:32 2023:   21    | Tr.loss: 0.071100 | Elapsed:   0.12   s | FPR 0.0003 -> TPR: 1.00 & F1: 1.00 | AUC: 1.0000
2023-03-16 14:47:32,418 WARNING  [*] Started epoch: 22
2023-03-16 14:47:32,511 WARNING  [*] 14:47:32: Train Epoch: 22 [  0  / 34   (0 %)] | Loss: 0.392173 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.5417 & F1 0.7027 | AUC 0.9000
2023-03-16 14:47:32,511 WARNING  [!] Time budget exceeded, training stopped.
2023-03-16 14:47:32,551 WARNING  [!] Thu Mar 16 14:47:32 2023: Dumped results:
                model       : 1678974449-model.torch
		train time  : 1678974449-trainTime.npy
		train losses: 1678974449-trainLosses.npy
		train AUC   : 1678974449-auc.npy
		train F1s   : 1678974449-trainF1s.npy
		train TPRs  : 1678974449-trainTPRs.npy
2023-03-16 14:47:32,553 WARNING  [!] Evaluating model on training set...
2023-03-16 14:47:32,573 WARNING  [!] This fold metrics on training set:
2023-03-16 14:47:32,575 WARNING 	AUC: 0.9500
2023-03-16 14:47:32,578 WARNING 	FPR: 0.0001 | TPR: 0.8750 | F1: 0.9333
2023-03-16 14:47:32,582 WARNING 	FPR: 0.0003 | TPR: 0.8750 | F1: 0.9333
2023-03-16 14:47:32,585 WARNING 	FPR: 0.001 | TPR: 0.8750 | F1: 0.9333
2023-03-16 14:47:32,588 WARNING 	FPR: 0.003 | TPR: 0.8750 | F1: 0.9333
2023-03-16 14:47:32,591 WARNING 	FPR: 0.01 | TPR: 0.8750 | F1: 0.9333
2023-03-16 14:47:32,595 WARNING 	FPR: 0.03 | TPR: 0.8750 | F1: 0.9333
2023-03-16 14:47:32,598 WARNING 	FPR: 0.1 | TPR: 0.8750 | F1: 0.9333
2023-03-16 14:47:32,598 WARNING  [!] Evaluating model on validation set...
2023-03-16 14:47:32,616 WARNING  [!] This fold metrics on validation set:
2023-03-16 14:47:32,619 WARNING 	AUC: 0.6875
2023-03-16 14:47:32,622 WARNING 	FPR: 0.0001 | TPR: 0.2500 | F1: 0.4000
2023-03-16 14:47:32,625 WARNING 	FPR: 0.0003 | TPR: 0.2500 | F1: 0.4000
2023-03-16 14:47:32,628 WARNING 	FPR: 0.001 | TPR: 0.2500 | F1: 0.4000
2023-03-16 14:47:32,630 WARNING 	FPR: 0.003 | TPR: 0.2500 | F1: 0.4000
2023-03-16 14:47:32,633 WARNING 	FPR: 0.01 | TPR: 0.2500 | F1: 0.4000
2023-03-16 14:47:32,636 WARNING 	FPR: 0.03 | TPR: 0.2500 | F1: 0.4000
2023-03-16 14:47:32,638 WARNING 	FPR: 0.1 | TPR: 0.2500 | F1: 0.4000
2023-03-16 14:47:32,723 WARNING  [!] Metrics saved to out_tokenizer_1678974355\cv_bpe_lim50_r1763_t0.05\bpe_metrics_validation.json
2023-03-16 14:47:32,726 WARNING  [!] Metrics saved to out_tokenizer_1678974355\cv_bpe_lim50_r1763_t0.05\bpe_metrics_training.json
2023-03-16 14:47:32,727 WARNING  [!] Average epoch time: 0.00s | Mean values over 3 folds:
	AUC: 0.7181
	FPR: 0.0001 -- TPR: 0.2222 -- F1: 0.3619
	FPR: 0.0003 -- TPR: 0.2222 -- F1: 0.3619
	FPR:  0.001 -- TPR: 0.2222 -- F1: 0.3619
	FPR:  0.003 -- TPR: 0.2222 -- F1: 0.3619
	FPR:   0.01 -- TPR: 0.2222 -- F1: 0.3619
	FPR:   0.03 -- TPR: 0.2222 -- F1: 0.3619
	FPR:    0.1 -- TPR: 0.2222 -- F1: 0.3619

