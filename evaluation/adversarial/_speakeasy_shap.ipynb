{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "torch.set_grad_enabled(False)\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import sys\n",
    "sys.path.append('../..')\n",
    "from nebula.models.attention import TransformerEncoderModel, TransformerEncoderChunks\n",
    "from nebula import PEDynamicFeatureExtractor\n",
    "from nebula.preprocessing import JSONTokenizerNaive, JSONTokenizerBPE\n",
    "from nebula.misc import get_path, clear_cuda_cache, set_random_seed\n",
    "from nebula.constants import *\n",
    "from bertviz import model_view, head_view\n",
    "from collections import Counter\n",
    "\n",
    "from tqdm import tqdm\n",
    "DEVICE = \"cuda\"\n",
    "\n",
    "SCRIPT_PATH = get_path(type=\"notebook\")\n",
    "ROOT = os.path.join(SCRIPT_PATH, \"..\", \"..\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# done three folds on that run\n",
    "MODEL_IDX = 2\n",
    "\n",
    "# BPE\n",
    "# datafolder = os.path.join(ROOT, r\"evaluation\\paper_sota\\out_speakeasy\\nebula_speakeasy_vocab_50000_seqlen_512\")\n",
    "# model_folder = os.path.join(ROOT, r\"evaluation\\paper_sota\\out_speakeasy\\cv_nebula_limNone_r1763_t20\\training_files\")\n",
    "\n",
    "# Whitespace\n",
    "datafolder = os.path.join(ROOT, r\"evaluation\\paper_ablation\\out_tokenizer\\nebula_whitespace_vocab_50000_seqlen_512\")\n",
    "#model_folder = os.path.join(ROOT, r\"evaluation\\paper_ablation\\out_tokenizer\\cv_whitespace_limNone_r1763_t5\\training_files\")\n",
    "model_folder = os.path.join(ROOT, r\"evaluation\\crossValidation\\vocab50k_len512_ep6\\TransformerEncoderModel_1675286959\\training_files\")\n",
    "\n",
    "# LOADING OBJECTS\n",
    "model_file = [x for x in os.listdir(model_folder) if x.endswith(\".torch\")][MODEL_IDX]\n",
    "model_file_fullpath = os.path.join(model_folder, model_file)\n",
    "state_dict = torch.load(model_file_fullpath)\n",
    "\n",
    "with open(os.path.join(datafolder, f\"tokenizer_50000_vocab.json\")) as f:\n",
    "    nebula_vocab = json.load(f)\n",
    "\n",
    "# BPE\n",
    "# tokenizer = JSONTokenizerBPE(\n",
    "#     vocab_size=len(nebula_vocab),\n",
    "#     seq_len=512,\n",
    "#     model_path=os.path.join(ROOT, datafolder, r\"tokenizer_50000.model\")\n",
    "# )\n",
    "\n",
    "# Whitespace\n",
    "tokenizer = JSONTokenizerNaive(\n",
    "    vocab_size=len(nebula_vocab),\n",
    "    seq_len=512,\n",
    "    vocab=nebula_vocab\n",
    ")\n",
    "\n",
    "model_config = {\n",
    "        \"vocab_size\": 50002, #len(nebula_vocab),\n",
    "        \"maxlen\": 512,\n",
    "        #\"chunk_size\": 64,\n",
    "        \"dModel\": 64,  # embedding & transformer dimension\n",
    "        \"nHeads\": 8,  # number of heads in nn.MultiheadAttention\n",
    "        \"dHidden\": 256,  # dimension of the feedforward network model in nn.TransformerEncoder\n",
    "        \"nLayers\": 2,  # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
    "        \"numClasses\": 1, # binary classification\n",
    "        \"hiddenNeurons\": [64],\n",
    "        \"layerNorm\": False,\n",
    "        \"dropout\": 0.3,\n",
    "        #\"mean_over_sequence\": False,\n",
    "        \"norm_first\": True\n",
    "    }\n",
    "#model = TransformerEncoderChunks(**model_config)\n",
    "model = TransformerEncoderModel(**model_config)\n",
    "model.load_state_dict(state_dict)\n",
    "_ = model.to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 512])\n",
      "7.3782 | 0.9994\n"
     ]
    }
   ],
   "source": [
    "DEVICE = \"cpu\"\n",
    "import torch.nn as nn\n",
    "from copy import deepcopy\n",
    "import shap\n",
    "\n",
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "\n",
    "# build two models -- one for getting embed, other for SHAP (w/o embeddings)\n",
    "model = TransformerEncoderChunks(**model_config).to(DEVICE)\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "model_no_embed = deepcopy(model)\n",
    "model_no_embed.encoder = Identity()\n",
    "\n",
    "\n",
    "# load sample\n",
    "report_root = os.path.join(ROOT, r\"data\\data_raw\\windows_emulation_trainset\\report_backdoor\")\n",
    "exampleFile = os.path.join(report_root, \"0009064322cdc719a82317553b805cbbc64230a9212d3b8aad1ea1b78d3bf10a.json\")\n",
    "with open(exampleFile) as f:\n",
    "    exampleFile = json.load(f)\n",
    "\n",
    "extractor = PEDynamicFeatureExtractor()\n",
    "exampleProcessed = extractor.filter_and_normalize_report(exampleFile)\n",
    "exampleTokenized = tokenizer.tokenize(exampleProcessed)\n",
    "exampleEncoded = tokenizer.encode(exampleProcessed)\n",
    "x = tokenizer.pad_sequence(exampleEncoded)\n",
    "x = torch.Tensor(exampleEncoded).long().reshape(1,-1).to(DEVICE)\n",
    "print(x.shape)\n",
    "x_embed = model.encoder(x.long()).float()\n",
    "\n",
    "def analyze_feature_importance_shap(model, x):\n",
    "    explainer = shap.DeepExplainer(model, x)\n",
    "    shap_values = explainer.shap_values(x)\n",
    "    return shap_values\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def plot_shap(shap_values):\n",
    "    # plot\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.bar(range(len(shap_values)), shap_values)\n",
    "\n",
    "shap_values = analyze_feature_importance_shap(model_no_embed, x_embed.requires_grad_())\n",
    "#plot_shap(shap_values[0].mean(axis=1))\n",
    "\n",
    "model_no_embed.eval()\n",
    "logit = model_no_embed(x_embed.requires_grad_(False))[0][0]\n",
    "prob = float(torch.sigmoid(logit))\n",
    "print(f\"{logit:.4f} | {prob:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=float64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = shap_values[0]\n",
    "# return elements in a that are not 0\n",
    "a[a != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
