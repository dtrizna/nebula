01/29/2023 10:25:11 PM  [!] Starting uSize downsample 0.2 evaluation!
01/29/2023 10:25:12 PM  [!] Starting Masked Language Model evaluation over 3 splits!
01/29/2023 10:25:12 PM  [!] Loaded data and vocab. X train size: (76126, 512), X test size: (17407, 512), vocab size: 50002
01/29/2023 10:25:12 PM  [!] Initiating Self-Supervised Learning Pretraining
     Language Modeling MaskedLanguageModel
     Model TransformerEncoderLM with config:
	{'vocabSize': 50002, 'maxLen': 512, 'dModel': 64, 'nHeads': 8, 'dHidden': 256, 'nLayers': 2, 'numClasses': 1, 'hiddenNeurons': [64], 'dropout': 0.3}

01/30/2023 08:00:28 AM  [!] Starting uSize downsample 0.2 evaluation!
01/30/2023 08:00:29 AM  [!] Starting Masked Language Model evaluation over 3 splits!
01/30/2023 08:00:29 AM  [!] Loaded data and vocab. X train size: (76126, 512), X test size: (17407, 512), vocab size: 50002
01/30/2023 08:00:29 AM  [!] Initiating Self-Supervised Learning Pretraining
     Language Modeling MaskedLanguageModel
     Model TransformerEncoderLM with config:
	{'vocabSize': 50002, 'maxLen': 512, 'dModel': 64, 'nHeads': 8, 'dHidden': 256, 'nLayers': 2, 'numClasses': 1, 'hiddenNeurons': [64], 'dropout': 0.3}

01/30/2023 08:01:49 AM  [!] Starting uSize downsample 0.2 evaluation!
01/30/2023 08:01:50 AM  [!] Starting Masked Language Model evaluation over 3 splits!
01/30/2023 08:01:50 AM  [!] Loaded data and vocab. X train size: (76126, 512), X test size: (17407, 512), vocab size: 50002
01/30/2023 08:01:50 AM  [!] Initiating Self-Supervised Learning Pretraining
     Language Modeling MaskedLanguageModel
     Model TransformerEncoderLM with config:
	{'vocabSize': 50002, 'maxLen': 512, 'dModel': 64, 'nHeads': 8, 'dHidden': 256, 'nLayers': 2, 'numClasses': 1, 'hiddenNeurons': [64], 'dropout': 0.3}

01/30/2023 08:01:50 AM  [!] Running pre-training split 1/3
01/30/2023 08:01:51 AM  [!] Pre-training model...
01/30/2023 08:01:52 AM  [*] Masking sequences...
01/30/2023 08:01:56 AM  [*] Started epoch: 1
01/30/2023 08:02:00 AM  [*] Mon Jan 30 08:02:00 2023: Train Epoch: 1 [  0  /13702 (0 %)]	Loss: 444.511292 | Elapsed: 4.10s
01/30/2023 08:02:12 AM  [*] Mon Jan 30 08:02:12 2023: Train Epoch: 1 [6400 /13702 (47%)]	Loss: 228.260727 | Elapsed: 11.76s
01/30/2023 08:02:24 AM  [*] Mon Jan 30 08:02:24 2023: Train Epoch: 1 [12800/13702 (93%)]	Loss: 215.057373 | Elapsed: 11.83s
01/30/2023 08:02:26 AM  [*] Mon Jan 30 08:02:26 2023:    1    | Tr.loss: 231.138364 | Elapsed:   29.84  s
01/30/2023 08:02:26 AM  [*] Started epoch: 2
01/30/2023 08:02:26 AM  [*] Mon Jan 30 08:02:26 2023: Train Epoch: 2 [  0  /13702 (0 %)]	Loss: 195.421204 | Elapsed: 0.14s
01/30/2023 08:02:38 AM  [*] Mon Jan 30 08:02:38 2023: Train Epoch: 2 [6400 /13702 (47%)]	Loss: 212.853027 | Elapsed: 12.11s
01/30/2023 08:02:50 AM  [*] Mon Jan 30 08:02:50 2023: Train Epoch: 2 [12800/13702 (93%)]	Loss: 193.216476 | Elapsed: 12.01s
01/30/2023 08:02:52 AM  [*] Mon Jan 30 08:02:52 2023:    2    | Tr.loss: 206.287974 | Elapsed:   26.20  s
01/30/2023 08:02:52 AM  [*] Started epoch: 3
01/30/2023 08:02:52 AM  [*] Mon Jan 30 08:02:52 2023: Train Epoch: 3 [  0  /13702 (0 %)]	Loss: 197.908234 | Elapsed: 0.12s
01/30/2023 08:03:04 AM  [*] Mon Jan 30 08:03:04 2023: Train Epoch: 3 [6400 /13702 (47%)]	Loss: 217.539581 | Elapsed: 11.91s
01/30/2023 08:03:16 AM  [*] Mon Jan 30 08:03:16 2023: Train Epoch: 3 [12800/13702 (93%)]	Loss: 178.346710 | Elapsed: 12.06s
01/30/2023 08:03:18 AM  [*] Mon Jan 30 08:03:18 2023:    3    | Tr.loss: 196.413888 | Elapsed:   26.11  s
01/30/2023 08:03:18 AM  [*] Started epoch: 4
01/30/2023 08:03:18 AM  [*] Mon Jan 30 08:03:18 2023: Train Epoch: 4 [  0  /13702 (0 %)]	Loss: 196.073608 | Elapsed: 0.13s
01/30/2023 08:03:31 AM  [*] Mon Jan 30 08:03:31 2023: Train Epoch: 4 [6400 /13702 (47%)]	Loss: 195.964020 | Elapsed: 12.22s
01/30/2023 08:03:43 AM  [*] Mon Jan 30 08:03:43 2023: Train Epoch: 4 [12800/13702 (93%)]	Loss: 169.775574 | Elapsed: 12.19s
01/30/2023 08:03:45 AM  [*] Mon Jan 30 08:03:45 2023:    4    | Tr.loss: 190.600164 | Elapsed:   26.57  s
01/30/2023 08:03:45 AM  [*] Started epoch: 5
01/30/2023 08:03:45 AM  [*] Mon Jan 30 08:03:45 2023: Train Epoch: 5 [  0  /13702 (0 %)]	Loss: 176.374054 | Elapsed: 0.13s
01/30/2023 08:03:57 AM  [*] Mon Jan 30 08:03:57 2023: Train Epoch: 5 [6400 /13702 (47%)]	Loss: 197.727173 | Elapsed: 12.21s
01/30/2023 08:04:09 AM  [*] Mon Jan 30 08:04:09 2023: Train Epoch: 5 [12800/13702 (93%)]	Loss: 182.451553 | Elapsed: 12.26s
01/30/2023 08:04:11 AM  [*] Mon Jan 30 08:04:11 2023:    5    | Tr.loss: 186.871941 | Elapsed:   26.62  s
01/30/2023 08:04:11 AM  [*] Started epoch: 6
01/30/2023 08:04:12 AM  [*] Mon Jan 30 08:04:12 2023: Train Epoch: 6 [  0  /13702 (0 %)]	Loss: 176.735138 | Elapsed: 0.13s
01/30/2023 08:04:24 AM  [*] Mon Jan 30 08:04:24 2023: Train Epoch: 6 [6400 /13702 (47%)]	Loss: 199.542206 | Elapsed: 12.24s
01/30/2023 08:04:36 AM  [*] Mon Jan 30 08:04:36 2023: Train Epoch: 6 [12800/13702 (93%)]	Loss: 191.062057 | Elapsed: 12.21s
01/30/2023 08:04:38 AM  [*] Mon Jan 30 08:04:38 2023:    6    | Tr.loss: 184.491451 | Elapsed:   26.59  s
01/30/2023 08:04:38 AM  [*] Started epoch: 7
01/30/2023 08:04:38 AM  [*] Mon Jan 30 08:04:38 2023: Train Epoch: 7 [  0  /13702 (0 %)]	Loss: 182.254990 | Elapsed: 0.14s
01/30/2023 08:04:50 AM  [*] Mon Jan 30 08:04:50 2023: Train Epoch: 7 [6400 /13702 (47%)]	Loss: 179.361267 | Elapsed: 12.22s
01/30/2023 08:05:03 AM  [*] Mon Jan 30 08:05:03 2023: Train Epoch: 7 [12800/13702 (93%)]	Loss: 178.493546 | Elapsed: 12.18s
01/30/2023 08:05:05 AM  [*] Mon Jan 30 08:05:05 2023:    7    | Tr.loss: 182.977443 | Elapsed:   26.58  s
01/30/2023 08:05:05 AM  [*] Started epoch: 8
01/30/2023 08:05:05 AM  [*] Mon Jan 30 08:05:05 2023: Train Epoch: 8 [  0  /13702 (0 %)]	Loss: 194.940308 | Elapsed: 0.13s
01/30/2023 08:05:17 AM  [*] Mon Jan 30 08:05:17 2023: Train Epoch: 8 [6400 /13702 (47%)]	Loss: 192.495758 | Elapsed: 12.19s
01/30/2023 08:05:29 AM  [*] Mon Jan 30 08:05:29 2023: Train Epoch: 8 [12800/13702 (93%)]	Loss: 171.577744 | Elapsed: 12.30s
01/30/2023 08:05:31 AM  [*] Mon Jan 30 08:05:31 2023:    8    | Tr.loss: 181.485378 | Elapsed:   26.67  s
01/30/2023 08:05:31 AM  [*] Started epoch: 9
01/30/2023 08:05:31 AM  [*] Mon Jan 30 08:05:31 2023: Train Epoch: 9 [  0  /13702 (0 %)]	Loss: 182.273178 | Elapsed: 0.12s
01/30/2023 08:05:44 AM  [*] Mon Jan 30 08:05:44 2023: Train Epoch: 9 [6400 /13702 (47%)]	Loss: 195.536819 | Elapsed: 12.26s
01/30/2023 08:05:56 AM  [*] Mon Jan 30 08:05:56 2023: Train Epoch: 9 [12800/13702 (93%)]	Loss: 168.452515 | Elapsed: 12.27s
01/30/2023 08:05:58 AM  [*] Mon Jan 30 08:05:58 2023:    9    | Tr.loss: 180.137879 | Elapsed:   26.67  s
01/30/2023 08:05:58 AM  [*] Started epoch: 10
01/30/2023 08:05:58 AM  [*] Mon Jan 30 08:05:58 2023: Train Epoch: 10 [  0  /13702 (0 %)]	Loss: 176.688873 | Elapsed: 0.14s
01/30/2023 08:06:10 AM  [*] Mon Jan 30 08:06:10 2023: Train Epoch: 10 [6400 /13702 (47%)]	Loss: 176.745605 | Elapsed: 12.27s
01/30/2023 08:06:23 AM  [*] Mon Jan 30 08:06:23 2023: Train Epoch: 10 [12800/13702 (93%)]	Loss: 191.194733 | Elapsed: 12.20s
01/30/2023 08:06:25 AM  [*] Mon Jan 30 08:06:25 2023:   10    | Tr.loss: 179.391057 | Elapsed:   26.63  s
01/30/2023 08:06:25 AM [!] Mon Jan 30 08:06:25 2023: Dumped results:
                model     : 1675062385-model.torch
		train time: 1675062385-trainTime.npy
		train losses: 1675062385-trainLosses.npy
		train AUC: 1675062385-auc.npy
01/30/2023 08:06:25 AM  [!] Training pretrained model on downstream task...
01/30/2023 08:06:25 AM  [*] Started epoch: 1
01/30/2023 08:06:25 AM  [*] Mon Jan 30 08:06:25 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 1.705306 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.0541 & F1 0.1026 | AUC 0.6106
01/30/2023 08:06:35 AM  [*] Mon Jan 30 08:06:35 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.363977 | Elapsed: 9.09s | FPR 0.0003 -> TPR 0.4915 & F1 0.6591 | AUC 0.9378
01/30/2023 08:06:36 AM  [*] Mon Jan 30 08:06:36 2023:    1    | Tr.loss: 0.499107 | Elapsed:   10.96  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8034
01/30/2023 08:06:36 AM  [*] Started epoch: 2
01/30/2023 08:06:36 AM  [*] Mon Jan 30 08:06:36 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.298415 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.7111 & F1 0.8312 | AUC 0.9228
01/30/2023 08:06:45 AM  [*] Mon Jan 30 08:06:45 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.249785 | Elapsed: 9.04s | FPR 0.0003 -> TPR 0.3288 & F1 0.4948 | AUC 0.9498
01/30/2023 08:06:47 AM  [*] Mon Jan 30 08:06:47 2023:    2    | Tr.loss: 0.353484 | Elapsed:   10.91  s | FPR 0.0003 -> TPR: 0.18 & F1: 0.31 | AUC: 0.9032
01/30/2023 08:06:47 AM  [*] Started epoch: 3
01/30/2023 08:06:47 AM  [*] Mon Jan 30 08:06:47 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.391008 | Elapsed: 0.11s | FPR 0.0003 -> TPR 0.6216 & F1 0.7667 | AUC 0.9009
01/30/2023 08:06:56 AM  [*] Mon Jan 30 08:06:56 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.259092 | Elapsed: 9.05s | FPR 0.0003 -> TPR 0.5000 & F1 0.6667 | AUC 0.9592
01/30/2023 08:06:58 AM  [*] Mon Jan 30 08:06:58 2023:    3    | Tr.loss: 0.292040 | Elapsed:   10.99  s | FPR 0.0003 -> TPR: 0.22 & F1: 0.36 | AUC: 0.9388
01/30/2023 08:06:59 AM [!] Mon Jan 30 08:06:59 2023: Dumped results:
                model     : 1675062418-model.torch
		train time: 1675062418-trainTime.npy
		train losses: 1675062418-trainLosses.npy
		train AUC: 1675062418-auc.npy
		train F1s : 1675062418-trainF1s.npy
		train TPRs: 1675062418-trainTPRs.npy
01/30/2023 08:06:59 AM  [!] Training non_pretrained model on downstream task...
01/30/2023 08:06:59 AM  [*] Started epoch: 1
01/30/2023 08:06:59 AM  [*] Mon Jan 30 08:06:59 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 1.530491 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.4384
01/30/2023 08:07:05 AM  [*] Mon Jan 30 08:07:05 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.398725 | Elapsed: 6.15s | FPR 0.0003 -> TPR 0.3200 & F1 0.4848 | AUC 0.8128
01/30/2023 08:07:07 AM  [*] Mon Jan 30 08:07:07 2023:    1    | Tr.loss: 0.550629 | Elapsed:   7.49   s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7672
01/30/2023 08:07:07 AM  [*] Started epoch: 2
01/30/2023 08:07:07 AM  [*] Mon Jan 30 08:07:07 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.507245 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.2553 & F1 0.4068 | AUC 0.8436
01/30/2023 08:07:13 AM  [*] Mon Jan 30 08:07:13 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.400548 | Elapsed: 6.14s | FPR 0.0003 -> TPR 0.3433 & F1 0.5111 | AUC 0.9095
01/30/2023 08:07:14 AM  [*] Mon Jan 30 08:07:14 2023:    2    | Tr.loss: 0.369684 | Elapsed:   7.49   s | FPR 0.0003 -> TPR: 0.07 & F1: 0.14 | AUC: 0.8908
01/30/2023 08:07:14 AM  [*] Started epoch: 3
01/30/2023 08:07:14 AM  [*] Mon Jan 30 08:07:14 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.278593 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.4894 & F1 0.6571 | AUC 0.9274
01/30/2023 08:07:20 AM  [*] Mon Jan 30 08:07:20 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.358509 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.5077 & F1 0.6735 | AUC 0.8593
01/30/2023 08:07:22 AM  [*] Mon Jan 30 08:07:22 2023:    3    | Tr.loss: 0.313773 | Elapsed:   7.56   s | FPR 0.0003 -> TPR: 0.22 & F1: 0.36 | AUC: 0.9244
01/30/2023 08:07:22 AM [!] Mon Jan 30 08:07:22 2023: Dumped results:
                model     : 1675062442-model.torch
		train time: 1675062442-trainTime.npy
		train losses: 1675062442-trainLosses.npy
		train AUC: 1675062442-auc.npy
		train F1s : 1675062442-trainF1s.npy
		train TPRs: 1675062442-trainTPRs.npy
01/30/2023 08:07:22 AM  [*] Evaluating pretrained model on test set...
01/30/2023 08:07:27 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0231 | F1: 0.0451
01/30/2023 08:07:27 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1102 | F1: 0.1984
01/30/2023 08:07:27 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.2526 | F1: 0.4030
01/30/2023 08:07:27 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.2983 | F1: 0.4586
01/30/2023 08:07:27 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3996 | F1: 0.5675
01/30/2023 08:07:27 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4624 | F1: 0.6215
01/30/2023 08:07:27 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.6525 | F1: 0.7510
01/30/2023 08:07:27 AM  [*] Evaluating non_pretrained model on test set...
01/30/2023 08:07:32 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0016 | F1: 0.0032
01/30/2023 08:07:32 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1144 | F1: 0.2053
01/30/2023 08:07:32 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.1718 | F1: 0.2929
01/30/2023 08:07:32 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.2396 | F1: 0.3858
01/30/2023 08:07:32 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3244 | F1: 0.4867
01/30/2023 08:07:32 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4113 | F1: 0.5725
01/30/2023 08:07:32 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.5746 | F1: 0.6924
01/30/2023 08:07:32 AM  [!] Running pre-training split 2/3
01/30/2023 08:07:33 AM  [!] Pre-training model...
01/30/2023 08:07:34 AM  [*] Masking sequences...
01/30/2023 08:07:38 AM  [*] Started epoch: 1
01/30/2023 08:07:38 AM  [*] Mon Jan 30 08:07:38 2023: Train Epoch: 1 [  0  /13702 (0 %)]	Loss: 415.376831 | Elapsed: 0.29s
01/30/2023 08:07:51 AM  [*] Mon Jan 30 08:07:51 2023: Train Epoch: 1 [6400 /13702 (47%)]	Loss: 211.483719 | Elapsed: 12.43s
01/30/2023 08:08:03 AM  [*] Mon Jan 30 08:08:03 2023: Train Epoch: 1 [12800/13702 (93%)]	Loss: 235.633774 | Elapsed: 12.27s
01/30/2023 08:08:05 AM  [*] Mon Jan 30 08:08:05 2023:    1    | Tr.loss: 232.156498 | Elapsed:   27.00  s
01/30/2023 08:08:05 AM  [*] Started epoch: 2
01/30/2023 08:08:05 AM  [*] Mon Jan 30 08:08:05 2023: Train Epoch: 2 [  0  /13702 (0 %)]	Loss: 207.659027 | Elapsed: 0.13s
01/30/2023 08:08:17 AM  [*] Mon Jan 30 08:08:17 2023: Train Epoch: 2 [6400 /13702 (47%)]	Loss: 236.806274 | Elapsed: 12.32s
01/30/2023 08:08:30 AM  [*] Mon Jan 30 08:08:30 2023: Train Epoch: 2 [12800/13702 (93%)]	Loss: 222.565765 | Elapsed: 12.42s
01/30/2023 08:08:32 AM  [*] Mon Jan 30 08:08:32 2023:    2    | Tr.loss: 208.024113 | Elapsed:   26.95  s
01/30/2023 08:08:32 AM  [*] Started epoch: 3
01/30/2023 08:08:32 AM  [*] Mon Jan 30 08:08:32 2023: Train Epoch: 3 [  0  /13702 (0 %)]	Loss: 199.576248 | Elapsed: 0.14s
01/30/2023 08:08:44 AM  [*] Mon Jan 30 08:08:44 2023: Train Epoch: 3 [6400 /13702 (47%)]	Loss: 217.220520 | Elapsed: 12.40s
01/30/2023 08:08:57 AM  [*] Mon Jan 30 08:08:57 2023: Train Epoch: 3 [12800/13702 (93%)]	Loss: 203.570572 | Elapsed: 12.41s
01/30/2023 08:08:59 AM  [*] Mon Jan 30 08:08:59 2023:    3    | Tr.loss: 197.658240 | Elapsed:   27.05  s
01/30/2023 08:08:59 AM  [*] Started epoch: 4
01/30/2023 08:08:59 AM  [*] Mon Jan 30 08:08:59 2023: Train Epoch: 4 [  0  /13702 (0 %)]	Loss: 183.676300 | Elapsed: 0.14s
01/30/2023 08:09:12 AM  [*] Mon Jan 30 08:09:12 2023: Train Epoch: 4 [6400 /13702 (47%)]	Loss: 181.885284 | Elapsed: 12.50s
01/30/2023 08:09:24 AM  [*] Mon Jan 30 08:09:24 2023: Train Epoch: 4 [12800/13702 (93%)]	Loss: 184.824371 | Elapsed: 12.48s
01/30/2023 08:09:26 AM  [*] Mon Jan 30 08:09:26 2023:    4    | Tr.loss: 191.363887 | Elapsed:   27.18  s
01/30/2023 08:09:26 AM  [*] Started epoch: 5
01/30/2023 08:09:26 AM  [*] Mon Jan 30 08:09:26 2023: Train Epoch: 5 [  0  /13702 (0 %)]	Loss: 208.978943 | Elapsed: 0.14s
01/30/2023 08:09:39 AM  [*] Mon Jan 30 08:09:39 2023: Train Epoch: 5 [6400 /13702 (47%)]	Loss: 167.343842 | Elapsed: 12.45s
01/30/2023 08:09:51 AM  [*] Mon Jan 30 08:09:51 2023: Train Epoch: 5 [12800/13702 (93%)]	Loss: 191.707672 | Elapsed: 12.46s
01/30/2023 08:09:53 AM  [*] Mon Jan 30 08:09:53 2023:    5    | Tr.loss: 186.905783 | Elapsed:   27.10  s
01/30/2023 08:09:53 AM  [*] Started epoch: 6
01/30/2023 08:09:53 AM  [*] Mon Jan 30 08:09:53 2023: Train Epoch: 6 [  0  /13702 (0 %)]	Loss: 200.104050 | Elapsed: 0.12s
01/30/2023 08:10:06 AM  [*] Mon Jan 30 08:10:06 2023: Train Epoch: 6 [6400 /13702 (47%)]	Loss: 204.879379 | Elapsed: 12.44s
01/30/2023 08:10:18 AM  [*] Mon Jan 30 08:10:18 2023: Train Epoch: 6 [12800/13702 (93%)]	Loss: 192.919739 | Elapsed: 12.50s
01/30/2023 08:10:20 AM  [*] Mon Jan 30 08:10:20 2023:    6    | Tr.loss: 183.873898 | Elapsed:   27.20  s
01/30/2023 08:10:20 AM  [*] Started epoch: 7
01/30/2023 08:10:21 AM  [*] Mon Jan 30 08:10:21 2023: Train Epoch: 7 [  0  /13702 (0 %)]	Loss: 176.557922 | Elapsed: 0.13s
01/30/2023 08:10:33 AM  [*] Mon Jan 30 08:10:33 2023: Train Epoch: 7 [6400 /13702 (47%)]	Loss: 189.569397 | Elapsed: 12.51s
01/30/2023 08:10:45 AM  [*] Mon Jan 30 08:10:45 2023: Train Epoch: 7 [12800/13702 (93%)]	Loss: 178.509460 | Elapsed: 12.38s
01/30/2023 08:10:48 AM  [*] Mon Jan 30 08:10:48 2023:    7    | Tr.loss: 181.881220 | Elapsed:   27.11  s
01/30/2023 08:10:48 AM  [*] Started epoch: 8
01/30/2023 08:10:48 AM  [*] Mon Jan 30 08:10:48 2023: Train Epoch: 8 [  0  /13702 (0 %)]	Loss: 176.525360 | Elapsed: 0.13s
01/30/2023 08:11:00 AM  [*] Mon Jan 30 08:11:00 2023: Train Epoch: 8 [6400 /13702 (47%)]	Loss: 182.827301 | Elapsed: 12.41s
01/30/2023 08:11:12 AM  [*] Mon Jan 30 08:11:12 2023: Train Epoch: 8 [12800/13702 (93%)]	Loss: 179.672699 | Elapsed: 12.38s
01/30/2023 08:11:15 AM  [*] Mon Jan 30 08:11:15 2023:    8    | Tr.loss: 179.919868 | Elapsed:   26.98  s
01/30/2023 08:11:15 AM  [*] Started epoch: 9
01/30/2023 08:11:15 AM  [*] Mon Jan 30 08:11:15 2023: Train Epoch: 9 [  0  /13702 (0 %)]	Loss: 167.559418 | Elapsed: 0.12s
01/30/2023 08:11:27 AM  [*] Mon Jan 30 08:11:27 2023: Train Epoch: 9 [6400 /13702 (47%)]	Loss: 193.405731 | Elapsed: 12.34s
01/30/2023 08:11:40 AM  [*] Mon Jan 30 08:11:40 2023: Train Epoch: 9 [12800/13702 (93%)]	Loss: 182.237061 | Elapsed: 12.52s
01/30/2023 08:11:42 AM  [*] Mon Jan 30 08:11:42 2023:    9    | Tr.loss: 179.155319 | Elapsed:   27.02  s
01/30/2023 08:11:42 AM  [*] Started epoch: 10
01/30/2023 08:11:42 AM  [*] Mon Jan 30 08:11:42 2023: Train Epoch: 10 [  0  /13702 (0 %)]	Loss: 195.270782 | Elapsed: 0.14s
01/30/2023 08:11:54 AM  [*] Mon Jan 30 08:11:54 2023: Train Epoch: 10 [6400 /13702 (47%)]	Loss: 182.483124 | Elapsed: 12.54s
01/30/2023 08:12:07 AM  [*] Mon Jan 30 08:12:07 2023: Train Epoch: 10 [12800/13702 (93%)]	Loss: 176.934296 | Elapsed: 12.47s
01/30/2023 08:12:09 AM  [*] Mon Jan 30 08:12:09 2023:   10    | Tr.loss: 178.004826 | Elapsed:   27.51  s
01/30/2023 08:12:10 AM [!] Mon Jan 30 08:12:10 2023: Dumped results:
                model     : 1675062729-model.torch
		train time: 1675062729-trainTime.npy
		train losses: 1675062729-trainLosses.npy
		train AUC: 1675062729-auc.npy
01/30/2023 08:12:10 AM  [!] Training pretrained model on downstream task...
01/30/2023 08:12:10 AM  [*] Started epoch: 1
01/30/2023 08:12:10 AM  [*] Mon Jan 30 08:12:10 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 2.439466 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.4621
01/30/2023 08:12:20 AM  [*] Mon Jan 30 08:12:20 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.424481 | Elapsed: 9.40s | FPR 0.0003 -> TPR 0.3600 & F1 0.5294 | AUC 0.7611
01/30/2023 08:12:21 AM  [*] Mon Jan 30 08:12:21 2023:    1    | Tr.loss: 0.486891 | Elapsed:   11.36  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8140
01/30/2023 08:12:21 AM  [*] Started epoch: 2
01/30/2023 08:12:21 AM  [*] Mon Jan 30 08:12:21 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.310406 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.5000 & F1 0.6667 | AUC 0.8750
01/30/2023 08:12:31 AM  [*] Mon Jan 30 08:12:31 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.344172 | Elapsed: 9.22s | FPR 0.0003 -> TPR 0.3077 & F1 0.4706 | AUC 0.9015
01/30/2023 08:12:33 AM  [*] Mon Jan 30 08:12:33 2023:    2    | Tr.loss: 0.352117 | Elapsed:   11.17  s | FPR 0.0003 -> TPR: 0.14 & F1: 0.24 | AUC: 0.9051
01/30/2023 08:12:33 AM  [*] Started epoch: 3
01/30/2023 08:12:33 AM  [*] Mon Jan 30 08:12:33 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.271036 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.6170 & F1 0.7632 | AUC 0.9349
01/30/2023 08:12:42 AM  [*] Mon Jan 30 08:12:42 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.322995 | Elapsed: 9.08s | FPR 0.0003 -> TPR 0.5606 & F1 0.7184 | AUC 0.9418
01/30/2023 08:12:44 AM  [*] Mon Jan 30 08:12:44 2023:    3    | Tr.loss: 0.300471 | Elapsed:   10.99  s | FPR 0.0003 -> TPR: 0.18 & F1: 0.30 | AUC: 0.9325
01/30/2023 08:12:44 AM [!] Mon Jan 30 08:12:44 2023: Dumped results:
                model     : 1675062764-model.torch
		train time: 1675062764-trainTime.npy
		train losses: 1675062764-trainLosses.npy
		train AUC: 1675062764-auc.npy
		train F1s : 1675062764-trainF1s.npy
		train TPRs: 1675062764-trainTPRs.npy
01/30/2023 08:12:44 AM  [!] Training non_pretrained model on downstream task...
01/30/2023 08:12:44 AM  [*] Started epoch: 1
01/30/2023 08:12:45 AM  [*] Mon Jan 30 08:12:45 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 1.876796 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0714 & F1 0.1333 | AUC 0.5639
01/30/2023 08:12:51 AM  [*] Mon Jan 30 08:12:51 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.427591 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.3065 & F1 0.4691 | AUC 0.8735
01/30/2023 08:12:52 AM  [*] Mon Jan 30 08:12:52 2023:    1    | Tr.loss: 0.574853 | Elapsed:   7.58   s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7538
01/30/2023 08:12:52 AM  [*] Started epoch: 2
01/30/2023 08:12:52 AM  [*] Mon Jan 30 08:12:52 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.378528 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.4250 & F1 0.5965 | AUC 0.9031
01/30/2023 08:12:58 AM  [*] Mon Jan 30 08:12:58 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.362130 | Elapsed: 6.27s | FPR 0.0003 -> TPR 0.5139 & F1 0.6789 | AUC 0.9177
01/30/2023 08:13:00 AM  [*] Mon Jan 30 08:13:00 2023:    2    | Tr.loss: 0.377694 | Elapsed:   7.61   s | FPR 0.0003 -> TPR: 0.11 & F1: 0.20 | AUC: 0.8860
01/30/2023 08:13:00 AM  [*] Started epoch: 3
01/30/2023 08:13:00 AM  [*] Mon Jan 30 08:13:00 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.280424 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.7250 & F1 0.8406 | AUC 0.9521
01/30/2023 08:13:06 AM  [*] Mon Jan 30 08:13:06 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.198531 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.6000 & F1 0.7500 | AUC 0.9648
01/30/2023 08:13:07 AM  [*] Mon Jan 30 08:13:07 2023:    3    | Tr.loss: 0.314254 | Elapsed:   7.59   s | FPR 0.0003 -> TPR: 0.13 & F1: 0.23 | AUC: 0.9239
01/30/2023 08:13:08 AM [!] Mon Jan 30 08:13:08 2023: Dumped results:
                model     : 1675062787-model.torch
		train time: 1675062787-trainTime.npy
		train losses: 1675062787-trainLosses.npy
		train AUC: 1675062787-auc.npy
		train F1s : 1675062787-trainF1s.npy
		train TPRs: 1675062787-trainTPRs.npy
01/30/2023 08:13:08 AM  [*] Evaluating pretrained model on test set...
01/30/2023 08:13:13 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0642 | F1: 0.1207
01/30/2023 08:13:13 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1210 | F1: 0.2159
01/30/2023 08:13:13 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.2710 | F1: 0.4261
01/30/2023 08:13:13 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3075 | F1: 0.4694
01/30/2023 08:13:13 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3791 | F1: 0.5464
01/30/2023 08:13:13 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4903 | F1: 0.6469
01/30/2023 08:13:13 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.6771 | F1: 0.7685
01/30/2023 08:13:13 AM  [*] Evaluating non_pretrained model on test set...
01/30/2023 08:13:18 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0400 | F1: 0.0769
01/30/2023 08:13:18 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1199 | F1: 0.2140
01/30/2023 08:13:18 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.1647 | F1: 0.2827
01/30/2023 08:13:18 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.1966 | F1: 0.3280
01/30/2023 08:13:18 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3042 | F1: 0.4634
01/30/2023 08:13:18 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4243 | F1: 0.5854
01/30/2023 08:13:18 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.5770 | F1: 0.6944
01/30/2023 08:13:18 AM  [!] Running pre-training split 3/3
01/30/2023 08:13:19 AM  [!] Pre-training model...
01/30/2023 08:13:19 AM  [*] Masking sequences...
01/30/2023 08:13:23 AM  [*] Started epoch: 1
01/30/2023 08:13:24 AM  [*] Mon Jan 30 08:13:24 2023: Train Epoch: 1 [  0  /13702 (0 %)]	Loss: 375.661865 | Elapsed: 0.47s
01/30/2023 08:13:36 AM  [*] Mon Jan 30 08:13:36 2023: Train Epoch: 1 [6400 /13702 (47%)]	Loss: 228.862579 | Elapsed: 12.21s
01/30/2023 08:13:48 AM  [*] Mon Jan 30 08:13:48 2023: Train Epoch: 1 [12800/13702 (93%)]	Loss: 219.997604 | Elapsed: 12.29s
01/30/2023 08:13:50 AM  [*] Mon Jan 30 08:13:50 2023:    1    | Tr.loss: 231.528030 | Elapsed:   27.00  s
01/30/2023 08:13:50 AM  [*] Started epoch: 2
01/30/2023 08:13:50 AM  [*] Mon Jan 30 08:13:50 2023: Train Epoch: 2 [  0  /13702 (0 %)]	Loss: 212.598022 | Elapsed: 0.14s
01/30/2023 08:14:03 AM  [*] Mon Jan 30 08:14:03 2023: Train Epoch: 2 [6400 /13702 (47%)]	Loss: 212.364761 | Elapsed: 12.25s
01/30/2023 08:14:15 AM  [*] Mon Jan 30 08:14:15 2023: Train Epoch: 2 [12800/13702 (93%)]	Loss: 211.506836 | Elapsed: 12.27s
01/30/2023 08:14:17 AM  [*] Mon Jan 30 08:14:17 2023:    2    | Tr.loss: 210.490619 | Elapsed:   26.72  s
01/30/2023 08:14:17 AM  [*] Started epoch: 3
01/30/2023 08:14:17 AM  [*] Mon Jan 30 08:14:17 2023: Train Epoch: 3 [  0  /13702 (0 %)]	Loss: 209.922638 | Elapsed: 0.14s
01/30/2023 08:14:30 AM  [*] Mon Jan 30 08:14:30 2023: Train Epoch: 3 [6400 /13702 (47%)]	Loss: 202.110931 | Elapsed: 12.38s
01/30/2023 08:14:42 AM  [*] Mon Jan 30 08:14:42 2023: Train Epoch: 3 [12800/13702 (93%)]	Loss: 204.994995 | Elapsed: 12.28s
01/30/2023 08:14:44 AM  [*] Mon Jan 30 08:14:44 2023:    3    | Tr.loss: 202.057594 | Elapsed:   26.88  s
01/30/2023 08:14:44 AM  [*] Started epoch: 4
01/30/2023 08:14:44 AM  [*] Mon Jan 30 08:14:44 2023: Train Epoch: 4 [  0  /13702 (0 %)]	Loss: 177.016144 | Elapsed: 0.15s
01/30/2023 08:14:56 AM  [*] Mon Jan 30 08:14:56 2023: Train Epoch: 4 [6400 /13702 (47%)]	Loss: 196.085815 | Elapsed: 12.27s
01/30/2023 08:15:09 AM  [*] Mon Jan 30 08:15:09 2023: Train Epoch: 4 [12800/13702 (93%)]	Loss: 176.624710 | Elapsed: 12.27s
01/30/2023 08:15:11 AM  [*] Mon Jan 30 08:15:11 2023:    4    | Tr.loss: 195.429672 | Elapsed:   26.73  s
01/30/2023 08:15:11 AM  [*] Started epoch: 5
01/30/2023 08:15:11 AM  [*] Mon Jan 30 08:15:11 2023: Train Epoch: 5 [  0  /13702 (0 %)]	Loss: 215.231247 | Elapsed: 0.12s
01/30/2023 08:15:23 AM  [*] Mon Jan 30 08:15:23 2023: Train Epoch: 5 [6400 /13702 (47%)]	Loss: 199.721680 | Elapsed: 12.34s
01/30/2023 08:15:35 AM  [*] Mon Jan 30 08:15:35 2023: Train Epoch: 5 [12800/13702 (93%)]	Loss: 183.807800 | Elapsed: 12.31s
01/30/2023 08:15:38 AM  [*] Mon Jan 30 08:15:38 2023:    5    | Tr.loss: 190.913586 | Elapsed:   26.98  s
01/30/2023 08:15:38 AM  [*] Started epoch: 6
01/30/2023 08:15:38 AM  [*] Mon Jan 30 08:15:38 2023: Train Epoch: 6 [  0  /13702 (0 %)]	Loss: 207.895081 | Elapsed: 0.13s
01/30/2023 08:15:50 AM  [*] Mon Jan 30 08:15:50 2023: Train Epoch: 6 [6400 /13702 (47%)]	Loss: 191.763824 | Elapsed: 12.38s
01/30/2023 08:16:03 AM  [*] Mon Jan 30 08:16:03 2023: Train Epoch: 6 [12800/13702 (93%)]	Loss: 158.500122 | Elapsed: 12.51s
01/30/2023 08:16:05 AM  [*] Mon Jan 30 08:16:05 2023:    6    | Tr.loss: 188.198098 | Elapsed:   27.07  s
01/30/2023 08:16:05 AM  [*] Started epoch: 7
01/30/2023 08:16:05 AM  [*] Mon Jan 30 08:16:05 2023: Train Epoch: 7 [  0  /13702 (0 %)]	Loss: 192.043655 | Elapsed: 0.14s
01/30/2023 08:16:17 AM  [*] Mon Jan 30 08:16:17 2023: Train Epoch: 7 [6400 /13702 (47%)]	Loss: 180.083466 | Elapsed: 12.33s
01/30/2023 08:16:29 AM  [*] Mon Jan 30 08:16:29 2023: Train Epoch: 7 [12800/13702 (93%)]	Loss: 177.509811 | Elapsed: 12.30s
01/30/2023 08:16:32 AM  [*] Mon Jan 30 08:16:32 2023:    7    | Tr.loss: 186.257089 | Elapsed:   26.85  s
01/30/2023 08:16:32 AM  [*] Started epoch: 8
01/30/2023 08:16:32 AM  [*] Mon Jan 30 08:16:32 2023: Train Epoch: 8 [  0  /13702 (0 %)]	Loss: 194.890564 | Elapsed: 0.12s
01/30/2023 08:16:44 AM  [*] Mon Jan 30 08:16:44 2023: Train Epoch: 8 [6400 /13702 (47%)]	Loss: 206.361816 | Elapsed: 12.35s
01/30/2023 08:16:56 AM  [*] Mon Jan 30 08:16:56 2023: Train Epoch: 8 [12800/13702 (93%)]	Loss: 180.774811 | Elapsed: 12.23s
01/30/2023 08:16:58 AM  [*] Mon Jan 30 08:16:58 2023:    8    | Tr.loss: 184.360147 | Elapsed:   26.74  s
01/30/2023 08:16:58 AM  [*] Started epoch: 9
01/30/2023 08:16:58 AM  [*] Mon Jan 30 08:16:58 2023: Train Epoch: 9 [  0  /13702 (0 %)]	Loss: 180.134445 | Elapsed: 0.13s
01/30/2023 08:17:11 AM  [*] Mon Jan 30 08:17:11 2023: Train Epoch: 9 [6400 /13702 (47%)]	Loss: 166.568207 | Elapsed: 12.32s
01/30/2023 08:17:23 AM  [*] Mon Jan 30 08:17:23 2023: Train Epoch: 9 [12800/13702 (93%)]	Loss: 207.898621 | Elapsed: 12.30s
01/30/2023 08:17:25 AM  [*] Mon Jan 30 08:17:25 2023:    9    | Tr.loss: 182.504118 | Elapsed:   26.81  s
01/30/2023 08:17:25 AM  [*] Started epoch: 10
01/30/2023 08:17:25 AM  [*] Mon Jan 30 08:17:25 2023: Train Epoch: 10 [  0  /13702 (0 %)]	Loss: 180.064194 | Elapsed: 0.13s
01/30/2023 08:17:38 AM  [*] Mon Jan 30 08:17:38 2023: Train Epoch: 10 [6400 /13702 (47%)]	Loss: 201.355789 | Elapsed: 12.35s
01/30/2023 08:17:50 AM  [*] Mon Jan 30 08:17:50 2023: Train Epoch: 10 [12800/13702 (93%)]	Loss: 169.434570 | Elapsed: 12.32s
01/30/2023 08:17:52 AM  [*] Mon Jan 30 08:17:52 2023:   10    | Tr.loss: 181.618239 | Elapsed:   26.94  s
01/30/2023 08:17:52 AM [!] Mon Jan 30 08:17:52 2023: Dumped results:
                model     : 1675063072-model.torch
		train time: 1675063072-trainTime.npy
		train losses: 1675063072-trainLosses.npy
		train AUC: 1675063072-auc.npy
01/30/2023 08:17:53 AM  [!] Training pretrained model on downstream task...
01/30/2023 08:17:53 AM  [*] Started epoch: 1
01/30/2023 08:17:53 AM  [*] Mon Jan 30 08:17:53 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 3.090020 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.2425
01/30/2023 08:18:02 AM  [*] Mon Jan 30 08:18:02 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.410127 | Elapsed: 9.10s | FPR 0.0003 -> TPR 0.3810 & F1 0.5517 | AUC 0.8910
01/30/2023 08:18:04 AM  [*] Mon Jan 30 08:18:04 2023:    1    | Tr.loss: 0.595870 | Elapsed:   10.99  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7548
01/30/2023 08:18:04 AM  [*] Started epoch: 2
01/30/2023 08:18:04 AM  [*] Mon Jan 30 08:18:04 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.382887 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.3404 & F1 0.5079 | AUC 0.8855
01/30/2023 08:18:13 AM  [*] Mon Jan 30 08:18:13 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.455015 | Elapsed: 9.03s | FPR 0.0003 -> TPR 0.3636 & F1 0.5333 | AUC 0.8739
01/30/2023 08:18:15 AM  [*] Mon Jan 30 08:18:15 2023:    2    | Tr.loss: 0.384471 | Elapsed:   10.96  s | FPR 0.0003 -> TPR: 0.12 & F1: 0.21 | AUC: 0.8854
01/30/2023 08:18:15 AM  [*] Started epoch: 3
01/30/2023 08:18:15 AM  [*] Mon Jan 30 08:18:15 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.285793 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.6053 & F1 0.7541 | AUC 0.9474
01/30/2023 08:18:24 AM  [*] Mon Jan 30 08:18:24 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.288576 | Elapsed: 9.04s | FPR 0.0003 -> TPR 0.7313 & F1 0.8448 | AUC 0.9502
01/30/2023 08:18:26 AM  [*] Mon Jan 30 08:18:26 2023:    3    | Tr.loss: 0.319865 | Elapsed:   10.93  s | FPR 0.0003 -> TPR: 0.17 & F1: 0.29 | AUC: 0.9241
01/30/2023 08:18:26 AM [!] Mon Jan 30 08:18:26 2023: Dumped results:
                model     : 1675063106-model.torch
		train time: 1675063106-trainTime.npy
		train losses: 1675063106-trainLosses.npy
		train AUC: 1675063106-auc.npy
		train F1s : 1675063106-trainF1s.npy
		train TPRs: 1675063106-trainTPRs.npy
01/30/2023 08:18:26 AM  [!] Training non_pretrained model on downstream task...
01/30/2023 08:18:27 AM  [*] Started epoch: 1
01/30/2023 08:18:27 AM  [*] Mon Jan 30 08:18:27 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 3.156840 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.0204 & F1 0.0400 | AUC 0.3946
01/30/2023 08:18:33 AM  [*] Mon Jan 30 08:18:33 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.438869 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.2794 & F1 0.4368 | AUC 0.7629
01/30/2023 08:18:34 AM  [*] Mon Jan 30 08:18:34 2023:    1    | Tr.loss: 0.691732 | Elapsed:   7.63   s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.6958
01/30/2023 08:18:34 AM  [*] Started epoch: 2
01/30/2023 08:18:34 AM  [*] Mon Jan 30 08:18:34 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.464821 | Elapsed: 0.05s | FPR 0.0003 -> TPR 0.3556 & F1 0.5246 | AUC 0.8082
01/30/2023 08:18:41 AM  [*] Mon Jan 30 08:18:41 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.311698 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.4203 & F1 0.5918 | AUC 0.9327
01/30/2023 08:18:42 AM  [*] Mon Jan 30 08:18:42 2023:    2    | Tr.loss: 0.402966 | Elapsed:   7.61   s | FPR 0.0003 -> TPR: 0.16 & F1: 0.28 | AUC: 0.8684
01/30/2023 08:18:42 AM  [*] Started epoch: 3
01/30/2023 08:18:42 AM  [*] Mon Jan 30 08:18:42 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.285773 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.6522 & F1 0.7895 | AUC 0.9457
01/30/2023 08:18:48 AM  [*] Mon Jan 30 08:18:48 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.420039 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.4828 & F1 0.6512 | AUC 0.9076
01/30/2023 08:18:50 AM  [*] Mon Jan 30 08:18:50 2023:    3    | Tr.loss: 0.333561 | Elapsed:   7.67   s | FPR 0.0003 -> TPR: 0.11 & F1: 0.20 | AUC: 0.9154
01/30/2023 08:18:50 AM [!] Mon Jan 30 08:18:50 2023: Dumped results:
                model     : 1675063130-model.torch
		train time: 1675063130-trainTime.npy
		train losses: 1675063130-trainLosses.npy
		train AUC: 1675063130-auc.npy
		train F1s : 1675063130-trainF1s.npy
		train TPRs: 1675063130-trainTPRs.npy
01/30/2023 08:18:50 AM  [*] Evaluating pretrained model on test set...
01/30/2023 08:18:55 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.1213 | F1: 0.2164
01/30/2023 08:18:55 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1319 | F1: 0.2330
01/30/2023 08:18:55 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.1753 | F1: 0.2980
01/30/2023 08:18:55 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.2515 | F1: 0.4011
01/30/2023 08:18:55 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3162 | F1: 0.4774
01/30/2023 08:18:55 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.3845 | F1: 0.5453
01/30/2023 08:18:55 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.5739 | F1: 0.6918
01/30/2023 08:18:55 AM  [*] Evaluating non_pretrained model on test set...
01/30/2023 08:19:00 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0498 | F1: 0.0948
01/30/2023 08:19:00 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.0910 | F1: 0.1668
01/30/2023 08:19:00 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.1799 | F1: 0.3048
01/30/2023 08:19:00 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.2553 | F1: 0.4060
01/30/2023 08:19:00 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3507 | F1: 0.5161
01/30/2023 08:19:00 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4244 | F1: 0.5854
01/30/2023 08:19:00 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.5710 | F1: 0.6896
01/30/2023 08:19:00 AM  [!] Finished pre-training evaluation over 3 splits! Saved metrics to:
	C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\downsample_tests\downsample_U_0.2_1675062110/metrics_MaskedLanguageModel_nSplits_3_limit_None.json
01/30/2023 08:19:00 AM  [!] Starting uSize downsample 0.3 evaluation!
01/30/2023 08:19:00 AM  [!] Starting Masked Language Model evaluation over 3 splits!
01/30/2023 08:19:00 AM  [!] Loaded data and vocab. X train size: (76126, 512), X test size: (17407, 512), vocab size: 50002
01/30/2023 08:19:00 AM  [!] Initiating Self-Supervised Learning Pretraining
     Language Modeling MaskedLanguageModel
     Model TransformerEncoderLM with config:
	{'vocabSize': 50002, 'maxLen': 512, 'dModel': 64, 'nHeads': 8, 'dHidden': 256, 'nLayers': 2, 'numClasses': 1, 'hiddenNeurons': [64], 'dropout': 0.3}

01/30/2023 08:19:00 AM  [!] Running pre-training split 1/3
01/30/2023 08:19:02 AM  [!] Pre-training model...
01/30/2023 08:19:02 AM  [*] Masking sequences...
01/30/2023 08:19:08 AM  [*] Started epoch: 1
01/30/2023 08:19:09 AM  [*] Mon Jan 30 08:19:09 2023: Train Epoch: 1 [  0  /20553 (0 %)]	Loss: 452.027557 | Elapsed: 0.41s
01/30/2023 08:19:21 AM  [*] Mon Jan 30 08:19:21 2023: Train Epoch: 1 [6400 /20553 (31%)]	Loss: 231.507233 | Elapsed: 12.52s
01/30/2023 08:19:37 AM  [*] Mon Jan 30 08:19:37 2023: Train Epoch: 1 [12800/20553 (62%)]	Loss: 228.698700 | Elapsed: 15.28s
01/30/2023 08:19:53 AM  [*] Mon Jan 30 08:19:53 2023: Train Epoch: 1 [19200/20553 (93%)]	Loss: 205.184784 | Elapsed: 16.28s
01/30/2023 08:19:57 AM  [*] Mon Jan 30 08:19:57 2023:    1    | Tr.loss: 225.011401 | Elapsed:   48.35  s
01/30/2023 08:19:57 AM  [*] Started epoch: 2
01/30/2023 08:19:57 AM  [*] Mon Jan 30 08:19:57 2023: Train Epoch: 2 [  0  /20553 (0 %)]	Loss: 208.196136 | Elapsed: 0.13s
01/30/2023 08:20:09 AM  [*] Mon Jan 30 08:20:09 2023: Train Epoch: 2 [6400 /20553 (31%)]	Loss: 224.572723 | Elapsed: 12.44s
01/30/2023 08:20:24 AM  [*] Mon Jan 30 08:20:24 2023: Train Epoch: 2 [12800/20553 (62%)]	Loss: 179.981201 | Elapsed: 14.99s
01/30/2023 08:20:41 AM  [*] Mon Jan 30 08:20:41 2023: Train Epoch: 2 [19200/20553 (93%)]	Loss: 207.050720 | Elapsed: 16.41s
01/30/2023 08:20:45 AM  [*] Mon Jan 30 08:20:45 2023:    2    | Tr.loss: 203.829709 | Elapsed:   47.91  s
01/30/2023 08:20:45 AM  [*] Started epoch: 3
01/30/2023 08:20:45 AM  [*] Mon Jan 30 08:20:45 2023: Train Epoch: 3 [  0  /20553 (0 %)]	Loss: 194.767075 | Elapsed: 0.12s
01/30/2023 08:20:57 AM  [*] Mon Jan 30 08:20:57 2023: Train Epoch: 3 [6400 /20553 (31%)]	Loss: 186.053253 | Elapsed: 12.50s
01/30/2023 08:21:12 AM  [*] Mon Jan 30 08:21:12 2023: Train Epoch: 3 [12800/20553 (62%)]	Loss: 218.040558 | Elapsed: 14.48s
01/30/2023 08:21:28 AM  [*] Mon Jan 30 08:21:28 2023: Train Epoch: 3 [19200/20553 (93%)]	Loss: 194.917023 | Elapsed: 16.20s
01/30/2023 08:21:32 AM  [*] Mon Jan 30 08:21:32 2023:    3    | Tr.loss: 195.606876 | Elapsed:   47.17  s
01/30/2023 08:21:32 AM  [*] Started epoch: 4
01/30/2023 08:21:32 AM  [*] Mon Jan 30 08:21:32 2023: Train Epoch: 4 [  0  /20553 (0 %)]	Loss: 185.643677 | Elapsed: 0.13s
01/30/2023 08:21:44 AM  [*] Mon Jan 30 08:21:44 2023: Train Epoch: 4 [6400 /20553 (31%)]	Loss: 209.096329 | Elapsed: 12.44s
01/30/2023 08:21:59 AM  [*] Mon Jan 30 08:21:59 2023: Train Epoch: 4 [12800/20553 (62%)]	Loss: 212.773224 | Elapsed: 14.24s
01/30/2023 08:22:15 AM  [*] Mon Jan 30 08:22:15 2023: Train Epoch: 4 [19200/20553 (93%)]	Loss: 209.876328 | Elapsed: 16.14s
01/30/2023 08:22:19 AM  [*] Mon Jan 30 08:22:19 2023:    4    | Tr.loss: 191.058068 | Elapsed:   46.79  s
01/30/2023 08:22:19 AM  [*] Started epoch: 5
01/30/2023 08:22:19 AM  [*] Mon Jan 30 08:22:19 2023: Train Epoch: 5 [  0  /20553 (0 %)]	Loss: 180.519867 | Elapsed: 0.15s
01/30/2023 08:22:31 AM  [*] Mon Jan 30 08:22:31 2023: Train Epoch: 5 [6400 /20553 (31%)]	Loss: 191.021362 | Elapsed: 12.63s
01/30/2023 08:22:45 AM  [*] Mon Jan 30 08:22:45 2023: Train Epoch: 5 [12800/20553 (62%)]	Loss: 183.402222 | Elapsed: 13.92s
01/30/2023 08:23:02 AM  [*] Mon Jan 30 08:23:02 2023: Train Epoch: 5 [19200/20553 (93%)]	Loss: 176.456665 | Elapsed: 16.29s
01/30/2023 08:23:06 AM  [*] Mon Jan 30 08:23:06 2023:    5    | Tr.loss: 188.108733 | Elapsed:   46.88  s
01/30/2023 08:23:06 AM  [*] Started epoch: 6
01/30/2023 08:23:06 AM  [*] Mon Jan 30 08:23:06 2023: Train Epoch: 6 [  0  /20553 (0 %)]	Loss: 180.363678 | Elapsed: 0.14s
01/30/2023 08:23:18 AM  [*] Mon Jan 30 08:23:18 2023: Train Epoch: 6 [6400 /20553 (31%)]	Loss: 163.801666 | Elapsed: 12.52s
01/30/2023 08:23:32 AM  [*] Mon Jan 30 08:23:32 2023: Train Epoch: 6 [12800/20553 (62%)]	Loss: 179.746658 | Elapsed: 14.03s
01/30/2023 08:23:48 AM  [*] Mon Jan 30 08:23:48 2023: Train Epoch: 6 [19200/20553 (93%)]	Loss: 182.732880 | Elapsed: 16.11s
01/30/2023 08:23:52 AM  [*] Mon Jan 30 08:23:52 2023:    6    | Tr.loss: 186.185015 | Elapsed:   46.66  s
01/30/2023 08:23:52 AM  [*] Started epoch: 7
01/30/2023 08:23:52 AM  [*] Mon Jan 30 08:23:52 2023: Train Epoch: 7 [  0  /20553 (0 %)]	Loss: 190.379349 | Elapsed: 0.12s
01/30/2023 08:24:05 AM  [*] Mon Jan 30 08:24:05 2023: Train Epoch: 7 [6400 /20553 (31%)]	Loss: 197.636536 | Elapsed: 12.48s
01/30/2023 08:24:18 AM  [*] Mon Jan 30 08:24:18 2023: Train Epoch: 7 [12800/20553 (62%)]	Loss: 204.764374 | Elapsed: 13.57s
01/30/2023 08:24:34 AM  [*] Mon Jan 30 08:24:34 2023: Train Epoch: 7 [19200/20553 (93%)]	Loss: 180.887512 | Elapsed: 16.01s
01/30/2023 08:24:38 AM  [*] Mon Jan 30 08:24:38 2023:    7    | Tr.loss: 184.445850 | Elapsed:   45.98  s
01/30/2023 08:24:38 AM  [*] Started epoch: 8
01/30/2023 08:24:38 AM  [*] Mon Jan 30 08:24:38 2023: Train Epoch: 8 [  0  /20553 (0 %)]	Loss: 195.512726 | Elapsed: 0.12s
01/30/2023 08:24:51 AM  [*] Mon Jan 30 08:24:51 2023: Train Epoch: 8 [6400 /20553 (31%)]	Loss: 182.373383 | Elapsed: 12.44s
01/30/2023 08:25:04 AM  [*] Mon Jan 30 08:25:04 2023: Train Epoch: 8 [12800/20553 (62%)]	Loss: 175.356812 | Elapsed: 13.34s
01/30/2023 08:25:21 AM  [*] Mon Jan 30 08:25:21 2023: Train Epoch: 8 [19200/20553 (93%)]	Loss: 163.652512 | Elapsed: 16.39s
01/30/2023 08:25:24 AM  [*] Mon Jan 30 08:25:24 2023:    8    | Tr.loss: 183.332638 | Elapsed:   46.15  s
01/30/2023 08:25:24 AM  [*] Started epoch: 9
01/30/2023 08:25:25 AM  [*] Mon Jan 30 08:25:25 2023: Train Epoch: 9 [  0  /20553 (0 %)]	Loss: 171.766052 | Elapsed: 0.13s
01/30/2023 08:25:37 AM  [*] Mon Jan 30 08:25:37 2023: Train Epoch: 9 [6400 /20553 (31%)]	Loss: 176.056274 | Elapsed: 12.49s
01/30/2023 08:25:50 AM  [*] Mon Jan 30 08:25:50 2023: Train Epoch: 9 [12800/20553 (62%)]	Loss: 176.587936 | Elapsed: 13.10s
01/30/2023 08:26:06 AM  [*] Mon Jan 30 08:26:06 2023: Train Epoch: 9 [19200/20553 (93%)]	Loss: 176.100616 | Elapsed: 16.15s
01/30/2023 08:26:10 AM  [*] Mon Jan 30 08:26:10 2023:    9    | Tr.loss: 181.773565 | Elapsed:   45.77  s
01/30/2023 08:26:10 AM  [*] Started epoch: 10
01/30/2023 08:26:10 AM  [*] Mon Jan 30 08:26:10 2023: Train Epoch: 10 [  0  /20553 (0 %)]	Loss: 203.433945 | Elapsed: 0.14s
01/30/2023 08:26:23 AM  [*] Mon Jan 30 08:26:23 2023: Train Epoch: 10 [6400 /20553 (31%)]	Loss: 174.833466 | Elapsed: 12.71s
01/30/2023 08:26:36 AM  [*] Mon Jan 30 08:26:36 2023: Train Epoch: 10 [12800/20553 (62%)]	Loss: 173.307587 | Elapsed: 12.84s
01/30/2023 08:26:52 AM  [*] Mon Jan 30 08:26:52 2023: Train Epoch: 10 [19200/20553 (93%)]	Loss: 189.051773 | Elapsed: 15.80s
01/30/2023 08:26:56 AM  [*] Mon Jan 30 08:26:56 2023:   10    | Tr.loss: 180.707010 | Elapsed:   45.52  s
01/30/2023 08:26:56 AM [!] Mon Jan 30 08:26:56 2023: Dumped results:
                model     : 1675063616-model.torch
		train time: 1675063616-trainTime.npy
		train losses: 1675063616-trainLosses.npy
		train AUC: 1675063616-auc.npy
01/30/2023 08:26:57 AM  [!] Training pretrained model on downstream task...
01/30/2023 08:26:57 AM  [*] Started epoch: 1
01/30/2023 08:26:57 AM  [*] Mon Jan 30 08:26:57 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 1.145096 | Elapsed: 0.16s | FPR 0.0003 -> TPR 0.0811 & F1 0.1500 | AUC 0.7097
01/30/2023 08:27:06 AM  [*] Mon Jan 30 08:27:06 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.372191 | Elapsed: 9.11s | FPR 0.0003 -> TPR 0.2373 & F1 0.3836 | AUC 0.9124
01/30/2023 08:27:08 AM  [*] Mon Jan 30 08:27:08 2023:    1    | Tr.loss: 0.484484 | Elapsed:   11.05  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8075
01/30/2023 08:27:08 AM  [*] Started epoch: 2
01/30/2023 08:27:08 AM  [*] Mon Jan 30 08:27:08 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.336028 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.5111 & F1 0.6765 | AUC 0.9000
01/30/2023 08:27:17 AM  [*] Mon Jan 30 08:27:17 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.260182 | Elapsed: 9.06s | FPR 0.0003 -> TPR 0.4384 & F1 0.6095 | AUC 0.9046
01/30/2023 08:27:19 AM  [*] Mon Jan 30 08:27:19 2023:    2    | Tr.loss: 0.361181 | Elapsed:   10.95  s | FPR 0.0003 -> TPR: 0.15 & F1: 0.26 | AUC: 0.8954
01/30/2023 08:27:19 AM  [*] Started epoch: 3
01/30/2023 08:27:19 AM  [*] Mon Jan 30 08:27:19 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.293798 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.8108 & F1 0.8955 | AUC 0.9479
01/30/2023 08:27:28 AM  [*] Mon Jan 30 08:27:28 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.198800 | Elapsed: 9.07s | FPR 0.0003 -> TPR 0.8167 & F1 0.8991 | AUC 0.9812
01/30/2023 08:27:30 AM  [*] Mon Jan 30 08:27:30 2023:    3    | Tr.loss: 0.280494 | Elapsed:   11.00  s | FPR 0.0003 -> TPR: 0.29 & F1: 0.45 | AUC: 0.9416
01/30/2023 08:27:31 AM [!] Mon Jan 30 08:27:31 2023: Dumped results:
                model     : 1675063650-model.torch
		train time: 1675063650-trainTime.npy
		train losses: 1675063650-trainLosses.npy
		train AUC: 1675063650-auc.npy
		train F1s : 1675063650-trainF1s.npy
		train TPRs: 1675063650-trainTPRs.npy
01/30/2023 08:27:31 AM  [!] Training non_pretrained model on downstream task...
01/30/2023 08:27:31 AM  [*] Started epoch: 1
01/30/2023 08:27:31 AM  [*] Mon Jan 30 08:27:31 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 1.707646 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0435 & F1 0.0833 | AUC 0.4155
01/30/2023 08:27:37 AM  [*] Mon Jan 30 08:27:37 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.382880 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.4800 & F1 0.6486 | AUC 0.8272
01/30/2023 08:27:38 AM  [*] Mon Jan 30 08:27:38 2023:    1    | Tr.loss: 0.601107 | Elapsed:   7.53   s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7323
01/30/2023 08:27:38 AM  [*] Started epoch: 2
01/30/2023 08:27:39 AM  [*] Mon Jan 30 08:27:39 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.437356 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.4894 & F1 0.6571 | AUC 0.8436
01/30/2023 08:27:45 AM  [*] Mon Jan 30 08:27:45 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.433749 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.2687 & F1 0.4235 | AUC 0.8933
01/30/2023 08:27:46 AM  [*] Mon Jan 30 08:27:46 2023:    2    | Tr.loss: 0.380755 | Elapsed:   7.51   s | FPR 0.0003 -> TPR: 0.07 & F1: 0.13 | AUC: 0.8815
01/30/2023 08:27:46 AM  [*] Started epoch: 3
01/30/2023 08:27:46 AM  [*] Mon Jan 30 08:27:46 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.267911 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.6809 & F1 0.8101 | AUC 0.9249
01/30/2023 08:27:52 AM  [*] Mon Jan 30 08:27:52 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.342373 | Elapsed: 6.19s | FPR 0.0003 -> TPR 0.2308 & F1 0.3750 | AUC 0.8462
01/30/2023 08:27:54 AM  [*] Mon Jan 30 08:27:54 2023:    3    | Tr.loss: 0.316541 | Elapsed:   7.61   s | FPR 0.0003 -> TPR: 0.21 & F1: 0.34 | AUC: 0.9220
01/30/2023 08:27:54 AM [!] Mon Jan 30 08:27:54 2023: Dumped results:
                model     : 1675063674-model.torch
		train time: 1675063674-trainTime.npy
		train losses: 1675063674-trainLosses.npy
		train AUC: 1675063674-auc.npy
		train F1s : 1675063674-trainF1s.npy
		train TPRs: 1675063674-trainTPRs.npy
01/30/2023 08:27:54 AM  [*] Evaluating pretrained model on test set...
01/30/2023 08:27:59 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.1202 | F1: 0.2146
01/30/2023 08:27:59 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.2113 | F1: 0.3488
01/30/2023 08:27:59 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.3113 | F1: 0.4745
01/30/2023 08:27:59 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3490 | F1: 0.5165
01/30/2023 08:27:59 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.4011 | F1: 0.5691
01/30/2023 08:27:59 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4661 | F1: 0.6250
01/30/2023 08:27:59 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.6901 | F1: 0.7775
01/30/2023 08:27:59 AM  [*] Evaluating non_pretrained model on test set...
01/30/2023 08:28:04 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0027 | F1: 0.0053
01/30/2023 08:28:04 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1440 | F1: 0.2517
01/30/2023 08:28:04 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.1986 | F1: 0.3311
01/30/2023 08:28:04 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.2585 | F1: 0.4100
01/30/2023 08:28:04 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3547 | F1: 0.5204
01/30/2023 08:28:04 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4166 | F1: 0.5778
01/30/2023 08:28:04 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.5531 | F1: 0.6753
01/30/2023 08:28:04 AM  [!] Running pre-training split 2/3
01/30/2023 08:28:05 AM  [!] Pre-training model...
01/30/2023 08:28:06 AM  [*] Masking sequences...
01/30/2023 08:28:12 AM  [*] Started epoch: 1
01/30/2023 08:28:12 AM  [*] Mon Jan 30 08:28:12 2023: Train Epoch: 1 [  0  /20553 (0 %)]	Loss: 439.585144 | Elapsed: 0.39s
01/30/2023 08:28:24 AM  [*] Mon Jan 30 08:28:24 2023: Train Epoch: 1 [6400 /20553 (31%)]	Loss: 262.110962 | Elapsed: 12.25s
01/30/2023 08:28:38 AM  [*] Mon Jan 30 08:28:38 2023: Train Epoch: 1 [12800/20553 (62%)]	Loss: 197.631180 | Elapsed: 14.03s
01/30/2023 08:28:54 AM  [*] Mon Jan 30 08:28:54 2023: Train Epoch: 1 [19200/20553 (93%)]	Loss: 164.585510 | Elapsed: 15.59s
01/30/2023 08:28:58 AM  [*] Mon Jan 30 08:28:58 2023:    1    | Tr.loss: 226.380271 | Elapsed:   45.93  s
01/30/2023 08:28:58 AM  [*] Started epoch: 2
01/30/2023 08:28:58 AM  [*] Mon Jan 30 08:28:58 2023: Train Epoch: 2 [  0  /20553 (0 %)]	Loss: 215.841446 | Elapsed: 0.13s
01/30/2023 08:29:10 AM  [*] Mon Jan 30 08:29:10 2023: Train Epoch: 2 [6400 /20553 (31%)]	Loss: 198.052902 | Elapsed: 12.29s
01/30/2023 08:29:24 AM  [*] Mon Jan 30 08:29:24 2023: Train Epoch: 2 [12800/20553 (62%)]	Loss: 186.973907 | Elapsed: 13.76s
01/30/2023 08:29:40 AM  [*] Mon Jan 30 08:29:40 2023: Train Epoch: 2 [19200/20553 (93%)]	Loss: 190.809555 | Elapsed: 15.69s
01/30/2023 08:29:43 AM  [*] Mon Jan 30 08:29:43 2023:    2    | Tr.loss: 201.908024 | Elapsed:   45.56  s
01/30/2023 08:29:43 AM  [*] Started epoch: 3
01/30/2023 08:29:43 AM  [*] Mon Jan 30 08:29:43 2023: Train Epoch: 3 [  0  /20553 (0 %)]	Loss: 165.977524 | Elapsed: 0.14s
01/30/2023 08:29:56 AM  [*] Mon Jan 30 08:29:56 2023: Train Epoch: 3 [6400 /20553 (31%)]	Loss: 204.502014 | Elapsed: 12.22s
01/30/2023 08:30:09 AM  [*] Mon Jan 30 08:30:09 2023: Train Epoch: 3 [12800/20553 (62%)]	Loss: 187.077393 | Elapsed: 13.63s
01/30/2023 08:30:25 AM  [*] Mon Jan 30 08:30:25 2023: Train Epoch: 3 [19200/20553 (93%)]	Loss: 196.630005 | Elapsed: 15.69s
01/30/2023 08:30:29 AM  [*] Mon Jan 30 08:30:29 2023:    3    | Tr.loss: 191.941172 | Elapsed:   45.37  s
01/30/2023 08:30:29 AM  [*] Started epoch: 4
01/30/2023 08:30:29 AM  [*] Mon Jan 30 08:30:29 2023: Train Epoch: 4 [  0  /20553 (0 %)]	Loss: 162.131714 | Elapsed: 0.12s
01/30/2023 08:30:41 AM  [*] Mon Jan 30 08:30:41 2023: Train Epoch: 4 [6400 /20553 (31%)]	Loss: 192.662781 | Elapsed: 12.39s
01/30/2023 08:30:55 AM  [*] Mon Jan 30 08:30:55 2023: Train Epoch: 4 [12800/20553 (62%)]	Loss: 192.061478 | Elapsed: 13.43s
01/30/2023 08:31:10 AM  [*] Mon Jan 30 08:31:10 2023: Train Epoch: 4 [19200/20553 (93%)]	Loss: 194.614990 | Elapsed: 15.86s
01/30/2023 08:31:14 AM  [*] Mon Jan 30 08:31:14 2023:    4    | Tr.loss: 186.769896 | Elapsed:   45.48  s
01/30/2023 08:31:14 AM  [*] Started epoch: 5
01/30/2023 08:31:14 AM  [*] Mon Jan 30 08:31:14 2023: Train Epoch: 5 [  0  /20553 (0 %)]	Loss: 180.695740 | Elapsed: 0.12s
01/30/2023 08:31:27 AM  [*] Mon Jan 30 08:31:27 2023: Train Epoch: 5 [6400 /20553 (31%)]	Loss: 176.685638 | Elapsed: 12.28s
01/30/2023 08:31:40 AM  [*] Mon Jan 30 08:31:40 2023: Train Epoch: 5 [12800/20553 (62%)]	Loss: 178.839752 | Elapsed: 13.37s
01/30/2023 08:31:56 AM  [*] Mon Jan 30 08:31:56 2023: Train Epoch: 5 [19200/20553 (93%)]	Loss: 183.360840 | Elapsed: 15.77s
01/30/2023 08:32:00 AM  [*] Mon Jan 30 08:32:00 2023:    5    | Tr.loss: 183.479004 | Elapsed:   45.47  s
01/30/2023 08:32:00 AM  [*] Started epoch: 6
01/30/2023 08:32:00 AM  [*] Mon Jan 30 08:32:00 2023: Train Epoch: 6 [  0  /20553 (0 %)]	Loss: 197.501648 | Elapsed: 0.11s
01/30/2023 08:32:12 AM  [*] Mon Jan 30 08:32:12 2023: Train Epoch: 6 [6400 /20553 (31%)]	Loss: 172.191223 | Elapsed: 12.23s
01/30/2023 08:32:25 AM  [*] Mon Jan 30 08:32:25 2023: Train Epoch: 6 [12800/20553 (62%)]	Loss: 174.916382 | Elapsed: 13.07s
01/30/2023 08:32:41 AM  [*] Mon Jan 30 08:32:41 2023: Train Epoch: 6 [19200/20553 (93%)]	Loss: 189.437134 | Elapsed: 16.16s
01/30/2023 08:32:45 AM  [*] Mon Jan 30 08:32:45 2023:    6    | Tr.loss: 180.844011 | Elapsed:   45.38  s
01/30/2023 08:32:45 AM  [*] Started epoch: 7
01/30/2023 08:32:45 AM  [*] Mon Jan 30 08:32:45 2023: Train Epoch: 7 [  0  /20553 (0 %)]	Loss: 197.226593 | Elapsed: 0.15s
01/30/2023 08:32:57 AM  [*] Mon Jan 30 08:32:57 2023: Train Epoch: 7 [6400 /20553 (31%)]	Loss: 173.913910 | Elapsed: 12.28s
01/30/2023 08:33:11 AM  [*] Mon Jan 30 08:33:11 2023: Train Epoch: 7 [12800/20553 (62%)]	Loss: 156.080643 | Elapsed: 13.08s
01/30/2023 08:33:26 AM  [*] Mon Jan 30 08:33:26 2023: Train Epoch: 7 [19200/20553 (93%)]	Loss: 183.146469 | Elapsed: 15.93s
01/30/2023 08:33:30 AM  [*] Mon Jan 30 08:33:30 2023:    7    | Tr.loss: 179.334444 | Elapsed:   45.18  s
01/30/2023 08:33:30 AM  [*] Started epoch: 8
01/30/2023 08:33:30 AM  [*] Mon Jan 30 08:33:30 2023: Train Epoch: 8 [  0  /20553 (0 %)]	Loss: 171.367126 | Elapsed: 0.13s
01/30/2023 08:33:43 AM  [*] Mon Jan 30 08:33:43 2023: Train Epoch: 8 [6400 /20553 (31%)]	Loss: 163.376221 | Elapsed: 12.21s
01/30/2023 08:33:56 AM  [*] Mon Jan 30 08:33:56 2023: Train Epoch: 8 [12800/20553 (62%)]	Loss: 182.136826 | Elapsed: 13.12s
01/30/2023 08:34:11 AM  [*] Mon Jan 30 08:34:11 2023: Train Epoch: 8 [19200/20553 (93%)]	Loss: 174.771210 | Elapsed: 15.54s
01/30/2023 08:34:15 AM  [*] Mon Jan 30 08:34:15 2023:    8    | Tr.loss: 177.758760 | Elapsed:   44.71  s
01/30/2023 08:34:15 AM  [*] Started epoch: 9
01/30/2023 08:34:15 AM  [*] Mon Jan 30 08:34:15 2023: Train Epoch: 9 [  0  /20553 (0 %)]	Loss: 162.020279 | Elapsed: 0.14s
01/30/2023 08:34:27 AM  [*] Mon Jan 30 08:34:27 2023: Train Epoch: 9 [6400 /20553 (31%)]	Loss: 188.838654 | Elapsed: 12.32s
01/30/2023 08:34:41 AM  [*] Mon Jan 30 08:34:41 2023: Train Epoch: 9 [12800/20553 (62%)]	Loss: 163.675369 | Elapsed: 13.18s
01/30/2023 08:34:56 AM  [*] Mon Jan 30 08:34:56 2023: Train Epoch: 9 [19200/20553 (93%)]	Loss: 155.052811 | Elapsed: 15.94s
01/30/2023 08:35:00 AM  [*] Mon Jan 30 08:35:00 2023:    9    | Tr.loss: 176.482059 | Elapsed:   45.40  s
01/30/2023 08:35:00 AM  [*] Started epoch: 10
01/30/2023 08:35:00 AM  [*] Mon Jan 30 08:35:00 2023: Train Epoch: 10 [  0  /20553 (0 %)]	Loss: 161.909637 | Elapsed: 0.12s
01/30/2023 08:35:13 AM  [*] Mon Jan 30 08:35:13 2023: Train Epoch: 10 [6400 /20553 (31%)]	Loss: 173.020981 | Elapsed: 12.31s
01/30/2023 08:35:26 AM  [*] Mon Jan 30 08:35:26 2023: Train Epoch: 10 [12800/20553 (62%)]	Loss: 173.573456 | Elapsed: 13.17s
01/30/2023 08:35:42 AM  [*] Mon Jan 30 08:35:42 2023: Train Epoch: 10 [19200/20553 (93%)]	Loss: 159.640167 | Elapsed: 15.72s
01/30/2023 08:35:45 AM  [*] Mon Jan 30 08:35:45 2023:   10    | Tr.loss: 175.303771 | Elapsed:   45.08  s
01/30/2023 08:35:46 AM [!] Mon Jan 30 08:35:46 2023: Dumped results:
                model     : 1675064145-model.torch
		train time: 1675064145-trainTime.npy
		train losses: 1675064145-trainLosses.npy
		train AUC: 1675064145-auc.npy
01/30/2023 08:35:46 AM  [!] Training pretrained model on downstream task...
01/30/2023 08:35:47 AM  [*] Started epoch: 1
01/30/2023 08:35:47 AM  [*] Mon Jan 30 08:35:47 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 1.634310 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.2051 & F1 0.3404 | AUC 0.6010
01/30/2023 08:35:56 AM  [*] Mon Jan 30 08:35:56 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.430078 | Elapsed: 9.06s | FPR 0.0003 -> TPR 0.3600 & F1 0.5294 | AUC 0.7979
01/30/2023 08:35:57 AM  [*] Mon Jan 30 08:35:57 2023:    1    | Tr.loss: 0.508998 | Elapsed:   10.93  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8094
01/30/2023 08:35:57 AM  [*] Started epoch: 2
01/30/2023 08:35:58 AM  [*] Mon Jan 30 08:35:58 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.289444 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.3462 & F1 0.5143 | AUC 0.9103
01/30/2023 08:36:07 AM  [*] Mon Jan 30 08:36:07 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.393433 | Elapsed: 9.03s | FPR 0.0003 -> TPR 0.0923 & F1 0.1690 | AUC 0.8554
01/30/2023 08:36:08 AM  [*] Mon Jan 30 08:36:08 2023:    2    | Tr.loss: 0.353493 | Elapsed:   10.91  s | FPR 0.0003 -> TPR: 0.04 & F1: 0.07 | AUC: 0.9002
01/30/2023 08:36:08 AM  [*] Started epoch: 3
01/30/2023 08:36:08 AM  [*] Mon Jan 30 08:36:08 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.310989 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.5532 & F1 0.7123 | AUC 0.9149
01/30/2023 08:36:18 AM  [*] Mon Jan 30 08:36:18 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.298574 | Elapsed: 9.04s | FPR 0.0003 -> TPR 0.5000 & F1 0.6667 | AUC 0.9441
01/30/2023 08:36:19 AM  [*] Mon Jan 30 08:36:19 2023:    3    | Tr.loss: 0.295345 | Elapsed:   10.98  s | FPR 0.0003 -> TPR: 0.20 & F1: 0.34 | AUC: 0.9352
01/30/2023 08:36:20 AM [!] Mon Jan 30 08:36:20 2023: Dumped results:
                model     : 1675064179-model.torch
		train time: 1675064179-trainTime.npy
		train losses: 1675064179-trainLosses.npy
		train AUC: 1675064179-auc.npy
		train F1s : 1675064179-trainF1s.npy
		train TPRs: 1675064179-trainTPRs.npy
01/30/2023 08:36:20 AM  [!] Training non_pretrained model on downstream task...
01/30/2023 08:36:20 AM  [*] Started epoch: 1
01/30/2023 08:36:20 AM  [*] Mon Jan 30 08:36:20 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 1.658424 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0476 & F1 0.0909 | AUC 0.6017
01/30/2023 08:36:26 AM  [*] Mon Jan 30 08:36:26 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.501530 | Elapsed: 6.17s | FPR 0.0003 -> TPR 0.3226 & F1 0.4878 | AUC 0.8209
01/30/2023 08:36:28 AM  [*] Mon Jan 30 08:36:28 2023:    1    | Tr.loss: 0.590116 | Elapsed:   7.57   s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7548
01/30/2023 08:36:28 AM  [*] Started epoch: 2
01/30/2023 08:36:28 AM  [*] Mon Jan 30 08:36:28 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.349772 | Elapsed: 0.05s | FPR 0.0003 -> TPR 0.6750 & F1 0.8060 | AUC 0.9146
01/30/2023 08:36:34 AM  [*] Mon Jan 30 08:36:34 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.381652 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.4306 & F1 0.6019 | AUC 0.9092
01/30/2023 08:36:35 AM  [*] Mon Jan 30 08:36:35 2023:    2    | Tr.loss: 0.385049 | Elapsed:   7.56   s | FPR 0.0003 -> TPR: 0.13 & F1: 0.23 | AUC: 0.8813
01/30/2023 08:36:35 AM  [*] Started epoch: 3
01/30/2023 08:36:35 AM  [*] Mon Jan 30 08:36:35 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.357111 | Elapsed: 0.05s | FPR 0.0003 -> TPR 0.4750 & F1 0.6441 | AUC 0.9094
01/30/2023 08:36:42 AM  [*] Mon Jan 30 08:36:42 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.274137 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.7286 & F1 0.8430 | AUC 0.9424
01/30/2023 08:36:43 AM  [*] Mon Jan 30 08:36:43 2023:    3    | Tr.loss: 0.322207 | Elapsed:   7.59   s | FPR 0.0003 -> TPR: 0.09 & F1: 0.17 | AUC: 0.9202
01/30/2023 08:36:43 AM [!] Mon Jan 30 08:36:43 2023: Dumped results:
                model     : 1675064203-model.torch
		train time: 1675064203-trainTime.npy
		train losses: 1675064203-trainLosses.npy
		train AUC: 1675064203-auc.npy
		train F1s : 1675064203-trainF1s.npy
		train TPRs: 1675064203-trainTPRs.npy
01/30/2023 08:36:43 AM  [*] Evaluating pretrained model on test set...
01/30/2023 08:36:48 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0222 | F1: 0.0435
01/30/2023 08:36:48 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1575 | F1: 0.2721
01/30/2023 08:36:48 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.1933 | F1: 0.3238
01/30/2023 08:36:48 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.2840 | F1: 0.4414
01/30/2023 08:36:48 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3582 | F1: 0.5242
01/30/2023 08:36:48 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4633 | F1: 0.6223
01/30/2023 08:36:48 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.5415 | F1: 0.6658
01/30/2023 08:36:48 AM  [*] Evaluating non_pretrained model on test set...
01/30/2023 08:36:53 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0525 | F1: 0.0998
01/30/2023 08:36:53 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1413 | F1: 0.2476
01/30/2023 08:36:53 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.1615 | F1: 0.2780
01/30/2023 08:36:53 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.2101 | F1: 0.3466
01/30/2023 08:36:53 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.2898 | F1: 0.4464
01/30/2023 08:36:53 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.3891 | F1: 0.5501
01/30/2023 08:36:53 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.5560 | F1: 0.6776
01/30/2023 08:36:53 AM  [!] Running pre-training split 3/3
01/30/2023 08:36:55 AM  [!] Pre-training model...
01/30/2023 08:36:55 AM  [*] Masking sequences...
01/30/2023 08:37:01 AM  [*] Started epoch: 1
01/30/2023 08:37:02 AM  [*] Mon Jan 30 08:37:02 2023: Train Epoch: 1 [  0  /20553 (0 %)]	Loss: 396.638977 | Elapsed: 0.43s
01/30/2023 08:37:14 AM  [*] Mon Jan 30 08:37:14 2023: Train Epoch: 1 [6400 /20553 (31%)]	Loss: 249.140564 | Elapsed: 12.38s
01/30/2023 08:37:29 AM  [*] Mon Jan 30 08:37:29 2023: Train Epoch: 1 [12800/20553 (62%)]	Loss: 219.668228 | Elapsed: 14.51s
01/30/2023 08:37:45 AM  [*] Mon Jan 30 08:37:45 2023: Train Epoch: 1 [19200/20553 (93%)]	Loss: 218.090042 | Elapsed: 16.34s
01/30/2023 08:37:49 AM  [*] Mon Jan 30 08:37:49 2023:    1    | Tr.loss: 226.606851 | Elapsed:   47.40  s
01/30/2023 08:37:49 AM  [*] Started epoch: 2
01/30/2023 08:37:49 AM  [*] Mon Jan 30 08:37:49 2023: Train Epoch: 2 [  0  /20553 (0 %)]	Loss: 209.886505 | Elapsed: 0.13s
01/30/2023 08:38:01 AM  [*] Mon Jan 30 08:38:01 2023: Train Epoch: 2 [6400 /20553 (31%)]	Loss: 221.299072 | Elapsed: 12.51s
01/30/2023 08:38:16 AM  [*] Mon Jan 30 08:38:16 2023: Train Epoch: 2 [12800/20553 (62%)]	Loss: 217.284439 | Elapsed: 14.21s
01/30/2023 08:38:33 AM  [*] Mon Jan 30 08:38:33 2023: Train Epoch: 2 [19200/20553 (93%)]	Loss: 201.484482 | Elapsed: 16.80s
01/30/2023 08:38:36 AM  [*] Mon Jan 30 08:38:36 2023:    2    | Tr.loss: 204.385452 | Elapsed:   47.59  s
01/30/2023 08:38:36 AM  [*] Started epoch: 3
01/30/2023 08:38:37 AM  [*] Mon Jan 30 08:38:37 2023: Train Epoch: 3 [  0  /20553 (0 %)]	Loss: 204.138763 | Elapsed: 0.13s
01/30/2023 08:38:49 AM  [*] Mon Jan 30 08:38:49 2023: Train Epoch: 3 [6400 /20553 (31%)]	Loss: 198.692947 | Elapsed: 12.46s
01/30/2023 08:39:03 AM  [*] Mon Jan 30 08:39:03 2023: Train Epoch: 3 [12800/20553 (62%)]	Loss: 217.407959 | Elapsed: 13.74s
01/30/2023 08:39:19 AM  [*] Mon Jan 30 08:39:19 2023: Train Epoch: 3 [19200/20553 (93%)]	Loss: 169.629166 | Elapsed: 16.46s
01/30/2023 08:39:23 AM  [*] Mon Jan 30 08:39:23 2023:    3    | Tr.loss: 195.326818 | Elapsed:   46.58  s
01/30/2023 08:39:23 AM  [*] Started epoch: 4
01/30/2023 08:39:23 AM  [*] Mon Jan 30 08:39:23 2023: Train Epoch: 4 [  0  /20553 (0 %)]	Loss: 167.680725 | Elapsed: 0.14s
01/30/2023 08:39:35 AM  [*] Mon Jan 30 08:39:35 2023: Train Epoch: 4 [6400 /20553 (31%)]	Loss: 190.870712 | Elapsed: 12.25s
01/30/2023 08:39:49 AM  [*] Mon Jan 30 08:39:49 2023: Train Epoch: 4 [12800/20553 (62%)]	Loss: 173.290421 | Elapsed: 13.18s
01/30/2023 08:40:05 AM  [*] Mon Jan 30 08:40:05 2023: Train Epoch: 4 [19200/20553 (93%)]	Loss: 172.709839 | Elapsed: 16.16s
01/30/2023 08:40:09 AM  [*] Mon Jan 30 08:40:09 2023:    4    | Tr.loss: 190.336661 | Elapsed:   45.51  s
01/30/2023 08:40:09 AM  [*] Started epoch: 5
01/30/2023 08:40:09 AM  [*] Mon Jan 30 08:40:09 2023: Train Epoch: 5 [  0  /20553 (0 %)]	Loss: 203.580139 | Elapsed: 0.13s
01/30/2023 08:40:21 AM  [*] Mon Jan 30 08:40:21 2023: Train Epoch: 5 [6400 /20553 (31%)]	Loss: 166.130585 | Elapsed: 12.31s
01/30/2023 08:40:34 AM  [*] Mon Jan 30 08:40:34 2023: Train Epoch: 5 [12800/20553 (62%)]	Loss: 197.234390 | Elapsed: 13.29s
01/30/2023 08:40:50 AM  [*] Mon Jan 30 08:40:50 2023: Train Epoch: 5 [19200/20553 (93%)]	Loss: 182.904083 | Elapsed: 16.00s
01/30/2023 08:40:54 AM  [*] Mon Jan 30 08:40:54 2023:    5    | Tr.loss: 187.275920 | Elapsed:   45.75  s
01/30/2023 08:40:54 AM  [*] Started epoch: 6
01/30/2023 08:40:54 AM  [*] Mon Jan 30 08:40:54 2023: Train Epoch: 6 [  0  /20553 (0 %)]	Loss: 185.435760 | Elapsed: 0.12s
01/30/2023 08:41:07 AM  [*] Mon Jan 30 08:41:07 2023: Train Epoch: 6 [6400 /20553 (31%)]	Loss: 181.181870 | Elapsed: 12.22s
01/30/2023 08:41:20 AM  [*] Mon Jan 30 08:41:20 2023: Train Epoch: 6 [12800/20553 (62%)]	Loss: 186.897675 | Elapsed: 13.18s
01/30/2023 08:41:36 AM  [*] Mon Jan 30 08:41:36 2023: Train Epoch: 6 [19200/20553 (93%)]	Loss: 180.168900 | Elapsed: 15.92s
01/30/2023 08:41:40 AM  [*] Mon Jan 30 08:41:40 2023:    6    | Tr.loss: 185.579441 | Elapsed:   45.23  s
01/30/2023 08:41:40 AM  [*] Started epoch: 7
01/30/2023 08:41:40 AM  [*] Mon Jan 30 08:41:40 2023: Train Epoch: 7 [  0  /20553 (0 %)]	Loss: 181.367752 | Elapsed: 0.12s
01/30/2023 08:41:52 AM  [*] Mon Jan 30 08:41:52 2023: Train Epoch: 7 [6400 /20553 (31%)]	Loss: 172.787201 | Elapsed: 12.32s
01/30/2023 08:42:05 AM  [*] Mon Jan 30 08:42:05 2023: Train Epoch: 7 [12800/20553 (62%)]	Loss: 184.825500 | Elapsed: 13.01s
01/30/2023 08:42:21 AM  [*] Mon Jan 30 08:42:21 2023: Train Epoch: 7 [19200/20553 (93%)]	Loss: 205.046326 | Elapsed: 15.83s
01/30/2023 08:42:24 AM  [*] Mon Jan 30 08:42:24 2023:    7    | Tr.loss: 183.924369 | Elapsed:   44.95  s
01/30/2023 08:42:24 AM  [*] Started epoch: 8
01/30/2023 08:42:25 AM  [*] Mon Jan 30 08:42:25 2023: Train Epoch: 8 [  0  /20553 (0 %)]	Loss: 188.662964 | Elapsed: 0.13s
01/30/2023 08:42:37 AM  [*] Mon Jan 30 08:42:37 2023: Train Epoch: 8 [6400 /20553 (31%)]	Loss: 177.931931 | Elapsed: 12.40s
01/30/2023 08:42:50 AM  [*] Mon Jan 30 08:42:50 2023: Train Epoch: 8 [12800/20553 (62%)]	Loss: 170.050354 | Elapsed: 12.92s
01/30/2023 08:43:06 AM  [*] Mon Jan 30 08:43:06 2023: Train Epoch: 8 [19200/20553 (93%)]	Loss: 173.528534 | Elapsed: 15.78s
01/30/2023 08:43:09 AM  [*] Mon Jan 30 08:43:09 2023:    8    | Tr.loss: 182.349959 | Elapsed:   44.95  s
01/30/2023 08:43:09 AM  [*] Started epoch: 9
01/30/2023 08:43:10 AM  [*] Mon Jan 30 08:43:10 2023: Train Epoch: 9 [  0  /20553 (0 %)]	Loss: 186.911713 | Elapsed: 0.12s
01/30/2023 08:43:22 AM  [*] Mon Jan 30 08:43:22 2023: Train Epoch: 9 [6400 /20553 (31%)]	Loss: 173.240738 | Elapsed: 12.34s
01/30/2023 08:43:35 AM  [*] Mon Jan 30 08:43:35 2023: Train Epoch: 9 [12800/20553 (62%)]	Loss: 168.543488 | Elapsed: 12.91s
01/30/2023 08:43:51 AM  [*] Mon Jan 30 08:43:51 2023: Train Epoch: 9 [19200/20553 (93%)]	Loss: 182.285797 | Elapsed: 15.92s
01/30/2023 08:43:54 AM  [*] Mon Jan 30 08:43:54 2023:    9    | Tr.loss: 181.138399 | Elapsed:   45.03  s
01/30/2023 08:43:54 AM  [*] Started epoch: 10
01/30/2023 08:43:55 AM  [*] Mon Jan 30 08:43:55 2023: Train Epoch: 10 [  0  /20553 (0 %)]	Loss: 168.694153 | Elapsed: 0.13s
01/30/2023 08:44:07 AM  [*] Mon Jan 30 08:44:07 2023: Train Epoch: 10 [6400 /20553 (31%)]	Loss: 162.901398 | Elapsed: 12.25s
01/30/2023 08:44:20 AM  [*] Mon Jan 30 08:44:20 2023: Train Epoch: 10 [12800/20553 (62%)]	Loss: 185.577789 | Elapsed: 12.89s
01/30/2023 08:44:36 AM  [*] Mon Jan 30 08:44:36 2023: Train Epoch: 10 [19200/20553 (93%)]	Loss: 173.741852 | Elapsed: 16.03s
01/30/2023 08:44:39 AM  [*] Mon Jan 30 08:44:39 2023:   10    | Tr.loss: 180.806036 | Elapsed:   44.99  s
01/30/2023 08:44:40 AM [!] Mon Jan 30 08:44:40 2023: Dumped results:
                model     : 1675064679-model.torch
		train time: 1675064679-trainTime.npy
		train losses: 1675064679-trainLosses.npy
		train AUC: 1675064679-auc.npy
01/30/2023 08:44:40 AM  [!] Training pretrained model on downstream task...
01/30/2023 08:44:41 AM  [*] Started epoch: 1
01/30/2023 08:44:41 AM  [*] Mon Jan 30 08:44:41 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 1.265563 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.1628 & F1 0.2800 | AUC 0.6467
01/30/2023 08:44:50 AM  [*] Mon Jan 30 08:44:50 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.439049 | Elapsed: 9.02s | FPR 0.0003 -> TPR 0.3175 & F1 0.4819 | AUC 0.8468
01/30/2023 08:44:51 AM  [*] Mon Jan 30 08:44:51 2023:    1    | Tr.loss: 0.504361 | Elapsed:   10.90  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8101
01/30/2023 08:44:51 AM  [*] Started epoch: 2
01/30/2023 08:44:52 AM  [*] Mon Jan 30 08:44:52 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.400036 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.3830 & F1 0.5538 | AUC 0.8310
01/30/2023 08:45:01 AM  [*] Mon Jan 30 08:45:01 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.423059 | Elapsed: 9.02s | FPR 0.0003 -> TPR 0.3939 & F1 0.5652 | AUC 0.8732
01/30/2023 08:45:02 AM  [*] Mon Jan 30 08:45:02 2023:    2    | Tr.loss: 0.371109 | Elapsed:   10.90  s | FPR 0.0003 -> TPR: 0.08 & F1: 0.15 | AUC: 0.8900
01/30/2023 08:45:02 AM  [*] Started epoch: 3
01/30/2023 08:45:02 AM  [*] Mon Jan 30 08:45:02 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.268888 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.5789 & F1 0.7333 | AUC 0.9474
01/30/2023 08:45:11 AM  [*] Mon Jan 30 08:45:11 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.300181 | Elapsed: 9.06s | FPR 0.0003 -> TPR 0.5821 & F1 0.7358 | AUC 0.9455
01/30/2023 08:45:13 AM  [*] Mon Jan 30 08:45:13 2023:    3    | Tr.loss: 0.310123 | Elapsed:   11.00  s | FPR 0.0003 -> TPR: 0.08 & F1: 0.15 | AUC: 0.9280
01/30/2023 08:45:14 AM [!] Mon Jan 30 08:45:14 2023: Dumped results:
                model     : 1675064713-model.torch
		train time: 1675064713-trainTime.npy
		train losses: 1675064713-trainLosses.npy
		train AUC: 1675064713-auc.npy
		train F1s : 1675064713-trainF1s.npy
		train TPRs: 1675064713-trainTPRs.npy
01/30/2023 08:45:14 AM  [!] Training non_pretrained model on downstream task...
01/30/2023 08:45:14 AM  [*] Started epoch: 1
01/30/2023 08:45:14 AM  [*] Mon Jan 30 08:45:14 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 3.478364 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.4653
01/30/2023 08:45:20 AM  [*] Mon Jan 30 08:45:20 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.395291 | Elapsed: 6.18s | FPR 0.0003 -> TPR 0.3382 & F1 0.5055 | AUC 0.8120
01/30/2023 08:45:22 AM  [*] Mon Jan 30 08:45:22 2023:    1    | Tr.loss: 0.687392 | Elapsed:   7.53   s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7172
01/30/2023 08:45:22 AM  [*] Started epoch: 2
01/30/2023 08:45:22 AM  [*] Mon Jan 30 08:45:22 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.524929 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.1556 & F1 0.2692 | AUC 0.7532
01/30/2023 08:45:28 AM  [*] Mon Jan 30 08:45:28 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.294680 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.4493 & F1 0.6200 | AUC 0.9028
01/30/2023 08:45:29 AM  [*] Mon Jan 30 08:45:29 2023:    2    | Tr.loss: 0.398250 | Elapsed:   7.59   s | FPR 0.0003 -> TPR: 0.12 & F1: 0.21 | AUC: 0.8769
01/30/2023 08:45:29 AM  [*] Started epoch: 3
01/30/2023 08:45:29 AM  [*] Mon Jan 30 08:45:29 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.328425 | Elapsed: 0.05s | FPR 0.0003 -> TPR 0.3913 & F1 0.5625 | AUC 0.9106
01/30/2023 08:45:36 AM  [*] Mon Jan 30 08:45:36 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.507434 | Elapsed: 6.29s | FPR 0.0003 -> TPR 0.1724 & F1 0.2941 | AUC 0.8933
01/30/2023 08:45:37 AM  [*] Mon Jan 30 08:45:37 2023:    3    | Tr.loss: 0.338290 | Elapsed:   7.71   s | FPR 0.0003 -> TPR: 0.04 & F1: 0.07 | AUC: 0.9126
01/30/2023 08:45:37 AM [!] Mon Jan 30 08:45:37 2023: Dumped results:
                model     : 1675064737-model.torch
		train time: 1675064737-trainTime.npy
		train losses: 1675064737-trainLosses.npy
		train AUC: 1675064737-auc.npy
		train F1s : 1675064737-trainF1s.npy
		train TPRs: 1675064737-trainTPRs.npy
01/30/2023 08:45:37 AM  [*] Evaluating pretrained model on test set...
01/30/2023 08:45:42 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0199 | F1: 0.0390
01/30/2023 08:45:42 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.0213 | F1: 0.0416
01/30/2023 08:45:42 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.0453 | F1: 0.0866
01/30/2023 08:45:42 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.2392 | F1: 0.3852
01/30/2023 08:45:42 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3397 | F1: 0.5039
01/30/2023 08:45:42 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4325 | F1: 0.5933
01/30/2023 08:45:42 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.6435 | F1: 0.7446
01/30/2023 08:45:42 AM  [*] Evaluating non_pretrained model on test set...
01/30/2023 08:45:47 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0665 | F1: 0.1247
01/30/2023 08:45:47 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.0921 | F1: 0.1686
01/30/2023 08:45:47 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.1896 | F1: 0.3186
01/30/2023 08:45:47 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.2645 | F1: 0.4175
01/30/2023 08:45:47 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3139 | F1: 0.4748
01/30/2023 08:45:47 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.3923 | F1: 0.5534
01/30/2023 08:45:47 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.5791 | F1: 0.6959
01/30/2023 08:45:47 AM  [!] Finished pre-training evaluation over 3 splits! Saved metrics to:
	C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\downsample_tests\downsample_U_0.3_1675063140/metrics_MaskedLanguageModel_nSplits_3_limit_None.json
01/30/2023 08:45:48 AM  [!] Starting uSize downsample 0.4 evaluation!
01/30/2023 08:45:48 AM  [!] Starting Masked Language Model evaluation over 3 splits!
01/30/2023 08:45:48 AM  [!] Loaded data and vocab. X train size: (76126, 512), X test size: (17407, 512), vocab size: 50002
01/30/2023 08:45:48 AM  [!] Initiating Self-Supervised Learning Pretraining
     Language Modeling MaskedLanguageModel
     Model TransformerEncoderLM with config:
	{'vocabSize': 50002, 'maxLen': 512, 'dModel': 64, 'nHeads': 8, 'dHidden': 256, 'nLayers': 2, 'numClasses': 1, 'hiddenNeurons': [64], 'dropout': 0.3}

01/30/2023 08:45:48 AM  [!] Running pre-training split 1/3
01/30/2023 08:45:49 AM  [!] Pre-training model...
01/30/2023 08:45:50 AM  [*] Masking sequences...
01/30/2023 08:45:58 AM  [*] Started epoch: 1
01/30/2023 08:45:59 AM  [*] Mon Jan 30 08:45:59 2023: Train Epoch: 1 [  0  /27405 (0 %)]	Loss: 436.925079 | Elapsed: 0.36s
01/30/2023 08:46:13 AM  [*] Mon Jan 30 08:46:13 2023: Train Epoch: 1 [6400 /27405 (23%)]	Loss: 233.116318 | Elapsed: 14.41s
01/30/2023 08:46:29 AM  [*] Mon Jan 30 08:46:29 2023: Train Epoch: 1 [12800/27405 (47%)]	Loss: 230.490784 | Elapsed: 16.48s
01/30/2023 08:46:46 AM  [*] Mon Jan 30 08:46:46 2023: Train Epoch: 1 [19200/27405 (70%)]	Loss: 204.122192 | Elapsed: 16.45s
01/30/2023 08:47:02 AM  [*] Mon Jan 30 08:47:02 2023: Train Epoch: 1 [25600/27405 (93%)]	Loss: 184.943085 | Elapsed: 16.39s
01/30/2023 08:47:07 AM  [*] Mon Jan 30 08:47:07 2023:    1    | Tr.loss: 220.655864 | Elapsed:   69.22  s
01/30/2023 08:47:07 AM  [*] Started epoch: 2
01/30/2023 08:47:08 AM  [*] Mon Jan 30 08:47:08 2023: Train Epoch: 2 [  0  /27405 (0 %)]	Loss: 203.190826 | Elapsed: 0.13s
01/30/2023 08:47:21 AM  [*] Mon Jan 30 08:47:21 2023: Train Epoch: 2 [6400 /27405 (23%)]	Loss: 192.964172 | Elapsed: 13.90s
01/30/2023 08:47:38 AM  [*] Mon Jan 30 08:47:38 2023: Train Epoch: 2 [12800/27405 (47%)]	Loss: 182.706772 | Elapsed: 16.22s
01/30/2023 08:47:54 AM  [*] Mon Jan 30 08:47:54 2023: Train Epoch: 2 [19200/27405 (70%)]	Loss: 177.652588 | Elapsed: 16.12s
01/30/2023 08:48:10 AM  [*] Mon Jan 30 08:48:10 2023: Train Epoch: 2 [25600/27405 (93%)]	Loss: 220.181519 | Elapsed: 16.21s
01/30/2023 08:48:15 AM  [*] Mon Jan 30 08:48:15 2023:    2    | Tr.loss: 198.129244 | Elapsed:   67.78  s
01/30/2023 08:48:15 AM  [*] Started epoch: 3
01/30/2023 08:48:15 AM  [*] Mon Jan 30 08:48:15 2023: Train Epoch: 3 [  0  /27405 (0 %)]	Loss: 200.985779 | Elapsed: 0.12s
01/30/2023 08:48:29 AM  [*] Mon Jan 30 08:48:29 2023: Train Epoch: 3 [6400 /27405 (23%)]	Loss: 185.753296 | Elapsed: 13.40s
01/30/2023 08:48:45 AM  [*] Mon Jan 30 08:48:45 2023: Train Epoch: 3 [12800/27405 (47%)]	Loss: 193.715210 | Elapsed: 16.05s
01/30/2023 08:49:01 AM  [*] Mon Jan 30 08:49:01 2023: Train Epoch: 3 [19200/27405 (70%)]	Loss: 195.355286 | Elapsed: 16.16s
01/30/2023 08:49:17 AM  [*] Mon Jan 30 08:49:17 2023: Train Epoch: 3 [25600/27405 (93%)]	Loss: 182.281448 | Elapsed: 16.15s
01/30/2023 08:49:22 AM  [*] Mon Jan 30 08:49:22 2023:    3    | Tr.loss: 190.069172 | Elapsed:   67.11  s
01/30/2023 08:49:22 AM  [*] Started epoch: 4
01/30/2023 08:49:22 AM  [*] Mon Jan 30 08:49:22 2023: Train Epoch: 4 [  0  /27405 (0 %)]	Loss: 195.961380 | Elapsed: 0.13s
01/30/2023 08:49:35 AM  [*] Mon Jan 30 08:49:35 2023: Train Epoch: 4 [6400 /27405 (23%)]	Loss: 175.738113 | Elapsed: 12.85s
01/30/2023 08:49:51 AM  [*] Mon Jan 30 08:49:51 2023: Train Epoch: 4 [12800/27405 (47%)]	Loss: 179.851761 | Elapsed: 16.15s
01/30/2023 08:50:08 AM  [*] Mon Jan 30 08:50:08 2023: Train Epoch: 4 [19200/27405 (70%)]	Loss: 187.787964 | Elapsed: 16.16s
01/30/2023 08:50:24 AM  [*] Mon Jan 30 08:50:24 2023: Train Epoch: 4 [25600/27405 (93%)]	Loss: 180.099716 | Elapsed: 16.27s
01/30/2023 08:50:29 AM  [*] Mon Jan 30 08:50:29 2023:    4    | Tr.loss: 185.924640 | Elapsed:   66.57  s
01/30/2023 08:50:29 AM  [*] Started epoch: 5
01/30/2023 08:50:29 AM  [*] Mon Jan 30 08:50:29 2023: Train Epoch: 5 [  0  /27405 (0 %)]	Loss: 181.821777 | Elapsed: 0.15s
01/30/2023 08:50:41 AM  [*] Mon Jan 30 08:50:41 2023: Train Epoch: 5 [6400 /27405 (23%)]	Loss: 189.503876 | Elapsed: 12.40s
01/30/2023 08:50:58 AM  [*] Mon Jan 30 08:50:58 2023: Train Epoch: 5 [12800/27405 (47%)]	Loss: 189.044220 | Elapsed: 16.59s
01/30/2023 08:51:15 AM  [*] Mon Jan 30 08:51:15 2023: Train Epoch: 5 [19200/27405 (70%)]	Loss: 156.587830 | Elapsed: 16.47s
01/30/2023 08:51:32 AM  [*] Mon Jan 30 08:51:32 2023: Train Epoch: 5 [25600/27405 (93%)]	Loss: 189.229706 | Elapsed: 17.66s
01/30/2023 08:51:38 AM  [*] Mon Jan 30 08:51:38 2023:    5    | Tr.loss: 182.954643 | Elapsed:   69.51  s
01/30/2023 08:51:38 AM  [*] Started epoch: 6
01/30/2023 08:51:39 AM  [*] Mon Jan 30 08:51:39 2023: Train Epoch: 6 [  0  /27405 (0 %)]	Loss: 176.254730 | Elapsed: 0.13s
01/30/2023 08:51:52 AM  [*] Mon Jan 30 08:51:52 2023: Train Epoch: 6 [6400 /27405 (23%)]	Loss: 157.448166 | Elapsed: 13.23s
01/30/2023 08:52:05 AM  [*] Mon Jan 30 08:52:05 2023: Train Epoch: 6 [12800/27405 (47%)]	Loss: 180.898743 | Elapsed: 13.57s
01/30/2023 08:52:21 AM  [*] Mon Jan 30 08:52:21 2023: Train Epoch: 6 [19200/27405 (70%)]	Loss: 180.746811 | Elapsed: 16.12s
01/30/2023 08:52:38 AM  [*] Mon Jan 30 08:52:38 2023: Train Epoch: 6 [25600/27405 (93%)]	Loss: 195.250977 | Elapsed: 16.12s
01/30/2023 08:52:43 AM  [*] Mon Jan 30 08:52:43 2023:    6    | Tr.loss: 180.989010 | Elapsed:   64.94  s
01/30/2023 08:52:43 AM  [*] Started epoch: 7
01/30/2023 08:52:43 AM  [*] Mon Jan 30 08:52:43 2023: Train Epoch: 7 [  0  /27405 (0 %)]	Loss: 169.721832 | Elapsed: 0.13s
01/30/2023 08:52:56 AM  [*] Mon Jan 30 08:52:56 2023: Train Epoch: 7 [6400 /27405 (23%)]	Loss: 199.645111 | Elapsed: 12.67s
01/30/2023 08:53:09 AM  [*] Mon Jan 30 08:53:09 2023: Train Epoch: 7 [12800/27405 (47%)]	Loss: 167.397644 | Elapsed: 13.23s
01/30/2023 08:53:26 AM  [*] Mon Jan 30 08:53:26 2023: Train Epoch: 7 [19200/27405 (70%)]	Loss: 192.907654 | Elapsed: 16.20s
01/30/2023 08:53:42 AM  [*] Mon Jan 30 08:53:42 2023: Train Epoch: 7 [25600/27405 (93%)]	Loss: 169.469391 | Elapsed: 16.22s
01/30/2023 08:53:47 AM  [*] Mon Jan 30 08:53:47 2023:    7    | Tr.loss: 179.718724 | Elapsed:   64.12  s
01/30/2023 08:53:47 AM  [*] Started epoch: 8
01/30/2023 08:53:48 AM  [*] Mon Jan 30 08:53:48 2023: Train Epoch: 8 [  0  /27405 (0 %)]	Loss: 183.855804 | Elapsed: 0.14s
01/30/2023 08:54:01 AM  [*] Mon Jan 30 08:54:01 2023: Train Epoch: 8 [6400 /27405 (23%)]	Loss: 167.635132 | Elapsed: 13.43s
01/30/2023 08:54:15 AM  [*] Mon Jan 30 08:54:15 2023: Train Epoch: 8 [12800/27405 (47%)]	Loss: 182.754730 | Elapsed: 13.53s
01/30/2023 08:54:31 AM  [*] Mon Jan 30 08:54:31 2023: Train Epoch: 8 [19200/27405 (70%)]	Loss: 191.472336 | Elapsed: 16.79s
01/30/2023 08:54:49 AM  [*] Mon Jan 30 08:54:49 2023: Train Epoch: 8 [25600/27405 (93%)]	Loss: 160.969498 | Elapsed: 17.56s
01/30/2023 08:54:54 AM  [*] Mon Jan 30 08:54:54 2023:    8    | Tr.loss: 178.468349 | Elapsed:   66.48  s
01/30/2023 08:54:54 AM  [*] Started epoch: 9
01/30/2023 08:54:54 AM  [*] Mon Jan 30 08:54:54 2023: Train Epoch: 9 [  0  /27405 (0 %)]	Loss: 187.062408 | Elapsed: 0.15s
01/30/2023 08:55:07 AM  [*] Mon Jan 30 08:55:07 2023: Train Epoch: 9 [6400 /27405 (23%)]	Loss: 146.703598 | Elapsed: 13.19s
01/30/2023 08:55:20 AM  [*] Mon Jan 30 08:55:20 2023: Train Epoch: 9 [12800/27405 (47%)]	Loss: 148.914871 | Elapsed: 13.12s
01/30/2023 08:55:36 AM  [*] Mon Jan 30 08:55:36 2023: Train Epoch: 9 [19200/27405 (70%)]	Loss: 175.250778 | Elapsed: 15.67s
01/30/2023 08:55:53 AM  [*] Mon Jan 30 08:55:53 2023: Train Epoch: 9 [25600/27405 (93%)]	Loss: 167.321091 | Elapsed: 17.10s
01/30/2023 08:55:59 AM  [*] Mon Jan 30 08:55:59 2023:    9    | Tr.loss: 177.404744 | Elapsed:   64.70  s
01/30/2023 08:55:59 AM  [*] Started epoch: 10
01/30/2023 08:55:59 AM  [*] Mon Jan 30 08:55:59 2023: Train Epoch: 10 [  0  /27405 (0 %)]	Loss: 148.040771 | Elapsed: 0.13s
01/30/2023 08:56:12 AM  [*] Mon Jan 30 08:56:12 2023: Train Epoch: 10 [6400 /27405 (23%)]	Loss: 196.765350 | Elapsed: 12.74s
01/30/2023 08:56:25 AM  [*] Mon Jan 30 08:56:25 2023: Train Epoch: 10 [12800/27405 (47%)]	Loss: 166.265320 | Elapsed: 13.07s
01/30/2023 08:56:40 AM  [*] Mon Jan 30 08:56:40 2023: Train Epoch: 10 [19200/27405 (70%)]	Loss: 171.453003 | Elapsed: 15.59s
01/30/2023 08:56:58 AM  [*] Mon Jan 30 08:56:58 2023: Train Epoch: 10 [25600/27405 (93%)]	Loss: 144.027908 | Elapsed: 17.53s
01/30/2023 08:57:03 AM  [*] Mon Jan 30 08:57:03 2023:   10    | Tr.loss: 176.588232 | Elapsed:   64.35  s
01/30/2023 08:57:04 AM [!] Mon Jan 30 08:57:04 2023: Dumped results:
                model     : 1675065423-model.torch
		train time: 1675065423-trainTime.npy
		train losses: 1675065423-trainLosses.npy
		train AUC: 1675065423-auc.npy
01/30/2023 08:57:04 AM  [!] Training pretrained model on downstream task...
01/30/2023 08:57:04 AM  [*] Started epoch: 1
01/30/2023 08:57:05 AM  [*] Mon Jan 30 08:57:05 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 1.290931 | Elapsed: 0.15s | FPR 0.0003 -> TPR 0.0811 & F1 0.1500 | AUC 0.6907
01/30/2023 08:57:14 AM  [*] Mon Jan 30 08:57:14 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.397561 | Elapsed: 9.49s | FPR 0.0003 -> TPR 0.2881 & F1 0.4474 | AUC 0.9014
01/30/2023 08:57:16 AM  [*] Mon Jan 30 08:57:16 2023:    1    | Tr.loss: 0.521026 | Elapsed:   11.54  s | FPR 0.0003 -> TPR: 0.01 & F1: 0.03 | AUC: 0.7808
01/30/2023 08:57:16 AM  [*] Started epoch: 2
01/30/2023 08:57:16 AM  [*] Mon Jan 30 08:57:16 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.348011 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.4667 & F1 0.6364 | AUC 0.8667
01/30/2023 08:57:26 AM  [*] Mon Jan 30 08:57:26 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.256541 | Elapsed: 9.44s | FPR 0.0003 -> TPR 0.1781 & F1 0.3023 | AUC 0.9107
01/30/2023 08:57:27 AM  [*] Mon Jan 30 08:57:27 2023:    2    | Tr.loss: 0.364945 | Elapsed:   11.40  s | FPR 0.0003 -> TPR: 0.16 & F1: 0.27 | AUC: 0.8924
01/30/2023 08:57:27 AM  [*] Started epoch: 3
01/30/2023 08:57:28 AM  [*] Mon Jan 30 08:57:28 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.259088 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.7838 & F1 0.8788 | AUC 0.9630
01/30/2023 08:57:38 AM  [*] Mon Jan 30 08:57:38 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.266885 | Elapsed: 10.54s | FPR 0.0003 -> TPR 0.3833 & F1 0.5542 | AUC 0.9585
01/30/2023 08:57:40 AM  [*] Mon Jan 30 08:57:40 2023:    3    | Tr.loss: 0.284439 | Elapsed:   12.76  s | FPR 0.0003 -> TPR: 0.32 & F1: 0.49 | AUC: 0.9430
01/30/2023 08:57:41 AM [!] Mon Jan 30 08:57:41 2023: Dumped results:
                model     : 1675065460-model.torch
		train time: 1675065460-trainTime.npy
		train losses: 1675065460-trainLosses.npy
		train AUC: 1675065460-auc.npy
		train F1s : 1675065460-trainF1s.npy
		train TPRs: 1675065460-trainTPRs.npy
01/30/2023 08:57:41 AM  [!] Training non_pretrained model on downstream task...
01/30/2023 08:57:41 AM  [*] Started epoch: 1
01/30/2023 08:57:41 AM  [*] Mon Jan 30 08:57:41 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 1.301832 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.1087 & F1 0.1961 | AUC 0.4771
01/30/2023 08:57:48 AM  [*] Mon Jan 30 08:57:48 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.418171 | Elapsed: 7.08s | FPR 0.0003 -> TPR 0.4000 & F1 0.5714 | AUC 0.8000
01/30/2023 08:57:50 AM  [*] Mon Jan 30 08:57:50 2023:    1    | Tr.loss: 0.583232 | Elapsed:   8.66   s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7458
01/30/2023 08:57:50 AM  [*] Started epoch: 2
01/30/2023 08:57:50 AM  [*] Mon Jan 30 08:57:50 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.441386 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.3617 & F1 0.5312 | AUC 0.8148
01/30/2023 08:57:57 AM  [*] Mon Jan 30 08:57:57 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.437415 | Elapsed: 7.05s | FPR 0.0003 -> TPR 0.1343 & F1 0.2368 | AUC 0.8860
01/30/2023 08:57:58 AM  [*] Mon Jan 30 08:57:58 2023:    2    | Tr.loss: 0.378870 | Elapsed:   8.54   s | FPR 0.0003 -> TPR: 0.10 & F1: 0.18 | AUC: 0.8847
01/30/2023 08:57:58 AM  [*] Started epoch: 3
01/30/2023 08:57:58 AM  [*] Mon Jan 30 08:57:58 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.211144 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.5957 & F1 0.7467 | AUC 0.9650
01/30/2023 08:58:05 AM  [*] Mon Jan 30 08:58:05 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.338604 | Elapsed: 6.98s | FPR 0.0003 -> TPR 0.5231 & F1 0.6869 | AUC 0.8769
01/30/2023 08:58:07 AM  [*] Mon Jan 30 08:58:07 2023:    3    | Tr.loss: 0.309237 | Elapsed:   8.60   s | FPR 0.0003 -> TPR: 0.23 & F1: 0.37 | AUC: 0.9274
01/30/2023 08:58:07 AM [!] Mon Jan 30 08:58:07 2023: Dumped results:
                model     : 1675065487-model.torch
		train time: 1675065487-trainTime.npy
		train losses: 1675065487-trainLosses.npy
		train AUC: 1675065487-auc.npy
		train F1s : 1675065487-trainF1s.npy
		train TPRs: 1675065487-trainTPRs.npy
01/30/2023 08:58:07 AM  [*] Evaluating pretrained model on test set...
01/30/2023 08:58:13 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0362 | F1: 0.0698
01/30/2023 08:58:13 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.2273 | F1: 0.3703
01/30/2023 08:58:13 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.3225 | F1: 0.4873
01/30/2023 08:58:13 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3738 | F1: 0.5432
01/30/2023 08:58:13 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.4433 | F1: 0.6107
01/30/2023 08:58:13 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4984 | F1: 0.6541
01/30/2023 08:58:13 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.7129 | F1: 0.7931
01/30/2023 08:58:13 AM  [*] Evaluating non_pretrained model on test set...
01/30/2023 08:58:19 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0000 | F1: 0.0000
01/30/2023 08:58:19 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1749 | F1: 0.2977
01/30/2023 08:58:19 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.2062 | F1: 0.3417
01/30/2023 08:58:19 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.2535 | F1: 0.4037
01/30/2023 08:58:19 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3148 | F1: 0.4758
01/30/2023 08:58:19 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4111 | F1: 0.5724
01/30/2023 08:58:19 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.5950 | F1: 0.7083
01/30/2023 08:58:19 AM  [!] Running pre-training split 2/3
01/30/2023 08:58:20 AM  [!] Pre-training model...
01/30/2023 08:58:21 AM  [*] Masking sequences...
01/30/2023 08:58:30 AM  [*] Started epoch: 1
01/30/2023 08:58:31 AM  [*] Mon Jan 30 08:58:31 2023: Train Epoch: 1 [  0  /27405 (0 %)]	Loss: 443.630402 | Elapsed: 0.31s
01/30/2023 08:58:44 AM  [*] Mon Jan 30 08:58:44 2023: Train Epoch: 1 [6400 /27405 (23%)]	Loss: 220.452652 | Elapsed: 13.86s
01/30/2023 08:58:58 AM  [*] Mon Jan 30 08:58:58 2023: Train Epoch: 1 [12800/27405 (47%)]	Loss: 230.888641 | Elapsed: 13.48s
01/30/2023 08:59:15 AM  [*] Mon Jan 30 08:59:15 2023: Train Epoch: 1 [19200/27405 (70%)]	Loss: 203.093491 | Elapsed: 17.02s
01/30/2023 08:59:33 AM  [*] Mon Jan 30 08:59:33 2023: Train Epoch: 1 [25600/27405 (93%)]	Loss: 203.837860 | Elapsed: 18.02s
01/30/2023 08:59:39 AM  [*] Mon Jan 30 08:59:39 2023:    1    | Tr.loss: 221.255532 | Elapsed:   68.42  s
01/30/2023 08:59:39 AM  [*] Started epoch: 2
01/30/2023 08:59:39 AM  [*] Mon Jan 30 08:59:39 2023: Train Epoch: 2 [  0  /27405 (0 %)]	Loss: 198.921326 | Elapsed: 0.14s
01/30/2023 08:59:53 AM  [*] Mon Jan 30 08:59:53 2023: Train Epoch: 2 [6400 /27405 (23%)]	Loss: 188.908310 | Elapsed: 13.65s
01/30/2023 09:00:06 AM  [*] Mon Jan 30 09:00:06 2023: Train Epoch: 2 [12800/27405 (47%)]	Loss: 180.741821 | Elapsed: 13.63s
01/30/2023 09:00:22 AM  [*] Mon Jan 30 09:00:22 2023: Train Epoch: 2 [19200/27405 (70%)]	Loss: 212.835922 | Elapsed: 16.17s
01/30/2023 09:00:39 AM  [*] Mon Jan 30 09:00:39 2023: Train Epoch: 2 [25600/27405 (93%)]	Loss: 192.480194 | Elapsed: 16.68s
01/30/2023 09:00:45 AM  [*] Mon Jan 30 09:00:45 2023:    2    | Tr.loss: 195.330599 | Elapsed:   65.90  s
01/30/2023 09:00:45 AM  [*] Started epoch: 3
01/30/2023 09:00:45 AM  [*] Mon Jan 30 09:00:45 2023: Train Epoch: 3 [  0  /27405 (0 %)]	Loss: 198.412628 | Elapsed: 0.14s
01/30/2023 09:00:58 AM  [*] Mon Jan 30 09:00:58 2023: Train Epoch: 3 [6400 /27405 (23%)]	Loss: 177.743164 | Elapsed: 13.47s
01/30/2023 09:01:12 AM  [*] Mon Jan 30 09:01:12 2023: Train Epoch: 3 [12800/27405 (47%)]	Loss: 190.716675 | Elapsed: 14.03s
01/30/2023 09:01:28 AM  [*] Mon Jan 30 09:01:28 2023: Train Epoch: 3 [19200/27405 (70%)]	Loss: 172.083984 | Elapsed: 16.12s
01/30/2023 09:01:45 AM  [*] Mon Jan 30 09:01:45 2023: Train Epoch: 3 [25600/27405 (93%)]	Loss: 196.955688 | Elapsed: 17.09s
01/30/2023 09:01:51 AM  [*] Mon Jan 30 09:01:51 2023:    3    | Tr.loss: 186.919808 | Elapsed:   66.26  s
01/30/2023 09:01:51 AM  [*] Started epoch: 4
01/30/2023 09:01:51 AM  [*] Mon Jan 30 09:01:51 2023: Train Epoch: 4 [  0  /27405 (0 %)]	Loss: 218.320663 | Elapsed: 0.13s
01/30/2023 09:02:05 AM  [*] Mon Jan 30 09:02:05 2023: Train Epoch: 4 [6400 /27405 (23%)]	Loss: 198.026886 | Elapsed: 13.91s
01/30/2023 09:02:19 AM  [*] Mon Jan 30 09:02:19 2023: Train Epoch: 4 [12800/27405 (47%)]	Loss: 207.267181 | Elapsed: 14.16s
01/30/2023 09:02:35 AM  [*] Mon Jan 30 09:02:35 2023: Train Epoch: 4 [19200/27405 (70%)]	Loss: 181.968231 | Elapsed: 15.97s
01/30/2023 09:02:52 AM  [*] Mon Jan 30 09:02:52 2023: Train Epoch: 4 [25600/27405 (93%)]	Loss: 187.126740 | Elapsed: 16.97s
01/30/2023 09:02:58 AM  [*] Mon Jan 30 09:02:58 2023:    4    | Tr.loss: 182.870052 | Elapsed:   66.83  s
01/30/2023 09:02:58 AM  [*] Started epoch: 5
01/30/2023 09:02:58 AM  [*] Mon Jan 30 09:02:58 2023: Train Epoch: 5 [  0  /27405 (0 %)]	Loss: 190.440842 | Elapsed: 0.14s
01/30/2023 09:03:12 AM  [*] Mon Jan 30 09:03:12 2023: Train Epoch: 5 [6400 /27405 (23%)]	Loss: 179.309052 | Elapsed: 14.10s
01/30/2023 09:03:25 AM  [*] Mon Jan 30 09:03:25 2023: Train Epoch: 5 [12800/27405 (47%)]	Loss: 202.493530 | Elapsed: 13.50s
01/30/2023 09:03:41 AM  [*] Mon Jan 30 09:03:41 2023: Train Epoch: 5 [19200/27405 (70%)]	Loss: 157.778336 | Elapsed: 15.42s
01/30/2023 09:03:58 AM  [*] Mon Jan 30 09:03:58 2023: Train Epoch: 5 [25600/27405 (93%)]	Loss: 193.484039 | Elapsed: 17.56s
01/30/2023 09:04:05 AM  [*] Mon Jan 30 09:04:05 2023:    5    | Tr.loss: 180.316281 | Elapsed:   66.80  s
01/30/2023 09:04:05 AM  [*] Started epoch: 6
01/30/2023 09:04:05 AM  [*] Mon Jan 30 09:04:05 2023: Train Epoch: 6 [  0  /27405 (0 %)]	Loss: 182.367493 | Elapsed: 0.14s
01/30/2023 09:04:18 AM  [*] Mon Jan 30 09:04:18 2023: Train Epoch: 6 [6400 /27405 (23%)]	Loss: 179.725418 | Elapsed: 13.27s
01/30/2023 09:04:31 AM  [*] Mon Jan 30 09:04:31 2023: Train Epoch: 6 [12800/27405 (47%)]	Loss: 194.183609 | Elapsed: 12.84s
01/30/2023 09:04:45 AM  [*] Mon Jan 30 09:04:45 2023: Train Epoch: 6 [19200/27405 (70%)]	Loss: 163.595566 | Elapsed: 14.63s
01/30/2023 09:05:02 AM  [*] Mon Jan 30 09:05:02 2023: Train Epoch: 6 [25600/27405 (93%)]	Loss: 181.192444 | Elapsed: 16.71s
01/30/2023 09:05:08 AM  [*] Mon Jan 30 09:05:08 2023:    6    | Tr.loss: 178.361993 | Elapsed:   63.09  s
01/30/2023 09:05:08 AM  [*] Started epoch: 7
01/30/2023 09:05:08 AM  [*] Mon Jan 30 09:05:08 2023: Train Epoch: 7 [  0  /27405 (0 %)]	Loss: 182.881470 | Elapsed: 0.14s
01/30/2023 09:05:21 AM  [*] Mon Jan 30 09:05:21 2023: Train Epoch: 7 [6400 /27405 (23%)]	Loss: 166.725250 | Elapsed: 13.47s
01/30/2023 09:05:35 AM  [*] Mon Jan 30 09:05:35 2023: Train Epoch: 7 [12800/27405 (47%)]	Loss: 196.964996 | Elapsed: 13.63s
01/30/2023 09:05:51 AM  [*] Mon Jan 30 09:05:51 2023: Train Epoch: 7 [19200/27405 (70%)]	Loss: 168.898041 | Elapsed: 15.83s
01/30/2023 09:06:08 AM  [*] Mon Jan 30 09:06:08 2023: Train Epoch: 7 [25600/27405 (93%)]	Loss: 167.368134 | Elapsed: 17.10s
01/30/2023 09:06:13 AM  [*] Mon Jan 30 09:06:13 2023:    7    | Tr.loss: 177.028689 | Elapsed:   65.55  s
01/30/2023 09:06:13 AM  [*] Started epoch: 8
01/30/2023 09:06:13 AM  [*] Mon Jan 30 09:06:13 2023: Train Epoch: 8 [  0  /27405 (0 %)]	Loss: 172.167450 | Elapsed: 0.15s
01/30/2023 09:06:27 AM  [*] Mon Jan 30 09:06:27 2023: Train Epoch: 8 [6400 /27405 (23%)]	Loss: 193.619568 | Elapsed: 13.60s
01/30/2023 09:06:41 AM  [*] Mon Jan 30 09:06:41 2023: Train Epoch: 8 [12800/27405 (47%)]	Loss: 171.095322 | Elapsed: 14.26s
01/30/2023 09:06:56 AM  [*] Mon Jan 30 09:06:56 2023: Train Epoch: 8 [19200/27405 (70%)]	Loss: 187.271500 | Elapsed: 15.22s
01/30/2023 09:07:14 AM  [*] Mon Jan 30 09:07:14 2023: Train Epoch: 8 [25600/27405 (93%)]	Loss: 169.542923 | Elapsed: 17.11s
01/30/2023 09:07:19 AM  [*] Mon Jan 30 09:07:19 2023:    8    | Tr.loss: 176.081192 | Elapsed:   66.08  s
01/30/2023 09:07:19 AM  [*] Started epoch: 9
01/30/2023 09:07:19 AM  [*] Mon Jan 30 09:07:19 2023: Train Epoch: 9 [  0  /27405 (0 %)]	Loss: 156.612991 | Elapsed: 0.15s
01/30/2023 09:07:34 AM  [*] Mon Jan 30 09:07:34 2023: Train Epoch: 9 [6400 /27405 (23%)]	Loss: 172.509735 | Elapsed: 14.38s
01/30/2023 09:07:47 AM  [*] Mon Jan 30 09:07:47 2023: Train Epoch: 9 [12800/27405 (47%)]	Loss: 172.855820 | Elapsed: 13.69s
01/30/2023 09:08:03 AM  [*] Mon Jan 30 09:08:03 2023: Train Epoch: 9 [19200/27405 (70%)]	Loss: 174.212769 | Elapsed: 15.45s
01/30/2023 09:08:21 AM  [*] Mon Jan 30 09:08:21 2023: Train Epoch: 9 [25600/27405 (93%)]	Loss: 180.894104 | Elapsed: 17.67s
01/30/2023 09:08:26 AM  [*] Mon Jan 30 09:08:26 2023:    9    | Tr.loss: 175.190456 | Elapsed:   67.11  s
01/30/2023 09:08:26 AM  [*] Started epoch: 10
01/30/2023 09:08:27 AM  [*] Mon Jan 30 09:08:27 2023: Train Epoch: 10 [  0  /27405 (0 %)]	Loss: 171.182343 | Elapsed: 0.15s
01/30/2023 09:08:40 AM  [*] Mon Jan 30 09:08:40 2023: Train Epoch: 10 [6400 /27405 (23%)]	Loss: 181.055740 | Elapsed: 13.85s
01/30/2023 09:08:54 AM  [*] Mon Jan 30 09:08:54 2023: Train Epoch: 10 [12800/27405 (47%)]	Loss: 161.561005 | Elapsed: 13.55s
01/30/2023 09:09:09 AM  [*] Mon Jan 30 09:09:09 2023: Train Epoch: 10 [19200/27405 (70%)]	Loss: 182.322159 | Elapsed: 14.87s
01/30/2023 09:09:26 AM  [*] Mon Jan 30 09:09:26 2023: Train Epoch: 10 [25600/27405 (93%)]	Loss: 168.926727 | Elapsed: 16.85s
01/30/2023 09:09:31 AM  [*] Mon Jan 30 09:09:31 2023:   10    | Tr.loss: 174.279780 | Elapsed:   64.81  s
01/30/2023 09:09:32 AM [!] Mon Jan 30 09:09:32 2023: Dumped results:
                model     : 1675066171-model.torch
		train time: 1675066171-trainTime.npy
		train losses: 1675066171-trainLosses.npy
		train AUC: 1675066171-auc.npy
01/30/2023 09:09:33 AM  [!] Training pretrained model on downstream task...
01/30/2023 09:09:33 AM  [*] Started epoch: 1
01/30/2023 09:09:33 AM  [*] Mon Jan 30 09:09:33 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 2.275626 | Elapsed: 0.14s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.5087
01/30/2023 09:09:43 AM  [*] Mon Jan 30 09:09:43 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.522899 | Elapsed: 9.59s | FPR 0.0003 -> TPR 0.1867 & F1 0.3146 | AUC 0.7589
01/30/2023 09:09:45 AM  [*] Mon Jan 30 09:09:45 2023:    1    | Tr.loss: 0.570367 | Elapsed:   11.73  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7917
01/30/2023 09:09:45 AM  [*] Started epoch: 2
01/30/2023 09:09:45 AM  [*] Mon Jan 30 09:09:45 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.363439 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.4615 & F1 0.6316 | AUC 0.8718
01/30/2023 09:09:54 AM  [*] Mon Jan 30 09:09:54 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.343202 | Elapsed: 9.45s | FPR 0.0003 -> TPR 0.5846 & F1 0.7379 | AUC 0.8967
01/30/2023 09:09:56 AM  [*] Mon Jan 30 09:09:56 2023:    2    | Tr.loss: 0.346302 | Elapsed:   11.43  s | FPR 0.0003 -> TPR: 0.16 & F1: 0.27 | AUC: 0.9038
01/30/2023 09:09:56 AM  [*] Started epoch: 3
01/30/2023 09:09:56 AM  [*] Mon Jan 30 09:09:56 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.238577 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.6383 & F1 0.7792 | AUC 0.9499
01/30/2023 09:10:06 AM  [*] Mon Jan 30 09:10:06 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.353782 | Elapsed: 9.57s | FPR 0.0003 -> TPR 0.4697 & F1 0.6392 | AUC 0.9122
01/30/2023 09:10:08 AM  [*] Mon Jan 30 09:10:08 2023:    3    | Tr.loss: 0.289478 | Elapsed:   11.64  s | FPR 0.0003 -> TPR: 0.28 & F1: 0.43 | AUC: 0.9359
01/30/2023 09:10:08 AM [!] Mon Jan 30 09:10:08 2023: Dumped results:
                model     : 1675066208-model.torch
		train time: 1675066208-trainTime.npy
		train losses: 1675066208-trainLosses.npy
		train AUC: 1675066208-auc.npy
		train F1s : 1675066208-trainF1s.npy
		train TPRs: 1675066208-trainTPRs.npy
01/30/2023 09:10:08 AM  [!] Training non_pretrained model on downstream task...
01/30/2023 09:10:09 AM  [*] Started epoch: 1
01/30/2023 09:10:09 AM  [*] Mon Jan 30 09:10:09 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 1.529234 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.1667 & F1 0.2857 | AUC 0.6818
01/30/2023 09:10:15 AM  [*] Mon Jan 30 09:10:15 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.490433 | Elapsed: 6.75s | FPR 0.0003 -> TPR 0.4032 & F1 0.5747 | AUC 0.8442
01/30/2023 09:10:17 AM  [*] Mon Jan 30 09:10:17 2023:    1    | Tr.loss: 0.586282 | Elapsed:   8.17   s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7446
01/30/2023 09:10:17 AM  [*] Started epoch: 2
01/30/2023 09:10:17 AM  [*] Mon Jan 30 09:10:17 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.393066 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.5000 & F1 0.6667 | AUC 0.8781
01/30/2023 09:10:24 AM  [*] Mon Jan 30 09:10:24 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.335582 | Elapsed: 6.92s | FPR 0.0003 -> TPR 0.4861 & F1 0.6542 | AUC 0.9127
01/30/2023 09:10:25 AM  [*] Mon Jan 30 09:10:25 2023:    2    | Tr.loss: 0.381202 | Elapsed:   8.38   s | FPR 0.0003 -> TPR: 0.08 & F1: 0.14 | AUC: 0.8819
01/30/2023 09:10:25 AM  [*] Started epoch: 3
01/30/2023 09:10:25 AM  [*] Mon Jan 30 09:10:25 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.329844 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.3750 & F1 0.5455 | AUC 0.9146
01/30/2023 09:10:32 AM  [*] Mon Jan 30 09:10:32 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.264716 | Elapsed: 6.83s | FPR 0.0003 -> TPR 0.7143 & F1 0.8333 | AUC 0.9448
01/30/2023 09:10:34 AM  [*] Mon Jan 30 09:10:34 2023:    3    | Tr.loss: 0.314477 | Elapsed:   8.46   s | FPR 0.0003 -> TPR: 0.22 & F1: 0.36 | AUC: 0.9233
01/30/2023 09:10:34 AM [!] Mon Jan 30 09:10:34 2023: Dumped results:
                model     : 1675066234-model.torch
		train time: 1675066234-trainTime.npy
		train losses: 1675066234-trainLosses.npy
		train AUC: 1675066234-auc.npy
		train F1s : 1675066234-trainF1s.npy
		train TPRs: 1675066234-trainTPRs.npy
01/30/2023 09:10:34 AM  [*] Evaluating pretrained model on test set...
01/30/2023 09:10:39 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0407 | F1: 0.0783
01/30/2023 09:10:39 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1395 | F1: 0.2448
01/30/2023 09:10:39 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.2687 | F1: 0.4234
01/30/2023 09:10:39 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3239 | F1: 0.4884
01/30/2023 09:10:39 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3818 | F1: 0.5492
01/30/2023 09:10:39 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4537 | F1: 0.6134
01/30/2023 09:10:39 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.6386 | F1: 0.7410
01/30/2023 09:10:39 AM  [*] Evaluating non_pretrained model on test set...
01/30/2023 09:10:45 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0345 | F1: 0.0666
01/30/2023 09:10:45 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1083 | F1: 0.1953
01/30/2023 09:10:45 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.1553 | F1: 0.2686
01/30/2023 09:10:45 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.2043 | F1: 0.3386
01/30/2023 09:10:45 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.2592 | F1: 0.4089
01/30/2023 09:10:45 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.3471 | F1: 0.5058
01/30/2023 09:10:45 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.5542 | F1: 0.6761
01/30/2023 09:10:45 AM  [!] Running pre-training split 3/3
01/30/2023 09:10:46 AM  [!] Pre-training model...
01/30/2023 09:10:47 AM  [*] Masking sequences...
01/30/2023 09:10:56 AM  [*] Started epoch: 1
01/30/2023 09:10:56 AM  [*] Mon Jan 30 09:10:56 2023: Train Epoch: 1 [  0  /27405 (0 %)]	Loss: 426.360229 | Elapsed: 0.37s
01/30/2023 09:11:09 AM  [*] Mon Jan 30 09:11:09 2023: Train Epoch: 1 [6400 /27405 (23%)]	Loss: 216.292969 | Elapsed: 12.66s
01/30/2023 09:11:21 AM  [*] Mon Jan 30 09:11:21 2023: Train Epoch: 1 [12800/27405 (47%)]	Loss: 203.440918 | Elapsed: 12.70s
01/30/2023 09:11:37 AM  [*] Mon Jan 30 09:11:37 2023: Train Epoch: 1 [19200/27405 (70%)]	Loss: 214.052200 | Elapsed: 15.63s
01/30/2023 09:11:54 AM  [*] Mon Jan 30 09:11:54 2023: Train Epoch: 1 [25600/27405 (93%)]	Loss: 194.122513 | Elapsed: 16.53s
01/30/2023 09:11:59 AM  [*] Mon Jan 30 09:11:59 2023:    1    | Tr.loss: 222.102317 | Elapsed:   63.15  s
01/30/2023 09:11:59 AM  [*] Started epoch: 2
01/30/2023 09:11:59 AM  [*] Mon Jan 30 09:11:59 2023: Train Epoch: 2 [  0  /27405 (0 %)]	Loss: 201.452484 | Elapsed: 0.13s
01/30/2023 09:12:12 AM  [*] Mon Jan 30 09:12:12 2023: Train Epoch: 2 [6400 /27405 (23%)]	Loss: 186.960449 | Elapsed: 12.96s
01/30/2023 09:12:25 AM  [*] Mon Jan 30 09:12:25 2023: Train Epoch: 2 [12800/27405 (47%)]	Loss: 204.346344 | Elapsed: 13.59s
01/30/2023 09:12:42 AM  [*] Mon Jan 30 09:12:42 2023: Train Epoch: 2 [19200/27405 (70%)]	Loss: 168.795532 | Elapsed: 16.46s
01/30/2023 09:13:00 AM  [*] Mon Jan 30 09:13:00 2023: Train Epoch: 2 [25600/27405 (93%)]	Loss: 169.977142 | Elapsed: 17.78s
01/30/2023 09:13:05 AM  [*] Mon Jan 30 09:13:05 2023:    2    | Tr.loss: 200.341695 | Elapsed:   66.32  s
01/30/2023 09:13:05 AM  [*] Started epoch: 3
01/30/2023 09:13:05 AM  [*] Mon Jan 30 09:13:05 2023: Train Epoch: 3 [  0  /27405 (0 %)]	Loss: 200.825119 | Elapsed: 0.14s
01/30/2023 09:13:19 AM  [*] Mon Jan 30 09:13:19 2023: Train Epoch: 3 [6400 /27405 (23%)]	Loss: 183.002899 | Elapsed: 13.55s
01/30/2023 09:13:32 AM  [*] Mon Jan 30 09:13:32 2023: Train Epoch: 3 [12800/27405 (47%)]	Loss: 180.438492 | Elapsed: 13.53s
01/30/2023 09:13:48 AM  [*] Mon Jan 30 09:13:48 2023: Train Epoch: 3 [19200/27405 (70%)]	Loss: 196.162109 | Elapsed: 15.77s
01/30/2023 09:14:06 AM  [*] Mon Jan 30 09:14:06 2023: Train Epoch: 3 [25600/27405 (93%)]	Loss: 204.237335 | Elapsed: 17.40s
01/30/2023 09:14:11 AM  [*] Mon Jan 30 09:14:11 2023:    3    | Tr.loss: 191.840628 | Elapsed:   65.99  s
01/30/2023 09:14:11 AM  [*] Started epoch: 4
01/30/2023 09:14:11 AM  [*] Mon Jan 30 09:14:11 2023: Train Epoch: 4 [  0  /27405 (0 %)]	Loss: 196.116241 | Elapsed: 0.13s
01/30/2023 09:14:25 AM  [*] Mon Jan 30 09:14:25 2023: Train Epoch: 4 [6400 /27405 (23%)]	Loss: 199.051208 | Elapsed: 13.53s
01/30/2023 09:14:39 AM  [*] Mon Jan 30 09:14:39 2023: Train Epoch: 4 [12800/27405 (47%)]	Loss: 186.156403 | Elapsed: 13.84s
01/30/2023 09:14:54 AM  [*] Mon Jan 30 09:14:54 2023: Train Epoch: 4 [19200/27405 (70%)]	Loss: 194.409653 | Elapsed: 15.46s
01/30/2023 09:15:11 AM  [*] Mon Jan 30 09:15:11 2023: Train Epoch: 4 [25600/27405 (93%)]	Loss: 187.295731 | Elapsed: 17.04s
01/30/2023 09:15:17 AM  [*] Mon Jan 30 09:15:17 2023:    4    | Tr.loss: 186.918971 | Elapsed:   65.57  s
01/30/2023 09:15:17 AM  [*] Started epoch: 5
01/30/2023 09:15:17 AM  [*] Mon Jan 30 09:15:17 2023: Train Epoch: 5 [  0  /27405 (0 %)]	Loss: 188.644379 | Elapsed: 0.14s
01/30/2023 09:15:31 AM  [*] Mon Jan 30 09:15:31 2023: Train Epoch: 5 [6400 /27405 (23%)]	Loss: 166.428009 | Elapsed: 13.83s
01/30/2023 09:15:45 AM  [*] Mon Jan 30 09:15:45 2023: Train Epoch: 5 [12800/27405 (47%)]	Loss: 176.545502 | Elapsed: 14.17s
01/30/2023 09:16:00 AM  [*] Mon Jan 30 09:16:00 2023: Train Epoch: 5 [19200/27405 (70%)]	Loss: 203.766174 | Elapsed: 15.30s
01/30/2023 09:16:17 AM  [*] Mon Jan 30 09:16:17 2023: Train Epoch: 5 [25600/27405 (93%)]	Loss: 168.377167 | Elapsed: 16.79s
01/30/2023 09:16:23 AM  [*] Mon Jan 30 09:16:23 2023:    5    | Tr.loss: 183.876861 | Elapsed:   65.84  s
01/30/2023 09:16:23 AM  [*] Started epoch: 6
01/30/2023 09:16:23 AM  [*] Mon Jan 30 09:16:23 2023: Train Epoch: 6 [  0  /27405 (0 %)]	Loss: 165.687775 | Elapsed: 0.13s
01/30/2023 09:16:36 AM  [*] Mon Jan 30 09:16:36 2023: Train Epoch: 6 [6400 /27405 (23%)]	Loss: 197.509094 | Elapsed: 13.78s
01/30/2023 09:16:50 AM  [*] Mon Jan 30 09:16:50 2023: Train Epoch: 6 [12800/27405 (47%)]	Loss: 184.544968 | Elapsed: 14.05s
01/30/2023 09:17:07 AM  [*] Mon Jan 30 09:17:07 2023: Train Epoch: 6 [19200/27405 (70%)]	Loss: 194.253601 | Elapsed: 16.72s
01/30/2023 09:17:26 AM  [*] Mon Jan 30 09:17:26 2023: Train Epoch: 6 [25600/27405 (93%)]	Loss: 178.924652 | Elapsed: 18.30s
01/30/2023 09:17:32 AM  [*] Mon Jan 30 09:17:32 2023:    6    | Tr.loss: 182.048429 | Elapsed:   69.03  s
01/30/2023 09:17:32 AM  [*] Started epoch: 7
01/30/2023 09:17:32 AM  [*] Mon Jan 30 09:17:32 2023: Train Epoch: 7 [  0  /27405 (0 %)]	Loss: 173.222656 | Elapsed: 0.15s
01/30/2023 09:17:46 AM  [*] Mon Jan 30 09:17:46 2023: Train Epoch: 7 [6400 /27405 (23%)]	Loss: 181.865936 | Elapsed: 14.70s
01/30/2023 09:18:01 AM  [*] Mon Jan 30 09:18:01 2023: Train Epoch: 7 [12800/27405 (47%)]	Loss: 194.489349 | Elapsed: 14.62s
01/30/2023 09:18:17 AM  [*] Mon Jan 30 09:18:17 2023: Train Epoch: 7 [19200/27405 (70%)]	Loss: 174.463028 | Elapsed: 16.34s
01/30/2023 09:18:36 AM  [*] Mon Jan 30 09:18:36 2023: Train Epoch: 7 [25600/27405 (93%)]	Loss: 169.022598 | Elapsed: 18.45s
01/30/2023 09:18:42 AM  [*] Mon Jan 30 09:18:42 2023:    7    | Tr.loss: 180.789546 | Elapsed:   70.46  s
01/30/2023 09:18:42 AM  [*] Started epoch: 8
01/30/2023 09:18:42 AM  [*] Mon Jan 30 09:18:42 2023: Train Epoch: 8 [  0  /27405 (0 %)]	Loss: 184.769577 | Elapsed: 0.15s
01/30/2023 09:18:56 AM  [*] Mon Jan 30 09:18:56 2023: Train Epoch: 8 [6400 /27405 (23%)]	Loss: 194.901199 | Elapsed: 14.32s
01/30/2023 09:19:11 AM  [*] Mon Jan 30 09:19:11 2023: Train Epoch: 8 [12800/27405 (47%)]	Loss: 190.362091 | Elapsed: 14.50s
01/30/2023 09:19:27 AM  [*] Mon Jan 30 09:19:27 2023: Train Epoch: 8 [19200/27405 (70%)]	Loss: 166.230194 | Elapsed: 15.87s
01/30/2023 09:19:46 AM  [*] Mon Jan 30 09:19:46 2023: Train Epoch: 8 [25600/27405 (93%)]	Loss: 195.337128 | Elapsed: 18.77s
01/30/2023 09:19:52 AM  [*] Mon Jan 30 09:19:52 2023:    8    | Tr.loss: 179.478149 | Elapsed:   69.87  s
01/30/2023 09:19:52 AM  [*] Started epoch: 9
01/30/2023 09:19:52 AM  [*] Mon Jan 30 09:19:52 2023: Train Epoch: 9 [  0  /27405 (0 %)]	Loss: 169.444702 | Elapsed: 0.15s
01/30/2023 09:20:07 AM  [*] Mon Jan 30 09:20:07 2023: Train Epoch: 9 [6400 /27405 (23%)]	Loss: 204.513474 | Elapsed: 15.22s
01/30/2023 09:20:23 AM  [*] Mon Jan 30 09:20:23 2023: Train Epoch: 9 [12800/27405 (47%)]	Loss: 203.859711 | Elapsed: 15.35s
01/30/2023 09:20:39 AM  [*] Mon Jan 30 09:20:39 2023: Train Epoch: 9 [19200/27405 (70%)]	Loss: 171.616638 | Elapsed: 16.32s
01/30/2023 09:20:58 AM  [*] Mon Jan 30 09:20:58 2023: Train Epoch: 9 [25600/27405 (93%)]	Loss: 180.816666 | Elapsed: 18.74s
01/30/2023 09:21:05 AM  [*] Mon Jan 30 09:21:05 2023:    9    | Tr.loss: 178.269982 | Elapsed:   72.68  s
01/30/2023 09:21:05 AM  [*] Started epoch: 10
01/30/2023 09:21:05 AM  [*] Mon Jan 30 09:21:05 2023: Train Epoch: 10 [  0  /27405 (0 %)]	Loss: 187.544128 | Elapsed: 0.17s
01/30/2023 09:21:20 AM  [*] Mon Jan 30 09:21:20 2023: Train Epoch: 10 [6400 /27405 (23%)]	Loss: 187.437149 | Elapsed: 15.07s
01/30/2023 09:21:35 AM  [*] Mon Jan 30 09:21:35 2023: Train Epoch: 10 [12800/27405 (47%)]	Loss: 167.883240 | Elapsed: 15.02s
01/30/2023 09:21:50 AM  [*] Mon Jan 30 09:21:50 2023: Train Epoch: 10 [19200/27405 (70%)]	Loss: 155.118134 | Elapsed: 15.62s
01/30/2023 09:22:09 AM  [*] Mon Jan 30 09:22:09 2023: Train Epoch: 10 [25600/27405 (93%)]	Loss: 186.598984 | Elapsed: 18.40s
01/30/2023 09:22:15 AM  [*] Mon Jan 30 09:22:15 2023:   10    | Tr.loss: 177.638531 | Elapsed:   70.52  s
01/30/2023 09:22:16 AM [!] Mon Jan 30 09:22:16 2023: Dumped results:
                model     : 1675066935-model.torch
		train time: 1675066935-trainTime.npy
		train losses: 1675066935-trainLosses.npy
		train AUC: 1675066935-auc.npy
01/30/2023 09:22:17 AM  [!] Training pretrained model on downstream task...
01/30/2023 09:22:17 AM  [*] Started epoch: 1
01/30/2023 09:22:17 AM  [*] Mon Jan 30 09:22:17 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 3.170606 | Elapsed: 0.17s | FPR 0.0003 -> TPR 0.0233 & F1 0.0455 | AUC 0.4363
01/30/2023 09:22:28 AM  [*] Mon Jan 30 09:22:28 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.464856 | Elapsed: 10.42s | FPR 0.0003 -> TPR 0.2381 & F1 0.3846 | AUC 0.7941
01/30/2023 09:22:30 AM  [*] Mon Jan 30 09:22:30 2023:    1    | Tr.loss: 0.668538 | Elapsed:   12.73  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7494
01/30/2023 09:22:30 AM  [*] Started epoch: 2
01/30/2023 09:22:30 AM  [*] Mon Jan 30 09:22:30 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.525278 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.1277 & F1 0.2264 | AUC 0.7897
01/30/2023 09:22:40 AM  [*] Mon Jan 30 09:22:40 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.488467 | Elapsed: 10.47s | FPR 0.0003 -> TPR 0.2424 & F1 0.3902 | AUC 0.8298
01/30/2023 09:22:43 AM  [*] Mon Jan 30 09:22:43 2023:    2    | Tr.loss: 0.436550 | Elapsed:   12.73  s | FPR 0.0003 -> TPR: 0.08 & F1: 0.14 | AUC: 0.8408
01/30/2023 09:22:43 AM  [*] Started epoch: 3
01/30/2023 09:22:43 AM  [*] Mon Jan 30 09:22:43 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.373011 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.4211 & F1 0.5926 | AUC 0.8775
01/30/2023 09:22:53 AM  [*] Mon Jan 30 09:22:53 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.352103 | Elapsed: 10.54s | FPR 0.0003 -> TPR 0.5672 & F1 0.7238 | AUC 0.8964
01/30/2023 09:22:55 AM  [*] Mon Jan 30 09:22:55 2023:    3    | Tr.loss: 0.401449 | Elapsed:   12.89  s | FPR 0.0003 -> TPR: 0.15 & F1: 0.25 | AUC: 0.8668
01/30/2023 09:22:56 AM [!] Mon Jan 30 09:22:56 2023: Dumped results:
                model     : 1675066975-model.torch
		train time: 1675066975-trainTime.npy
		train losses: 1675066975-trainLosses.npy
		train AUC: 1675066975-auc.npy
		train F1s : 1675066975-trainF1s.npy
		train TPRs: 1675066975-trainTPRs.npy
01/30/2023 09:22:56 AM  [!] Training non_pretrained model on downstream task...
01/30/2023 09:22:57 AM  [*] Started epoch: 1
01/30/2023 09:22:57 AM  [*] Mon Jan 30 09:22:57 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 2.963509 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.1020 & F1 0.1852 | AUC 0.5102
01/30/2023 09:23:04 AM  [*] Mon Jan 30 09:23:04 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.435875 | Elapsed: 6.93s | FPR 0.0003 -> TPR 0.1912 & F1 0.3210 | AUC 0.7790
01/30/2023 09:23:05 AM  [*] Mon Jan 30 09:23:05 2023:    1    | Tr.loss: 0.669250 | Elapsed:   8.54   s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7188
01/30/2023 09:23:05 AM  [*] Started epoch: 2
01/30/2023 09:23:05 AM  [*] Mon Jan 30 09:23:05 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.479490 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.3111 & F1 0.4746 | AUC 0.7942
01/30/2023 09:23:13 AM  [*] Mon Jan 30 09:23:13 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.478040 | Elapsed: 7.46s | FPR 0.0003 -> TPR 0.1304 & F1 0.2308 | AUC 0.8308
01/30/2023 09:23:14 AM  [*] Mon Jan 30 09:23:14 2023:    2    | Tr.loss: 0.398249 | Elapsed:   9.01   s | FPR 0.0003 -> TPR: 0.07 & F1: 0.13 | AUC: 0.8741
01/30/2023 09:23:14 AM  [*] Started epoch: 3
01/30/2023 09:23:14 AM  [*] Mon Jan 30 09:23:14 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.370604 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.4565 & F1 0.6269 | AUC 0.8973
01/30/2023 09:23:22 AM  [*] Mon Jan 30 09:23:22 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.487597 | Elapsed: 7.05s | FPR 0.0003 -> TPR 0.3103 & F1 0.4737 | AUC 0.8834
01/30/2023 09:23:23 AM  [*] Mon Jan 30 09:23:23 2023:    3    | Tr.loss: 0.333084 | Elapsed:   8.67   s | FPR 0.0003 -> TPR: 0.14 & F1: 0.25 | AUC: 0.9165
01/30/2023 09:23:24 AM [!] Mon Jan 30 09:23:24 2023: Dumped results:
                model     : 1675067003-model.torch
		train time: 1675067003-trainTime.npy
		train losses: 1675067003-trainLosses.npy
		train AUC: 1675067003-auc.npy
		train F1s : 1675067003-trainF1s.npy
		train TPRs: 1675067003-trainTPRs.npy
01/30/2023 09:23:24 AM  [*] Evaluating pretrained model on test set...
01/30/2023 09:23:29 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0748 | F1: 0.1391
01/30/2023 09:23:29 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1346 | F1: 0.2373
01/30/2023 09:23:29 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.2356 | F1: 0.3810
01/30/2023 09:23:29 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.2721 | F1: 0.4270
01/30/2023 09:23:29 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3654 | F1: 0.5319
01/30/2023 09:23:29 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4208 | F1: 0.5820
01/30/2023 09:23:29 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.4968 | F1: 0.6282
01/30/2023 09:23:29 AM  [*] Evaluating non_pretrained model on test set...
01/30/2023 09:23:35 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0524 | F1: 0.0996
01/30/2023 09:23:35 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1005 | F1: 0.1826
01/30/2023 09:23:35 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.1691 | F1: 0.2891
01/30/2023 09:23:35 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.2851 | F1: 0.4428
01/30/2023 09:23:35 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3591 | F1: 0.5252
01/30/2023 09:23:35 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4184 | F1: 0.5795
01/30/2023 09:23:35 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.5932 | F1: 0.7070
01/30/2023 09:23:35 AM  [!] Finished pre-training evaluation over 3 splits! Saved metrics to:
	C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\downsample_tests\downsample_U_0.4_1675064748/metrics_MaskedLanguageModel_nSplits_3_limit_None.json
01/30/2023 09:23:35 AM  [!] Starting uSize downsample 0.5 evaluation!
01/30/2023 09:23:35 AM  [!] Starting Masked Language Model evaluation over 3 splits!
01/30/2023 09:23:35 AM  [!] Loaded data and vocab. X train size: (76126, 512), X test size: (17407, 512), vocab size: 50002
01/30/2023 09:23:35 AM  [!] Initiating Self-Supervised Learning Pretraining
     Language Modeling MaskedLanguageModel
     Model TransformerEncoderLM with config:
	{'vocabSize': 50002, 'maxLen': 512, 'dModel': 64, 'nHeads': 8, 'dHidden': 256, 'nLayers': 2, 'numClasses': 1, 'hiddenNeurons': [64], 'dropout': 0.3}

01/30/2023 09:23:35 AM  [!] Running pre-training split 1/3
01/30/2023 09:23:37 AM  [!] Pre-training model...
01/30/2023 09:23:38 AM  [*] Masking sequences...
01/30/2023 09:23:55 AM  [*] Started epoch: 1
01/30/2023 09:23:55 AM  [*] Mon Jan 30 09:23:55 2023: Train Epoch: 1 [  0  /34256 (0 %)]	Loss: 419.884369 | Elapsed: 0.35s
01/30/2023 09:24:10 AM  [*] Mon Jan 30 09:24:10 2023: Train Epoch: 1 [6400 /34256 (19%)]	Loss: 231.166306 | Elapsed: 14.47s
01/30/2023 09:24:27 AM  [*] Mon Jan 30 09:24:27 2023: Train Epoch: 1 [12800/34256 (37%)]	Loss: 207.430969 | Elapsed: 16.98s
01/30/2023 09:24:45 AM  [*] Mon Jan 30 09:24:45 2023: Train Epoch: 1 [19200/34256 (56%)]	Loss: 210.497910 | Elapsed: 18.29s
01/30/2023 09:25:03 AM  [*] Mon Jan 30 09:25:03 2023: Train Epoch: 1 [25600/34256 (75%)]	Loss: 224.394653 | Elapsed: 18.28s
01/30/2023 09:25:21 AM  [*] Mon Jan 30 09:25:21 2023: Train Epoch: 1 [32000/34256 (93%)]	Loss: 182.062988 | Elapsed: 18.39s
01/30/2023 09:25:29 AM  [*] Mon Jan 30 09:25:29 2023:    1    | Tr.loss: 216.178180 | Elapsed:   94.55  s
01/30/2023 09:25:29 AM  [*] Started epoch: 2
01/30/2023 09:25:29 AM  [*] Mon Jan 30 09:25:29 2023: Train Epoch: 2 [  0  /34256 (0 %)]	Loss: 203.798340 | Elapsed: 0.15s
01/30/2023 09:25:44 AM  [*] Mon Jan 30 09:25:44 2023: Train Epoch: 2 [6400 /34256 (19%)]	Loss: 205.943390 | Elapsed: 14.66s
01/30/2023 09:26:01 AM  [*] Mon Jan 30 09:26:01 2023: Train Epoch: 2 [12800/34256 (37%)]	Loss: 212.613281 | Elapsed: 16.63s
01/30/2023 09:26:19 AM  [*] Mon Jan 30 09:26:19 2023: Train Epoch: 2 [19200/34256 (56%)]	Loss: 192.090286 | Elapsed: 18.00s
01/30/2023 09:26:37 AM  [*] Mon Jan 30 09:26:37 2023: Train Epoch: 2 [25600/34256 (75%)]	Loss: 193.805756 | Elapsed: 18.04s
01/30/2023 09:26:55 AM  [*] Mon Jan 30 09:26:55 2023: Train Epoch: 2 [32000/34256 (93%)]	Loss: 182.999512 | Elapsed: 18.45s
01/30/2023 09:27:03 AM  [*] Mon Jan 30 09:27:03 2023:    2    | Tr.loss: 192.181833 | Elapsed:   93.74  s
01/30/2023 09:27:03 AM  [*] Started epoch: 3
01/30/2023 09:27:03 AM  [*] Mon Jan 30 09:27:03 2023: Train Epoch: 3 [  0  /34256 (0 %)]	Loss: 178.495819 | Elapsed: 0.15s
01/30/2023 09:27:18 AM  [*] Mon Jan 30 09:27:18 2023: Train Epoch: 3 [6400 /34256 (19%)]	Loss: 178.602173 | Elapsed: 14.55s
01/30/2023 09:27:33 AM  [*] Mon Jan 30 09:27:33 2023: Train Epoch: 3 [12800/34256 (37%)]	Loss: 153.358032 | Elapsed: 15.56s
01/30/2023 09:27:52 AM  [*] Mon Jan 30 09:27:52 2023: Train Epoch: 3 [19200/34256 (56%)]	Loss: 192.125763 | Elapsed: 18.99s
01/30/2023 09:28:11 AM  [*] Mon Jan 30 09:28:11 2023: Train Epoch: 3 [25600/34256 (75%)]	Loss: 180.194092 | Elapsed: 18.72s
01/30/2023 09:28:29 AM  [*] Mon Jan 30 09:28:29 2023: Train Epoch: 3 [32000/34256 (93%)]	Loss: 165.383209 | Elapsed: 18.40s
01/30/2023 09:28:37 AM  [*] Mon Jan 30 09:28:37 2023:    3    | Tr.loss: 185.663652 | Elapsed:   94.22  s
01/30/2023 09:28:37 AM  [*] Started epoch: 4
01/30/2023 09:28:37 AM  [*] Mon Jan 30 09:28:37 2023: Train Epoch: 4 [  0  /34256 (0 %)]	Loss: 169.634888 | Elapsed: 0.14s
01/30/2023 09:28:52 AM  [*] Mon Jan 30 09:28:52 2023: Train Epoch: 4 [6400 /34256 (19%)]	Loss: 191.087463 | Elapsed: 14.81s
01/30/2023 09:29:07 AM  [*] Mon Jan 30 09:29:07 2023: Train Epoch: 4 [12800/34256 (37%)]	Loss: 185.691971 | Elapsed: 14.83s
01/30/2023 09:29:25 AM  [*] Mon Jan 30 09:29:25 2023: Train Epoch: 4 [19200/34256 (56%)]	Loss: 169.860229 | Elapsed: 18.25s
01/30/2023 09:29:43 AM  [*] Mon Jan 30 09:29:43 2023: Train Epoch: 4 [25600/34256 (75%)]	Loss: 187.842865 | Elapsed: 18.04s
01/30/2023 09:30:01 AM  [*] Mon Jan 30 09:30:01 2023: Train Epoch: 4 [32000/34256 (93%)]	Loss: 188.575317 | Elapsed: 17.40s
01/30/2023 09:30:09 AM  [*] Mon Jan 30 09:30:09 2023:    4    | Tr.loss: 182.465441 | Elapsed:   91.32  s
01/30/2023 09:30:09 AM  [*] Started epoch: 5
01/30/2023 09:30:09 AM  [*] Mon Jan 30 09:30:09 2023: Train Epoch: 5 [  0  /34256 (0 %)]	Loss: 185.950928 | Elapsed: 0.14s
01/30/2023 09:30:23 AM  [*] Mon Jan 30 09:30:23 2023: Train Epoch: 5 [6400 /34256 (19%)]	Loss: 195.242157 | Elapsed: 13.97s
01/30/2023 09:30:37 AM  [*] Mon Jan 30 09:30:37 2023: Train Epoch: 5 [12800/34256 (37%)]	Loss: 176.499496 | Elapsed: 14.40s
01/30/2023 09:30:55 AM  [*] Mon Jan 30 09:30:55 2023: Train Epoch: 5 [19200/34256 (56%)]	Loss: 167.324890 | Elapsed: 17.74s
01/30/2023 09:31:15 AM  [*] Mon Jan 30 09:31:15 2023: Train Epoch: 5 [25600/34256 (75%)]	Loss: 190.549133 | Elapsed: 20.50s
01/30/2023 09:31:35 AM  [*] Mon Jan 30 09:31:35 2023: Train Epoch: 5 [32000/34256 (93%)]	Loss: 164.741653 | Elapsed: 20.04s
01/30/2023 09:31:44 AM  [*] Mon Jan 30 09:31:44 2023:    5    | Tr.loss: 180.501523 | Elapsed:   94.95  s
01/30/2023 09:31:44 AM  [*] Started epoch: 6
01/30/2023 09:31:44 AM  [*] Mon Jan 30 09:31:44 2023: Train Epoch: 6 [  0  /34256 (0 %)]	Loss: 195.616364 | Elapsed: 0.16s
01/30/2023 09:32:00 AM  [*] Mon Jan 30 09:32:00 2023: Train Epoch: 6 [6400 /34256 (19%)]	Loss: 163.074570 | Elapsed: 16.61s
01/30/2023 09:32:17 AM  [*] Mon Jan 30 09:32:17 2023: Train Epoch: 6 [12800/34256 (37%)]	Loss: 168.613708 | Elapsed: 16.63s
01/30/2023 09:32:40 AM  [*] Mon Jan 30 09:32:40 2023: Train Epoch: 6 [19200/34256 (56%)]	Loss: 178.144989 | Elapsed: 23.00s
01/30/2023 09:33:02 AM  [*] Mon Jan 30 09:33:02 2023: Train Epoch: 6 [25600/34256 (75%)]	Loss: 172.244781 | Elapsed: 21.98s
01/30/2023 09:33:22 AM  [*] Mon Jan 30 09:33:22 2023: Train Epoch: 6 [32000/34256 (93%)]	Loss: 189.016541 | Elapsed: 20.24s
01/30/2023 09:33:30 AM  [*] Mon Jan 30 09:33:30 2023:    6    | Tr.loss: 178.839304 | Elapsed:  106.71  s
01/30/2023 09:33:30 AM  [*] Started epoch: 7
01/30/2023 09:33:30 AM  [*] Mon Jan 30 09:33:30 2023: Train Epoch: 7 [  0  /34256 (0 %)]	Loss: 182.380096 | Elapsed: 0.16s
01/30/2023 09:33:46 AM  [*] Mon Jan 30 09:33:46 2023: Train Epoch: 7 [6400 /34256 (19%)]	Loss: 173.707672 | Elapsed: 15.94s
01/30/2023 09:34:02 AM  [*] Mon Jan 30 09:34:02 2023: Train Epoch: 7 [12800/34256 (37%)]	Loss: 169.533386 | Elapsed: 15.81s
01/30/2023 09:34:18 AM  [*] Mon Jan 30 09:34:18 2023: Train Epoch: 7 [19200/34256 (56%)]	Loss: 181.687286 | Elapsed: 15.80s
01/30/2023 09:34:37 AM  [*] Mon Jan 30 09:34:37 2023: Train Epoch: 7 [25600/34256 (75%)]	Loss: 168.229599 | Elapsed: 19.29s
01/30/2023 09:34:57 AM  [*] Mon Jan 30 09:34:57 2023: Train Epoch: 7 [32000/34256 (93%)]	Loss: 196.995178 | Elapsed: 19.68s
01/30/2023 09:35:05 AM  [*] Mon Jan 30 09:35:05 2023:    7    | Tr.loss: 177.531050 | Elapsed:   94.80  s
01/30/2023 09:35:05 AM  [*] Started epoch: 8
01/30/2023 09:35:05 AM  [*] Mon Jan 30 09:35:05 2023: Train Epoch: 8 [  0  /34256 (0 %)]	Loss: 172.351074 | Elapsed: 0.16s
01/30/2023 09:35:21 AM  [*] Mon Jan 30 09:35:21 2023: Train Epoch: 8 [6400 /34256 (19%)]	Loss: 172.043884 | Elapsed: 15.89s
01/30/2023 09:35:37 AM  [*] Mon Jan 30 09:35:37 2023: Train Epoch: 8 [12800/34256 (37%)]	Loss: 149.163101 | Elapsed: 16.02s
01/30/2023 09:35:53 AM  [*] Mon Jan 30 09:35:53 2023: Train Epoch: 8 [19200/34256 (56%)]	Loss: 176.404678 | Elapsed: 15.92s
01/30/2023 09:36:12 AM  [*] Mon Jan 30 09:36:12 2023: Train Epoch: 8 [25600/34256 (75%)]	Loss: 174.205917 | Elapsed: 19.21s
01/30/2023 09:36:32 AM  [*] Mon Jan 30 09:36:32 2023: Train Epoch: 8 [32000/34256 (93%)]	Loss: 132.807007 | Elapsed: 19.58s
01/30/2023 09:36:40 AM  [*] Mon Jan 30 09:36:40 2023:    8    | Tr.loss: 176.343744 | Elapsed:   94.82  s
01/30/2023 09:36:40 AM  [*] Started epoch: 9
01/30/2023 09:36:40 AM  [*] Mon Jan 30 09:36:40 2023: Train Epoch: 9 [  0  /34256 (0 %)]	Loss: 149.423676 | Elapsed: 0.16s
01/30/2023 09:36:56 AM  [*] Mon Jan 30 09:36:56 2023: Train Epoch: 9 [6400 /34256 (19%)]	Loss: 189.315948 | Elapsed: 15.85s
01/30/2023 09:37:12 AM  [*] Mon Jan 30 09:37:12 2023: Train Epoch: 9 [12800/34256 (37%)]	Loss: 174.073746 | Elapsed: 15.75s
01/30/2023 09:37:27 AM  [*] Mon Jan 30 09:37:27 2023: Train Epoch: 9 [19200/34256 (56%)]	Loss: 163.254547 | Elapsed: 15.70s
01/30/2023 09:37:46 AM  [*] Mon Jan 30 09:37:46 2023: Train Epoch: 9 [25600/34256 (75%)]	Loss: 177.502670 | Elapsed: 18.81s
01/30/2023 09:38:06 AM  [*] Mon Jan 30 09:38:06 2023: Train Epoch: 9 [32000/34256 (93%)]	Loss: 178.010056 | Elapsed: 19.80s
01/30/2023 09:38:14 AM  [*] Mon Jan 30 09:38:14 2023:    9    | Tr.loss: 175.419153 | Elapsed:   94.28  s
01/30/2023 09:38:14 AM  [*] Started epoch: 10
01/30/2023 09:38:14 AM  [*] Mon Jan 30 09:38:14 2023: Train Epoch: 10 [  0  /34256 (0 %)]	Loss: 175.547546 | Elapsed: 0.16s
01/30/2023 09:38:30 AM  [*] Mon Jan 30 09:38:30 2023: Train Epoch: 10 [6400 /34256 (19%)]	Loss: 176.398590 | Elapsed: 16.04s
01/30/2023 09:38:46 AM  [*] Mon Jan 30 09:38:46 2023: Train Epoch: 10 [12800/34256 (37%)]	Loss: 167.598999 | Elapsed: 15.78s
01/30/2023 09:39:02 AM  [*] Mon Jan 30 09:39:02 2023: Train Epoch: 10 [19200/34256 (56%)]	Loss: 157.825562 | Elapsed: 15.82s
01/30/2023 09:39:21 AM  [*] Mon Jan 30 09:39:21 2023: Train Epoch: 10 [25600/34256 (75%)]	Loss: 161.678711 | Elapsed: 18.66s
01/30/2023 09:39:40 AM  [*] Mon Jan 30 09:39:40 2023: Train Epoch: 10 [32000/34256 (93%)]	Loss: 171.337006 | Elapsed: 19.59s
01/30/2023 09:39:49 AM  [*] Mon Jan 30 09:39:49 2023:   10    | Tr.loss: 174.698084 | Elapsed:   94.48  s
01/30/2023 09:39:49 AM [!] Mon Jan 30 09:39:49 2023: Dumped results:
                model     : 1675067989-model.torch
		train time: 1675067989-trainTime.npy
		train losses: 1675067989-trainLosses.npy
		train AUC: 1675067989-auc.npy
01/30/2023 09:39:51 AM  [!] Training pretrained model on downstream task...
01/30/2023 09:39:51 AM  [*] Started epoch: 1
01/30/2023 09:39:51 AM  [*] Mon Jan 30 09:39:51 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 2.121717 | Elapsed: 0.21s | FPR 0.0003 -> TPR 0.0541 & F1 0.1026 | AUC 0.5806
01/30/2023 09:40:03 AM  [*] Mon Jan 30 09:40:03 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.398298 | Elapsed: 11.65s | FPR 0.0003 -> TPR 0.4576 & F1 0.6279 | AUC 0.8975
01/30/2023 09:40:05 AM  [*] Mon Jan 30 09:40:05 2023:    1    | Tr.loss: 0.528547 | Elapsed:   14.18  s | FPR 0.0003 -> TPR: 0.01 & F1: 0.01 | AUC: 0.7955
01/30/2023 09:40:05 AM  [*] Started epoch: 2
01/30/2023 09:40:05 AM  [*] Mon Jan 30 09:40:05 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.325181 | Elapsed: 0.12s | FPR 0.0003 -> TPR 0.6667 & F1 0.8000 | AUC 0.9333
01/30/2023 09:40:17 AM  [*] Mon Jan 30 09:40:17 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.322768 | Elapsed: 11.94s | FPR 0.0003 -> TPR 0.4384 & F1 0.6095 | AUC 0.9006
01/30/2023 09:40:19 AM  [*] Mon Jan 30 09:40:19 2023:    2    | Tr.loss: 0.362037 | Elapsed:   14.51  s | FPR 0.0003 -> TPR: 0.08 & F1: 0.15 | AUC: 0.8988
01/30/2023 09:40:19 AM  [*] Started epoch: 3
01/30/2023 09:40:20 AM  [*] Mon Jan 30 09:40:20 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.326221 | Elapsed: 0.12s | FPR 0.0003 -> TPR 0.7297 & F1 0.8437 | AUC 0.9449
01/30/2023 09:40:32 AM  [*] Mon Jan 30 09:40:32 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.253076 | Elapsed: 12.34s | FPR 0.0003 -> TPR 0.7500 & F1 0.8571 | AUC 0.9527
01/30/2023 09:40:35 AM  [*] Mon Jan 30 09:40:35 2023:    3    | Tr.loss: 0.289141 | Elapsed:   15.00  s | FPR 0.0003 -> TPR: 0.21 & F1: 0.34 | AUC: 0.9429
01/30/2023 09:40:35 AM [!] Mon Jan 30 09:40:35 2023: Dumped results:
                model     : 1675068035-model.torch
		train time: 1675068035-trainTime.npy
		train losses: 1675068035-trainLosses.npy
		train AUC: 1675068035-auc.npy
		train F1s : 1675068035-trainF1s.npy
		train TPRs: 1675068035-trainTPRs.npy
01/30/2023 09:40:35 AM  [!] Training non_pretrained model on downstream task...
01/30/2023 09:40:36 AM  [*] Started epoch: 1
01/30/2023 09:40:36 AM  [*] Mon Jan 30 09:40:36 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 2.030117 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.4414
01/30/2023 09:40:45 AM  [*] Mon Jan 30 09:40:45 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.336841 | Elapsed: 9.00s | FPR 0.0003 -> TPR 0.5867 & F1 0.7395 | AUC 0.9029
01/30/2023 09:40:47 AM  [*] Mon Jan 30 09:40:47 2023:    1    | Tr.loss: 0.573355 | Elapsed:   10.98  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7519
01/30/2023 09:40:47 AM  [*] Started epoch: 2
01/30/2023 09:40:47 AM  [*] Mon Jan 30 09:40:47 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.373882 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.4255 & F1 0.5970 | AUC 0.8798
01/30/2023 09:40:56 AM  [*] Mon Jan 30 09:40:56 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.418195 | Elapsed: 9.11s | FPR 0.0003 -> TPR 0.3881 & F1 0.5591 | AUC 0.9104
01/30/2023 09:40:58 AM  [*] Mon Jan 30 09:40:58 2023:    2    | Tr.loss: 0.362771 | Elapsed:   11.12  s | FPR 0.0003 -> TPR: 0.12 & F1: 0.21 | AUC: 0.8953
01/30/2023 09:40:58 AM  [*] Started epoch: 3
01/30/2023 09:40:58 AM  [*] Mon Jan 30 09:40:58 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.212019 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.8298 & F1 0.9070 | AUC 0.9775
01/30/2023 09:41:07 AM  [*] Mon Jan 30 09:41:07 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.434749 | Elapsed: 8.83s | FPR 0.0003 -> TPR 0.3538 & F1 0.5227 | AUC 0.8607
01/30/2023 09:41:09 AM  [*] Mon Jan 30 09:41:09 2023:    3    | Tr.loss: 0.306975 | Elapsed:   10.81  s | FPR 0.0003 -> TPR: 0.21 & F1: 0.34 | AUC: 0.9280
01/30/2023 09:41:09 AM [!] Mon Jan 30 09:41:09 2023: Dumped results:
                model     : 1675068069-model.torch
		train time: 1675068069-trainTime.npy
		train losses: 1675068069-trainLosses.npy
		train AUC: 1675068069-auc.npy
		train F1s : 1675068069-trainF1s.npy
		train TPRs: 1675068069-trainTPRs.npy
01/30/2023 09:41:09 AM  [*] Evaluating pretrained model on test set...
01/30/2023 09:41:17 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0412 | F1: 0.0791
01/30/2023 09:41:17 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.2033 | F1: 0.3379
01/30/2023 09:41:17 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.2409 | F1: 0.3880
01/30/2023 09:41:17 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3298 | F1: 0.4951
01/30/2023 09:41:17 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.4261 | F1: 0.5941
01/30/2023 09:41:17 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4762 | F1: 0.6342
01/30/2023 09:41:17 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.7092 | F1: 0.7905
01/30/2023 09:41:17 AM  [*] Evaluating non_pretrained model on test set...
01/30/2023 09:41:24 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0034 | F1: 0.0068
01/30/2023 09:41:24 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1391 | F1: 0.2442
01/30/2023 09:41:24 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.2214 | F1: 0.3623
01/30/2023 09:41:24 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.2458 | F1: 0.3938
01/30/2023 09:41:24 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3324 | F1: 0.4958
01/30/2023 09:41:24 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4139 | F1: 0.5751
01/30/2023 09:41:24 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.6235 | F1: 0.7299
01/30/2023 09:41:24 AM  [!] Running pre-training split 2/3
01/30/2023 09:41:26 AM  [!] Pre-training model...
01/30/2023 09:41:27 AM  [*] Masking sequences...
01/30/2023 09:41:41 AM  [*] Started epoch: 1
01/30/2023 09:41:41 AM  [*] Mon Jan 30 09:41:41 2023: Train Epoch: 1 [  0  /34256 (0 %)]	Loss: 397.838440 | Elapsed: 0.40s
01/30/2023 09:41:58 AM  [*] Mon Jan 30 09:41:58 2023: Train Epoch: 1 [6400 /34256 (19%)]	Loss: 214.617294 | Elapsed: 16.69s
01/30/2023 09:42:14 AM  [*] Mon Jan 30 09:42:14 2023: Train Epoch: 1 [12800/34256 (37%)]	Loss: 212.844482 | Elapsed: 16.49s
01/30/2023 09:42:31 AM  [*] Mon Jan 30 09:42:31 2023: Train Epoch: 1 [19200/34256 (56%)]	Loss: 183.563248 | Elapsed: 17.15s
01/30/2023 09:42:51 AM  [*] Mon Jan 30 09:42:51 2023: Train Epoch: 1 [25600/34256 (75%)]	Loss: 209.274445 | Elapsed: 19.99s
01/30/2023 09:43:12 AM  [*] Mon Jan 30 09:43:12 2023: Train Epoch: 1 [32000/34256 (93%)]	Loss: 194.650116 | Elapsed: 20.54s
01/30/2023 09:43:20 AM  [*] Mon Jan 30 09:43:20 2023:    1    | Tr.loss: 216.050986 | Elapsed:   99.16  s
01/30/2023 09:43:20 AM  [*] Started epoch: 2
01/30/2023 09:43:20 AM  [*] Mon Jan 30 09:43:20 2023: Train Epoch: 2 [  0  /34256 (0 %)]	Loss: 224.538818 | Elapsed: 0.16s
01/30/2023 09:43:37 AM  [*] Mon Jan 30 09:43:37 2023: Train Epoch: 2 [6400 /34256 (19%)]	Loss: 228.582779 | Elapsed: 17.02s
01/30/2023 09:43:53 AM  [*] Mon Jan 30 09:43:53 2023: Train Epoch: 2 [12800/34256 (37%)]	Loss: 154.858551 | Elapsed: 16.04s
01/30/2023 09:44:09 AM  [*] Mon Jan 30 09:44:09 2023: Train Epoch: 2 [19200/34256 (56%)]	Loss: 198.937775 | Elapsed: 15.91s
01/30/2023 09:44:25 AM  [*] Mon Jan 30 09:44:25 2023: Train Epoch: 2 [25600/34256 (75%)]	Loss: 200.488419 | Elapsed: 16.12s
01/30/2023 09:44:41 AM  [*] Mon Jan 30 09:44:41 2023: Train Epoch: 2 [32000/34256 (93%)]	Loss: 178.615311 | Elapsed: 16.33s
01/30/2023 09:44:49 AM  [*] Mon Jan 30 09:44:49 2023:    2    | Tr.loss: 191.283962 | Elapsed:   88.81  s
01/30/2023 09:44:49 AM  [*] Started epoch: 3
01/30/2023 09:44:49 AM  [*] Mon Jan 30 09:44:49 2023: Train Epoch: 3 [  0  /34256 (0 %)]	Loss: 188.518951 | Elapsed: 0.17s
01/30/2023 09:45:05 AM  [*] Mon Jan 30 09:45:05 2023: Train Epoch: 3 [6400 /34256 (19%)]	Loss: 191.537064 | Elapsed: 16.55s
01/30/2023 09:45:22 AM  [*] Mon Jan 30 09:45:22 2023: Train Epoch: 3 [12800/34256 (37%)]	Loss: 181.786057 | Elapsed: 16.48s
01/30/2023 09:45:38 AM  [*] Mon Jan 30 09:45:38 2023: Train Epoch: 3 [19200/34256 (56%)]	Loss: 186.877441 | Elapsed: 16.01s
01/30/2023 09:45:55 AM  [*] Mon Jan 30 09:45:55 2023: Train Epoch: 3 [25600/34256 (75%)]	Loss: 192.092010 | Elapsed: 16.74s
01/30/2023 09:46:16 AM  [*] Mon Jan 30 09:46:16 2023: Train Epoch: 3 [32000/34256 (93%)]	Loss: 166.337006 | Elapsed: 21.08s
01/30/2023 09:46:24 AM  [*] Mon Jan 30 09:46:24 2023:    3    | Tr.loss: 183.897265 | Elapsed:   95.81  s
01/30/2023 09:46:24 AM  [*] Started epoch: 4
01/30/2023 09:46:25 AM  [*] Mon Jan 30 09:46:25 2023: Train Epoch: 4 [  0  /34256 (0 %)]	Loss: 176.283905 | Elapsed: 0.25s
01/30/2023 09:46:42 AM  [*] Mon Jan 30 09:46:42 2023: Train Epoch: 4 [6400 /34256 (19%)]	Loss: 176.989883 | Elapsed: 17.40s
01/30/2023 09:46:59 AM  [*] Mon Jan 30 09:46:59 2023: Train Epoch: 4 [12800/34256 (37%)]	Loss: 181.185242 | Elapsed: 17.11s
01/30/2023 09:47:15 AM  [*] Mon Jan 30 09:47:15 2023: Train Epoch: 4 [19200/34256 (56%)]	Loss: 196.399170 | Elapsed: 16.12s
01/30/2023 09:47:31 AM  [*] Mon Jan 30 09:47:31 2023: Train Epoch: 4 [25600/34256 (75%)]	Loss: 193.729538 | Elapsed: 16.15s
01/30/2023 09:47:48 AM  [*] Mon Jan 30 09:47:48 2023: Train Epoch: 4 [32000/34256 (93%)]	Loss: 163.279785 | Elapsed: 16.04s
01/30/2023 09:47:54 AM  [*] Mon Jan 30 09:47:54 2023:    4    | Tr.loss: 180.320733 | Elapsed:   90.00  s
01/30/2023 09:47:54 AM  [*] Started epoch: 5
01/30/2023 09:47:55 AM  [*] Mon Jan 30 09:47:55 2023: Train Epoch: 5 [  0  /34256 (0 %)]	Loss: 186.578339 | Elapsed: 0.16s
01/30/2023 09:48:10 AM  [*] Mon Jan 30 09:48:10 2023: Train Epoch: 5 [6400 /34256 (19%)]	Loss: 166.991913 | Elapsed: 15.72s
01/30/2023 09:48:26 AM  [*] Mon Jan 30 09:48:26 2023: Train Epoch: 5 [12800/34256 (37%)]	Loss: 175.876801 | Elapsed: 15.92s
01/30/2023 09:48:42 AM  [*] Mon Jan 30 09:48:42 2023: Train Epoch: 5 [19200/34256 (56%)]	Loss: 177.363449 | Elapsed: 15.97s
01/30/2023 09:48:58 AM  [*] Mon Jan 30 09:48:58 2023: Train Epoch: 5 [25600/34256 (75%)]	Loss: 183.335754 | Elapsed: 15.86s
01/30/2023 09:49:14 AM  [*] Mon Jan 30 09:49:14 2023: Train Epoch: 5 [32000/34256 (93%)]	Loss: 160.275421 | Elapsed: 15.90s
01/30/2023 09:49:21 AM  [*] Mon Jan 30 09:49:21 2023:    5    | Tr.loss: 178.236139 | Elapsed:   86.61  s
01/30/2023 09:49:21 AM  [*] Started epoch: 6
01/30/2023 09:49:21 AM  [*] Mon Jan 30 09:49:21 2023: Train Epoch: 6 [  0  /34256 (0 %)]	Loss: 164.664978 | Elapsed: 0.16s
01/30/2023 09:49:38 AM  [*] Mon Jan 30 09:49:38 2023: Train Epoch: 6 [6400 /34256 (19%)]	Loss: 159.141129 | Elapsed: 16.51s
01/30/2023 09:49:54 AM  [*] Mon Jan 30 09:49:54 2023: Train Epoch: 6 [12800/34256 (37%)]	Loss: 168.197983 | Elapsed: 16.57s
01/30/2023 09:50:12 AM  [*] Mon Jan 30 09:50:12 2023: Train Epoch: 6 [19200/34256 (56%)]	Loss: 163.518387 | Elapsed: 17.39s
01/30/2023 09:50:30 AM  [*] Mon Jan 30 09:50:30 2023: Train Epoch: 6 [25600/34256 (75%)]	Loss: 181.334915 | Elapsed: 18.11s
01/30/2023 09:50:48 AM  [*] Mon Jan 30 09:50:48 2023: Train Epoch: 6 [32000/34256 (93%)]	Loss: 189.493942 | Elapsed: 18.17s
01/30/2023 09:50:55 AM  [*] Mon Jan 30 09:50:55 2023:    6    | Tr.loss: 176.616506 | Elapsed:   94.26  s
01/30/2023 09:50:55 AM  [*] Started epoch: 7
01/30/2023 09:50:55 AM  [*] Mon Jan 30 09:50:55 2023: Train Epoch: 7 [  0  /34256 (0 %)]	Loss: 186.911819 | Elapsed: 0.17s
01/30/2023 09:51:13 AM  [*] Mon Jan 30 09:51:13 2023: Train Epoch: 7 [6400 /34256 (19%)]	Loss: 178.910767 | Elapsed: 17.26s
01/30/2023 09:51:29 AM  [*] Mon Jan 30 09:51:29 2023: Train Epoch: 7 [12800/34256 (37%)]	Loss: 177.900864 | Elapsed: 15.88s
01/30/2023 09:51:44 AM  [*] Mon Jan 30 09:51:44 2023: Train Epoch: 7 [19200/34256 (56%)]	Loss: 169.537796 | Elapsed: 15.54s
01/30/2023 09:52:00 AM  [*] Mon Jan 30 09:52:00 2023: Train Epoch: 7 [25600/34256 (75%)]	Loss: 171.946701 | Elapsed: 15.39s
01/30/2023 09:52:15 AM  [*] Mon Jan 30 09:52:15 2023: Train Epoch: 7 [32000/34256 (93%)]	Loss: 198.453278 | Elapsed: 15.89s
01/30/2023 09:52:23 AM  [*] Mon Jan 30 09:52:23 2023:    7    | Tr.loss: 175.404053 | Elapsed:   87.83  s
01/30/2023 09:52:23 AM  [*] Started epoch: 8
01/30/2023 09:52:23 AM  [*] Mon Jan 30 09:52:23 2023: Train Epoch: 8 [  0  /34256 (0 %)]	Loss: 179.473236 | Elapsed: 0.15s
01/30/2023 09:52:39 AM  [*] Mon Jan 30 09:52:39 2023: Train Epoch: 8 [6400 /34256 (19%)]	Loss: 168.108215 | Elapsed: 16.02s
01/30/2023 09:52:55 AM  [*] Mon Jan 30 09:52:55 2023: Train Epoch: 8 [12800/34256 (37%)]	Loss: 181.806213 | Elapsed: 15.30s
01/30/2023 09:53:10 AM  [*] Mon Jan 30 09:53:10 2023: Train Epoch: 8 [19200/34256 (56%)]	Loss: 163.185471 | Elapsed: 15.79s
01/30/2023 09:53:27 AM  [*] Mon Jan 30 09:53:27 2023: Train Epoch: 8 [25600/34256 (75%)]	Loss: 181.003235 | Elapsed: 16.15s
01/30/2023 09:53:43 AM  [*] Mon Jan 30 09:53:43 2023: Train Epoch: 8 [32000/34256 (93%)]	Loss: 175.333572 | Elapsed: 16.77s
01/30/2023 09:53:52 AM  [*] Mon Jan 30 09:53:52 2023:    8    | Tr.loss: 174.521820 | Elapsed:   88.43  s
01/30/2023 09:53:52 AM  [*] Started epoch: 9
01/30/2023 09:53:52 AM  [*] Mon Jan 30 09:53:52 2023: Train Epoch: 9 [  0  /34256 (0 %)]	Loss: 186.632385 | Elapsed: 0.17s
01/30/2023 09:54:08 AM  [*] Mon Jan 30 09:54:08 2023: Train Epoch: 9 [6400 /34256 (19%)]	Loss: 167.296631 | Elapsed: 15.83s
01/30/2023 09:54:24 AM  [*] Mon Jan 30 09:54:24 2023: Train Epoch: 9 [12800/34256 (37%)]	Loss: 174.713791 | Elapsed: 16.03s
01/30/2023 09:54:39 AM  [*] Mon Jan 30 09:54:39 2023: Train Epoch: 9 [19200/34256 (56%)]	Loss: 166.935349 | Elapsed: 15.57s
01/30/2023 09:54:55 AM  [*] Mon Jan 30 09:54:55 2023: Train Epoch: 9 [25600/34256 (75%)]	Loss: 179.385056 | Elapsed: 15.58s
01/30/2023 09:55:11 AM  [*] Mon Jan 30 09:55:11 2023: Train Epoch: 9 [32000/34256 (93%)]	Loss: 176.058441 | Elapsed: 15.91s
01/30/2023 09:55:19 AM  [*] Mon Jan 30 09:55:19 2023:    9    | Tr.loss: 173.786971 | Elapsed:   87.06  s
01/30/2023 09:55:19 AM  [*] Started epoch: 10
01/30/2023 09:55:19 AM  [*] Mon Jan 30 09:55:19 2023: Train Epoch: 10 [  0  /34256 (0 %)]	Loss: 185.229706 | Elapsed: 0.15s
01/30/2023 09:55:35 AM  [*] Mon Jan 30 09:55:35 2023: Train Epoch: 10 [6400 /34256 (19%)]	Loss: 167.625977 | Elapsed: 15.71s
01/30/2023 09:55:50 AM  [*] Mon Jan 30 09:55:50 2023: Train Epoch: 10 [12800/34256 (37%)]	Loss: 177.824539 | Elapsed: 15.68s
01/30/2023 09:56:06 AM  [*] Mon Jan 30 09:56:06 2023: Train Epoch: 10 [19200/34256 (56%)]	Loss: 189.023788 | Elapsed: 15.41s
01/30/2023 09:56:21 AM  [*] Mon Jan 30 09:56:21 2023: Train Epoch: 10 [25600/34256 (75%)]	Loss: 156.701874 | Elapsed: 15.49s
01/30/2023 09:56:37 AM  [*] Mon Jan 30 09:56:37 2023: Train Epoch: 10 [32000/34256 (93%)]	Loss: 165.752792 | Elapsed: 15.90s
01/30/2023 09:56:45 AM  [*] Mon Jan 30 09:56:45 2023:   10    | Tr.loss: 172.799887 | Elapsed:   85.85  s
01/30/2023 09:56:45 AM [!] Mon Jan 30 09:56:45 2023: Dumped results:
                model     : 1675069005-model.torch
		train time: 1675069005-trainTime.npy
		train losses: 1675069005-trainLosses.npy
		train AUC: 1675069005-auc.npy
01/30/2023 09:56:46 AM  [!] Training pretrained model on downstream task...
01/30/2023 09:56:46 AM  [*] Started epoch: 1
01/30/2023 09:56:46 AM  [*] Mon Jan 30 09:56:46 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 2.848305 | Elapsed: 0.17s | FPR 0.0003 -> TPR 0.2051 & F1 0.3404 | AUC 0.7154
01/30/2023 09:56:56 AM  [*] Mon Jan 30 09:56:56 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.360776 | Elapsed: 9.54s | FPR 0.0003 -> TPR 0.3867 & F1 0.5577 | AUC 0.8123
01/30/2023 09:56:58 AM  [*] Mon Jan 30 09:56:58 2023:    1    | Tr.loss: 0.548358 | Elapsed:   11.56  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8193
01/30/2023 09:56:58 AM  [*] Started epoch: 2
01/30/2023 09:56:58 AM  [*] Mon Jan 30 09:56:58 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.290396 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.7500 & F1 0.8571 | AUC 0.9423
01/30/2023 09:57:08 AM  [*] Mon Jan 30 09:57:08 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.417619 | Elapsed: 10.12s | FPR 0.0003 -> TPR 0.1846 & F1 0.3117 | AUC 0.8712
01/30/2023 09:57:10 AM  [*] Mon Jan 30 09:57:10 2023:    2    | Tr.loss: 0.342943 | Elapsed:   12.23  s | FPR 0.0003 -> TPR: 0.09 & F1: 0.16 | AUC: 0.9102
01/30/2023 09:57:10 AM  [*] Started epoch: 3
01/30/2023 09:57:10 AM  [*] Mon Jan 30 09:57:10 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.301168 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.6596 & F1 0.7949 | AUC 0.9168
01/30/2023 09:57:20 AM  [*] Mon Jan 30 09:57:20 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.312312 | Elapsed: 10.26s | FPR 0.0003 -> TPR 0.6970 & F1 0.8214 | AUC 0.9323
01/30/2023 09:57:22 AM  [*] Mon Jan 30 09:57:22 2023:    3    | Tr.loss: 0.296659 | Elapsed:   12.49  s | FPR 0.0003 -> TPR: 0.17 & F1: 0.29 | AUC: 0.9339
01/30/2023 09:57:23 AM [!] Mon Jan 30 09:57:23 2023: Dumped results:
                model     : 1675069042-model.torch
		train time: 1675069042-trainTime.npy
		train losses: 1675069042-trainLosses.npy
		train AUC: 1675069042-auc.npy
		train F1s : 1675069042-trainF1s.npy
		train TPRs: 1675069042-trainTPRs.npy
01/30/2023 09:57:23 AM  [!] Training non_pretrained model on downstream task...
01/30/2023 09:57:23 AM  [*] Started epoch: 1
01/30/2023 09:57:23 AM  [*] Mon Jan 30 09:57:23 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 2.150559 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.5065
01/30/2023 09:57:31 AM  [*] Mon Jan 30 09:57:31 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.498864 | Elapsed: 7.18s | FPR 0.0003 -> TPR 0.2581 & F1 0.4103 | AUC 0.8332
01/30/2023 09:57:32 AM  [*] Mon Jan 30 09:57:32 2023:    1    | Tr.loss: 0.603831 | Elapsed:   8.85   s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7477
01/30/2023 09:57:32 AM  [*] Started epoch: 2
01/30/2023 09:57:32 AM  [*] Mon Jan 30 09:57:32 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.387921 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.5250 & F1 0.6885 | AUC 0.8708
01/30/2023 09:57:40 AM  [*] Mon Jan 30 09:57:40 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.360021 | Elapsed: 7.58s | FPR 0.0003 -> TPR 0.3889 & F1 0.5600 | AUC 0.9028
01/30/2023 09:57:42 AM  [*] Mon Jan 30 09:57:42 2023:    2    | Tr.loss: 0.377507 | Elapsed:   9.33   s | FPR 0.0003 -> TPR: 0.03 & F1: 0.06 | AUC: 0.8854
01/30/2023 09:57:42 AM  [*] Started epoch: 3
01/30/2023 09:57:42 AM  [*] Mon Jan 30 09:57:42 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.274447 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.5500 & F1 0.7097 | AUC 0.9542
01/30/2023 09:57:49 AM  [*] Mon Jan 30 09:57:49 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.281863 | Elapsed: 7.66s | FPR 0.0003 -> TPR 0.5143 & F1 0.6792 | AUC 0.9567
01/30/2023 09:57:51 AM  [*] Mon Jan 30 09:57:51 2023:    3    | Tr.loss: 0.322331 | Elapsed:   9.52   s | FPR 0.0003 -> TPR: 0.18 & F1: 0.31 | AUC: 0.9190
01/30/2023 09:57:52 AM [!] Mon Jan 30 09:57:52 2023: Dumped results:
                model     : 1675069071-model.torch
		train time: 1675069071-trainTime.npy
		train losses: 1675069071-trainLosses.npy
		train AUC: 1675069071-auc.npy
		train F1s : 1675069071-trainF1s.npy
		train TPRs: 1675069071-trainTPRs.npy
01/30/2023 09:57:52 AM  [*] Evaluating pretrained model on test set...
01/30/2023 09:57:57 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0472 | F1: 0.0902
01/30/2023 09:57:57 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1505 | F1: 0.2616
01/30/2023 09:57:57 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.2424 | F1: 0.3899
01/30/2023 09:57:57 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3026 | F1: 0.4637
01/30/2023 09:57:57 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3685 | F1: 0.5352
01/30/2023 09:57:57 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4463 | F1: 0.6065
01/30/2023 09:57:57 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.6085 | F1: 0.7186
01/30/2023 09:57:57 AM  [*] Evaluating non_pretrained model on test set...
01/30/2023 09:58:03 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0312 | F1: 0.0604
01/30/2023 09:58:03 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1108 | F1: 0.1995
01/30/2023 09:58:03 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.1828 | F1: 0.3089
01/30/2023 09:58:03 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.2318 | F1: 0.3756
01/30/2023 09:58:03 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3272 | F1: 0.4900
01/30/2023 09:58:03 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4594 | F1: 0.6188
01/30/2023 09:58:03 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.5973 | F1: 0.7101
01/30/2023 09:58:03 AM  [!] Running pre-training split 3/3
01/30/2023 09:58:06 AM  [!] Pre-training model...
01/30/2023 09:58:07 AM  [*] Masking sequences...
01/30/2023 09:58:19 AM  [*] Started epoch: 1
01/30/2023 09:58:20 AM  [*] Mon Jan 30 09:58:20 2023: Train Epoch: 1 [  0  /34256 (0 %)]	Loss: 433.351044 | Elapsed: 0.43s
01/30/2023 09:58:34 AM  [*] Mon Jan 30 09:58:34 2023: Train Epoch: 1 [6400 /34256 (19%)]	Loss: 222.158173 | Elapsed: 13.85s
01/30/2023 09:58:48 AM  [*] Mon Jan 30 09:58:48 2023: Train Epoch: 1 [12800/34256 (37%)]	Loss: 244.956696 | Elapsed: 14.02s
01/30/2023 09:59:01 AM  [*] Mon Jan 30 09:59:01 2023: Train Epoch: 1 [19200/34256 (56%)]	Loss: 203.635422 | Elapsed: 13.75s
01/30/2023 09:59:15 AM  [*] Mon Jan 30 09:59:15 2023: Train Epoch: 1 [25600/34256 (75%)]	Loss: 222.145325 | Elapsed: 13.57s
01/30/2023 09:59:30 AM  [*] Mon Jan 30 09:59:30 2023: Train Epoch: 1 [32000/34256 (93%)]	Loss: 194.621460 | Elapsed: 15.26s
01/30/2023 09:59:37 AM  [*] Mon Jan 30 09:59:37 2023:    1    | Tr.loss: 218.856164 | Elapsed:   78.06  s
01/30/2023 09:59:37 AM  [*] Started epoch: 2
01/30/2023 09:59:38 AM  [*] Mon Jan 30 09:59:38 2023: Train Epoch: 2 [  0  /34256 (0 %)]	Loss: 188.791519 | Elapsed: 0.14s
01/30/2023 09:59:51 AM  [*] Mon Jan 30 09:59:51 2023: Train Epoch: 2 [6400 /34256 (19%)]	Loss: 182.126251 | Elapsed: 13.69s
01/30/2023 10:00:05 AM  [*] Mon Jan 30 10:00:05 2023: Train Epoch: 2 [12800/34256 (37%)]	Loss: 199.644196 | Elapsed: 13.59s
01/30/2023 10:00:19 AM  [*] Mon Jan 30 10:00:19 2023: Train Epoch: 2 [19200/34256 (56%)]	Loss: 209.877609 | Elapsed: 13.99s
01/30/2023 10:00:33 AM  [*] Mon Jan 30 10:00:33 2023: Train Epoch: 2 [25600/34256 (75%)]	Loss: 202.427582 | Elapsed: 13.76s
01/30/2023 10:00:46 AM  [*] Mon Jan 30 10:00:46 2023: Train Epoch: 2 [32000/34256 (93%)]	Loss: 190.928162 | Elapsed: 13.90s
01/30/2023 10:00:54 AM  [*] Mon Jan 30 10:00:54 2023:    2    | Tr.loss: 195.788613 | Elapsed:   76.62  s
01/30/2023 10:00:54 AM  [*] Started epoch: 3
01/30/2023 10:00:54 AM  [*] Mon Jan 30 10:00:54 2023: Train Epoch: 3 [  0  /34256 (0 %)]	Loss: 190.167679 | Elapsed: 0.15s
01/30/2023 10:01:08 AM  [*] Mon Jan 30 10:01:08 2023: Train Epoch: 3 [6400 /34256 (19%)]	Loss: 169.937012 | Elapsed: 14.13s
01/30/2023 10:01:23 AM  [*] Mon Jan 30 10:01:23 2023: Train Epoch: 3 [12800/34256 (37%)]	Loss: 184.463303 | Elapsed: 14.24s
01/30/2023 10:01:37 AM  [*] Mon Jan 30 10:01:37 2023: Train Epoch: 3 [19200/34256 (56%)]	Loss: 166.432678 | Elapsed: 14.00s
01/30/2023 10:01:50 AM  [*] Mon Jan 30 10:01:50 2023: Train Epoch: 3 [25600/34256 (75%)]	Loss: 205.075638 | Elapsed: 13.90s
01/30/2023 10:02:04 AM  [*] Mon Jan 30 10:02:04 2023: Train Epoch: 3 [32000/34256 (93%)]	Loss: 177.914795 | Elapsed: 14.05s
01/30/2023 10:02:11 AM  [*] Mon Jan 30 10:02:11 2023:    3    | Tr.loss: 188.662617 | Elapsed:   77.29  s
01/30/2023 10:02:11 AM  [*] Started epoch: 4
01/30/2023 10:02:11 AM  [*] Mon Jan 30 10:02:11 2023: Train Epoch: 4 [  0  /34256 (0 %)]	Loss: 173.888092 | Elapsed: 0.15s
01/30/2023 10:02:25 AM  [*] Mon Jan 30 10:02:25 2023: Train Epoch: 4 [6400 /34256 (19%)]	Loss: 191.340363 | Elapsed: 14.02s
01/30/2023 10:02:40 AM  [*] Mon Jan 30 10:02:40 2023: Train Epoch: 4 [12800/34256 (37%)]	Loss: 180.674698 | Elapsed: 14.72s
01/30/2023 10:02:55 AM  [*] Mon Jan 30 10:02:55 2023: Train Epoch: 4 [19200/34256 (56%)]	Loss: 172.437851 | Elapsed: 14.73s
01/30/2023 10:03:10 AM  [*] Mon Jan 30 10:03:10 2023: Train Epoch: 4 [25600/34256 (75%)]	Loss: 180.906876 | Elapsed: 14.83s
01/30/2023 10:03:24 AM  [*] Mon Jan 30 10:03:24 2023: Train Epoch: 4 [32000/34256 (93%)]	Loss: 179.338425 | Elapsed: 14.01s
01/30/2023 10:03:30 AM  [*] Mon Jan 30 10:03:30 2023:    4    | Tr.loss: 185.089126 | Elapsed:   78.88  s
01/30/2023 10:03:30 AM  [*] Started epoch: 5
01/30/2023 10:03:30 AM  [*] Mon Jan 30 10:03:30 2023: Train Epoch: 5 [  0  /34256 (0 %)]	Loss: 205.121216 | Elapsed: 0.14s
01/30/2023 10:03:44 AM  [*] Mon Jan 30 10:03:44 2023: Train Epoch: 5 [6400 /34256 (19%)]	Loss: 175.587738 | Elapsed: 13.90s
01/30/2023 10:03:58 AM  [*] Mon Jan 30 10:03:58 2023: Train Epoch: 5 [12800/34256 (37%)]	Loss: 183.552826 | Elapsed: 14.13s
01/30/2023 10:04:12 AM  [*] Mon Jan 30 10:04:12 2023: Train Epoch: 5 [19200/34256 (56%)]	Loss: 192.490158 | Elapsed: 13.96s
01/30/2023 10:04:26 AM  [*] Mon Jan 30 10:04:26 2023: Train Epoch: 5 [25600/34256 (75%)]	Loss: 183.856720 | Elapsed: 13.74s
01/30/2023 10:04:41 AM  [*] Mon Jan 30 10:04:41 2023: Train Epoch: 5 [32000/34256 (93%)]	Loss: 191.414520 | Elapsed: 14.54s
01/30/2023 10:04:47 AM  [*] Mon Jan 30 10:04:47 2023:    5    | Tr.loss: 182.799040 | Elapsed:   76.52  s
01/30/2023 10:04:47 AM  [*] Started epoch: 6
01/30/2023 10:04:47 AM  [*] Mon Jan 30 10:04:47 2023: Train Epoch: 6 [  0  /34256 (0 %)]	Loss: 171.619629 | Elapsed: 0.14s
01/30/2023 10:05:00 AM  [*] Mon Jan 30 10:05:00 2023: Train Epoch: 6 [6400 /34256 (19%)]	Loss: 169.302246 | Elapsed: 13.67s
01/30/2023 10:05:14 AM  [*] Mon Jan 30 10:05:14 2023: Train Epoch: 6 [12800/34256 (37%)]	Loss: 176.294830 | Elapsed: 13.85s
01/30/2023 10:05:28 AM  [*] Mon Jan 30 10:05:28 2023: Train Epoch: 6 [19200/34256 (56%)]	Loss: 200.854309 | Elapsed: 13.61s
01/30/2023 10:05:42 AM  [*] Mon Jan 30 10:05:42 2023: Train Epoch: 6 [25600/34256 (75%)]	Loss: 182.099060 | Elapsed: 13.90s
01/30/2023 10:05:56 AM  [*] Mon Jan 30 10:05:56 2023: Train Epoch: 6 [32000/34256 (93%)]	Loss: 192.650391 | Elapsed: 13.91s
01/30/2023 10:06:02 AM  [*] Mon Jan 30 10:06:02 2023:    6    | Tr.loss: 181.031102 | Elapsed:   75.35  s
01/30/2023 10:06:02 AM  [*] Started epoch: 7
01/30/2023 10:06:02 AM  [*] Mon Jan 30 10:06:02 2023: Train Epoch: 7 [  0  /34256 (0 %)]	Loss: 179.882233 | Elapsed: 0.13s
01/30/2023 10:06:16 AM  [*] Mon Jan 30 10:06:16 2023: Train Epoch: 7 [6400 /34256 (19%)]	Loss: 190.059601 | Elapsed: 13.87s
01/30/2023 10:06:30 AM  [*] Mon Jan 30 10:06:30 2023: Train Epoch: 7 [12800/34256 (37%)]	Loss: 180.741821 | Elapsed: 13.95s
01/30/2023 10:06:44 AM  [*] Mon Jan 30 10:06:44 2023: Train Epoch: 7 [19200/34256 (56%)]	Loss: 179.200653 | Elapsed: 13.85s
01/30/2023 10:06:58 AM  [*] Mon Jan 30 10:06:58 2023: Train Epoch: 7 [25600/34256 (75%)]	Loss: 172.050049 | Elapsed: 14.34s
01/30/2023 10:07:12 AM  [*] Mon Jan 30 10:07:12 2023: Train Epoch: 7 [32000/34256 (93%)]	Loss: 173.589340 | Elapsed: 13.68s
01/30/2023 10:07:18 AM  [*] Mon Jan 30 10:07:18 2023:    7    | Tr.loss: 180.033412 | Elapsed:   75.99  s
01/30/2023 10:07:18 AM  [*] Started epoch: 8
01/30/2023 10:07:18 AM  [*] Mon Jan 30 10:07:18 2023: Train Epoch: 8 [  0  /34256 (0 %)]	Loss: 195.871704 | Elapsed: 0.14s
01/30/2023 10:07:32 AM  [*] Mon Jan 30 10:07:32 2023: Train Epoch: 8 [6400 /34256 (19%)]	Loss: 202.745300 | Elapsed: 13.67s
01/30/2023 10:07:46 AM  [*] Mon Jan 30 10:07:46 2023: Train Epoch: 8 [12800/34256 (37%)]	Loss: 180.279755 | Elapsed: 13.77s
01/30/2023 10:08:00 AM  [*] Mon Jan 30 10:08:00 2023: Train Epoch: 8 [19200/34256 (56%)]	Loss: 175.283569 | Elapsed: 14.01s
01/30/2023 10:08:13 AM  [*] Mon Jan 30 10:08:13 2023: Train Epoch: 8 [25600/34256 (75%)]	Loss: 156.158615 | Elapsed: 13.49s
01/30/2023 10:08:26 AM  [*] Mon Jan 30 10:08:26 2023: Train Epoch: 8 [32000/34256 (93%)]	Loss: 169.934509 | Elapsed: 13.39s
01/30/2023 10:08:33 AM  [*] Mon Jan 30 10:08:33 2023:    8    | Tr.loss: 178.945882 | Elapsed:   74.55  s
01/30/2023 10:08:33 AM  [*] Started epoch: 9
01/30/2023 10:08:33 AM  [*] Mon Jan 30 10:08:33 2023: Train Epoch: 9 [  0  /34256 (0 %)]	Loss: 182.975708 | Elapsed: 0.14s
01/30/2023 10:08:47 AM  [*] Mon Jan 30 10:08:47 2023: Train Epoch: 9 [6400 /34256 (19%)]	Loss: 188.086655 | Elapsed: 14.48s
01/30/2023 10:09:01 AM  [*] Mon Jan 30 10:09:01 2023: Train Epoch: 9 [12800/34256 (37%)]	Loss: 169.763397 | Elapsed: 14.18s
01/30/2023 10:09:15 AM  [*] Mon Jan 30 10:09:15 2023: Train Epoch: 9 [19200/34256 (56%)]	Loss: 196.494202 | Elapsed: 13.84s
01/30/2023 10:09:29 AM  [*] Mon Jan 30 10:09:29 2023: Train Epoch: 9 [25600/34256 (75%)]	Loss: 184.637848 | Elapsed: 13.88s
01/30/2023 10:09:43 AM  [*] Mon Jan 30 10:09:43 2023: Train Epoch: 9 [32000/34256 (93%)]	Loss: 165.460571 | Elapsed: 13.43s
01/30/2023 10:09:49 AM  [*] Mon Jan 30 10:09:49 2023:    9    | Tr.loss: 178.190185 | Elapsed:   76.27  s
01/30/2023 10:09:49 AM  [*] Started epoch: 10
01/30/2023 10:09:49 AM  [*] Mon Jan 30 10:09:49 2023: Train Epoch: 10 [  0  /34256 (0 %)]	Loss: 180.425018 | Elapsed: 0.13s
01/30/2023 10:10:03 AM  [*] Mon Jan 30 10:10:03 2023: Train Epoch: 10 [6400 /34256 (19%)]	Loss: 173.772369 | Elapsed: 13.55s
01/30/2023 10:10:16 AM  [*] Mon Jan 30 10:10:16 2023: Train Epoch: 10 [12800/34256 (37%)]	Loss: 172.226166 | Elapsed: 13.48s
01/30/2023 10:10:29 AM  [*] Mon Jan 30 10:10:29 2023: Train Epoch: 10 [19200/34256 (56%)]	Loss: 167.840637 | Elapsed: 13.45s
01/30/2023 10:10:43 AM  [*] Mon Jan 30 10:10:43 2023: Train Epoch: 10 [25600/34256 (75%)]	Loss: 183.123901 | Elapsed: 13.58s
01/30/2023 10:10:57 AM  [*] Mon Jan 30 10:10:57 2023: Train Epoch: 10 [32000/34256 (93%)]	Loss: 152.158554 | Elapsed: 13.55s
01/30/2023 10:11:03 AM  [*] Mon Jan 30 10:11:03 2023:   10    | Tr.loss: 177.361875 | Elapsed:   73.85  s
01/30/2023 10:11:03 AM [!] Mon Jan 30 10:11:03 2023: Dumped results:
                model     : 1675069863-model.torch
		train time: 1675069863-trainTime.npy
		train losses: 1675069863-trainLosses.npy
		train AUC: 1675069863-auc.npy
01/30/2023 10:11:05 AM  [!] Training pretrained model on downstream task...
01/30/2023 10:11:05 AM  [*] Started epoch: 1
01/30/2023 10:11:05 AM  [*] Mon Jan 30 10:11:05 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 2.763670 | Elapsed: 0.32s | FPR 0.0003 -> TPR 0.0233 & F1 0.0455 | AUC 0.4690
01/30/2023 10:11:15 AM  [*] Mon Jan 30 10:11:15 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.489160 | Elapsed: 9.68s | FPR 0.0003 -> TPR 0.3810 & F1 0.5517 | AUC 0.7104
01/30/2023 10:11:17 AM  [*] Mon Jan 30 10:11:17 2023:    1    | Tr.loss: 0.689095 | Elapsed:   11.94  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.01 | AUC: 0.7122
01/30/2023 10:11:17 AM  [*] Started epoch: 2
01/30/2023 10:11:17 AM  [*] Mon Jan 30 10:11:17 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.477155 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.2766 & F1 0.4333 | AUC 0.7259
01/30/2023 10:11:26 AM  [*] Mon Jan 30 10:11:26 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.374600 | Elapsed: 9.71s | FPR 0.0003 -> TPR 0.4545 & F1 0.6250 | AUC 0.8512
01/30/2023 10:11:28 AM  [*] Mon Jan 30 10:11:28 2023:    2    | Tr.loss: 0.443324 | Elapsed:   11.76  s | FPR 0.0003 -> TPR: 0.07 & F1: 0.12 | AUC: 0.8176
01/30/2023 10:11:28 AM  [*] Started epoch: 3
01/30/2023 10:11:28 AM  [*] Mon Jan 30 10:11:28 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.411495 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.3684 & F1 0.5385 | AUC 0.8512
01/30/2023 10:11:38 AM  [*] Mon Jan 30 10:11:38 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.354317 | Elapsed: 9.65s | FPR 0.0003 -> TPR 0.5821 & F1 0.7358 | AUC 0.8905
01/30/2023 10:11:40 AM  [*] Mon Jan 30 10:11:40 2023:    3    | Tr.loss: 0.399767 | Elapsed:   11.79  s | FPR 0.0003 -> TPR: 0.11 & F1: 0.20 | AUC: 0.8584
01/30/2023 10:11:41 AM [!] Mon Jan 30 10:11:41 2023: Dumped results:
                model     : 1675069900-model.torch
		train time: 1675069900-trainTime.npy
		train losses: 1675069900-trainLosses.npy
		train AUC: 1675069900-auc.npy
		train F1s : 1675069900-trainF1s.npy
		train TPRs: 1675069900-trainTPRs.npy
01/30/2023 10:11:41 AM  [!] Training non_pretrained model on downstream task...
01/30/2023 10:11:41 AM  [*] Started epoch: 1
01/30/2023 10:11:41 AM  [*] Mon Jan 30 10:11:41 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 2.886136 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.2245 & F1 0.3667 | AUC 0.4231
01/30/2023 10:11:48 AM  [*] Mon Jan 30 10:11:48 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.417658 | Elapsed: 6.87s | FPR 0.0003 -> TPR 0.3676 & F1 0.5376 | AUC 0.8493
01/30/2023 10:11:50 AM  [*] Mon Jan 30 10:11:50 2023:    1    | Tr.loss: 0.662237 | Elapsed:   8.42   s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7161
01/30/2023 10:11:50 AM  [*] Started epoch: 2
01/30/2023 10:11:50 AM  [*] Mon Jan 30 10:11:50 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.491040 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.3111 & F1 0.4746 | AUC 0.7556
01/30/2023 10:11:57 AM  [*] Mon Jan 30 10:11:57 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.361094 | Elapsed: 6.92s | FPR 0.0003 -> TPR 0.4348 & F1 0.6061 | AUC 0.8864
01/30/2023 10:11:58 AM  [*] Mon Jan 30 10:11:58 2023:    2    | Tr.loss: 0.400077 | Elapsed:   8.45   s | FPR 0.0003 -> TPR: 0.12 & F1: 0.22 | AUC: 0.8724
01/30/2023 10:11:58 AM  [*] Started epoch: 3
01/30/2023 10:11:58 AM  [*] Mon Jan 30 10:11:58 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.262618 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.6087 & F1 0.7568 | AUC 0.9650
01/30/2023 10:12:05 AM  [*] Mon Jan 30 10:12:05 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.348552 | Elapsed: 7.02s | FPR 0.0003 -> TPR 0.6552 & F1 0.7917 | AUC 0.9142
01/30/2023 10:12:07 AM  [*] Mon Jan 30 10:12:07 2023:    3    | Tr.loss: 0.330732 | Elapsed:   8.63   s | FPR 0.0003 -> TPR: 0.21 & F1: 0.35 | AUC: 0.9162
01/30/2023 10:12:07 AM [!] Mon Jan 30 10:12:07 2023: Dumped results:
                model     : 1675069927-model.torch
		train time: 1675069927-trainTime.npy
		train losses: 1675069927-trainLosses.npy
		train AUC: 1675069927-auc.npy
		train F1s : 1675069927-trainF1s.npy
		train TPRs: 1675069927-trainTPRs.npy
01/30/2023 10:12:07 AM  [*] Evaluating pretrained model on test set...
01/30/2023 10:12:13 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.1006 | F1: 0.1828
01/30/2023 10:12:13 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1492 | F1: 0.2596
01/30/2023 10:12:13 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.2263 | F1: 0.3688
01/30/2023 10:12:13 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.2886 | F1: 0.4471
01/30/2023 10:12:13 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3639 | F1: 0.5304
01/30/2023 10:12:13 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4123 | F1: 0.5736
01/30/2023 10:12:13 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.5183 | F1: 0.6465
01/30/2023 10:12:13 AM  [*] Evaluating non_pretrained model on test set...
01/30/2023 10:12:18 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0726 | F1: 0.1354
01/30/2023 10:12:18 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1539 | F1: 0.2667
01/30/2023 10:12:18 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.2113 | F1: 0.3487
01/30/2023 10:12:18 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.2534 | F1: 0.4036
01/30/2023 10:12:18 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3077 | F1: 0.4675
01/30/2023 10:12:18 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.3985 | F1: 0.5597
01/30/2023 10:12:18 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.5785 | F1: 0.6955
01/30/2023 10:12:18 AM  [!] Finished pre-training evaluation over 3 splits! Saved metrics to:
	C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\downsample_tests\downsample_U_0.5_1675067015/metrics_MaskedLanguageModel_nSplits_3_limit_None.json
01/30/2023 10:12:18 AM  [!] Starting uSize downsample 0.6 evaluation!
01/30/2023 10:12:18 AM  [!] Starting Masked Language Model evaluation over 3 splits!
01/30/2023 10:12:18 AM  [!] Loaded data and vocab. X train size: (76126, 512), X test size: (17407, 512), vocab size: 50002
01/30/2023 10:12:18 AM  [!] Initiating Self-Supervised Learning Pretraining
     Language Modeling MaskedLanguageModel
     Model TransformerEncoderLM with config:
	{'vocabSize': 50002, 'maxLen': 512, 'dModel': 64, 'nHeads': 8, 'dHidden': 256, 'nLayers': 2, 'numClasses': 1, 'hiddenNeurons': [64], 'dropout': 0.3}

01/30/2023 10:12:18 AM  [!] Running pre-training split 1/3
01/30/2023 10:12:21 AM  [!] Pre-training model...
01/30/2023 10:12:22 AM  [*] Masking sequences...
01/30/2023 10:12:38 AM  [*] Started epoch: 1
01/30/2023 10:12:39 AM  [*] Mon Jan 30 10:12:39 2023: Train Epoch: 1 [  0  /41107 (0 %)]	Loss: 439.739685 | Elapsed: 0.33s
01/30/2023 10:12:52 AM  [*] Mon Jan 30 10:12:52 2023: Train Epoch: 1 [6400 /41107 (16%)]	Loss: 242.025726 | Elapsed: 13.22s
01/30/2023 10:13:05 AM  [*] Mon Jan 30 10:13:05 2023: Train Epoch: 1 [12800/41107 (31%)]	Loss: 218.744324 | Elapsed: 13.42s
01/30/2023 10:13:19 AM  [*] Mon Jan 30 10:13:19 2023: Train Epoch: 1 [19200/41107 (47%)]	Loss: 218.554276 | Elapsed: 13.50s
01/30/2023 10:13:32 AM  [*] Mon Jan 30 10:13:32 2023: Train Epoch: 1 [25600/41107 (62%)]	Loss: 217.183487 | Elapsed: 13.51s
01/30/2023 10:13:46 AM  [*] Mon Jan 30 10:13:46 2023: Train Epoch: 1 [32000/41107 (78%)]	Loss: 235.074966 | Elapsed: 13.75s
01/30/2023 10:14:00 AM  [*] Mon Jan 30 10:14:00 2023: Train Epoch: 1 [38400/41107 (93%)]	Loss: 200.111633 | Elapsed: 13.95s
01/30/2023 10:14:07 AM  [*] Mon Jan 30 10:14:07 2023:    1    | Tr.loss: 215.294051 | Elapsed:   88.97  s
01/30/2023 10:14:07 AM  [*] Started epoch: 2
01/30/2023 10:14:08 AM  [*] Mon Jan 30 10:14:08 2023: Train Epoch: 2 [  0  /41107 (0 %)]	Loss: 187.715057 | Elapsed: 0.14s
01/30/2023 10:14:21 AM  [*] Mon Jan 30 10:14:21 2023: Train Epoch: 2 [6400 /41107 (16%)]	Loss: 219.494614 | Elapsed: 13.50s
01/30/2023 10:14:35 AM  [*] Mon Jan 30 10:14:35 2023: Train Epoch: 2 [12800/41107 (31%)]	Loss: 194.702057 | Elapsed: 13.52s
01/30/2023 10:14:48 AM  [*] Mon Jan 30 10:14:48 2023: Train Epoch: 2 [19200/41107 (47%)]	Loss: 196.922272 | Elapsed: 13.54s
01/30/2023 10:15:02 AM  [*] Mon Jan 30 10:15:02 2023: Train Epoch: 2 [25600/41107 (62%)]	Loss: 202.323517 | Elapsed: 13.74s
01/30/2023 10:15:15 AM  [*] Mon Jan 30 10:15:15 2023: Train Epoch: 2 [32000/41107 (78%)]	Loss: 209.521713 | Elapsed: 13.68s
01/30/2023 10:15:29 AM  [*] Mon Jan 30 10:15:29 2023: Train Epoch: 2 [38400/41107 (93%)]	Loss: 182.390930 | Elapsed: 13.63s
01/30/2023 10:15:36 AM  [*] Mon Jan 30 10:15:36 2023:    2    | Tr.loss: 191.792974 | Elapsed:   89.10  s
01/30/2023 10:15:36 AM  [*] Started epoch: 3
01/30/2023 10:15:37 AM  [*] Mon Jan 30 10:15:37 2023: Train Epoch: 3 [  0  /41107 (0 %)]	Loss: 200.498413 | Elapsed: 0.15s
01/30/2023 10:15:50 AM  [*] Mon Jan 30 10:15:50 2023: Train Epoch: 3 [6400 /41107 (16%)]	Loss: 205.077698 | Elapsed: 13.68s
01/30/2023 10:16:04 AM  [*] Mon Jan 30 10:16:04 2023: Train Epoch: 3 [12800/41107 (31%)]	Loss: 201.870575 | Elapsed: 13.96s
01/30/2023 10:16:18 AM  [*] Mon Jan 30 10:16:18 2023: Train Epoch: 3 [19200/41107 (47%)]	Loss: 169.908447 | Elapsed: 13.91s
01/30/2023 10:16:32 AM  [*] Mon Jan 30 10:16:32 2023: Train Epoch: 3 [25600/41107 (62%)]	Loss: 179.536133 | Elapsed: 13.69s
01/30/2023 10:16:45 AM  [*] Mon Jan 30 10:16:45 2023: Train Epoch: 3 [32000/41107 (78%)]	Loss: 192.394745 | Elapsed: 13.51s
01/30/2023 10:16:59 AM  [*] Mon Jan 30 10:16:59 2023: Train Epoch: 3 [38400/41107 (93%)]	Loss: 190.425079 | Elapsed: 13.51s
01/30/2023 10:17:06 AM  [*] Mon Jan 30 10:17:06 2023:    3    | Tr.loss: 185.736634 | Elapsed:   89.59  s
01/30/2023 10:17:06 AM  [*] Started epoch: 4
01/30/2023 10:17:06 AM  [*] Mon Jan 30 10:17:06 2023: Train Epoch: 4 [  0  /41107 (0 %)]	Loss: 180.570618 | Elapsed: 0.14s
01/30/2023 10:17:20 AM  [*] Mon Jan 30 10:17:20 2023: Train Epoch: 4 [6400 /41107 (16%)]	Loss: 194.795441 | Elapsed: 13.52s
01/30/2023 10:17:33 AM  [*] Mon Jan 30 10:17:33 2023: Train Epoch: 4 [12800/41107 (31%)]	Loss: 177.450775 | Elapsed: 13.46s
01/30/2023 10:17:47 AM  [*] Mon Jan 30 10:17:47 2023: Train Epoch: 4 [19200/41107 (47%)]	Loss: 197.119431 | Elapsed: 13.55s
01/30/2023 10:18:01 AM  [*] Mon Jan 30 10:18:01 2023: Train Epoch: 4 [25600/41107 (62%)]	Loss: 180.838837 | Elapsed: 13.94s
01/30/2023 10:18:15 AM  [*] Mon Jan 30 10:18:15 2023: Train Epoch: 4 [32000/41107 (78%)]	Loss: 171.336548 | Elapsed: 13.83s
01/30/2023 10:18:28 AM  [*] Mon Jan 30 10:18:28 2023: Train Epoch: 4 [38400/41107 (93%)]	Loss: 196.622208 | Elapsed: 13.66s
01/30/2023 10:18:35 AM  [*] Mon Jan 30 10:18:35 2023:    4    | Tr.loss: 182.512110 | Elapsed:   89.31  s
01/30/2023 10:18:35 AM  [*] Started epoch: 5
01/30/2023 10:18:35 AM  [*] Mon Jan 30 10:18:35 2023: Train Epoch: 5 [  0  /41107 (0 %)]	Loss: 174.150635 | Elapsed: 0.13s
01/30/2023 10:18:50 AM  [*] Mon Jan 30 10:18:50 2023: Train Epoch: 5 [6400 /41107 (16%)]	Loss: 201.521973 | Elapsed: 14.29s
01/30/2023 10:19:04 AM  [*] Mon Jan 30 10:19:04 2023: Train Epoch: 5 [12800/41107 (31%)]	Loss: 174.380096 | Elapsed: 13.86s
01/30/2023 10:19:18 AM  [*] Mon Jan 30 10:19:18 2023: Train Epoch: 5 [19200/41107 (47%)]	Loss: 190.370850 | Elapsed: 14.00s
01/30/2023 10:19:31 AM  [*] Mon Jan 30 10:19:31 2023: Train Epoch: 5 [25600/41107 (62%)]	Loss: 164.493759 | Elapsed: 13.74s
01/30/2023 10:19:45 AM  [*] Mon Jan 30 10:19:45 2023: Train Epoch: 5 [32000/41107 (78%)]	Loss: 173.608124 | Elapsed: 13.64s
01/30/2023 10:19:59 AM  [*] Mon Jan 30 10:19:59 2023: Train Epoch: 5 [38400/41107 (93%)]	Loss: 187.323700 | Elapsed: 13.75s
01/30/2023 10:20:06 AM  [*] Mon Jan 30 10:20:06 2023:    5    | Tr.loss: 180.489925 | Elapsed:   91.01  s
01/30/2023 10:20:06 AM  [*] Started epoch: 6
01/30/2023 10:20:07 AM  [*] Mon Jan 30 10:20:07 2023: Train Epoch: 6 [  0  /41107 (0 %)]	Loss: 188.598587 | Elapsed: 0.14s
01/30/2023 10:20:20 AM  [*] Mon Jan 30 10:20:20 2023: Train Epoch: 6 [6400 /41107 (16%)]	Loss: 169.773071 | Elapsed: 13.79s
01/30/2023 10:20:34 AM  [*] Mon Jan 30 10:20:34 2023: Train Epoch: 6 [12800/41107 (31%)]	Loss: 187.851059 | Elapsed: 13.58s
01/30/2023 10:20:48 AM  [*] Mon Jan 30 10:20:48 2023: Train Epoch: 6 [19200/41107 (47%)]	Loss: 163.998428 | Elapsed: 13.67s
01/30/2023 10:21:01 AM  [*] Mon Jan 30 10:21:01 2023: Train Epoch: 6 [25600/41107 (62%)]	Loss: 196.657318 | Elapsed: 13.70s
01/30/2023 10:21:15 AM  [*] Mon Jan 30 10:21:15 2023: Train Epoch: 6 [32000/41107 (78%)]	Loss: 175.641449 | Elapsed: 13.73s
01/30/2023 10:21:29 AM  [*] Mon Jan 30 10:21:29 2023: Train Epoch: 6 [38400/41107 (93%)]	Loss: 180.827133 | Elapsed: 14.09s
01/30/2023 10:21:37 AM  [*] Mon Jan 30 10:21:37 2023:    6    | Tr.loss: 178.913921 | Elapsed:   90.30  s
01/30/2023 10:21:37 AM  [*] Started epoch: 7
01/30/2023 10:21:37 AM  [*] Mon Jan 30 10:21:37 2023: Train Epoch: 7 [  0  /41107 (0 %)]	Loss: 182.125656 | Elapsed: 0.15s
01/30/2023 10:21:51 AM  [*] Mon Jan 30 10:21:51 2023: Train Epoch: 7 [6400 /41107 (16%)]	Loss: 170.080017 | Elapsed: 13.96s
01/30/2023 10:22:05 AM  [*] Mon Jan 30 10:22:05 2023: Train Epoch: 7 [12800/41107 (31%)]	Loss: 164.478851 | Elapsed: 14.14s
01/30/2023 10:22:19 AM  [*] Mon Jan 30 10:22:19 2023: Train Epoch: 7 [19200/41107 (47%)]	Loss: 183.914215 | Elapsed: 13.69s
01/30/2023 10:22:32 AM  [*] Mon Jan 30 10:22:32 2023: Train Epoch: 7 [25600/41107 (62%)]	Loss: 177.553146 | Elapsed: 13.43s
01/30/2023 10:22:46 AM  [*] Mon Jan 30 10:22:46 2023: Train Epoch: 7 [32000/41107 (78%)]	Loss: 183.303223 | Elapsed: 13.76s
01/30/2023 10:22:59 AM  [*] Mon Jan 30 10:22:59 2023: Train Epoch: 7 [38400/41107 (93%)]	Loss: 171.653030 | Elapsed: 13.67s
01/30/2023 10:23:07 AM  [*] Mon Jan 30 10:23:07 2023:    7    | Tr.loss: 177.718559 | Elapsed:   90.38  s
01/30/2023 10:23:07 AM  [*] Started epoch: 8
01/30/2023 10:23:07 AM  [*] Mon Jan 30 10:23:07 2023: Train Epoch: 8 [  0  /41107 (0 %)]	Loss: 188.561951 | Elapsed: 0.14s
01/30/2023 10:23:21 AM  [*] Mon Jan 30 10:23:21 2023: Train Epoch: 8 [6400 /41107 (16%)]	Loss: 168.722931 | Elapsed: 13.69s
01/30/2023 10:23:35 AM  [*] Mon Jan 30 10:23:35 2023: Train Epoch: 8 [12800/41107 (31%)]	Loss: 157.487869 | Elapsed: 13.69s
01/30/2023 10:23:48 AM  [*] Mon Jan 30 10:23:48 2023: Train Epoch: 8 [19200/41107 (47%)]	Loss: 177.749756 | Elapsed: 13.50s
01/30/2023 10:24:02 AM  [*] Mon Jan 30 10:24:02 2023: Train Epoch: 8 [25600/41107 (62%)]	Loss: 170.623932 | Elapsed: 13.48s
01/30/2023 10:24:15 AM  [*] Mon Jan 30 10:24:15 2023: Train Epoch: 8 [32000/41107 (78%)]	Loss: 182.450424 | Elapsed: 13.61s
01/30/2023 10:24:29 AM  [*] Mon Jan 30 10:24:29 2023: Train Epoch: 8 [38400/41107 (93%)]	Loss: 181.124115 | Elapsed: 13.56s
01/30/2023 10:24:36 AM  [*] Mon Jan 30 10:24:36 2023:    8    | Tr.loss: 176.817026 | Elapsed:   88.86  s
01/30/2023 10:24:36 AM  [*] Started epoch: 9
01/30/2023 10:24:36 AM  [*] Mon Jan 30 10:24:36 2023: Train Epoch: 9 [  0  /41107 (0 %)]	Loss: 172.068787 | Elapsed: 0.14s
01/30/2023 10:24:50 AM  [*] Mon Jan 30 10:24:50 2023: Train Epoch: 9 [6400 /41107 (16%)]	Loss: 177.417938 | Elapsed: 13.65s
01/30/2023 10:25:03 AM  [*] Mon Jan 30 10:25:03 2023: Train Epoch: 9 [12800/41107 (31%)]	Loss: 178.322800 | Elapsed: 13.58s
01/30/2023 10:25:17 AM  [*] Mon Jan 30 10:25:17 2023: Train Epoch: 9 [19200/41107 (47%)]	Loss: 184.209930 | Elapsed: 13.60s
01/30/2023 10:25:31 AM  [*] Mon Jan 30 10:25:31 2023: Train Epoch: 9 [25600/41107 (62%)]	Loss: 171.147049 | Elapsed: 13.64s
01/30/2023 10:25:44 AM  [*] Mon Jan 30 10:25:44 2023: Train Epoch: 9 [32000/41107 (78%)]	Loss: 175.925308 | Elapsed: 13.50s
01/30/2023 10:25:58 AM  [*] Mon Jan 30 10:25:58 2023: Train Epoch: 9 [38400/41107 (93%)]	Loss: 168.831146 | Elapsed: 13.71s
01/30/2023 10:26:05 AM  [*] Mon Jan 30 10:26:05 2023:    9    | Tr.loss: 175.849351 | Elapsed:   88.97  s
01/30/2023 10:26:05 AM  [*] Started epoch: 10
01/30/2023 10:26:05 AM  [*] Mon Jan 30 10:26:05 2023: Train Epoch: 10 [  0  /41107 (0 %)]	Loss: 193.443329 | Elapsed: 0.14s
01/30/2023 10:26:19 AM  [*] Mon Jan 30 10:26:19 2023: Train Epoch: 10 [6400 /41107 (16%)]	Loss: 184.179001 | Elapsed: 14.06s
01/30/2023 10:26:33 AM  [*] Mon Jan 30 10:26:33 2023: Train Epoch: 10 [12800/41107 (31%)]	Loss: 167.881042 | Elapsed: 14.24s
01/30/2023 10:26:47 AM  [*] Mon Jan 30 10:26:47 2023: Train Epoch: 10 [19200/41107 (47%)]	Loss: 178.012543 | Elapsed: 13.52s
01/30/2023 10:27:00 AM  [*] Mon Jan 30 10:27:00 2023: Train Epoch: 10 [25600/41107 (62%)]	Loss: 171.207230 | Elapsed: 13.56s
01/30/2023 10:27:14 AM  [*] Mon Jan 30 10:27:14 2023: Train Epoch: 10 [32000/41107 (78%)]	Loss: 176.863739 | Elapsed: 13.95s
01/30/2023 10:27:28 AM  [*] Mon Jan 30 10:27:28 2023: Train Epoch: 10 [38400/41107 (93%)]	Loss: 178.424713 | Elapsed: 14.14s
01/30/2023 10:27:35 AM  [*] Mon Jan 30 10:27:35 2023:   10    | Tr.loss: 175.250055 | Elapsed:   90.17  s
01/30/2023 10:27:35 AM [!] Mon Jan 30 10:27:35 2023: Dumped results:
                model     : 1675070855-model.torch
		train time: 1675070855-trainTime.npy
		train losses: 1675070855-trainLosses.npy
		train AUC: 1675070855-auc.npy
01/30/2023 10:27:37 AM  [!] Training pretrained model on downstream task...
01/30/2023 10:27:37 AM  [*] Started epoch: 1
01/30/2023 10:27:37 AM  [*] Mon Jan 30 10:27:37 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 2.041810 | Elapsed: 0.20s | FPR 0.0003 -> TPR 0.0270 & F1 0.0526 | AUC 0.5085
01/30/2023 10:27:47 AM  [*] Mon Jan 30 10:27:47 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.463588 | Elapsed: 9.50s | FPR 0.0003 -> TPR 0.1864 & F1 0.3143 | AUC 0.8632
01/30/2023 10:27:48 AM  [*] Mon Jan 30 10:27:48 2023:    1    | Tr.loss: 0.621454 | Elapsed:   11.55  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7746
01/30/2023 10:27:48 AM  [*] Started epoch: 2
01/30/2023 10:27:48 AM  [*] Mon Jan 30 10:27:48 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.357355 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.4444 & F1 0.6154 | AUC 0.8760
01/30/2023 10:27:58 AM  [*] Mon Jan 30 10:27:58 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.317906 | Elapsed: 9.50s | FPR 0.0003 -> TPR 0.6986 & F1 0.8226 | AUC 0.9183
01/30/2023 10:28:00 AM  [*] Mon Jan 30 10:28:00 2023:    2    | Tr.loss: 0.384075 | Elapsed:   11.48  s | FPR 0.0003 -> TPR: 0.02 & F1: 0.04 | AUC: 0.8835
01/30/2023 10:28:00 AM  [*] Started epoch: 3
01/30/2023 10:28:00 AM  [*] Mon Jan 30 10:28:00 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.378505 | Elapsed: 0.11s | FPR 0.0003 -> TPR 0.7297 & F1 0.8437 | AUC 0.9144
01/30/2023 10:28:09 AM  [*] Mon Jan 30 10:28:09 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.338960 | Elapsed: 9.34s | FPR 0.0003 -> TPR 0.3333 & F1 0.5000 | AUC 0.9346
01/30/2023 10:28:11 AM  [*] Mon Jan 30 10:28:11 2023:    3    | Tr.loss: 0.321563 | Elapsed:   11.33  s | FPR 0.0003 -> TPR: 0.19 & F1: 0.32 | AUC: 0.9220
01/30/2023 10:28:12 AM [!] Mon Jan 30 10:28:12 2023: Dumped results:
                model     : 1675070891-model.torch
		train time: 1675070891-trainTime.npy
		train losses: 1675070891-trainLosses.npy
		train AUC: 1675070891-auc.npy
		train F1s : 1675070891-trainF1s.npy
		train TPRs: 1675070891-trainTPRs.npy
01/30/2023 10:28:12 AM  [!] Training non_pretrained model on downstream task...
01/30/2023 10:28:12 AM  [*] Started epoch: 1
01/30/2023 10:28:12 AM  [*] Mon Jan 30 10:28:12 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 1.528291 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0435 & F1 0.0833 | AUC 0.4879
01/30/2023 10:28:19 AM  [*] Mon Jan 30 10:28:19 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.333055 | Elapsed: 6.32s | FPR 0.0003 -> TPR 0.5867 & F1 0.7395 | AUC 0.8603
01/30/2023 10:28:20 AM  [*] Mon Jan 30 10:28:20 2023:    1    | Tr.loss: 0.555410 | Elapsed:   7.80   s | FPR 0.0003 -> TPR: 0.00 & F1: 0.01 | AUC: 0.7599
01/30/2023 10:28:20 AM  [*] Started epoch: 2
01/30/2023 10:28:20 AM  [*] Mon Jan 30 10:28:20 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.463121 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.5319 & F1 0.6944 | AUC 0.8523
01/30/2023 10:28:26 AM  [*] Mon Jan 30 10:28:26 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.420662 | Elapsed: 6.40s | FPR 0.0003 -> TPR 0.2239 & F1 0.3659 | AUC 0.8933
01/30/2023 10:28:28 AM  [*] Mon Jan 30 10:28:28 2023:    2    | Tr.loss: 0.369449 | Elapsed:   7.78   s | FPR 0.0003 -> TPR: 0.09 & F1: 0.17 | AUC: 0.8909
01/30/2023 10:28:28 AM  [*] Started epoch: 3
01/30/2023 10:28:28 AM  [*] Mon Jan 30 10:28:28 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.220371 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.6170 & F1 0.7632 | AUC 0.9737
01/30/2023 10:28:34 AM  [*] Mon Jan 30 10:28:34 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.365216 | Elapsed: 6.46s | FPR 0.0003 -> TPR 0.3538 & F1 0.5227 | AUC 0.8646
01/30/2023 10:28:36 AM  [*] Mon Jan 30 10:28:36 2023:    3    | Tr.loss: 0.306971 | Elapsed:   7.87   s | FPR 0.0003 -> TPR: 0.14 & F1: 0.24 | AUC: 0.9284
01/30/2023 10:28:36 AM [!] Mon Jan 30 10:28:36 2023: Dumped results:
                model     : 1675070916-model.torch
		train time: 1675070916-trainTime.npy
		train losses: 1675070916-trainLosses.npy
		train AUC: 1675070916-auc.npy
		train F1s : 1675070916-trainF1s.npy
		train TPRs: 1675070916-trainTPRs.npy
01/30/2023 10:28:36 AM  [*] Evaluating pretrained model on test set...
01/30/2023 10:28:41 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0869 | F1: 0.1599
01/30/2023 10:28:41 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1943 | F1: 0.3253
01/30/2023 10:28:41 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.3111 | F1: 0.4742
01/30/2023 10:28:41 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3606 | F1: 0.5291
01/30/2023 10:28:41 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3970 | F1: 0.5649
01/30/2023 10:28:41 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4542 | F1: 0.6139
01/30/2023 10:28:41 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.6623 | F1: 0.7581
01/30/2023 10:28:41 AM  [*] Evaluating non_pretrained model on test set...
01/30/2023 10:28:46 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0007 | F1: 0.0015
01/30/2023 10:28:46 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.0986 | F1: 0.1794
01/30/2023 10:28:46 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.2021 | F1: 0.3360
01/30/2023 10:28:46 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.2301 | F1: 0.3734
01/30/2023 10:28:46 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.2849 | F1: 0.4406
01/30/2023 10:28:46 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.3858 | F1: 0.5468
01/30/2023 10:28:46 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.6249 | F1: 0.7309
01/30/2023 10:28:46 AM  [!] Running pre-training split 2/3
01/30/2023 10:28:48 AM  [!] Pre-training model...
01/30/2023 10:28:49 AM  [*] Masking sequences...
01/30/2023 10:29:02 AM  [*] Started epoch: 1
01/30/2023 10:29:02 AM  [*] Mon Jan 30 10:29:02 2023: Train Epoch: 1 [  0  /41107 (0 %)]	Loss: 416.664795 | Elapsed: 0.39s
01/30/2023 10:29:14 AM  [*] Mon Jan 30 10:29:14 2023: Train Epoch: 1 [6400 /41107 (16%)]	Loss: 212.492310 | Elapsed: 12.39s
01/30/2023 10:29:27 AM  [*] Mon Jan 30 10:29:27 2023: Train Epoch: 1 [12800/41107 (31%)]	Loss: 200.366882 | Elapsed: 12.25s
01/30/2023 10:29:39 AM  [*] Mon Jan 30 10:29:39 2023: Train Epoch: 1 [19200/41107 (47%)]	Loss: 210.756348 | Elapsed: 12.69s
01/30/2023 10:29:52 AM  [*] Mon Jan 30 10:29:52 2023: Train Epoch: 1 [25600/41107 (62%)]	Loss: 190.448029 | Elapsed: 12.43s
01/30/2023 10:30:04 AM  [*] Mon Jan 30 10:30:04 2023: Train Epoch: 1 [32000/41107 (78%)]	Loss: 195.577179 | Elapsed: 12.63s
01/30/2023 10:30:21 AM  [*] Mon Jan 30 10:30:21 2023: Train Epoch: 1 [38400/41107 (93%)]	Loss: 175.001099 | Elapsed: 16.21s
01/30/2023 10:30:27 AM  [*] Mon Jan 30 10:30:27 2023:    1    | Tr.loss: 214.060644 | Elapsed:   85.73  s
01/30/2023 10:30:27 AM  [*] Started epoch: 2
01/30/2023 10:30:27 AM  [*] Mon Jan 30 10:30:27 2023: Train Epoch: 2 [  0  /41107 (0 %)]	Loss: 191.553543 | Elapsed: 0.14s
01/30/2023 10:30:40 AM  [*] Mon Jan 30 10:30:40 2023: Train Epoch: 2 [6400 /41107 (16%)]	Loss: 196.473404 | Elapsed: 12.55s
01/30/2023 10:30:52 AM  [*] Mon Jan 30 10:30:52 2023: Train Epoch: 2 [12800/41107 (31%)]	Loss: 179.280167 | Elapsed: 12.43s
01/30/2023 10:31:05 AM  [*] Mon Jan 30 10:31:05 2023: Train Epoch: 2 [19200/41107 (47%)]	Loss: 194.185974 | Elapsed: 12.45s
01/30/2023 10:31:17 AM  [*] Mon Jan 30 10:31:17 2023: Train Epoch: 2 [25600/41107 (62%)]	Loss: 180.293884 | Elapsed: 12.41s
01/30/2023 10:31:30 AM  [*] Mon Jan 30 10:31:30 2023: Train Epoch: 2 [32000/41107 (78%)]	Loss: 201.993652 | Elapsed: 12.43s
01/30/2023 10:31:42 AM  [*] Mon Jan 30 10:31:42 2023: Train Epoch: 2 [38400/41107 (93%)]	Loss: 198.044830 | Elapsed: 12.42s
01/30/2023 10:31:49 AM  [*] Mon Jan 30 10:31:49 2023:    2    | Tr.loss: 190.832584 | Elapsed:   81.19  s
01/30/2023 10:31:49 AM  [*] Started epoch: 3
01/30/2023 10:31:49 AM  [*] Mon Jan 30 10:31:49 2023: Train Epoch: 3 [  0  /41107 (0 %)]	Loss: 176.727158 | Elapsed: 0.14s
01/30/2023 10:32:01 AM  [*] Mon Jan 30 10:32:01 2023: Train Epoch: 3 [6400 /41107 (16%)]	Loss: 182.389862 | Elapsed: 12.34s
01/30/2023 10:32:13 AM  [*] Mon Jan 30 10:32:13 2023: Train Epoch: 3 [12800/41107 (31%)]	Loss: 179.211090 | Elapsed: 12.38s
01/30/2023 10:32:26 AM  [*] Mon Jan 30 10:32:26 2023: Train Epoch: 3 [19200/41107 (47%)]	Loss: 185.021210 | Elapsed: 12.32s
01/30/2023 10:32:38 AM  [*] Mon Jan 30 10:32:38 2023: Train Epoch: 3 [25600/41107 (62%)]	Loss: 179.471741 | Elapsed: 12.47s
01/30/2023 10:32:51 AM  [*] Mon Jan 30 10:32:51 2023: Train Epoch: 3 [32000/41107 (78%)]	Loss: 180.910233 | Elapsed: 12.46s
01/30/2023 10:33:03 AM  [*] Mon Jan 30 10:33:03 2023: Train Epoch: 3 [38400/41107 (93%)]	Loss: 168.486542 | Elapsed: 12.38s
01/30/2023 10:33:09 AM  [*] Mon Jan 30 10:33:09 2023:    3    | Tr.loss: 184.235931 | Elapsed:   80.85  s
01/30/2023 10:33:09 AM  [*] Started epoch: 4
01/30/2023 10:33:09 AM  [*] Mon Jan 30 10:33:09 2023: Train Epoch: 4 [  0  /41107 (0 %)]	Loss: 191.489624 | Elapsed: 0.13s
01/30/2023 10:33:22 AM  [*] Mon Jan 30 10:33:22 2023: Train Epoch: 4 [6400 /41107 (16%)]	Loss: 177.201385 | Elapsed: 12.46s
01/30/2023 10:33:34 AM  [*] Mon Jan 30 10:33:34 2023: Train Epoch: 4 [12800/41107 (31%)]	Loss: 205.328796 | Elapsed: 12.42s
01/30/2023 10:33:47 AM  [*] Mon Jan 30 10:33:47 2023: Train Epoch: 4 [19200/41107 (47%)]	Loss: 187.600845 | Elapsed: 12.49s
01/30/2023 10:33:59 AM  [*] Mon Jan 30 10:33:59 2023: Train Epoch: 4 [25600/41107 (62%)]	Loss: 192.593292 | Elapsed: 12.54s
01/30/2023 10:34:12 AM  [*] Mon Jan 30 10:34:12 2023: Train Epoch: 4 [32000/41107 (78%)]	Loss: 177.772400 | Elapsed: 12.57s
01/30/2023 10:34:24 AM  [*] Mon Jan 30 10:34:24 2023: Train Epoch: 4 [38400/41107 (93%)]	Loss: 165.841522 | Elapsed: 12.36s
01/30/2023 10:34:31 AM  [*] Mon Jan 30 10:34:31 2023:    4    | Tr.loss: 180.923395 | Elapsed:   81.28  s
01/30/2023 10:34:31 AM  [*] Started epoch: 5
01/30/2023 10:34:31 AM  [*] Mon Jan 30 10:34:31 2023: Train Epoch: 5 [  0  /41107 (0 %)]	Loss: 179.815201 | Elapsed: 0.13s
01/30/2023 10:34:43 AM  [*] Mon Jan 30 10:34:43 2023: Train Epoch: 5 [6400 /41107 (16%)]	Loss: 193.289825 | Elapsed: 12.38s
01/30/2023 10:34:56 AM  [*] Mon Jan 30 10:34:56 2023: Train Epoch: 5 [12800/41107 (31%)]	Loss: 169.938309 | Elapsed: 12.53s
01/30/2023 10:35:08 AM  [*] Mon Jan 30 10:35:08 2023: Train Epoch: 5 [19200/41107 (47%)]	Loss: 184.411163 | Elapsed: 12.42s
01/30/2023 10:35:21 AM  [*] Mon Jan 30 10:35:21 2023: Train Epoch: 5 [25600/41107 (62%)]	Loss: 193.561157 | Elapsed: 12.49s
01/30/2023 10:35:33 AM  [*] Mon Jan 30 10:35:33 2023: Train Epoch: 5 [32000/41107 (78%)]	Loss: 171.906845 | Elapsed: 12.32s
01/30/2023 10:35:45 AM  [*] Mon Jan 30 10:35:45 2023: Train Epoch: 5 [38400/41107 (93%)]	Loss: 170.184372 | Elapsed: 12.35s
01/30/2023 10:35:52 AM  [*] Mon Jan 30 10:35:52 2023:    5    | Tr.loss: 178.736648 | Elapsed:   81.02  s
01/30/2023 10:35:52 AM  [*] Started epoch: 6
01/30/2023 10:35:52 AM  [*] Mon Jan 30 10:35:52 2023: Train Epoch: 6 [  0  /41107 (0 %)]	Loss: 179.376770 | Elapsed: 0.13s
01/30/2023 10:36:04 AM  [*] Mon Jan 30 10:36:04 2023: Train Epoch: 6 [6400 /41107 (16%)]	Loss: 172.256927 | Elapsed: 12.37s
01/30/2023 10:36:16 AM  [*] Mon Jan 30 10:36:16 2023: Train Epoch: 6 [12800/41107 (31%)]	Loss: 154.743103 | Elapsed: 12.33s
01/30/2023 10:36:29 AM  [*] Mon Jan 30 10:36:29 2023: Train Epoch: 6 [19200/41107 (47%)]	Loss: 163.894653 | Elapsed: 12.44s
01/30/2023 10:36:41 AM  [*] Mon Jan 30 10:36:41 2023: Train Epoch: 6 [25600/41107 (62%)]	Loss: 186.256363 | Elapsed: 12.30s
01/30/2023 10:36:54 AM  [*] Mon Jan 30 10:36:54 2023: Train Epoch: 6 [32000/41107 (78%)]	Loss: 184.492508 | Elapsed: 12.36s
01/30/2023 10:37:06 AM  [*] Mon Jan 30 10:37:06 2023: Train Epoch: 6 [38400/41107 (93%)]	Loss: 196.197708 | Elapsed: 12.40s
01/30/2023 10:37:12 AM  [*] Mon Jan 30 10:37:12 2023:    6    | Tr.loss: 177.273613 | Elapsed:   80.72  s
01/30/2023 10:37:12 AM  [*] Started epoch: 7
01/30/2023 10:37:12 AM  [*] Mon Jan 30 10:37:12 2023: Train Epoch: 7 [  0  /41107 (0 %)]	Loss: 182.959564 | Elapsed: 0.12s
01/30/2023 10:37:25 AM  [*] Mon Jan 30 10:37:25 2023: Train Epoch: 7 [6400 /41107 (16%)]	Loss: 178.990204 | Elapsed: 12.41s
01/30/2023 10:37:37 AM  [*] Mon Jan 30 10:37:37 2023: Train Epoch: 7 [12800/41107 (31%)]	Loss: 170.540161 | Elapsed: 12.38s
01/30/2023 10:37:50 AM  [*] Mon Jan 30 10:37:50 2023: Train Epoch: 7 [19200/41107 (47%)]	Loss: 171.550781 | Elapsed: 12.39s
01/30/2023 10:38:02 AM  [*] Mon Jan 30 10:38:02 2023: Train Epoch: 7 [25600/41107 (62%)]	Loss: 175.404633 | Elapsed: 12.32s
01/30/2023 10:38:14 AM  [*] Mon Jan 30 10:38:14 2023: Train Epoch: 7 [32000/41107 (78%)]	Loss: 176.653076 | Elapsed: 12.29s
01/30/2023 10:38:27 AM  [*] Mon Jan 30 10:38:27 2023: Train Epoch: 7 [38400/41107 (93%)]	Loss: 182.552856 | Elapsed: 12.34s
01/30/2023 10:38:33 AM  [*] Mon Jan 30 10:38:33 2023:    7    | Tr.loss: 176.175030 | Elapsed:   80.65  s
01/30/2023 10:38:33 AM  [*] Started epoch: 8
01/30/2023 10:38:33 AM  [*] Mon Jan 30 10:38:33 2023: Train Epoch: 8 [  0  /41107 (0 %)]	Loss: 172.601593 | Elapsed: 0.12s
01/30/2023 10:38:46 AM  [*] Mon Jan 30 10:38:46 2023: Train Epoch: 8 [6400 /41107 (16%)]	Loss: 186.008698 | Elapsed: 12.45s
01/30/2023 10:38:58 AM  [*] Mon Jan 30 10:38:58 2023: Train Epoch: 8 [12800/41107 (31%)]	Loss: 193.898651 | Elapsed: 12.32s
01/30/2023 10:39:10 AM  [*] Mon Jan 30 10:39:10 2023: Train Epoch: 8 [19200/41107 (47%)]	Loss: 200.216553 | Elapsed: 12.31s
01/30/2023 10:39:22 AM  [*] Mon Jan 30 10:39:22 2023: Train Epoch: 8 [25600/41107 (62%)]	Loss: 177.587234 | Elapsed: 12.26s
01/30/2023 10:39:35 AM  [*] Mon Jan 30 10:39:35 2023: Train Epoch: 8 [32000/41107 (78%)]	Loss: 160.647141 | Elapsed: 12.37s
01/30/2023 10:39:47 AM  [*] Mon Jan 30 10:39:47 2023: Train Epoch: 8 [38400/41107 (93%)]	Loss: 195.432419 | Elapsed: 12.37s
01/30/2023 10:39:54 AM  [*] Mon Jan 30 10:39:54 2023:    8    | Tr.loss: 175.180531 | Elapsed:   80.53  s
01/30/2023 10:39:54 AM  [*] Started epoch: 9
01/30/2023 10:39:54 AM  [*] Mon Jan 30 10:39:54 2023: Train Epoch: 9 [  0  /41107 (0 %)]	Loss: 168.656372 | Elapsed: 0.14s
01/30/2023 10:40:06 AM  [*] Mon Jan 30 10:40:06 2023: Train Epoch: 9 [6400 /41107 (16%)]	Loss: 200.420334 | Elapsed: 12.45s
01/30/2023 10:40:18 AM  [*] Mon Jan 30 10:40:18 2023: Train Epoch: 9 [12800/41107 (31%)]	Loss: 171.755646 | Elapsed: 12.30s
01/30/2023 10:40:31 AM  [*] Mon Jan 30 10:40:31 2023: Train Epoch: 9 [19200/41107 (47%)]	Loss: 160.388519 | Elapsed: 12.39s
01/30/2023 10:40:43 AM  [*] Mon Jan 30 10:40:43 2023: Train Epoch: 9 [25600/41107 (62%)]	Loss: 184.026474 | Elapsed: 12.40s
01/30/2023 10:40:56 AM  [*] Mon Jan 30 10:40:56 2023: Train Epoch: 9 [32000/41107 (78%)]	Loss: 197.501633 | Elapsed: 12.36s
01/30/2023 10:41:08 AM  [*] Mon Jan 30 10:41:08 2023: Train Epoch: 9 [38400/41107 (93%)]	Loss: 163.433929 | Elapsed: 12.32s
01/30/2023 10:41:14 AM  [*] Mon Jan 30 10:41:14 2023:    9    | Tr.loss: 174.422618 | Elapsed:   80.65  s
01/30/2023 10:41:14 AM  [*] Started epoch: 10
01/30/2023 10:41:14 AM  [*] Mon Jan 30 10:41:14 2023: Train Epoch: 10 [  0  /41107 (0 %)]	Loss: 166.214569 | Elapsed: 0.13s
01/30/2023 10:41:27 AM  [*] Mon Jan 30 10:41:27 2023: Train Epoch: 10 [6400 /41107 (16%)]	Loss: 150.228516 | Elapsed: 12.33s
01/30/2023 10:41:39 AM  [*] Mon Jan 30 10:41:39 2023: Train Epoch: 10 [12800/41107 (31%)]	Loss: 174.946167 | Elapsed: 12.32s
01/30/2023 10:41:51 AM  [*] Mon Jan 30 10:41:51 2023: Train Epoch: 10 [19200/41107 (47%)]	Loss: 182.179962 | Elapsed: 12.34s
01/30/2023 10:42:04 AM  [*] Mon Jan 30 10:42:04 2023: Train Epoch: 10 [25600/41107 (62%)]	Loss: 173.406433 | Elapsed: 12.36s
01/30/2023 10:42:16 AM  [*] Mon Jan 30 10:42:16 2023: Train Epoch: 10 [32000/41107 (78%)]	Loss: 188.628555 | Elapsed: 12.30s
01/30/2023 10:42:28 AM  [*] Mon Jan 30 10:42:28 2023: Train Epoch: 10 [38400/41107 (93%)]	Loss: 176.523270 | Elapsed: 12.42s
01/30/2023 10:42:35 AM  [*] Mon Jan 30 10:42:35 2023:   10    | Tr.loss: 173.833154 | Elapsed:   80.60  s
01/30/2023 10:42:35 AM [!] Mon Jan 30 10:42:35 2023: Dumped results:
                model     : 1675071755-model.torch
		train time: 1675071755-trainTime.npy
		train losses: 1675071755-trainLosses.npy
		train AUC: 1675071755-auc.npy
01/30/2023 10:42:37 AM  [!] Training pretrained model on downstream task...
01/30/2023 10:42:37 AM  [*] Started epoch: 1
01/30/2023 10:42:37 AM  [*] Mon Jan 30 10:42:37 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 2.834039 | Elapsed: 0.33s | FPR 0.0003 -> TPR 0.1026 & F1 0.1860 | AUC 0.4579
01/30/2023 10:42:46 AM  [*] Mon Jan 30 10:42:46 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.503928 | Elapsed: 9.17s | FPR 0.0003 -> TPR 0.1867 & F1 0.3146 | AUC 0.6800
01/30/2023 10:42:48 AM  [*] Mon Jan 30 10:42:48 2023:    1    | Tr.loss: 0.597369 | Elapsed:   11.29  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7754
01/30/2023 10:42:48 AM  [*] Started epoch: 2
01/30/2023 10:42:48 AM  [*] Mon Jan 30 10:42:48 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.295000 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.8269 & F1 0.9053 | AUC 0.9311
01/30/2023 10:42:57 AM  [*] Mon Jan 30 10:42:57 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.444103 | Elapsed: 9.11s | FPR 0.0003 -> TPR 0.1692 & F1 0.2895 | AUC 0.8123
01/30/2023 10:42:59 AM  [*] Mon Jan 30 10:42:59 2023:    2    | Tr.loss: 0.400615 | Elapsed:   11.00  s | FPR 0.0003 -> TPR: 0.09 & F1: 0.17 | AUC: 0.8645
01/30/2023 10:42:59 AM  [*] Started epoch: 3
01/30/2023 10:42:59 AM  [*] Mon Jan 30 10:42:59 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.322087 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.5319 & F1 0.6944 | AUC 0.8942
01/30/2023 10:43:08 AM  [*] Mon Jan 30 10:43:08 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.367173 | Elapsed: 9.48s | FPR 0.0003 -> TPR 0.6061 & F1 0.7547 | AUC 0.9127
01/30/2023 10:43:10 AM  [*] Mon Jan 30 10:43:10 2023:    3    | Tr.loss: 0.353176 | Elapsed:   11.53  s | FPR 0.0003 -> TPR: 0.23 & F1: 0.37 | AUC: 0.9003
01/30/2023 10:43:11 AM [!] Mon Jan 30 10:43:11 2023: Dumped results:
                model     : 1675071790-model.torch
		train time: 1675071790-trainTime.npy
		train losses: 1675071790-trainLosses.npy
		train AUC: 1675071790-auc.npy
		train F1s : 1675071790-trainF1s.npy
		train TPRs: 1675071790-trainTPRs.npy
01/30/2023 10:43:11 AM  [!] Training non_pretrained model on downstream task...
01/30/2023 10:43:12 AM  [*] Started epoch: 1
01/30/2023 10:43:12 AM  [*] Mon Jan 30 10:43:12 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 2.365977 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.0714 & F1 0.1333 | AUC 0.4827
01/30/2023 10:43:18 AM  [*] Mon Jan 30 10:43:18 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.445064 | Elapsed: 6.49s | FPR 0.0003 -> TPR 0.5645 & F1 0.7216 | AUC 0.8595
01/30/2023 10:43:20 AM  [*] Mon Jan 30 10:43:20 2023:    1    | Tr.loss: 0.589289 | Elapsed:   8.01   s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7471
01/30/2023 10:43:20 AM  [*] Started epoch: 2
01/30/2023 10:43:20 AM  [*] Mon Jan 30 10:43:20 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.362953 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.6000 & F1 0.7500 | AUC 0.8875
01/30/2023 10:43:26 AM  [*] Mon Jan 30 10:43:26 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.369743 | Elapsed: 6.47s | FPR 0.0003 -> TPR 0.6806 & F1 0.8099 | AUC 0.9226
01/30/2023 10:43:27 AM  [*] Mon Jan 30 10:43:27 2023:    2    | Tr.loss: 0.376496 | Elapsed:   7.87   s | FPR 0.0003 -> TPR: 0.05 & F1: 0.09 | AUC: 0.8859
01/30/2023 10:43:27 AM  [*] Started epoch: 3
01/30/2023 10:43:27 AM  [*] Mon Jan 30 10:43:27 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.304173 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.7250 & F1 0.8406 | AUC 0.9448
01/30/2023 10:43:34 AM  [*] Mon Jan 30 10:43:34 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.341202 | Elapsed: 6.34s | FPR 0.0003 -> TPR 0.4143 & F1 0.5859 | AUC 0.9162
01/30/2023 10:43:35 AM  [*] Mon Jan 30 10:43:35 2023:    3    | Tr.loss: 0.328381 | Elapsed:   7.74   s | FPR 0.0003 -> TPR: 0.15 & F1: 0.27 | AUC: 0.9157
01/30/2023 10:43:36 AM [!] Mon Jan 30 10:43:36 2023: Dumped results:
                model     : 1675071815-model.torch
		train time: 1675071815-trainTime.npy
		train losses: 1675071815-trainLosses.npy
		train AUC: 1675071815-auc.npy
		train F1s : 1675071815-trainF1s.npy
		train TPRs: 1675071815-trainTPRs.npy
01/30/2023 10:43:36 AM  [*] Evaluating pretrained model on test set...
01/30/2023 10:43:41 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.1460 | F1: 0.2548
01/30/2023 10:43:41 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1691 | F1: 0.2892
01/30/2023 10:43:41 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.2398 | F1: 0.3866
01/30/2023 10:43:41 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3234 | F1: 0.4878
01/30/2023 10:43:41 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3688 | F1: 0.5356
01/30/2023 10:43:41 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4674 | F1: 0.6262
01/30/2023 10:43:41 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.6137 | F1: 0.7225
01/30/2023 10:43:41 AM  [*] Evaluating non_pretrained model on test set...
01/30/2023 10:43:46 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0309 | F1: 0.0600
01/30/2023 10:43:46 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1569 | F1: 0.2711
01/30/2023 10:43:46 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.1852 | F1: 0.3122
01/30/2023 10:43:46 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.2276 | F1: 0.3700
01/30/2023 10:43:46 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3110 | F1: 0.4713
01/30/2023 10:43:46 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4259 | F1: 0.5869
01/30/2023 10:43:46 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.5799 | F1: 0.6966
01/30/2023 10:43:46 AM  [!] Running pre-training split 3/3
01/30/2023 10:43:48 AM  [!] Pre-training model...
01/30/2023 10:43:48 AM  [*] Masking sequences...
01/30/2023 10:44:03 AM  [*] Started epoch: 1
01/30/2023 10:44:03 AM  [*] Mon Jan 30 10:44:03 2023: Train Epoch: 1 [  0  /41107 (0 %)]	Loss: 383.234039 | Elapsed: 0.31s
01/30/2023 10:44:16 AM  [*] Mon Jan 30 10:44:16 2023: Train Epoch: 1 [6400 /41107 (16%)]	Loss: 242.082901 | Elapsed: 12.46s
01/30/2023 10:44:28 AM  [*] Mon Jan 30 10:44:28 2023: Train Epoch: 1 [12800/41107 (31%)]	Loss: 214.375839 | Elapsed: 12.49s
01/30/2023 10:44:41 AM  [*] Mon Jan 30 10:44:41 2023: Train Epoch: 1 [19200/41107 (47%)]	Loss: 212.986359 | Elapsed: 12.64s
01/30/2023 10:44:53 AM  [*] Mon Jan 30 10:44:53 2023: Train Epoch: 1 [25600/41107 (62%)]	Loss: 188.665680 | Elapsed: 12.64s
01/30/2023 10:45:06 AM  [*] Mon Jan 30 10:45:06 2023: Train Epoch: 1 [32000/41107 (78%)]	Loss: 200.824890 | Elapsed: 12.74s
01/30/2023 10:45:19 AM  [*] Mon Jan 30 10:45:19 2023: Train Epoch: 1 [38400/41107 (93%)]	Loss: 201.974487 | Elapsed: 12.51s
01/30/2023 10:45:25 AM  [*] Mon Jan 30 10:45:25 2023:    1    | Tr.loss: 214.779642 | Elapsed:   82.44  s
01/30/2023 10:45:25 AM  [*] Started epoch: 2
01/30/2023 10:45:25 AM  [*] Mon Jan 30 10:45:25 2023: Train Epoch: 2 [  0  /41107 (0 %)]	Loss: 201.335663 | Elapsed: 0.13s
01/30/2023 10:45:38 AM  [*] Mon Jan 30 10:45:38 2023: Train Epoch: 2 [6400 /41107 (16%)]	Loss: 199.756546 | Elapsed: 12.56s
01/30/2023 10:45:50 AM  [*] Mon Jan 30 10:45:50 2023: Train Epoch: 2 [12800/41107 (31%)]	Loss: 193.498474 | Elapsed: 12.50s
01/30/2023 10:46:03 AM  [*] Mon Jan 30 10:46:03 2023: Train Epoch: 2 [19200/41107 (47%)]	Loss: 191.263428 | Elapsed: 12.54s
01/30/2023 10:46:15 AM  [*] Mon Jan 30 10:46:15 2023: Train Epoch: 2 [25600/41107 (62%)]	Loss: 185.962463 | Elapsed: 12.55s
01/30/2023 10:46:28 AM  [*] Mon Jan 30 10:46:28 2023: Train Epoch: 2 [32000/41107 (78%)]	Loss: 198.783173 | Elapsed: 12.67s
01/30/2023 10:46:41 AM  [*] Mon Jan 30 10:46:41 2023: Train Epoch: 2 [38400/41107 (93%)]	Loss: 188.219666 | Elapsed: 12.59s
01/30/2023 10:46:47 AM  [*] Mon Jan 30 10:46:47 2023:    2    | Tr.loss: 192.046009 | Elapsed:   82.01  s
01/30/2023 10:46:47 AM  [*] Started epoch: 3
01/30/2023 10:46:47 AM  [*] Mon Jan 30 10:46:47 2023: Train Epoch: 3 [  0  /41107 (0 %)]	Loss: 192.143829 | Elapsed: 0.14s
01/30/2023 10:47:00 AM  [*] Mon Jan 30 10:47:00 2023: Train Epoch: 3 [6400 /41107 (16%)]	Loss: 178.822601 | Elapsed: 12.60s
01/30/2023 10:47:13 AM  [*] Mon Jan 30 10:47:13 2023: Train Epoch: 3 [12800/41107 (31%)]	Loss: 183.138260 | Elapsed: 12.58s
01/30/2023 10:47:25 AM  [*] Mon Jan 30 10:47:25 2023: Train Epoch: 3 [19200/41107 (47%)]	Loss: 192.137573 | Elapsed: 12.56s
01/30/2023 10:47:38 AM  [*] Mon Jan 30 10:47:38 2023: Train Epoch: 3 [25600/41107 (62%)]	Loss: 179.884094 | Elapsed: 12.66s
01/30/2023 10:47:50 AM  [*] Mon Jan 30 10:47:50 2023: Train Epoch: 3 [32000/41107 (78%)]	Loss: 199.300064 | Elapsed: 12.49s
01/30/2023 10:48:03 AM  [*] Mon Jan 30 10:48:03 2023: Train Epoch: 3 [38400/41107 (93%)]	Loss: 182.841141 | Elapsed: 12.56s
01/30/2023 10:48:09 AM  [*] Mon Jan 30 10:48:09 2023:    3    | Tr.loss: 185.690718 | Elapsed:   82.04  s
01/30/2023 10:48:09 AM  [*] Started epoch: 4
01/30/2023 10:48:09 AM  [*] Mon Jan 30 10:48:09 2023: Train Epoch: 4 [  0  /41107 (0 %)]	Loss: 163.438843 | Elapsed: 0.13s
01/30/2023 10:48:22 AM  [*] Mon Jan 30 10:48:22 2023: Train Epoch: 4 [6400 /41107 (16%)]	Loss: 175.651855 | Elapsed: 12.63s
01/30/2023 10:48:35 AM  [*] Mon Jan 30 10:48:35 2023: Train Epoch: 4 [12800/41107 (31%)]	Loss: 183.728546 | Elapsed: 12.55s
01/30/2023 10:48:47 AM  [*] Mon Jan 30 10:48:47 2023: Train Epoch: 4 [19200/41107 (47%)]	Loss: 173.917847 | Elapsed: 12.60s
01/30/2023 10:49:00 AM  [*] Mon Jan 30 10:49:00 2023: Train Epoch: 4 [25600/41107 (62%)]	Loss: 149.834381 | Elapsed: 12.49s
01/30/2023 10:49:12 AM  [*] Mon Jan 30 10:49:12 2023: Train Epoch: 4 [32000/41107 (78%)]	Loss: 173.896790 | Elapsed: 12.57s
01/30/2023 10:49:25 AM  [*] Mon Jan 30 10:49:25 2023: Train Epoch: 4 [38400/41107 (93%)]	Loss: 174.548340 | Elapsed: 12.55s
01/30/2023 10:49:31 AM  [*] Mon Jan 30 10:49:31 2023:    4    | Tr.loss: 182.695517 | Elapsed:   82.00  s
01/30/2023 10:49:31 AM  [*] Started epoch: 5
01/30/2023 10:49:31 AM  [*] Mon Jan 30 10:49:31 2023: Train Epoch: 5 [  0  /41107 (0 %)]	Loss: 178.144821 | Elapsed: 0.13s
01/30/2023 10:49:44 AM  [*] Mon Jan 30 10:49:44 2023: Train Epoch: 5 [6400 /41107 (16%)]	Loss: 189.821793 | Elapsed: 12.65s
01/30/2023 10:49:57 AM  [*] Mon Jan 30 10:49:57 2023: Train Epoch: 5 [12800/41107 (31%)]	Loss: 184.792664 | Elapsed: 12.53s
01/30/2023 10:50:09 AM  [*] Mon Jan 30 10:50:09 2023: Train Epoch: 5 [19200/41107 (47%)]	Loss: 186.897949 | Elapsed: 12.42s
01/30/2023 10:50:22 AM  [*] Mon Jan 30 10:50:22 2023: Train Epoch: 5 [25600/41107 (62%)]	Loss: 171.858154 | Elapsed: 12.53s
01/30/2023 10:50:34 AM  [*] Mon Jan 30 10:50:34 2023: Train Epoch: 5 [32000/41107 (78%)]	Loss: 179.613312 | Elapsed: 12.56s
01/30/2023 10:50:47 AM  [*] Mon Jan 30 10:50:47 2023: Train Epoch: 5 [38400/41107 (93%)]	Loss: 167.012497 | Elapsed: 12.54s
01/30/2023 10:50:53 AM  [*] Mon Jan 30 10:50:53 2023:    5    | Tr.loss: 180.576319 | Elapsed:   81.88  s
01/30/2023 10:50:53 AM  [*] Started epoch: 6
01/30/2023 10:50:53 AM  [*] Mon Jan 30 10:50:53 2023: Train Epoch: 6 [  0  /41107 (0 %)]	Loss: 176.024078 | Elapsed: 0.13s
01/30/2023 10:51:06 AM  [*] Mon Jan 30 10:51:06 2023: Train Epoch: 6 [6400 /41107 (16%)]	Loss: 196.611267 | Elapsed: 12.61s
01/30/2023 10:51:18 AM  [*] Mon Jan 30 10:51:18 2023: Train Epoch: 6 [12800/41107 (31%)]	Loss: 172.402344 | Elapsed: 12.57s
01/30/2023 10:51:31 AM  [*] Mon Jan 30 10:51:31 2023: Train Epoch: 6 [19200/41107 (47%)]	Loss: 201.160248 | Elapsed: 12.63s
01/30/2023 10:51:44 AM  [*] Mon Jan 30 10:51:44 2023: Train Epoch: 6 [25600/41107 (62%)]	Loss: 184.009750 | Elapsed: 12.55s
01/30/2023 10:51:56 AM  [*] Mon Jan 30 10:51:56 2023: Train Epoch: 6 [32000/41107 (78%)]	Loss: 170.553589 | Elapsed: 12.47s
01/30/2023 10:52:09 AM  [*] Mon Jan 30 10:52:09 2023: Train Epoch: 6 [38400/41107 (93%)]	Loss: 159.612228 | Elapsed: 12.59s
01/30/2023 10:52:15 AM  [*] Mon Jan 30 10:52:15 2023:    6    | Tr.loss: 178.879908 | Elapsed:   82.09  s
01/30/2023 10:52:15 AM  [*] Started epoch: 7
01/30/2023 10:52:15 AM  [*] Mon Jan 30 10:52:15 2023: Train Epoch: 7 [  0  /41107 (0 %)]	Loss: 173.080872 | Elapsed: 0.14s
01/30/2023 10:52:28 AM  [*] Mon Jan 30 10:52:28 2023: Train Epoch: 7 [6400 /41107 (16%)]	Loss: 183.554779 | Elapsed: 12.71s
01/30/2023 10:52:41 AM  [*] Mon Jan 30 10:52:41 2023: Train Epoch: 7 [12800/41107 (31%)]	Loss: 198.723053 | Elapsed: 12.57s
01/30/2023 10:52:53 AM  [*] Mon Jan 30 10:52:53 2023: Train Epoch: 7 [19200/41107 (47%)]	Loss: 187.774536 | Elapsed: 12.45s
01/30/2023 10:53:06 AM  [*] Mon Jan 30 10:53:06 2023: Train Epoch: 7 [25600/41107 (62%)]	Loss: 167.471741 | Elapsed: 12.44s
01/30/2023 10:53:18 AM  [*] Mon Jan 30 10:53:18 2023: Train Epoch: 7 [32000/41107 (78%)]	Loss: 195.711365 | Elapsed: 12.49s
01/30/2023 10:53:31 AM  [*] Mon Jan 30 10:53:31 2023: Train Epoch: 7 [38400/41107 (93%)]	Loss: 185.785339 | Elapsed: 12.54s
01/30/2023 10:53:37 AM  [*] Mon Jan 30 10:53:37 2023:    7    | Tr.loss: 177.524668 | Elapsed:   81.77  s
01/30/2023 10:53:37 AM  [*] Started epoch: 8
01/30/2023 10:53:37 AM  [*] Mon Jan 30 10:53:37 2023: Train Epoch: 8 [  0  /41107 (0 %)]	Loss: 169.342346 | Elapsed: 0.13s
01/30/2023 10:53:50 AM  [*] Mon Jan 30 10:53:50 2023: Train Epoch: 8 [6400 /41107 (16%)]	Loss: 181.829803 | Elapsed: 12.65s
01/30/2023 10:54:02 AM  [*] Mon Jan 30 10:54:02 2023: Train Epoch: 8 [12800/41107 (31%)]	Loss: 197.468872 | Elapsed: 12.57s
01/30/2023 10:54:15 AM  [*] Mon Jan 30 10:54:15 2023: Train Epoch: 8 [19200/41107 (47%)]	Loss: 162.909103 | Elapsed: 12.46s
01/30/2023 10:54:27 AM  [*] Mon Jan 30 10:54:27 2023: Train Epoch: 8 [25600/41107 (62%)]	Loss: 185.228241 | Elapsed: 12.42s
01/30/2023 10:54:40 AM  [*] Mon Jan 30 10:54:40 2023: Train Epoch: 8 [32000/41107 (78%)]	Loss: 184.713654 | Elapsed: 12.50s
01/30/2023 10:54:52 AM  [*] Mon Jan 30 10:54:52 2023: Train Epoch: 8 [38400/41107 (93%)]	Loss: 185.736511 | Elapsed: 12.70s
01/30/2023 10:54:59 AM  [*] Mon Jan 30 10:54:59 2023:    8    | Tr.loss: 176.507399 | Elapsed:   82.05  s
01/30/2023 10:54:59 AM  [*] Started epoch: 9
01/30/2023 10:54:59 AM  [*] Mon Jan 30 10:54:59 2023: Train Epoch: 9 [  0  /41107 (0 %)]	Loss: 173.724289 | Elapsed: 0.13s
01/30/2023 10:55:12 AM  [*] Mon Jan 30 10:55:12 2023: Train Epoch: 9 [6400 /41107 (16%)]	Loss: 161.659103 | Elapsed: 12.53s
01/30/2023 10:55:24 AM  [*] Mon Jan 30 10:55:24 2023: Train Epoch: 9 [12800/41107 (31%)]	Loss: 183.434433 | Elapsed: 12.47s
01/30/2023 10:55:37 AM  [*] Mon Jan 30 10:55:37 2023: Train Epoch: 9 [19200/41107 (47%)]	Loss: 170.822449 | Elapsed: 12.53s
01/30/2023 10:55:49 AM  [*] Mon Jan 30 10:55:49 2023: Train Epoch: 9 [25600/41107 (62%)]	Loss: 181.273712 | Elapsed: 12.55s
01/30/2023 10:56:02 AM  [*] Mon Jan 30 10:56:02 2023: Train Epoch: 9 [32000/41107 (78%)]	Loss: 161.708191 | Elapsed: 12.58s
01/30/2023 10:56:14 AM  [*] Mon Jan 30 10:56:14 2023: Train Epoch: 9 [38400/41107 (93%)]	Loss: 179.303787 | Elapsed: 12.57s
01/30/2023 10:56:21 AM  [*] Mon Jan 30 10:56:21 2023:    9    | Tr.loss: 175.564966 | Elapsed:   82.18  s
01/30/2023 10:56:21 AM  [*] Started epoch: 10
01/30/2023 10:56:21 AM  [*] Mon Jan 30 10:56:21 2023: Train Epoch: 10 [  0  /41107 (0 %)]	Loss: 163.191559 | Elapsed: 0.14s
01/30/2023 10:56:34 AM  [*] Mon Jan 30 10:56:34 2023: Train Epoch: 10 [6400 /41107 (16%)]	Loss: 184.029419 | Elapsed: 12.90s
01/30/2023 10:56:47 AM  [*] Mon Jan 30 10:56:47 2023: Train Epoch: 10 [12800/41107 (31%)]	Loss: 161.905090 | Elapsed: 12.59s
01/30/2023 10:56:59 AM  [*] Mon Jan 30 10:56:59 2023: Train Epoch: 10 [19200/41107 (47%)]	Loss: 173.339630 | Elapsed: 12.61s
01/30/2023 10:57:12 AM  [*] Mon Jan 30 10:57:12 2023: Train Epoch: 10 [25600/41107 (62%)]	Loss: 183.025177 | Elapsed: 12.50s
01/30/2023 10:57:24 AM  [*] Mon Jan 30 10:57:24 2023: Train Epoch: 10 [32000/41107 (78%)]	Loss: 182.824524 | Elapsed: 12.46s
01/30/2023 10:57:37 AM  [*] Mon Jan 30 10:57:37 2023: Train Epoch: 10 [38400/41107 (93%)]	Loss: 180.637573 | Elapsed: 12.63s
01/30/2023 10:57:44 AM  [*] Mon Jan 30 10:57:44 2023:   10    | Tr.loss: 174.817495 | Elapsed:   82.28  s
01/30/2023 10:57:44 AM [!] Mon Jan 30 10:57:44 2023: Dumped results:
                model     : 1675072664-model.torch
		train time: 1675072664-trainTime.npy
		train losses: 1675072664-trainLosses.npy
		train AUC: 1675072664-auc.npy
01/30/2023 10:57:45 AM  [!] Training pretrained model on downstream task...
01/30/2023 10:57:45 AM  [*] Started epoch: 1
01/30/2023 10:57:46 AM  [*] Mon Jan 30 10:57:46 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 1.350189 | Elapsed: 0.19s | FPR 0.0003 -> TPR 0.2326 & F1 0.3774 | AUC 0.6346
01/30/2023 10:57:55 AM  [*] Mon Jan 30 10:57:55 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.464684 | Elapsed: 9.22s | FPR 0.0003 -> TPR 0.2540 & F1 0.4051 | AUC 0.8417
01/30/2023 10:57:57 AM  [*] Mon Jan 30 10:57:57 2023:    1    | Tr.loss: 0.534385 | Elapsed:   11.26  s | FPR 0.0003 -> TPR: 0.01 & F1: 0.01 | AUC: 0.7851
01/30/2023 10:57:57 AM  [*] Started epoch: 2
01/30/2023 10:57:57 AM  [*] Mon Jan 30 10:57:57 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.408143 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.3404 & F1 0.5079 | AUC 0.8204
01/30/2023 10:58:06 AM  [*] Mon Jan 30 10:58:06 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.482806 | Elapsed: 9.16s | FPR 0.0003 -> TPR 0.2424 & F1 0.3902 | AUC 0.8329
01/30/2023 10:58:08 AM  [*] Mon Jan 30 10:58:08 2023:    2    | Tr.loss: 0.387263 | Elapsed:   11.08  s | FPR 0.0003 -> TPR: 0.12 & F1: 0.21 | AUC: 0.8743
01/30/2023 10:58:08 AM  [*] Started epoch: 3
01/30/2023 10:58:08 AM  [*] Mon Jan 30 10:58:08 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.317918 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.5000 & F1 0.6667 | AUC 0.9140
01/30/2023 10:58:17 AM  [*] Mon Jan 30 10:58:17 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.277509 | Elapsed: 9.13s | FPR 0.0003 -> TPR 0.6119 & F1 0.7593 | AUC 0.9607
01/30/2023 10:58:19 AM  [*] Mon Jan 30 10:58:19 2023:    3    | Tr.loss: 0.318025 | Elapsed:   11.08  s | FPR 0.0003 -> TPR: 0.26 & F1: 0.41 | AUC: 0.9240
01/30/2023 10:58:19 AM [!] Mon Jan 30 10:58:19 2023: Dumped results:
                model     : 1675072699-model.torch
		train time: 1675072699-trainTime.npy
		train losses: 1675072699-trainLosses.npy
		train AUC: 1675072699-auc.npy
		train F1s : 1675072699-trainF1s.npy
		train TPRs: 1675072699-trainTPRs.npy
01/30/2023 10:58:19 AM  [!] Training non_pretrained model on downstream task...
01/30/2023 10:58:20 AM  [*] Started epoch: 1
01/30/2023 10:58:20 AM  [*] Mon Jan 30 10:58:20 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 2.524632 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.1020 & F1 0.1852 | AUC 0.5864
01/30/2023 10:58:26 AM  [*] Mon Jan 30 10:58:26 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.415572 | Elapsed: 6.34s | FPR 0.0003 -> TPR 0.2794 & F1 0.4368 | AUC 0.8038
01/30/2023 10:58:27 AM  [*] Mon Jan 30 10:58:27 2023:    1    | Tr.loss: 0.671392 | Elapsed:   7.78   s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7097
01/30/2023 10:58:27 AM  [*] Started epoch: 2
01/30/2023 10:58:28 AM  [*] Mon Jan 30 10:58:28 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.382024 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.4222 & F1 0.5938 | AUC 0.8784
01/30/2023 10:58:34 AM  [*] Mon Jan 30 10:58:34 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.320486 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.3478 & F1 0.5161 | AUC 0.9009
01/30/2023 10:58:35 AM  [*] Mon Jan 30 10:58:35 2023:    2    | Tr.loss: 0.400968 | Elapsed:   7.63   s | FPR 0.0003 -> TPR: 0.10 & F1: 0.18 | AUC: 0.8722
01/30/2023 10:58:35 AM  [*] Started epoch: 3
01/30/2023 10:58:35 AM  [*] Mon Jan 30 10:58:35 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.300083 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.3478 & F1 0.5161 | AUC 0.9287
01/30/2023 10:58:41 AM  [*] Mon Jan 30 10:58:41 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.453239 | Elapsed: 6.27s | FPR 0.0003 -> TPR 0.4483 & F1 0.6190 | AUC 0.8859
01/30/2023 10:58:43 AM  [*] Mon Jan 30 10:58:43 2023:    3    | Tr.loss: 0.340831 | Elapsed:   7.63   s | FPR 0.0003 -> TPR: 0.25 & F1: 0.41 | AUC: 0.9107
01/30/2023 10:58:43 AM [!] Mon Jan 30 10:58:43 2023: Dumped results:
                model     : 1675072723-model.torch
		train time: 1675072723-trainTime.npy
		train losses: 1675072723-trainLosses.npy
		train AUC: 1675072723-auc.npy
		train F1s : 1675072723-trainF1s.npy
		train TPRs: 1675072723-trainTPRs.npy
01/30/2023 10:58:43 AM  [*] Evaluating pretrained model on test set...
01/30/2023 10:58:48 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.1038 | F1: 0.1881
01/30/2023 10:58:48 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1785 | F1: 0.3028
01/30/2023 10:58:48 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.2125 | F1: 0.3502
01/30/2023 10:58:48 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3194 | F1: 0.4832
01/30/2023 10:58:48 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.4042 | F1: 0.5723
01/30/2023 10:58:48 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4588 | F1: 0.6182
01/30/2023 10:58:48 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.5652 | F1: 0.6850
01/30/2023 10:58:48 AM  [*] Evaluating non_pretrained model on test set...
01/30/2023 10:58:53 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0232 | F1: 0.0453
01/30/2023 10:58:53 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.0908 | F1: 0.1665
01/30/2023 10:58:53 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.1729 | F1: 0.2946
01/30/2023 10:58:53 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.2379 | F1: 0.3836
01/30/2023 10:58:53 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3437 | F1: 0.5084
01/30/2023 10:58:53 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4090 | F1: 0.5702
01/30/2023 10:58:53 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.5664 | F1: 0.6859
01/30/2023 10:58:53 AM  [!] Finished pre-training evaluation over 3 splits! Saved metrics to:
	C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\downsample_tests\downsample_U_0.6_1675069938/metrics_MaskedLanguageModel_nSplits_3_limit_None.json
01/30/2023 10:58:53 AM  [!] Starting uSize downsample 0.7 evaluation!
01/30/2023 10:58:53 AM  [!] Starting Masked Language Model evaluation over 3 splits!
01/30/2023 10:58:53 AM  [!] Loaded data and vocab. X train size: (76126, 512), X test size: (17407, 512), vocab size: 50002
01/30/2023 10:58:53 AM  [!] Initiating Self-Supervised Learning Pretraining
     Language Modeling MaskedLanguageModel
     Model TransformerEncoderLM with config:
	{'vocabSize': 50002, 'maxLen': 512, 'dModel': 64, 'nHeads': 8, 'dHidden': 256, 'nLayers': 2, 'numClasses': 1, 'hiddenNeurons': [64], 'dropout': 0.3}

01/30/2023 10:58:53 AM  [!] Running pre-training split 1/3
01/30/2023 10:58:56 AM  [!] Pre-training model...
01/30/2023 10:58:56 AM  [*] Masking sequences...
01/30/2023 10:59:12 AM  [*] Started epoch: 1
01/30/2023 10:59:12 AM  [*] Mon Jan 30 10:59:12 2023: Train Epoch: 1 [  0  /47959 (0 %)]	Loss: 378.467224 | Elapsed: 0.37s
01/30/2023 10:59:25 AM  [*] Mon Jan 30 10:59:25 2023: Train Epoch: 1 [6400 /47959 (13%)]	Loss: 230.771973 | Elapsed: 12.43s
01/30/2023 10:59:37 AM  [*] Mon Jan 30 10:59:37 2023: Train Epoch: 1 [12800/47959 (27%)]	Loss: 205.996613 | Elapsed: 12.44s
01/30/2023 10:59:50 AM  [*] Mon Jan 30 10:59:50 2023: Train Epoch: 1 [19200/47959 (40%)]	Loss: 204.318146 | Elapsed: 12.49s
01/30/2023 11:00:02 AM  [*] Mon Jan 30 11:00:02 2023: Train Epoch: 1 [25600/47959 (53%)]	Loss: 231.823761 | Elapsed: 12.63s
01/30/2023 11:00:15 AM  [*] Mon Jan 30 11:00:15 2023: Train Epoch: 1 [32000/47959 (67%)]	Loss: 195.721008 | Elapsed: 12.59s
01/30/2023 11:00:28 AM  [*] Mon Jan 30 11:00:28 2023: Train Epoch: 1 [38400/47959 (80%)]	Loss: 211.584976 | Elapsed: 13.07s
01/30/2023 11:00:41 AM  [*] Mon Jan 30 11:00:41 2023: Train Epoch: 1 [44800/47959 (93%)]	Loss: 172.425568 | Elapsed: 12.89s
01/30/2023 11:00:48 AM  [*] Mon Jan 30 11:00:48 2023:    1    | Tr.loss: 213.736417 | Elapsed:   96.55  s
01/30/2023 11:00:48 AM  [*] Started epoch: 2
01/30/2023 11:00:49 AM  [*] Mon Jan 30 11:00:49 2023: Train Epoch: 2 [  0  /47959 (0 %)]	Loss: 192.777328 | Elapsed: 0.13s
01/30/2023 11:01:01 AM  [*] Mon Jan 30 11:01:01 2023: Train Epoch: 2 [6400 /47959 (13%)]	Loss: 208.761032 | Elapsed: 12.72s
01/30/2023 11:01:14 AM  [*] Mon Jan 30 11:01:14 2023: Train Epoch: 2 [12800/47959 (27%)]	Loss: 197.027908 | Elapsed: 12.68s
01/30/2023 11:01:27 AM  [*] Mon Jan 30 11:01:27 2023: Train Epoch: 2 [19200/47959 (40%)]	Loss: 172.649460 | Elapsed: 12.55s
01/30/2023 11:01:39 AM  [*] Mon Jan 30 11:01:39 2023: Train Epoch: 2 [25600/47959 (53%)]	Loss: 200.214249 | Elapsed: 12.63s
01/30/2023 11:01:52 AM  [*] Mon Jan 30 11:01:52 2023: Train Epoch: 2 [32000/47959 (67%)]	Loss: 209.195679 | Elapsed: 12.51s
01/30/2023 11:02:04 AM  [*] Mon Jan 30 11:02:04 2023: Train Epoch: 2 [38400/47959 (80%)]	Loss: 185.152771 | Elapsed: 12.71s
01/30/2023 11:02:17 AM  [*] Mon Jan 30 11:02:17 2023: Train Epoch: 2 [44800/47959 (93%)]	Loss: 205.203445 | Elapsed: 12.56s
01/30/2023 11:02:25 AM  [*] Mon Jan 30 11:02:25 2023:    2    | Tr.loss: 192.539033 | Elapsed:   96.03  s
01/30/2023 11:02:25 AM  [*] Started epoch: 3
01/30/2023 11:02:25 AM  [*] Mon Jan 30 11:02:25 2023: Train Epoch: 3 [  0  /47959 (0 %)]	Loss: 180.687408 | Elapsed: 0.13s
01/30/2023 11:02:37 AM  [*] Mon Jan 30 11:02:37 2023: Train Epoch: 3 [6400 /47959 (13%)]	Loss: 187.932190 | Elapsed: 12.66s
01/30/2023 11:02:50 AM  [*] Mon Jan 30 11:02:50 2023: Train Epoch: 3 [12800/47959 (27%)]	Loss: 179.185547 | Elapsed: 12.61s
01/30/2023 11:03:03 AM  [*] Mon Jan 30 11:03:03 2023: Train Epoch: 3 [19200/47959 (40%)]	Loss: 182.827972 | Elapsed: 12.70s
01/30/2023 11:03:15 AM  [*] Mon Jan 30 11:03:15 2023: Train Epoch: 3 [25600/47959 (53%)]	Loss: 180.642914 | Elapsed: 12.52s
01/30/2023 11:03:28 AM  [*] Mon Jan 30 11:03:28 2023: Train Epoch: 3 [32000/47959 (67%)]	Loss: 185.754242 | Elapsed: 12.51s
01/30/2023 11:03:40 AM  [*] Mon Jan 30 11:03:40 2023: Train Epoch: 3 [38400/47959 (80%)]	Loss: 189.861023 | Elapsed: 12.56s
01/30/2023 11:03:53 AM  [*] Mon Jan 30 11:03:53 2023: Train Epoch: 3 [44800/47959 (93%)]	Loss: 173.345200 | Elapsed: 12.49s
01/30/2023 11:04:00 AM  [*] Mon Jan 30 11:04:00 2023:    3    | Tr.loss: 186.347953 | Elapsed:   95.84  s
01/30/2023 11:04:00 AM  [*] Started epoch: 4
01/30/2023 11:04:00 AM  [*] Mon Jan 30 11:04:00 2023: Train Epoch: 4 [  0  /47959 (0 %)]	Loss: 193.702271 | Elapsed: 0.14s
01/30/2023 11:04:13 AM  [*] Mon Jan 30 11:04:13 2023: Train Epoch: 4 [6400 /47959 (13%)]	Loss: 197.326447 | Elapsed: 12.71s
01/30/2023 11:04:26 AM  [*] Mon Jan 30 11:04:26 2023: Train Epoch: 4 [12800/47959 (27%)]	Loss: 180.216339 | Elapsed: 12.73s
01/30/2023 11:04:38 AM  [*] Mon Jan 30 11:04:38 2023: Train Epoch: 4 [19200/47959 (40%)]	Loss: 193.799896 | Elapsed: 12.54s
01/30/2023 11:04:51 AM  [*] Mon Jan 30 11:04:51 2023: Train Epoch: 4 [25600/47959 (53%)]	Loss: 171.025513 | Elapsed: 12.53s
01/30/2023 11:05:04 AM  [*] Mon Jan 30 11:05:04 2023: Train Epoch: 4 [32000/47959 (67%)]	Loss: 177.583694 | Elapsed: 12.57s
01/30/2023 11:05:16 AM  [*] Mon Jan 30 11:05:16 2023: Train Epoch: 4 [38400/47959 (80%)]	Loss: 193.777649 | Elapsed: 12.57s
01/30/2023 11:05:29 AM  [*] Mon Jan 30 11:05:29 2023: Train Epoch: 4 [44800/47959 (93%)]	Loss: 176.816818 | Elapsed: 12.60s
01/30/2023 11:05:36 AM  [*] Mon Jan 30 11:05:36 2023:    4    | Tr.loss: 183.212961 | Elapsed:   96.10  s
01/30/2023 11:05:36 AM  [*] Started epoch: 5
01/30/2023 11:05:37 AM  [*] Mon Jan 30 11:05:37 2023: Train Epoch: 5 [  0  /47959 (0 %)]	Loss: 185.004944 | Elapsed: 0.14s
01/30/2023 11:05:49 AM  [*] Mon Jan 30 11:05:49 2023: Train Epoch: 5 [6400 /47959 (13%)]	Loss: 202.840805 | Elapsed: 12.63s
01/30/2023 11:06:02 AM  [*] Mon Jan 30 11:06:02 2023: Train Epoch: 5 [12800/47959 (27%)]	Loss: 177.521393 | Elapsed: 12.65s
01/30/2023 11:06:14 AM  [*] Mon Jan 30 11:06:14 2023: Train Epoch: 5 [19200/47959 (40%)]	Loss: 173.949341 | Elapsed: 12.59s
01/30/2023 11:06:27 AM  [*] Mon Jan 30 11:06:27 2023: Train Epoch: 5 [25600/47959 (53%)]	Loss: 194.030579 | Elapsed: 12.56s
01/30/2023 11:06:39 AM  [*] Mon Jan 30 11:06:39 2023: Train Epoch: 5 [32000/47959 (67%)]	Loss: 194.527283 | Elapsed: 12.46s
01/30/2023 11:06:52 AM  [*] Mon Jan 30 11:06:52 2023: Train Epoch: 5 [38400/47959 (80%)]	Loss: 176.916168 | Elapsed: 12.65s
01/30/2023 11:07:05 AM  [*] Mon Jan 30 11:07:05 2023: Train Epoch: 5 [44800/47959 (93%)]	Loss: 193.914124 | Elapsed: 12.57s
01/30/2023 11:07:12 AM  [*] Mon Jan 30 11:07:12 2023:    5    | Tr.loss: 181.190729 | Elapsed:   95.81  s
01/30/2023 11:07:12 AM  [*] Started epoch: 6
01/30/2023 11:07:12 AM  [*] Mon Jan 30 11:07:12 2023: Train Epoch: 6 [  0  /47959 (0 %)]	Loss: 179.209595 | Elapsed: 0.14s
01/30/2023 11:07:25 AM  [*] Mon Jan 30 11:07:25 2023: Train Epoch: 6 [6400 /47959 (13%)]	Loss: 178.093475 | Elapsed: 12.64s
01/30/2023 11:07:38 AM  [*] Mon Jan 30 11:07:38 2023: Train Epoch: 6 [12800/47959 (27%)]	Loss: 195.099289 | Elapsed: 12.55s
01/30/2023 11:07:50 AM  [*] Mon Jan 30 11:07:50 2023: Train Epoch: 6 [19200/47959 (40%)]	Loss: 187.395782 | Elapsed: 12.53s
01/30/2023 11:08:03 AM  [*] Mon Jan 30 11:08:03 2023: Train Epoch: 6 [25600/47959 (53%)]	Loss: 175.746445 | Elapsed: 12.61s
01/30/2023 11:08:15 AM  [*] Mon Jan 30 11:08:15 2023: Train Epoch: 6 [32000/47959 (67%)]	Loss: 181.982056 | Elapsed: 12.59s
01/30/2023 11:08:28 AM  [*] Mon Jan 30 11:08:28 2023: Train Epoch: 6 [38400/47959 (80%)]	Loss: 217.695221 | Elapsed: 12.66s
01/30/2023 11:08:41 AM  [*] Mon Jan 30 11:08:41 2023: Train Epoch: 6 [44800/47959 (93%)]	Loss: 199.325272 | Elapsed: 12.63s
01/30/2023 11:08:48 AM  [*] Mon Jan 30 11:08:48 2023:    6    | Tr.loss: 179.844785 | Elapsed:   95.88  s
01/30/2023 11:08:48 AM  [*] Started epoch: 7
01/30/2023 11:08:48 AM  [*] Mon Jan 30 11:08:48 2023: Train Epoch: 7 [  0  /47959 (0 %)]	Loss: 181.323715 | Elapsed: 0.13s
01/30/2023 11:09:01 AM  [*] Mon Jan 30 11:09:01 2023: Train Epoch: 7 [6400 /47959 (13%)]	Loss: 180.015869 | Elapsed: 12.58s
01/30/2023 11:09:13 AM  [*] Mon Jan 30 11:09:13 2023: Train Epoch: 7 [12800/47959 (27%)]	Loss: 180.146271 | Elapsed: 12.57s
01/30/2023 11:09:26 AM  [*] Mon Jan 30 11:09:26 2023: Train Epoch: 7 [19200/47959 (40%)]	Loss: 192.108856 | Elapsed: 12.59s
01/30/2023 11:09:39 AM  [*] Mon Jan 30 11:09:39 2023: Train Epoch: 7 [25600/47959 (53%)]	Loss: 176.061340 | Elapsed: 12.62s
01/30/2023 11:09:51 AM  [*] Mon Jan 30 11:09:51 2023: Train Epoch: 7 [32000/47959 (67%)]	Loss: 162.315063 | Elapsed: 12.61s
01/30/2023 11:10:04 AM  [*] Mon Jan 30 11:10:04 2023: Train Epoch: 7 [38400/47959 (80%)]	Loss: 167.821564 | Elapsed: 12.53s
01/30/2023 11:10:16 AM  [*] Mon Jan 30 11:10:16 2023: Train Epoch: 7 [44800/47959 (93%)]	Loss: 179.312393 | Elapsed: 12.52s
01/30/2023 11:10:24 AM  [*] Mon Jan 30 11:10:24 2023:    7    | Tr.loss: 178.700146 | Elapsed:   95.98  s
01/30/2023 11:10:24 AM  [*] Started epoch: 8
01/30/2023 11:10:24 AM  [*] Mon Jan 30 11:10:24 2023: Train Epoch: 8 [  0  /47959 (0 %)]	Loss: 179.010757 | Elapsed: 0.14s
01/30/2023 11:10:37 AM  [*] Mon Jan 30 11:10:37 2023: Train Epoch: 8 [6400 /47959 (13%)]	Loss: 203.892410 | Elapsed: 12.71s
01/30/2023 11:10:50 AM  [*] Mon Jan 30 11:10:50 2023: Train Epoch: 8 [12800/47959 (27%)]	Loss: 178.824799 | Elapsed: 12.58s
01/30/2023 11:11:02 AM  [*] Mon Jan 30 11:11:02 2023: Train Epoch: 8 [19200/47959 (40%)]	Loss: 180.695129 | Elapsed: 12.67s
01/30/2023 11:11:15 AM  [*] Mon Jan 30 11:11:15 2023: Train Epoch: 8 [25600/47959 (53%)]	Loss: 166.343033 | Elapsed: 12.57s
01/30/2023 11:11:27 AM  [*] Mon Jan 30 11:11:27 2023: Train Epoch: 8 [32000/47959 (67%)]	Loss: 179.653915 | Elapsed: 12.50s
01/30/2023 11:11:40 AM  [*] Mon Jan 30 11:11:40 2023: Train Epoch: 8 [38400/47959 (80%)]	Loss: 173.296082 | Elapsed: 12.48s
01/30/2023 11:11:52 AM  [*] Mon Jan 30 11:11:52 2023: Train Epoch: 8 [44800/47959 (93%)]	Loss: 182.468262 | Elapsed: 12.63s
01/30/2023 11:12:00 AM  [*] Mon Jan 30 11:12:00 2023:    8    | Tr.loss: 177.929989 | Elapsed:   96.02  s
01/30/2023 11:12:00 AM  [*] Started epoch: 9
01/30/2023 11:12:00 AM  [*] Mon Jan 30 11:12:00 2023: Train Epoch: 9 [  0  /47959 (0 %)]	Loss: 176.925018 | Elapsed: 0.13s
01/30/2023 11:12:13 AM  [*] Mon Jan 30 11:12:13 2023: Train Epoch: 9 [6400 /47959 (13%)]	Loss: 170.358185 | Elapsed: 12.71s
01/30/2023 11:12:26 AM  [*] Mon Jan 30 11:12:26 2023: Train Epoch: 9 [12800/47959 (27%)]	Loss: 155.157867 | Elapsed: 12.58s
01/30/2023 11:12:38 AM  [*] Mon Jan 30 11:12:38 2023: Train Epoch: 9 [19200/47959 (40%)]	Loss: 163.362793 | Elapsed: 12.71s
01/30/2023 11:12:51 AM  [*] Mon Jan 30 11:12:51 2023: Train Epoch: 9 [25600/47959 (53%)]	Loss: 197.062592 | Elapsed: 12.54s
01/30/2023 11:13:03 AM  [*] Mon Jan 30 11:13:03 2023: Train Epoch: 9 [32000/47959 (67%)]	Loss: 175.332275 | Elapsed: 12.66s
01/30/2023 11:13:16 AM  [*] Mon Jan 30 11:13:16 2023: Train Epoch: 9 [38400/47959 (80%)]	Loss: 168.797684 | Elapsed: 12.63s
01/30/2023 11:13:29 AM  [*] Mon Jan 30 11:13:29 2023: Train Epoch: 9 [44800/47959 (93%)]	Loss: 158.431412 | Elapsed: 12.56s
01/30/2023 11:13:36 AM  [*] Mon Jan 30 11:13:36 2023:    9    | Tr.loss: 177.156598 | Elapsed:   96.12  s
01/30/2023 11:13:36 AM  [*] Started epoch: 10
01/30/2023 11:13:36 AM  [*] Mon Jan 30 11:13:36 2023: Train Epoch: 10 [  0  /47959 (0 %)]	Loss: 185.830215 | Elapsed: 0.13s
01/30/2023 11:13:49 AM  [*] Mon Jan 30 11:13:49 2023: Train Epoch: 10 [6400 /47959 (13%)]	Loss: 166.192535 | Elapsed: 12.55s
01/30/2023 11:14:01 AM  [*] Mon Jan 30 11:14:01 2023: Train Epoch: 10 [12800/47959 (27%)]	Loss: 189.607544 | Elapsed: 12.52s
01/30/2023 11:14:14 AM  [*] Mon Jan 30 11:14:14 2023: Train Epoch: 10 [19200/47959 (40%)]	Loss: 186.440704 | Elapsed: 12.57s
01/30/2023 11:14:27 AM  [*] Mon Jan 30 11:14:27 2023: Train Epoch: 10 [25600/47959 (53%)]	Loss: 191.731903 | Elapsed: 12.57s
01/30/2023 11:14:39 AM  [*] Mon Jan 30 11:14:39 2023: Train Epoch: 10 [32000/47959 (67%)]	Loss: 183.505402 | Elapsed: 12.54s
01/30/2023 11:14:52 AM  [*] Mon Jan 30 11:14:52 2023: Train Epoch: 10 [38400/47959 (80%)]	Loss: 182.432709 | Elapsed: 12.54s
01/30/2023 11:15:04 AM  [*] Mon Jan 30 11:15:04 2023: Train Epoch: 10 [44800/47959 (93%)]	Loss: 182.794388 | Elapsed: 12.50s
01/30/2023 11:15:12 AM  [*] Mon Jan 30 11:15:12 2023:   10    | Tr.loss: 176.544977 | Elapsed:   95.51  s
01/30/2023 11:15:12 AM [!] Mon Jan 30 11:15:12 2023: Dumped results:
                model     : 1675073712-model.torch
		train time: 1675073712-trainTime.npy
		train losses: 1675073712-trainLosses.npy
		train AUC: 1675073712-auc.npy
01/30/2023 11:15:14 AM  [!] Training pretrained model on downstream task...
01/30/2023 11:15:14 AM  [*] Started epoch: 1
01/30/2023 11:15:14 AM  [*] Mon Jan 30 11:15:14 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 3.437115 | Elapsed: 0.25s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.4144
01/30/2023 11:15:23 AM  [*] Mon Jan 30 11:15:23 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.494650 | Elapsed: 9.24s | FPR 0.0003 -> TPR 0.3898 & F1 0.5610 | AUC 0.8661
01/30/2023 11:15:25 AM  [*] Mon Jan 30 11:15:25 2023:    1    | Tr.loss: 0.754288 | Elapsed:   11.33  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.6885
01/30/2023 11:15:25 AM  [*] Started epoch: 2
01/30/2023 11:15:25 AM  [*] Mon Jan 30 11:15:25 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.374493 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.4444 & F1 0.6154 | AUC 0.8924
01/30/2023 11:15:34 AM  [*] Mon Jan 30 11:15:34 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.452703 | Elapsed: 9.15s | FPR 0.0003 -> TPR 0.2603 & F1 0.4130 | AUC 0.8387
01/30/2023 11:15:36 AM  [*] Mon Jan 30 11:15:36 2023:    2    | Tr.loss: 0.440469 | Elapsed:   11.06  s | FPR 0.0003 -> TPR: 0.01 & F1: 0.02 | AUC: 0.8458
01/30/2023 11:15:36 AM  [*] Started epoch: 3
01/30/2023 11:15:36 AM  [*] Mon Jan 30 11:15:36 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.443277 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.4865 & F1 0.6545 | AUC 0.8654
01/30/2023 11:15:46 AM  [*] Mon Jan 30 11:15:46 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.287114 | Elapsed: 9.18s | FPR 0.0003 -> TPR 0.6667 & F1 0.8000 | AUC 0.9637
01/30/2023 11:15:47 AM  [*] Mon Jan 30 11:15:47 2023:    3    | Tr.loss: 0.359374 | Elapsed:   11.11  s | FPR 0.0003 -> TPR: 0.11 & F1: 0.19 | AUC: 0.9055
01/30/2023 11:15:48 AM [!] Mon Jan 30 11:15:48 2023: Dumped results:
                model     : 1675073747-model.torch
		train time: 1675073747-trainTime.npy
		train losses: 1675073747-trainLosses.npy
		train AUC: 1675073747-auc.npy
		train F1s : 1675073747-trainF1s.npy
		train TPRs: 1675073747-trainTPRs.npy
01/30/2023 11:15:48 AM  [!] Training non_pretrained model on downstream task...
01/30/2023 11:15:48 AM  [*] Started epoch: 1
01/30/2023 11:15:48 AM  [*] Mon Jan 30 11:15:48 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 1.391998 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0435 & F1 0.0833 | AUC 0.5072
01/30/2023 11:15:55 AM  [*] Mon Jan 30 11:15:55 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.366575 | Elapsed: 6.33s | FPR 0.0003 -> TPR 0.4667 & F1 0.6364 | AUC 0.8245
01/30/2023 11:15:56 AM  [*] Mon Jan 30 11:15:56 2023:    1    | Tr.loss: 0.580642 | Elapsed:   7.74   s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7401
01/30/2023 11:15:56 AM  [*] Started epoch: 2
01/30/2023 11:15:56 AM  [*] Mon Jan 30 11:15:56 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.410910 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.3830 & F1 0.5538 | AUC 0.8561
01/30/2023 11:16:02 AM  [*] Mon Jan 30 11:16:02 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.405459 | Elapsed: 6.31s | FPR 0.0003 -> TPR 0.2388 & F1 0.3855 | AUC 0.9095
01/30/2023 11:16:04 AM  [*] Mon Jan 30 11:16:04 2023:    2    | Tr.loss: 0.376923 | Elapsed:   7.69   s | FPR 0.0003 -> TPR: 0.14 & F1: 0.25 | AUC: 0.8852
01/30/2023 11:16:04 AM  [*] Started epoch: 3
01/30/2023 11:16:04 AM  [*] Mon Jan 30 11:16:04 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.240720 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.6170 & F1 0.7632 | AUC 0.9474
01/30/2023 11:16:10 AM  [*] Mon Jan 30 11:16:10 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.384372 | Elapsed: 6.36s | FPR 0.0003 -> TPR 0.4615 & F1 0.6316 | AUC 0.8418
01/30/2023 11:16:11 AM  [*] Mon Jan 30 11:16:11 2023:    3    | Tr.loss: 0.321521 | Elapsed:   7.73   s | FPR 0.0003 -> TPR: 0.11 & F1: 0.19 | AUC: 0.9209
01/30/2023 11:16:12 AM [!] Mon Jan 30 11:16:12 2023: Dumped results:
                model     : 1675073771-model.torch
		train time: 1675073771-trainTime.npy
		train losses: 1675073771-trainLosses.npy
		train AUC: 1675073771-auc.npy
		train F1s : 1675073771-trainF1s.npy
		train TPRs: 1675073771-trainTPRs.npy
01/30/2023 11:16:12 AM  [*] Evaluating pretrained model on test set...
01/30/2023 11:16:17 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0136 | F1: 0.0269
01/30/2023 11:16:17 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1684 | F1: 0.2881
01/30/2023 11:16:17 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.2462 | F1: 0.3948
01/30/2023 11:16:17 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.2659 | F1: 0.4193
01/30/2023 11:16:17 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3283 | F1: 0.4912
01/30/2023 11:16:17 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.5076 | F1: 0.6622
01/30/2023 11:16:17 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.6277 | F1: 0.7329
01/30/2023 11:16:17 AM  [*] Evaluating non_pretrained model on test set...
01/30/2023 11:16:22 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0053 | F1: 0.0106
01/30/2023 11:16:22 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1056 | F1: 0.1910
01/30/2023 11:16:22 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.1993 | F1: 0.3321
01/30/2023 11:16:22 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.2804 | F1: 0.4372
01/30/2023 11:16:22 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3602 | F1: 0.5263
01/30/2023 11:16:22 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4325 | F1: 0.5933
01/30/2023 11:16:22 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.5655 | F1: 0.6852
01/30/2023 11:16:22 AM  [!] Running pre-training split 2/3
01/30/2023 11:16:24 AM  [!] Pre-training model...
01/30/2023 11:16:25 AM  [*] Masking sequences...
01/30/2023 11:16:40 AM  [*] Started epoch: 1
01/30/2023 11:16:41 AM  [*] Mon Jan 30 11:16:41 2023: Train Epoch: 1 [  0  /47959 (0 %)]	Loss: 428.998932 | Elapsed: 0.37s
01/30/2023 11:16:53 AM  [*] Mon Jan 30 11:16:53 2023: Train Epoch: 1 [6400 /47959 (13%)]	Loss: 261.514709 | Elapsed: 12.37s
01/30/2023 11:17:05 AM  [*] Mon Jan 30 11:17:05 2023: Train Epoch: 1 [12800/47959 (27%)]	Loss: 209.848389 | Elapsed: 12.49s
01/30/2023 11:17:18 AM  [*] Mon Jan 30 11:17:18 2023: Train Epoch: 1 [19200/47959 (40%)]	Loss: 222.524963 | Elapsed: 12.51s
01/30/2023 11:17:31 AM  [*] Mon Jan 30 11:17:31 2023: Train Epoch: 1 [25600/47959 (53%)]	Loss: 205.533203 | Elapsed: 12.60s
01/30/2023 11:17:43 AM  [*] Mon Jan 30 11:17:43 2023: Train Epoch: 1 [32000/47959 (67%)]	Loss: 207.208160 | Elapsed: 12.49s
01/30/2023 11:17:56 AM  [*] Mon Jan 30 11:17:56 2023: Train Epoch: 1 [38400/47959 (80%)]	Loss: 196.769501 | Elapsed: 12.53s
01/30/2023 11:18:08 AM  [*] Mon Jan 30 11:18:08 2023: Train Epoch: 1 [44800/47959 (93%)]	Loss: 192.438721 | Elapsed: 12.43s
01/30/2023 11:18:16 AM  [*] Mon Jan 30 11:18:16 2023:    1    | Tr.loss: 211.133974 | Elapsed:   95.43  s
01/30/2023 11:18:16 AM  [*] Started epoch: 2
01/30/2023 11:18:16 AM  [*] Mon Jan 30 11:18:16 2023: Train Epoch: 2 [  0  /47959 (0 %)]	Loss: 185.776321 | Elapsed: 0.13s
01/30/2023 11:18:28 AM  [*] Mon Jan 30 11:18:28 2023: Train Epoch: 2 [6400 /47959 (13%)]	Loss: 180.152466 | Elapsed: 12.67s
01/30/2023 11:18:41 AM  [*] Mon Jan 30 11:18:41 2023: Train Epoch: 2 [12800/47959 (27%)]	Loss: 196.848175 | Elapsed: 12.58s
01/30/2023 11:18:54 AM  [*] Mon Jan 30 11:18:54 2023: Train Epoch: 2 [19200/47959 (40%)]	Loss: 180.351288 | Elapsed: 12.54s
01/30/2023 11:19:06 AM  [*] Mon Jan 30 11:19:06 2023: Train Epoch: 2 [25600/47959 (53%)]	Loss: 188.041336 | Elapsed: 12.70s
01/30/2023 11:19:19 AM  [*] Mon Jan 30 11:19:19 2023: Train Epoch: 2 [32000/47959 (67%)]	Loss: 186.398621 | Elapsed: 12.56s
01/30/2023 11:19:31 AM  [*] Mon Jan 30 11:19:31 2023: Train Epoch: 2 [38400/47959 (80%)]	Loss: 189.963791 | Elapsed: 12.47s
01/30/2023 11:19:44 AM  [*] Mon Jan 30 11:19:44 2023: Train Epoch: 2 [44800/47959 (93%)]	Loss: 177.680130 | Elapsed: 12.55s
01/30/2023 11:19:51 AM  [*] Mon Jan 30 11:19:51 2023:    2    | Tr.loss: 188.626552 | Elapsed:   95.81  s
01/30/2023 11:19:51 AM  [*] Started epoch: 3
01/30/2023 11:19:52 AM  [*] Mon Jan 30 11:19:52 2023: Train Epoch: 3 [  0  /47959 (0 %)]	Loss: 193.128159 | Elapsed: 0.13s
01/30/2023 11:20:04 AM  [*] Mon Jan 30 11:20:04 2023: Train Epoch: 3 [6400 /47959 (13%)]	Loss: 170.910538 | Elapsed: 12.79s
01/30/2023 11:20:17 AM  [*] Mon Jan 30 11:20:17 2023: Train Epoch: 3 [12800/47959 (27%)]	Loss: 190.735352 | Elapsed: 12.63s
01/30/2023 11:20:30 AM  [*] Mon Jan 30 11:20:30 2023: Train Epoch: 3 [19200/47959 (40%)]	Loss: 177.850250 | Elapsed: 12.56s
01/30/2023 11:20:42 AM  [*] Mon Jan 30 11:20:42 2023: Train Epoch: 3 [25600/47959 (53%)]	Loss: 185.463730 | Elapsed: 12.61s
01/30/2023 11:20:55 AM  [*] Mon Jan 30 11:20:55 2023: Train Epoch: 3 [32000/47959 (67%)]	Loss: 167.368347 | Elapsed: 12.60s
01/30/2023 11:21:07 AM  [*] Mon Jan 30 11:21:07 2023: Train Epoch: 3 [38400/47959 (80%)]	Loss: 186.093002 | Elapsed: 12.60s
01/30/2023 11:21:20 AM  [*] Mon Jan 30 11:21:20 2023: Train Epoch: 3 [44800/47959 (93%)]	Loss: 188.744858 | Elapsed: 12.68s
01/30/2023 11:21:28 AM  [*] Mon Jan 30 11:21:28 2023:    3    | Tr.loss: 182.760995 | Elapsed:   96.26  s
01/30/2023 11:21:28 AM  [*] Started epoch: 4
01/30/2023 11:21:28 AM  [*] Mon Jan 30 11:21:28 2023: Train Epoch: 4 [  0  /47959 (0 %)]	Loss: 166.451447 | Elapsed: 0.13s
01/30/2023 11:21:41 AM  [*] Mon Jan 30 11:21:41 2023: Train Epoch: 4 [6400 /47959 (13%)]	Loss: 169.313873 | Elapsed: 12.73s
01/30/2023 11:21:53 AM  [*] Mon Jan 30 11:21:53 2023: Train Epoch: 4 [12800/47959 (27%)]	Loss: 198.750549 | Elapsed: 12.57s
01/30/2023 11:22:06 AM  [*] Mon Jan 30 11:22:06 2023: Train Epoch: 4 [19200/47959 (40%)]	Loss: 175.286102 | Elapsed: 12.58s
01/30/2023 11:22:18 AM  [*] Mon Jan 30 11:22:18 2023: Train Epoch: 4 [25600/47959 (53%)]	Loss: 188.973724 | Elapsed: 12.52s
01/30/2023 11:22:31 AM  [*] Mon Jan 30 11:22:31 2023: Train Epoch: 4 [32000/47959 (67%)]	Loss: 160.228851 | Elapsed: 12.62s
01/30/2023 11:22:44 AM  [*] Mon Jan 30 11:22:44 2023: Train Epoch: 4 [38400/47959 (80%)]	Loss: 171.033951 | Elapsed: 12.66s
01/30/2023 11:22:56 AM  [*] Mon Jan 30 11:22:56 2023: Train Epoch: 4 [44800/47959 (93%)]	Loss: 183.573563 | Elapsed: 12.64s
01/30/2023 11:23:04 AM  [*] Mon Jan 30 11:23:04 2023:    4    | Tr.loss: 179.896597 | Elapsed:   96.00  s
01/30/2023 11:23:04 AM  [*] Started epoch: 5
01/30/2023 11:23:04 AM  [*] Mon Jan 30 11:23:04 2023: Train Epoch: 5 [  0  /47959 (0 %)]	Loss: 158.709396 | Elapsed: 0.13s
01/30/2023 11:23:17 AM  [*] Mon Jan 30 11:23:17 2023: Train Epoch: 5 [6400 /47959 (13%)]	Loss: 178.533920 | Elapsed: 12.64s
01/30/2023 11:23:29 AM  [*] Mon Jan 30 11:23:29 2023: Train Epoch: 5 [12800/47959 (27%)]	Loss: 180.330597 | Elapsed: 12.50s
01/30/2023 11:23:42 AM  [*] Mon Jan 30 11:23:42 2023: Train Epoch: 5 [19200/47959 (40%)]	Loss: 176.374252 | Elapsed: 12.76s
01/30/2023 11:23:54 AM  [*] Mon Jan 30 11:23:54 2023: Train Epoch: 5 [25600/47959 (53%)]	Loss: 179.209686 | Elapsed: 12.54s
01/30/2023 11:24:07 AM  [*] Mon Jan 30 11:24:07 2023: Train Epoch: 5 [32000/47959 (67%)]	Loss: 172.523224 | Elapsed: 12.55s
01/30/2023 11:24:20 AM  [*] Mon Jan 30 11:24:20 2023: Train Epoch: 5 [38400/47959 (80%)]	Loss: 173.627487 | Elapsed: 12.63s
01/30/2023 11:24:32 AM  [*] Mon Jan 30 11:24:32 2023: Train Epoch: 5 [44800/47959 (93%)]	Loss: 176.470490 | Elapsed: 12.53s
01/30/2023 11:24:40 AM  [*] Mon Jan 30 11:24:40 2023:    5    | Tr.loss: 178.034821 | Elapsed:   95.94  s
01/30/2023 11:24:40 AM  [*] Started epoch: 6
01/30/2023 11:24:40 AM  [*] Mon Jan 30 11:24:40 2023: Train Epoch: 6 [  0  /47959 (0 %)]	Loss: 163.923492 | Elapsed: 0.13s
01/30/2023 11:24:52 AM  [*] Mon Jan 30 11:24:52 2023: Train Epoch: 6 [6400 /47959 (13%)]	Loss: 176.061462 | Elapsed: 12.66s
01/30/2023 11:25:05 AM  [*] Mon Jan 30 11:25:05 2023: Train Epoch: 6 [12800/47959 (27%)]	Loss: 167.612228 | Elapsed: 12.57s
01/30/2023 11:25:18 AM  [*] Mon Jan 30 11:25:18 2023: Train Epoch: 6 [19200/47959 (40%)]	Loss: 187.224182 | Elapsed: 12.70s
01/30/2023 11:25:30 AM  [*] Mon Jan 30 11:25:30 2023: Train Epoch: 6 [25600/47959 (53%)]	Loss: 184.718842 | Elapsed: 12.46s
01/30/2023 11:25:43 AM  [*] Mon Jan 30 11:25:43 2023: Train Epoch: 6 [32000/47959 (67%)]	Loss: 191.005920 | Elapsed: 12.53s
01/30/2023 11:25:55 AM  [*] Mon Jan 30 11:25:55 2023: Train Epoch: 6 [38400/47959 (80%)]	Loss: 168.897049 | Elapsed: 12.57s
01/30/2023 11:26:08 AM  [*] Mon Jan 30 11:26:08 2023: Train Epoch: 6 [44800/47959 (93%)]	Loss: 168.490463 | Elapsed: 12.63s
01/30/2023 11:26:16 AM  [*] Mon Jan 30 11:26:16 2023:    6    | Tr.loss: 176.533455 | Elapsed:   95.93  s
01/30/2023 11:26:16 AM  [*] Started epoch: 7
01/30/2023 11:26:16 AM  [*] Mon Jan 30 11:26:16 2023: Train Epoch: 7 [  0  /47959 (0 %)]	Loss: 173.341019 | Elapsed: 0.13s
01/30/2023 11:26:28 AM  [*] Mon Jan 30 11:26:28 2023: Train Epoch: 7 [6400 /47959 (13%)]	Loss: 184.163605 | Elapsed: 12.64s
01/30/2023 11:26:41 AM  [*] Mon Jan 30 11:26:41 2023: Train Epoch: 7 [12800/47959 (27%)]	Loss: 178.991592 | Elapsed: 12.57s
01/30/2023 11:26:54 AM  [*] Mon Jan 30 11:26:54 2023: Train Epoch: 7 [19200/47959 (40%)]	Loss: 182.877716 | Elapsed: 12.68s
01/30/2023 11:27:06 AM  [*] Mon Jan 30 11:27:06 2023: Train Epoch: 7 [25600/47959 (53%)]	Loss: 184.547699 | Elapsed: 12.64s
01/30/2023 11:27:19 AM  [*] Mon Jan 30 11:27:19 2023: Train Epoch: 7 [32000/47959 (67%)]	Loss: 186.709259 | Elapsed: 12.54s
01/30/2023 11:27:31 AM  [*] Mon Jan 30 11:27:31 2023: Train Epoch: 7 [38400/47959 (80%)]	Loss: 199.248871 | Elapsed: 12.56s
01/30/2023 11:27:44 AM  [*] Mon Jan 30 11:27:44 2023: Train Epoch: 7 [44800/47959 (93%)]	Loss: 163.084000 | Elapsed: 12.54s
01/30/2023 11:27:52 AM  [*] Mon Jan 30 11:27:52 2023:    7    | Tr.loss: 175.362592 | Elapsed:   95.91  s
01/30/2023 11:27:52 AM  [*] Started epoch: 8
01/30/2023 11:27:52 AM  [*] Mon Jan 30 11:27:52 2023: Train Epoch: 8 [  0  /47959 (0 %)]	Loss: 161.498474 | Elapsed: 0.14s
01/30/2023 11:28:04 AM  [*] Mon Jan 30 11:28:04 2023: Train Epoch: 8 [6400 /47959 (13%)]	Loss: 179.449432 | Elapsed: 12.66s
01/30/2023 11:28:17 AM  [*] Mon Jan 30 11:28:17 2023: Train Epoch: 8 [12800/47959 (27%)]	Loss: 158.522339 | Elapsed: 12.63s
01/30/2023 11:28:29 AM  [*] Mon Jan 30 11:28:29 2023: Train Epoch: 8 [19200/47959 (40%)]	Loss: 159.931870 | Elapsed: 12.52s
01/30/2023 11:28:42 AM  [*] Mon Jan 30 11:28:42 2023: Train Epoch: 8 [25600/47959 (53%)]	Loss: 176.443298 | Elapsed: 12.55s
01/30/2023 11:28:55 AM  [*] Mon Jan 30 11:28:55 2023: Train Epoch: 8 [32000/47959 (67%)]	Loss: 174.761902 | Elapsed: 12.54s
01/30/2023 11:29:07 AM  [*] Mon Jan 30 11:29:07 2023: Train Epoch: 8 [38400/47959 (80%)]	Loss: 166.554550 | Elapsed: 12.57s
01/30/2023 11:29:20 AM  [*] Mon Jan 30 11:29:20 2023: Train Epoch: 8 [44800/47959 (93%)]	Loss: 182.090073 | Elapsed: 12.92s
01/30/2023 11:29:28 AM  [*] Mon Jan 30 11:29:28 2023:    8    | Tr.loss: 174.494827 | Elapsed:   96.55  s
01/30/2023 11:29:28 AM  [*] Started epoch: 9
01/30/2023 11:29:28 AM  [*] Mon Jan 30 11:29:28 2023: Train Epoch: 9 [  0  /47959 (0 %)]	Loss: 151.612488 | Elapsed: 0.14s
01/30/2023 11:29:41 AM  [*] Mon Jan 30 11:29:41 2023: Train Epoch: 9 [6400 /47959 (13%)]	Loss: 179.406479 | Elapsed: 12.84s
01/30/2023 11:29:54 AM  [*] Mon Jan 30 11:29:54 2023: Train Epoch: 9 [12800/47959 (27%)]	Loss: 181.109665 | Elapsed: 12.71s
01/30/2023 11:30:06 AM  [*] Mon Jan 30 11:30:06 2023: Train Epoch: 9 [19200/47959 (40%)]	Loss: 177.998718 | Elapsed: 12.61s
01/30/2023 11:30:19 AM  [*] Mon Jan 30 11:30:19 2023: Train Epoch: 9 [25600/47959 (53%)]	Loss: 157.599716 | Elapsed: 12.63s
01/30/2023 11:30:32 AM  [*] Mon Jan 30 11:30:32 2023: Train Epoch: 9 [32000/47959 (67%)]	Loss: 175.529846 | Elapsed: 12.60s
01/30/2023 11:30:44 AM  [*] Mon Jan 30 11:30:44 2023: Train Epoch: 9 [38400/47959 (80%)]	Loss: 183.600250 | Elapsed: 12.55s
01/30/2023 11:30:57 AM  [*] Mon Jan 30 11:30:57 2023: Train Epoch: 9 [44800/47959 (93%)]	Loss: 164.967865 | Elapsed: 12.48s
01/30/2023 11:31:04 AM  [*] Mon Jan 30 11:31:04 2023:    9    | Tr.loss: 173.678107 | Elapsed:   96.26  s
01/30/2023 11:31:04 AM  [*] Started epoch: 10
01/30/2023 11:31:04 AM  [*] Mon Jan 30 11:31:04 2023: Train Epoch: 10 [  0  /47959 (0 %)]	Loss: 164.343781 | Elapsed: 0.13s
01/30/2023 11:31:17 AM  [*] Mon Jan 30 11:31:17 2023: Train Epoch: 10 [6400 /47959 (13%)]	Loss: 159.747955 | Elapsed: 12.76s
01/30/2023 11:31:30 AM  [*] Mon Jan 30 11:31:30 2023: Train Epoch: 10 [12800/47959 (27%)]	Loss: 162.598480 | Elapsed: 12.66s
01/30/2023 11:31:42 AM  [*] Mon Jan 30 11:31:42 2023: Train Epoch: 10 [19200/47959 (40%)]	Loss: 188.137848 | Elapsed: 12.57s
01/30/2023 11:31:55 AM  [*] Mon Jan 30 11:31:55 2023: Train Epoch: 10 [25600/47959 (53%)]	Loss: 156.627655 | Elapsed: 12.52s
01/30/2023 11:32:08 AM  [*] Mon Jan 30 11:32:08 2023: Train Epoch: 10 [32000/47959 (67%)]	Loss: 178.708221 | Elapsed: 12.50s
01/30/2023 11:32:20 AM  [*] Mon Jan 30 11:32:20 2023: Train Epoch: 10 [38400/47959 (80%)]	Loss: 181.444427 | Elapsed: 12.69s
01/30/2023 11:32:33 AM  [*] Mon Jan 30 11:32:33 2023: Train Epoch: 10 [44800/47959 (93%)]	Loss: 146.449203 | Elapsed: 12.70s
01/30/2023 11:32:41 AM  [*] Mon Jan 30 11:32:41 2023:   10    | Tr.loss: 173.044973 | Elapsed:   96.19  s
01/30/2023 11:32:41 AM [!] Mon Jan 30 11:32:41 2023: Dumped results:
                model     : 1675074761-model.torch
		train time: 1675074761-trainTime.npy
		train losses: 1675074761-trainLosses.npy
		train AUC: 1675074761-auc.npy
01/30/2023 11:32:43 AM  [!] Training pretrained model on downstream task...
01/30/2023 11:32:43 AM  [*] Started epoch: 1
01/30/2023 11:32:43 AM  [*] Mon Jan 30 11:32:43 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 1.424715 | Elapsed: 0.42s | FPR 0.0003 -> TPR 0.2051 & F1 0.3404 | AUC 0.7190
01/30/2023 11:32:52 AM  [*] Mon Jan 30 11:32:52 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.376760 | Elapsed: 9.20s | FPR 0.0003 -> TPR 0.4400 & F1 0.6111 | AUC 0.8043
01/30/2023 11:32:54 AM  [*] Mon Jan 30 11:32:54 2023:    1    | Tr.loss: 0.539817 | Elapsed:   11.48  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8048
01/30/2023 11:32:54 AM  [*] Started epoch: 2
01/30/2023 11:32:54 AM  [*] Mon Jan 30 11:32:54 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.322339 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.6538 & F1 0.7907 | AUC 0.9151
01/30/2023 11:33:03 AM  [*] Mon Jan 30 11:33:03 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.383813 | Elapsed: 9.19s | FPR 0.0003 -> TPR 0.4923 & F1 0.6598 | AUC 0.8826
01/30/2023 11:33:05 AM  [*] Mon Jan 30 11:33:05 2023:    2    | Tr.loss: 0.378613 | Elapsed:   11.14  s | FPR 0.0003 -> TPR: 0.20 & F1: 0.34 | AUC: 0.8788
01/30/2023 11:33:05 AM  [*] Started epoch: 3
01/30/2023 11:33:05 AM  [*] Mon Jan 30 11:33:05 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.309647 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.6383 & F1 0.7792 | AUC 0.9111
01/30/2023 11:33:14 AM  [*] Mon Jan 30 11:33:14 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.377288 | Elapsed: 9.16s | FPR 0.0003 -> TPR 0.5758 & F1 0.7308 | AUC 0.9098
01/30/2023 11:33:16 AM  [*] Mon Jan 30 11:33:16 2023:    3    | Tr.loss: 0.321528 | Elapsed:   11.07  s | FPR 0.0003 -> TPR: 0.28 & F1: 0.43 | AUC: 0.9154
01/30/2023 11:33:17 AM [!] Mon Jan 30 11:33:17 2023: Dumped results:
                model     : 1675074796-model.torch
		train time: 1675074796-trainTime.npy
		train losses: 1675074796-trainLosses.npy
		train AUC: 1675074796-auc.npy
		train F1s : 1675074796-trainF1s.npy
		train TPRs: 1675074796-trainTPRs.npy
01/30/2023 11:33:17 AM  [!] Training non_pretrained model on downstream task...
01/30/2023 11:33:17 AM  [*] Started epoch: 1
01/30/2023 11:33:17 AM  [*] Mon Jan 30 11:33:17 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 2.410878 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.0952 & F1 0.1739 | AUC 0.4383
01/30/2023 11:33:24 AM  [*] Mon Jan 30 11:33:24 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.416239 | Elapsed: 6.35s | FPR 0.0003 -> TPR 0.4839 & F1 0.6522 | AUC 0.8786
01/30/2023 11:33:25 AM  [*] Mon Jan 30 11:33:25 2023:    1    | Tr.loss: 0.584121 | Elapsed:   7.72   s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7459
01/30/2023 11:33:25 AM  [*] Started epoch: 2
01/30/2023 11:33:25 AM  [*] Mon Jan 30 11:33:25 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.401189 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.5000 & F1 0.6667 | AUC 0.8813
01/30/2023 11:33:31 AM  [*] Mon Jan 30 11:33:31 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.421811 | Elapsed: 6.27s | FPR 0.0003 -> TPR 0.4722 & F1 0.6415 | AUC 0.8914
01/30/2023 11:33:33 AM  [*] Mon Jan 30 11:33:33 2023:    2    | Tr.loss: 0.375435 | Elapsed:   7.66   s | FPR 0.0003 -> TPR: 0.05 & F1: 0.09 | AUC: 0.8881
01/30/2023 11:33:33 AM  [*] Started epoch: 3
01/30/2023 11:33:33 AM  [*] Mon Jan 30 11:33:33 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.369737 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.1750 & F1 0.2979 | AUC 0.8979
01/30/2023 11:33:39 AM  [*] Mon Jan 30 11:33:39 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.267320 | Elapsed: 6.29s | FPR 0.0003 -> TPR 0.6000 & F1 0.7500 | AUC 0.9314
01/30/2023 11:33:40 AM  [*] Mon Jan 30 11:33:40 2023:    3    | Tr.loss: 0.320550 | Elapsed:   7.67   s | FPR 0.0003 -> TPR: 0.22 & F1: 0.36 | AUC: 0.9194
01/30/2023 11:33:41 AM [!] Mon Jan 30 11:33:41 2023: Dumped results:
                model     : 1675074820-model.torch
		train time: 1675074820-trainTime.npy
		train losses: 1675074820-trainLosses.npy
		train AUC: 1675074820-auc.npy
		train F1s : 1675074820-trainF1s.npy
		train TPRs: 1675074820-trainTPRs.npy
01/30/2023 11:33:41 AM  [*] Evaluating pretrained model on test set...
01/30/2023 11:33:46 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.2005 | F1: 0.3340
01/30/2023 11:33:46 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.2478 | F1: 0.3971
01/30/2023 11:33:46 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.2907 | F1: 0.4501
01/30/2023 11:33:46 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3242 | F1: 0.4887
01/30/2023 11:33:46 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.4163 | F1: 0.5843
01/30/2023 11:33:46 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4960 | F1: 0.6520
01/30/2023 11:33:46 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.6540 | F1: 0.7522
01/30/2023 11:33:46 AM  [*] Evaluating non_pretrained model on test set...
01/30/2023 11:33:51 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0340 | F1: 0.0658
01/30/2023 11:33:51 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1211 | F1: 0.2160
01/30/2023 11:33:51 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.1704 | F1: 0.2909
01/30/2023 11:33:51 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.2245 | F1: 0.3659
01/30/2023 11:33:51 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3147 | F1: 0.4756
01/30/2023 11:33:51 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4099 | F1: 0.5711
01/30/2023 11:33:51 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.5494 | F1: 0.6723
01/30/2023 11:33:51 AM  [!] Running pre-training split 3/3
01/30/2023 11:33:53 AM  [!] Pre-training model...
01/30/2023 11:33:54 AM  [*] Masking sequences...
01/30/2023 11:34:09 AM  [*] Started epoch: 1
01/30/2023 11:34:10 AM  [*] Mon Jan 30 11:34:10 2023: Train Epoch: 1 [  0  /47959 (0 %)]	Loss: 420.184814 | Elapsed: 0.33s
01/30/2023 11:34:22 AM  [*] Mon Jan 30 11:34:22 2023: Train Epoch: 1 [6400 /47959 (13%)]	Loss: 246.286957 | Elapsed: 12.49s
01/30/2023 11:34:34 AM  [*] Mon Jan 30 11:34:34 2023: Train Epoch: 1 [12800/47959 (27%)]	Loss: 213.702240 | Elapsed: 12.45s
01/30/2023 11:34:47 AM  [*] Mon Jan 30 11:34:47 2023: Train Epoch: 1 [19200/47959 (40%)]	Loss: 209.766510 | Elapsed: 12.46s
01/30/2023 11:35:00 AM  [*] Mon Jan 30 11:35:00 2023: Train Epoch: 1 [25600/47959 (53%)]	Loss: 221.720917 | Elapsed: 13.23s
01/30/2023 11:35:13 AM  [*] Mon Jan 30 11:35:13 2023: Train Epoch: 1 [32000/47959 (67%)]	Loss: 205.479050 | Elapsed: 13.26s
01/30/2023 11:35:26 AM  [*] Mon Jan 30 11:35:26 2023: Train Epoch: 1 [38400/47959 (80%)]	Loss: 188.600403 | Elapsed: 12.59s
01/30/2023 11:35:39 AM  [*] Mon Jan 30 11:35:39 2023: Train Epoch: 1 [44800/47959 (93%)]	Loss: 204.288116 | Elapsed: 12.61s
01/30/2023 11:35:46 AM  [*] Mon Jan 30 11:35:46 2023:    1    | Tr.loss: 212.661551 | Elapsed:   96.96  s
01/30/2023 11:35:46 AM  [*] Started epoch: 2
01/30/2023 11:35:46 AM  [*] Mon Jan 30 11:35:46 2023: Train Epoch: 2 [  0  /47959 (0 %)]	Loss: 204.684464 | Elapsed: 0.12s
01/30/2023 11:35:59 AM  [*] Mon Jan 30 11:35:59 2023: Train Epoch: 2 [6400 /47959 (13%)]	Loss: 179.947845 | Elapsed: 12.48s
01/30/2023 11:36:11 AM  [*] Mon Jan 30 11:36:11 2023: Train Epoch: 2 [12800/47959 (27%)]	Loss: 193.999496 | Elapsed: 12.47s
01/30/2023 11:36:24 AM  [*] Mon Jan 30 11:36:24 2023: Train Epoch: 2 [19200/47959 (40%)]	Loss: 190.289352 | Elapsed: 12.54s
01/30/2023 11:36:36 AM  [*] Mon Jan 30 11:36:36 2023: Train Epoch: 2 [25600/47959 (53%)]	Loss: 205.203796 | Elapsed: 12.47s
01/30/2023 11:36:49 AM  [*] Mon Jan 30 11:36:49 2023: Train Epoch: 2 [32000/47959 (67%)]	Loss: 204.453156 | Elapsed: 12.48s
01/30/2023 11:37:01 AM  [*] Mon Jan 30 11:37:01 2023: Train Epoch: 2 [38400/47959 (80%)]	Loss: 200.787659 | Elapsed: 12.53s
01/30/2023 11:37:14 AM  [*] Mon Jan 30 11:37:14 2023: Train Epoch: 2 [44800/47959 (93%)]	Loss: 170.349976 | Elapsed: 12.42s
01/30/2023 11:37:21 AM  [*] Mon Jan 30 11:37:21 2023:    2    | Tr.loss: 191.056719 | Elapsed:   95.00  s
01/30/2023 11:37:21 AM  [*] Started epoch: 3
01/30/2023 11:37:21 AM  [*] Mon Jan 30 11:37:21 2023: Train Epoch: 3 [  0  /47959 (0 %)]	Loss: 193.821655 | Elapsed: 0.14s
01/30/2023 11:37:34 AM  [*] Mon Jan 30 11:37:34 2023: Train Epoch: 3 [6400 /47959 (13%)]	Loss: 170.533020 | Elapsed: 12.61s
01/30/2023 11:37:46 AM  [*] Mon Jan 30 11:37:46 2023: Train Epoch: 3 [12800/47959 (27%)]	Loss: 181.975784 | Elapsed: 12.40s
01/30/2023 11:37:59 AM  [*] Mon Jan 30 11:37:59 2023: Train Epoch: 3 [19200/47959 (40%)]	Loss: 188.700958 | Elapsed: 12.43s
01/30/2023 11:38:11 AM  [*] Mon Jan 30 11:38:11 2023: Train Epoch: 3 [25600/47959 (53%)]	Loss: 183.567322 | Elapsed: 12.50s
01/30/2023 11:38:24 AM  [*] Mon Jan 30 11:38:24 2023: Train Epoch: 3 [32000/47959 (67%)]	Loss: 186.623932 | Elapsed: 12.49s
01/30/2023 11:38:36 AM  [*] Mon Jan 30 11:38:36 2023: Train Epoch: 3 [38400/47959 (80%)]	Loss: 173.931122 | Elapsed: 12.46s
01/30/2023 11:38:49 AM  [*] Mon Jan 30 11:38:49 2023: Train Epoch: 3 [44800/47959 (93%)]	Loss: 180.553162 | Elapsed: 12.34s
01/30/2023 11:38:56 AM  [*] Mon Jan 30 11:38:56 2023:    3    | Tr.loss: 185.359236 | Elapsed:   94.78  s
01/30/2023 11:38:56 AM  [*] Started epoch: 4
01/30/2023 11:38:56 AM  [*] Mon Jan 30 11:38:56 2023: Train Epoch: 4 [  0  /47959 (0 %)]	Loss: 209.334259 | Elapsed: 0.14s
01/30/2023 11:39:09 AM  [*] Mon Jan 30 11:39:09 2023: Train Epoch: 4 [6400 /47959 (13%)]	Loss: 178.460434 | Elapsed: 12.55s
01/30/2023 11:39:21 AM  [*] Mon Jan 30 11:39:21 2023: Train Epoch: 4 [12800/47959 (27%)]	Loss: 161.399673 | Elapsed: 12.52s
01/30/2023 11:39:34 AM  [*] Mon Jan 30 11:39:34 2023: Train Epoch: 4 [19200/47959 (40%)]	Loss: 171.776901 | Elapsed: 12.49s
01/30/2023 11:39:46 AM  [*] Mon Jan 30 11:39:46 2023: Train Epoch: 4 [25600/47959 (53%)]	Loss: 182.523224 | Elapsed: 12.40s
01/30/2023 11:39:58 AM  [*] Mon Jan 30 11:39:58 2023: Train Epoch: 4 [32000/47959 (67%)]	Loss: 192.500671 | Elapsed: 12.39s
01/30/2023 11:40:11 AM  [*] Mon Jan 30 11:40:11 2023: Train Epoch: 4 [38400/47959 (80%)]	Loss: 182.814987 | Elapsed: 12.42s
01/30/2023 11:40:23 AM  [*] Mon Jan 30 11:40:23 2023: Train Epoch: 4 [44800/47959 (93%)]	Loss: 165.733521 | Elapsed: 12.51s
01/30/2023 11:40:31 AM  [*] Mon Jan 30 11:40:31 2023:    4    | Tr.loss: 182.084618 | Elapsed:   94.79  s
01/30/2023 11:40:31 AM  [*] Started epoch: 5
01/30/2023 11:40:31 AM  [*] Mon Jan 30 11:40:31 2023: Train Epoch: 5 [  0  /47959 (0 %)]	Loss: 206.941269 | Elapsed: 0.13s
01/30/2023 11:40:43 AM  [*] Mon Jan 30 11:40:43 2023: Train Epoch: 5 [6400 /47959 (13%)]	Loss: 178.335358 | Elapsed: 12.39s
01/30/2023 11:40:56 AM  [*] Mon Jan 30 11:40:56 2023: Train Epoch: 5 [12800/47959 (27%)]	Loss: 173.416260 | Elapsed: 12.35s
01/30/2023 11:41:08 AM  [*] Mon Jan 30 11:41:08 2023: Train Epoch: 5 [19200/47959 (40%)]	Loss: 191.385941 | Elapsed: 12.34s
01/30/2023 11:41:20 AM  [*] Mon Jan 30 11:41:20 2023: Train Epoch: 5 [25600/47959 (53%)]	Loss: 208.349945 | Elapsed: 12.33s
01/30/2023 11:41:33 AM  [*] Mon Jan 30 11:41:33 2023: Train Epoch: 5 [32000/47959 (67%)]	Loss: 174.840607 | Elapsed: 12.37s
01/30/2023 11:41:45 AM  [*] Mon Jan 30 11:41:45 2023: Train Epoch: 5 [38400/47959 (80%)]	Loss: 181.091354 | Elapsed: 12.51s
01/30/2023 11:41:57 AM  [*] Mon Jan 30 11:41:57 2023: Train Epoch: 5 [44800/47959 (93%)]	Loss: 173.262573 | Elapsed: 12.24s
01/30/2023 11:42:05 AM  [*] Mon Jan 30 11:42:05 2023:    5    | Tr.loss: 180.058941 | Elapsed:   94.13  s
01/30/2023 11:42:05 AM  [*] Started epoch: 6
01/30/2023 11:42:05 AM  [*] Mon Jan 30 11:42:05 2023: Train Epoch: 6 [  0  /47959 (0 %)]	Loss: 161.169922 | Elapsed: 0.13s
01/30/2023 11:42:17 AM  [*] Mon Jan 30 11:42:17 2023: Train Epoch: 6 [6400 /47959 (13%)]	Loss: 172.474152 | Elapsed: 12.35s
01/30/2023 11:42:30 AM  [*] Mon Jan 30 11:42:30 2023: Train Epoch: 6 [12800/47959 (27%)]	Loss: 186.684280 | Elapsed: 12.51s
01/30/2023 11:42:42 AM  [*] Mon Jan 30 11:42:42 2023: Train Epoch: 6 [19200/47959 (40%)]	Loss: 203.493134 | Elapsed: 12.43s
01/30/2023 11:42:55 AM  [*] Mon Jan 30 11:42:55 2023: Train Epoch: 6 [25600/47959 (53%)]	Loss: 159.050415 | Elapsed: 12.39s
01/30/2023 11:43:07 AM  [*] Mon Jan 30 11:43:07 2023: Train Epoch: 6 [32000/47959 (67%)]	Loss: 198.693039 | Elapsed: 12.32s
01/30/2023 11:43:19 AM  [*] Mon Jan 30 11:43:19 2023: Train Epoch: 6 [38400/47959 (80%)]	Loss: 173.541595 | Elapsed: 12.38s
01/30/2023 11:43:32 AM  [*] Mon Jan 30 11:43:32 2023: Train Epoch: 6 [44800/47959 (93%)]	Loss: 177.957245 | Elapsed: 12.35s
01/30/2023 11:43:39 AM  [*] Mon Jan 30 11:43:39 2023:    6    | Tr.loss: 178.486847 | Elapsed:   94.32  s
01/30/2023 11:43:39 AM  [*] Started epoch: 7
01/30/2023 11:43:39 AM  [*] Mon Jan 30 11:43:39 2023: Train Epoch: 7 [  0  /47959 (0 %)]	Loss: 194.898819 | Elapsed: 0.13s
01/30/2023 11:43:52 AM  [*] Mon Jan 30 11:43:52 2023: Train Epoch: 7 [6400 /47959 (13%)]	Loss: 164.914978 | Elapsed: 12.34s
01/30/2023 11:44:04 AM  [*] Mon Jan 30 11:44:04 2023: Train Epoch: 7 [12800/47959 (27%)]	Loss: 200.547760 | Elapsed: 12.38s
01/30/2023 11:44:16 AM  [*] Mon Jan 30 11:44:16 2023: Train Epoch: 7 [19200/47959 (40%)]	Loss: 173.519196 | Elapsed: 12.29s
01/30/2023 11:44:29 AM  [*] Mon Jan 30 11:44:29 2023: Train Epoch: 7 [25600/47959 (53%)]	Loss: 176.465881 | Elapsed: 12.43s
01/30/2023 11:44:41 AM  [*] Mon Jan 30 11:44:41 2023: Train Epoch: 7 [32000/47959 (67%)]	Loss: 192.582489 | Elapsed: 12.27s
01/30/2023 11:44:53 AM  [*] Mon Jan 30 11:44:53 2023: Train Epoch: 7 [38400/47959 (80%)]	Loss: 188.966690 | Elapsed: 12.43s
01/30/2023 11:45:06 AM  [*] Mon Jan 30 11:45:06 2023: Train Epoch: 7 [44800/47959 (93%)]	Loss: 147.347702 | Elapsed: 12.46s
01/30/2023 11:45:13 AM  [*] Mon Jan 30 11:45:13 2023:    7    | Tr.loss: 177.656314 | Elapsed:   94.21  s
01/30/2023 11:45:13 AM  [*] Started epoch: 8
01/30/2023 11:45:14 AM  [*] Mon Jan 30 11:45:14 2023: Train Epoch: 8 [  0  /47959 (0 %)]	Loss: 181.814911 | Elapsed: 0.13s
01/30/2023 11:45:26 AM  [*] Mon Jan 30 11:45:26 2023: Train Epoch: 8 [6400 /47959 (13%)]	Loss: 186.107605 | Elapsed: 12.42s
01/30/2023 11:45:38 AM  [*] Mon Jan 30 11:45:38 2023: Train Epoch: 8 [12800/47959 (27%)]	Loss: 176.345963 | Elapsed: 12.47s
01/30/2023 11:45:51 AM  [*] Mon Jan 30 11:45:51 2023: Train Epoch: 8 [19200/47959 (40%)]	Loss: 179.400269 | Elapsed: 12.32s
01/30/2023 11:46:03 AM  [*] Mon Jan 30 11:46:03 2023: Train Epoch: 8 [25600/47959 (53%)]	Loss: 185.146759 | Elapsed: 12.34s
01/30/2023 11:46:16 AM  [*] Mon Jan 30 11:46:16 2023: Train Epoch: 8 [32000/47959 (67%)]	Loss: 169.504333 | Elapsed: 12.48s
01/30/2023 11:46:28 AM  [*] Mon Jan 30 11:46:28 2023: Train Epoch: 8 [38400/47959 (80%)]	Loss: 179.567429 | Elapsed: 12.45s
01/30/2023 11:46:40 AM  [*] Mon Jan 30 11:46:40 2023: Train Epoch: 8 [44800/47959 (93%)]	Loss: 174.331543 | Elapsed: 12.33s
01/30/2023 11:46:48 AM  [*] Mon Jan 30 11:46:48 2023:    8    | Tr.loss: 176.603448 | Elapsed:   94.44  s
01/30/2023 11:46:48 AM  [*] Started epoch: 9
01/30/2023 11:46:48 AM  [*] Mon Jan 30 11:46:48 2023: Train Epoch: 9 [  0  /47959 (0 %)]	Loss: 185.480026 | Elapsed: 0.13s
01/30/2023 11:47:00 AM  [*] Mon Jan 30 11:47:00 2023: Train Epoch: 9 [6400 /47959 (13%)]	Loss: 168.605377 | Elapsed: 12.41s
01/30/2023 11:47:13 AM  [*] Mon Jan 30 11:47:13 2023: Train Epoch: 9 [12800/47959 (27%)]	Loss: 179.084717 | Elapsed: 12.53s
01/30/2023 11:47:25 AM  [*] Mon Jan 30 11:47:25 2023: Train Epoch: 9 [19200/47959 (40%)]	Loss: 163.021362 | Elapsed: 12.49s
01/30/2023 11:47:38 AM  [*] Mon Jan 30 11:47:38 2023: Train Epoch: 9 [25600/47959 (53%)]	Loss: 191.438049 | Elapsed: 12.44s
01/30/2023 11:47:50 AM  [*] Mon Jan 30 11:47:50 2023: Train Epoch: 9 [32000/47959 (67%)]	Loss: 181.782532 | Elapsed: 12.54s
01/30/2023 11:48:03 AM  [*] Mon Jan 30 11:48:03 2023: Train Epoch: 9 [38400/47959 (80%)]	Loss: 178.933472 | Elapsed: 12.42s
01/30/2023 11:48:15 AM  [*] Mon Jan 30 11:48:15 2023: Train Epoch: 9 [44800/47959 (93%)]	Loss: 163.358994 | Elapsed: 12.42s
01/30/2023 11:48:23 AM  [*] Mon Jan 30 11:48:23 2023:    9    | Tr.loss: 175.958422 | Elapsed:   94.99  s
01/30/2023 11:48:23 AM  [*] Started epoch: 10
01/30/2023 11:48:23 AM  [*] Mon Jan 30 11:48:23 2023: Train Epoch: 10 [  0  /47959 (0 %)]	Loss: 172.885803 | Elapsed: 0.13s
01/30/2023 11:48:35 AM  [*] Mon Jan 30 11:48:35 2023: Train Epoch: 10 [6400 /47959 (13%)]	Loss: 195.554489 | Elapsed: 12.54s
01/30/2023 11:48:48 AM  [*] Mon Jan 30 11:48:48 2023: Train Epoch: 10 [12800/47959 (27%)]	Loss: 188.816483 | Elapsed: 12.47s
01/30/2023 11:49:00 AM  [*] Mon Jan 30 11:49:00 2023: Train Epoch: 10 [19200/47959 (40%)]	Loss: 182.715973 | Elapsed: 12.45s
01/30/2023 11:49:13 AM  [*] Mon Jan 30 11:49:13 2023: Train Epoch: 10 [25600/47959 (53%)]	Loss: 177.849213 | Elapsed: 12.45s
01/30/2023 11:49:25 AM  [*] Mon Jan 30 11:49:25 2023: Train Epoch: 10 [32000/47959 (67%)]	Loss: 178.232574 | Elapsed: 12.34s
01/30/2023 11:49:38 AM  [*] Mon Jan 30 11:49:38 2023: Train Epoch: 10 [38400/47959 (80%)]	Loss: 156.592621 | Elapsed: 12.45s
01/30/2023 11:49:50 AM  [*] Mon Jan 30 11:49:50 2023: Train Epoch: 10 [44800/47959 (93%)]	Loss: 179.981323 | Elapsed: 12.35s
01/30/2023 11:49:57 AM  [*] Mon Jan 30 11:49:57 2023:   10    | Tr.loss: 175.451629 | Elapsed:   94.65  s
01/30/2023 11:49:58 AM [!] Mon Jan 30 11:49:58 2023: Dumped results:
                model     : 1675075797-model.torch
		train time: 1675075797-trainTime.npy
		train losses: 1675075797-trainLosses.npy
		train AUC: 1675075797-auc.npy
01/30/2023 11:49:59 AM  [!] Training pretrained model on downstream task...
01/30/2023 11:49:59 AM  [*] Started epoch: 1
01/30/2023 11:50:00 AM  [*] Mon Jan 30 11:50:00 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 3.993166 | Elapsed: 0.32s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.3433
01/30/2023 11:50:09 AM  [*] Mon Jan 30 11:50:09 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.507097 | Elapsed: 9.16s | FPR 0.0003 -> TPR 0.3492 & F1 0.5176 | AUC 0.7799
01/30/2023 11:50:11 AM  [*] Mon Jan 30 11:50:11 2023:    1    | Tr.loss: 0.845707 | Elapsed:   11.30  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7032
01/30/2023 11:50:11 AM  [*] Started epoch: 2
01/30/2023 11:50:11 AM  [*] Mon Jan 30 11:50:11 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.547745 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.3191 & F1 0.4839 | AUC 0.7322
01/30/2023 11:50:20 AM  [*] Mon Jan 30 11:50:20 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.484851 | Elapsed: 9.17s | FPR 0.0003 -> TPR 0.3333 & F1 0.5000 | AUC 0.7723
01/30/2023 11:50:22 AM  [*] Mon Jan 30 11:50:22 2023:    2    | Tr.loss: 0.473421 | Elapsed:   11.14  s | FPR 0.0003 -> TPR: 0.18 & F1: 0.30 | AUC: 0.8122
01/30/2023 11:50:22 AM  [*] Started epoch: 3
01/30/2023 11:50:22 AM  [*] Mon Jan 30 11:50:22 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.435052 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.3158 & F1 0.4800 | AUC 0.8482
01/30/2023 11:50:31 AM  [*] Mon Jan 30 11:50:31 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.489256 | Elapsed: 9.19s | FPR 0.0003 -> TPR 0.4478 & F1 0.6186 | AUC 0.8209
01/30/2023 11:50:33 AM  [*] Mon Jan 30 11:50:33 2023:    3    | Tr.loss: 0.416676 | Elapsed:   11.12  s | FPR 0.0003 -> TPR: 0.15 & F1: 0.26 | AUC: 0.8561
01/30/2023 11:50:33 AM [!] Mon Jan 30 11:50:33 2023: Dumped results:
                model     : 1675075833-model.torch
		train time: 1675075833-trainTime.npy
		train losses: 1675075833-trainLosses.npy
		train AUC: 1675075833-auc.npy
		train F1s : 1675075833-trainF1s.npy
		train TPRs: 1675075833-trainTPRs.npy
01/30/2023 11:50:33 AM  [!] Training non_pretrained model on downstream task...
01/30/2023 11:50:34 AM  [*] Started epoch: 1
01/30/2023 11:50:34 AM  [*] Mon Jan 30 11:50:34 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 2.231770 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0816 & F1 0.1509 | AUC 0.5401
01/30/2023 11:50:40 AM  [*] Mon Jan 30 11:50:40 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.501361 | Elapsed: 6.31s | FPR 0.0003 -> TPR 0.2206 & F1 0.3614 | AUC 0.7675
01/30/2023 11:50:42 AM  [*] Mon Jan 30 11:50:42 2023:    1    | Tr.loss: 0.657187 | Elapsed:   7.68   s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7311
01/30/2023 11:50:42 AM  [*] Started epoch: 2
01/30/2023 11:50:42 AM  [*] Mon Jan 30 11:50:42 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.437385 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.4000 & F1 0.5714 | AUC 0.8643
01/30/2023 11:50:48 AM  [*] Mon Jan 30 11:50:48 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.461600 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.1304 & F1 0.2308 | AUC 0.8588
01/30/2023 11:50:49 AM  [*] Mon Jan 30 11:50:49 2023:    2    | Tr.loss: 0.397111 | Elapsed:   7.60   s | FPR 0.0003 -> TPR: 0.19 & F1: 0.31 | AUC: 0.8746
01/30/2023 11:50:49 AM  [*] Started epoch: 3
01/30/2023 11:50:49 AM  [*] Mon Jan 30 11:50:49 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.343357 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.6087 & F1 0.7568 | AUC 0.9106
01/30/2023 11:50:56 AM  [*] Mon Jan 30 11:50:56 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.480618 | Elapsed: 6.26s | FPR 0.0003 -> TPR 0.4655 & F1 0.6353 | AUC 0.8715
01/30/2023 11:50:57 AM  [*] Mon Jan 30 11:50:57 2023:    3    | Tr.loss: 0.336120 | Elapsed:   7.63   s | FPR 0.0003 -> TPR: 0.08 & F1: 0.14 | AUC: 0.9132
01/30/2023 11:50:57 AM [!] Mon Jan 30 11:50:57 2023: Dumped results:
                model     : 1675075857-model.torch
		train time: 1675075857-trainTime.npy
		train losses: 1675075857-trainLosses.npy
		train AUC: 1675075857-auc.npy
		train F1s : 1675075857-trainF1s.npy
		train TPRs: 1675075857-trainTPRs.npy
01/30/2023 11:50:57 AM  [*] Evaluating pretrained model on test set...
01/30/2023 11:51:02 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0468 | F1: 0.0894
01/30/2023 11:51:02 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1503 | F1: 0.2612
01/30/2023 11:51:02 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.2432 | F1: 0.3910
01/30/2023 11:51:02 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.2942 | F1: 0.4537
01/30/2023 11:51:02 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3226 | F1: 0.4847
01/30/2023 11:51:02 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4091 | F1: 0.5703
01/30/2023 11:51:02 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.5696 | F1: 0.6885
01/30/2023 11:51:02 AM  [*] Evaluating non_pretrained model on test set...
01/30/2023 11:51:07 AM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0239 | F1: 0.0467
01/30/2023 11:51:07 AM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.0989 | F1: 0.1800
01/30/2023 11:51:07 AM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.1867 | F1: 0.3145
01/30/2023 11:51:07 AM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.2518 | F1: 0.4016
01/30/2023 11:51:07 AM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3595 | F1: 0.5255
01/30/2023 11:51:07 AM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4268 | F1: 0.5877
01/30/2023 11:51:07 AM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.5857 | F1: 0.7011
01/30/2023 11:51:07 AM  [!] Finished pre-training evaluation over 3 splits! Saved metrics to:
	C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\downsample_tests\downsample_U_0.7_1675072733/metrics_MaskedLanguageModel_nSplits_3_limit_None.json
01/30/2023 11:51:07 AM  [!] Starting uSize downsample 0.8 evaluation!
01/30/2023 11:51:07 AM  [!] Starting Masked Language Model evaluation over 3 splits!
01/30/2023 11:51:07 AM  [!] Loaded data and vocab. X train size: (76126, 512), X test size: (17407, 512), vocab size: 50002
01/30/2023 11:51:07 AM  [!] Initiating Self-Supervised Learning Pretraining
     Language Modeling MaskedLanguageModel
     Model TransformerEncoderLM with config:
	{'vocabSize': 50002, 'maxLen': 512, 'dModel': 64, 'nHeads': 8, 'dHidden': 256, 'nLayers': 2, 'numClasses': 1, 'hiddenNeurons': [64], 'dropout': 0.3}

01/30/2023 11:51:07 AM  [!] Running pre-training split 1/3
01/30/2023 11:51:10 AM  [!] Pre-training model...
01/30/2023 11:51:11 AM  [*] Masking sequences...
01/30/2023 11:51:28 AM  [*] Started epoch: 1
01/30/2023 11:51:29 AM  [*] Mon Jan 30 11:51:29 2023: Train Epoch: 1 [  0  /54810 (0 %)]	Loss: 448.590271 | Elapsed: 0.43s
01/30/2023 11:51:41 AM  [*] Mon Jan 30 11:51:41 2023: Train Epoch: 1 [6400 /54810 (12%)]	Loss: 225.950500 | Elapsed: 12.38s
01/30/2023 11:51:54 AM  [*] Mon Jan 30 11:51:54 2023: Train Epoch: 1 [12800/54810 (23%)]	Loss: 244.993866 | Elapsed: 12.40s
01/30/2023 11:52:06 AM  [*] Mon Jan 30 11:52:06 2023: Train Epoch: 1 [19200/54810 (35%)]	Loss: 219.881073 | Elapsed: 12.47s
01/30/2023 11:52:18 AM  [*] Mon Jan 30 11:52:18 2023: Train Epoch: 1 [25600/54810 (47%)]	Loss: 221.755157 | Elapsed: 12.52s
01/30/2023 11:52:31 AM  [*] Mon Jan 30 11:52:31 2023: Train Epoch: 1 [32000/54810 (58%)]	Loss: 205.302078 | Elapsed: 12.64s
01/30/2023 11:52:44 AM  [*] Mon Jan 30 11:52:44 2023: Train Epoch: 1 [38400/54810 (70%)]	Loss: 193.288956 | Elapsed: 12.46s
01/30/2023 11:52:56 AM  [*] Mon Jan 30 11:52:56 2023: Train Epoch: 1 [44800/54810 (82%)]	Loss: 187.839615 | Elapsed: 12.74s
01/30/2023 11:53:09 AM  [*] Mon Jan 30 11:53:09 2023: Train Epoch: 1 [51200/54810 (93%)]	Loss: 209.671478 | Elapsed: 12.71s
01/30/2023 11:53:18 AM  [*] Mon Jan 30 11:53:18 2023:    1    | Tr.loss: 209.004379 | Elapsed:  109.42  s
01/30/2023 11:53:18 AM  [*] Started epoch: 2
01/30/2023 11:53:18 AM  [*] Mon Jan 30 11:53:18 2023: Train Epoch: 2 [  0  /54810 (0 %)]	Loss: 180.577011 | Elapsed: 0.13s
01/30/2023 11:53:30 AM  [*] Mon Jan 30 11:53:30 2023: Train Epoch: 2 [6400 /54810 (12%)]	Loss: 196.224426 | Elapsed: 12.61s
01/30/2023 11:53:43 AM  [*] Mon Jan 30 11:53:43 2023: Train Epoch: 2 [12800/54810 (23%)]	Loss: 177.372650 | Elapsed: 12.54s
01/30/2023 11:53:56 AM  [*] Mon Jan 30 11:53:56 2023: Train Epoch: 2 [19200/54810 (35%)]	Loss: 180.975433 | Elapsed: 12.67s
01/30/2023 11:54:08 AM  [*] Mon Jan 30 11:54:08 2023: Train Epoch: 2 [25600/54810 (47%)]	Loss: 174.591583 | Elapsed: 12.43s
01/30/2023 11:54:21 AM  [*] Mon Jan 30 11:54:21 2023: Train Epoch: 2 [32000/54810 (58%)]	Loss: 197.900467 | Elapsed: 12.50s
01/30/2023 11:54:33 AM  [*] Mon Jan 30 11:54:33 2023: Train Epoch: 2 [38400/54810 (70%)]	Loss: 193.456848 | Elapsed: 12.47s
01/30/2023 11:54:46 AM  [*] Mon Jan 30 11:54:46 2023: Train Epoch: 2 [44800/54810 (82%)]	Loss: 175.189377 | Elapsed: 12.64s
01/30/2023 11:54:58 AM  [*] Mon Jan 30 11:54:58 2023: Train Epoch: 2 [51200/54810 (93%)]	Loss: 179.656433 | Elapsed: 12.59s
01/30/2023 11:55:07 AM  [*] Mon Jan 30 11:55:07 2023:    2    | Tr.loss: 187.630424 | Elapsed:  109.24  s
01/30/2023 11:55:07 AM  [*] Started epoch: 3
01/30/2023 11:55:07 AM  [*] Mon Jan 30 11:55:07 2023: Train Epoch: 3 [  0  /54810 (0 %)]	Loss: 180.643692 | Elapsed: 0.12s
01/30/2023 11:55:20 AM  [*] Mon Jan 30 11:55:20 2023: Train Epoch: 3 [6400 /54810 (12%)]	Loss: 193.821991 | Elapsed: 12.53s
01/30/2023 11:55:32 AM  [*] Mon Jan 30 11:55:32 2023: Train Epoch: 3 [12800/54810 (23%)]	Loss: 181.711319 | Elapsed: 12.53s
01/30/2023 11:55:45 AM  [*] Mon Jan 30 11:55:45 2023: Train Epoch: 3 [19200/54810 (35%)]	Loss: 190.658875 | Elapsed: 12.55s
01/30/2023 11:55:57 AM  [*] Mon Jan 30 11:55:57 2023: Train Epoch: 3 [25600/54810 (47%)]	Loss: 172.240875 | Elapsed: 12.62s
01/30/2023 11:56:10 AM  [*] Mon Jan 30 11:56:10 2023: Train Epoch: 3 [32000/54810 (58%)]	Loss: 179.401382 | Elapsed: 12.58s
01/30/2023 11:56:23 AM  [*] Mon Jan 30 11:56:23 2023: Train Epoch: 3 [38400/54810 (70%)]	Loss: 178.983887 | Elapsed: 12.68s
01/30/2023 11:56:35 AM  [*] Mon Jan 30 11:56:35 2023: Train Epoch: 3 [44800/54810 (82%)]	Loss: 158.085648 | Elapsed: 12.46s
01/30/2023 11:56:48 AM  [*] Mon Jan 30 11:56:48 2023: Train Epoch: 3 [51200/54810 (93%)]	Loss: 190.570892 | Elapsed: 12.53s
01/30/2023 11:56:56 AM  [*] Mon Jan 30 11:56:56 2023:    3    | Tr.loss: 182.745241 | Elapsed:  109.23  s
01/30/2023 11:56:56 AM  [*] Started epoch: 4
01/30/2023 11:56:56 AM  [*] Mon Jan 30 11:56:56 2023: Train Epoch: 4 [  0  /54810 (0 %)]	Loss: 166.922333 | Elapsed: 0.14s
01/30/2023 11:57:09 AM  [*] Mon Jan 30 11:57:09 2023: Train Epoch: 4 [6400 /54810 (12%)]	Loss: 163.807144 | Elapsed: 12.60s
01/30/2023 11:57:22 AM  [*] Mon Jan 30 11:57:22 2023: Train Epoch: 4 [12800/54810 (23%)]	Loss: 176.821686 | Elapsed: 12.62s
01/30/2023 11:57:34 AM  [*] Mon Jan 30 11:57:34 2023: Train Epoch: 4 [19200/54810 (35%)]	Loss: 176.185822 | Elapsed: 12.68s
01/30/2023 11:57:47 AM  [*] Mon Jan 30 11:57:47 2023: Train Epoch: 4 [25600/54810 (47%)]	Loss: 191.137512 | Elapsed: 12.52s
01/30/2023 11:57:59 AM  [*] Mon Jan 30 11:57:59 2023: Train Epoch: 4 [32000/54810 (58%)]	Loss: 191.373932 | Elapsed: 12.54s
01/30/2023 11:58:12 AM  [*] Mon Jan 30 11:58:12 2023: Train Epoch: 4 [38400/54810 (70%)]	Loss: 198.008591 | Elapsed: 12.51s
01/30/2023 11:58:24 AM  [*] Mon Jan 30 11:58:24 2023: Train Epoch: 4 [44800/54810 (82%)]	Loss: 191.968613 | Elapsed: 12.52s
01/30/2023 11:58:37 AM  [*] Mon Jan 30 11:58:37 2023: Train Epoch: 4 [51200/54810 (93%)]	Loss: 164.650818 | Elapsed: 12.59s
01/30/2023 11:58:46 AM  [*] Mon Jan 30 11:58:46 2023:    4    | Tr.loss: 180.066901 | Elapsed:  109.33  s
01/30/2023 11:58:46 AM  [*] Started epoch: 5
01/30/2023 11:58:46 AM  [*] Mon Jan 30 11:58:46 2023: Train Epoch: 5 [  0  /54810 (0 %)]	Loss: 184.810410 | Elapsed: 0.13s
01/30/2023 11:58:58 AM  [*] Mon Jan 30 11:58:58 2023: Train Epoch: 5 [6400 /54810 (12%)]	Loss: 222.548920 | Elapsed: 12.56s
01/30/2023 11:59:11 AM  [*] Mon Jan 30 11:59:11 2023: Train Epoch: 5 [12800/54810 (23%)]	Loss: 204.546921 | Elapsed: 12.59s
01/30/2023 11:59:24 AM  [*] Mon Jan 30 11:59:24 2023: Train Epoch: 5 [19200/54810 (35%)]	Loss: 185.136322 | Elapsed: 12.73s
01/30/2023 11:59:36 AM  [*] Mon Jan 30 11:59:36 2023: Train Epoch: 5 [25600/54810 (47%)]	Loss: 194.052948 | Elapsed: 12.60s
01/30/2023 11:59:49 AM  [*] Mon Jan 30 11:59:49 2023: Train Epoch: 5 [32000/54810 (58%)]	Loss: 167.840912 | Elapsed: 12.54s
01/30/2023 12:00:01 PM  [*] Mon Jan 30 12:00:01 2023: Train Epoch: 5 [38400/54810 (70%)]	Loss: 161.090103 | Elapsed: 12.48s
01/30/2023 12:00:14 PM  [*] Mon Jan 30 12:00:14 2023: Train Epoch: 5 [44800/54810 (82%)]	Loss: 176.103409 | Elapsed: 12.62s
01/30/2023 12:00:26 PM  [*] Mon Jan 30 12:00:26 2023: Train Epoch: 5 [51200/54810 (93%)]	Loss: 176.532349 | Elapsed: 12.62s
01/30/2023 12:00:35 PM  [*] Mon Jan 30 12:00:35 2023:    5    | Tr.loss: 178.305972 | Elapsed:  109.70  s
01/30/2023 12:00:35 PM  [*] Started epoch: 6
01/30/2023 12:00:35 PM  [*] Mon Jan 30 12:00:35 2023: Train Epoch: 6 [  0  /54810 (0 %)]	Loss: 168.682846 | Elapsed: 0.22s
01/30/2023 12:00:48 PM  [*] Mon Jan 30 12:00:48 2023: Train Epoch: 6 [6400 /54810 (12%)]	Loss: 163.169342 | Elapsed: 12.60s
01/30/2023 12:01:01 PM  [*] Mon Jan 30 12:01:01 2023: Train Epoch: 6 [12800/54810 (23%)]	Loss: 170.208130 | Elapsed: 12.57s
01/30/2023 12:01:13 PM  [*] Mon Jan 30 12:01:13 2023: Train Epoch: 6 [19200/54810 (35%)]	Loss: 174.108078 | Elapsed: 12.51s
01/30/2023 12:01:26 PM  [*] Mon Jan 30 12:01:26 2023: Train Epoch: 6 [25600/54810 (47%)]	Loss: 191.415314 | Elapsed: 12.44s
01/30/2023 12:01:38 PM  [*] Mon Jan 30 12:01:38 2023: Train Epoch: 6 [32000/54810 (58%)]	Loss: 180.798096 | Elapsed: 12.45s
01/30/2023 12:01:51 PM  [*] Mon Jan 30 12:01:51 2023: Train Epoch: 6 [38400/54810 (70%)]	Loss: 184.755142 | Elapsed: 12.51s
01/30/2023 12:02:03 PM  [*] Mon Jan 30 12:02:03 2023: Train Epoch: 6 [44800/54810 (82%)]	Loss: 177.783600 | Elapsed: 12.59s
01/30/2023 12:02:16 PM  [*] Mon Jan 30 12:02:16 2023: Train Epoch: 6 [51200/54810 (93%)]	Loss: 174.944809 | Elapsed: 12.54s
01/30/2023 12:02:24 PM  [*] Mon Jan 30 12:02:24 2023:    6    | Tr.loss: 176.678789 | Elapsed:  109.12  s
01/30/2023 12:02:24 PM  [*] Started epoch: 7
01/30/2023 12:02:24 PM  [*] Mon Jan 30 12:02:24 2023: Train Epoch: 7 [  0  /54810 (0 %)]	Loss: 182.173676 | Elapsed: 0.13s
01/30/2023 12:02:37 PM  [*] Mon Jan 30 12:02:37 2023: Train Epoch: 7 [6400 /54810 (12%)]	Loss: 160.147156 | Elapsed: 12.71s
01/30/2023 12:02:50 PM  [*] Mon Jan 30 12:02:50 2023: Train Epoch: 7 [12800/54810 (23%)]	Loss: 189.602509 | Elapsed: 12.38s
01/30/2023 12:03:02 PM  [*] Mon Jan 30 12:03:02 2023: Train Epoch: 7 [19200/54810 (35%)]	Loss: 159.020996 | Elapsed: 12.43s
01/30/2023 12:03:15 PM  [*] Mon Jan 30 12:03:15 2023: Train Epoch: 7 [25600/54810 (47%)]	Loss: 190.867981 | Elapsed: 12.51s
01/30/2023 12:03:27 PM  [*] Mon Jan 30 12:03:27 2023: Train Epoch: 7 [32000/54810 (58%)]	Loss: 169.535629 | Elapsed: 12.55s
01/30/2023 12:03:40 PM  [*] Mon Jan 30 12:03:40 2023: Train Epoch: 7 [38400/54810 (70%)]	Loss: 194.554199 | Elapsed: 12.68s
01/30/2023 12:03:52 PM  [*] Mon Jan 30 12:03:52 2023: Train Epoch: 7 [44800/54810 (82%)]	Loss: 168.642395 | Elapsed: 12.49s
01/30/2023 12:04:05 PM  [*] Mon Jan 30 12:04:05 2023: Train Epoch: 7 [51200/54810 (93%)]	Loss: 176.970901 | Elapsed: 12.50s
01/30/2023 12:04:13 PM  [*] Mon Jan 30 12:04:13 2023:    7    | Tr.loss: 175.627819 | Elapsed:  109.01  s
01/30/2023 12:04:13 PM  [*] Started epoch: 8
01/30/2023 12:04:14 PM  [*] Mon Jan 30 12:04:14 2023: Train Epoch: 8 [  0  /54810 (0 %)]	Loss: 182.033417 | Elapsed: 0.20s
01/30/2023 12:04:26 PM  [*] Mon Jan 30 12:04:26 2023: Train Epoch: 8 [6400 /54810 (12%)]	Loss: 184.840240 | Elapsed: 12.54s
01/30/2023 12:04:39 PM  [*] Mon Jan 30 12:04:39 2023: Train Epoch: 8 [12800/54810 (23%)]	Loss: 183.225250 | Elapsed: 12.50s
01/30/2023 12:04:51 PM  [*] Mon Jan 30 12:04:51 2023: Train Epoch: 8 [19200/54810 (35%)]	Loss: 180.350647 | Elapsed: 12.67s
01/30/2023 12:05:04 PM  [*] Mon Jan 30 12:05:04 2023: Train Epoch: 8 [25600/54810 (47%)]	Loss: 149.553802 | Elapsed: 12.54s
01/30/2023 12:05:16 PM  [*] Mon Jan 30 12:05:16 2023: Train Epoch: 8 [32000/54810 (58%)]	Loss: 182.491577 | Elapsed: 12.48s
01/30/2023 12:05:29 PM  [*] Mon Jan 30 12:05:29 2023: Train Epoch: 8 [38400/54810 (70%)]	Loss: 194.039993 | Elapsed: 12.48s
01/30/2023 12:05:41 PM  [*] Mon Jan 30 12:05:41 2023: Train Epoch: 8 [44800/54810 (82%)]	Loss: 191.220139 | Elapsed: 12.59s
01/30/2023 12:05:54 PM  [*] Mon Jan 30 12:05:54 2023: Train Epoch: 8 [51200/54810 (93%)]	Loss: 182.786102 | Elapsed: 12.52s
01/30/2023 12:06:03 PM  [*] Mon Jan 30 12:06:03 2023:    8    | Tr.loss: 174.757180 | Elapsed:  109.20  s
01/30/2023 12:06:03 PM  [*] Started epoch: 9
01/30/2023 12:06:03 PM  [*] Mon Jan 30 12:06:03 2023: Train Epoch: 9 [  0  /54810 (0 %)]	Loss: 191.023865 | Elapsed: 0.13s
01/30/2023 12:06:15 PM  [*] Mon Jan 30 12:06:15 2023: Train Epoch: 9 [6400 /54810 (12%)]	Loss: 175.784744 | Elapsed: 12.55s
01/30/2023 12:06:28 PM  [*] Mon Jan 30 12:06:28 2023: Train Epoch: 9 [12800/54810 (23%)]	Loss: 153.724487 | Elapsed: 12.54s
01/30/2023 12:06:40 PM  [*] Mon Jan 30 12:06:40 2023: Train Epoch: 9 [19200/54810 (35%)]	Loss: 193.565399 | Elapsed: 12.52s
01/30/2023 12:06:53 PM  [*] Mon Jan 30 12:06:53 2023: Train Epoch: 9 [25600/54810 (47%)]	Loss: 154.099548 | Elapsed: 12.55s
01/30/2023 12:07:05 PM  [*] Mon Jan 30 12:07:05 2023: Train Epoch: 9 [32000/54810 (58%)]	Loss: 166.843964 | Elapsed: 12.44s
01/30/2023 12:07:18 PM  [*] Mon Jan 30 12:07:18 2023: Train Epoch: 9 [38400/54810 (70%)]	Loss: 171.467606 | Elapsed: 12.45s
01/30/2023 12:07:30 PM  [*] Mon Jan 30 12:07:30 2023: Train Epoch: 9 [44800/54810 (82%)]	Loss: 203.453308 | Elapsed: 12.61s
01/30/2023 12:07:43 PM  [*] Mon Jan 30 12:07:43 2023: Train Epoch: 9 [51200/54810 (93%)]	Loss: 161.965668 | Elapsed: 12.53s
01/30/2023 12:07:52 PM  [*] Mon Jan 30 12:07:52 2023:    9    | Tr.loss: 174.073197 | Elapsed:  108.98  s
01/30/2023 12:07:52 PM  [*] Started epoch: 10
01/30/2023 12:07:52 PM  [*] Mon Jan 30 12:07:52 2023: Train Epoch: 10 [  0  /54810 (0 %)]	Loss: 181.962982 | Elapsed: 0.13s
01/30/2023 12:08:04 PM  [*] Mon Jan 30 12:08:04 2023: Train Epoch: 10 [6400 /54810 (12%)]	Loss: 180.730774 | Elapsed: 12.63s
01/30/2023 12:08:17 PM  [*] Mon Jan 30 12:08:17 2023: Train Epoch: 10 [12800/54810 (23%)]	Loss: 168.662628 | Elapsed: 12.67s
01/30/2023 12:08:29 PM  [*] Mon Jan 30 12:08:29 2023: Train Epoch: 10 [19200/54810 (35%)]	Loss: 180.477356 | Elapsed: 12.50s
01/30/2023 12:08:42 PM  [*] Mon Jan 30 12:08:42 2023: Train Epoch: 10 [25600/54810 (47%)]	Loss: 156.763611 | Elapsed: 12.50s
01/30/2023 12:08:54 PM  [*] Mon Jan 30 12:08:54 2023: Train Epoch: 10 [32000/54810 (58%)]	Loss: 168.661865 | Elapsed: 12.52s
01/30/2023 12:09:07 PM  [*] Mon Jan 30 12:09:07 2023: Train Epoch: 10 [38400/54810 (70%)]	Loss: 169.340866 | Elapsed: 12.59s
01/30/2023 12:09:20 PM  [*] Mon Jan 30 12:09:20 2023: Train Epoch: 10 [44800/54810 (82%)]	Loss: 164.568787 | Elapsed: 12.57s
01/30/2023 12:09:32 PM  [*] Mon Jan 30 12:09:32 2023: Train Epoch: 10 [51200/54810 (93%)]	Loss: 177.379333 | Elapsed: 12.55s
01/30/2023 12:09:41 PM  [*] Mon Jan 30 12:09:41 2023:   10    | Tr.loss: 173.568415 | Elapsed:  109.27  s
01/30/2023 12:09:41 PM [!] Mon Jan 30 12:09:41 2023: Dumped results:
                model     : 1675076981-model.torch
		train time: 1675076981-trainTime.npy
		train losses: 1675076981-trainLosses.npy
		train AUC: 1675076981-auc.npy
01/30/2023 12:09:43 PM  [!] Training pretrained model on downstream task...
01/30/2023 12:09:43 PM  [*] Started epoch: 1
01/30/2023 12:09:43 PM  [*] Mon Jan 30 12:09:43 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 2.066883 | Elapsed: 0.27s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.4434
01/30/2023 12:09:53 PM  [*] Mon Jan 30 12:09:53 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.411847 | Elapsed: 9.17s | FPR 0.0003 -> TPR 0.0339 & F1 0.0656 | AUC 0.8921
01/30/2023 12:09:54 PM  [*] Mon Jan 30 12:09:54 2023:    1    | Tr.loss: 0.578097 | Elapsed:   11.31  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7696
01/30/2023 12:09:54 PM  [*] Started epoch: 2
01/30/2023 12:09:55 PM  [*] Mon Jan 30 12:09:55 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.334645 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.4889 & F1 0.6567 | AUC 0.9187
01/30/2023 12:10:04 PM  [*] Mon Jan 30 12:10:04 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.308182 | Elapsed: 9.14s | FPR 0.0003 -> TPR 0.4932 & F1 0.6606 | AUC 0.9305
01/30/2023 12:10:05 PM  [*] Mon Jan 30 12:10:05 2023:    2    | Tr.loss: 0.383563 | Elapsed:   11.06  s | FPR 0.0003 -> TPR: 0.07 & F1: 0.13 | AUC: 0.8833
01/30/2023 12:10:05 PM  [*] Started epoch: 3
01/30/2023 12:10:06 PM  [*] Mon Jan 30 12:10:06 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.318150 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.3784 & F1 0.5490 | AUC 0.9469
01/30/2023 12:10:15 PM  [*] Mon Jan 30 12:10:15 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.285286 | Elapsed: 9.13s | FPR 0.0003 -> TPR 0.7333 & F1 0.8462 | AUC 0.9623
01/30/2023 12:10:16 PM  [*] Mon Jan 30 12:10:16 2023:    3    | Tr.loss: 0.300984 | Elapsed:   11.04  s | FPR 0.0003 -> TPR: 0.17 & F1: 0.29 | AUC: 0.9337
01/30/2023 12:10:17 PM [!] Mon Jan 30 12:10:17 2023: Dumped results:
                model     : 1675077016-model.torch
		train time: 1675077016-trainTime.npy
		train losses: 1675077016-trainLosses.npy
		train AUC: 1675077016-auc.npy
		train F1s : 1675077016-trainF1s.npy
		train TPRs: 1675077016-trainTPRs.npy
01/30/2023 12:10:17 PM  [!] Training non_pretrained model on downstream task...
01/30/2023 12:10:17 PM  [*] Started epoch: 1
01/30/2023 12:10:17 PM  [*] Mon Jan 30 12:10:17 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 1.533359 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0652 & F1 0.1224 | AUC 0.4734
01/30/2023 12:10:24 PM  [*] Mon Jan 30 12:10:24 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.401231 | Elapsed: 6.28s | FPR 0.0003 -> TPR 0.3867 & F1 0.5577 | AUC 0.8336
01/30/2023 12:10:25 PM  [*] Mon Jan 30 12:10:25 2023:    1    | Tr.loss: 0.556351 | Elapsed:   7.70   s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7654
01/30/2023 12:10:25 PM  [*] Started epoch: 2
01/30/2023 12:10:25 PM  [*] Mon Jan 30 12:10:25 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.522775 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.1064 & F1 0.1923 | AUC 0.8123
01/30/2023 12:10:31 PM  [*] Mon Jan 30 12:10:31 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.403593 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.5075 & F1 0.6733 | AUC 0.8973
01/30/2023 12:10:33 PM  [*] Mon Jan 30 12:10:33 2023:    2    | Tr.loss: 0.363329 | Elapsed:   7.62   s | FPR 0.0003 -> TPR: 0.14 & F1: 0.25 | AUC: 0.8947
01/30/2023 12:10:33 PM  [*] Started epoch: 3
01/30/2023 12:10:33 PM  [*] Mon Jan 30 12:10:33 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.248431 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.6809 & F1 0.8101 | AUC 0.9462
01/30/2023 12:10:39 PM  [*] Mon Jan 30 12:10:39 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.394582 | Elapsed: 6.25s | FPR 0.0003 -> TPR 0.4154 & F1 0.5870 | AUC 0.8668
01/30/2023 12:10:40 PM  [*] Mon Jan 30 12:10:40 2023:    3    | Tr.loss: 0.305087 | Elapsed:   7.61   s | FPR 0.0003 -> TPR: 0.17 & F1: 0.28 | AUC: 0.9300
01/30/2023 12:10:41 PM [!] Mon Jan 30 12:10:41 2023: Dumped results:
                model     : 1675077040-model.torch
		train time: 1675077040-trainTime.npy
		train losses: 1675077040-trainLosses.npy
		train AUC: 1675077040-auc.npy
		train F1s : 1675077040-trainF1s.npy
		train TPRs: 1675077040-trainTPRs.npy
01/30/2023 12:10:41 PM  [*] Evaluating pretrained model on test set...
01/30/2023 12:10:46 PM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.1211 | F1: 0.2161
01/30/2023 12:10:46 PM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1950 | F1: 0.3264
01/30/2023 12:10:46 PM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.3370 | F1: 0.5038
01/30/2023 12:10:46 PM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3706 | F1: 0.5398
01/30/2023 12:10:46 PM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3962 | F1: 0.5641
01/30/2023 12:10:46 PM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4480 | F1: 0.6081
01/30/2023 12:10:46 PM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.6124 | F1: 0.7216
01/30/2023 12:10:46 PM  [*] Evaluating non_pretrained model on test set...
01/30/2023 12:10:51 PM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0022 | F1: 0.0045
01/30/2023 12:10:51 PM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1340 | F1: 0.2363
01/30/2023 12:10:51 PM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.2083 | F1: 0.3446
01/30/2023 12:10:51 PM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.2564 | F1: 0.4073
01/30/2023 12:10:51 PM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3477 | F1: 0.5127
01/30/2023 12:10:51 PM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4265 | F1: 0.5874
01/30/2023 12:10:51 PM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.5975 | F1: 0.7102
01/30/2023 12:10:51 PM  [!] Running pre-training split 2/3
01/30/2023 12:10:53 PM  [!] Pre-training model...
01/30/2023 12:10:54 PM  [*] Masking sequences...
01/30/2023 12:11:11 PM  [*] Started epoch: 1
01/30/2023 12:11:12 PM  [*] Mon Jan 30 12:11:12 2023: Train Epoch: 1 [  0  /54810 (0 %)]	Loss: 423.819092 | Elapsed: 0.33s
01/30/2023 12:11:24 PM  [*] Mon Jan 30 12:11:24 2023: Train Epoch: 1 [6400 /54810 (12%)]	Loss: 224.634674 | Elapsed: 12.35s
01/30/2023 12:11:36 PM  [*] Mon Jan 30 12:11:36 2023: Train Epoch: 1 [12800/54810 (23%)]	Loss: 211.244446 | Elapsed: 12.42s
01/30/2023 12:11:49 PM  [*] Mon Jan 30 12:11:49 2023: Train Epoch: 1 [19200/54810 (35%)]	Loss: 201.590683 | Elapsed: 12.48s
01/30/2023 12:12:01 PM  [*] Mon Jan 30 12:12:01 2023: Train Epoch: 1 [25600/54810 (47%)]	Loss: 228.194626 | Elapsed: 12.49s
01/30/2023 12:12:14 PM  [*] Mon Jan 30 12:12:14 2023: Train Epoch: 1 [32000/54810 (58%)]	Loss: 182.360077 | Elapsed: 12.50s
01/30/2023 12:12:26 PM  [*] Mon Jan 30 12:12:26 2023: Train Epoch: 1 [38400/54810 (70%)]	Loss: 195.597717 | Elapsed: 12.55s
01/30/2023 12:12:39 PM  [*] Mon Jan 30 12:12:39 2023: Train Epoch: 1 [44800/54810 (82%)]	Loss: 179.955475 | Elapsed: 12.60s
01/30/2023 12:12:52 PM  [*] Mon Jan 30 12:12:52 2023: Train Epoch: 1 [51200/54810 (93%)]	Loss: 203.796051 | Elapsed: 12.46s
01/30/2023 12:13:00 PM  [*] Mon Jan 30 12:13:00 2023:    1    | Tr.loss: 208.187654 | Elapsed:  108.86  s
01/30/2023 12:13:00 PM  [*] Started epoch: 2
01/30/2023 12:13:00 PM  [*] Mon Jan 30 12:13:00 2023: Train Epoch: 2 [  0  /54810 (0 %)]	Loss: 200.310791 | Elapsed: 0.13s
01/30/2023 12:13:13 PM  [*] Mon Jan 30 12:13:13 2023: Train Epoch: 2 [6400 /54810 (12%)]	Loss: 186.045471 | Elapsed: 12.57s
01/30/2023 12:13:25 PM  [*] Mon Jan 30 12:13:25 2023: Train Epoch: 2 [12800/54810 (23%)]	Loss: 190.549408 | Elapsed: 12.54s
01/30/2023 12:13:38 PM  [*] Mon Jan 30 12:13:38 2023: Train Epoch: 2 [19200/54810 (35%)]	Loss: 174.876205 | Elapsed: 12.69s
01/30/2023 12:13:51 PM  [*] Mon Jan 30 12:13:51 2023: Train Epoch: 2 [25600/54810 (47%)]	Loss: 209.743698 | Elapsed: 12.53s
01/30/2023 12:14:03 PM  [*] Mon Jan 30 12:14:03 2023: Train Epoch: 2 [32000/54810 (58%)]	Loss: 192.989502 | Elapsed: 12.61s
01/30/2023 12:14:16 PM  [*] Mon Jan 30 12:14:16 2023: Train Epoch: 2 [38400/54810 (70%)]	Loss: 164.346649 | Elapsed: 12.50s
01/30/2023 12:14:28 PM  [*] Mon Jan 30 12:14:28 2023: Train Epoch: 2 [44800/54810 (82%)]	Loss: 172.910645 | Elapsed: 12.57s
01/30/2023 12:14:41 PM  [*] Mon Jan 30 12:14:41 2023: Train Epoch: 2 [51200/54810 (93%)]	Loss: 190.219727 | Elapsed: 12.57s
01/30/2023 12:14:50 PM  [*] Mon Jan 30 12:14:50 2023:    2    | Tr.loss: 185.605035 | Elapsed:  109.39  s
01/30/2023 12:14:50 PM  [*] Started epoch: 3
01/30/2023 12:14:50 PM  [*] Mon Jan 30 12:14:50 2023: Train Epoch: 3 [  0  /54810 (0 %)]	Loss: 166.956665 | Elapsed: 0.12s
01/30/2023 12:15:02 PM  [*] Mon Jan 30 12:15:02 2023: Train Epoch: 3 [6400 /54810 (12%)]	Loss: 178.300507 | Elapsed: 12.58s
01/30/2023 12:15:15 PM  [*] Mon Jan 30 12:15:15 2023: Train Epoch: 3 [12800/54810 (23%)]	Loss: 179.624420 | Elapsed: 12.48s
01/30/2023 12:15:27 PM  [*] Mon Jan 30 12:15:27 2023: Train Epoch: 3 [19200/54810 (35%)]	Loss: 183.240448 | Elapsed: 12.51s
01/30/2023 12:15:40 PM  [*] Mon Jan 30 12:15:40 2023: Train Epoch: 3 [25600/54810 (47%)]	Loss: 173.034164 | Elapsed: 12.51s
01/30/2023 12:15:52 PM  [*] Mon Jan 30 12:15:52 2023: Train Epoch: 3 [32000/54810 (58%)]	Loss: 178.618683 | Elapsed: 12.59s
01/30/2023 12:16:05 PM  [*] Mon Jan 30 12:16:05 2023: Train Epoch: 3 [38400/54810 (70%)]	Loss: 167.776886 | Elapsed: 12.57s
01/30/2023 12:16:17 PM  [*] Mon Jan 30 12:16:17 2023: Train Epoch: 3 [44800/54810 (82%)]	Loss: 168.102417 | Elapsed: 12.49s
01/30/2023 12:16:30 PM  [*] Mon Jan 30 12:16:30 2023: Train Epoch: 3 [51200/54810 (93%)]	Loss: 175.175262 | Elapsed: 12.45s
01/30/2023 12:16:39 PM  [*] Mon Jan 30 12:16:39 2023:    3    | Tr.loss: 180.339830 | Elapsed:  108.95  s
01/30/2023 12:16:39 PM  [*] Started epoch: 4
01/30/2023 12:16:39 PM  [*] Mon Jan 30 12:16:39 2023: Train Epoch: 4 [  0  /54810 (0 %)]	Loss: 171.299011 | Elapsed: 0.13s
01/30/2023 12:16:51 PM  [*] Mon Jan 30 12:16:51 2023: Train Epoch: 4 [6400 /54810 (12%)]	Loss: 183.987671 | Elapsed: 12.65s
01/30/2023 12:17:04 PM  [*] Mon Jan 30 12:17:04 2023: Train Epoch: 4 [12800/54810 (23%)]	Loss: 151.808212 | Elapsed: 12.53s
01/30/2023 12:17:16 PM  [*] Mon Jan 30 12:17:16 2023: Train Epoch: 4 [19200/54810 (35%)]	Loss: 153.675278 | Elapsed: 12.45s
01/30/2023 12:17:29 PM  [*] Mon Jan 30 12:17:29 2023: Train Epoch: 4 [25600/54810 (47%)]	Loss: 171.719971 | Elapsed: 12.47s
01/30/2023 12:17:41 PM  [*] Mon Jan 30 12:17:41 2023: Train Epoch: 4 [32000/54810 (58%)]	Loss: 174.736511 | Elapsed: 12.46s
01/30/2023 12:17:54 PM  [*] Mon Jan 30 12:17:54 2023: Train Epoch: 4 [38400/54810 (70%)]	Loss: 200.177368 | Elapsed: 12.62s
01/30/2023 12:18:06 PM  [*] Mon Jan 30 12:18:06 2023: Train Epoch: 4 [44800/54810 (82%)]	Loss: 181.682404 | Elapsed: 12.54s
01/30/2023 12:18:19 PM  [*] Mon Jan 30 12:18:19 2023: Train Epoch: 4 [51200/54810 (93%)]	Loss: 179.052795 | Elapsed: 12.45s
01/30/2023 12:18:27 PM  [*] Mon Jan 30 12:18:27 2023:    4    | Tr.loss: 177.477090 | Elapsed:  108.92  s
01/30/2023 12:18:27 PM  [*] Started epoch: 5
01/30/2023 12:18:28 PM  [*] Mon Jan 30 12:18:28 2023: Train Epoch: 5 [  0  /54810 (0 %)]	Loss: 176.278107 | Elapsed: 0.13s
01/30/2023 12:18:40 PM  [*] Mon Jan 30 12:18:40 2023: Train Epoch: 5 [6400 /54810 (12%)]	Loss: 159.537155 | Elapsed: 12.53s
01/30/2023 12:18:53 PM  [*] Mon Jan 30 12:18:53 2023: Train Epoch: 5 [12800/54810 (23%)]	Loss: 175.240387 | Elapsed: 12.49s
01/30/2023 12:19:05 PM  [*] Mon Jan 30 12:19:05 2023: Train Epoch: 5 [19200/54810 (35%)]	Loss: 164.489868 | Elapsed: 12.64s
01/30/2023 12:19:18 PM  [*] Mon Jan 30 12:19:18 2023: Train Epoch: 5 [25600/54810 (47%)]	Loss: 169.410721 | Elapsed: 12.48s
01/30/2023 12:19:30 PM  [*] Mon Jan 30 12:19:30 2023: Train Epoch: 5 [32000/54810 (58%)]	Loss: 179.126266 | Elapsed: 12.52s
01/30/2023 12:19:43 PM  [*] Mon Jan 30 12:19:43 2023: Train Epoch: 5 [38400/54810 (70%)]	Loss: 164.445099 | Elapsed: 12.47s
01/30/2023 12:19:55 PM  [*] Mon Jan 30 12:19:55 2023: Train Epoch: 5 [44800/54810 (82%)]	Loss: 164.375549 | Elapsed: 12.54s
01/30/2023 12:20:08 PM  [*] Mon Jan 30 12:20:08 2023: Train Epoch: 5 [51200/54810 (93%)]	Loss: 173.650864 | Elapsed: 12.51s
01/30/2023 12:20:16 PM  [*] Mon Jan 30 12:20:16 2023:    5    | Tr.loss: 175.692941 | Elapsed:  108.95  s
01/30/2023 12:20:16 PM  [*] Started epoch: 6
01/30/2023 12:20:17 PM  [*] Mon Jan 30 12:20:17 2023: Train Epoch: 6 [  0  /54810 (0 %)]	Loss: 183.130219 | Elapsed: 0.14s
01/30/2023 12:20:29 PM  [*] Mon Jan 30 12:20:29 2023: Train Epoch: 6 [6400 /54810 (12%)]	Loss: 165.593628 | Elapsed: 12.52s
01/30/2023 12:20:42 PM  [*] Mon Jan 30 12:20:42 2023: Train Epoch: 6 [12800/54810 (23%)]	Loss: 173.544678 | Elapsed: 12.54s
01/30/2023 12:20:54 PM  [*] Mon Jan 30 12:20:54 2023: Train Epoch: 6 [19200/54810 (35%)]	Loss: 161.782349 | Elapsed: 12.59s
01/30/2023 12:21:07 PM  [*] Mon Jan 30 12:21:07 2023: Train Epoch: 6 [25600/54810 (47%)]	Loss: 190.055878 | Elapsed: 12.57s
01/30/2023 12:21:19 PM  [*] Mon Jan 30 12:21:19 2023: Train Epoch: 6 [32000/54810 (58%)]	Loss: 181.582092 | Elapsed: 12.59s
01/30/2023 12:21:32 PM  [*] Mon Jan 30 12:21:32 2023: Train Epoch: 6 [38400/54810 (70%)]	Loss: 186.301941 | Elapsed: 12.50s
01/30/2023 12:21:45 PM  [*] Mon Jan 30 12:21:45 2023: Train Epoch: 6 [44800/54810 (82%)]	Loss: 164.448105 | Elapsed: 12.63s
01/30/2023 12:21:57 PM  [*] Mon Jan 30 12:21:57 2023: Train Epoch: 6 [51200/54810 (93%)]	Loss: 174.999619 | Elapsed: 12.47s
01/30/2023 12:22:06 PM  [*] Mon Jan 30 12:22:06 2023:    6    | Tr.loss: 174.264549 | Elapsed:  109.19  s
01/30/2023 12:22:06 PM  [*] Started epoch: 7
01/30/2023 12:22:06 PM  [*] Mon Jan 30 12:22:06 2023: Train Epoch: 7 [  0  /54810 (0 %)]	Loss: 180.135300 | Elapsed: 0.12s
01/30/2023 12:22:18 PM  [*] Mon Jan 30 12:22:18 2023: Train Epoch: 7 [6400 /54810 (12%)]	Loss: 167.533722 | Elapsed: 12.67s
01/30/2023 12:22:31 PM  [*] Mon Jan 30 12:22:31 2023: Train Epoch: 7 [12800/54810 (23%)]	Loss: 169.961182 | Elapsed: 12.56s
01/30/2023 12:22:43 PM  [*] Mon Jan 30 12:22:43 2023: Train Epoch: 7 [19200/54810 (35%)]	Loss: 147.226578 | Elapsed: 12.48s
01/30/2023 12:22:56 PM  [*] Mon Jan 30 12:22:56 2023: Train Epoch: 7 [25600/54810 (47%)]	Loss: 169.271561 | Elapsed: 12.55s
01/30/2023 12:23:08 PM  [*] Mon Jan 30 12:23:08 2023: Train Epoch: 7 [32000/54810 (58%)]	Loss: 159.536224 | Elapsed: 12.49s
01/30/2023 12:23:21 PM  [*] Mon Jan 30 12:23:21 2023: Train Epoch: 7 [38400/54810 (70%)]	Loss: 179.788025 | Elapsed: 12.56s
01/30/2023 12:23:34 PM  [*] Mon Jan 30 12:23:34 2023: Train Epoch: 7 [44800/54810 (82%)]	Loss: 154.043884 | Elapsed: 12.57s
01/30/2023 12:23:46 PM  [*] Mon Jan 30 12:23:46 2023: Train Epoch: 7 [51200/54810 (93%)]	Loss: 188.980591 | Elapsed: 12.66s
01/30/2023 12:23:55 PM  [*] Mon Jan 30 12:23:55 2023:    7    | Tr.loss: 173.181731 | Elapsed:  109.36  s
01/30/2023 12:23:55 PM  [*] Started epoch: 8
01/30/2023 12:23:55 PM  [*] Mon Jan 30 12:23:55 2023: Train Epoch: 8 [  0  /54810 (0 %)]	Loss: 197.775650 | Elapsed: 0.13s
01/30/2023 12:24:08 PM  [*] Mon Jan 30 12:24:08 2023: Train Epoch: 8 [6400 /54810 (12%)]	Loss: 194.913300 | Elapsed: 12.50s
01/30/2023 12:24:20 PM  [*] Mon Jan 30 12:24:20 2023: Train Epoch: 8 [12800/54810 (23%)]	Loss: 166.822754 | Elapsed: 12.45s
01/30/2023 12:24:33 PM  [*] Mon Jan 30 12:24:33 2023: Train Epoch: 8 [19200/54810 (35%)]	Loss: 169.642960 | Elapsed: 12.66s
01/30/2023 12:24:45 PM  [*] Mon Jan 30 12:24:45 2023: Train Epoch: 8 [25600/54810 (47%)]	Loss: 179.340149 | Elapsed: 12.49s
01/30/2023 12:24:58 PM  [*] Mon Jan 30 12:24:58 2023: Train Epoch: 8 [32000/54810 (58%)]	Loss: 189.864441 | Elapsed: 12.53s
01/30/2023 12:25:10 PM  [*] Mon Jan 30 12:25:10 2023: Train Epoch: 8 [38400/54810 (70%)]	Loss: 170.244019 | Elapsed: 12.48s
01/30/2023 12:25:23 PM  [*] Mon Jan 30 12:25:23 2023: Train Epoch: 8 [44800/54810 (82%)]	Loss: 164.488708 | Elapsed: 12.51s
01/30/2023 12:25:35 PM  [*] Mon Jan 30 12:25:35 2023: Train Epoch: 8 [51200/54810 (93%)]	Loss: 172.167603 | Elapsed: 12.64s
01/30/2023 12:25:44 PM  [*] Mon Jan 30 12:25:44 2023:    8    | Tr.loss: 172.264526 | Elapsed:  109.06  s
01/30/2023 12:25:44 PM  [*] Started epoch: 9
01/30/2023 12:25:44 PM  [*] Mon Jan 30 12:25:44 2023: Train Epoch: 9 [  0  /54810 (0 %)]	Loss: 183.780609 | Elapsed: 0.13s
01/30/2023 12:25:57 PM  [*] Mon Jan 30 12:25:57 2023: Train Epoch: 9 [6400 /54810 (12%)]	Loss: 163.256226 | Elapsed: 12.55s
01/30/2023 12:26:09 PM  [*] Mon Jan 30 12:26:09 2023: Train Epoch: 9 [12800/54810 (23%)]	Loss: 155.444229 | Elapsed: 12.58s
01/30/2023 12:26:22 PM  [*] Mon Jan 30 12:26:22 2023: Train Epoch: 9 [19200/54810 (35%)]	Loss: 192.670273 | Elapsed: 12.51s
01/30/2023 12:26:34 PM  [*] Mon Jan 30 12:26:34 2023: Train Epoch: 9 [25600/54810 (47%)]	Loss: 183.463440 | Elapsed: 12.49s
01/30/2023 12:26:47 PM  [*] Mon Jan 30 12:26:47 2023: Train Epoch: 9 [32000/54810 (58%)]	Loss: 194.007812 | Elapsed: 12.47s
01/30/2023 12:26:59 PM  [*] Mon Jan 30 12:26:59 2023: Train Epoch: 9 [38400/54810 (70%)]	Loss: 155.267426 | Elapsed: 12.49s
01/30/2023 12:27:12 PM  [*] Mon Jan 30 12:27:12 2023: Train Epoch: 9 [44800/54810 (82%)]	Loss: 167.322952 | Elapsed: 12.71s
01/30/2023 12:27:24 PM  [*] Mon Jan 30 12:27:24 2023: Train Epoch: 9 [51200/54810 (93%)]	Loss: 175.703766 | Elapsed: 12.50s
01/30/2023 12:27:33 PM  [*] Mon Jan 30 12:27:33 2023:    9    | Tr.loss: 171.582737 | Elapsed:  109.11  s
01/30/2023 12:27:33 PM  [*] Started epoch: 10
01/30/2023 12:27:33 PM  [*] Mon Jan 30 12:27:33 2023: Train Epoch: 10 [  0  /54810 (0 %)]	Loss: 172.262115 | Elapsed: 0.13s
01/30/2023 12:27:46 PM  [*] Mon Jan 30 12:27:46 2023: Train Epoch: 10 [6400 /54810 (12%)]	Loss: 163.629501 | Elapsed: 12.57s
01/30/2023 12:27:58 PM  [*] Mon Jan 30 12:27:58 2023: Train Epoch: 10 [12800/54810 (23%)]	Loss: 181.635101 | Elapsed: 12.59s
01/30/2023 12:28:11 PM  [*] Mon Jan 30 12:28:11 2023: Train Epoch: 10 [19200/54810 (35%)]	Loss: 179.002686 | Elapsed: 12.53s
01/30/2023 12:28:24 PM  [*] Mon Jan 30 12:28:24 2023: Train Epoch: 10 [25600/54810 (47%)]	Loss: 168.958282 | Elapsed: 12.57s
01/30/2023 12:28:36 PM  [*] Mon Jan 30 12:28:36 2023: Train Epoch: 10 [32000/54810 (58%)]	Loss: 159.091187 | Elapsed: 12.54s
01/30/2023 12:28:49 PM  [*] Mon Jan 30 12:28:49 2023: Train Epoch: 10 [38400/54810 (70%)]	Loss: 152.876373 | Elapsed: 12.57s
01/30/2023 12:29:01 PM  [*] Mon Jan 30 12:29:01 2023: Train Epoch: 10 [44800/54810 (82%)]	Loss: 168.952576 | Elapsed: 12.53s
01/30/2023 12:29:14 PM  [*] Mon Jan 30 12:29:14 2023: Train Epoch: 10 [51200/54810 (93%)]	Loss: 161.916107 | Elapsed: 12.68s
01/30/2023 12:29:23 PM  [*] Mon Jan 30 12:29:23 2023:   10    | Tr.loss: 171.002855 | Elapsed:  109.55  s
01/30/2023 12:29:23 PM [!] Mon Jan 30 12:29:23 2023: Dumped results:
                model     : 1675078163-model.torch
		train time: 1675078163-trainTime.npy
		train losses: 1675078163-trainLosses.npy
		train AUC: 1675078163-auc.npy
01/30/2023 12:29:25 PM  [!] Training pretrained model on downstream task...
01/30/2023 12:29:25 PM  [*] Started epoch: 1
01/30/2023 12:29:25 PM  [*] Mon Jan 30 12:29:25 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 2.528985 | Elapsed: 0.23s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.5128
01/30/2023 12:29:35 PM  [*] Mon Jan 30 12:29:35 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.402914 | Elapsed: 9.23s | FPR 0.0003 -> TPR 0.2533 & F1 0.4043 | AUC 0.8040
01/30/2023 12:29:36 PM  [*] Mon Jan 30 12:29:36 2023:    1    | Tr.loss: 0.595294 | Elapsed:   11.35  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7900
01/30/2023 12:29:36 PM  [*] Started epoch: 2
01/30/2023 12:29:37 PM  [*] Mon Jan 30 12:29:37 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.349022 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.5385 & F1 0.7000 | AUC 0.8349
01/30/2023 12:29:46 PM  [*] Mon Jan 30 12:29:46 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.346903 | Elapsed: 9.17s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.8681
01/30/2023 12:29:48 PM  [*] Mon Jan 30 12:29:48 2023:    2    | Tr.loss: 0.342971 | Elapsed:   11.09  s | FPR 0.0003 -> TPR: 0.01 & F1: 0.02 | AUC: 0.9128
01/30/2023 12:29:48 PM  [*] Started epoch: 3
01/30/2023 12:29:48 PM  [*] Mon Jan 30 12:29:48 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.244295 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.8723 & F1 0.9318 | AUC 0.9606
01/30/2023 12:29:57 PM  [*] Mon Jan 30 12:29:57 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.333567 | Elapsed: 9.16s | FPR 0.0003 -> TPR 0.3485 & F1 0.5169 | AUC 0.9084
01/30/2023 12:29:59 PM  [*] Mon Jan 30 12:29:59 2023:    3    | Tr.loss: 0.286707 | Elapsed:   11.08  s | FPR 0.0003 -> TPR: 0.22 & F1: 0.35 | AUC: 0.9424
01/30/2023 12:29:59 PM [!] Mon Jan 30 12:29:59 2023: Dumped results:
                model     : 1675078199-model.torch
		train time: 1675078199-trainTime.npy
		train losses: 1675078199-trainLosses.npy
		train AUC: 1675078199-auc.npy
		train F1s : 1675078199-trainF1s.npy
		train TPRs: 1675078199-trainTPRs.npy
01/30/2023 12:29:59 PM  [!] Training non_pretrained model on downstream task...
01/30/2023 12:30:00 PM  [*] Started epoch: 1
01/30/2023 12:30:00 PM  [*] Mon Jan 30 12:30:00 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 1.813542 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0238 & F1 0.0465 | AUC 0.6331
01/30/2023 12:30:06 PM  [*] Mon Jan 30 12:30:06 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.479285 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.5484 & F1 0.7083 | AUC 0.8701
01/30/2023 12:30:07 PM  [*] Mon Jan 30 12:30:07 2023:    1    | Tr.loss: 0.595431 | Elapsed:   7.66   s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7491
01/30/2023 12:30:07 PM  [*] Started epoch: 2
01/30/2023 12:30:07 PM  [*] Mon Jan 30 12:30:07 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.388430 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.3250 & F1 0.4906 | AUC 0.8833
01/30/2023 12:30:14 PM  [*] Mon Jan 30 12:30:14 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.378340 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.5139 & F1 0.6789 | AUC 0.8998
01/30/2023 12:30:15 PM  [*] Mon Jan 30 12:30:15 2023:    2    | Tr.loss: 0.373748 | Elapsed:   7.59   s | FPR 0.0003 -> TPR: 0.13 & F1: 0.24 | AUC: 0.8874
01/30/2023 12:30:15 PM  [*] Started epoch: 3
01/30/2023 12:30:15 PM  [*] Mon Jan 30 12:30:15 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.276597 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.5750 & F1 0.7302 | AUC 0.9510
01/30/2023 12:30:21 PM  [*] Mon Jan 30 12:30:21 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.219606 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.7857 & F1 0.8800 | AUC 0.9667
01/30/2023 12:30:22 PM  [*] Mon Jan 30 12:30:22 2023:    3    | Tr.loss: 0.310686 | Elapsed:   7.63   s | FPR 0.0003 -> TPR: 0.13 & F1: 0.23 | AUC: 0.9266
01/30/2023 12:30:23 PM [!] Mon Jan 30 12:30:23 2023: Dumped results:
                model     : 1675078222-model.torch
		train time: 1675078222-trainTime.npy
		train losses: 1675078222-trainLosses.npy
		train AUC: 1675078222-auc.npy
		train F1s : 1675078222-trainF1s.npy
		train TPRs: 1675078222-trainTPRs.npy
01/30/2023 12:30:23 PM  [*] Evaluating pretrained model on test set...
01/30/2023 12:30:28 PM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0931 | F1: 0.1703
01/30/2023 12:30:28 PM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.2180 | F1: 0.3579
01/30/2023 12:30:28 PM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.2881 | F1: 0.4470
01/30/2023 12:30:28 PM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3671 | F1: 0.5361
01/30/2023 12:30:28 PM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.4483 | F1: 0.6154
01/30/2023 12:30:28 PM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.5245 | F1: 0.6768
01/30/2023 12:30:28 PM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.6821 | F1: 0.7720
01/30/2023 12:30:28 PM  [*] Evaluating non_pretrained model on test set...
01/30/2023 12:30:33 PM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0612 | F1: 0.1153
01/30/2023 12:30:33 PM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1255 | F1: 0.2230
01/30/2023 12:30:33 PM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.1769 | F1: 0.3003
01/30/2023 12:30:33 PM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.2295 | F1: 0.3726
01/30/2023 12:30:33 PM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.2927 | F1: 0.4499
01/30/2023 12:30:33 PM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.3986 | F1: 0.5598
01/30/2023 12:30:33 PM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.5942 | F1: 0.7077
01/30/2023 12:30:33 PM  [!] Running pre-training split 3/3
01/30/2023 12:30:36 PM  [!] Pre-training model...
01/30/2023 12:30:36 PM  [*] Masking sequences...
01/30/2023 12:30:54 PM  [*] Started epoch: 1
01/30/2023 12:30:54 PM  [*] Mon Jan 30 12:30:54 2023: Train Epoch: 1 [  0  /54810 (0 %)]	Loss: 392.457977 | Elapsed: 0.41s
01/30/2023 12:31:07 PM  [*] Mon Jan 30 12:31:07 2023: Train Epoch: 1 [6400 /54810 (12%)]	Loss: 219.871033 | Elapsed: 12.37s
01/30/2023 12:31:19 PM  [*] Mon Jan 30 12:31:19 2023: Train Epoch: 1 [12800/54810 (23%)]	Loss: 239.011902 | Elapsed: 12.50s
01/30/2023 12:31:32 PM  [*] Mon Jan 30 12:31:32 2023: Train Epoch: 1 [19200/54810 (35%)]	Loss: 222.881424 | Elapsed: 12.50s
01/30/2023 12:31:44 PM  [*] Mon Jan 30 12:31:44 2023: Train Epoch: 1 [25600/54810 (47%)]	Loss: 228.419678 | Elapsed: 12.52s
01/30/2023 12:31:57 PM  [*] Mon Jan 30 12:31:57 2023: Train Epoch: 1 [32000/54810 (58%)]	Loss: 213.251709 | Elapsed: 12.60s
01/30/2023 12:32:09 PM  [*] Mon Jan 30 12:32:09 2023: Train Epoch: 1 [38400/54810 (70%)]	Loss: 191.128174 | Elapsed: 12.50s
01/30/2023 12:32:22 PM  [*] Mon Jan 30 12:32:22 2023: Train Epoch: 1 [44800/54810 (82%)]	Loss: 205.425354 | Elapsed: 12.51s
01/30/2023 12:32:34 PM  [*] Mon Jan 30 12:32:34 2023: Train Epoch: 1 [51200/54810 (93%)]	Loss: 193.279587 | Elapsed: 12.54s
01/30/2023 12:32:43 PM  [*] Mon Jan 30 12:32:43 2023:    1    | Tr.loss: 210.422422 | Elapsed:  109.17  s
01/30/2023 12:32:43 PM  [*] Started epoch: 2
01/30/2023 12:32:43 PM  [*] Mon Jan 30 12:32:43 2023: Train Epoch: 2 [  0  /54810 (0 %)]	Loss: 202.399414 | Elapsed: 0.13s
01/30/2023 12:32:56 PM  [*] Mon Jan 30 12:32:56 2023: Train Epoch: 2 [6400 /54810 (12%)]	Loss: 184.067474 | Elapsed: 12.64s
01/30/2023 12:33:08 PM  [*] Mon Jan 30 12:33:08 2023: Train Epoch: 2 [12800/54810 (23%)]	Loss: 188.405243 | Elapsed: 12.55s
01/30/2023 12:33:21 PM  [*] Mon Jan 30 12:33:21 2023: Train Epoch: 2 [19200/54810 (35%)]	Loss: 172.152985 | Elapsed: 12.57s
01/30/2023 12:33:33 PM  [*] Mon Jan 30 12:33:33 2023: Train Epoch: 2 [25600/54810 (47%)]	Loss: 182.443405 | Elapsed: 12.50s
01/30/2023 12:33:46 PM  [*] Mon Jan 30 12:33:46 2023: Train Epoch: 2 [32000/54810 (58%)]	Loss: 177.187347 | Elapsed: 12.51s
01/30/2023 12:33:59 PM  [*] Mon Jan 30 12:33:59 2023: Train Epoch: 2 [38400/54810 (70%)]	Loss: 168.560059 | Elapsed: 12.63s
01/30/2023 12:34:11 PM  [*] Mon Jan 30 12:34:11 2023: Train Epoch: 2 [44800/54810 (82%)]	Loss: 184.829926 | Elapsed: 12.58s
01/30/2023 12:34:24 PM  [*] Mon Jan 30 12:34:24 2023: Train Epoch: 2 [51200/54810 (93%)]	Loss: 183.942825 | Elapsed: 12.53s
01/30/2023 12:34:32 PM  [*] Mon Jan 30 12:34:32 2023:    2    | Tr.loss: 189.203001 | Elapsed:  109.32  s
01/30/2023 12:34:32 PM  [*] Started epoch: 3
01/30/2023 12:34:32 PM  [*] Mon Jan 30 12:34:32 2023: Train Epoch: 3 [  0  /54810 (0 %)]	Loss: 194.999329 | Elapsed: 0.13s
01/30/2023 12:34:45 PM  [*] Mon Jan 30 12:34:45 2023: Train Epoch: 3 [6400 /54810 (12%)]	Loss: 183.331573 | Elapsed: 12.63s
01/30/2023 12:34:58 PM  [*] Mon Jan 30 12:34:58 2023: Train Epoch: 3 [12800/54810 (23%)]	Loss: 175.353409 | Elapsed: 12.58s
01/30/2023 12:35:10 PM  [*] Mon Jan 30 12:35:10 2023: Train Epoch: 3 [19200/54810 (35%)]	Loss: 193.332642 | Elapsed: 12.56s
01/30/2023 12:35:23 PM  [*] Mon Jan 30 12:35:23 2023: Train Epoch: 3 [25600/54810 (47%)]	Loss: 174.716888 | Elapsed: 12.55s
01/30/2023 12:35:35 PM  [*] Mon Jan 30 12:35:35 2023: Train Epoch: 3 [32000/54810 (58%)]	Loss: 201.012177 | Elapsed: 12.58s
01/30/2023 12:35:48 PM  [*] Mon Jan 30 12:35:48 2023: Train Epoch: 3 [38400/54810 (70%)]	Loss: 187.768738 | Elapsed: 12.61s
01/30/2023 12:36:01 PM  [*] Mon Jan 30 12:36:01 2023: Train Epoch: 3 [44800/54810 (82%)]	Loss: 154.880814 | Elapsed: 12.56s
01/30/2023 12:36:13 PM  [*] Mon Jan 30 12:36:13 2023: Train Epoch: 3 [51200/54810 (93%)]	Loss: 176.165436 | Elapsed: 12.57s
01/30/2023 12:36:22 PM  [*] Mon Jan 30 12:36:22 2023:    3    | Tr.loss: 184.075528 | Elapsed:  109.44  s
01/30/2023 12:36:22 PM  [*] Started epoch: 4
01/30/2023 12:36:22 PM  [*] Mon Jan 30 12:36:22 2023: Train Epoch: 4 [  0  /54810 (0 %)]	Loss: 181.607452 | Elapsed: 0.13s
01/30/2023 12:36:34 PM  [*] Mon Jan 30 12:36:34 2023: Train Epoch: 4 [6400 /54810 (12%)]	Loss: 188.266647 | Elapsed: 12.48s
01/30/2023 12:36:47 PM  [*] Mon Jan 30 12:36:47 2023: Train Epoch: 4 [12800/54810 (23%)]	Loss: 173.391418 | Elapsed: 12.54s
01/30/2023 12:37:00 PM  [*] Mon Jan 30 12:37:00 2023: Train Epoch: 4 [19200/54810 (35%)]	Loss: 183.859406 | Elapsed: 12.68s
01/30/2023 12:37:12 PM  [*] Mon Jan 30 12:37:12 2023: Train Epoch: 4 [25600/54810 (47%)]	Loss: 161.700592 | Elapsed: 12.57s
01/30/2023 12:37:25 PM  [*] Mon Jan 30 12:37:25 2023: Train Epoch: 4 [32000/54810 (58%)]	Loss: 194.902985 | Elapsed: 12.49s
01/30/2023 12:37:37 PM  [*] Mon Jan 30 12:37:37 2023: Train Epoch: 4 [38400/54810 (70%)]	Loss: 191.094009 | Elapsed: 12.40s
01/30/2023 12:37:50 PM  [*] Mon Jan 30 12:37:50 2023: Train Epoch: 4 [44800/54810 (82%)]	Loss: 173.866150 | Elapsed: 12.47s
01/30/2023 12:38:02 PM  [*] Mon Jan 30 12:38:02 2023: Train Epoch: 4 [51200/54810 (93%)]	Loss: 189.039734 | Elapsed: 12.54s
01/30/2023 12:38:11 PM  [*] Mon Jan 30 12:38:11 2023:    4    | Tr.loss: 181.386028 | Elapsed:  108.97  s
01/30/2023 12:38:11 PM  [*] Started epoch: 5
01/30/2023 12:38:11 PM  [*] Mon Jan 30 12:38:11 2023: Train Epoch: 5 [  0  /54810 (0 %)]	Loss: 187.354736 | Elapsed: 0.13s
01/30/2023 12:38:24 PM  [*] Mon Jan 30 12:38:24 2023: Train Epoch: 5 [6400 /54810 (12%)]	Loss: 153.774689 | Elapsed: 12.66s
01/30/2023 12:38:36 PM  [*] Mon Jan 30 12:38:36 2023: Train Epoch: 5 [12800/54810 (23%)]	Loss: 192.768280 | Elapsed: 12.56s
01/30/2023 12:38:49 PM  [*] Mon Jan 30 12:38:49 2023: Train Epoch: 5 [19200/54810 (35%)]	Loss: 163.359955 | Elapsed: 12.53s
01/30/2023 12:39:01 PM  [*] Mon Jan 30 12:39:01 2023: Train Epoch: 5 [25600/54810 (47%)]	Loss: 168.829483 | Elapsed: 12.56s
01/30/2023 12:39:14 PM  [*] Mon Jan 30 12:39:14 2023: Train Epoch: 5 [32000/54810 (58%)]	Loss: 170.039810 | Elapsed: 12.52s
01/30/2023 12:39:26 PM  [*] Mon Jan 30 12:39:26 2023: Train Epoch: 5 [38400/54810 (70%)]	Loss: 170.187531 | Elapsed: 12.55s
01/30/2023 12:39:39 PM  [*] Mon Jan 30 12:39:39 2023: Train Epoch: 5 [44800/54810 (82%)]	Loss: 168.649063 | Elapsed: 12.52s
01/30/2023 12:39:51 PM  [*] Mon Jan 30 12:39:51 2023: Train Epoch: 5 [51200/54810 (93%)]	Loss: 177.949448 | Elapsed: 12.50s
01/30/2023 12:40:00 PM  [*] Mon Jan 30 12:40:00 2023:    5    | Tr.loss: 179.540245 | Elapsed:  109.23  s
01/30/2023 12:40:00 PM  [*] Started epoch: 6
01/30/2023 12:40:00 PM  [*] Mon Jan 30 12:40:00 2023: Train Epoch: 6 [  0  /54810 (0 %)]	Loss: 175.567719 | Elapsed: 0.11s
01/30/2023 12:40:13 PM  [*] Mon Jan 30 12:40:13 2023: Train Epoch: 6 [6400 /54810 (12%)]	Loss: 165.850113 | Elapsed: 12.59s
01/30/2023 12:40:25 PM  [*] Mon Jan 30 12:40:25 2023: Train Epoch: 6 [12800/54810 (23%)]	Loss: 209.894623 | Elapsed: 12.62s
01/30/2023 12:40:38 PM  [*] Mon Jan 30 12:40:38 2023: Train Epoch: 6 [19200/54810 (35%)]	Loss: 174.540863 | Elapsed: 12.52s
01/30/2023 12:40:50 PM  [*] Mon Jan 30 12:40:50 2023: Train Epoch: 6 [25600/54810 (47%)]	Loss: 170.239777 | Elapsed: 12.44s
01/30/2023 12:41:03 PM  [*] Mon Jan 30 12:41:03 2023: Train Epoch: 6 [32000/54810 (58%)]	Loss: 171.103760 | Elapsed: 12.50s
01/30/2023 12:41:15 PM  [*] Mon Jan 30 12:41:15 2023: Train Epoch: 6 [38400/54810 (70%)]	Loss: 158.809784 | Elapsed: 12.56s
01/30/2023 12:41:28 PM  [*] Mon Jan 30 12:41:28 2023: Train Epoch: 6 [44800/54810 (82%)]	Loss: 196.827820 | Elapsed: 12.67s
01/30/2023 12:41:41 PM  [*] Mon Jan 30 12:41:41 2023: Train Epoch: 6 [51200/54810 (93%)]	Loss: 165.764648 | Elapsed: 12.60s
01/30/2023 12:41:49 PM  [*] Mon Jan 30 12:41:49 2023:    6    | Tr.loss: 178.300080 | Elapsed:  109.23  s
01/30/2023 12:41:49 PM  [*] Started epoch: 7
01/30/2023 12:41:49 PM  [*] Mon Jan 30 12:41:49 2023: Train Epoch: 7 [  0  /54810 (0 %)]	Loss: 175.975052 | Elapsed: 0.13s
01/30/2023 12:42:02 PM  [*] Mon Jan 30 12:42:02 2023: Train Epoch: 7 [6400 /54810 (12%)]	Loss: 176.765991 | Elapsed: 12.63s
01/30/2023 12:42:14 PM  [*] Mon Jan 30 12:42:14 2023: Train Epoch: 7 [12800/54810 (23%)]	Loss: 181.814407 | Elapsed: 12.48s
01/30/2023 12:42:27 PM  [*] Mon Jan 30 12:42:27 2023: Train Epoch: 7 [19200/54810 (35%)]	Loss: 188.005890 | Elapsed: 12.51s
01/30/2023 12:42:39 PM  [*] Mon Jan 30 12:42:39 2023: Train Epoch: 7 [25600/54810 (47%)]	Loss: 187.960236 | Elapsed: 12.53s
01/30/2023 12:42:52 PM  [*] Mon Jan 30 12:42:52 2023: Train Epoch: 7 [32000/54810 (58%)]	Loss: 205.866089 | Elapsed: 12.37s
01/30/2023 12:43:04 PM  [*] Mon Jan 30 12:43:04 2023: Train Epoch: 7 [38400/54810 (70%)]	Loss: 175.432526 | Elapsed: 12.52s
01/30/2023 12:43:17 PM  [*] Mon Jan 30 12:43:17 2023: Train Epoch: 7 [44800/54810 (82%)]	Loss: 164.918579 | Elapsed: 12.47s
01/30/2023 12:43:29 PM  [*] Mon Jan 30 12:43:29 2023: Train Epoch: 7 [51200/54810 (93%)]	Loss: 176.167038 | Elapsed: 12.46s
01/30/2023 12:43:38 PM  [*] Mon Jan 30 12:43:38 2023:    7    | Tr.loss: 177.230479 | Elapsed:  108.80  s
01/30/2023 12:43:38 PM  [*] Started epoch: 8
01/30/2023 12:43:38 PM  [*] Mon Jan 30 12:43:38 2023: Train Epoch: 8 [  0  /54810 (0 %)]	Loss: 168.529236 | Elapsed: 0.13s
01/30/2023 12:43:51 PM  [*] Mon Jan 30 12:43:51 2023: Train Epoch: 8 [6400 /54810 (12%)]	Loss: 177.426178 | Elapsed: 12.65s
01/30/2023 12:44:03 PM  [*] Mon Jan 30 12:44:03 2023: Train Epoch: 8 [12800/54810 (23%)]	Loss: 158.602142 | Elapsed: 12.53s
01/30/2023 12:44:16 PM  [*] Mon Jan 30 12:44:16 2023: Train Epoch: 8 [19200/54810 (35%)]	Loss: 178.563950 | Elapsed: 12.46s
01/30/2023 12:44:28 PM  [*] Mon Jan 30 12:44:28 2023: Train Epoch: 8 [25600/54810 (47%)]	Loss: 152.732330 | Elapsed: 12.46s
01/30/2023 12:44:41 PM  [*] Mon Jan 30 12:44:41 2023: Train Epoch: 8 [32000/54810 (58%)]	Loss: 160.628418 | Elapsed: 12.52s
01/30/2023 12:44:53 PM  [*] Mon Jan 30 12:44:53 2023: Train Epoch: 8 [38400/54810 (70%)]	Loss: 189.149902 | Elapsed: 12.51s
01/30/2023 12:45:06 PM  [*] Mon Jan 30 12:45:06 2023: Train Epoch: 8 [44800/54810 (82%)]	Loss: 170.991577 | Elapsed: 12.41s
01/30/2023 12:45:18 PM  [*] Mon Jan 30 12:45:18 2023: Train Epoch: 8 [51200/54810 (93%)]	Loss: 153.527374 | Elapsed: 12.44s
01/30/2023 12:45:27 PM  [*] Mon Jan 30 12:45:27 2023:    8    | Tr.loss: 176.439007 | Elapsed:  108.77  s
01/30/2023 12:45:27 PM  [*] Started epoch: 9
01/30/2023 12:45:27 PM  [*] Mon Jan 30 12:45:27 2023: Train Epoch: 9 [  0  /54810 (0 %)]	Loss: 177.515991 | Elapsed: 0.14s
01/30/2023 12:45:40 PM  [*] Mon Jan 30 12:45:40 2023: Train Epoch: 9 [6400 /54810 (12%)]	Loss: 161.994843 | Elapsed: 12.63s
01/30/2023 12:45:52 PM  [*] Mon Jan 30 12:45:52 2023: Train Epoch: 9 [12800/54810 (23%)]	Loss: 172.042160 | Elapsed: 12.56s
01/30/2023 12:46:05 PM  [*] Mon Jan 30 12:46:05 2023: Train Epoch: 9 [19200/54810 (35%)]	Loss: 181.832123 | Elapsed: 12.55s
01/30/2023 12:46:17 PM  [*] Mon Jan 30 12:46:17 2023: Train Epoch: 9 [25600/54810 (47%)]	Loss: 167.791595 | Elapsed: 12.48s
01/30/2023 12:46:30 PM  [*] Mon Jan 30 12:46:30 2023: Train Epoch: 9 [32000/54810 (58%)]	Loss: 172.439636 | Elapsed: 12.49s
01/30/2023 12:46:42 PM  [*] Mon Jan 30 12:46:42 2023: Train Epoch: 9 [38400/54810 (70%)]	Loss: 160.339386 | Elapsed: 12.48s
01/30/2023 12:46:55 PM  [*] Mon Jan 30 12:46:55 2023: Train Epoch: 9 [44800/54810 (82%)]	Loss: 183.597107 | Elapsed: 12.60s
01/30/2023 12:47:07 PM  [*] Mon Jan 30 12:47:07 2023: Train Epoch: 9 [51200/54810 (93%)]	Loss: 189.602509 | Elapsed: 12.64s
01/30/2023 12:47:16 PM  [*] Mon Jan 30 12:47:16 2023:    9    | Tr.loss: 175.704713 | Elapsed:  109.18  s
01/30/2023 12:47:16 PM  [*] Started epoch: 10
01/30/2023 12:47:16 PM  [*] Mon Jan 30 12:47:16 2023: Train Epoch: 10 [  0  /54810 (0 %)]	Loss: 170.471466 | Elapsed: 0.13s
01/30/2023 12:47:29 PM  [*] Mon Jan 30 12:47:29 2023: Train Epoch: 10 [6400 /54810 (12%)]	Loss: 160.739471 | Elapsed: 12.64s
01/30/2023 12:47:41 PM  [*] Mon Jan 30 12:47:41 2023: Train Epoch: 10 [12800/54810 (23%)]	Loss: 190.808868 | Elapsed: 12.55s
01/30/2023 12:47:54 PM  [*] Mon Jan 30 12:47:54 2023: Train Epoch: 10 [19200/54810 (35%)]	Loss: 184.994293 | Elapsed: 12.50s
01/30/2023 12:48:06 PM  [*] Mon Jan 30 12:48:06 2023: Train Epoch: 10 [25600/54810 (47%)]	Loss: 179.630554 | Elapsed: 12.58s
01/30/2023 12:48:19 PM  [*] Mon Jan 30 12:48:19 2023: Train Epoch: 10 [32000/54810 (58%)]	Loss: 189.961670 | Elapsed: 12.73s
01/30/2023 12:48:32 PM  [*] Mon Jan 30 12:48:32 2023: Train Epoch: 10 [38400/54810 (70%)]	Loss: 172.444290 | Elapsed: 12.41s
01/30/2023 12:48:44 PM  [*] Mon Jan 30 12:48:44 2023: Train Epoch: 10 [44800/54810 (82%)]	Loss: 181.031097 | Elapsed: 12.58s
01/30/2023 12:48:57 PM  [*] Mon Jan 30 12:48:57 2023: Train Epoch: 10 [51200/54810 (93%)]	Loss: 171.107498 | Elapsed: 12.53s
01/30/2023 12:49:05 PM  [*] Mon Jan 30 12:49:05 2023:   10    | Tr.loss: 175.054172 | Elapsed:  109.38  s
01/30/2023 12:49:06 PM [!] Mon Jan 30 12:49:06 2023: Dumped results:
                model     : 1675079345-model.torch
		train time: 1675079345-trainTime.npy
		train losses: 1675079345-trainLosses.npy
		train AUC: 1675079345-auc.npy
01/30/2023 12:49:08 PM  [!] Training pretrained model on downstream task...
01/30/2023 12:49:08 PM  [*] Started epoch: 1
01/30/2023 12:49:08 PM  [*] Mon Jan 30 12:49:08 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 2.875279 | Elapsed: 0.33s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.5249
01/30/2023 12:49:17 PM  [*] Mon Jan 30 12:49:17 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.487000 | Elapsed: 9.20s | FPR 0.0003 -> TPR 0.1111 & F1 0.2000 | AUC 0.7949
01/30/2023 12:49:19 PM  [*] Mon Jan 30 12:49:19 2023:    1    | Tr.loss: 0.662000 | Elapsed:   11.43  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7516
01/30/2023 12:49:19 PM  [*] Started epoch: 2
01/30/2023 12:49:19 PM  [*] Mon Jan 30 12:49:19 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.363370 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.5745 & F1 0.7297 | AUC 0.9099
01/30/2023 12:49:28 PM  [*] Mon Jan 30 12:49:28 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.455626 | Elapsed: 9.13s | FPR 0.0003 -> TPR 0.4545 & F1 0.6250 | AUC 0.8106
01/30/2023 12:49:30 PM  [*] Mon Jan 30 12:49:30 2023:    2    | Tr.loss: 0.393137 | Elapsed:   11.05  s | FPR 0.0003 -> TPR: 0.20 & F1: 0.33 | AUC: 0.8744
01/30/2023 12:49:30 PM  [*] Started epoch: 3
01/30/2023 12:49:30 PM  [*] Mon Jan 30 12:49:30 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.390580 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.6053 & F1 0.7541 | AUC 0.8613
01/30/2023 12:49:39 PM  [*] Mon Jan 30 12:49:39 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.262713 | Elapsed: 9.15s | FPR 0.0003 -> TPR 0.7761 & F1 0.8739 | AUC 0.9525
01/30/2023 12:49:41 PM  [*] Mon Jan 30 12:49:41 2023:    3    | Tr.loss: 0.340180 | Elapsed:   11.08  s | FPR 0.0003 -> TPR: 0.08 & F1: 0.15 | AUC: 0.9101
01/30/2023 12:49:42 PM [!] Mon Jan 30 12:49:42 2023: Dumped results:
                model     : 1675079381-model.torch
		train time: 1675079381-trainTime.npy
		train losses: 1675079381-trainLosses.npy
		train AUC: 1675079381-auc.npy
		train F1s : 1675079381-trainF1s.npy
		train TPRs: 1675079381-trainTPRs.npy
01/30/2023 12:49:42 PM  [!] Training non_pretrained model on downstream task...
01/30/2023 12:49:42 PM  [*] Started epoch: 1
01/30/2023 12:49:42 PM  [*] Mon Jan 30 12:49:42 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 2.473320 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0408 & F1 0.0784 | AUC 0.6680
01/30/2023 12:49:48 PM  [*] Mon Jan 30 12:49:48 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.438539 | Elapsed: 6.26s | FPR 0.0003 -> TPR 0.3824 & F1 0.5532 | AUC 0.8235
01/30/2023 12:49:50 PM  [*] Mon Jan 30 12:49:50 2023:    1    | Tr.loss: 0.677131 | Elapsed:   7.70   s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7148
01/30/2023 12:49:50 PM  [*] Started epoch: 2
01/30/2023 12:49:50 PM  [*] Mon Jan 30 12:49:50 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.538129 | Elapsed: 0.05s | FPR 0.0003 -> TPR 0.1556 & F1 0.2692 | AUC 0.7567
01/30/2023 12:49:56 PM  [*] Mon Jan 30 12:49:56 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.296532 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.3623 & F1 0.5319 | AUC 0.8855
01/30/2023 12:49:57 PM  [*] Mon Jan 30 12:49:57 2023:    2    | Tr.loss: 0.402012 | Elapsed:   7.61   s | FPR 0.0003 -> TPR: 0.10 & F1: 0.18 | AUC: 0.8696
01/30/2023 12:49:57 PM  [*] Started epoch: 3
01/30/2023 12:49:57 PM  [*] Mon Jan 30 12:49:57 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.292058 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.7609 & F1 0.8642 | AUC 0.9444
01/30/2023 12:50:04 PM  [*] Mon Jan 30 12:50:04 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.376446 | Elapsed: 6.26s | FPR 0.0003 -> TPR 0.2586 & F1 0.4110 | AUC 0.8892
01/30/2023 12:50:05 PM  [*] Mon Jan 30 12:50:05 2023:    3    | Tr.loss: 0.346874 | Elapsed:   7.62   s | FPR 0.0003 -> TPR: 0.15 & F1: 0.26 | AUC: 0.9074
01/30/2023 12:50:05 PM [!] Mon Jan 30 12:50:05 2023: Dumped results:
                model     : 1675079405-model.torch
		train time: 1675079405-trainTime.npy
		train losses: 1675079405-trainLosses.npy
		train AUC: 1675079405-auc.npy
		train F1s : 1675079405-trainF1s.npy
		train TPRs: 1675079405-trainTPRs.npy
01/30/2023 12:50:05 PM  [*] Evaluating pretrained model on test set...
01/30/2023 12:50:10 PM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.1313 | F1: 0.2322
01/30/2023 12:50:10 PM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.2319 | F1: 0.3765
01/30/2023 12:50:10 PM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.3025 | F1: 0.4641
01/30/2023 12:50:10 PM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3564 | F1: 0.5245
01/30/2023 12:50:10 PM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.4203 | F1: 0.5883
01/30/2023 12:50:10 PM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4800 | F1: 0.6376
01/30/2023 12:50:10 PM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.6356 | F1: 0.7388
01/30/2023 12:50:10 PM  [*] Evaluating non_pretrained model on test set...
01/30/2023 12:50:15 PM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0382 | F1: 0.0736
01/30/2023 12:50:15 PM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1085 | F1: 0.1957
01/30/2023 12:50:15 PM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.1898 | F1: 0.3189
01/30/2023 12:50:15 PM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.2817 | F1: 0.4387
01/30/2023 12:50:15 PM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3692 | F1: 0.5360
01/30/2023 12:50:15 PM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4713 | F1: 0.6298
01/30/2023 12:50:15 PM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.6146 | F1: 0.7232
01/30/2023 12:50:15 PM  [!] Finished pre-training evaluation over 3 splits! Saved metrics to:
	C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\downsample_tests\downsample_U_0.8_1675075867/metrics_MaskedLanguageModel_nSplits_3_limit_None.json
01/30/2023 12:50:16 PM  [!] Starting uSize downsample 0.9 evaluation!
01/30/2023 12:50:16 PM  [!] Starting Masked Language Model evaluation over 3 splits!
01/30/2023 12:50:16 PM  [!] Loaded data and vocab. X train size: (76126, 512), X test size: (17407, 512), vocab size: 50002
01/30/2023 12:50:16 PM  [!] Initiating Self-Supervised Learning Pretraining
     Language Modeling MaskedLanguageModel
     Model TransformerEncoderLM with config:
	{'vocabSize': 50002, 'maxLen': 512, 'dModel': 64, 'nHeads': 8, 'dHidden': 256, 'nLayers': 2, 'numClasses': 1, 'hiddenNeurons': [64], 'dropout': 0.3}

01/30/2023 12:50:16 PM  [!] Running pre-training split 1/3
01/30/2023 12:50:19 PM  [!] Pre-training model...
01/30/2023 12:50:19 PM  [*] Masking sequences...
01/30/2023 12:50:38 PM  [*] Started epoch: 1
01/30/2023 12:50:38 PM  [*] Mon Jan 30 12:50:38 2023: Train Epoch: 1 [  0  /61661 (0 %)]	Loss: 480.866699 | Elapsed: 0.47s
01/30/2023 12:50:51 PM  [*] Mon Jan 30 12:50:51 2023: Train Epoch: 1 [6400 /61661 (10%)]	Loss: 214.661469 | Elapsed: 12.25s
01/30/2023 12:51:03 PM  [*] Mon Jan 30 12:51:03 2023: Train Epoch: 1 [12800/61661 (21%)]	Loss: 220.869156 | Elapsed: 12.33s
01/30/2023 12:51:15 PM  [*] Mon Jan 30 12:51:15 2023: Train Epoch: 1 [19200/61661 (31%)]	Loss: 193.389191 | Elapsed: 12.33s
01/30/2023 12:51:28 PM  [*] Mon Jan 30 12:51:28 2023: Train Epoch: 1 [25600/61661 (41%)]	Loss: 193.175095 | Elapsed: 12.34s
01/30/2023 12:51:40 PM  [*] Mon Jan 30 12:51:40 2023: Train Epoch: 1 [32000/61661 (52%)]	Loss: 187.127319 | Elapsed: 12.35s
01/30/2023 12:51:52 PM  [*] Mon Jan 30 12:51:52 2023: Train Epoch: 1 [38400/61661 (62%)]	Loss: 210.511826 | Elapsed: 12.30s
01/30/2023 12:52:05 PM  [*] Mon Jan 30 12:52:05 2023: Train Epoch: 1 [44800/61661 (73%)]	Loss: 211.669525 | Elapsed: 12.32s
01/30/2023 12:52:17 PM  [*] Mon Jan 30 12:52:17 2023: Train Epoch: 1 [51200/61661 (83%)]	Loss: 198.237640 | Elapsed: 12.49s
01/30/2023 12:52:30 PM  [*] Mon Jan 30 12:52:30 2023: Train Epoch: 1 [57600/61661 (93%)]	Loss: 212.427277 | Elapsed: 12.55s
01/30/2023 12:52:39 PM  [*] Mon Jan 30 12:52:39 2023:    1    | Tr.loss: 211.452873 | Elapsed:  121.31  s
01/30/2023 12:52:39 PM  [*] Started epoch: 2
01/30/2023 12:52:39 PM  [*] Mon Jan 30 12:52:39 2023: Train Epoch: 2 [  0  /61661 (0 %)]	Loss: 189.892960 | Elapsed: 0.21s
01/30/2023 12:52:52 PM  [*] Mon Jan 30 12:52:52 2023: Train Epoch: 2 [6400 /61661 (10%)]	Loss: 206.697327 | Elapsed: 12.59s
01/30/2023 12:53:04 PM  [*] Mon Jan 30 12:53:04 2023: Train Epoch: 2 [12800/61661 (21%)]	Loss: 205.870255 | Elapsed: 12.44s
01/30/2023 12:53:17 PM  [*] Mon Jan 30 12:53:17 2023: Train Epoch: 2 [19200/61661 (31%)]	Loss: 199.053162 | Elapsed: 12.32s
01/30/2023 12:53:29 PM  [*] Mon Jan 30 12:53:29 2023: Train Epoch: 2 [25600/61661 (41%)]	Loss: 191.585541 | Elapsed: 12.28s
01/30/2023 12:53:41 PM  [*] Mon Jan 30 12:53:41 2023: Train Epoch: 2 [32000/61661 (52%)]	Loss: 180.118988 | Elapsed: 12.28s
01/30/2023 12:53:54 PM  [*] Mon Jan 30 12:53:54 2023: Train Epoch: 2 [38400/61661 (62%)]	Loss: 184.667725 | Elapsed: 12.33s
01/30/2023 12:54:06 PM  [*] Mon Jan 30 12:54:06 2023: Train Epoch: 2 [44800/61661 (73%)]	Loss: 202.414612 | Elapsed: 12.39s
01/30/2023 12:54:18 PM  [*] Mon Jan 30 12:54:18 2023: Train Epoch: 2 [51200/61661 (83%)]	Loss: 182.159515 | Elapsed: 12.34s
01/30/2023 12:54:31 PM  [*] Mon Jan 30 12:54:31 2023: Train Epoch: 2 [57600/61661 (93%)]	Loss: 157.196335 | Elapsed: 12.23s
01/30/2023 12:54:40 PM  [*] Mon Jan 30 12:54:40 2023:    2    | Tr.loss: 191.662411 | Elapsed:  120.91  s
01/30/2023 12:54:40 PM  [*] Started epoch: 3
01/30/2023 12:54:40 PM  [*] Mon Jan 30 12:54:40 2023: Train Epoch: 3 [  0  /61661 (0 %)]	Loss: 206.660400 | Elapsed: 0.21s
01/30/2023 12:54:53 PM  [*] Mon Jan 30 12:54:53 2023: Train Epoch: 3 [6400 /61661 (10%)]	Loss: 182.508118 | Elapsed: 12.37s
01/30/2023 12:55:05 PM  [*] Mon Jan 30 12:55:05 2023: Train Epoch: 3 [12800/61661 (21%)]	Loss: 200.549866 | Elapsed: 12.45s
01/30/2023 12:55:17 PM  [*] Mon Jan 30 12:55:17 2023: Train Epoch: 3 [19200/61661 (31%)]	Loss: 168.102448 | Elapsed: 12.40s
01/30/2023 12:55:30 PM  [*] Mon Jan 30 12:55:30 2023: Train Epoch: 3 [25600/61661 (41%)]	Loss: 146.916595 | Elapsed: 12.32s
01/30/2023 12:55:42 PM  [*] Mon Jan 30 12:55:42 2023: Train Epoch: 3 [32000/61661 (52%)]	Loss: 175.243134 | Elapsed: 12.36s
01/30/2023 12:55:54 PM  [*] Mon Jan 30 12:55:54 2023: Train Epoch: 3 [38400/61661 (62%)]	Loss: 191.773254 | Elapsed: 12.33s
01/30/2023 12:56:07 PM  [*] Mon Jan 30 12:56:07 2023: Train Epoch: 3 [44800/61661 (73%)]	Loss: 171.676636 | Elapsed: 12.40s
01/30/2023 12:56:19 PM  [*] Mon Jan 30 12:56:19 2023: Train Epoch: 3 [51200/61661 (83%)]	Loss: 174.176178 | Elapsed: 12.53s
01/30/2023 12:56:32 PM  [*] Mon Jan 30 12:56:32 2023: Train Epoch: 3 [57600/61661 (93%)]	Loss: 184.377518 | Elapsed: 12.44s
01/30/2023 12:56:41 PM  [*] Mon Jan 30 12:56:41 2023:    3    | Tr.loss: 186.056223 | Elapsed:  121.39  s
01/30/2023 12:56:41 PM  [*] Started epoch: 4
01/30/2023 12:56:42 PM  [*] Mon Jan 30 12:56:42 2023: Train Epoch: 4 [  0  /61661 (0 %)]	Loss: 182.446411 | Elapsed: 0.20s
01/30/2023 12:56:54 PM  [*] Mon Jan 30 12:56:54 2023: Train Epoch: 4 [6400 /61661 (10%)]	Loss: 189.590881 | Elapsed: 12.39s
01/30/2023 12:57:07 PM  [*] Mon Jan 30 12:57:07 2023: Train Epoch: 4 [12800/61661 (21%)]	Loss: 172.997910 | Elapsed: 12.49s
01/30/2023 12:57:19 PM  [*] Mon Jan 30 12:57:19 2023: Train Epoch: 4 [19200/61661 (31%)]	Loss: 184.078445 | Elapsed: 12.30s
01/30/2023 12:57:31 PM  [*] Mon Jan 30 12:57:31 2023: Train Epoch: 4 [25600/61661 (41%)]	Loss: 196.853333 | Elapsed: 12.28s
01/30/2023 12:57:43 PM  [*] Mon Jan 30 12:57:43 2023: Train Epoch: 4 [32000/61661 (52%)]	Loss: 182.954926 | Elapsed: 12.35s
01/30/2023 12:57:56 PM  [*] Mon Jan 30 12:57:56 2023: Train Epoch: 4 [38400/61661 (62%)]	Loss: 194.927261 | Elapsed: 12.40s
01/30/2023 12:58:08 PM  [*] Mon Jan 30 12:58:08 2023: Train Epoch: 4 [44800/61661 (73%)]	Loss: 166.944550 | Elapsed: 12.37s
01/30/2023 12:58:21 PM  [*] Mon Jan 30 12:58:21 2023: Train Epoch: 4 [51200/61661 (83%)]	Loss: 199.954269 | Elapsed: 12.40s
01/30/2023 12:58:33 PM  [*] Mon Jan 30 12:58:33 2023: Train Epoch: 4 [57600/61661 (93%)]	Loss: 208.839996 | Elapsed: 12.36s
01/30/2023 12:58:43 PM  [*] Mon Jan 30 12:58:43 2023:    4    | Tr.loss: 183.347173 | Elapsed:  121.05  s
01/30/2023 12:58:43 PM  [*] Started epoch: 5
01/30/2023 12:58:43 PM  [*] Mon Jan 30 12:58:43 2023: Train Epoch: 5 [  0  /61661 (0 %)]	Loss: 169.149429 | Elapsed: 0.14s
01/30/2023 12:58:55 PM  [*] Mon Jan 30 12:58:55 2023: Train Epoch: 5 [6400 /61661 (10%)]	Loss: 174.918518 | Elapsed: 12.46s
01/30/2023 12:59:07 PM  [*] Mon Jan 30 12:59:07 2023: Train Epoch: 5 [12800/61661 (21%)]	Loss: 174.764954 | Elapsed: 12.31s
01/30/2023 12:59:20 PM  [*] Mon Jan 30 12:59:20 2023: Train Epoch: 5 [19200/61661 (31%)]	Loss: 174.884430 | Elapsed: 12.43s
01/30/2023 12:59:32 PM  [*] Mon Jan 30 12:59:32 2023: Train Epoch: 5 [25600/61661 (41%)]	Loss: 169.187073 | Elapsed: 12.30s
01/30/2023 12:59:44 PM  [*] Mon Jan 30 12:59:44 2023: Train Epoch: 5 [32000/61661 (52%)]	Loss: 169.583344 | Elapsed: 12.27s
01/30/2023 12:59:57 PM  [*] Mon Jan 30 12:59:57 2023: Train Epoch: 5 [38400/61661 (62%)]	Loss: 197.148041 | Elapsed: 12.24s
01/30/2023 01:00:09 PM  [*] Mon Jan 30 13:00:09 2023: Train Epoch: 5 [44800/61661 (73%)]	Loss: 183.658020 | Elapsed: 12.40s
01/30/2023 01:00:21 PM  [*] Mon Jan 30 13:00:21 2023: Train Epoch: 5 [51200/61661 (83%)]	Loss: 177.384491 | Elapsed: 12.44s
01/30/2023 01:00:34 PM  [*] Mon Jan 30 13:00:34 2023: Train Epoch: 5 [57600/61661 (93%)]	Loss: 164.685364 | Elapsed: 12.47s
01/30/2023 01:00:44 PM  [*] Mon Jan 30 13:00:44 2023:    5    | Tr.loss: 181.050476 | Elapsed:  121.02  s
01/30/2023 01:00:44 PM  [*] Started epoch: 6
01/30/2023 01:00:44 PM  [*] Mon Jan 30 13:00:44 2023: Train Epoch: 6 [  0  /61661 (0 %)]	Loss: 171.790878 | Elapsed: 0.20s
01/30/2023 01:00:56 PM  [*] Mon Jan 30 13:00:56 2023: Train Epoch: 6 [6400 /61661 (10%)]	Loss: 192.708771 | Elapsed: 12.38s
01/30/2023 01:01:08 PM  [*] Mon Jan 30 13:01:08 2023: Train Epoch: 6 [12800/61661 (21%)]	Loss: 178.441833 | Elapsed: 12.35s
01/30/2023 01:01:21 PM  [*] Mon Jan 30 13:01:21 2023: Train Epoch: 6 [19200/61661 (31%)]	Loss: 179.790115 | Elapsed: 12.40s
01/30/2023 01:01:33 PM  [*] Mon Jan 30 13:01:33 2023: Train Epoch: 6 [25600/61661 (41%)]	Loss: 207.187836 | Elapsed: 12.33s
01/30/2023 01:01:46 PM  [*] Mon Jan 30 13:01:46 2023: Train Epoch: 6 [32000/61661 (52%)]	Loss: 188.998154 | Elapsed: 12.33s
01/30/2023 01:01:58 PM  [*] Mon Jan 30 13:01:58 2023: Train Epoch: 6 [38400/61661 (62%)]	Loss: 174.503036 | Elapsed: 12.26s
01/30/2023 01:02:10 PM  [*] Mon Jan 30 13:02:10 2023: Train Epoch: 6 [44800/61661 (73%)]	Loss: 181.256485 | Elapsed: 12.28s
01/30/2023 01:02:22 PM  [*] Mon Jan 30 13:02:22 2023: Train Epoch: 6 [51200/61661 (83%)]	Loss: 185.891693 | Elapsed: 12.32s
01/30/2023 01:02:35 PM  [*] Mon Jan 30 13:02:35 2023: Train Epoch: 6 [57600/61661 (93%)]	Loss: 171.123962 | Elapsed: 12.43s
01/30/2023 01:02:44 PM  [*] Mon Jan 30 13:02:44 2023:    6    | Tr.loss: 179.327118 | Elapsed:  120.78  s
01/30/2023 01:02:44 PM  [*] Started epoch: 7
01/30/2023 01:02:45 PM  [*] Mon Jan 30 13:02:45 2023: Train Epoch: 7 [  0  /61661 (0 %)]	Loss: 164.149368 | Elapsed: 0.20s
01/30/2023 01:02:57 PM  [*] Mon Jan 30 13:02:57 2023: Train Epoch: 7 [6400 /61661 (10%)]	Loss: 183.028503 | Elapsed: 12.42s
01/30/2023 01:03:09 PM  [*] Mon Jan 30 13:03:09 2023: Train Epoch: 7 [12800/61661 (21%)]	Loss: 188.795776 | Elapsed: 12.34s
01/30/2023 01:03:22 PM  [*] Mon Jan 30 13:03:22 2023: Train Epoch: 7 [19200/61661 (31%)]	Loss: 182.059540 | Elapsed: 12.54s
01/30/2023 01:03:34 PM  [*] Mon Jan 30 13:03:34 2023: Train Epoch: 7 [25600/61661 (41%)]	Loss: 186.905304 | Elapsed: 12.29s
01/30/2023 01:03:46 PM  [*] Mon Jan 30 13:03:46 2023: Train Epoch: 7 [32000/61661 (52%)]	Loss: 179.682358 | Elapsed: 12.34s
01/30/2023 01:03:59 PM  [*] Mon Jan 30 13:03:59 2023: Train Epoch: 7 [38400/61661 (62%)]	Loss: 195.986298 | Elapsed: 12.30s
01/30/2023 01:04:11 PM  [*] Mon Jan 30 13:04:11 2023: Train Epoch: 7 [44800/61661 (73%)]	Loss: 170.948990 | Elapsed: 12.31s
01/30/2023 01:04:23 PM  [*] Mon Jan 30 13:04:23 2023: Train Epoch: 7 [51200/61661 (83%)]	Loss: 174.397003 | Elapsed: 12.31s
01/30/2023 01:04:36 PM  [*] Mon Jan 30 13:04:36 2023: Train Epoch: 7 [57600/61661 (93%)]	Loss: 204.025452 | Elapsed: 12.38s
01/30/2023 01:04:45 PM  [*] Mon Jan 30 13:04:45 2023:    7    | Tr.loss: 178.229424 | Elapsed:  120.98  s
01/30/2023 01:04:45 PM  [*] Started epoch: 8
01/30/2023 01:04:45 PM  [*] Mon Jan 30 13:04:45 2023: Train Epoch: 8 [  0  /61661 (0 %)]	Loss: 181.462967 | Elapsed: 0.20s
01/30/2023 01:04:58 PM  [*] Mon Jan 30 13:04:58 2023: Train Epoch: 8 [6400 /61661 (10%)]	Loss: 198.410049 | Elapsed: 12.38s
01/30/2023 01:05:10 PM  [*] Mon Jan 30 13:05:10 2023: Train Epoch: 8 [12800/61661 (21%)]	Loss: 178.509033 | Elapsed: 12.32s
01/30/2023 01:05:23 PM  [*] Mon Jan 30 13:05:23 2023: Train Epoch: 8 [19200/61661 (31%)]	Loss: 167.014832 | Elapsed: 12.32s
01/30/2023 01:05:35 PM  [*] Mon Jan 30 13:05:35 2023: Train Epoch: 8 [25600/61661 (41%)]	Loss: 193.624084 | Elapsed: 12.34s
01/30/2023 01:05:47 PM  [*] Mon Jan 30 13:05:47 2023: Train Epoch: 8 [32000/61661 (52%)]	Loss: 189.752930 | Elapsed: 12.45s
01/30/2023 01:06:00 PM  [*] Mon Jan 30 13:06:00 2023: Train Epoch: 8 [38400/61661 (62%)]	Loss: 198.533081 | Elapsed: 12.39s
01/30/2023 01:06:12 PM  [*] Mon Jan 30 13:06:12 2023: Train Epoch: 8 [44800/61661 (73%)]	Loss: 197.835632 | Elapsed: 12.31s
01/30/2023 01:06:24 PM  [*] Mon Jan 30 13:06:24 2023: Train Epoch: 8 [51200/61661 (83%)]	Loss: 176.550125 | Elapsed: 12.29s
01/30/2023 01:06:37 PM  [*] Mon Jan 30 13:06:37 2023: Train Epoch: 8 [57600/61661 (93%)]	Loss: 158.271423 | Elapsed: 12.31s
01/30/2023 01:06:46 PM  [*] Mon Jan 30 13:06:46 2023:    8    | Tr.loss: 177.425304 | Elapsed:  120.87  s
01/30/2023 01:06:46 PM  [*] Started epoch: 9
01/30/2023 01:06:46 PM  [*] Mon Jan 30 13:06:46 2023: Train Epoch: 9 [  0  /61661 (0 %)]	Loss: 189.642380 | Elapsed: 0.21s
01/30/2023 01:06:59 PM  [*] Mon Jan 30 13:06:59 2023: Train Epoch: 9 [6400 /61661 (10%)]	Loss: 178.317902 | Elapsed: 12.46s
01/30/2023 01:07:11 PM  [*] Mon Jan 30 13:07:11 2023: Train Epoch: 9 [12800/61661 (21%)]	Loss: 166.225800 | Elapsed: 12.38s
01/30/2023 01:07:23 PM  [*] Mon Jan 30 13:07:23 2023: Train Epoch: 9 [19200/61661 (31%)]	Loss: 178.078949 | Elapsed: 12.28s
01/30/2023 01:07:36 PM  [*] Mon Jan 30 13:07:36 2023: Train Epoch: 9 [25600/61661 (41%)]	Loss: 162.319214 | Elapsed: 12.33s
01/30/2023 01:07:48 PM  [*] Mon Jan 30 13:07:48 2023: Train Epoch: 9 [32000/61661 (52%)]	Loss: 159.335098 | Elapsed: 12.26s
01/30/2023 01:08:01 PM  [*] Mon Jan 30 13:08:01 2023: Train Epoch: 9 [38400/61661 (62%)]	Loss: 170.577515 | Elapsed: 12.44s
01/30/2023 01:08:13 PM  [*] Mon Jan 30 13:08:13 2023: Train Epoch: 9 [44800/61661 (73%)]	Loss: 180.694839 | Elapsed: 12.30s
01/30/2023 01:08:26 PM  [*] Mon Jan 30 13:08:26 2023: Train Epoch: 9 [51200/61661 (83%)]	Loss: 182.889771 | Elapsed: 12.85s
01/30/2023 01:08:39 PM  [*] Mon Jan 30 13:08:39 2023: Train Epoch: 9 [57600/61661 (93%)]	Loss: 159.589035 | Elapsed: 13.01s
01/30/2023 01:08:49 PM  [*] Mon Jan 30 13:08:49 2023:    9    | Tr.loss: 176.922562 | Elapsed:  122.88  s
01/30/2023 01:08:49 PM  [*] Started epoch: 10
01/30/2023 01:08:49 PM  [*] Mon Jan 30 13:08:49 2023: Train Epoch: 10 [  0  /61661 (0 %)]	Loss: 181.432327 | Elapsed: 0.36s
01/30/2023 01:09:02 PM  [*] Mon Jan 30 13:09:02 2023: Train Epoch: 10 [6400 /61661 (10%)]	Loss: 188.955399 | Elapsed: 12.50s
01/30/2023 01:09:14 PM  [*] Mon Jan 30 13:09:14 2023: Train Epoch: 10 [12800/61661 (21%)]	Loss: 183.603912 | Elapsed: 12.47s
01/30/2023 01:09:27 PM  [*] Mon Jan 30 13:09:27 2023: Train Epoch: 10 [19200/61661 (31%)]	Loss: 173.590683 | Elapsed: 12.37s
01/30/2023 01:09:39 PM  [*] Mon Jan 30 13:09:39 2023: Train Epoch: 10 [25600/61661 (41%)]	Loss: 184.943390 | Elapsed: 12.33s
01/30/2023 01:09:51 PM  [*] Mon Jan 30 13:09:51 2023: Train Epoch: 10 [32000/61661 (52%)]	Loss: 184.173599 | Elapsed: 12.33s
01/30/2023 01:10:04 PM  [*] Mon Jan 30 13:10:04 2023: Train Epoch: 10 [38400/61661 (62%)]	Loss: 187.758698 | Elapsed: 12.33s
01/30/2023 01:10:16 PM  [*] Mon Jan 30 13:10:16 2023: Train Epoch: 10 [44800/61661 (73%)]	Loss: 188.107544 | Elapsed: 12.48s
01/30/2023 01:10:29 PM  [*] Mon Jan 30 13:10:29 2023: Train Epoch: 10 [51200/61661 (83%)]	Loss: 178.839676 | Elapsed: 12.38s
01/30/2023 01:10:41 PM  [*] Mon Jan 30 13:10:41 2023: Train Epoch: 10 [57600/61661 (93%)]	Loss: 170.422668 | Elapsed: 12.41s
01/30/2023 01:10:51 PM  [*] Mon Jan 30 13:10:51 2023:   10    | Tr.loss: 176.297617 | Elapsed:  121.58  s
01/30/2023 01:10:51 PM [!] Mon Jan 30 13:10:51 2023: Dumped results:
                model     : 1675080651-model.torch
		train time: 1675080651-trainTime.npy
		train losses: 1675080651-trainLosses.npy
		train AUC: 1675080651-auc.npy
01/30/2023 01:10:53 PM  [!] Training pretrained model on downstream task...
01/30/2023 01:10:53 PM  [*] Started epoch: 1
01/30/2023 01:10:53 PM  [*] Mon Jan 30 13:10:53 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 7.781750 | Elapsed: 0.27s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.1927
01/30/2023 01:11:03 PM  [*] Mon Jan 30 13:11:03 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.534977 | Elapsed: 9.15s | FPR 0.0003 -> TPR 0.2881 & F1 0.4474 | AUC 0.7755
01/30/2023 01:11:04 PM  [*] Mon Jan 30 13:11:04 2023:    1    | Tr.loss: 0.894632 | Elapsed:   11.27  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.6336
01/30/2023 01:11:04 PM  [*] Started epoch: 2
01/30/2023 01:11:04 PM  [*] Mon Jan 30 13:11:04 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.420908 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.4000 & F1 0.5714 | AUC 0.8327
01/30/2023 01:11:14 PM  [*] Mon Jan 30 13:11:14 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.453537 | Elapsed: 9.10s | FPR 0.0003 -> TPR 0.3562 & F1 0.5253 | AUC 0.7121
01/30/2023 01:11:15 PM  [*] Mon Jan 30 13:11:15 2023:    2    | Tr.loss: 0.484416 | Elapsed:   10.98  s | FPR 0.0003 -> TPR: 0.07 & F1: 0.13 | AUC: 0.7780
01/30/2023 01:11:15 PM  [*] Started epoch: 3
01/30/2023 01:11:15 PM  [*] Mon Jan 30 13:11:15 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.470096 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.0811 & F1 0.1500 | AUC 0.8514
01/30/2023 01:11:25 PM  [*] Mon Jan 30 13:11:25 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.402145 | Elapsed: 9.09s | FPR 0.0003 -> TPR 0.3500 & F1 0.5185 | AUC 0.8638
01/30/2023 01:11:26 PM  [*] Mon Jan 30 13:11:26 2023:    3    | Tr.loss: 0.427626 | Elapsed:   10.99  s | FPR 0.0003 -> TPR: 0.07 & F1: 0.13 | AUC: 0.8410
01/30/2023 01:11:27 PM [!] Mon Jan 30 13:11:27 2023: Dumped results:
                model     : 1675080686-model.torch
		train time: 1675080686-trainTime.npy
		train losses: 1675080686-trainLosses.npy
		train AUC: 1675080686-auc.npy
		train F1s : 1675080686-trainF1s.npy
		train TPRs: 1675080686-trainTPRs.npy
01/30/2023 01:11:27 PM  [!] Training non_pretrained model on downstream task...
01/30/2023 01:11:27 PM  [*] Started epoch: 1
01/30/2023 01:11:27 PM  [*] Mon Jan 30 13:11:27 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 1.732965 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.3285
01/30/2023 01:11:34 PM  [*] Mon Jan 30 13:11:34 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.378601 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.3467 & F1 0.5149 | AUC 0.8331
01/30/2023 01:11:35 PM  [*] Mon Jan 30 13:11:35 2023:    1    | Tr.loss: 0.551263 | Elapsed:   7.56   s | FPR 0.0003 -> TPR: 0.01 & F1: 0.01 | AUC: 0.7622
01/30/2023 01:11:35 PM  [*] Started epoch: 2
01/30/2023 01:11:35 PM  [*] Mon Jan 30 13:11:35 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.423375 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.4468 & F1 0.6176 | AUC 0.8348
01/30/2023 01:11:41 PM  [*] Mon Jan 30 13:11:41 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.396077 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.3134 & F1 0.4773 | AUC 0.9005
01/30/2023 01:11:42 PM  [*] Mon Jan 30 13:11:42 2023:    2    | Tr.loss: 0.365006 | Elapsed:   7.62   s | FPR 0.0003 -> TPR: 0.14 & F1: 0.24 | AUC: 0.8929
01/30/2023 01:11:42 PM  [*] Started epoch: 3
01/30/2023 01:11:42 PM  [*] Mon Jan 30 13:11:42 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.233584 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.7872 & F1 0.8810 | AUC 0.9574
01/30/2023 01:11:49 PM  [*] Mon Jan 30 13:11:49 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.327427 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.4308 & F1 0.6022 | AUC 0.8774
01/30/2023 01:11:50 PM  [*] Mon Jan 30 13:11:50 2023:    3    | Tr.loss: 0.310251 | Elapsed:   7.58   s | FPR 0.0003 -> TPR: 0.32 & F1: 0.49 | AUC: 0.9270
01/30/2023 01:11:50 PM [!] Mon Jan 30 13:11:50 2023: Dumped results:
                model     : 1675080710-model.torch
		train time: 1675080710-trainTime.npy
		train losses: 1675080710-trainLosses.npy
		train AUC: 1675080710-auc.npy
		train F1s : 1675080710-trainF1s.npy
		train TPRs: 1675080710-trainTPRs.npy
01/30/2023 01:11:50 PM  [*] Evaluating pretrained model on test set...
01/30/2023 01:11:55 PM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0286 | F1: 0.0556
01/30/2023 01:11:55 PM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.0326 | F1: 0.0632
01/30/2023 01:11:55 PM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.0608 | F1: 0.1146
01/30/2023 01:11:55 PM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.0720 | F1: 0.1340
01/30/2023 01:11:55 PM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.1317 | F1: 0.2309
01/30/2023 01:11:55 PM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4105 | F1: 0.5717
01/30/2023 01:11:55 PM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.5230 | F1: 0.6505
01/30/2023 01:11:55 PM  [*] Evaluating non_pretrained model on test set...
01/30/2023 01:12:00 PM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0007 | F1: 0.0015
01/30/2023 01:12:00 PM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1384 | F1: 0.2430
01/30/2023 01:12:00 PM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.2281 | F1: 0.3712
01/30/2023 01:12:00 PM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.2610 | F1: 0.4131
01/30/2023 01:12:00 PM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3069 | F1: 0.4667
01/30/2023 01:12:00 PM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.3955 | F1: 0.5567
01/30/2023 01:12:00 PM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.6304 | F1: 0.7350
01/30/2023 01:12:00 PM  [!] Running pre-training split 2/3
01/30/2023 01:12:03 PM  [!] Pre-training model...
01/30/2023 01:12:04 PM  [*] Masking sequences...
01/30/2023 01:12:22 PM  [*] Started epoch: 1
01/30/2023 01:12:23 PM  [*] Mon Jan 30 13:12:23 2023: Train Epoch: 1 [  0  /61661 (0 %)]	Loss: 421.088562 | Elapsed: 0.39s
01/30/2023 01:12:35 PM  [*] Mon Jan 30 13:12:35 2023: Train Epoch: 1 [6400 /61661 (10%)]	Loss: 248.704712 | Elapsed: 12.24s
01/30/2023 01:12:47 PM  [*] Mon Jan 30 13:12:47 2023: Train Epoch: 1 [12800/61661 (21%)]	Loss: 221.021545 | Elapsed: 12.26s
01/30/2023 01:12:59 PM  [*] Mon Jan 30 13:12:59 2023: Train Epoch: 1 [19200/61661 (31%)]	Loss: 211.534744 | Elapsed: 12.25s
01/30/2023 01:13:12 PM  [*] Mon Jan 30 13:13:12 2023: Train Epoch: 1 [25600/61661 (41%)]	Loss: 198.121155 | Elapsed: 12.37s
01/30/2023 01:13:24 PM  [*] Mon Jan 30 13:13:24 2023: Train Epoch: 1 [32000/61661 (52%)]	Loss: 190.084198 | Elapsed: 12.32s
01/30/2023 01:13:36 PM  [*] Mon Jan 30 13:13:36 2023: Train Epoch: 1 [38400/61661 (62%)]	Loss: 217.482056 | Elapsed: 12.36s
01/30/2023 01:13:49 PM  [*] Mon Jan 30 13:13:49 2023: Train Epoch: 1 [44800/61661 (73%)]	Loss: 186.930954 | Elapsed: 12.28s
01/30/2023 01:14:01 PM  [*] Mon Jan 30 13:14:01 2023: Train Epoch: 1 [51200/61661 (83%)]	Loss: 180.130585 | Elapsed: 12.36s
01/30/2023 01:14:13 PM  [*] Mon Jan 30 13:14:13 2023: Train Epoch: 1 [57600/61661 (93%)]	Loss: 197.401932 | Elapsed: 12.28s
01/30/2023 01:14:23 PM  [*] Mon Jan 30 13:14:23 2023:    1    | Tr.loss: 205.960503 | Elapsed:  120.69  s
01/30/2023 01:14:23 PM  [*] Started epoch: 2
01/30/2023 01:14:23 PM  [*] Mon Jan 30 13:14:23 2023: Train Epoch: 2 [  0  /61661 (0 %)]	Loss: 186.895874 | Elapsed: 0.12s
01/30/2023 01:14:35 PM  [*] Mon Jan 30 13:14:35 2023: Train Epoch: 2 [6400 /61661 (10%)]	Loss: 193.852112 | Elapsed: 12.45s
01/30/2023 01:14:48 PM  [*] Mon Jan 30 13:14:48 2023: Train Epoch: 2 [12800/61661 (21%)]	Loss: 200.957123 | Elapsed: 12.50s
01/30/2023 01:15:00 PM  [*] Mon Jan 30 13:15:00 2023: Train Epoch: 2 [19200/61661 (31%)]	Loss: 195.443695 | Elapsed: 12.31s
01/30/2023 01:15:13 PM  [*] Mon Jan 30 13:15:13 2023: Train Epoch: 2 [25600/61661 (41%)]	Loss: 175.150970 | Elapsed: 12.32s
01/30/2023 01:15:25 PM  [*] Mon Jan 30 13:15:25 2023: Train Epoch: 2 [32000/61661 (52%)]	Loss: 195.644897 | Elapsed: 12.31s
01/30/2023 01:15:37 PM  [*] Mon Jan 30 13:15:37 2023: Train Epoch: 2 [38400/61661 (62%)]	Loss: 185.811493 | Elapsed: 12.49s
01/30/2023 01:15:50 PM  [*] Mon Jan 30 13:15:50 2023: Train Epoch: 2 [44800/61661 (73%)]	Loss: 189.088623 | Elapsed: 12.33s
01/30/2023 01:16:02 PM  [*] Mon Jan 30 13:16:02 2023: Train Epoch: 2 [51200/61661 (83%)]	Loss: 175.654724 | Elapsed: 12.32s
01/30/2023 01:16:14 PM  [*] Mon Jan 30 13:16:14 2023: Train Epoch: 2 [57600/61661 (93%)]	Loss: 183.584244 | Elapsed: 12.35s
01/30/2023 01:16:24 PM  [*] Mon Jan 30 13:16:24 2023:    2    | Tr.loss: 184.656947 | Elapsed:  121.03  s
01/30/2023 01:16:24 PM  [*] Started epoch: 3
01/30/2023 01:16:24 PM  [*] Mon Jan 30 13:16:24 2023: Train Epoch: 3 [  0  /61661 (0 %)]	Loss: 173.288910 | Elapsed: 0.13s
01/30/2023 01:16:36 PM  [*] Mon Jan 30 13:16:36 2023: Train Epoch: 3 [6400 /61661 (10%)]	Loss: 187.827759 | Elapsed: 12.43s
01/30/2023 01:16:49 PM  [*] Mon Jan 30 13:16:49 2023: Train Epoch: 3 [12800/61661 (21%)]	Loss: 190.325806 | Elapsed: 12.38s
01/30/2023 01:17:01 PM  [*] Mon Jan 30 13:17:01 2023: Train Epoch: 3 [19200/61661 (31%)]	Loss: 172.824677 | Elapsed: 12.43s
01/30/2023 01:17:14 PM  [*] Mon Jan 30 13:17:14 2023: Train Epoch: 3 [25600/61661 (41%)]	Loss: 164.284668 | Elapsed: 12.39s
01/30/2023 01:17:26 PM  [*] Mon Jan 30 13:17:26 2023: Train Epoch: 3 [32000/61661 (52%)]	Loss: 183.176605 | Elapsed: 12.32s
01/30/2023 01:17:38 PM  [*] Mon Jan 30 13:17:38 2023: Train Epoch: 3 [38400/61661 (62%)]	Loss: 194.329254 | Elapsed: 12.31s
01/30/2023 01:17:51 PM  [*] Mon Jan 30 13:17:51 2023: Train Epoch: 3 [44800/61661 (73%)]	Loss: 189.853516 | Elapsed: 12.39s
01/30/2023 01:18:03 PM  [*] Mon Jan 30 13:18:03 2023: Train Epoch: 3 [51200/61661 (83%)]	Loss: 171.484543 | Elapsed: 12.36s
01/30/2023 01:18:15 PM  [*] Mon Jan 30 13:18:15 2023: Train Epoch: 3 [57600/61661 (93%)]	Loss: 172.212326 | Elapsed: 12.37s
01/30/2023 01:18:25 PM  [*] Mon Jan 30 13:18:25 2023:    3    | Tr.loss: 179.951227 | Elapsed:  121.04  s
01/30/2023 01:18:25 PM  [*] Started epoch: 4
01/30/2023 01:18:25 PM  [*] Mon Jan 30 13:18:25 2023: Train Epoch: 4 [  0  /61661 (0 %)]	Loss: 178.988190 | Elapsed: 0.20s
01/30/2023 01:18:37 PM  [*] Mon Jan 30 13:18:37 2023: Train Epoch: 4 [6400 /61661 (10%)]	Loss: 173.449127 | Elapsed: 12.41s
01/30/2023 01:18:50 PM  [*] Mon Jan 30 13:18:50 2023: Train Epoch: 4 [12800/61661 (21%)]	Loss: 154.454971 | Elapsed: 12.33s
01/30/2023 01:19:02 PM  [*] Mon Jan 30 13:19:02 2023: Train Epoch: 4 [19200/61661 (31%)]	Loss: 195.944458 | Elapsed: 12.39s
01/30/2023 01:19:15 PM  [*] Mon Jan 30 13:19:15 2023: Train Epoch: 4 [25600/61661 (41%)]	Loss: 181.539062 | Elapsed: 12.40s
01/30/2023 01:19:27 PM  [*] Mon Jan 30 13:19:27 2023: Train Epoch: 4 [32000/61661 (52%)]	Loss: 171.518677 | Elapsed: 12.41s
01/30/2023 01:19:39 PM  [*] Mon Jan 30 13:19:39 2023: Train Epoch: 4 [38400/61661 (62%)]	Loss: 193.168945 | Elapsed: 12.32s
01/30/2023 01:19:52 PM  [*] Mon Jan 30 13:19:52 2023: Train Epoch: 4 [44800/61661 (73%)]	Loss: 188.288651 | Elapsed: 12.29s
01/30/2023 01:20:04 PM  [*] Mon Jan 30 13:20:04 2023: Train Epoch: 4 [51200/61661 (83%)]	Loss: 187.480255 | Elapsed: 12.26s
01/30/2023 01:20:16 PM  [*] Mon Jan 30 13:20:16 2023: Train Epoch: 4 [57600/61661 (93%)]	Loss: 160.519836 | Elapsed: 12.54s
01/30/2023 01:20:26 PM  [*] Mon Jan 30 13:20:26 2023:    4    | Tr.loss: 177.408982 | Elapsed:  121.13  s
01/30/2023 01:20:26 PM  [*] Started epoch: 5
01/30/2023 01:20:26 PM  [*] Mon Jan 30 13:20:26 2023: Train Epoch: 5 [  0  /61661 (0 %)]	Loss: 162.625549 | Elapsed: 0.22s
01/30/2023 01:20:39 PM  [*] Mon Jan 30 13:20:39 2023: Train Epoch: 5 [6400 /61661 (10%)]	Loss: 176.721588 | Elapsed: 12.56s
01/30/2023 01:20:51 PM  [*] Mon Jan 30 13:20:51 2023: Train Epoch: 5 [12800/61661 (21%)]	Loss: 180.420563 | Elapsed: 12.36s
01/30/2023 01:21:04 PM  [*] Mon Jan 30 13:21:04 2023: Train Epoch: 5 [19200/61661 (31%)]	Loss: 147.472305 | Elapsed: 12.50s
01/30/2023 01:21:16 PM  [*] Mon Jan 30 13:21:16 2023: Train Epoch: 5 [25600/61661 (41%)]	Loss: 168.964401 | Elapsed: 12.36s
01/30/2023 01:21:28 PM  [*] Mon Jan 30 13:21:28 2023: Train Epoch: 5 [32000/61661 (52%)]	Loss: 171.307526 | Elapsed: 12.31s
01/30/2023 01:21:41 PM  [*] Mon Jan 30 13:21:41 2023: Train Epoch: 5 [38400/61661 (62%)]	Loss: 173.465668 | Elapsed: 12.44s
01/30/2023 01:21:53 PM  [*] Mon Jan 30 13:21:53 2023: Train Epoch: 5 [44800/61661 (73%)]	Loss: 175.255661 | Elapsed: 12.57s
01/30/2023 01:22:06 PM  [*] Mon Jan 30 13:22:06 2023: Train Epoch: 5 [51200/61661 (83%)]	Loss: 169.503265 | Elapsed: 12.69s
01/30/2023 01:22:19 PM  [*] Mon Jan 30 13:22:19 2023: Train Epoch: 5 [57600/61661 (93%)]	Loss: 187.602783 | Elapsed: 12.60s
01/30/2023 01:22:29 PM  [*] Mon Jan 30 13:22:29 2023:    5    | Tr.loss: 175.487709 | Elapsed:  122.50  s
01/30/2023 01:22:29 PM  [*] Started epoch: 6
01/30/2023 01:22:29 PM  [*] Mon Jan 30 13:22:29 2023: Train Epoch: 6 [  0  /61661 (0 %)]	Loss: 173.376129 | Elapsed: 0.20s
01/30/2023 01:22:41 PM  [*] Mon Jan 30 13:22:41 2023: Train Epoch: 6 [6400 /61661 (10%)]	Loss: 187.170166 | Elapsed: 12.73s
01/30/2023 01:22:54 PM  [*] Mon Jan 30 13:22:54 2023: Train Epoch: 6 [12800/61661 (21%)]	Loss: 177.931152 | Elapsed: 12.57s
01/30/2023 01:23:07 PM  [*] Mon Jan 30 13:23:07 2023: Train Epoch: 6 [19200/61661 (31%)]	Loss: 186.589935 | Elapsed: 12.58s
01/30/2023 01:23:19 PM  [*] Mon Jan 30 13:23:19 2023: Train Epoch: 6 [25600/61661 (41%)]	Loss: 177.545456 | Elapsed: 12.64s
01/30/2023 01:23:32 PM  [*] Mon Jan 30 13:23:32 2023: Train Epoch: 6 [32000/61661 (52%)]	Loss: 190.886292 | Elapsed: 12.58s
01/30/2023 01:23:44 PM  [*] Mon Jan 30 13:23:44 2023: Train Epoch: 6 [38400/61661 (62%)]	Loss: 171.695053 | Elapsed: 12.48s
01/30/2023 01:23:57 PM  [*] Mon Jan 30 13:23:57 2023: Train Epoch: 6 [44800/61661 (73%)]	Loss: 180.023193 | Elapsed: 12.43s
01/30/2023 01:24:09 PM  [*] Mon Jan 30 13:24:09 2023: Train Epoch: 6 [51200/61661 (83%)]	Loss: 157.783844 | Elapsed: 12.49s
01/30/2023 01:24:22 PM  [*] Mon Jan 30 13:24:22 2023: Train Epoch: 6 [57600/61661 (93%)]	Loss: 166.260590 | Elapsed: 12.42s
01/30/2023 01:24:31 PM  [*] Mon Jan 30 13:24:31 2023:    6    | Tr.loss: 174.234744 | Elapsed:  122.68  s
01/30/2023 01:24:31 PM  [*] Started epoch: 7
01/30/2023 01:24:31 PM  [*] Mon Jan 30 13:24:31 2023: Train Epoch: 7 [  0  /61661 (0 %)]	Loss: 150.200958 | Elapsed: 0.21s
01/30/2023 01:24:44 PM  [*] Mon Jan 30 13:24:44 2023: Train Epoch: 7 [6400 /61661 (10%)]	Loss: 171.425232 | Elapsed: 12.39s
01/30/2023 01:24:56 PM  [*] Mon Jan 30 13:24:56 2023: Train Epoch: 7 [12800/61661 (21%)]	Loss: 183.536469 | Elapsed: 12.42s
01/30/2023 01:25:09 PM  [*] Mon Jan 30 13:25:09 2023: Train Epoch: 7 [19200/61661 (31%)]	Loss: 152.859634 | Elapsed: 12.41s
01/30/2023 01:25:21 PM  [*] Mon Jan 30 13:25:21 2023: Train Epoch: 7 [25600/61661 (41%)]	Loss: 173.349426 | Elapsed: 12.53s
01/30/2023 01:25:33 PM  [*] Mon Jan 30 13:25:33 2023: Train Epoch: 7 [32000/61661 (52%)]	Loss: 173.558533 | Elapsed: 12.34s
01/30/2023 01:25:46 PM  [*] Mon Jan 30 13:25:46 2023: Train Epoch: 7 [38400/61661 (62%)]	Loss: 180.381638 | Elapsed: 12.33s
01/30/2023 01:25:58 PM  [*] Mon Jan 30 13:25:58 2023: Train Epoch: 7 [44800/61661 (73%)]	Loss: 172.361115 | Elapsed: 12.32s
01/30/2023 01:26:11 PM  [*] Mon Jan 30 13:26:11 2023: Train Epoch: 7 [51200/61661 (83%)]	Loss: 180.894104 | Elapsed: 12.41s
01/30/2023 01:26:23 PM  [*] Mon Jan 30 13:26:23 2023: Train Epoch: 7 [57600/61661 (93%)]	Loss: 160.209396 | Elapsed: 12.31s
01/30/2023 01:26:32 PM  [*] Mon Jan 30 13:26:32 2023:    7    | Tr.loss: 173.198963 | Elapsed:  121.27  s
01/30/2023 01:26:32 PM  [*] Started epoch: 8
01/30/2023 01:26:33 PM  [*] Mon Jan 30 13:26:33 2023: Train Epoch: 8 [  0  /61661 (0 %)]	Loss: 176.808853 | Elapsed: 0.14s
01/30/2023 01:26:45 PM  [*] Mon Jan 30 13:26:45 2023: Train Epoch: 8 [6400 /61661 (10%)]	Loss: 167.763382 | Elapsed: 12.53s
01/30/2023 01:26:58 PM  [*] Mon Jan 30 13:26:58 2023: Train Epoch: 8 [12800/61661 (21%)]	Loss: 167.840881 | Elapsed: 12.40s
01/30/2023 01:27:10 PM  [*] Mon Jan 30 13:27:10 2023: Train Epoch: 8 [19200/61661 (31%)]	Loss: 167.041687 | Elapsed: 12.37s
01/30/2023 01:27:22 PM  [*] Mon Jan 30 13:27:22 2023: Train Epoch: 8 [25600/61661 (41%)]	Loss: 163.928894 | Elapsed: 12.31s
01/30/2023 01:27:35 PM  [*] Mon Jan 30 13:27:35 2023: Train Epoch: 8 [32000/61661 (52%)]	Loss: 171.968872 | Elapsed: 12.41s
01/30/2023 01:27:47 PM  [*] Mon Jan 30 13:27:47 2023: Train Epoch: 8 [38400/61661 (62%)]	Loss: 202.500092 | Elapsed: 12.37s
01/30/2023 01:27:59 PM  [*] Mon Jan 30 13:27:59 2023: Train Epoch: 8 [44800/61661 (73%)]	Loss: 177.237839 | Elapsed: 12.40s
01/30/2023 01:28:12 PM  [*] Mon Jan 30 13:28:12 2023: Train Epoch: 8 [51200/61661 (83%)]	Loss: 179.938629 | Elapsed: 12.32s
01/30/2023 01:28:24 PM  [*] Mon Jan 30 13:28:24 2023: Train Epoch: 8 [57600/61661 (93%)]	Loss: 182.582947 | Elapsed: 12.29s
01/30/2023 01:28:34 PM  [*] Mon Jan 30 13:28:34 2023:    8    | Tr.loss: 172.377095 | Elapsed:  121.04  s
01/30/2023 01:28:34 PM  [*] Started epoch: 9
01/30/2023 01:28:34 PM  [*] Mon Jan 30 13:28:34 2023: Train Epoch: 9 [  0  /61661 (0 %)]	Loss: 182.294510 | Elapsed: 0.20s
01/30/2023 01:28:46 PM  [*] Mon Jan 30 13:28:46 2023: Train Epoch: 9 [6400 /61661 (10%)]	Loss: 188.267044 | Elapsed: 12.43s
01/30/2023 01:28:58 PM  [*] Mon Jan 30 13:28:58 2023: Train Epoch: 9 [12800/61661 (21%)]	Loss: 159.403122 | Elapsed: 12.31s
01/30/2023 01:29:11 PM  [*] Mon Jan 30 13:29:11 2023: Train Epoch: 9 [19200/61661 (31%)]	Loss: 175.291458 | Elapsed: 12.44s
01/30/2023 01:29:23 PM  [*] Mon Jan 30 13:29:23 2023: Train Epoch: 9 [25600/61661 (41%)]	Loss: 173.825241 | Elapsed: 12.33s
01/30/2023 01:29:36 PM  [*] Mon Jan 30 13:29:36 2023: Train Epoch: 9 [32000/61661 (52%)]	Loss: 179.339874 | Elapsed: 12.35s
01/30/2023 01:29:48 PM  [*] Mon Jan 30 13:29:48 2023: Train Epoch: 9 [38400/61661 (62%)]	Loss: 178.422546 | Elapsed: 12.26s
01/30/2023 01:30:00 PM  [*] Mon Jan 30 13:30:00 2023: Train Epoch: 9 [44800/61661 (73%)]	Loss: 174.594940 | Elapsed: 12.38s
01/30/2023 01:30:13 PM  [*] Mon Jan 30 13:30:13 2023: Train Epoch: 9 [51200/61661 (83%)]	Loss: 169.809738 | Elapsed: 12.44s
01/30/2023 01:30:25 PM  [*] Mon Jan 30 13:30:25 2023: Train Epoch: 9 [57600/61661 (93%)]	Loss: 163.421173 | Elapsed: 12.51s
01/30/2023 01:30:35 PM  [*] Mon Jan 30 13:30:35 2023:    9    | Tr.loss: 171.763434 | Elapsed:  121.19  s
01/30/2023 01:30:35 PM  [*] Started epoch: 10
01/30/2023 01:30:35 PM  [*] Mon Jan 30 13:30:35 2023: Train Epoch: 10 [  0  /61661 (0 %)]	Loss: 170.274475 | Elapsed: 0.21s
01/30/2023 01:30:47 PM  [*] Mon Jan 30 13:30:47 2023: Train Epoch: 10 [6400 /61661 (10%)]	Loss: 183.277985 | Elapsed: 12.37s
01/30/2023 01:31:00 PM  [*] Mon Jan 30 13:31:00 2023: Train Epoch: 10 [12800/61661 (21%)]	Loss: 174.624710 | Elapsed: 12.27s
01/30/2023 01:31:12 PM  [*] Mon Jan 30 13:31:12 2023: Train Epoch: 10 [19200/61661 (31%)]	Loss: 178.655853 | Elapsed: 12.40s
01/30/2023 01:31:24 PM  [*] Mon Jan 30 13:31:24 2023: Train Epoch: 10 [25600/61661 (41%)]	Loss: 187.474747 | Elapsed: 12.41s
01/30/2023 01:31:37 PM  [*] Mon Jan 30 13:31:37 2023: Train Epoch: 10 [32000/61661 (52%)]	Loss: 187.877930 | Elapsed: 12.32s
01/30/2023 01:31:49 PM  [*] Mon Jan 30 13:31:49 2023: Train Epoch: 10 [38400/61661 (62%)]	Loss: 149.057678 | Elapsed: 12.32s
01/30/2023 01:32:01 PM  [*] Mon Jan 30 13:32:01 2023: Train Epoch: 10 [44800/61661 (73%)]	Loss: 184.789917 | Elapsed: 12.31s
01/30/2023 01:32:14 PM  [*] Mon Jan 30 13:32:14 2023: Train Epoch: 10 [51200/61661 (83%)]	Loss: 162.774857 | Elapsed: 12.31s
01/30/2023 01:32:26 PM  [*] Mon Jan 30 13:32:26 2023: Train Epoch: 10 [57600/61661 (93%)]	Loss: 178.949615 | Elapsed: 12.43s
01/30/2023 01:32:36 PM  [*] Mon Jan 30 13:32:36 2023:   10    | Tr.loss: 171.126883 | Elapsed:  120.92  s
01/30/2023 01:32:36 PM [!] Mon Jan 30 13:32:36 2023: Dumped results:
                model     : 1675081956-model.torch
		train time: 1675081956-trainTime.npy
		train losses: 1675081956-trainLosses.npy
		train AUC: 1675081956-auc.npy
01/30/2023 01:32:38 PM  [!] Training pretrained model on downstream task...
01/30/2023 01:32:38 PM  [*] Started epoch: 1
01/30/2023 01:32:38 PM  [*] Mon Jan 30 13:32:38 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 1.209585 | Elapsed: 0.26s | FPR 0.0003 -> TPR 0.2051 & F1 0.3404 | AUC 0.6513
01/30/2023 01:32:47 PM  [*] Mon Jan 30 13:32:47 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.368274 | Elapsed: 9.12s | FPR 0.0003 -> TPR 0.2800 & F1 0.4375 | AUC 0.8411
01/30/2023 01:32:49 PM  [*] Mon Jan 30 13:32:49 2023:    1    | Tr.loss: 0.493382 | Elapsed:   11.23  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8289
01/30/2023 01:32:49 PM  [*] Started epoch: 2
01/30/2023 01:32:49 PM  [*] Mon Jan 30 13:32:49 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.403416 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.4615 & F1 0.6316 | AUC 0.8269
01/30/2023 01:32:58 PM  [*] Mon Jan 30 13:32:58 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.459929 | Elapsed: 9.09s | FPR 0.0003 -> TPR 0.1385 & F1 0.2432 | AUC 0.8545
01/30/2023 01:33:00 PM  [*] Mon Jan 30 13:33:00 2023:    2    | Tr.loss: 0.330197 | Elapsed:   10.98  s | FPR 0.0003 -> TPR: 0.08 & F1: 0.15 | AUC: 0.9140
01/30/2023 01:33:00 PM  [*] Started epoch: 3
01/30/2023 01:33:00 PM  [*] Mon Jan 30 13:33:00 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.199627 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.8298 & F1 0.9070 | AUC 0.9731
01/30/2023 01:33:09 PM  [*] Mon Jan 30 13:33:09 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.267834 | Elapsed: 9.09s | FPR 0.0003 -> TPR 0.8333 & F1 0.9091 | AUC 0.9643
01/30/2023 01:33:11 PM  [*] Mon Jan 30 13:33:11 2023:    3    | Tr.loss: 0.267656 | Elapsed:   10.97  s | FPR 0.0003 -> TPR: 0.39 & F1: 0.56 | AUC: 0.9474
01/30/2023 01:33:12 PM [!] Mon Jan 30 13:33:12 2023: Dumped results:
                model     : 1675081991-model.torch
		train time: 1675081991-trainTime.npy
		train losses: 1675081991-trainLosses.npy
		train AUC: 1675081991-auc.npy
		train F1s : 1675081991-trainF1s.npy
		train TPRs: 1675081991-trainTPRs.npy
01/30/2023 01:33:12 PM  [!] Training non_pretrained model on downstream task...
01/30/2023 01:33:12 PM  [*] Started epoch: 1
01/30/2023 01:33:12 PM  [*] Mon Jan 30 13:33:12 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 2.111446 | Elapsed: 0.08s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.4935
01/30/2023 01:33:18 PM  [*] Mon Jan 30 13:33:18 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.474459 | Elapsed: 6.22s | FPR 0.0003 -> TPR 0.4516 & F1 0.6222 | AUC 0.8510
01/30/2023 01:33:20 PM  [*] Mon Jan 30 13:33:20 2023:    1    | Tr.loss: 0.588374 | Elapsed:   7.57   s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7397
01/30/2023 01:33:20 PM  [*] Started epoch: 2
01/30/2023 01:33:20 PM  [*] Mon Jan 30 13:33:20 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.373533 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.5500 & F1 0.7097 | AUC 0.9021
01/30/2023 01:33:26 PM  [*] Mon Jan 30 13:33:26 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.385547 | Elapsed: 6.21s | FPR 0.0003 -> TPR 0.4444 & F1 0.6154 | AUC 0.9127
01/30/2023 01:33:27 PM  [*] Mon Jan 30 13:33:27 2023:    2    | Tr.loss: 0.376598 | Elapsed:   7.62   s | FPR 0.0003 -> TPR: 0.03 & F1: 0.05 | AUC: 0.8864
01/30/2023 01:33:27 PM  [*] Started epoch: 3
01/30/2023 01:33:27 PM  [*] Mon Jan 30 13:33:27 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.302658 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.3500 & F1 0.5185 | AUC 0.9448
01/30/2023 01:33:34 PM  [*] Mon Jan 30 13:33:34 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.290532 | Elapsed: 6.20s | FPR 0.0003 -> TPR 0.5714 & F1 0.7273 | AUC 0.9305
01/30/2023 01:33:35 PM  [*] Mon Jan 30 13:33:35 2023:    3    | Tr.loss: 0.322680 | Elapsed:   7.55   s | FPR 0.0003 -> TPR: 0.21 & F1: 0.35 | AUC: 0.9176
01/30/2023 01:33:35 PM [!] Mon Jan 30 13:33:35 2023: Dumped results:
                model     : 1675082015-model.torch
		train time: 1675082015-trainTime.npy
		train losses: 1675082015-trainLosses.npy
		train AUC: 1675082015-auc.npy
		train F1s : 1675082015-trainF1s.npy
		train TPRs: 1675082015-trainTPRs.npy
01/30/2023 01:33:35 PM  [*] Evaluating pretrained model on test set...
01/30/2023 01:33:40 PM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.1291 | F1: 0.2287
01/30/2023 01:33:40 PM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1666 | F1: 0.2856
01/30/2023 01:33:40 PM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.2987 | F1: 0.4597
01/30/2023 01:33:40 PM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.3612 | F1: 0.5297
01/30/2023 01:33:40 PM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.4219 | F1: 0.5899
01/30/2023 01:33:40 PM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4812 | F1: 0.6388
01/30/2023 01:33:40 PM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.5815 | F1: 0.6979
01/30/2023 01:33:40 PM  [*] Evaluating non_pretrained model on test set...
01/30/2023 01:33:45 PM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0468 | F1: 0.0894
01/30/2023 01:33:45 PM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1445 | F1: 0.2525
01/30/2023 01:33:45 PM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.1913 | F1: 0.3210
01/30/2023 01:33:45 PM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.2438 | F1: 0.3912
01/30/2023 01:33:45 PM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3482 | F1: 0.5133
01/30/2023 01:33:45 PM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4538 | F1: 0.6135
01/30/2023 01:33:45 PM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.5961 | F1: 0.7091
01/30/2023 01:33:45 PM  [!] Running pre-training split 3/3
01/30/2023 01:33:48 PM  [!] Pre-training model...
01/30/2023 01:33:49 PM  [*] Masking sequences...
01/30/2023 01:34:07 PM  [*] Started epoch: 1
01/30/2023 01:34:07 PM  [*] Mon Jan 30 13:34:07 2023: Train Epoch: 1 [  0  /61661 (0 %)]	Loss: 403.496613 | Elapsed: 0.36s
01/30/2023 01:34:20 PM  [*] Mon Jan 30 13:34:20 2023: Train Epoch: 1 [6400 /61661 (10%)]	Loss: 235.619751 | Elapsed: 12.29s
01/30/2023 01:34:32 PM  [*] Mon Jan 30 13:34:32 2023: Train Epoch: 1 [12800/61661 (21%)]	Loss: 225.316574 | Elapsed: 12.26s
01/30/2023 01:34:44 PM  [*] Mon Jan 30 13:34:44 2023: Train Epoch: 1 [19200/61661 (31%)]	Loss: 206.404694 | Elapsed: 12.34s
01/30/2023 01:34:56 PM  [*] Mon Jan 30 13:34:56 2023: Train Epoch: 1 [25600/61661 (41%)]	Loss: 204.123474 | Elapsed: 12.25s
01/30/2023 01:35:09 PM  [*] Mon Jan 30 13:35:09 2023: Train Epoch: 1 [32000/61661 (52%)]	Loss: 203.818756 | Elapsed: 12.33s
01/30/2023 01:35:21 PM  [*] Mon Jan 30 13:35:21 2023: Train Epoch: 1 [38400/61661 (62%)]	Loss: 203.990784 | Elapsed: 12.29s
01/30/2023 01:35:33 PM  [*] Mon Jan 30 13:35:33 2023: Train Epoch: 1 [44800/61661 (73%)]	Loss: 191.579681 | Elapsed: 12.38s
01/30/2023 01:35:46 PM  [*] Mon Jan 30 13:35:46 2023: Train Epoch: 1 [51200/61661 (83%)]	Loss: 200.455200 | Elapsed: 12.31s
01/30/2023 01:35:58 PM  [*] Mon Jan 30 13:35:58 2023: Train Epoch: 1 [57600/61661 (93%)]	Loss: 185.122131 | Elapsed: 12.34s
01/30/2023 01:36:08 PM  [*] Mon Jan 30 13:36:08 2023:    1    | Tr.loss: 211.342627 | Elapsed:  120.68  s
01/30/2023 01:36:08 PM  [*] Started epoch: 2
01/30/2023 01:36:08 PM  [*] Mon Jan 30 13:36:08 2023: Train Epoch: 2 [  0  /61661 (0 %)]	Loss: 190.021881 | Elapsed: 0.13s
01/30/2023 01:36:20 PM  [*] Mon Jan 30 13:36:20 2023: Train Epoch: 2 [6400 /61661 (10%)]	Loss: 188.455627 | Elapsed: 12.53s
01/30/2023 01:36:33 PM  [*] Mon Jan 30 13:36:33 2023: Train Epoch: 2 [12800/61661 (21%)]	Loss: 195.175171 | Elapsed: 12.30s
01/30/2023 01:36:45 PM  [*] Mon Jan 30 13:36:45 2023: Train Epoch: 2 [19200/61661 (31%)]	Loss: 193.480148 | Elapsed: 12.33s
01/30/2023 01:36:57 PM  [*] Mon Jan 30 13:36:57 2023: Train Epoch: 2 [25600/61661 (41%)]	Loss: 176.472778 | Elapsed: 12.33s
01/30/2023 01:37:10 PM  [*] Mon Jan 30 13:37:10 2023: Train Epoch: 2 [32000/61661 (52%)]	Loss: 198.138977 | Elapsed: 12.38s
01/30/2023 01:37:22 PM  [*] Mon Jan 30 13:37:22 2023: Train Epoch: 2 [38400/61661 (62%)]	Loss: 198.189423 | Elapsed: 12.34s
01/30/2023 01:37:34 PM  [*] Mon Jan 30 13:37:34 2023: Train Epoch: 2 [44800/61661 (73%)]	Loss: 164.950592 | Elapsed: 12.40s
01/30/2023 01:37:47 PM  [*] Mon Jan 30 13:37:47 2023: Train Epoch: 2 [51200/61661 (83%)]	Loss: 196.318893 | Elapsed: 12.28s
01/30/2023 01:37:59 PM  [*] Mon Jan 30 13:37:59 2023: Train Epoch: 2 [57600/61661 (93%)]	Loss: 181.860718 | Elapsed: 12.38s
01/30/2023 01:38:09 PM  [*] Mon Jan 30 13:38:09 2023:    2    | Tr.loss: 190.966532 | Elapsed:  120.98  s
01/30/2023 01:38:09 PM  [*] Started epoch: 3
01/30/2023 01:38:09 PM  [*] Mon Jan 30 13:38:09 2023: Train Epoch: 3 [  0  /61661 (0 %)]	Loss: 195.644867 | Elapsed: 0.12s
01/30/2023 01:38:21 PM  [*] Mon Jan 30 13:38:21 2023: Train Epoch: 3 [6400 /61661 (10%)]	Loss: 196.531448 | Elapsed: 12.50s
01/30/2023 01:38:34 PM  [*] Mon Jan 30 13:38:34 2023: Train Epoch: 3 [12800/61661 (21%)]	Loss: 176.707428 | Elapsed: 13.02s
01/30/2023 01:38:47 PM  [*] Mon Jan 30 13:38:47 2023: Train Epoch: 3 [19200/61661 (31%)]	Loss: 197.057449 | Elapsed: 12.69s
01/30/2023 01:38:59 PM  [*] Mon Jan 30 13:38:59 2023: Train Epoch: 3 [25600/61661 (41%)]	Loss: 188.591721 | Elapsed: 12.51s
01/30/2023 01:39:12 PM  [*] Mon Jan 30 13:39:12 2023: Train Epoch: 3 [32000/61661 (52%)]	Loss: 166.875458 | Elapsed: 12.43s
01/30/2023 01:39:24 PM  [*] Mon Jan 30 13:39:24 2023: Train Epoch: 3 [38400/61661 (62%)]	Loss: 182.524445 | Elapsed: 12.42s
01/30/2023 01:39:37 PM  [*] Mon Jan 30 13:39:37 2023: Train Epoch: 3 [44800/61661 (73%)]	Loss: 152.630310 | Elapsed: 12.31s
01/30/2023 01:39:49 PM  [*] Mon Jan 30 13:39:49 2023: Train Epoch: 3 [51200/61661 (83%)]	Loss: 182.066559 | Elapsed: 12.35s
01/30/2023 01:40:01 PM  [*] Mon Jan 30 13:40:01 2023: Train Epoch: 3 [57600/61661 (93%)]	Loss: 166.094345 | Elapsed: 12.32s
01/30/2023 01:40:11 PM  [*] Mon Jan 30 13:40:11 2023:    3    | Tr.loss: 185.127688 | Elapsed:  122.19  s
01/30/2023 01:40:11 PM  [*] Started epoch: 4
01/30/2023 01:40:11 PM  [*] Mon Jan 30 13:40:11 2023: Train Epoch: 4 [  0  /61661 (0 %)]	Loss: 179.891754 | Elapsed: 0.14s
01/30/2023 01:40:23 PM  [*] Mon Jan 30 13:40:23 2023: Train Epoch: 4 [6400 /61661 (10%)]	Loss: 193.261993 | Elapsed: 12.44s
01/30/2023 01:40:36 PM  [*] Mon Jan 30 13:40:36 2023: Train Epoch: 4 [12800/61661 (21%)]	Loss: 182.830597 | Elapsed: 12.44s
01/30/2023 01:40:48 PM  [*] Mon Jan 30 13:40:48 2023: Train Epoch: 4 [19200/61661 (31%)]	Loss: 160.269638 | Elapsed: 12.31s
01/30/2023 01:41:00 PM  [*] Mon Jan 30 13:41:00 2023: Train Epoch: 4 [25600/61661 (41%)]	Loss: 193.465607 | Elapsed: 12.35s
01/30/2023 01:41:13 PM  [*] Mon Jan 30 13:41:13 2023: Train Epoch: 4 [32000/61661 (52%)]	Loss: 196.479126 | Elapsed: 12.41s
01/30/2023 01:41:25 PM  [*] Mon Jan 30 13:41:25 2023: Train Epoch: 4 [38400/61661 (62%)]	Loss: 163.924042 | Elapsed: 12.44s
01/30/2023 01:41:38 PM  [*] Mon Jan 30 13:41:38 2023: Train Epoch: 4 [44800/61661 (73%)]	Loss: 180.085434 | Elapsed: 12.36s
01/30/2023 01:41:50 PM  [*] Mon Jan 30 13:41:50 2023: Train Epoch: 4 [51200/61661 (83%)]	Loss: 202.282410 | Elapsed: 12.32s
01/30/2023 01:42:02 PM  [*] Mon Jan 30 13:42:02 2023: Train Epoch: 4 [57600/61661 (93%)]	Loss: 168.578033 | Elapsed: 12.30s
01/30/2023 01:42:12 PM  [*] Mon Jan 30 13:42:12 2023:    4    | Tr.loss: 182.377013 | Elapsed:  121.06  s
01/30/2023 01:42:12 PM  [*] Started epoch: 5
01/30/2023 01:42:12 PM  [*] Mon Jan 30 13:42:12 2023: Train Epoch: 5 [  0  /61661 (0 %)]	Loss: 177.107803 | Elapsed: 0.21s
01/30/2023 01:42:24 PM  [*] Mon Jan 30 13:42:24 2023: Train Epoch: 5 [6400 /61661 (10%)]	Loss: 194.503510 | Elapsed: 12.39s
01/30/2023 01:42:37 PM  [*] Mon Jan 30 13:42:37 2023: Train Epoch: 5 [12800/61661 (21%)]	Loss: 194.495544 | Elapsed: 12.48s
01/30/2023 01:42:49 PM  [*] Mon Jan 30 13:42:49 2023: Train Epoch: 5 [19200/61661 (31%)]	Loss: 169.432663 | Elapsed: 12.33s
01/30/2023 01:43:02 PM  [*] Mon Jan 30 13:43:02 2023: Train Epoch: 5 [25600/61661 (41%)]	Loss: 172.375626 | Elapsed: 12.33s
01/30/2023 01:43:14 PM  [*] Mon Jan 30 13:43:14 2023: Train Epoch: 5 [32000/61661 (52%)]	Loss: 200.611099 | Elapsed: 12.29s
01/30/2023 01:43:26 PM  [*] Mon Jan 30 13:43:26 2023: Train Epoch: 5 [38400/61661 (62%)]	Loss: 201.866135 | Elapsed: 12.43s
01/30/2023 01:43:39 PM  [*] Mon Jan 30 13:43:39 2023: Train Epoch: 5 [44800/61661 (73%)]	Loss: 181.018463 | Elapsed: 12.31s
01/30/2023 01:43:51 PM  [*] Mon Jan 30 13:43:51 2023: Train Epoch: 5 [51200/61661 (83%)]	Loss: 186.386047 | Elapsed: 12.46s
01/30/2023 01:44:03 PM  [*] Mon Jan 30 13:44:03 2023: Train Epoch: 5 [57600/61661 (93%)]	Loss: 199.488312 | Elapsed: 12.32s
01/30/2023 01:44:13 PM  [*] Mon Jan 30 13:44:13 2023:    5    | Tr.loss: 180.717941 | Elapsed:  121.03  s
01/30/2023 01:44:13 PM  [*] Started epoch: 6
01/30/2023 01:44:13 PM  [*] Mon Jan 30 13:44:13 2023: Train Epoch: 6 [  0  /61661 (0 %)]	Loss: 159.705734 | Elapsed: 0.13s
01/30/2023 01:44:25 PM  [*] Mon Jan 30 13:44:25 2023: Train Epoch: 6 [6400 /61661 (10%)]	Loss: 175.388596 | Elapsed: 12.32s
01/30/2023 01:44:38 PM  [*] Mon Jan 30 13:44:38 2023: Train Epoch: 6 [12800/61661 (21%)]	Loss: 186.909988 | Elapsed: 12.40s
01/30/2023 01:44:50 PM  [*] Mon Jan 30 13:44:50 2023: Train Epoch: 6 [19200/61661 (31%)]	Loss: 177.034332 | Elapsed: 12.36s
01/30/2023 01:45:02 PM  [*] Mon Jan 30 13:45:02 2023: Train Epoch: 6 [25600/61661 (41%)]	Loss: 165.019409 | Elapsed: 12.40s
01/30/2023 01:45:15 PM  [*] Mon Jan 30 13:45:15 2023: Train Epoch: 6 [32000/61661 (52%)]	Loss: 204.164795 | Elapsed: 12.28s
01/30/2023 01:45:27 PM  [*] Mon Jan 30 13:45:27 2023: Train Epoch: 6 [38400/61661 (62%)]	Loss: 187.586166 | Elapsed: 12.35s
01/30/2023 01:45:39 PM  [*] Mon Jan 30 13:45:39 2023: Train Epoch: 6 [44800/61661 (73%)]	Loss: 190.863571 | Elapsed: 12.40s
01/30/2023 01:45:52 PM  [*] Mon Jan 30 13:45:52 2023: Train Epoch: 6 [51200/61661 (83%)]	Loss: 184.699509 | Elapsed: 12.39s
01/30/2023 01:46:04 PM  [*] Mon Jan 30 13:46:04 2023: Train Epoch: 6 [57600/61661 (93%)]	Loss: 179.229950 | Elapsed: 12.35s
01/30/2023 01:46:14 PM  [*] Mon Jan 30 13:46:14 2023:    6    | Tr.loss: 179.571412 | Elapsed:  121.13  s
01/30/2023 01:46:14 PM  [*] Started epoch: 7
01/30/2023 01:46:14 PM  [*] Mon Jan 30 13:46:14 2023: Train Epoch: 7 [  0  /61661 (0 %)]	Loss: 177.791229 | Elapsed: 0.20s
01/30/2023 01:46:27 PM  [*] Mon Jan 30 13:46:27 2023: Train Epoch: 7 [6400 /61661 (10%)]	Loss: 178.761963 | Elapsed: 12.45s
01/30/2023 01:46:39 PM  [*] Mon Jan 30 13:46:39 2023: Train Epoch: 7 [12800/61661 (21%)]	Loss: 144.774673 | Elapsed: 12.43s
01/30/2023 01:46:52 PM  [*] Mon Jan 30 13:46:52 2023: Train Epoch: 7 [19200/61661 (31%)]	Loss: 185.355469 | Elapsed: 12.52s
01/30/2023 01:47:04 PM  [*] Mon Jan 30 13:47:04 2023: Train Epoch: 7 [25600/61661 (41%)]	Loss: 180.126190 | Elapsed: 12.31s
01/30/2023 01:47:16 PM  [*] Mon Jan 30 13:47:16 2023: Train Epoch: 7 [32000/61661 (52%)]	Loss: 164.460480 | Elapsed: 12.37s
01/30/2023 01:47:29 PM  [*] Mon Jan 30 13:47:29 2023: Train Epoch: 7 [38400/61661 (62%)]	Loss: 169.449799 | Elapsed: 12.34s
01/30/2023 01:47:41 PM  [*] Mon Jan 30 13:47:41 2023: Train Epoch: 7 [44800/61661 (73%)]	Loss: 180.550980 | Elapsed: 12.36s
01/30/2023 01:47:53 PM  [*] Mon Jan 30 13:47:53 2023: Train Epoch: 7 [51200/61661 (83%)]	Loss: 197.140244 | Elapsed: 12.31s
01/30/2023 01:48:06 PM  [*] Mon Jan 30 13:48:06 2023: Train Epoch: 7 [57600/61661 (93%)]	Loss: 180.680313 | Elapsed: 12.44s
01/30/2023 01:48:15 PM  [*] Mon Jan 30 13:48:15 2023:    7    | Tr.loss: 178.632447 | Elapsed:  121.26  s
01/30/2023 01:48:15 PM  [*] Started epoch: 8
01/30/2023 01:48:15 PM  [*] Mon Jan 30 13:48:15 2023: Train Epoch: 8 [  0  /61661 (0 %)]	Loss: 173.886337 | Elapsed: 0.22s
01/30/2023 01:48:28 PM  [*] Mon Jan 30 13:48:28 2023: Train Epoch: 8 [6400 /61661 (10%)]	Loss: 155.764496 | Elapsed: 12.46s
01/30/2023 01:48:40 PM  [*] Mon Jan 30 13:48:40 2023: Train Epoch: 8 [12800/61661 (21%)]	Loss: 179.040085 | Elapsed: 12.41s
01/30/2023 01:48:53 PM  [*] Mon Jan 30 13:48:53 2023: Train Epoch: 8 [19200/61661 (31%)]	Loss: 175.887955 | Elapsed: 12.45s
01/30/2023 01:49:05 PM  [*] Mon Jan 30 13:49:05 2023: Train Epoch: 8 [25600/61661 (41%)]	Loss: 185.940979 | Elapsed: 12.40s
01/30/2023 01:49:18 PM  [*] Mon Jan 30 13:49:18 2023: Train Epoch: 8 [32000/61661 (52%)]	Loss: 170.494614 | Elapsed: 12.45s
01/30/2023 01:49:30 PM  [*] Mon Jan 30 13:49:30 2023: Train Epoch: 8 [38400/61661 (62%)]	Loss: 164.425171 | Elapsed: 12.23s
01/30/2023 01:49:42 PM  [*] Mon Jan 30 13:49:42 2023: Train Epoch: 8 [44800/61661 (73%)]	Loss: 174.814270 | Elapsed: 12.32s
01/30/2023 01:49:54 PM  [*] Mon Jan 30 13:49:54 2023: Train Epoch: 8 [51200/61661 (83%)]	Loss: 193.326355 | Elapsed: 12.33s
01/30/2023 01:50:07 PM  [*] Mon Jan 30 13:50:07 2023: Train Epoch: 8 [57600/61661 (93%)]	Loss: 194.685257 | Elapsed: 12.34s
01/30/2023 01:50:16 PM  [*] Mon Jan 30 13:50:16 2023:    8    | Tr.loss: 177.841154 | Elapsed:  121.08  s
01/30/2023 01:50:16 PM  [*] Started epoch: 9
01/30/2023 01:50:16 PM  [*] Mon Jan 30 13:50:16 2023: Train Epoch: 9 [  0  /61661 (0 %)]	Loss: 179.638062 | Elapsed: 0.13s
01/30/2023 01:50:29 PM  [*] Mon Jan 30 13:50:29 2023: Train Epoch: 9 [6400 /61661 (10%)]	Loss: 162.059967 | Elapsed: 12.38s
01/30/2023 01:50:41 PM  [*] Mon Jan 30 13:50:41 2023: Train Epoch: 9 [12800/61661 (21%)]	Loss: 189.984283 | Elapsed: 12.37s
01/30/2023 01:50:54 PM  [*] Mon Jan 30 13:50:54 2023: Train Epoch: 9 [19200/61661 (31%)]	Loss: 195.511200 | Elapsed: 12.41s
01/30/2023 01:51:06 PM  [*] Mon Jan 30 13:51:06 2023: Train Epoch: 9 [25600/61661 (41%)]	Loss: 179.754944 | Elapsed: 12.36s
01/30/2023 01:51:18 PM  [*] Mon Jan 30 13:51:18 2023: Train Epoch: 9 [32000/61661 (52%)]	Loss: 187.663300 | Elapsed: 12.39s
01/30/2023 01:51:31 PM  [*] Mon Jan 30 13:51:31 2023: Train Epoch: 9 [38400/61661 (62%)]	Loss: 167.796021 | Elapsed: 12.31s
01/30/2023 01:51:43 PM  [*] Mon Jan 30 13:51:43 2023: Train Epoch: 9 [44800/61661 (73%)]	Loss: 193.518005 | Elapsed: 12.37s
01/30/2023 01:51:55 PM  [*] Mon Jan 30 13:51:55 2023: Train Epoch: 9 [51200/61661 (83%)]	Loss: 187.695923 | Elapsed: 12.40s
01/30/2023 01:52:08 PM  [*] Mon Jan 30 13:52:08 2023: Train Epoch: 9 [57600/61661 (93%)]	Loss: 192.536423 | Elapsed: 12.31s
01/30/2023 01:52:17 PM  [*] Mon Jan 30 13:52:17 2023:    9    | Tr.loss: 177.262002 | Elapsed:  120.94  s
01/30/2023 01:52:17 PM  [*] Started epoch: 10
01/30/2023 01:52:17 PM  [*] Mon Jan 30 13:52:17 2023: Train Epoch: 10 [  0  /61661 (0 %)]	Loss: 165.470428 | Elapsed: 0.13s
01/30/2023 01:52:30 PM  [*] Mon Jan 30 13:52:30 2023: Train Epoch: 10 [6400 /61661 (10%)]	Loss: 171.039413 | Elapsed: 12.41s
01/30/2023 01:52:42 PM  [*] Mon Jan 30 13:52:42 2023: Train Epoch: 10 [12800/61661 (21%)]	Loss: 165.546387 | Elapsed: 12.37s
01/30/2023 01:52:54 PM  [*] Mon Jan 30 13:52:54 2023: Train Epoch: 10 [19200/61661 (31%)]	Loss: 180.131516 | Elapsed: 12.31s
01/30/2023 01:53:07 PM  [*] Mon Jan 30 13:53:07 2023: Train Epoch: 10 [25600/61661 (41%)]	Loss: 159.822845 | Elapsed: 12.33s
01/30/2023 01:53:19 PM  [*] Mon Jan 30 13:53:19 2023: Train Epoch: 10 [32000/61661 (52%)]	Loss: 182.111115 | Elapsed: 12.37s
01/30/2023 01:53:32 PM  [*] Mon Jan 30 13:53:32 2023: Train Epoch: 10 [38400/61661 (62%)]	Loss: 180.109940 | Elapsed: 12.63s
01/30/2023 01:53:45 PM  [*] Mon Jan 30 13:53:45 2023: Train Epoch: 10 [44800/61661 (73%)]	Loss: 192.668961 | Elapsed: 12.75s
01/30/2023 01:53:57 PM  [*] Mon Jan 30 13:53:57 2023: Train Epoch: 10 [51200/61661 (83%)]	Loss: 182.527985 | Elapsed: 12.57s
01/30/2023 01:54:10 PM  [*] Mon Jan 30 13:54:10 2023: Train Epoch: 10 [57600/61661 (93%)]	Loss: 192.768463 | Elapsed: 12.44s
01/30/2023 01:54:19 PM  [*] Mon Jan 30 13:54:19 2023:   10    | Tr.loss: 176.609330 | Elapsed:  122.10  s
01/30/2023 01:54:20 PM [!] Mon Jan 30 13:54:20 2023: Dumped results:
                model     : 1675083259-model.torch
		train time: 1675083259-trainTime.npy
		train losses: 1675083259-trainLosses.npy
		train AUC: 1675083259-auc.npy
01/30/2023 01:54:22 PM  [!] Training pretrained model on downstream task...
01/30/2023 01:54:22 PM  [*] Started epoch: 1
01/30/2023 01:54:22 PM  [*] Mon Jan 30 13:54:22 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 2.276694 | Elapsed: 0.37s | FPR 0.0003 -> TPR 0.2791 & F1 0.4364 | AUC 0.6788
01/30/2023 01:54:31 PM  [*] Mon Jan 30 13:54:31 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.467633 | Elapsed: 9.21s | FPR 0.0003 -> TPR 0.2381 & F1 0.3846 | AUC 0.7868
01/30/2023 01:54:33 PM  [*] Mon Jan 30 13:54:33 2023:    1    | Tr.loss: 0.685888 | Elapsed:   11.47  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.7361
01/30/2023 01:54:33 PM  [*] Started epoch: 2
01/30/2023 01:54:33 PM  [*] Mon Jan 30 13:54:33 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.417669 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.4894 & F1 0.6571 | AUC 0.7860
01/30/2023 01:54:42 PM  [*] Mon Jan 30 13:54:42 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.536782 | Elapsed: 9.13s | FPR 0.0003 -> TPR 0.2273 & F1 0.3704 | AUC 0.7402
01/30/2023 01:54:44 PM  [*] Mon Jan 30 13:54:44 2023:    2    | Tr.loss: 0.452089 | Elapsed:   11.05  s | FPR 0.0003 -> TPR: 0.07 & F1: 0.14 | AUC: 0.8168
01/30/2023 01:54:44 PM  [*] Started epoch: 3
01/30/2023 01:54:44 PM  [*] Mon Jan 30 13:54:44 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.455332 | Elapsed: 0.09s | FPR 0.0003 -> TPR 0.2895 & F1 0.4490 | AUC 0.7874
01/30/2023 01:54:54 PM  [*] Mon Jan 30 13:54:54 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.366100 | Elapsed: 9.15s | FPR 0.0003 -> TPR 0.5821 & F1 0.7358 | AUC 0.9184
01/30/2023 01:54:55 PM  [*] Mon Jan 30 13:54:55 2023:    3    | Tr.loss: 0.412806 | Elapsed:   11.06  s | FPR 0.0003 -> TPR: 0.15 & F1: 0.27 | AUC: 0.8550
01/30/2023 01:54:56 PM [!] Mon Jan 30 13:54:56 2023: Dumped results:
                model     : 1675083295-model.torch
		train time: 1675083295-trainTime.npy
		train losses: 1675083295-trainLosses.npy
		train AUC: 1675083295-auc.npy
		train F1s : 1675083295-trainF1s.npy
		train TPRs: 1675083295-trainTPRs.npy
01/30/2023 01:54:56 PM  [!] Training non_pretrained model on downstream task...
01/30/2023 01:54:56 PM  [*] Started epoch: 1
01/30/2023 01:54:56 PM  [*] Mon Jan 30 13:54:56 2023: Train Epoch: 1 [  0  /7613  (0 %)]	Loss: 3.311242 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.0408 & F1 0.0784 | AUC 0.4041
01/30/2023 01:55:03 PM  [*] Mon Jan 30 13:55:03 2023: Train Epoch: 1 [6400 /7613  (84%)]	Loss: 0.449081 | Elapsed: 6.24s | FPR 0.0003 -> TPR 0.1912 & F1 0.3210 | AUC 0.7716
01/30/2023 01:55:04 PM  [*] Mon Jan 30 13:55:04 2023:    1    | Tr.loss: 0.709344 | Elapsed:   7.62   s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.6973
01/30/2023 01:55:04 PM  [*] Started epoch: 2
01/30/2023 01:55:04 PM  [*] Mon Jan 30 13:55:04 2023: Train Epoch: 2 [  0  /7613  (0 %)]	Loss: 0.525284 | Elapsed: 0.06s | FPR 0.0003 -> TPR 0.1111 & F1 0.2000 | AUC 0.7474
01/30/2023 01:55:10 PM  [*] Mon Jan 30 13:55:10 2023: Train Epoch: 2 [6400 /7613  (84%)]	Loss: 0.407844 | Elapsed: 6.23s | FPR 0.0003 -> TPR 0.2174 & F1 0.3571 | AUC 0.8943
01/30/2023 01:55:11 PM  [*] Mon Jan 30 13:55:11 2023:    2    | Tr.loss: 0.401598 | Elapsed:   7.66   s | FPR 0.0003 -> TPR: 0.16 & F1: 0.28 | AUC: 0.8727
01/30/2023 01:55:11 PM  [*] Started epoch: 3
01/30/2023 01:55:12 PM  [*] Mon Jan 30 13:55:12 2023: Train Epoch: 3 [  0  /7613  (0 %)]	Loss: 0.324976 | Elapsed: 0.07s | FPR 0.0003 -> TPR 0.4348 & F1 0.6061 | AUC 0.9143
01/30/2023 01:55:18 PM  [*] Mon Jan 30 13:55:18 2023: Train Epoch: 3 [6400 /7613  (84%)]	Loss: 0.328136 | Elapsed: 6.26s | FPR 0.0003 -> TPR 0.6897 & F1 0.8163 | AUC 0.9397
01/30/2023 01:55:19 PM  [*] Mon Jan 30 13:55:19 2023:    3    | Tr.loss: 0.341537 | Elapsed:   7.62   s | FPR 0.0003 -> TPR: 0.04 & F1: 0.07 | AUC: 0.9103
01/30/2023 01:55:20 PM [!] Mon Jan 30 13:55:20 2023: Dumped results:
                model     : 1675083319-model.torch
		train time: 1675083319-trainTime.npy
		train losses: 1675083319-trainLosses.npy
		train AUC: 1675083319-auc.npy
		train F1s : 1675083319-trainF1s.npy
		train TPRs: 1675083319-trainTPRs.npy
01/30/2023 01:55:20 PM  [*] Evaluating pretrained model on test set...
01/30/2023 01:55:25 PM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.1247 | F1: 0.2218
01/30/2023 01:55:25 PM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1798 | F1: 0.3048
01/30/2023 01:55:25 PM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.2362 | F1: 0.3819
01/30/2023 01:55:25 PM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.2718 | F1: 0.4266
01/30/2023 01:55:25 PM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3155 | F1: 0.4766
01/30/2023 01:55:25 PM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.3813 | F1: 0.5421
01/30/2023 01:55:25 PM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.4956 | F1: 0.6271
01/30/2023 01:55:25 PM  [*] Evaluating non_pretrained model on test set...
01/30/2023 01:55:29 PM 	[!] Test set scores at FPR: 0.0001 --> TPR: 0.0097 | F1: 0.0192
01/30/2023 01:55:29 PM 	[!] Test set scores at FPR: 0.0003 --> TPR: 0.1216 | F1: 0.2167
01/30/2023 01:55:29 PM 	[!] Test set scores at FPR:  0.001 --> TPR: 0.2017 | F1: 0.3355
01/30/2023 01:55:29 PM 	[!] Test set scores at FPR:  0.003 --> TPR: 0.2423 | F1: 0.3892
01/30/2023 01:55:29 PM 	[!] Test set scores at FPR:   0.01 --> TPR: 0.3197 | F1: 0.4814
01/30/2023 01:55:29 PM 	[!] Test set scores at FPR:   0.03 --> TPR: 0.4279 | F1: 0.5889
01/30/2023 01:55:29 PM 	[!] Test set scores at FPR:    0.1 --> TPR: 0.6034 | F1: 0.7147
01/30/2023 01:55:30 PM  [!] Finished pre-training evaluation over 3 splits! Saved metrics to:
	C:\Users\dtrizna\Code\nebula\scripts\..\evaluation\MaskedLanguageModeling\downsample_tests\downsample_U_0.9_1675079416/metrics_MaskedLanguageModel_nSplits_3_limit_None.json
