{
    "unlabeledDataSize": 0.9,
    "nSplits": 3,
    "downStreamEpochs": 3,
    "preTrainEpochs": 10,
    "falsePositiveRates": [
        0.0001,
        0.0003,
        0.001,
        0.003,
        0.01,
        0.03,
        0.1
    ],
    "modelType": "TransformerEncoderLM",
    "train_limit": null,
    "random_state": 42,
    "batchSize": 64,
    "optimizerStep": 0,
    "verbosity_batches": 100,
    "downsample_unlabeled_data": 0.5,
    "training_types": [
        "pretrained",
        "non_pretrained"
    ]
}