2023-03-18 21:04:23,193 WARNING  [!] Working on api_file_network_registry!
2023-03-18 21:04:23,194 WARNING  [!] Skipping since exists: out_fields_1679165454\api_file_network_registry_vocab_50000_seqlen_512\x_train_full.npy
2023-03-18 21:04:23,275 WARNING  [!] Skipping since exists: out_fields_1679165454\api_file_network_registry_vocab_50000_seqlen_512\x_test_full.npy
2023-03-18 21:04:23,317 WARNING  [!!!] Starting CV over api_file_network_registry!
2023-03-18 21:04:23,399 WARNING  [!] CV output folder out_fields_1679165454\cv_api_file_network_registry_limNone_r1763_t5 already exists, skipping!
2023-03-18 21:04:23,400 WARNING  [!] Working on api_only_name!
2023-03-18 21:04:23,402 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_backdoor
2023-03-18 21:06:42,289 WARNING Finished... Took: 138.89s
2023-03-18 21:06:42,290 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_clean
2023-03-18 21:10:19,410 WARNING Finished... Took: 217.12s
2023-03-18 21:10:19,410 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_coinminer
2023-03-18 21:11:16,352 WARNING Finished... Took: 56.94s
2023-03-18 21:11:16,352 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_dropper
2023-03-18 21:12:12,717 WARNING Finished... Took: 56.36s
2023-03-18 21:12:12,717 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_keylogger
2023-03-18 21:12:43,482 WARNING Finished... Took: 30.77s
2023-03-18 21:12:43,483 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_ransomware
2023-03-18 21:14:14,135 WARNING Finished... Took: 90.65s
2023-03-18 21:14:14,135 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_rat
2023-03-18 21:14:36,900 WARNING Finished... Took: 22.76s
2023-03-18 21:14:36,900 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_trojan
2023-03-18 21:15:50,465 WARNING Finished... Took: 73.57s
2023-03-18 21:15:50,465 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_windows_syswow64
2023-03-18 21:15:51,636 WARNING Finished... Took: 1.17s
2023-03-18 21:15:51,643 WARNING  [!] Saved Y as out_fields_1679165454\api_only_name_vocab_50000_seqlen_512\y_train_full.npy
2023-03-18 21:15:51,843 WARNING  [!] Saved Y names as out_fields_1679165454\api_only_name_vocab_50000_seqlen_512\y_names_train_full.json
2023-03-18 21:15:51,843 WARNING  [*] Initializing tokenizer training...
2023-03-18 21:16:16,632 WARNING Dumped vocab to out_fields_1679165454\api_only_name_vocab_50000_seqlen_512\tokenizer_50000_vocab.json
2023-03-18 21:16:16,635 WARNING Dumped vocab counter to out_fields_1679165454\api_only_name_vocab_50000_seqlen_512\tokenizer_50000_counter.json
2023-03-18 21:16:16,635 WARNING  [*] Encoding and padding...
2023-03-18 21:16:51,361 WARNING  [!] Saved X as out_fields_1679165454\api_only_name_vocab_50000_seqlen_512\x_train_full.npy
2023-03-18 21:16:52,767 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_backdoor
2023-03-18 21:17:29,337 WARNING Finished... Took: 36.57s
2023-03-18 21:17:29,337 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_clean
2023-03-18 21:19:03,575 WARNING Finished... Took: 94.24s
2023-03-18 21:19:03,575 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_coinminer
2023-03-18 21:19:30,348 WARNING Finished... Took: 26.77s
2023-03-18 21:19:30,348 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_dropper
2023-03-18 21:19:32,941 WARNING Finished... Took: 2.59s
2023-03-18 21:19:32,941 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_keylogger
2023-03-18 21:19:43,082 WARNING Finished... Took: 10.14s
2023-03-18 21:19:43,082 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_ransomware
2023-03-18 21:21:52,782 WARNING Finished... Took: 129.70s
2023-03-18 21:21:52,782 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_rat
2023-03-18 21:22:11,089 WARNING Finished... Took: 18.31s
2023-03-18 21:22:11,089 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_trojan
2023-03-18 21:22:22,485 WARNING Finished... Took: 11.40s
2023-03-18 21:22:22,485 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_windows_syswow64
2023-03-18 21:22:22,946 WARNING Finished... Took: 0.46s
2023-03-18 21:22:22,955 WARNING  [!] Saved Y as out_fields_1679165454\api_only_name_vocab_50000_seqlen_512\y_test_full.npy
2023-03-18 21:22:22,991 WARNING  [!] Saved Y names as out_fields_1679165454\api_only_name_vocab_50000_seqlen_512\y_names_test_full.json
2023-03-18 21:22:23,006 WARNING  [*] Encoding and padding...
2023-03-18 21:22:41,966 WARNING  [!] Saved X as out_fields_1679165454\api_only_name_vocab_50000_seqlen_512\x_test_full.npy
2023-03-18 21:22:42,472 WARNING  [!!!] Starting CV over api_only_name!
2023-03-18 21:22:42,557 WARNING  [!] Training time budget: 300min
2023-03-18 21:22:42,558 WARNING  [!] Model config: {'vocab_size': 2825, 'maxlen': 512, 'chunk_size': 64, 'dModel': 64, 'nHeads': 8, 'dHidden': 256, 'nLayers': 2, 'numClasses': 1, 'hiddenNeurons': [64], 'layerNorm': False, 'dropout': 0.3, 'mean_over_sequence': False, 'norm_first': True}
2023-03-18 21:22:42,622 WARNING  [1/3] Train set size: 50750, Validation set size: 25376
2023-03-18 21:22:43,583 WARNING  [!] Saved dataset splits to dataset_splits_1679170962.npz
2023-03-18 21:22:44,259 WARNING  [!] Iniatialized TransformerEncoderChunks. Total trainable parameters: 2.3780e6
2023-03-18 21:22:44,259 WARNING  [*] Training time budget set: 5.0 min
2023-03-18 21:22:44,288 WARNING  [*] Started epoch: 1
2023-03-18 21:22:46,016 WARNING  [*] 21:22:46: Train Epoch: 1 [  0  /50750 (0 %)] | Loss: 2.250134 | Elapsed: 1.73s | FPR 0.0003 -> TPR 0.0290 & F1 0.0563 | AUC 0.4616
2023-03-18 21:22:55,618 WARNING  [*] 21:22:55: Train Epoch: 1 [9600 /50750 (19%)] | Loss: 0.461500 | Elapsed: 9.59s | FPR 0.0003 -> TPR 0.0735 & F1 0.1370 | AUC 0.8015
2023-03-18 21:23:05,264 WARNING  [*] 21:23:05: Train Epoch: 1 [19200/50750 (38%)] | Loss: 0.382647 | Elapsed: 9.63s | FPR 0.0003 -> TPR 0.5606 & F1 0.7184 | AUC 0.8815
2023-03-18 21:23:14,952 WARNING  [*] 21:23:14: Train Epoch: 1 [28800/50750 (57%)] | Loss: 0.335021 | Elapsed: 9.69s | FPR 0.0003 -> TPR 0.6066 & F1 0.7551 | AUC 0.9285
2023-03-18 21:23:24,707 WARNING  [*] 21:23:24: Train Epoch: 1 [38400/50750 (76%)] | Loss: 0.283337 | Elapsed: 9.76s | FPR 0.0003 -> TPR 0.4615 & F1 0.6316 | AUC 0.9354
2023-03-18 21:23:34,564 WARNING  [*] 21:23:34: Train Epoch: 1 [48000/50750 (95%)] | Loss: 0.448674 | Elapsed: 9.84s | FPR 0.0003 -> TPR 0.2903 & F1 0.4500 | AUC 0.8591
2023-03-18 21:23:38,324 WARNING  [*] Sat Mar 18 21:23:38 2023:    1    | Tr.loss: 0.379562 | Elapsed:   54.04  s | FPR 0.0003 -> TPR: 0.01 & F1: 0.01 | AUC: 0.8887
2023-03-18 21:23:38,324 WARNING  [*] Started epoch: 2
2023-03-18 21:23:38,449 WARNING  [*] 21:23:38: Train Epoch: 2 [  0  /50750 (0 %)] | Loss: 0.301908 | Elapsed: 0.11s | FPR 0.0003 -> TPR 0.3871 & F1 0.5581 | AUC 0.9265
2023-03-18 21:23:48,320 WARNING  [*] 21:23:48: Train Epoch: 2 [9600 /50750 (19%)] | Loss: 0.249787 | Elapsed: 9.87s | FPR 0.0003 -> TPR 0.5882 & F1 0.7407 | AUC 0.9582
2023-03-18 21:23:58,171 WARNING  [*] 21:23:58: Train Epoch: 2 [19200/50750 (38%)] | Loss: 0.136801 | Elapsed: 9.84s | FPR 0.0003 -> TPR 0.9286 & F1 0.9630 | AUC 0.9914
2023-03-18 21:24:08,018 WARNING  [*] 21:24:08: Train Epoch: 2 [28800/50750 (57%)] | Loss: 0.112844 | Elapsed: 9.85s | FPR 0.0003 -> TPR 0.8356 & F1 0.9104 | AUC 0.9868
2023-03-18 21:24:17,874 WARNING  [*] 21:24:17: Train Epoch: 2 [38400/50750 (76%)] | Loss: 0.121606 | Elapsed: 9.86s | FPR 0.0003 -> TPR 0.8750 & F1 0.9333 | AUC 0.9896
2023-03-18 21:24:27,749 WARNING  [*] 21:24:27: Train Epoch: 2 [48000/50750 (95%)] | Loss: 0.155591 | Elapsed: 9.88s | FPR 0.0003 -> TPR 0.8312 & F1 0.9078 | AUC 0.9819
2023-03-18 21:24:31,542 WARNING  [*] Sat Mar 18 21:24:31 2023:    2    | Tr.loss: 0.205438 | Elapsed:   53.22  s | FPR 0.0003 -> TPR: 0.20 & F1: 0.33 | AUC: 0.9696
2023-03-18 21:24:31,542 WARNING  [*] Started epoch: 3
2023-03-18 21:24:31,656 WARNING  [*] 21:24:31: Train Epoch: 3 [  0  /50750 (0 %)] | Loss: 0.108801 | Elapsed: 0.11s | FPR 0.0003 -> TPR 0.9296 & F1 0.9635 | AUC 0.9921
2023-03-18 21:24:41,546 WARNING  [*] 21:24:41: Train Epoch: 3 [9600 /50750 (19%)] | Loss: 0.140905 | Elapsed: 9.87s | FPR 0.0003 -> TPR 0.8382 & F1 0.9120 | AUC 0.9881
2023-03-18 21:24:51,421 WARNING  [*] 21:24:51: Train Epoch: 3 [19200/50750 (38%)] | Loss: 0.074909 | Elapsed: 9.86s | FPR 0.0003 -> TPR 0.9545 & F1 0.9767 | AUC 0.9969
2023-03-18 21:25:01,283 WARNING  [*] 21:25:01: Train Epoch: 3 [28800/50750 (57%)] | Loss: 0.089254 | Elapsed: 9.86s | FPR 0.0003 -> TPR 0.9306 & F1 0.9640 | AUC 0.9955
2023-03-18 21:25:11,167 WARNING  [*] 21:25:11: Train Epoch: 3 [38400/50750 (76%)] | Loss: 0.198091 | Elapsed: 9.88s | FPR 0.0003 -> TPR 0.8438 & F1 0.9153 | AUC 0.9757
2023-03-18 21:25:21,073 WARNING  [*] 21:25:21: Train Epoch: 3 [48000/50750 (95%)] | Loss: 0.099466 | Elapsed: 9.89s | FPR 0.0003 -> TPR 0.9365 & F1 0.9672 | AUC 0.9936
2023-03-18 21:25:24,835 WARNING  [*] Sat Mar 18 21:25:24 2023:    3    | Tr.loss: 0.158419 | Elapsed:   53.29  s | FPR 0.0003 -> TPR: 0.26 & F1: 0.41 | AUC: 0.9821
2023-03-18 21:25:24,835 WARNING  [*] Started epoch: 4
2023-03-18 21:25:24,968 WARNING  [*] 21:25:24: Train Epoch: 4 [  0  /50750 (0 %)] | Loss: 0.179365 | Elapsed: 0.12s | FPR 0.0003 -> TPR 0.8814 & F1 0.9369 | AUC 0.9840
2023-03-18 21:25:34,860 WARNING  [*] 21:25:34: Train Epoch: 4 [9600 /50750 (19%)] | Loss: 0.116836 | Elapsed: 9.89s | FPR 0.0003 -> TPR 0.9296 & F1 0.9635 | AUC 0.9947
2023-03-18 21:25:44,757 WARNING  [*] 21:25:44: Train Epoch: 4 [19200/50750 (38%)] | Loss: 0.142037 | Elapsed: 9.88s | FPR 0.0003 -> TPR 0.9365 & F1 0.9672 | AUC 0.9888
2023-03-18 21:25:54,634 WARNING  [*] 21:25:54: Train Epoch: 4 [28800/50750 (57%)] | Loss: 0.149329 | Elapsed: 9.88s | FPR 0.0003 -> TPR 0.9219 & F1 0.9593 | AUC 0.9883
2023-03-18 21:26:04,554 WARNING  [*] 21:26:04: Train Epoch: 4 [38400/50750 (76%)] | Loss: 0.178554 | Elapsed: 9.90s | FPR 0.0003 -> TPR 0.8788 & F1 0.9355 | AUC 0.9840
2023-03-18 21:26:14,434 WARNING  [*] 21:26:14: Train Epoch: 4 [48000/50750 (95%)] | Loss: 0.217859 | Elapsed: 9.88s | FPR 0.0003 -> TPR 0.6618 & F1 0.7965 | AUC 0.9784
2023-03-18 21:26:18,208 WARNING  [*] Sat Mar 18 21:26:18 2023:    4    | Tr.loss: 0.138946 | Elapsed:   53.37  s | FPR 0.0003 -> TPR: 0.32 & F1: 0.48 | AUC: 0.9862
2023-03-18 21:26:18,208 WARNING  [*] Started epoch: 5
2023-03-18 21:26:18,332 WARNING  [*] 21:26:18: Train Epoch: 5 [  0  /50750 (0 %)] | Loss: 0.102906 | Elapsed: 0.11s | FPR 0.0003 -> TPR 0.9206 & F1 0.9587 | AUC 0.9928
2023-03-18 21:26:28,253 WARNING  [*] 21:26:28: Train Epoch: 5 [9600 /50750 (19%)] | Loss: 0.079202 | Elapsed: 9.90s | FPR 0.0003 -> TPR 0.9219 & F1 0.9593 | AUC 0.9965
2023-03-18 21:26:38,140 WARNING  [*] 21:26:38: Train Epoch: 5 [19200/50750 (38%)] | Loss: 0.140689 | Elapsed: 9.89s | FPR 0.0003 -> TPR 0.8333 & F1 0.9091 | AUC 0.9875
2023-03-18 21:26:48,053 WARNING  [*] 21:26:48: Train Epoch: 5 [28800/50750 (57%)] | Loss: 0.122235 | Elapsed: 9.91s | FPR 0.0003 -> TPR 0.8281 & F1 0.9060 | AUC 0.9835
2023-03-18 21:26:57,951 WARNING  [*] 21:26:57: Train Epoch: 5 [38400/50750 (76%)] | Loss: 0.123510 | Elapsed: 9.88s | FPR 0.0003 -> TPR 0.8814 & F1 0.9369 | AUC 0.9926
2023-03-18 21:27:07,866 WARNING  [*] 21:27:07: Train Epoch: 5 [48000/50750 (95%)] | Loss: 0.131737 | Elapsed: 9.92s | FPR 0.0003 -> TPR 0.8413 & F1 0.9138 | AUC 0.9880
2023-03-18 21:27:11,815 WARNING  [*] Sat Mar 18 21:27:11 2023:    5    | Tr.loss: 0.125980 | Elapsed:   53.61  s | FPR 0.0003 -> TPR: 0.53 & F1: 0.69 | AUC: 0.9887
2023-03-18 21:27:11,815 WARNING  [*] Started epoch: 6
2023-03-18 21:27:11,955 WARNING  [*] 21:27:11: Train Epoch: 6 [  0  /50750 (0 %)] | Loss: 0.101942 | Elapsed: 0.12s | FPR 0.0003 -> TPR 0.8986 & F1 0.9466 | AUC 0.9928
2023-03-18 21:27:21,857 WARNING  [*] 21:27:21: Train Epoch: 6 [9600 /50750 (19%)] | Loss: 0.119830 | Elapsed: 9.89s | FPR 0.0003 -> TPR 0.9167 & F1 0.9565 | AUC 0.9906
2023-03-18 21:27:31,800 WARNING  [*] 21:27:31: Train Epoch: 6 [19200/50750 (38%)] | Loss: 0.147315 | Elapsed: 9.93s | FPR 0.0003 -> TPR 0.8545 & F1 0.9216 | AUC 0.9903
2023-03-18 21:27:41,707 WARNING  [*] 21:27:41: Train Epoch: 6 [28800/50750 (57%)] | Loss: 0.069163 | Elapsed: 9.91s | FPR 0.0003 -> TPR 0.9859 & F1 0.9929 | AUC 0.9976
2023-03-18 21:27:44,286 WARNING  [!] Time budget exceeded, training stopped.
2023-03-18 21:27:44,307 WARNING  [!] Sat Mar 18 21:27:44 2023: Dumped results:
                model       : 1679170962-model.torch
		train time  : 1679170962-trainTime.npy
		train losses: 1679170962-trainLosses.npy
		train AUC   : 1679170962-auc.npy
		train F1s   : 1679170962-trainF1s.npy
		train TPRs  : 1679170962-trainTPRs.npy
2023-03-18 21:27:44,354 WARNING  [!] Evaluating model on training set...
2023-03-18 21:27:57,963 WARNING  [!] This fold metrics on training set:
2023-03-18 21:27:57,977 WARNING 	AUC: 0.9928
2023-03-18 21:27:57,984 WARNING 	FPR: 0.0001 | TPR: 0.0000 | F1: 0.0000
2023-03-18 21:27:58,011 WARNING 	FPR: 0.0003 | TPR: 0.7004 | F1: 0.8238
2023-03-18 21:27:58,018 WARNING 	FPR: 0.001 | TPR: 0.7869 | F1: 0.8805
2023-03-18 21:27:58,028 WARNING 	FPR: 0.003 | TPR: 0.8649 | F1: 0.9268
2023-03-18 21:27:58,052 WARNING 	FPR: 0.01 | TPR: 0.8968 | F1: 0.9432
2023-03-18 21:27:58,058 WARNING 	FPR: 0.03 | TPR: 0.9252 | F1: 0.9540
2023-03-18 21:27:58,067 WARNING 	FPR: 0.1 | TPR: 0.9799 | F1: 0.9665
2023-03-18 21:27:58,067 WARNING  [!] Evaluating model on validation set...
2023-03-18 21:28:04,882 WARNING  [!] This fold metrics on validation set:
2023-03-18 21:28:04,897 WARNING 	AUC: 0.9913
2023-03-18 21:28:04,900 WARNING 	FPR: 0.0001 | TPR: 0.0000 | F1: 0.0000
2023-03-18 21:28:04,907 WARNING 	FPR: 0.0003 | TPR: 0.0000 | F1: 0.0000
2023-03-18 21:28:04,914 WARNING 	FPR: 0.001 | TPR: 0.7417 | F1: 0.8515
2023-03-18 21:28:04,922 WARNING 	FPR: 0.003 | TPR: 0.8376 | F1: 0.9109
2023-03-18 21:28:04,935 WARNING 	FPR: 0.01 | TPR: 0.8888 | F1: 0.9388
2023-03-18 21:28:04,942 WARNING 	FPR: 0.03 | TPR: 0.9208 | F1: 0.9517
2023-03-18 21:28:04,946 WARNING 	FPR: 0.1 | TPR: 0.9709 | F1: 0.9634
2023-03-18 21:28:05,078 WARNING  [2/3] Train set size: 50751, Validation set size: 25375
2023-03-18 21:28:06,129 WARNING  [!] Saved dataset splits to dataset_splits_1679171285.npz
2023-03-18 21:28:06,197 WARNING  [!] Iniatialized TransformerEncoderChunks. Total trainable parameters: 2.3780e6
2023-03-18 21:28:06,197 WARNING  [*] Training time budget set: 5.0 min
2023-03-18 21:28:06,237 WARNING  [*] Started epoch: 1
2023-03-18 21:28:06,380 WARNING  [*] 21:28:06: Train Epoch: 1 [  0  /50751 (0 %)] | Loss: 3.548718 | Elapsed: 0.13s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.3759
2023-03-18 21:28:16,265 WARNING  [*] 21:28:16: Train Epoch: 1 [9600 /50751 (19%)] | Loss: 0.458591 | Elapsed: 9.89s | FPR 0.0003 -> TPR 0.0282 & F1 0.0548 | AUC 0.8689
2023-03-18 21:28:26,181 WARNING  [*] 21:28:26: Train Epoch: 1 [19200/50751 (38%)] | Loss: 0.454218 | Elapsed: 9.90s | FPR 0.0003 -> TPR 0.3056 & F1 0.4681 | AUC 0.8279
2023-03-18 21:28:36,109 WARNING  [*] 21:28:36: Train Epoch: 1 [28800/50751 (57%)] | Loss: 0.312373 | Elapsed: 9.91s | FPR 0.0003 -> TPR 0.4795 & F1 0.6481 | AUC 0.9239
2023-03-18 21:28:46,021 WARNING  [*] 21:28:46: Train Epoch: 1 [38400/50751 (76%)] | Loss: 0.313276 | Elapsed: 9.90s | FPR 0.0003 -> TPR 0.6212 & F1 0.7664 | AUC 0.9407
2023-03-18 21:28:55,931 WARNING  [*] 21:28:55: Train Epoch: 1 [48000/50751 (95%)] | Loss: 0.366195 | Elapsed: 9.91s | FPR 0.0003 -> TPR 0.2742 & F1 0.4304 | AUC 0.9185
2023-03-18 21:28:59,924 WARNING  [*] Sat Mar 18 21:28:59 2023:    1    | Tr.loss: 0.378370 | Elapsed:   53.69  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.01 | AUC: 0.8928
2023-03-18 21:28:59,924 WARNING  [*] Started epoch: 2
2023-03-18 21:29:00,058 WARNING  [*] 21:29:00: Train Epoch: 2 [  0  /50751 (0 %)] | Loss: 0.291046 | Elapsed: 0.13s | FPR 0.0003 -> TPR 0.6102 & F1 0.7579 | AUC 0.9437
2023-03-18 21:29:10,017 WARNING  [*] 21:29:10: Train Epoch: 2 [9600 /50751 (19%)] | Loss: 0.237960 | Elapsed: 9.96s | FPR 0.0003 -> TPR 0.4366 & F1 0.6078 | AUC 0.9568
2023-03-18 21:29:19,941 WARNING  [*] 21:29:19: Train Epoch: 2 [19200/50751 (38%)] | Loss: 0.212573 | Elapsed: 9.92s | FPR 0.0003 -> TPR 0.6812 & F1 0.8103 | AUC 0.9705
2023-03-18 21:29:29,882 WARNING  [*] 21:29:29: Train Epoch: 2 [28800/50751 (57%)] | Loss: 0.233564 | Elapsed: 9.93s | FPR 0.0003 -> TPR 0.5323 & F1 0.6947 | AUC 0.9703
2023-03-18 21:29:39,800 WARNING  [*] 21:29:39: Train Epoch: 2 [38400/50751 (76%)] | Loss: 0.158624 | Elapsed: 9.92s | FPR 0.0003 -> TPR 0.7606 & F1 0.8640 | AUC 0.9825
2023-03-18 21:29:49,735 WARNING  [*] 21:29:49: Train Epoch: 2 [48000/50751 (95%)] | Loss: 0.191618 | Elapsed: 9.92s | FPR 0.0003 -> TPR 0.8387 & F1 0.9123 | AUC 0.9728
2023-03-18 21:29:53,695 WARNING  [*] Sat Mar 18 21:29:53 2023:    2    | Tr.loss: 0.200741 | Elapsed:   53.77  s | FPR 0.0003 -> TPR: 0.15 & F1: 0.26 | AUC: 0.9711
2023-03-18 21:29:53,695 WARNING  [*] Started epoch: 3
2023-03-18 21:29:53,808 WARNING  [*] 21:29:53: Train Epoch: 3 [  0  /50751 (0 %)] | Loss: 0.173908 | Elapsed: 0.11s | FPR 0.0003 -> TPR 0.8125 & F1 0.8966 | AUC 0.9775
2023-03-18 21:30:03,792 WARNING  [*] 21:30:03: Train Epoch: 3 [9600 /50751 (19%)] | Loss: 0.227122 | Elapsed: 9.98s | FPR 0.0003 -> TPR 0.6825 & F1 0.8113 | AUC 0.9751
2023-03-18 21:30:13,734 WARNING  [*] 21:30:13: Train Epoch: 3 [19200/50751 (38%)] | Loss: 0.142771 | Elapsed: 9.94s | FPR 0.0003 -> TPR 0.9538 & F1 0.9764 | AUC 0.9921
2023-03-18 21:30:23,694 WARNING  [*] 21:30:23: Train Epoch: 3 [28800/50751 (57%)] | Loss: 0.109749 | Elapsed: 9.96s | FPR 0.0003 -> TPR 0.8333 & F1 0.9091 | AUC 0.9916
2023-03-18 21:30:33,643 WARNING  [*] 21:30:33: Train Epoch: 3 [38400/50751 (76%)] | Loss: 0.116212 | Elapsed: 9.95s | FPR 0.0003 -> TPR 0.9625 & F1 0.9809 | AUC 0.9938
2023-03-18 21:30:43,649 WARNING  [*] 21:30:43: Train Epoch: 3 [48000/50751 (95%)] | Loss: 0.150402 | Elapsed: 10.01s | FPR 0.0003 -> TPR 0.8219 & F1 0.9023 | AUC 0.9833
2023-03-18 21:30:47,605 WARNING  [*] Sat Mar 18 21:30:47 2023:    3    | Tr.loss: 0.157813 | Elapsed:   53.91  s | FPR 0.0003 -> TPR: 0.26 & F1: 0.42 | AUC: 0.9822
2023-03-18 21:30:47,605 WARNING  [*] Started epoch: 4
2023-03-18 21:30:47,735 WARNING  [*] 21:30:47: Train Epoch: 4 [  0  /50751 (0 %)] | Loss: 0.090679 | Elapsed: 0.13s | FPR 0.0003 -> TPR 0.9565 & F1 0.9778 | AUC 0.9968
2023-03-18 21:30:57,688 WARNING  [*] 21:30:57: Train Epoch: 4 [9600 /50751 (19%)] | Loss: 0.163732 | Elapsed: 9.95s | FPR 0.0003 -> TPR 0.8852 & F1 0.9391 | AUC 0.9870
2023-03-18 21:31:07,652 WARNING  [*] 21:31:07: Train Epoch: 4 [19200/50751 (38%)] | Loss: 0.044876 | Elapsed: 9.95s | FPR 0.0003 -> TPR 1.0000 & F1 1.0000 | AUC 1.0000
2023-03-18 21:31:17,590 WARNING  [*] 21:31:17: Train Epoch: 4 [28800/50751 (57%)] | Loss: 0.217030 | Elapsed: 9.92s | FPR 0.0003 -> TPR 0.8784 & F1 0.9353 | AUC 0.9802
2023-03-18 21:31:27,559 WARNING  [*] 21:31:27: Train Epoch: 4 [38400/50751 (76%)] | Loss: 0.149809 | Elapsed: 9.96s | FPR 0.0003 -> TPR 0.9444 & F1 0.9714 | AUC 0.9881
2023-03-18 21:31:37,544 WARNING  [*] 21:31:37: Train Epoch: 4 [48000/50751 (95%)] | Loss: 0.180361 | Elapsed: 9.98s | FPR 0.0003 -> TPR 0.9726 & F1 0.9861 | AUC 0.9904
2023-03-18 21:31:41,468 WARNING  [*] Sat Mar 18 21:31:41 2023:    4    | Tr.loss: 0.137998 | Elapsed:   53.86  s | FPR 0.0003 -> TPR: 0.22 & F1: 0.36 | AUC: 0.9863
2023-03-18 21:31:41,468 WARNING  [*] Started epoch: 5
2023-03-18 21:31:41,599 WARNING  [*] 21:31:41: Train Epoch: 5 [  0  /50751 (0 %)] | Loss: 0.118606 | Elapsed: 0.12s | FPR 0.0003 -> TPR 0.8971 & F1 0.9457 | AUC 0.9916
2023-03-18 21:31:51,581 WARNING  [*] 21:31:51: Train Epoch: 5 [9600 /50751 (19%)] | Loss: 0.085438 | Elapsed: 9.97s | FPR 0.0003 -> TPR 0.9385 & F1 0.9683 | AUC 0.9965
2023-03-18 21:32:01,525 WARNING  [*] 21:32:01: Train Epoch: 5 [19200/50751 (38%)] | Loss: 0.077228 | Elapsed: 9.94s | FPR 0.0003 -> TPR 0.9200 & F1 0.9583 | AUC 0.9952
2023-03-18 21:32:11,476 WARNING  [*] 21:32:11: Train Epoch: 5 [28800/50751 (57%)] | Loss: 0.170849 | Elapsed: 9.94s | FPR 0.0003 -> TPR 0.8056 & F1 0.8923 | AUC 0.9861
2023-03-18 21:32:21,394 WARNING  [*] 21:32:21: Train Epoch: 5 [38400/50751 (76%)] | Loss: 0.138875 | Elapsed: 9.92s | FPR 0.0003 -> TPR 0.8197 & F1 0.9009 | AUC 0.9870
2023-03-18 21:32:31,328 WARNING  [*] 21:32:31: Train Epoch: 5 [48000/50751 (95%)] | Loss: 0.169431 | Elapsed: 9.93s | FPR 0.0003 -> TPR 0.8676 & F1 0.9291 | AUC 0.9890
2023-03-18 21:32:35,292 WARNING  [*] Sat Mar 18 21:32:35 2023:    5    | Tr.loss: 0.127983 | Elapsed:   53.82  s | FPR 0.0003 -> TPR: 0.40 & F1: 0.57 | AUC: 0.9882
2023-03-18 21:32:35,292 WARNING  [*] Started epoch: 6
2023-03-18 21:32:35,422 WARNING  [*] 21:32:35: Train Epoch: 6 [  0  /50751 (0 %)] | Loss: 0.084046 | Elapsed: 0.11s | FPR 0.0003 -> TPR 0.9697 & F1 0.9846 | AUC 0.9970
2023-03-18 21:32:45,348 WARNING  [*] 21:32:45: Train Epoch: 6 [9600 /50751 (19%)] | Loss: 0.125199 | Elapsed: 9.91s | FPR 0.0003 -> TPR 0.9296 & F1 0.9635 | AUC 0.9883
2023-03-18 21:32:55,265 WARNING  [*] 21:32:55: Train Epoch: 6 [19200/50751 (38%)] | Loss: 0.179211 | Elapsed: 9.92s | FPR 0.0003 -> TPR 0.8056 & F1 0.8923 | AUC 0.9730
2023-03-18 21:33:05,217 WARNING  [*] 21:33:05: Train Epoch: 6 [28800/50751 (57%)] | Loss: 0.054070 | Elapsed: 9.94s | FPR 0.0003 -> TPR 0.9403 & F1 0.9692 | AUC 0.9982
2023-03-18 21:33:06,211 WARNING  [!] Time budget exceeded, training stopped.
2023-03-18 21:33:06,238 WARNING  [!] Sat Mar 18 21:33:06 2023: Dumped results:
                model       : 1679171285-model.torch
		train time  : 1679171285-trainTime.npy
		train losses: 1679171285-trainLosses.npy
		train AUC   : 1679171285-auc.npy
		train F1s   : 1679171285-trainF1s.npy
		train TPRs  : 1679171285-trainTPRs.npy
2023-03-18 21:33:06,296 WARNING  [!] Evaluating model on training set...
2023-03-18 21:33:19,993 WARNING  [!] This fold metrics on training set:
2023-03-18 21:33:20,007 WARNING 	AUC: 0.9924
2023-03-18 21:33:20,012 WARNING 	FPR: 0.0001 | TPR: 0.5319 | F1: 0.6944
2023-03-18 21:33:20,025 WARNING 	FPR: 0.0003 | TPR: 0.5653 | F1: 0.7222
2023-03-18 21:33:20,052 WARNING 	FPR: 0.001 | TPR: 0.7923 | F1: 0.8839
2023-03-18 21:33:20,056 WARNING 	FPR: 0.003 | TPR: 0.8544 | F1: 0.9208
2023-03-18 21:33:20,068 WARNING 	FPR: 0.01 | TPR: 0.9008 | F1: 0.9455
2023-03-18 21:33:20,092 WARNING 	FPR: 0.03 | TPR: 0.9244 | F1: 0.9537
2023-03-18 21:33:20,098 WARNING 	FPR: 0.1 | TPR: 0.9713 | F1: 0.9637
2023-03-18 21:33:20,098 WARNING  [!] Evaluating model on validation set...
2023-03-18 21:33:26,942 WARNING  [!] This fold metrics on validation set:
2023-03-18 21:33:26,959 WARNING 	AUC: 0.9908
2023-03-18 21:33:26,963 WARNING 	FPR: 0.0001 | TPR: 0.5093 | F1: 0.6749
2023-03-18 21:33:26,971 WARNING 	FPR: 0.0003 | TPR: 0.6520 | F1: 0.7893
2023-03-18 21:33:26,982 WARNING 	FPR: 0.001 | TPR: 0.7447 | F1: 0.8535
2023-03-18 21:33:26,989 WARNING 	FPR: 0.003 | TPR: 0.8225 | F1: 0.9019
2023-03-18 21:33:26,995 WARNING 	FPR: 0.01 | TPR: 0.8864 | F1: 0.9374
2023-03-18 21:33:27,008 WARNING 	FPR: 0.03 | TPR: 0.9172 | F1: 0.9497
2023-03-18 21:33:27,015 WARNING 	FPR: 0.1 | TPR: 0.9693 | F1: 0.9610
2023-03-18 21:33:27,161 WARNING  [3/3] Train set size: 50751, Validation set size: 25375
2023-03-18 21:33:28,216 WARNING  [!] Saved dataset splits to dataset_splits_1679171607.npz
2023-03-18 21:33:28,268 WARNING  [!] Iniatialized TransformerEncoderChunks. Total trainable parameters: 2.3780e6
2023-03-18 21:33:28,268 WARNING  [*] Training time budget set: 5.0 min
2023-03-18 21:33:28,307 WARNING  [*] Started epoch: 1
2023-03-18 21:33:28,458 WARNING  [*] 21:33:28: Train Epoch: 1 [  0  /50751 (0 %)] | Loss: 2.547542 | Elapsed: 0.13s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.5156
2023-03-18 21:33:38,398 WARNING  [*] 21:33:38: Train Epoch: 1 [9600 /50751 (19%)] | Loss: 0.342969 | Elapsed: 9.94s | FPR 0.0003 -> TPR 0.6176 & F1 0.7636 | AUC 0.9026
2023-03-18 21:33:48,342 WARNING  [*] 21:33:48: Train Epoch: 1 [19200/50751 (38%)] | Loss: 0.311554 | Elapsed: 9.94s | FPR 0.0003 -> TPR 0.7500 & F1 0.8571 | AUC 0.9484
2023-03-18 21:33:58,264 WARNING  [*] 21:33:58: Train Epoch: 1 [28800/50751 (57%)] | Loss: 0.328230 | Elapsed: 9.92s | FPR 0.0003 -> TPR 0.5077 & F1 0.6735 | AUC 0.9209
2023-03-18 21:34:08,218 WARNING  [*] 21:34:08: Train Epoch: 1 [38400/50751 (76%)] | Loss: 0.230689 | Elapsed: 9.95s | FPR 0.0003 -> TPR 0.5806 & F1 0.7347 | AUC 0.9665
2023-03-18 21:34:18,168 WARNING  [*] 21:34:18: Train Epoch: 1 [48000/50751 (95%)] | Loss: 0.204143 | Elapsed: 9.93s | FPR 0.0003 -> TPR 0.8182 & F1 0.9000 | AUC 0.9656
2023-03-18 21:34:22,144 WARNING  [*] Sat Mar 18 21:34:22 2023:    1    | Tr.loss: 0.381831 | Elapsed:   53.84  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.8942
2023-03-18 21:34:22,144 WARNING  [*] Started epoch: 2
2023-03-18 21:34:22,282 WARNING  [*] 21:34:22: Train Epoch: 2 [  0  /50751 (0 %)] | Loss: 0.250533 | Elapsed: 0.12s | FPR 0.0003 -> TPR 0.7183 & F1 0.8361 | AUC 0.9510
2023-03-18 21:34:32,223 WARNING  [*] 21:34:32: Train Epoch: 2 [9600 /50751 (19%)] | Loss: 0.259862 | Elapsed: 9.93s | FPR 0.0003 -> TPR 0.4507 & F1 0.6214 | AUC 0.9704
2023-03-18 21:34:42,153 WARNING  [*] 21:34:42: Train Epoch: 2 [19200/50751 (38%)] | Loss: 0.186030 | Elapsed: 9.93s | FPR 0.0003 -> TPR 0.8000 & F1 0.8889 | AUC 0.9776
2023-03-18 21:34:52,095 WARNING  [*] 21:34:52: Train Epoch: 2 [28800/50751 (57%)] | Loss: 0.357592 | Elapsed: 9.93s | FPR 0.0003 -> TPR 0.1077 & F1 0.1944 | AUC 0.9391
2023-03-18 21:35:02,047 WARNING  [*] 21:35:02: Train Epoch: 2 [38400/50751 (76%)] | Loss: 0.159445 | Elapsed: 9.94s | FPR 0.0003 -> TPR 0.8625 & F1 0.9262 | AUC 0.9750
2023-03-18 21:35:12,003 WARNING  [*] 21:35:12: Train Epoch: 2 [48000/50751 (95%)] | Loss: 0.151901 | Elapsed: 9.96s | FPR 0.0003 -> TPR 0.8116 & F1 0.8960 | AUC 0.9790
2023-03-18 21:35:15,930 WARNING  [*] Sat Mar 18 21:35:15 2023:    2    | Tr.loss: 0.193458 | Elapsed:   53.79  s | FPR 0.0003 -> TPR: 0.18 & F1: 0.31 | AUC: 0.9734
2023-03-18 21:35:15,930 WARNING  [*] Started epoch: 3
2023-03-18 21:35:16,061 WARNING  [*] 21:35:16: Train Epoch: 3 [  0  /50751 (0 %)] | Loss: 0.098894 | Elapsed: 0.12s | FPR 0.0003 -> TPR 0.9531 & F1 0.9760 | AUC 0.9951
2023-03-18 21:35:26,049 WARNING  [*] 21:35:26: Train Epoch: 3 [9600 /50751 (19%)] | Loss: 0.180610 | Elapsed: 9.99s | FPR 0.0003 -> TPR 0.9516 & F1 0.9752 | AUC 0.9862
2023-03-18 21:35:36,012 WARNING  [*] 21:35:36: Train Epoch: 3 [19200/50751 (38%)] | Loss: 0.164539 | Elapsed: 9.96s | FPR 0.0003 -> TPR 0.8209 & F1 0.9016 | AUC 0.9774
2023-03-18 21:35:45,965 WARNING  [*] 21:35:45: Train Epoch: 3 [28800/50751 (57%)] | Loss: 0.188004 | Elapsed: 9.94s | FPR 0.0003 -> TPR 0.7576 & F1 0.8621 | AUC 0.9777
2023-03-18 21:35:55,911 WARNING  [*] 21:35:55: Train Epoch: 3 [38400/50751 (76%)] | Loss: 0.178007 | Elapsed: 9.93s | FPR 0.0003 -> TPR 0.8438 & F1 0.9153 | AUC 0.9796
2023-03-18 21:36:05,870 WARNING  [*] 21:36:05: Train Epoch: 3 [48000/50751 (95%)] | Loss: 0.176378 | Elapsed: 9.94s | FPR 0.0003 -> TPR 0.8310 & F1 0.9077 | AUC 0.9815
2023-03-18 21:36:09,840 WARNING  [*] Sat Mar 18 21:36:09 2023:    3    | Tr.loss: 0.157578 | Elapsed:   53.91  s | FPR 0.0003 -> TPR: 0.36 & F1: 0.53 | AUC: 0.9824
2023-03-18 21:36:09,851 WARNING  [*] Started epoch: 4
2023-03-18 21:36:09,965 WARNING  [*] 21:36:09: Train Epoch: 4 [  0  /50751 (0 %)] | Loss: 0.258503 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.8676 & F1 0.9291 | AUC 0.9732
2023-03-18 21:36:19,955 WARNING  [*] 21:36:19: Train Epoch: 4 [9600 /50751 (19%)] | Loss: 0.198680 | Elapsed: 9.97s | FPR 0.0003 -> TPR 0.7000 & F1 0.8235 | AUC 0.9733
2023-03-18 21:36:29,892 WARNING  [*] 21:36:29: Train Epoch: 4 [19200/50751 (38%)] | Loss: 0.192052 | Elapsed: 9.94s | FPR 0.0003 -> TPR 0.7969 & F1 0.8870 | AUC 0.9766
2023-03-18 21:36:39,842 WARNING  [*] 21:36:39: Train Epoch: 4 [28800/50751 (57%)] | Loss: 0.140877 | Elapsed: 9.95s | FPR 0.0003 -> TPR 0.9375 & F1 0.9677 | AUC 0.9887
2023-03-18 21:36:49,806 WARNING  [*] 21:36:49: Train Epoch: 4 [38400/50751 (76%)] | Loss: 0.109890 | Elapsed: 9.96s | FPR 0.0003 -> TPR 0.9265 & F1 0.9618 | AUC 0.9959
2023-03-18 21:36:59,763 WARNING  [*] 21:36:59: Train Epoch: 4 [48000/50751 (95%)] | Loss: 0.120000 | Elapsed: 9.96s | FPR 0.0003 -> TPR 0.9265 & F1 0.9618 | AUC 0.9885
2023-03-18 21:37:03,678 WARNING  [*] Sat Mar 18 21:37:03 2023:    4    | Tr.loss: 0.138985 | Elapsed:   53.83  s | FPR 0.0003 -> TPR: 0.32 & F1: 0.48 | AUC: 0.9863
2023-03-18 21:37:03,678 WARNING  [*] Started epoch: 5
2023-03-18 21:37:03,800 WARNING  [*] 21:37:03: Train Epoch: 5 [  0  /50751 (0 %)] | Loss: 0.281297 | Elapsed: 0.11s | FPR 0.0003 -> TPR 0.6129 & F1 0.7600 | AUC 0.9554
2023-03-18 21:37:13,794 WARNING  [*] 21:37:13: Train Epoch: 5 [9600 /50751 (19%)] | Loss: 0.126147 | Elapsed: 9.99s | FPR 0.0003 -> TPR 0.8462 & F1 0.9167 | AUC 0.9884
2023-03-18 21:37:23,727 WARNING  [*] 21:37:23: Train Epoch: 5 [19200/50751 (38%)] | Loss: 0.144238 | Elapsed: 9.93s | FPR 0.0003 -> TPR 0.8438 & F1 0.9153 | AUC 0.9894
2023-03-18 21:37:33,672 WARNING  [*] 21:37:33: Train Epoch: 5 [28800/50751 (57%)] | Loss: 0.089841 | Elapsed: 9.94s | FPR 0.0003 -> TPR 0.9167 & F1 0.9565 | AUC 0.9933
2023-03-18 21:37:43,621 WARNING  [*] 21:37:43: Train Epoch: 5 [38400/50751 (76%)] | Loss: 0.127419 | Elapsed: 9.95s | FPR 0.0003 -> TPR 0.9143 & F1 0.9552 | AUC 0.9871
2023-03-18 21:37:53,558 WARNING  [*] 21:37:53: Train Epoch: 5 [48000/50751 (95%)] | Loss: 0.120587 | Elapsed: 9.94s | FPR 0.0003 -> TPR 0.8060 & F1 0.8926 | AUC 0.9905
2023-03-18 21:37:57,559 WARNING  [*] Sat Mar 18 21:37:57 2023:    5    | Tr.loss: 0.128382 | Elapsed:   53.88  s | FPR 0.0003 -> TPR: 0.52 & F1: 0.69 | AUC: 0.9881
2023-03-18 21:37:57,559 WARNING  [*] Started epoch: 6
2023-03-18 21:37:57,688 WARNING  [*] 21:37:57: Train Epoch: 6 [  0  /50751 (0 %)] | Loss: 0.095709 | Elapsed: 0.11s | FPR 0.0003 -> TPR 0.9444 & F1 0.9714 | AUC 0.9945
2023-03-18 21:38:07,619 WARNING  [*] 21:38:07: Train Epoch: 6 [9600 /50751 (19%)] | Loss: 0.163491 | Elapsed: 9.92s | FPR 0.0003 -> TPR 0.8000 & F1 0.8889 | AUC 0.9807
2023-03-18 21:38:17,587 WARNING  [*] 21:38:17: Train Epoch: 6 [19200/50751 (38%)] | Loss: 0.134688 | Elapsed: 9.95s | FPR 0.0003 -> TPR 0.9014 & F1 0.9481 | AUC 0.9876
2023-03-18 21:38:27,551 WARNING  [*] 21:38:27: Train Epoch: 6 [28800/50751 (57%)] | Loss: 0.276294 | Elapsed: 9.96s | FPR 0.0003 -> TPR 0.3824 & F1 0.5532 | AUC 0.9671
2023-03-18 21:38:28,344 WARNING  [!] Time budget exceeded, training stopped.
2023-03-18 21:38:28,390 WARNING  [!] Sat Mar 18 21:38:28 2023: Dumped results:
                model       : 1679171607-model.torch
		train time  : 1679171607-trainTime.npy
		train losses: 1679171607-trainLosses.npy
		train AUC   : 1679171607-auc.npy
		train F1s   : 1679171607-trainF1s.npy
		train TPRs  : 1679171607-trainTPRs.npy
2023-03-18 21:38:28,425 WARNING  [!] Evaluating model on training set...
2023-03-18 21:38:42,094 WARNING  [!] This fold metrics on training set:
2023-03-18 21:38:42,108 WARNING 	AUC: 0.9923
2023-03-18 21:38:42,112 WARNING 	FPR: 0.0001 | TPR: 0.3185 | F1: 0.4831
2023-03-18 21:38:42,138 WARNING 	FPR: 0.0003 | TPR: 0.5365 | F1: 0.6983
2023-03-18 21:38:42,143 WARNING 	FPR: 0.001 | TPR: 0.7845 | F1: 0.8790
2023-03-18 21:38:42,165 WARNING 	FPR: 0.003 | TPR: 0.8652 | F1: 0.9270
2023-03-18 21:38:42,179 WARNING 	FPR: 0.01 | TPR: 0.9007 | F1: 0.9454
2023-03-18 21:38:42,181 WARNING 	FPR: 0.03 | TPR: 0.9243 | F1: 0.9536
2023-03-18 21:38:42,206 WARNING 	FPR: 0.1 | TPR: 0.9663 | F1: 0.9642
2023-03-18 21:38:42,207 WARNING  [!] Evaluating model on validation set...
2023-03-18 21:38:49,040 WARNING  [!] This fold metrics on validation set:
2023-03-18 21:38:49,048 WARNING 	AUC: 0.9907
2023-03-18 21:38:49,055 WARNING 	FPR: 0.0001 | TPR: 0.0000 | F1: 0.0000
2023-03-18 21:38:49,061 WARNING 	FPR: 0.0003 | TPR: 0.4711 | F1: 0.6404
2023-03-18 21:38:49,065 WARNING 	FPR: 0.001 | TPR: 0.7753 | F1: 0.8732
2023-03-18 21:38:49,079 WARNING 	FPR: 0.003 | TPR: 0.8430 | F1: 0.9141
2023-03-18 21:38:49,087 WARNING 	FPR: 0.01 | TPR: 0.8837 | F1: 0.9359
2023-03-18 21:38:49,091 WARNING 	FPR: 0.03 | TPR: 0.9155 | F1: 0.9488
2023-03-18 21:38:49,096 WARNING 	FPR: 0.1 | TPR: 0.9629 | F1: 0.9606
2023-03-18 21:38:49,173 WARNING  [!] Metrics saved to out_fields_1679165454\cv_api_only_name_limNone_r1763_t5\api_only_name_metrics_validation.json
2023-03-18 21:38:49,183 WARNING  [!] Metrics saved to out_fields_1679165454\cv_api_only_name_limNone_r1763_t5\api_only_name_metrics_training.json
2023-03-18 21:38:49,183 WARNING  [!] Average epoch time: 0.03s | Mean values over 3 folds:
	AUC: 0.9909
	FPR: 0.0001 -- TPR: 0.1698 -- F1: 0.2250
	FPR: 0.0003 -- TPR: 0.3744 -- F1: 0.4766
	FPR:  0.001 -- TPR: 0.7539 -- F1: 0.8594
	FPR:  0.003 -- TPR: 0.8344 -- F1: 0.9090
	FPR:   0.01 -- TPR: 0.8863 -- F1: 0.9374
	FPR:   0.03 -- TPR: 0.9178 -- F1: 0.9501
	FPR:    0.1 -- TPR: 0.9677 -- F1: 0.9617

2023-03-18 21:38:49,224 WARNING  [!] Working on api_only_full!
2023-03-18 21:38:49,240 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_backdoor
2023-03-18 21:42:34,135 WARNING Finished... Took: 224.89s
2023-03-18 21:42:34,135 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_clean
2023-03-18 21:46:13,595 WARNING Finished... Took: 219.46s
2023-03-18 21:46:13,595 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_coinminer
2023-03-18 21:47:29,166 WARNING Finished... Took: 75.57s
2023-03-18 21:47:29,166 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_dropper
2023-03-18 21:48:25,871 WARNING Finished... Took: 56.71s
2023-03-18 21:48:25,871 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_keylogger
2023-03-18 21:49:10,705 WARNING Finished... Took: 44.83s
2023-03-18 21:49:10,705 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_ransomware
2023-03-18 21:51:34,731 WARNING Finished... Took: 144.03s
2023-03-18 21:51:34,731 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_rat
2023-03-18 21:52:10,402 WARNING Finished... Took: 35.67s
2023-03-18 21:52:10,403 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_trojan
2023-03-18 21:54:05,813 WARNING Finished... Took: 115.41s
2023-03-18 21:54:05,813 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_windows_syswow64
2023-03-18 21:54:07,561 WARNING Finished... Took: 1.75s
2023-03-18 21:54:07,565 WARNING  [!] Saved Y as out_fields_1679165454\api_only_full_vocab_50000_seqlen_512\y_train_full.npy
2023-03-18 21:54:07,786 WARNING  [!] Saved Y names as out_fields_1679165454\api_only_full_vocab_50000_seqlen_512\y_names_train_full.json
2023-03-18 21:54:07,786 WARNING  [*] Initializing tokenizer training...
2023-03-18 21:55:22,259 WARNING Dumped vocab to out_fields_1679165454\api_only_full_vocab_50000_seqlen_512\tokenizer_50000_vocab.json
2023-03-18 21:55:23,045 WARNING Dumped vocab counter to out_fields_1679165454\api_only_full_vocab_50000_seqlen_512\tokenizer_50000_counter.json
2023-03-18 21:55:23,045 WARNING  [*] Encoding and padding...
2023-03-18 21:57:16,708 WARNING  [!] Saved X as out_fields_1679165454\api_only_full_vocab_50000_seqlen_512\x_train_full.npy
2023-03-18 21:57:19,524 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_backdoor
2023-03-18 21:57:56,637 WARNING Finished... Took: 37.11s
2023-03-18 21:57:56,638 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_clean
2023-03-18 21:59:31,781 WARNING Finished... Took: 95.14s
2023-03-18 21:59:31,781 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_coinminer
2023-03-18 21:59:58,411 WARNING Finished... Took: 26.63s
2023-03-18 21:59:58,411 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_dropper
2023-03-18 22:00:00,963 WARNING Finished... Took: 2.55s
2023-03-18 22:00:00,964 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_keylogger
2023-03-18 22:00:10,979 WARNING Finished... Took: 10.01s
2023-03-18 22:00:10,979 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_ransomware
2023-03-18 22:02:19,922 WARNING Finished... Took: 128.94s
2023-03-18 22:02:19,922 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_rat
2023-03-18 22:02:36,399 WARNING Finished... Took: 16.48s
2023-03-18 22:02:36,399 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_trojan
2023-03-18 22:02:49,678 WARNING Finished... Took: 13.28s
2023-03-18 22:02:49,678 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_windows_syswow64
2023-03-18 22:02:50,146 WARNING Finished... Took: 0.47s
2023-03-18 22:02:50,158 WARNING  [!] Saved Y as out_fields_1679165454\api_only_full_vocab_50000_seqlen_512\y_test_full.npy
2023-03-18 22:02:50,209 WARNING  [!] Saved Y names as out_fields_1679165454\api_only_full_vocab_50000_seqlen_512\y_names_test_full.json
2023-03-18 22:02:50,230 WARNING  [*] Encoding and padding...
2023-03-18 22:03:08,913 WARNING  [!] Saved X as out_fields_1679165454\api_only_full_vocab_50000_seqlen_512\x_test_full.npy
2023-03-18 22:03:09,651 WARNING  [!!!] Starting CV over api_only_full!
2023-03-18 22:03:09,724 WARNING  [!] Training time budget: 300min
2023-03-18 22:03:09,725 WARNING  [!] Model config: {'vocab_size': 50000, 'maxlen': 512, 'chunk_size': 64, 'dModel': 64, 'nHeads': 8, 'dHidden': 256, 'nLayers': 2, 'numClasses': 1, 'hiddenNeurons': [64], 'layerNorm': False, 'dropout': 0.3, 'mean_over_sequence': False, 'norm_first': True}
2023-03-18 22:03:09,773 WARNING  [1/3] Train set size: 50750, Validation set size: 25376
2023-03-18 22:03:11,573 WARNING  [!] Saved dataset splits to dataset_splits_1679173389.npz
2023-03-18 22:03:11,656 WARNING  [!] Iniatialized TransformerEncoderChunks. Total trainable parameters: 5.3972e6
2023-03-18 22:03:11,656 WARNING  [*] Training time budget set: 5.0 min
2023-03-18 22:03:11,686 WARNING  [*] Started epoch: 1
2023-03-18 22:03:11,978 WARNING  [*] 22:03:11: Train Epoch: 1 [  0  /50750 (0 %)] | Loss: 1.589087 | Elapsed: 0.29s | FPR 0.0003 -> TPR 0.0926 & F1 0.1695 | AUC 0.5772
2023-03-18 22:03:21,779 WARNING  [*] 22:03:21: Train Epoch: 1 [9600 /50750 (19%)] | Loss: 0.335506 | Elapsed: 9.79s | FPR 0.0003 -> TPR 0.5714 & F1 0.7273 | AUC 0.8910
2023-03-18 22:03:31,596 WARNING  [*] 22:03:31: Train Epoch: 1 [19200/50750 (38%)] | Loss: 0.431046 | Elapsed: 9.82s | FPR 0.0003 -> TPR 0.4211 & F1 0.5926 | AUC 0.8968
2023-03-18 22:03:41,457 WARNING  [*] 22:03:41: Train Epoch: 1 [28800/50750 (57%)] | Loss: 0.329304 | Elapsed: 9.86s | FPR 0.0003 -> TPR 0.3810 & F1 0.5517 | AUC 0.9378
2023-03-18 22:03:51,372 WARNING  [*] 22:03:51: Train Epoch: 1 [38400/50750 (76%)] | Loss: 0.173365 | Elapsed: 9.92s | FPR 0.0003 -> TPR 0.8000 & F1 0.8889 | AUC 0.9833
2023-03-18 22:04:01,330 WARNING  [*] 22:04:01: Train Epoch: 1 [48000/50750 (95%)] | Loss: 0.198135 | Elapsed: 9.94s | FPR 0.0003 -> TPR 0.8529 & F1 0.9206 | AUC 0.9752
2023-03-18 22:04:05,114 WARNING  [*] Sat Mar 18 22:04:05 2023:    1    | Tr.loss: 0.325824 | Elapsed:   53.43  s | FPR 0.0003 -> TPR: 0.08 & F1: 0.15 | AUC: 0.9217
2023-03-18 22:04:05,114 WARNING  [*] Started epoch: 2
2023-03-18 22:04:05,226 WARNING  [*] 22:04:05: Train Epoch: 2 [  0  /50750 (0 %)] | Loss: 0.219300 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.5397 & F1 0.7010 | AUC 0.9658
2023-03-18 22:04:15,210 WARNING  [*] 22:04:15: Train Epoch: 2 [9600 /50750 (19%)] | Loss: 0.201122 | Elapsed: 9.98s | FPR 0.0003 -> TPR 0.5938 & F1 0.7451 | AUC 0.9744
2023-03-18 22:04:25,218 WARNING  [*] 22:04:25: Train Epoch: 2 [19200/50750 (38%)] | Loss: 0.121571 | Elapsed: 10.01s | FPR 0.0003 -> TPR 0.8676 & F1 0.9291 | AUC 0.9894
2023-03-18 22:04:35,264 WARNING  [*] 22:04:35: Train Epoch: 2 [28800/50750 (57%)] | Loss: 0.171249 | Elapsed: 10.03s | FPR 0.0003 -> TPR 0.8788 & F1 0.9355 | AUC 0.9889
2023-03-18 22:04:45,289 WARNING  [*] 22:04:45: Train Epoch: 2 [38400/50750 (76%)] | Loss: 0.150443 | Elapsed: 10.02s | FPR 0.0003 -> TPR 0.9286 & F1 0.9630 | AUC 0.9910
2023-03-18 22:04:55,318 WARNING  [*] 22:04:55: Train Epoch: 2 [48000/50750 (95%)] | Loss: 0.072188 | Elapsed: 10.03s | FPR 0.0003 -> TPR 0.8966 & F1 0.9455 | AUC 0.9955
2023-03-18 22:04:59,129 WARNING  [*] Sat Mar 18 22:04:59 2023:    2    | Tr.loss: 0.148451 | Elapsed:   54.00  s | FPR 0.0003 -> TPR: 0.43 & F1: 0.60 | AUC: 0.9847
2023-03-18 22:04:59,129 WARNING  [*] Started epoch: 3
2023-03-18 22:04:59,254 WARNING  [*] 22:04:59: Train Epoch: 3 [  0  /50750 (0 %)] | Loss: 0.184552 | Elapsed: 0.13s | FPR 0.0003 -> TPR 0.7931 & F1 0.8846 | AUC 0.9841
2023-03-18 22:05:09,299 WARNING  [*] 22:05:09: Train Epoch: 3 [9600 /50750 (19%)] | Loss: 0.077972 | Elapsed: 10.03s | FPR 0.0003 -> TPR 0.9853 & F1 0.9926 | AUC 0.9963
2023-03-18 22:05:19,343 WARNING  [*] 22:05:19: Train Epoch: 3 [19200/50750 (38%)] | Loss: 0.120675 | Elapsed: 10.04s | FPR 0.0003 -> TPR 0.9355 & F1 0.9667 | AUC 0.9898
2023-03-18 22:05:29,397 WARNING  [*] 22:05:29: Train Epoch: 3 [28800/50750 (57%)] | Loss: 0.076287 | Elapsed: 10.05s | FPR 0.0003 -> TPR 0.9365 & F1 0.9672 | AUC 0.9979
2023-03-18 22:05:39,470 WARNING  [*] 22:05:39: Train Epoch: 3 [38400/50750 (76%)] | Loss: 0.115828 | Elapsed: 10.06s | FPR 0.0003 -> TPR 0.7368 & F1 0.8485 | AUC 0.9890
2023-03-18 22:05:49,505 WARNING  [*] 22:05:49: Train Epoch: 3 [48000/50750 (95%)] | Loss: 0.092138 | Elapsed: 10.02s | FPR 0.0003 -> TPR 0.9836 & F1 0.9917 | AUC 0.9920
2023-03-18 22:05:53,316 WARNING  [*] Sat Mar 18 22:05:53 2023:    3    | Tr.loss: 0.083008 | Elapsed:   54.19  s | FPR 0.0003 -> TPR: 0.69 & F1: 0.82 | AUC: 0.9950
2023-03-18 22:05:53,316 WARNING  [*] Started epoch: 4
2023-03-18 22:05:53,432 WARNING  [*] 22:05:53: Train Epoch: 4 [  0  /50750 (0 %)] | Loss: 0.028216 | Elapsed: 0.12s | FPR 0.0003 -> TPR 1.0000 & F1 1.0000 | AUC 1.0000
2023-03-18 22:06:03,493 WARNING  [*] 22:06:03: Train Epoch: 4 [9600 /50750 (19%)] | Loss: 0.022566 | Elapsed: 10.06s | FPR 0.0003 -> TPR 1.0000 & F1 1.0000 | AUC 1.0000
2023-03-18 22:06:13,538 WARNING  [*] 22:06:13: Train Epoch: 4 [19200/50750 (38%)] | Loss: 0.159718 | Elapsed: 10.04s | FPR 0.0003 -> TPR 0.9118 & F1 0.9538 | AUC 0.9862
2023-03-18 22:06:23,634 WARNING  [*] 22:06:23: Train Epoch: 4 [28800/50750 (57%)] | Loss: 0.051643 | Elapsed: 10.08s | FPR 0.0003 -> TPR 0.9846 & F1 0.9922 | AUC 0.9987
2023-03-18 22:06:33,703 WARNING  [*] 22:06:33: Train Epoch: 4 [38400/50750 (76%)] | Loss: 0.005371 | Elapsed: 10.05s | FPR 0.0003 -> TPR 1.0000 & F1 1.0000 | AUC 1.0000
2023-03-18 22:06:43,746 WARNING  [*] 22:06:43: Train Epoch: 4 [48000/50750 (95%)] | Loss: 0.041447 | Elapsed: 10.04s | FPR 0.0003 -> TPR 0.9851 & F1 0.9925 | AUC 0.9991
2023-03-18 22:06:47,551 WARNING  [*] Sat Mar 18 22:06:47 2023:    4    | Tr.loss: 0.061804 | Elapsed:   54.23  s | FPR 0.0003 -> TPR: 0.76 & F1: 0.86 | AUC: 0.9969
2023-03-18 22:06:47,551 WARNING  [*] Started epoch: 5
2023-03-18 22:06:47,682 WARNING  [*] 22:06:47: Train Epoch: 5 [  0  /50750 (0 %)] | Loss: 0.033646 | Elapsed: 0.12s | FPR 0.0003 -> TPR 0.9841 & F1 0.9920 | AUC 0.9995
2023-03-18 22:06:57,719 WARNING  [*] 22:06:57: Train Epoch: 5 [9600 /50750 (19%)] | Loss: 0.045395 | Elapsed: 10.04s | FPR 0.0003 -> TPR 0.9855 & F1 0.9927 | AUC 0.9991
2023-03-18 22:07:07,811 WARNING  [*] 22:07:07: Train Epoch: 5 [19200/50750 (38%)] | Loss: 0.020014 | Elapsed: 10.06s | FPR 0.0003 -> TPR 1.0000 & F1 1.0000 | AUC 1.0000
2023-03-18 22:07:17,883 WARNING  [*] 22:07:17: Train Epoch: 5 [28800/50750 (57%)] | Loss: 0.018288 | Elapsed: 10.07s | FPR 0.0003 -> TPR 1.0000 & F1 1.0000 | AUC 1.0000
2023-03-18 22:07:27,954 WARNING  [*] 22:07:27: Train Epoch: 5 [38400/50750 (76%)] | Loss: 0.045545 | Elapsed: 10.07s | FPR 0.0003 -> TPR 1.0000 & F1 1.0000 | AUC 1.0000
2023-03-18 22:07:38,029 WARNING  [*] 22:07:38: Train Epoch: 5 [48000/50750 (95%)] | Loss: 0.039908 | Elapsed: 10.07s | FPR 0.0003 -> TPR 0.9872 & F1 0.9935 | AUC 0.9977
2023-03-18 22:07:41,835 WARNING  [*] Sat Mar 18 22:07:41 2023:    5    | Tr.loss: 0.050062 | Elapsed:   54.28  s | FPR 0.0003 -> TPR: 0.82 & F1: 0.90 | AUC: 0.9980
2023-03-18 22:07:41,835 WARNING  [*] Started epoch: 6
2023-03-18 22:07:41,955 WARNING  [*] 22:07:41: Train Epoch: 6 [  0  /50750 (0 %)] | Loss: 0.048636 | Elapsed: 0.12s | FPR 0.0003 -> TPR 0.9833 & F1 0.9916 | AUC 0.9986
2023-03-18 22:07:52,034 WARNING  [*] 22:07:52: Train Epoch: 6 [9600 /50750 (19%)] | Loss: 0.042414 | Elapsed: 10.05s | FPR 0.0003 -> TPR 0.9853 & F1 0.9926 | AUC 0.9991
2023-03-18 22:08:02,095 WARNING  [*] 22:08:02: Train Epoch: 6 [19200/50750 (38%)] | Loss: 0.052620 | Elapsed: 10.04s | FPR 0.0003 -> TPR 0.9710 & F1 0.9853 | AUC 0.9991
2023-03-18 22:08:11,748 WARNING  [!] Time budget exceeded, training stopped.
2023-03-18 22:08:11,798 WARNING  [!] Sat Mar 18 22:08:11 2023: Dumped results:
                model       : 1679173389-model.torch
		train time  : 1679173389-trainTime.npy
		train losses: 1679173389-trainLosses.npy
		train AUC   : 1679173389-auc.npy
		train F1s   : 1679173389-trainF1s.npy
		train TPRs  : 1679173389-trainTPRs.npy
2023-03-18 22:08:11,828 WARNING  [!] Evaluating model on training set...
2023-03-18 22:08:25,529 WARNING  [!] This fold metrics on training set:
2023-03-18 22:08:25,544 WARNING 	AUC: 0.9992
2023-03-18 22:08:25,553 WARNING 	FPR: 0.0001 | TPR: 0.8254 | F1: 0.9043
2023-03-18 22:08:25,575 WARNING 	FPR: 0.0003 | TPR: 0.9219 | F1: 0.9593
2023-03-18 22:08:25,584 WARNING 	FPR: 0.001 | TPR: 0.9569 | F1: 0.9778
2023-03-18 22:08:25,612 WARNING 	FPR: 0.003 | TPR: 0.9760 | F1: 0.9871
2023-03-18 22:08:25,623 WARNING 	FPR: 0.01 | TPR: 0.9873 | F1: 0.9912
2023-03-18 22:08:25,628 WARNING 	FPR: 0.03 | TPR: 0.9942 | F1: 0.9899
2023-03-18 22:08:25,651 WARNING 	FPR: 0.1 | TPR: 0.9982 | F1: 0.9761
2023-03-18 22:08:25,652 WARNING  [!] Evaluating model on validation set...
2023-03-18 22:08:32,499 WARNING  [!] This fold metrics on validation set:
2023-03-18 22:08:32,505 WARNING 	AUC: 0.9980
2023-03-18 22:08:32,511 WARNING 	FPR: 0.0001 | TPR: 0.0000 | F1: 0.0000
2023-03-18 22:08:32,517 WARNING 	FPR: 0.0003 | TPR: 0.0000 | F1: 0.0000
2023-03-18 22:08:32,521 WARNING 	FPR: 0.001 | TPR: 0.8870 | F1: 0.9399
2023-03-18 22:08:32,528 WARNING 	FPR: 0.003 | TPR: 0.9421 | F1: 0.9695
2023-03-18 22:08:32,539 WARNING 	FPR: 0.01 | TPR: 0.9768 | F1: 0.9859
2023-03-18 22:08:32,546 WARNING 	FPR: 0.03 | TPR: 0.9889 | F1: 0.9873
2023-03-18 22:08:32,551 WARNING 	FPR: 0.1 | TPR: 0.9960 | F1: 0.9746
2023-03-18 22:08:32,705 WARNING  [2/3] Train set size: 50751, Validation set size: 25375
2023-03-18 22:08:34,721 WARNING  [!] Saved dataset splits to dataset_splits_1679173712.npz
2023-03-18 22:08:34,808 WARNING  [!] Iniatialized TransformerEncoderChunks. Total trainable parameters: 5.3972e6
2023-03-18 22:08:34,808 WARNING  [*] Training time budget set: 5.0 min
2023-03-18 22:08:34,840 WARNING  [*] Started epoch: 1
2023-03-18 22:08:35,192 WARNING  [*] 22:08:35: Train Epoch: 1 [  0  /50751 (0 %)] | Loss: 1.510908 | Elapsed: 0.35s | FPR 0.0003 -> TPR 0.1077 & F1 0.1944 | AUC 0.5985
2023-03-18 22:08:45,281 WARNING  [*] 22:08:45: Train Epoch: 1 [9600 /50751 (19%)] | Loss: 0.311541 | Elapsed: 10.07s | FPR 0.0003 -> TPR 0.2639 & F1 0.4176 | AUC 0.9345
2023-03-18 22:08:55,353 WARNING  [*] 22:08:55: Train Epoch: 1 [19200/50751 (38%)] | Loss: 0.308658 | Elapsed: 10.06s | FPR 0.0003 -> TPR 0.3788 & F1 0.5495 | AUC 0.9180
2023-03-18 22:09:05,438 WARNING  [*] 22:09:05: Train Epoch: 1 [28800/50751 (57%)] | Loss: 0.367133 | Elapsed: 10.09s | FPR 0.0003 -> TPR 0.5211 & F1 0.6852 | AUC 0.9004
2023-03-18 22:09:15,534 WARNING  [*] 22:09:15: Train Epoch: 1 [38400/50751 (76%)] | Loss: 0.210384 | Elapsed: 10.08s | FPR 0.0003 -> TPR 0.6575 & F1 0.7934 | AUC 0.9655
2023-03-18 22:09:25,630 WARNING  [*] 22:09:25: Train Epoch: 1 [48000/50751 (95%)] | Loss: 0.160951 | Elapsed: 10.10s | FPR 0.0003 -> TPR 0.8354 & F1 0.9103 | AUC 0.9771
2023-03-18 22:09:29,649 WARNING  [*] Sat Mar 18 22:09:29 2023:    1    | Tr.loss: 0.314325 | Elapsed:   54.81  s | FPR 0.0003 -> TPR: 0.08 & F1: 0.15 | AUC: 0.9265
2023-03-18 22:09:29,649 WARNING  [*] Started epoch: 2
2023-03-18 22:09:29,777 WARNING  [*] 22:09:29: Train Epoch: 2 [  0  /50751 (0 %)] | Loss: 0.218711 | Elapsed: 0.11s | FPR 0.0003 -> TPR 0.7812 & F1 0.8772 | AUC 0.9653
2023-03-18 22:09:39,878 WARNING  [*] 22:09:39: Train Epoch: 2 [9600 /50751 (19%)] | Loss: 0.122732 | Elapsed: 10.10s | FPR 0.0003 -> TPR 0.8636 & F1 0.9268 | AUC 0.9942
2023-03-18 22:09:49,987 WARNING  [*] 22:09:49: Train Epoch: 2 [19200/50751 (38%)] | Loss: 0.093271 | Elapsed: 10.11s | FPR 0.0003 -> TPR 0.9508 & F1 0.9748 | AUC 0.9966
2023-03-18 22:10:00,156 WARNING  [*] 22:10:00: Train Epoch: 2 [28800/50751 (57%)] | Loss: 0.071351 | Elapsed: 10.16s | FPR 0.0003 -> TPR 0.9710 & F1 0.9853 | AUC 0.9972
2023-03-18 22:10:10,374 WARNING  [*] 22:10:10: Train Epoch: 2 [38400/50751 (76%)] | Loss: 0.101507 | Elapsed: 10.22s | FPR 0.0003 -> TPR 0.9459 & F1 0.9722 | AUC 0.9938
2023-03-18 22:10:20,681 WARNING  [*] 22:10:20: Train Epoch: 2 [48000/50751 (95%)] | Loss: 0.117617 | Elapsed: 10.31s | FPR 0.0003 -> TPR 0.9559 & F1 0.9774 | AUC 0.9940
2023-03-18 22:10:24,812 WARNING  [*] Sat Mar 18 22:10:24 2023:    2    | Tr.loss: 0.142626 | Elapsed:   55.16  s | FPR 0.0003 -> TPR: 0.36 & F1: 0.53 | AUC: 0.9857
2023-03-18 22:10:24,812 WARNING  [*] Started epoch: 3
2023-03-18 22:10:24,948 WARNING  [*] 22:10:24: Train Epoch: 3 [  0  /50751 (0 %)] | Loss: 0.084571 | Elapsed: 0.12s | FPR 0.0003 -> TPR 0.8767 & F1 0.9343 | AUC 0.9929
2023-03-18 22:10:35,101 WARNING  [*] 22:10:35: Train Epoch: 3 [9600 /50751 (19%)] | Loss: 0.072417 | Elapsed: 10.15s | FPR 0.0003 -> TPR 0.9714 & F1 0.9855 | AUC 0.9967
2023-03-18 22:10:45,203 WARNING  [*] 22:10:45: Train Epoch: 3 [19200/50751 (38%)] | Loss: 0.066188 | Elapsed: 10.09s | FPR 0.0003 -> TPR 0.9516 & F1 0.9752 | AUC 0.9983
2023-03-18 22:10:55,284 WARNING  [*] 22:10:55: Train Epoch: 3 [28800/50751 (57%)] | Loss: 0.186816 | Elapsed: 10.08s | FPR 0.0003 -> TPR 0.9672 & F1 0.9833 | AUC 0.9849
2023-03-18 22:11:05,383 WARNING  [*] 22:11:05: Train Epoch: 3 [38400/50751 (76%)] | Loss: 0.035886 | Elapsed: 10.10s | FPR 0.0003 -> TPR 0.9846 & F1 0.9922 | AUC 0.9996
2023-03-18 22:11:15,486 WARNING  [*] 22:11:15: Train Epoch: 3 [48000/50751 (95%)] | Loss: 0.108404 | Elapsed: 10.09s | FPR 0.0003 -> TPR 0.9706 & F1 0.9851 | AUC 0.9945
2023-03-18 22:11:19,563 WARNING  [*] Sat Mar 18 22:11:19 2023:    3    | Tr.loss: 0.079000 | Elapsed:   54.75  s | FPR 0.0003 -> TPR: 0.39 & F1: 0.56 | AUC: 0.9953
2023-03-18 22:11:19,563 WARNING  [*] Started epoch: 4
2023-03-18 22:11:19,681 WARNING  [*] 22:11:19: Train Epoch: 4 [  0  /50751 (0 %)] | Loss: 0.045098 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.9714 & F1 0.9855 | AUC 0.9984
2023-03-18 22:11:29,804 WARNING  [*] 22:11:29: Train Epoch: 4 [9600 /50751 (19%)] | Loss: 0.024775 | Elapsed: 10.12s | FPR 0.0003 -> TPR 0.9853 & F1 0.9926 | AUC 0.9995
2023-03-18 22:11:39,957 WARNING  [*] 22:11:39: Train Epoch: 4 [19200/50751 (38%)] | Loss: 0.063113 | Elapsed: 10.14s | FPR 0.0003 -> TPR 1.0000 & F1 1.0000 | AUC 1.0000
2023-03-18 22:11:50,057 WARNING  [*] 22:11:50: Train Epoch: 4 [28800/50751 (57%)] | Loss: 0.038982 | Elapsed: 10.08s | FPR 0.0003 -> TPR 0.9841 & F1 0.9920 | AUC 0.9991
2023-03-18 22:12:00,128 WARNING  [*] 22:12:00: Train Epoch: 4 [38400/50751 (76%)] | Loss: 0.103843 | Elapsed: 10.06s | FPR 0.0003 -> TPR 0.9538 & F1 0.9764 | AUC 0.9925
2023-03-18 22:12:10,190 WARNING  [*] 22:12:10: Train Epoch: 4 [48000/50751 (95%)] | Loss: 0.066948 | Elapsed: 10.06s | FPR 0.0003 -> TPR 0.9483 & F1 0.9735 | AUC 0.9979
2023-03-18 22:12:14,141 WARNING  [*] Sat Mar 18 22:12:14 2023:    4    | Tr.loss: 0.059988 | Elapsed:   54.58  s | FPR 0.0003 -> TPR: 0.66 & F1: 0.80 | AUC: 0.9972
2023-03-18 22:12:14,141 WARNING  [*] Started epoch: 5
2023-03-18 22:12:14,265 WARNING  [*] 22:12:14: Train Epoch: 5 [  0  /50751 (0 %)] | Loss: 0.048744 | Elapsed: 0.11s | FPR 0.0003 -> TPR 0.9846 & F1 0.9922 | AUC 0.9980
2023-03-18 22:12:24,380 WARNING  [*] 22:12:24: Train Epoch: 5 [9600 /50751 (19%)] | Loss: 0.026831 | Elapsed: 10.11s | FPR 0.0003 -> TPR 1.0000 & F1 1.0000 | AUC 1.0000
2023-03-18 22:12:34,473 WARNING  [*] 22:12:34: Train Epoch: 5 [19200/50751 (38%)] | Loss: 0.043133 | Elapsed: 10.08s | FPR 0.0003 -> TPR 0.9839 & F1 0.9919 | AUC 0.9996
2023-03-18 22:12:44,530 WARNING  [*] 22:12:44: Train Epoch: 5 [28800/50751 (57%)] | Loss: 0.061261 | Elapsed: 10.06s | FPR 0.0003 -> TPR 0.9857 & F1 0.9928 | AUC 0.9971
2023-03-18 22:12:54,606 WARNING  [*] 22:12:54: Train Epoch: 5 [38400/50751 (76%)] | Loss: 0.019040 | Elapsed: 10.08s | FPR 0.0003 -> TPR 1.0000 & F1 1.0000 | AUC 1.0000
2023-03-18 22:13:04,695 WARNING  [*] 22:13:04: Train Epoch: 5 [48000/50751 (95%)] | Loss: 0.014950 | Elapsed: 10.07s | FPR 0.0003 -> TPR 1.0000 & F1 1.0000 | AUC 1.0000
2023-03-18 22:13:08,665 WARNING  [*] Sat Mar 18 22:13:08 2023:    5    | Tr.loss: 0.048568 | Elapsed:   54.52  s | FPR 0.0003 -> TPR: 0.74 & F1: 0.85 | AUC: 0.9981
2023-03-18 22:13:08,665 WARNING  [*] Started epoch: 6
2023-03-18 22:13:08,805 WARNING  [*] 22:13:08: Train Epoch: 6 [  0  /50751 (0 %)] | Loss: 0.029295 | Elapsed: 0.12s | FPR 0.0003 -> TPR 0.9844 & F1 0.9921 | AUC 0.9995
2023-03-18 22:13:18,882 WARNING  [*] 22:13:18: Train Epoch: 6 [9600 /50751 (19%)] | Loss: 0.099810 | Elapsed: 10.08s | FPR 0.0003 -> TPR 0.9054 & F1 0.9504 | AUC 0.9938
2023-03-18 22:13:28,988 WARNING  [*] 22:13:28: Train Epoch: 6 [19200/50751 (38%)] | Loss: 0.088893 | Elapsed: 10.11s | FPR 0.0003 -> TPR 0.9583 & F1 0.9787 | AUC 0.9945
2023-03-18 22:13:34,834 WARNING  [!] Time budget exceeded, training stopped.
2023-03-18 22:13:34,884 WARNING  [!] Sat Mar 18 22:13:34 2023: Dumped results:
                model       : 1679173712-model.torch
		train time  : 1679173712-trainTime.npy
		train losses: 1679173712-trainLosses.npy
		train AUC   : 1679173712-auc.npy
		train F1s   : 1679173712-trainF1s.npy
		train TPRs  : 1679173712-trainTPRs.npy
2023-03-18 22:13:34,906 WARNING  [!] Evaluating model on training set...
2023-03-18 22:13:48,614 WARNING  [!] This fold metrics on training set:
2023-03-18 22:13:48,627 WARNING 	AUC: 0.9993
2023-03-18 22:13:48,631 WARNING 	FPR: 0.0001 | TPR: 0.8507 | F1: 0.9193
2023-03-18 22:13:48,641 WARNING 	FPR: 0.0003 | TPR: 0.8793 | F1: 0.9357
2023-03-18 22:13:48,664 WARNING 	FPR: 0.001 | TPR: 0.9499 | F1: 0.9741
2023-03-18 22:13:48,671 WARNING 	FPR: 0.003 | TPR: 0.9791 | F1: 0.9887
2023-03-18 22:13:48,679 WARNING 	FPR: 0.01 | TPR: 0.9875 | F1: 0.9913
2023-03-18 22:13:48,703 WARNING 	FPR: 0.03 | TPR: 0.9943 | F1: 0.9900
2023-03-18 22:13:48,708 WARNING 	FPR: 0.1 | TPR: 0.9985 | F1: 0.9761
2023-03-18 22:13:48,708 WARNING  [!] Evaluating model on validation set...
2023-03-18 22:13:55,566 WARNING  [!] This fold metrics on validation set:
2023-03-18 22:13:55,578 WARNING 	AUC: 0.9982
2023-03-18 22:13:55,585 WARNING 	FPR: 0.0001 | TPR: 0.7998 | F1: 0.8888
2023-03-18 22:13:55,589 WARNING 	FPR: 0.0003 | TPR: 0.8223 | F1: 0.9024
2023-03-18 22:13:55,604 WARNING 	FPR: 0.001 | TPR: 0.8609 | F1: 0.9250
2023-03-18 22:13:55,611 WARNING 	FPR: 0.003 | TPR: 0.9640 | F1: 0.9810
2023-03-18 22:13:55,616 WARNING 	FPR: 0.01 | TPR: 0.9800 | F1: 0.9875
2023-03-18 22:13:55,621 WARNING 	FPR: 0.03 | TPR: 0.9893 | F1: 0.9875
2023-03-18 22:13:55,628 WARNING 	FPR: 0.1 | TPR: 0.9950 | F1: 0.9742
2023-03-18 22:13:55,790 WARNING  [3/3] Train set size: 50751, Validation set size: 25375
2023-03-18 22:13:57,758 WARNING  [!] Saved dataset splits to dataset_splits_1679174035.npz
2023-03-18 22:13:57,862 WARNING  [!] Iniatialized TransformerEncoderChunks. Total trainable parameters: 5.3972e6
2023-03-18 22:13:57,862 WARNING  [*] Training time budget set: 5.0 min
2023-03-18 22:13:57,884 WARNING  [*] Started epoch: 1
2023-03-18 22:13:58,117 WARNING  [*] 22:13:58: Train Epoch: 1 [  0  /50751 (0 %)] | Loss: 2.685838 | Elapsed: 0.22s | FPR 0.0003 -> TPR 0.0725 & F1 0.1351 | AUC 0.4187
2023-03-18 22:14:08,184 WARNING  [*] 22:14:08: Train Epoch: 1 [9600 /50751 (19%)] | Loss: 0.329025 | Elapsed: 10.07s | FPR 0.0003 -> TPR 0.6364 & F1 0.7778 | AUC 0.9171
2023-03-18 22:14:18,254 WARNING  [*] 22:14:18: Train Epoch: 1 [19200/50751 (38%)] | Loss: 0.387239 | Elapsed: 10.05s | FPR 0.0003 -> TPR 0.5909 & F1 0.7429 | AUC 0.8997
2023-03-18 22:14:28,344 WARNING  [*] 22:14:28: Train Epoch: 1 [28800/50751 (57%)] | Loss: 0.276793 | Elapsed: 10.08s | FPR 0.0003 -> TPR 0.5571 & F1 0.7156 | AUC 0.9429
2023-03-18 22:14:38,427 WARNING  [*] 22:14:38: Train Epoch: 1 [38400/50751 (76%)] | Loss: 0.237088 | Elapsed: 10.07s | FPR 0.0003 -> TPR 0.6667 & F1 0.8000 | AUC 0.9694
2023-03-18 22:14:48,507 WARNING  [*] 22:14:48: Train Epoch: 1 [48000/50751 (95%)] | Loss: 0.189671 | Elapsed: 10.08s | FPR 0.0003 -> TPR 0.6029 & F1 0.7523 | AUC 0.9683
2023-03-18 22:14:52,559 WARNING  [*] Sat Mar 18 22:14:52 2023:    1    | Tr.loss: 0.338396 | Elapsed:   54.67  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.01 | AUC: 0.9199
2023-03-18 22:14:52,559 WARNING  [*] Started epoch: 2
2023-03-18 22:14:52,676 WARNING  [*] 22:14:52: Train Epoch: 2 [  0  /50751 (0 %)] | Loss: 0.105989 | Elapsed: 0.12s | FPR 0.0003 -> TPR 0.9394 & F1 0.9688 | AUC 0.9965
2023-03-18 22:15:02,760 WARNING  [*] 22:15:02: Train Epoch: 2 [9600 /50751 (19%)] | Loss: 0.247791 | Elapsed: 10.07s | FPR 0.0003 -> TPR 0.8657 & F1 0.9280 | AUC 0.9724
2023-03-18 22:15:12,820 WARNING  [*] 22:15:12: Train Epoch: 2 [19200/50751 (38%)] | Loss: 0.118934 | Elapsed: 10.06s | FPR 0.0003 -> TPR 0.9444 & F1 0.9714 | AUC 0.9901
2023-03-18 22:15:22,932 WARNING  [*] 22:15:22: Train Epoch: 2 [28800/50751 (57%)] | Loss: 0.084159 | Elapsed: 10.11s | FPR 0.0003 -> TPR 0.9577 & F1 0.9784 | AUC 0.9985
2023-03-18 22:15:33,024 WARNING  [*] 22:15:33: Train Epoch: 2 [38400/50751 (76%)] | Loss: 0.047359 | Elapsed: 10.09s | FPR 0.0003 -> TPR 0.9859 & F1 0.9929 | AUC 0.9985
2023-03-18 22:15:43,097 WARNING  [*] 22:15:43: Train Epoch: 2 [48000/50751 (95%)] | Loss: 0.143247 | Elapsed: 10.07s | FPR 0.0003 -> TPR 0.8644 & F1 0.9273 | AUC 0.9897
2023-03-18 22:15:47,054 WARNING  [*] Sat Mar 18 22:15:47 2023:    2    | Tr.loss: 0.143573 | Elapsed:   54.50  s | FPR 0.0003 -> TPR: 0.37 & F1: 0.54 | AUC: 0.9856
2023-03-18 22:15:47,054 WARNING  [*] Started epoch: 3
2023-03-18 22:15:47,180 WARNING  [*] 22:15:47: Train Epoch: 3 [  0  /50751 (0 %)] | Loss: 0.159480 | Elapsed: 0.11s | FPR 0.0003 -> TPR 0.9661 & F1 0.9828 | AUC 0.9885
2023-03-18 22:15:57,285 WARNING  [*] 22:15:57: Train Epoch: 3 [9600 /50751 (19%)] | Loss: 0.033645 | Elapsed: 10.11s | FPR 0.0003 -> TPR 0.9857 & F1 0.9928 | AUC 0.9995
2023-03-18 22:16:07,345 WARNING  [*] 22:16:07: Train Epoch: 3 [19200/50751 (38%)] | Loss: 0.051382 | Elapsed: 10.06s | FPR 0.0003 -> TPR 0.9855 & F1 0.9927 | AUC 0.9986
2023-03-18 22:16:17,427 WARNING  [*] 22:16:17: Train Epoch: 3 [28800/50751 (57%)] | Loss: 0.029166 | Elapsed: 10.05s | FPR 0.0003 -> TPR 1.0000 & F1 1.0000 | AUC 1.0000
2023-03-18 22:16:27,521 WARNING  [*] 22:16:27: Train Epoch: 3 [38400/50751 (76%)] | Loss: 0.060218 | Elapsed: 10.08s | FPR 0.0003 -> TPR 0.9219 & F1 0.9593 | AUC 0.9970
2023-03-18 22:16:37,598 WARNING  [*] 22:16:37: Train Epoch: 3 [48000/50751 (95%)] | Loss: 0.110002 | Elapsed: 10.08s | FPR 0.0003 -> TPR 0.9552 & F1 0.9771 | AUC 0.9955
2023-03-18 22:16:41,587 WARNING  [*] Sat Mar 18 22:16:41 2023:    3    | Tr.loss: 0.082058 | Elapsed:   54.53  s | FPR 0.0003 -> TPR: 0.38 & F1: 0.55 | AUC: 0.9950
2023-03-18 22:16:41,587 WARNING  [*] Started epoch: 4
2023-03-18 22:16:41,716 WARNING  [*] 22:16:41: Train Epoch: 4 [  0  /50751 (0 %)] | Loss: 0.058396 | Elapsed: 0.11s | FPR 0.0003 -> TPR 0.9403 & F1 0.9692 | AUC 0.9979
2023-03-18 22:16:51,783 WARNING  [*] 22:16:51: Train Epoch: 4 [9600 /50751 (19%)] | Loss: 0.040074 | Elapsed: 10.07s | FPR 0.0003 -> TPR 0.9831 & F1 0.9915 | AUC 0.9979
2023-03-18 22:17:01,862 WARNING  [*] 22:17:01: Train Epoch: 4 [19200/50751 (38%)] | Loss: 0.033544 | Elapsed: 10.08s | FPR 0.0003 -> TPR 1.0000 & F1 1.0000 | AUC 1.0000
2023-03-18 22:17:11,935 WARNING  [*] 22:17:11: Train Epoch: 4 [28800/50751 (57%)] | Loss: 0.153741 | Elapsed: 10.07s | FPR 0.0003 -> TPR 0.9420 & F1 0.9701 | AUC 0.9921
2023-03-18 22:17:22,014 WARNING  [*] 22:17:22: Train Epoch: 4 [38400/50751 (76%)] | Loss: 0.123915 | Elapsed: 10.06s | FPR 0.0003 -> TPR 0.9403 & F1 0.9692 | AUC 0.9941
2023-03-18 22:17:32,077 WARNING  [*] 22:17:32: Train Epoch: 4 [48000/50751 (95%)] | Loss: 0.006964 | Elapsed: 10.06s | FPR 0.0003 -> TPR 1.0000 & F1 1.0000 | AUC 1.0000
2023-03-18 22:17:36,091 WARNING  [*] Sat Mar 18 22:17:36 2023:    4    | Tr.loss: 0.059107 | Elapsed:   54.50  s | FPR 0.0003 -> TPR: 0.74 & F1: 0.85 | AUC: 0.9972
2023-03-18 22:17:36,091 WARNING  [*] Started epoch: 5
2023-03-18 22:17:36,206 WARNING  [*] 22:17:36: Train Epoch: 5 [  0  /50751 (0 %)] | Loss: 0.055616 | Elapsed: 0.12s | FPR 0.0003 -> TPR 0.9857 & F1 0.9928 | AUC 0.9962
2023-03-18 22:17:46,340 WARNING  [*] 22:17:46: Train Epoch: 5 [9600 /50751 (19%)] | Loss: 0.015934 | Elapsed: 10.13s | FPR 0.0003 -> TPR 1.0000 & F1 1.0000 | AUC 1.0000
2023-03-18 22:17:56,415 WARNING  [*] 22:17:56: Train Epoch: 5 [19200/50751 (38%)] | Loss: 0.019723 | Elapsed: 10.06s | FPR 0.0003 -> TPR 1.0000 & F1 1.0000 | AUC 1.0000
2023-03-18 22:18:06,467 WARNING  [*] 22:18:06: Train Epoch: 5 [28800/50751 (57%)] | Loss: 0.083020 | Elapsed: 10.05s | FPR 0.0003 -> TPR 0.9857 & F1 0.9928 | AUC 0.9995
2023-03-18 22:18:16,531 WARNING  [*] 22:18:16: Train Epoch: 5 [38400/50751 (76%)] | Loss: 0.010133 | Elapsed: 10.05s | FPR 0.0003 -> TPR 1.0000 & F1 1.0000 | AUC 1.0000
2023-03-18 22:18:26,613 WARNING  [*] 22:18:26: Train Epoch: 5 [48000/50751 (95%)] | Loss: 0.015870 | Elapsed: 10.07s | FPR 0.0003 -> TPR 1.0000 & F1 1.0000 | AUC 1.0000
2023-03-18 22:18:30,613 WARNING  [*] Sat Mar 18 22:18:30 2023:    5    | Tr.loss: 0.049154 | Elapsed:   54.52  s | FPR 0.0003 -> TPR: 0.75 & F1: 0.86 | AUC: 0.9980
2023-03-18 22:18:30,613 WARNING  [*] Started epoch: 6
2023-03-18 22:18:30,745 WARNING  [*] 22:18:30: Train Epoch: 6 [  0  /50751 (0 %)] | Loss: 0.042737 | Elapsed: 0.12s | FPR 0.0003 -> TPR 0.9855 & F1 0.9927 | AUC 0.9989
2023-03-18 22:18:40,824 WARNING  [*] 22:18:40: Train Epoch: 6 [9600 /50751 (19%)] | Loss: 0.017835 | Elapsed: 10.06s | FPR 0.0003 -> TPR 1.0000 & F1 1.0000 | AUC 1.0000
2023-03-18 22:18:50,865 WARNING  [*] 22:18:50: Train Epoch: 6 [19200/50751 (38%)] | Loss: 0.015067 | Elapsed: 10.04s | FPR 0.0003 -> TPR 1.0000 & F1 1.0000 | AUC 1.0000
2023-03-18 22:18:57,950 WARNING  [!] Time budget exceeded, training stopped.
2023-03-18 22:18:57,990 WARNING  [!] Sat Mar 18 22:18:57 2023: Dumped results:
                model       : 1679174035-model.torch
		train time  : 1679174035-trainTime.npy
		train losses: 1679174035-trainLosses.npy
		train AUC   : 1679174035-auc.npy
		train F1s   : 1679174035-trainF1s.npy
		train TPRs  : 1679174035-trainTPRs.npy
2023-03-18 22:18:58,019 WARNING  [!] Evaluating model on training set...
2023-03-18 22:19:11,750 WARNING  [!] This fold metrics on training set:
2023-03-18 22:19:11,766 WARNING 	AUC: 0.9991
2023-03-18 22:19:11,769 WARNING 	FPR: 0.0001 | TPR: 0.0000 | F1: 0.0000
2023-03-18 22:19:11,779 WARNING 	FPR: 0.0003 | TPR: 0.9196 | F1: 0.9580
2023-03-18 22:19:11,800 WARNING 	FPR: 0.001 | TPR: 0.9553 | F1: 0.9769
2023-03-18 22:19:11,809 WARNING 	FPR: 0.003 | TPR: 0.9694 | F1: 0.9837
2023-03-18 22:19:11,814 WARNING 	FPR: 0.01 | TPR: 0.9873 | F1: 0.9912
2023-03-18 22:19:11,835 WARNING 	FPR: 0.03 | TPR: 0.9944 | F1: 0.9901
2023-03-18 22:19:11,842 WARNING 	FPR: 0.1 | TPR: 0.9985 | F1: 0.9761
2023-03-18 22:19:11,842 WARNING  [!] Evaluating model on validation set...
2023-03-18 22:19:18,716 WARNING  [!] This fold metrics on validation set:
2023-03-18 22:19:18,720 WARNING 	AUC: 0.9977
2023-03-18 22:19:18,727 WARNING 	FPR: 0.0001 | TPR: 0.0000 | F1: 0.0000
2023-03-18 22:19:18,733 WARNING 	FPR: 0.0003 | TPR: 0.0000 | F1: 0.0000
2023-03-18 22:19:18,736 WARNING 	FPR: 0.001 | TPR: 0.9211 | F1: 0.9587
2023-03-18 22:19:18,742 WARNING 	FPR: 0.003 | TPR: 0.9401 | F1: 0.9684
2023-03-18 22:19:18,753 WARNING 	FPR: 0.01 | TPR: 0.9768 | F1: 0.9859
2023-03-18 22:19:18,760 WARNING 	FPR: 0.03 | TPR: 0.9878 | F1: 0.9869
2023-03-18 22:19:18,765 WARNING 	FPR: 0.1 | TPR: 0.9954 | F1: 0.9745
2023-03-18 22:19:18,849 WARNING  [!] Metrics saved to out_fields_1679165454\cv_api_only_full_limNone_r1763_t5\api_only_full_metrics_validation.json
2023-03-18 22:19:18,851 WARNING  [!] Metrics saved to out_fields_1679165454\cv_api_only_full_limNone_r1763_t5\api_only_full_metrics_training.json
2023-03-18 22:19:18,852 WARNING  [!] Average epoch time: 0.03s | Mean values over 3 folds:
	AUC: 0.9980
	FPR: 0.0001 -- TPR: 0.2666 -- F1: 0.2963
	FPR: 0.0003 -- TPR: 0.2741 -- F1: 0.3008
	FPR:  0.001 -- TPR: 0.8897 -- F1: 0.9412
	FPR:  0.003 -- TPR: 0.9487 -- F1: 0.9730
	FPR:   0.01 -- TPR: 0.9779 -- F1: 0.9864
	FPR:   0.03 -- TPR: 0.9887 -- F1: 0.9872
	FPR:    0.1 -- TPR: 0.9955 -- F1: 0.9744

2023-03-18 22:19:18,913 WARNING  [!] Working on file_network_registry!
2023-03-18 22:19:18,922 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_backdoor
2023-03-18 22:20:49,803 WARNING Finished... Took: 90.88s
2023-03-18 22:20:49,803 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_clean
2023-03-18 22:23:05,203 WARNING Finished... Took: 135.40s
2023-03-18 22:23:05,203 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_coinminer
2023-03-18 22:23:43,141 WARNING Finished... Took: 37.94s
2023-03-18 22:23:43,141 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_dropper
2023-03-18 22:24:24,463 WARNING Finished... Took: 41.32s
2023-03-18 22:24:24,463 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_keylogger
2023-03-18 22:24:49,132 WARNING Finished... Took: 24.67s
2023-03-18 22:24:49,132 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_ransomware
2023-03-18 22:25:35,215 WARNING Finished... Took: 46.08s
2023-03-18 22:25:35,216 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_rat
2023-03-18 22:25:49,364 WARNING Finished... Took: 14.15s
2023-03-18 22:25:49,364 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_trojan
2023-03-18 22:26:46,001 WARNING Finished... Took: 56.64s
2023-03-18 22:26:46,002 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_windows_syswow64
2023-03-18 22:26:46,998 WARNING Finished... Took: 1.00s
2023-03-18 22:26:47,004 WARNING  [!] Saved Y as out_fields_1679165454\file_network_registry_vocab_50000_seqlen_512\y_train_full.npy
2023-03-18 22:26:47,244 WARNING  [!] Saved Y names as out_fields_1679165454\file_network_registry_vocab_50000_seqlen_512\y_names_train_full.json
2023-03-18 22:26:47,244 WARNING  [*] Initializing tokenizer training...
2023-03-18 22:26:48,066 WARNING Dumped vocab to out_fields_1679165454\file_network_registry_vocab_50000_seqlen_512\tokenizer_50000_vocab.json
2023-03-18 22:26:48,070 WARNING Dumped vocab counter to out_fields_1679165454\file_network_registry_vocab_50000_seqlen_512\tokenizer_50000_counter.json
2023-03-18 22:26:48,070 WARNING  [*] Encoding and padding...
2023-03-18 22:26:51,381 WARNING  [!] Saved X as out_fields_1679165454\file_network_registry_vocab_50000_seqlen_512\x_train_full.npy
2023-03-18 22:26:51,533 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_backdoor
2023-03-18 22:27:29,828 WARNING Finished... Took: 38.30s
2023-03-18 22:27:29,828 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_clean
2023-03-18 22:29:07,206 WARNING Finished... Took: 97.38s
2023-03-18 22:29:07,206 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_coinminer
2023-03-18 22:29:32,497 WARNING Finished... Took: 25.29s
2023-03-18 22:29:32,497 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_dropper
2023-03-18 22:29:35,038 WARNING Finished... Took: 2.54s
2023-03-18 22:29:35,038 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_keylogger
2023-03-18 22:29:46,460 WARNING Finished... Took: 11.42s
2023-03-18 22:29:46,460 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_ransomware
2023-03-18 22:31:54,036 WARNING Finished... Took: 127.58s
2023-03-18 22:31:54,036 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_rat
2023-03-18 22:32:11,912 WARNING Finished... Took: 17.88s
2023-03-18 22:32:11,912 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_trojan
2023-03-18 22:32:23,306 WARNING Finished... Took: 11.39s
2023-03-18 22:32:23,306 WARNING Filtering and normalizing C:\Users\dtrizna\Code\nebula\evaluation\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_windows_syswow64
2023-03-18 22:32:23,763 WARNING Finished... Took: 0.46s
2023-03-18 22:32:23,768 WARNING  [!] Saved Y as out_fields_1679165454\file_network_registry_vocab_50000_seqlen_512\y_test_full.npy
2023-03-18 22:32:23,803 WARNING  [!] Saved Y names as out_fields_1679165454\file_network_registry_vocab_50000_seqlen_512\y_names_test_full.json
2023-03-18 22:32:23,820 WARNING  [*] Encoding and padding...
2023-03-18 22:32:42,454 WARNING  [!] Saved X as out_fields_1679165454\file_network_registry_vocab_50000_seqlen_512\x_test_full.npy
2023-03-18 22:32:43,019 WARNING  [!!!] Starting CV over file_network_registry!
2023-03-18 22:32:43,098 WARNING  [!] Training time budget: 300min
2023-03-18 22:32:43,099 WARNING  [!] Model config: {'vocab_size': 6215, 'maxlen': 512, 'chunk_size': 64, 'dModel': 64, 'nHeads': 8, 'dHidden': 256, 'nLayers': 2, 'numClasses': 1, 'hiddenNeurons': [64], 'layerNorm': False, 'dropout': 0.3, 'mean_over_sequence': False, 'norm_first': True}
2023-03-18 22:32:43,173 WARNING  [1/3] Train set size: 60730, Validation set size: 30366
2023-03-18 22:32:44,004 WARNING  [!] Saved dataset splits to dataset_splits_1679175163.npz
2023-03-18 22:32:44,053 WARNING  [!] Iniatialized TransformerEncoderChunks. Total trainable parameters: 2.5950e6
2023-03-18 22:32:44,053 WARNING  [*] Training time budget set: 5.0 min
2023-03-18 22:32:44,087 WARNING  [*] Started epoch: 1
2023-03-18 22:32:44,490 WARNING  [*] 22:32:44: Train Epoch: 1 [  0  /60730 (0 %)] | Loss: 3.427146 | Elapsed: 0.40s | FPR 0.0003 -> TPR 0.0282 & F1 0.0548 | AUC 0.3268
2023-03-18 22:32:54,042 WARNING  [*] 22:32:54: Train Epoch: 1 [9600 /60730 (16%)] | Loss: 0.651726 | Elapsed: 9.54s | FPR 0.0003 -> TPR 0.0455 & F1 0.0870 | AUC 0.5165
2023-03-18 22:33:03,636 WARNING  [*] 22:33:03: Train Epoch: 1 [19200/60730 (32%)] | Loss: 0.614477 | Elapsed: 9.58s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.5580
2023-03-18 22:33:13,276 WARNING  [*] 22:33:13: Train Epoch: 1 [28800/60730 (47%)] | Loss: 0.581956 | Elapsed: 9.62s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.5754
2023-03-18 22:33:22,949 WARNING  [*] 22:33:22: Train Epoch: 1 [38400/60730 (63%)] | Loss: 0.585931 | Elapsed: 9.67s | FPR 0.0003 -> TPR 0.0270 & F1 0.0526 | AUC 0.5395
2023-03-18 22:33:32,669 WARNING  [*] 22:33:32: Train Epoch: 1 [48000/60730 (79%)] | Loss: 0.546027 | Elapsed: 9.72s | FPR 0.0003 -> TPR 0.0789 & F1 0.1463 | AUC 0.5932
2023-03-18 22:33:42,420 WARNING  [*] 22:33:42: Train Epoch: 1 [57600/60730 (95%)] | Loss: 0.583223 | Elapsed: 9.75s | FPR 0.0003 -> TPR 0.1711 & F1 0.2921 | AUC 0.4578
2023-03-18 22:33:46,698 WARNING  [*] Sat Mar 18 22:33:46 2023:    1    | Tr.loss: 0.622870 | Elapsed:   62.61  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.5118
2023-03-18 22:33:46,698 WARNING  [*] Started epoch: 2
2023-03-18 22:33:46,829 WARNING  [*] 22:33:46: Train Epoch: 2 [  0  /60730 (0 %)] | Loss: 0.576107 | Elapsed: 0.12s | FPR 0.0003 -> TPR 0.0137 & F1 0.0270 | AUC 0.4443
2023-03-18 22:33:56,626 WARNING  [*] 22:33:56: Train Epoch: 2 [9600 /60730 (16%)] | Loss: 0.599561 | Elapsed: 9.80s | FPR 0.0003 -> TPR 0.1143 & F1 0.2051 | AUC 0.5810
2023-03-18 22:34:06,434 WARNING  [*] 22:34:06: Train Epoch: 2 [19200/60730 (32%)] | Loss: 0.565859 | Elapsed: 9.81s | FPR 0.0003 -> TPR 0.0933 & F1 0.1707 | AUC 0.5627
2023-03-18 22:34:16,255 WARNING  [*] 22:34:16: Train Epoch: 2 [28800/60730 (47%)] | Loss: 0.568254 | Elapsed: 9.82s | FPR 0.0003 -> TPR 0.1944 & F1 0.3256 | AUC 0.6275
2023-03-18 22:34:26,085 WARNING  [*] 22:34:26: Train Epoch: 2 [38400/60730 (63%)] | Loss: 0.587115 | Elapsed: 9.80s | FPR 0.0003 -> TPR 0.1806 & F1 0.3059 | AUC 0.5362
2023-03-18 22:34:35,939 WARNING  [*] 22:34:35: Train Epoch: 2 [48000/60730 (79%)] | Loss: 0.614078 | Elapsed: 9.85s | FPR 0.0003 -> TPR 0.1970 & F1 0.3291 | AUC 0.6203
2023-03-18 22:34:45,778 WARNING  [*] 22:34:45: Train Epoch: 2 [57600/60730 (95%)] | Loss: 0.506465 | Elapsed: 9.82s | FPR 0.0003 -> TPR 0.2400 & F1 0.3871 | AUC 0.6827
2023-03-18 22:34:50,118 WARNING  [*] Sat Mar 18 22:34:50 2023:    2    | Tr.loss: 0.569501 | Elapsed:   63.42  s | FPR 0.0003 -> TPR: 0.02 & F1: 0.04 | AUC: 0.6118
2023-03-18 22:34:50,118 WARNING  [*] Started epoch: 3
2023-03-18 22:34:50,233 WARNING  [*] 22:34:50: Train Epoch: 3 [  0  /60730 (0 %)] | Loss: 0.510652 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.2794 & F1 0.4368 | AUC 0.7445
2023-03-18 22:35:00,075 WARNING  [*] 22:35:00: Train Epoch: 3 [9600 /60730 (16%)] | Loss: 0.481941 | Elapsed: 9.83s | FPR 0.0003 -> TPR 0.2703 & F1 0.4255 | AUC 0.7251
2023-03-18 22:35:09,926 WARNING  [*] 22:35:09: Train Epoch: 3 [19200/60730 (32%)] | Loss: 0.586571 | Elapsed: 9.84s | FPR 0.0003 -> TPR 0.2609 & F1 0.4138 | AUC 0.6503
2023-03-18 22:35:19,812 WARNING  [*] 22:35:19: Train Epoch: 3 [28800/60730 (47%)] | Loss: 0.491950 | Elapsed: 9.87s | FPR 0.0003 -> TPR 0.2466 & F1 0.3956 | AUC 0.7235
2023-03-18 22:35:29,690 WARNING  [*] 22:35:29: Train Epoch: 3 [38400/60730 (63%)] | Loss: 0.480172 | Elapsed: 9.88s | FPR 0.0003 -> TPR 0.1711 & F1 0.2921 | AUC 0.7330
2023-03-18 22:35:39,549 WARNING  [*] 22:35:39: Train Epoch: 3 [48000/60730 (79%)] | Loss: 0.395391 | Elapsed: 9.86s | FPR 0.0003 -> TPR 0.2683 & F1 0.4231 | AUC 0.7419
2023-03-18 22:35:49,405 WARNING  [*] 22:35:49: Train Epoch: 3 [57600/60730 (95%)] | Loss: 0.478444 | Elapsed: 9.84s | FPR 0.0003 -> TPR 0.1690 & F1 0.2892 | AUC 0.6969
2023-03-18 22:35:53,934 WARNING  [*] Sat Mar 18 22:35:53 2023:    3    | Tr.loss: 0.506213 | Elapsed:   63.82  s | FPR 0.0003 -> TPR: 0.06 & F1: 0.11 | AUC: 0.7102
2023-03-18 22:35:53,934 WARNING  [*] Started epoch: 4
2023-03-18 22:35:54,055 WARNING  [*] 22:35:54: Train Epoch: 4 [  0  /60730 (0 %)] | Loss: 0.448430 | Elapsed: 0.11s | FPR 0.0003 -> TPR 0.3803 & F1 0.5510 | AUC 0.7561
2023-03-18 22:36:03,890 WARNING  [*] 22:36:03: Train Epoch: 4 [9600 /60730 (16%)] | Loss: 0.450549 | Elapsed: 9.83s | FPR 0.0003 -> TPR 0.2571 & F1 0.4091 | AUC 0.7576
2023-03-18 22:36:13,743 WARNING  [*] 22:36:13: Train Epoch: 4 [19200/60730 (32%)] | Loss: 0.456570 | Elapsed: 9.84s | FPR 0.0003 -> TPR 0.2667 & F1 0.4211 | AUC 0.7285
2023-03-18 22:36:23,590 WARNING  [*] 22:36:23: Train Epoch: 4 [28800/60730 (47%)] | Loss: 0.445034 | Elapsed: 9.83s | FPR 0.0003 -> TPR 0.1486 & F1 0.2588 | AUC 0.7601
2023-03-18 22:36:33,453 WARNING  [*] 22:36:33: Train Epoch: 4 [38400/60730 (63%)] | Loss: 0.461553 | Elapsed: 9.86s | FPR 0.0003 -> TPR 0.1333 & F1 0.2353 | AUC 0.6720
2023-03-18 22:36:43,373 WARNING  [*] 22:36:43: Train Epoch: 4 [48000/60730 (79%)] | Loss: 0.420953 | Elapsed: 9.92s | FPR 0.0003 -> TPR 0.2875 & F1 0.4466 | AUC 0.6456
2023-03-18 22:36:53,239 WARNING  [*] 22:36:53: Train Epoch: 4 [57600/60730 (95%)] | Loss: 0.413107 | Elapsed: 9.85s | FPR 0.0003 -> TPR 0.3038 & F1 0.4660 | AUC 0.7242
2023-03-18 22:36:57,717 WARNING  [*] Sat Mar 18 22:36:57 2023:    4    | Tr.loss: 0.479661 | Elapsed:   63.78  s | FPR 0.0003 -> TPR: 0.08 & F1: 0.15 | AUC: 0.7180
2023-03-18 22:36:57,717 WARNING  [*] Started epoch: 5
2023-03-18 22:36:57,832 WARNING  [*] 22:36:57: Train Epoch: 5 [  0  /60730 (0 %)] | Loss: 0.539606 | Elapsed: 0.11s | FPR 0.0003 -> TPR 0.2063 & F1 0.3421 | AUC 0.6460
2023-03-18 22:37:07,770 WARNING  [*] 22:37:07: Train Epoch: 5 [9600 /60730 (16%)] | Loss: 0.587676 | Elapsed: 9.92s | FPR 0.0003 -> TPR 0.2667 & F1 0.4211 | AUC 0.7592
2023-03-18 22:37:17,618 WARNING  [*] 22:37:17: Train Epoch: 5 [19200/60730 (32%)] | Loss: 0.435440 | Elapsed: 9.83s | FPR 0.0003 -> TPR 0.3200 & F1 0.4848 | AUC 0.7408
2023-03-18 22:37:27,470 WARNING  [*] 22:37:27: Train Epoch: 5 [28800/60730 (47%)] | Loss: 0.419580 | Elapsed: 9.84s | FPR 0.0003 -> TPR 0.2933 & F1 0.4536 | AUC 0.7707
2023-03-18 22:37:37,344 WARNING  [*] 22:37:37: Train Epoch: 5 [38400/60730 (63%)] | Loss: 0.493186 | Elapsed: 9.86s | FPR 0.0003 -> TPR 0.1806 & F1 0.3059 | AUC 0.6825
2023-03-18 22:37:44,065 WARNING  [!] Time budget exceeded, training stopped.
2023-03-18 22:37:44,095 WARNING  [!] Sat Mar 18 22:37:44 2023: Dumped results:
                model       : 1679175163-model.torch
		train time  : 1679175163-trainTime.npy
		train losses: 1679175163-trainLosses.npy
		train AUC   : 1679175163-auc.npy
		train F1s   : 1679175163-trainF1s.npy
		train TPRs  : 1679175163-trainTPRs.npy
2023-03-18 22:37:44,137 WARNING  [!] Evaluating model on training set...
2023-03-18 22:38:00,303 WARNING  [!] This fold metrics on training set:
2023-03-18 22:38:00,322 WARNING 	AUC: 0.7224
2023-03-18 22:38:00,328 WARNING 	FPR: 0.0001 | TPR: 0.1297 | F1: 0.2296
2023-03-18 22:38:00,356 WARNING 	FPR: 0.0003 | TPR: 0.1657 | F1: 0.2843
2023-03-18 22:38:00,360 WARNING 	FPR: 0.001 | TPR: 0.1809 | F1: 0.3062
2023-03-18 22:38:00,386 WARNING 	FPR: 0.003 | TPR: 0.2122 | F1: 0.3498
2023-03-18 22:38:00,389 WARNING 	FPR: 0.01 | TPR: 0.2433 | F1: 0.3902
2023-03-18 22:38:00,419 WARNING 	FPR: 0.03 | TPR: 0.2605 | F1: 0.4102
2023-03-18 22:38:00,422 WARNING 	FPR: 0.1 | TPR: 0.3392 | F1: 0.4926
2023-03-18 22:38:00,422 WARNING  [!] Evaluating model on validation set...
2023-03-18 22:38:08,501 WARNING  [!] This fold metrics on validation set:
2023-03-18 22:38:08,520 WARNING 	AUC: 0.7279
2023-03-18 22:38:08,527 WARNING 	FPR: 0.0001 | TPR: 0.0000 | F1: 0.0000
2023-03-18 22:38:08,530 WARNING 	FPR: 0.0003 | TPR: 0.1663 | F1: 0.2852
2023-03-18 22:38:08,545 WARNING 	FPR: 0.001 | TPR: 0.1723 | F1: 0.2939
2023-03-18 22:38:08,554 WARNING 	FPR: 0.003 | TPR: 0.1968 | F1: 0.3286
2023-03-18 22:38:08,558 WARNING 	FPR: 0.01 | TPR: 0.2439 | F1: 0.3910
2023-03-18 22:38:08,564 WARNING 	FPR: 0.03 | TPR: 0.2611 | F1: 0.4110
2023-03-18 22:38:08,579 WARNING 	FPR: 0.1 | TPR: 0.3411 | F1: 0.4945
2023-03-18 22:38:08,741 WARNING  [2/3] Train set size: 60731, Validation set size: 30365
2023-03-18 22:38:09,640 WARNING  [!] Saved dataset splits to dataset_splits_1679175488.npz
2023-03-18 22:38:09,693 WARNING  [!] Iniatialized TransformerEncoderChunks. Total trainable parameters: 2.5950e6
2023-03-18 22:38:09,693 WARNING  [*] Training time budget set: 5.0 min
2023-03-18 22:38:09,738 WARNING  [*] Started epoch: 1
2023-03-18 22:38:09,876 WARNING  [*] 22:38:09: Train Epoch: 1 [  0  /60731 (0 %)] | Loss: 7.903575 | Elapsed: 0.13s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.5454
2023-03-18 22:38:19,761 WARNING  [*] 22:38:19: Train Epoch: 1 [9600 /60731 (16%)] | Loss: 0.653742 | Elapsed: 9.87s | FPR 0.0003 -> TPR 0.0147 & F1 0.0290 | AUC 0.4862
2023-03-18 22:38:29,678 WARNING  [*] 22:38:29: Train Epoch: 1 [19200/60731 (32%)] | Loss: 0.604555 | Elapsed: 9.90s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.4530
2023-03-18 22:38:39,548 WARNING  [*] 22:38:39: Train Epoch: 1 [28800/60731 (47%)] | Loss: 0.655774 | Elapsed: 9.87s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.3817
2023-03-18 22:38:49,418 WARNING  [*] 22:38:49: Train Epoch: 1 [38400/60731 (63%)] | Loss: 0.607735 | Elapsed: 9.87s | FPR 0.0003 -> TPR 0.0833 & F1 0.1538 | AUC 0.5303
2023-03-18 22:38:59,294 WARNING  [*] 22:38:59: Train Epoch: 1 [48000/60731 (79%)] | Loss: 0.544236 | Elapsed: 9.88s | FPR 0.0003 -> TPR 0.0375 & F1 0.0723 | AUC 0.5159
2023-03-18 22:39:09,227 WARNING  [*] 22:39:09: Train Epoch: 1 [57600/60731 (95%)] | Loss: 0.582886 | Elapsed: 9.92s | FPR 0.0003 -> TPR 0.0133 & F1 0.0263 | AUC 0.4664
2023-03-18 22:39:13,686 WARNING  [*] Sat Mar 18 22:39:13 2023:    1    | Tr.loss: 0.635877 | Elapsed:   63.95  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.5055
2023-03-18 22:39:13,686 WARNING  [*] Started epoch: 2
2023-03-18 22:39:13,815 WARNING  [*] 22:39:13: Train Epoch: 2 [  0  /60731 (0 %)] | Loss: 0.628769 | Elapsed: 0.11s | FPR 0.0003 -> TPR 0.0299 & F1 0.0580 | AUC 0.4856
2023-03-18 22:39:23,663 WARNING  [*] 22:39:23: Train Epoch: 2 [9600 /60731 (16%)] | Loss: 0.576529 | Elapsed: 9.85s | FPR 0.0003 -> TPR 0.1127 & F1 0.2025 | AUC 0.6377
2023-03-18 22:39:33,610 WARNING  [*] 22:39:33: Train Epoch: 2 [19200/60731 (32%)] | Loss: 0.507727 | Elapsed: 9.93s | FPR 0.0003 -> TPR 0.2466 & F1 0.3956 | AUC 0.6900
2023-03-18 22:39:43,466 WARNING  [*] 22:39:43: Train Epoch: 2 [28800/60731 (47%)] | Loss: 0.625924 | Elapsed: 9.86s | FPR 0.0003 -> TPR 0.1159 & F1 0.2078 | AUC 0.6587
2023-03-18 22:39:53,331 WARNING  [*] 22:39:53: Train Epoch: 2 [38400/60731 (63%)] | Loss: 0.487751 | Elapsed: 9.86s | FPR 0.0003 -> TPR 0.3143 & F1 0.4783 | AUC 0.8043
2023-03-18 22:40:03,213 WARNING  [*] 22:40:03: Train Epoch: 2 [48000/60731 (79%)] | Loss: 0.451225 | Elapsed: 9.87s | FPR 0.0003 -> TPR 0.3247 & F1 0.4902 | AUC 0.7086
2023-03-18 22:40:13,067 WARNING  [*] 22:40:13: Train Epoch: 2 [57600/60731 (95%)] | Loss: 0.554765 | Elapsed: 9.85s | FPR 0.0003 -> TPR 0.3182 & F1 0.4828 | AUC 0.7825
2023-03-18 22:40:17,620 WARNING  [*] Sat Mar 18 22:40:17 2023:    2    | Tr.loss: 0.555060 | Elapsed:   63.93  s | FPR 0.0003 -> TPR: 0.01 & F1: 0.02 | AUC: 0.6524
2023-03-18 22:40:17,620 WARNING  [*] Started epoch: 3
2023-03-18 22:40:17,757 WARNING  [*] 22:40:17: Train Epoch: 3 [  0  /60731 (0 %)] | Loss: 0.519060 | Elapsed: 0.12s | FPR 0.0003 -> TPR 0.1429 & F1 0.2500 | AUC 0.7346
2023-03-18 22:40:27,620 WARNING  [*] 22:40:27: Train Epoch: 3 [9600 /60731 (16%)] | Loss: 0.632411 | Elapsed: 9.85s | FPR 0.0003 -> TPR 0.2308 & F1 0.3750 | AUC 0.5785
2023-03-18 22:40:37,522 WARNING  [*] 22:40:37: Train Epoch: 3 [19200/60731 (32%)] | Loss: 0.511612 | Elapsed: 9.89s | FPR 0.0003 -> TPR 0.2055 & F1 0.3409 | AUC 0.6497
2023-03-18 22:40:47,386 WARNING  [*] 22:40:47: Train Epoch: 3 [28800/60731 (47%)] | Loss: 0.492133 | Elapsed: 9.85s | FPR 0.0003 -> TPR 0.3088 & F1 0.4719 | AUC 0.7606
2023-03-18 22:40:57,242 WARNING  [*] 22:40:57: Train Epoch: 3 [38400/60731 (63%)] | Loss: 0.495031 | Elapsed: 9.86s | FPR 0.0003 -> TPR 0.2754 & F1 0.4318 | AUC 0.6732
2023-03-18 22:41:07,177 WARNING  [*] 22:41:07: Train Epoch: 3 [48000/60731 (79%)] | Loss: 0.537130 | Elapsed: 9.92s | FPR 0.0003 -> TPR 0.0984 & F1 0.1791 | AUC 0.6841
2023-03-18 22:41:17,073 WARNING  [*] 22:41:17: Train Epoch: 3 [57600/60731 (95%)] | Loss: 0.475067 | Elapsed: 9.88s | FPR 0.0003 -> TPR 0.2078 & F1 0.3441 | AUC 0.6570
2023-03-18 22:41:21,628 WARNING  [*] Sat Mar 18 22:41:21 2023:    3    | Tr.loss: 0.498591 | Elapsed:   64.01  s | FPR 0.0003 -> TPR: 0.02 & F1: 0.04 | AUC: 0.7111
2023-03-18 22:41:21,628 WARNING  [*] Started epoch: 4
2023-03-18 22:41:21,745 WARNING  [*] 22:41:21: Train Epoch: 4 [  0  /60731 (0 %)] | Loss: 0.400168 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.2740 & F1 0.4301 | AUC 0.7630
2023-03-18 22:41:31,714 WARNING  [*] 22:41:31: Train Epoch: 4 [9600 /60731 (16%)] | Loss: 0.388937 | Elapsed: 9.95s | FPR 0.0003 -> TPR 0.3333 & F1 0.5000 | AUC 0.7925
2023-03-18 22:41:41,654 WARNING  [*] 22:41:41: Train Epoch: 4 [19200/60731 (32%)] | Loss: 0.452479 | Elapsed: 9.92s | FPR 0.0003 -> TPR 0.2055 & F1 0.3409 | AUC 0.7993
2023-03-18 22:41:51,510 WARNING  [*] 22:41:51: Train Epoch: 4 [28800/60731 (47%)] | Loss: 0.484253 | Elapsed: 9.86s | FPR 0.0003 -> TPR 0.1912 & F1 0.3210 | AUC 0.7206
2023-03-18 22:42:01,376 WARNING  [*] 22:42:01: Train Epoch: 4 [38400/60731 (63%)] | Loss: 0.593454 | Elapsed: 9.87s | FPR 0.0003 -> TPR 0.1449 & F1 0.2532 | AUC 0.5400
2023-03-18 22:42:11,255 WARNING  [*] 22:42:11: Train Epoch: 4 [48000/60731 (79%)] | Loss: 0.516184 | Elapsed: 9.87s | FPR 0.0003 -> TPR 0.1940 & F1 0.3250 | AUC 0.6983
2023-03-18 22:42:21,116 WARNING  [*] 22:42:21: Train Epoch: 4 [57600/60731 (95%)] | Loss: 0.435495 | Elapsed: 9.86s | FPR 0.0003 -> TPR 0.2676 & F1 0.4222 | AUC 0.7676
2023-03-18 22:42:25,650 WARNING  [*] Sat Mar 18 22:42:25 2023:    4    | Tr.loss: 0.485368 | Elapsed:   64.02  s | FPR 0.0003 -> TPR: 0.05 & F1: 0.09 | AUC: 0.7160
2023-03-18 22:42:25,650 WARNING  [*] Started epoch: 5
2023-03-18 22:42:25,781 WARNING  [*] 22:42:25: Train Epoch: 5 [  0  /60731 (0 %)] | Loss: 0.538623 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.1061 & F1 0.1918 | AUC 0.6192
2023-03-18 22:42:35,666 WARNING  [*] 22:42:35: Train Epoch: 5 [9600 /60731 (16%)] | Loss: 0.444243 | Elapsed: 9.87s | FPR 0.0003 -> TPR 0.2319 & F1 0.3765 | AUC 0.7733
2023-03-18 22:42:45,523 WARNING  [*] 22:42:45: Train Epoch: 5 [19200/60731 (32%)] | Loss: 0.537344 | Elapsed: 9.86s | FPR 0.0003 -> TPR 0.0571 & F1 0.1081 | AUC 0.6819
2023-03-18 22:42:55,391 WARNING  [*] 22:42:55: Train Epoch: 5 [28800/60731 (47%)] | Loss: 0.559212 | Elapsed: 9.87s | FPR 0.0003 -> TPR 0.0882 & F1 0.1622 | AUC 0.5993
2023-03-18 22:43:05,317 WARNING  [*] 22:43:05: Train Epoch: 5 [38400/60731 (63%)] | Loss: 0.439499 | Elapsed: 9.91s | FPR 0.0003 -> TPR 0.2466 & F1 0.3956 | AUC 0.7788
2023-03-18 22:43:09,723 WARNING  [!] Time budget exceeded, training stopped.
2023-03-18 22:43:09,756 WARNING  [!] Sat Mar 18 22:43:09 2023: Dumped results:
                model       : 1679175488-model.torch
		train time  : 1679175488-trainTime.npy
		train losses: 1679175488-trainLosses.npy
		train AUC   : 1679175488-auc.npy
		train F1s   : 1679175488-trainF1s.npy
		train TPRs  : 1679175488-trainTPRs.npy
2023-03-18 22:43:09,805 WARNING  [!] Evaluating model on training set...
2023-03-18 22:43:26,013 WARNING  [!] This fold metrics on training set:
2023-03-18 22:43:26,031 WARNING 	AUC: 0.7200
2023-03-18 22:43:26,040 WARNING 	FPR: 0.0001 | TPR: 0.1200 | F1: 0.2142
2023-03-18 22:43:26,062 WARNING 	FPR: 0.0003 | TPR: 0.1399 | F1: 0.2454
2023-03-18 22:43:26,067 WARNING 	FPR: 0.001 | TPR: 0.1846 | F1: 0.3115
2023-03-18 22:43:26,095 WARNING 	FPR: 0.003 | TPR: 0.2023 | F1: 0.3363
2023-03-18 22:43:26,099 WARNING 	FPR: 0.01 | TPR: 0.2389 | F1: 0.3845
2023-03-18 22:43:26,129 WARNING 	FPR: 0.03 | TPR: 0.2541 | F1: 0.4020
2023-03-18 22:43:26,132 WARNING 	FPR: 0.1 | TPR: 0.3318 | F1: 0.4843
2023-03-18 22:43:26,132 WARNING  [!] Evaluating model on validation set...
2023-03-18 22:43:34,259 WARNING  [!] This fold metrics on validation set:
2023-03-18 22:43:34,268 WARNING 	AUC: 0.7163
2023-03-18 22:43:34,277 WARNING 	FPR: 0.0001 | TPR: 0.0351 | F1: 0.0678
2023-03-18 22:43:34,281 WARNING 	FPR: 0.0003 | TPR: 0.1217 | F1: 0.2170
2023-03-18 22:43:34,288 WARNING 	FPR: 0.001 | TPR: 0.1625 | F1: 0.2795
2023-03-18 22:43:34,302 WARNING 	FPR: 0.003 | TPR: 0.1958 | F1: 0.3272
2023-03-18 22:43:34,310 WARNING 	FPR: 0.01 | TPR: 0.2338 | F1: 0.3779
2023-03-18 22:43:34,314 WARNING 	FPR: 0.03 | TPR: 0.2529 | F1: 0.4006
2023-03-18 22:43:34,321 WARNING 	FPR: 0.1 | TPR: 0.3299 | F1: 0.4824
2023-03-18 22:43:34,480 WARNING  [3/3] Train set size: 60731, Validation set size: 30365
2023-03-18 22:43:35,405 WARNING  [!] Saved dataset splits to dataset_splits_1679175814.npz
2023-03-18 22:43:35,458 WARNING  [!] Iniatialized TransformerEncoderChunks. Total trainable parameters: 2.5950e6
2023-03-18 22:43:35,458 WARNING  [*] Training time budget set: 5.0 min
2023-03-18 22:43:35,494 WARNING  [*] Started epoch: 1
2023-03-18 22:43:35,654 WARNING  [*] 22:43:35: Train Epoch: 1 [  0  /60731 (0 %)] | Loss: 4.307667 | Elapsed: 0.15s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.3887
2023-03-18 22:43:45,549 WARNING  [*] 22:43:45: Train Epoch: 1 [9600 /60731 (16%)] | Loss: 0.626946 | Elapsed: 9.89s | FPR 0.0003 -> TPR 0.0145 & F1 0.0286 | AUC 0.5839
2023-03-18 22:43:55,465 WARNING  [*] 22:43:55: Train Epoch: 1 [19200/60731 (32%)] | Loss: 0.684150 | Elapsed: 9.90s | FPR 0.0003 -> TPR 0.0462 & F1 0.0882 | AUC 0.5086
2023-03-18 22:44:05,388 WARNING  [*] 22:44:05: Train Epoch: 1 [28800/60731 (47%)] | Loss: 0.536382 | Elapsed: 9.91s | FPR 0.0003 -> TPR 0.0506 & F1 0.0964 | AUC 0.5353
2023-03-18 22:44:15,297 WARNING  [*] 22:44:15: Train Epoch: 1 [38400/60731 (63%)] | Loss: 0.568490 | Elapsed: 9.89s | FPR 0.0003 -> TPR 0.1053 & F1 0.1905 | AUC 0.5340
2023-03-18 22:44:25,200 WARNING  [*] 22:44:25: Train Epoch: 1 [48000/60731 (79%)] | Loss: 0.640304 | Elapsed: 9.90s | FPR 0.0003 -> TPR 0.0448 & F1 0.0857 | AUC 0.5568
2023-03-18 22:44:35,221 WARNING  [*] 22:44:35: Train Epoch: 1 [57600/60731 (95%)] | Loss: 0.666839 | Elapsed: 10.02s | FPR 0.0003 -> TPR 0.0000 & F1 0.0000 | AUC 0.4215
2023-03-18 22:44:39,731 WARNING  [*] Sat Mar 18 22:44:39 2023:    1    | Tr.loss: 0.626017 | Elapsed:   64.24  s | FPR 0.0003 -> TPR: 0.00 & F1: 0.00 | AUC: 0.5081
2023-03-18 22:44:39,731 WARNING  [*] Started epoch: 2
2023-03-18 22:44:39,850 WARNING  [*] 22:44:39: Train Epoch: 2 [  0  /60731 (0 %)] | Loss: 0.560727 | Elapsed: 0.12s | FPR 0.0003 -> TPR 0.0278 & F1 0.0541 | AUC 0.5440
2023-03-18 22:44:49,770 WARNING  [*] 22:44:49: Train Epoch: 2 [9600 /60731 (16%)] | Loss: 0.556425 | Elapsed: 9.90s | FPR 0.0003 -> TPR 0.0385 & F1 0.0741 | AUC 0.4441
2023-03-18 22:44:59,727 WARNING  [*] 22:44:59: Train Epoch: 2 [19200/60731 (32%)] | Loss: 0.555530 | Elapsed: 9.96s | FPR 0.0003 -> TPR 0.1867 & F1 0.3146 | AUC 0.6171
2023-03-18 22:45:09,648 WARNING  [*] 22:45:09: Train Epoch: 2 [28800/60731 (47%)] | Loss: 0.588983 | Elapsed: 9.92s | FPR 0.0003 -> TPR 0.0143 & F1 0.0282 | AUC 0.6643
2023-03-18 22:45:19,568 WARNING  [*] 22:45:19: Train Epoch: 2 [38400/60731 (63%)] | Loss: 0.563071 | Elapsed: 9.90s | FPR 0.0003 -> TPR 0.2254 & F1 0.3678 | AUC 0.6928
2023-03-18 22:45:29,490 WARNING  [*] 22:45:29: Train Epoch: 2 [48000/60731 (79%)] | Loss: 0.545816 | Elapsed: 9.91s | FPR 0.0003 -> TPR 0.2090 & F1 0.3457 | AUC 0.7802
2023-03-18 22:45:39,424 WARNING  [*] 22:45:39: Train Epoch: 2 [57600/60731 (95%)] | Loss: 0.485597 | Elapsed: 9.92s | FPR 0.0003 -> TPR 0.1169 & F1 0.2093 | AUC 0.7261
2023-03-18 22:45:43,988 WARNING  [*] Sat Mar 18 22:45:43 2023:    2    | Tr.loss: 0.565857 | Elapsed:   64.26  s | FPR 0.0003 -> TPR: 0.02 & F1: 0.05 | AUC: 0.6226
2023-03-18 22:45:43,988 WARNING  [*] Started epoch: 3
2023-03-18 22:45:44,111 WARNING  [*] 22:45:44: Train Epoch: 3 [  0  /60731 (0 %)] | Loss: 0.581380 | Elapsed: 0.11s | FPR 0.0003 -> TPR 0.2951 & F1 0.4557 | AUC 0.7293
2023-03-18 22:45:54,022 WARNING  [*] 22:45:54: Train Epoch: 3 [9600 /60731 (16%)] | Loss: 0.514581 | Elapsed: 9.89s | FPR 0.0003 -> TPR 0.1558 & F1 0.2697 | AUC 0.6293
2023-03-18 22:46:03,941 WARNING  [*] 22:46:03: Train Epoch: 3 [19200/60731 (32%)] | Loss: 0.518886 | Elapsed: 9.92s | FPR 0.0003 -> TPR 0.1972 & F1 0.3294 | AUC 0.7489
2023-03-18 22:46:13,863 WARNING  [*] 22:46:13: Train Epoch: 3 [28800/60731 (47%)] | Loss: 0.536370 | Elapsed: 9.92s | FPR 0.0003 -> TPR 0.2639 & F1 0.4176 | AUC 0.7068
2023-03-18 22:46:23,780 WARNING  [*] 22:46:23: Train Epoch: 3 [38400/60731 (63%)] | Loss: 0.533780 | Elapsed: 9.90s | FPR 0.0003 -> TPR 0.2432 & F1 0.3913 | AUC 0.6357
2023-03-18 22:46:33,767 WARNING  [*] 22:46:33: Train Epoch: 3 [48000/60731 (79%)] | Loss: 0.536135 | Elapsed: 9.97s | FPR 0.0003 -> TPR 0.1781 & F1 0.3023 | AUC 0.6743
2023-03-18 22:46:43,684 WARNING  [*] 22:46:43: Train Epoch: 3 [57600/60731 (95%)] | Loss: 0.513653 | Elapsed: 9.91s | FPR 0.0003 -> TPR 0.1528 & F1 0.2651 | AUC 0.7207
2023-03-18 22:46:48,273 WARNING  [*] Sat Mar 18 22:46:48 2023:    3    | Tr.loss: 0.523045 | Elapsed:   64.29  s | FPR 0.0003 -> TPR: 0.06 & F1: 0.11 | AUC: 0.7072
2023-03-18 22:46:48,273 WARNING  [*] Started epoch: 4
2023-03-18 22:46:48,393 WARNING  [*] 22:46:48: Train Epoch: 4 [  0  /60731 (0 %)] | Loss: 0.561317 | Elapsed: 0.10s | FPR 0.0003 -> TPR 0.2113 & F1 0.3488 | AUC 0.6155
2023-03-18 22:46:58,309 WARNING  [*] 22:46:58: Train Epoch: 4 [9600 /60731 (16%)] | Loss: 0.499167 | Elapsed: 9.90s | FPR 0.0003 -> TPR 0.2609 & F1 0.4138 | AUC 0.7027
2023-03-18 22:47:08,204 WARNING  [*] 22:47:08: Train Epoch: 4 [19200/60731 (32%)] | Loss: 0.455914 | Elapsed: 9.89s | FPR 0.0003 -> TPR 0.2125 & F1 0.3505 | AUC 0.6125
2023-03-18 22:47:18,120 WARNING  [*] 22:47:18: Train Epoch: 4 [28800/60731 (47%)] | Loss: 0.477537 | Elapsed: 9.92s | FPR 0.0003 -> TPR 0.1772 & F1 0.3011 | AUC 0.6658
2023-03-18 22:47:28,025 WARNING  [*] 22:47:28: Train Epoch: 4 [38400/60731 (63%)] | Loss: 0.578304 | Elapsed: 9.90s | FPR 0.0003 -> TPR 0.3077 & F1 0.4706 | AUC 0.6470
2023-03-18 22:47:37,974 WARNING  [*] 22:47:37: Train Epoch: 4 [48000/60731 (79%)] | Loss: 0.460424 | Elapsed: 9.95s | FPR 0.0003 -> TPR 0.1842 & F1 0.3111 | AUC 0.6774
2023-03-18 22:47:47,892 WARNING  [*] 22:47:47: Train Epoch: 4 [57600/60731 (95%)] | Loss: 0.489994 | Elapsed: 9.92s | FPR 0.0003 -> TPR 0.2143 & F1 0.3529 | AUC 0.7160
2023-03-18 22:47:52,452 WARNING  [*] Sat Mar 18 22:47:52 2023:    4    | Tr.loss: 0.489674 | Elapsed:   64.18  s | FPR 0.0003 -> TPR: 0.07 & F1: 0.13 | AUC: 0.7177
2023-03-18 22:47:52,452 WARNING  [*] Started epoch: 5
2023-03-18 22:47:52,587 WARNING  [*] 22:47:52: Train Epoch: 5 [  0  /60731 (0 %)] | Loss: 0.445839 | Elapsed: 0.12s | FPR 0.0003 -> TPR 0.3333 & F1 0.5000 | AUC 0.7957
2023-03-18 22:48:02,503 WARNING  [*] 22:48:02: Train Epoch: 5 [9600 /60731 (16%)] | Loss: 0.460034 | Elapsed: 9.92s | FPR 0.0003 -> TPR 0.2055 & F1 0.3409 | AUC 0.7524
2023-03-18 22:48:12,430 WARNING  [*] 22:48:12: Train Epoch: 5 [19200/60731 (32%)] | Loss: 0.452071 | Elapsed: 9.91s | FPR 0.0003 -> TPR 0.2568 & F1 0.4086 | AUC 0.7427
2023-03-18 22:48:22,346 WARNING  [*] 22:48:22: Train Epoch: 5 [28800/60731 (47%)] | Loss: 0.544899 | Elapsed: 9.90s | FPR 0.0003 -> TPR 0.2121 & F1 0.3500 | AUC 0.6823
2023-03-18 22:48:32,282 WARNING  [*] 22:48:32: Train Epoch: 5 [38400/60731 (63%)] | Loss: 0.490988 | Elapsed: 9.94s | FPR 0.0003 -> TPR 0.2381 & F1 0.3846 | AUC 0.7778
2023-03-18 22:48:35,520 WARNING  [!] Time budget exceeded, training stopped.
2023-03-18 22:48:35,542 WARNING  [!] Sat Mar 18 22:48:35 2023: Dumped results:
                model       : 1679175814-model.torch
		train time  : 1679175814-trainTime.npy
		train losses: 1679175814-trainLosses.npy
		train AUC   : 1679175814-auc.npy
		train F1s   : 1679175814-trainF1s.npy
		train TPRs  : 1679175814-trainTPRs.npy
2023-03-18 22:48:35,585 WARNING  [!] Evaluating model on training set...
2023-03-18 22:48:51,773 WARNING  [!] This fold metrics on training set:
2023-03-18 22:48:51,794 WARNING 	AUC: 0.7213
2023-03-18 22:48:51,806 WARNING 	FPR: 0.0001 | TPR: 0.0952 | F1: 0.1738
2023-03-18 22:48:51,811 WARNING 	FPR: 0.0003 | TPR: 0.1649 | F1: 0.2830
2023-03-18 22:48:51,841 WARNING 	FPR: 0.001 | TPR: 0.1797 | F1: 0.3046
2023-03-18 22:48:51,843 WARNING 	FPR: 0.003 | TPR: 0.1999 | F1: 0.3329
2023-03-18 22:48:51,872 WARNING 	FPR: 0.01 | TPR: 0.2282 | F1: 0.3705
2023-03-18 22:48:51,875 WARNING 	FPR: 0.03 | TPR: 0.2538 | F1: 0.4018
2023-03-18 22:48:51,903 WARNING 	FPR: 0.1 | TPR: 0.3306 | F1: 0.4834
2023-03-18 22:48:51,903 WARNING  [!] Evaluating model on validation set...
2023-03-18 22:48:59,988 WARNING  [!] This fold metrics on validation set:
2023-03-18 22:49:00,008 WARNING 	AUC: 0.7168
2023-03-18 22:49:00,017 WARNING 	FPR: 0.0001 | TPR: 0.0943 | F1: 0.1724
2023-03-18 22:49:00,023 WARNING 	FPR: 0.0003 | TPR: 0.1673 | F1: 0.2866
2023-03-18 22:49:00,031 WARNING 	FPR: 0.001 | TPR: 0.1772 | F1: 0.3009
2023-03-18 22:49:00,048 WARNING 	FPR: 0.003 | TPR: 0.1968 | F1: 0.3286
2023-03-18 22:49:00,057 WARNING 	FPR: 0.01 | TPR: 0.2253 | F1: 0.3666
2023-03-18 22:49:00,059 WARNING 	FPR: 0.03 | TPR: 0.2543 | F1: 0.4020
2023-03-18 22:49:00,067 WARNING 	FPR: 0.1 | TPR: 0.3308 | F1: 0.4831
2023-03-18 22:49:00,159 WARNING  [!] Metrics saved to out_fields_1679165454\cv_file_network_registry_limNone_r1763_t5\file_network_registry_metrics_validation.json
2023-03-18 22:49:00,167 WARNING  [!] Metrics saved to out_fields_1679165454\cv_file_network_registry_limNone_r1763_t5\file_network_registry_metrics_training.json
2023-03-18 22:49:00,167 WARNING  [!] Average epoch time: 0.03s | Mean values over 3 folds:
	AUC: 0.7203
	FPR: 0.0001 -- TPR: 0.0431 -- F1: 0.0800
	FPR: 0.0003 -- TPR: 0.1518 -- F1: 0.2629
	FPR:  0.001 -- TPR: 0.1707 -- F1: 0.2914
	FPR:  0.003 -- TPR: 0.1965 -- F1: 0.3281
	FPR:   0.01 -- TPR: 0.2343 -- F1: 0.3785
	FPR:   0.03 -- TPR: 0.2561 -- F1: 0.4045
	FPR:    0.1 -- TPR: 0.3339 -- F1: 0.4866

