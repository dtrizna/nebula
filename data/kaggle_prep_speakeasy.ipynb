{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting trainset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 76126/76126 [3:07:29<00:00,  6.77it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting testset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17407/17407 [16:59<00:00, 17.08it/s]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "trainset_dirty_raw = \"..\\data\\data_raw\\windows_emulation_trainset\"\n",
    "testset_dirty_raw = \"..\\data\\data_raw\\windows_emulation_testset\"\n",
    "\n",
    "trainset_clean_raw = \"..\\data\\data_raw\\windows_emulation_trainset_clean\"\n",
    "testset_clean_raw = \"..\\data\\data_raw\\windows_emulation_testset_clean\"\n",
    "os.makedirs(trainset_clean_raw, exist_ok=True)\n",
    "os.makedirs(testset_clean_raw, exist_ok=True)\n",
    "\n",
    "trainset_clean_files = \"..\\data\\data_filtered\\speakeasy_trainset_whitespace_10k\\speakeasy_yHashes.json\"\n",
    "testset_clean_files = \"..\\data\\data_filtered\\speakeasy_testset_whitespace_10k\\speakeasy_yHashes.json\"\n",
    "\n",
    "with open(trainset_clean_files, \"r\") as f:\n",
    "    trainset_clean_hashes = json.load(f)\n",
    "with open(testset_clean_files, \"r\") as f:\n",
    "    testset_clean_hashes = json.load(f)\n",
    "\n",
    "def get_filepath_from_hash(hhash, rootfolder=\".\"):\n",
    "    # search for file in subfolders\n",
    "    for root, dirs, files in os.walk(rootfolder):\n",
    "        for file in files:\n",
    "            if hhash in file:\n",
    "                return os.path.join(root, file), os.path.basename(root)\n",
    "    return None, None\n",
    "\n",
    "def copy_file_to_folder(filepath, folder):\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    filename = os.path.basename(filepath)\n",
    "    new_filepath = os.path.join(folder, filename)\n",
    "    with open(filepath, \"rb\") as f:\n",
    "        content = f.read()\n",
    "    with open(new_filepath, \"wb\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "print(\"Starting trainset\")\n",
    "for hhash in tqdm(trainset_clean_hashes):\n",
    "    filepath, folder = get_filepath_from_hash(hhash, trainset_dirty_raw)\n",
    "    if filepath is not None:\n",
    "        copy_file_to_folder(filepath, os.path.join(trainset_clean_raw, folder))\n",
    "    else:\n",
    "        print(f\"File not found: {hhash}\")\n",
    "\n",
    "print(\"Starting testset\")\n",
    "for hhash in tqdm(testset_clean_hashes):\n",
    "    filepath, folder = get_filepath_from_hash(hhash, testset_dirty_raw)\n",
    "    if filepath is not None:\n",
    "        copy_file_to_folder(filepath, os.path.join(testset_clean_raw, folder))\n",
    "    else:\n",
    "        print(f\"File not found: {hhash}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
