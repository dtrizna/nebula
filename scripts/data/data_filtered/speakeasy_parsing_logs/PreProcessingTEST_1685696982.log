06/02/2023 11:09:42 AM Initialized ...
06/02/2023 11:09:42 AM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_backdoor...
06/02/2023 11:09:44 AM Finished... Took: 2.28s
06/02/2023 11:09:44 AM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_clean...
06/02/2023 11:09:46 AM Finished... Took: 1.29s
06/02/2023 11:09:46 AM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_coinminer...
06/02/2023 11:09:48 AM Finished... Took: 2.08s
06/02/2023 11:09:48 AM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_dropper...
06/02/2023 11:09:49 AM Finished... Took: 1.38s
06/02/2023 11:09:49 AM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_keylogger...
06/02/2023 11:09:51 AM Finished... Took: 1.81s
06/02/2023 11:09:51 AM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_ransomware...
06/02/2023 11:09:53 AM Finished... Took: 1.79s
06/02/2023 11:09:53 AM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_rat...
06/02/2023 11:09:54 AM Finished... Took: 1.70s
06/02/2023 11:09:54 AM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_trojan...
06/02/2023 11:09:56 AM Finished... Took: 1.62s
06/02/2023 11:09:56 AM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_windows_syswow64...
06/02/2023 11:09:57 AM Finished... Took: 1.07s
06/02/2023 11:09:57 AM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_backdoor...
06/02/2023 11:10:00 AM Finished... Took: 2.51s
06/02/2023 11:10:00 AM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_clean...
06/02/2023 11:10:01 AM Finished... Took: 1.47s
06/02/2023 11:10:01 AM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_coinminer...
06/02/2023 11:10:03 AM Finished... Took: 2.18s
06/02/2023 11:10:03 AM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_dropper...
06/02/2023 11:10:05 AM Finished... Took: 1.42s
06/02/2023 11:10:05 AM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_keylogger...
06/02/2023 11:10:06 AM Finished... Took: 1.41s
06/02/2023 11:10:06 AM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_ransomware...
06/02/2023 11:10:13 AM Finished... Took: 7.34s
06/02/2023 11:10:13 AM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_rat...
06/02/2023 11:10:15 AM Finished... Took: 1.85s
06/02/2023 11:10:15 AM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_trojan...
06/02/2023 11:10:17 AM Finished... Took: 1.38s
06/02/2023 11:10:17 AM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_windows_syswow64...
06/02/2023 11:10:17 AM Finished... Took: 0.64s
06/02/2023 11:10:17 AM  [!] Initialized tokenizer without pre-trained model.
	You need to train tokenizer with .train() or specify 'model_path=' during initialization!
06/02/2023 11:10:17 AM Training tokenizer with vocab size: 50000...
06/02/2023 11:10:17 AM  [*] Data preparation for SentencePiece tokenizer...
06/02/2023 11:10:19 AM  [*] Saving to disk...
06/02/2023 11:10:19 AM  [!] Training tokenizer with command: --input=C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_filtered\speakeasy_trainsetTEST\speakeasy_VocabSize_50000_tokenizer_trainset_1685697019.txt --model_prefix=C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_filtered\speakeasy_trainsetTEST\speakeasy_VocabSize_50000_tokenizer --vocab_size=50000 --model_type=bpe --split_by_number=False --max_sentence_length=4192 --max_sentencepiece_length=64
06/02/2023 11:10:31 AM  [!] Loaded vocab with size 50001 from C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_filtered\speakeasy_trainsetTEST\speakeasy_VocabSize_50000_tokenizer.vocab
06/02/2023 11:10:31 AM Encoding...
06/02/2023 11:10:53 AM Padding with maxLen=512...
06/02/2023 11:10:53 AM Saving files with prefix: speakeasy_VocabSize_50000_maxLen_512
