06/02/2023 01:30:09 PM Initialized ...
06/02/2023 01:30:09 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_backdoor...
06/02/2023 01:30:11 PM Finished... Took: 1.99s
06/02/2023 01:30:11 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_clean...
06/02/2023 01:30:12 PM Finished... Took: 0.97s
06/02/2023 01:30:12 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_coinminer...
06/02/2023 01:30:13 PM Finished... Took: 1.00s
06/02/2023 01:30:13 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_dropper...
06/02/2023 01:30:14 PM Finished... Took: 0.54s
06/02/2023 01:30:14 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_keylogger...
06/02/2023 01:30:15 PM Finished... Took: 0.96s
06/02/2023 01:30:15 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_ransomware...
06/02/2023 01:30:15 PM Finished... Took: 0.49s
06/02/2023 01:30:15 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_rat...
06/02/2023 01:30:16 PM Finished... Took: 0.81s
06/02/2023 01:30:16 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_trojan...
06/02/2023 01:30:16 PM Finished... Took: 0.57s
06/02/2023 01:30:16 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_windows_syswow64...
06/02/2023 01:30:16 PM Finished... Took: 0.12s
06/02/2023 01:30:16 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_backdoor...
06/02/2023 01:30:17 PM Finished... Took: 0.56s
06/02/2023 01:30:17 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_clean...
06/02/2023 01:30:17 PM Finished... Took: 0.26s
06/02/2023 01:30:17 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_coinminer...
06/02/2023 01:30:18 PM Finished... Took: 0.59s
06/02/2023 01:30:18 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_dropper...
06/02/2023 01:30:18 PM Finished... Took: 0.28s
06/02/2023 01:30:18 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_keylogger...
06/02/2023 01:30:18 PM Finished... Took: 0.19s
06/02/2023 01:30:18 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_ransomware...
06/02/2023 01:30:20 PM Finished... Took: 1.49s
06/02/2023 01:30:20 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_rat...
06/02/2023 01:30:20 PM Finished... Took: 0.50s
06/02/2023 01:30:20 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_trojan...
06/02/2023 01:30:21 PM Finished... Took: 0.24s
06/02/2023 01:30:21 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_windows_syswow64...
06/02/2023 01:30:21 PM Finished... Took: 0.13s
06/02/2023 01:30:21 PM  [!] Initialized tokenizer without pre-trained model.
	You need to train tokenizer with .train() or specify 'model_path=' during initialization!
06/02/2023 01:30:21 PM Training tokenizer with vocab size: 5000...
06/02/2023 01:30:21 PM  [*] Data preparation for SentencePiece tokenizer...
06/02/2023 01:30:21 PM  [*] Saving to disk...
06/02/2023 01:30:21 PM  [!] Training tokenizer with command: --input=C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_filtered\speakeasy_trainsetTEST\speakeasy_vocab_size_5000_tokenizer_trainset_1685705421.txt --model_prefix=C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_filtered\speakeasy_trainsetTEST\speakeasy_vocab_size_5000_tokenizer --vocab_size=5000 --model_type=bpe --split_by_number=False --max_sentence_length=4192 --max_sentencepiece_length=64
06/02/2023 01:30:22 PM  [!] Loaded vocab with size 5001 from C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_filtered\speakeasy_trainsetTEST\speakeasy_vocab_size_5000_tokenizer_vocab.json
06/02/2023 01:30:22 PM Encoding...
