06/02/2023 01:24:58 PM Initialized ...
06/02/2023 01:24:58 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_backdoor...
06/02/2023 01:24:59 PM Finished... Took: 1.52s
06/02/2023 01:24:59 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_clean...
06/02/2023 01:25:01 PM Finished... Took: 1.98s
06/02/2023 01:25:01 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_coinminer...
06/02/2023 01:25:02 PM Finished... Took: 1.09s
06/02/2023 01:25:02 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_dropper...
06/02/2023 01:25:03 PM Finished... Took: 0.90s
06/02/2023 01:25:03 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_keylogger...
06/02/2023 01:25:04 PM Finished... Took: 0.98s
06/02/2023 01:25:04 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_ransomware...
06/02/2023 01:25:05 PM Finished... Took: 0.99s
06/02/2023 01:25:05 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_rat...
06/02/2023 01:25:06 PM Finished... Took: 0.92s
06/02/2023 01:25:06 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_trojan...
06/02/2023 01:25:07 PM Finished... Took: 1.03s
06/02/2023 01:25:07 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_windows_syswow64...
06/02/2023 01:25:07 PM Finished... Took: 0.21s
06/02/2023 01:25:07 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_backdoor...
06/02/2023 01:25:08 PM Finished... Took: 1.07s
06/02/2023 01:25:08 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_clean...
06/02/2023 01:25:09 PM Finished... Took: 0.88s
06/02/2023 01:25:09 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_coinminer...
06/02/2023 01:25:10 PM Finished... Took: 1.04s
06/02/2023 01:25:10 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_dropper...
06/02/2023 01:25:11 PM Finished... Took: 0.46s
06/02/2023 01:25:11 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_keylogger...
06/02/2023 01:25:11 PM Finished... Took: 0.40s
06/02/2023 01:25:11 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_ransomware...
06/02/2023 01:25:14 PM Finished... Took: 2.52s
06/02/2023 01:25:14 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_rat...
06/02/2023 01:25:15 PM Finished... Took: 0.87s
06/02/2023 01:25:15 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_trojan...
06/02/2023 01:25:15 PM Finished... Took: 0.60s
06/02/2023 01:25:15 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_windows_syswow64...
06/02/2023 01:25:15 PM Finished... Took: 0.22s
06/02/2023 01:25:15 PM  [!] Initialized tokenizer without pre-trained model.
	You need to train tokenizer with .train() or specify 'model_path=' during initialization!
06/02/2023 01:25:15 PM Training tokenizer with vocab size: 50000...
06/02/2023 01:25:15 PM  [*] Data preparation for SentencePiece tokenizer...
06/02/2023 01:25:16 PM  [*] Saving to disk...
06/02/2023 01:25:16 PM  [!] Training tokenizer with command: --input=C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_filtered\speakeasy_trainsetTEST\speakeasy_vocab_size_50000_tokenizer_trainset_1685705116.txt --model_prefix=C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_filtered\speakeasy_trainsetTEST\speakeasy_vocab_size_50000_tokenizer --vocab_size=50000 --model_type=bpe --split_by_number=False --max_sentence_length=4192 --max_sentencepiece_length=64
