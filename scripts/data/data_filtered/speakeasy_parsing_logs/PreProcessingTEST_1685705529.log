06/02/2023 01:32:09 PM Initialized ...
06/02/2023 01:32:09 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_backdoor...
06/02/2023 01:32:09 PM Finished... Took: 0.36s
06/02/2023 01:32:09 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_clean...
06/02/2023 01:32:10 PM Finished... Took: 0.28s
06/02/2023 01:32:10 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_coinminer...
06/02/2023 01:32:10 PM Finished... Took: 0.16s
06/02/2023 01:32:10 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_dropper...
06/02/2023 01:32:10 PM Finished... Took: 0.16s
06/02/2023 01:32:10 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_keylogger...
06/02/2023 01:32:10 PM Finished... Took: 0.15s
06/02/2023 01:32:10 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_ransomware...
06/02/2023 01:32:10 PM Finished... Took: 0.14s
06/02/2023 01:32:10 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_rat...
06/02/2023 01:32:10 PM Finished... Took: 0.12s
06/02/2023 01:32:10 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_trojan...
06/02/2023 01:32:11 PM Finished... Took: 0.10s
06/02/2023 01:32:11 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_windows_syswow64...
06/02/2023 01:32:11 PM Finished... Took: 0.09s
06/02/2023 01:32:11 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_backdoor...
06/02/2023 01:32:11 PM Finished... Took: 0.16s
06/02/2023 01:32:11 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_clean...
06/02/2023 01:32:11 PM Finished... Took: 0.13s
06/02/2023 01:32:11 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_coinminer...
06/02/2023 01:32:11 PM Finished... Took: 0.20s
06/02/2023 01:32:11 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_dropper...
06/02/2023 01:32:11 PM Finished... Took: 0.10s
06/02/2023 01:32:11 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_keylogger...
06/02/2023 01:32:11 PM Finished... Took: 0.09s
06/02/2023 01:32:11 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_ransomware...
06/02/2023 01:32:12 PM Finished... Took: 0.73s
06/02/2023 01:32:12 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_rat...
06/02/2023 01:32:12 PM Finished... Took: 0.15s
06/02/2023 01:32:12 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_trojan...
06/02/2023 01:32:12 PM Finished... Took: 0.12s
06/02/2023 01:32:12 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_windows_syswow64...
06/02/2023 01:32:12 PM Finished... Took: 0.07s
06/02/2023 01:32:12 PM  [!] Initialized tokenizer without pre-trained model.
	You need to train tokenizer with .train() or specify 'model_path=' during initialization!
06/02/2023 01:32:12 PM Training tokenizer with vocab size: 5000...
06/02/2023 01:32:12 PM  [*] Data preparation for SentencePiece tokenizer...
06/02/2023 01:32:13 PM  [*] Saving to disk...
06/02/2023 01:32:13 PM  [!] Training tokenizer with command: --input=C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_filtered\speakeasy_trainsetTEST\speakeasy_vocab_size_5000_tokenizer_trainset_1685705533.txt --model_prefix=C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_filtered\speakeasy_trainsetTEST\speakeasy_vocab_size_5000_tokenizer --vocab_size=5000 --model_type=bpe --split_by_number=False --max_sentence_length=4192 --max_sentencepiece_length=64
06/02/2023 01:32:14 PM  [!] Loaded vocab with size 5001 from C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_filtered\speakeasy_trainsetTEST\speakeasy_vocab_size_5000_tokenizer_vocab.json
06/02/2023 01:32:14 PM Encoding...
06/02/2023 01:32:14 PM Padding with maxLen=512...
06/02/2023 01:32:14 PM Saving files with prefix: speakeasy_vocab_size_5000_maxLen_512
