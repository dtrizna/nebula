06/02/2023 01:25:43 PM Initialized ...
06/02/2023 01:25:43 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_backdoor...
06/02/2023 01:25:45 PM Finished... Took: 1.23s
06/02/2023 01:25:45 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_clean...
06/02/2023 01:25:45 PM Finished... Took: 0.71s
06/02/2023 01:25:45 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_coinminer...
06/02/2023 01:25:46 PM Finished... Took: 0.87s
06/02/2023 01:25:46 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_dropper...
06/02/2023 01:25:47 PM Finished... Took: 0.43s
06/02/2023 01:25:47 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_keylogger...
06/02/2023 01:25:47 PM Finished... Took: 0.77s
06/02/2023 01:25:47 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_ransomware...
06/02/2023 01:25:48 PM Finished... Took: 0.62s
06/02/2023 01:25:48 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_rat...
06/02/2023 01:25:49 PM Finished... Took: 1.07s
06/02/2023 01:25:49 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_trojan...
06/02/2023 01:25:50 PM Finished... Took: 0.63s
06/02/2023 01:25:50 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_trainset\report_windows_syswow64...
06/02/2023 01:25:50 PM Finished... Took: 0.15s
06/02/2023 01:25:50 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_backdoor...
06/02/2023 01:25:51 PM Finished... Took: 1.23s
06/02/2023 01:25:51 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_clean...
06/02/2023 01:25:52 PM Finished... Took: 0.56s
06/02/2023 01:25:52 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_coinminer...
06/02/2023 01:25:53 PM Finished... Took: 1.30s
06/02/2023 01:25:53 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_dropper...
06/02/2023 01:25:54 PM Finished... Took: 0.51s
06/02/2023 01:25:54 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_keylogger...
06/02/2023 01:25:54 PM Finished... Took: 0.43s
06/02/2023 01:25:54 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_ransomware...
06/02/2023 01:25:57 PM Finished... Took: 3.12s
06/02/2023 01:25:57 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_rat...
06/02/2023 01:25:58 PM Finished... Took: 0.73s
06/02/2023 01:25:58 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_trojan...
06/02/2023 01:25:58 PM Finished... Took: 0.33s
06/02/2023 01:25:58 PM Filtering and normalizing C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_raw\windows_emulation_testset\report_windows_syswow64...
06/02/2023 01:25:58 PM Finished... Took: 0.20s
06/02/2023 01:25:58 PM  [!] Initialized tokenizer without pre-trained model.
	You need to train tokenizer with .train() or specify 'model_path=' during initialization!
06/02/2023 01:25:58 PM Training tokenizer with vocab size: 5000...
06/02/2023 01:25:58 PM  [*] Data preparation for SentencePiece tokenizer...
06/02/2023 01:25:59 PM  [*] Saving to disk...
06/02/2023 01:25:59 PM  [!] Training tokenizer with command: --input=C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_filtered\speakeasy_trainsetTEST\speakeasy_vocab_size_5000_tokenizer_trainset_1685705159.txt --model_prefix=C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_filtered\speakeasy_trainsetTEST\speakeasy_vocab_size_5000_tokenizer --vocab_size=5000 --model_type=bpe --split_by_number=False --max_sentence_length=4192 --max_sentencepiece_length=64
06/02/2023 01:26:00 PM  [!] Loaded vocab with size 5001 from C:\Users\dtrizna\Code\nebula\scripts\preprocessing\..\..\data\data_filtered\speakeasy_trainsetTEST\speakeasy_vocab_size_5000_tokenizer.vocab
06/02/2023 01:26:00 PM Encoding...
