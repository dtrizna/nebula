{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Black Hat USA Training (Early draft)\n",
    "\n",
    "## Lab 2: Feature Extraction from Byte Level Data with Neural Networks\n",
    "\n",
    "We will follow a \"Top-Down\" teaching methodology: We will start with higher level concepts familiar to our students in the cybersecurity domain, for instance, by introducing a specific library and demonstrating its use. Then, we delve deeper into the methods and parameters of these applications. Finally, we explore the underlying fundamentals, such as the specific PE format properties or mathematical concepts at the core of these ideas.\n",
    "\n",
    "**NOTE: This is a raw draft that will be populated with more material (especially visual) and explanations, especially, facilitating AI/ML intuition and more gradual familiriaztion with concepts.**\n",
    "\n",
    "Contents:\n",
    "- Downloading AsyncRAT Sample\n",
    "- Pre-Trained MalConv Model\n",
    "- PyTorch Introduction\n",
    "- PE File Path through Neural Network:\n",
    "  - Embeddings\n",
    "  - Convolutional Neural Network\n",
    "\n",
    "### Downloading AsyncRAT Sample\n",
    "\n",
    "We will use the same sample as in Lab 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# force reimport of lab_helpers\n",
    "import sys\n",
    "if 'lab_helpers' in sys.modules:\n",
    "    del sys.modules['lab_helpers']\n",
    "\n",
    "from lab_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'MZ\\x90\\x00\\x03\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\xff\\xff\\x00\\x00\\xb8\\x00\\x00\\x00'\n"
     ]
    }
   ],
   "source": [
    "# NOTE: for some reason download from vx-underground is denied by the server \n",
    "# works from browser, but not if using requests.get, user-agent browser mimic does not help\n",
    "vx_link = \"https://samples.vx-underground.org/Samples/Families/AsyncRAT/5e3588e8ddebd61c2bd6dab4b87f601bd6a4857b33eb281cb5059c29cfe62b80.7z\"\n",
    "\n",
    "# NOTE: go to https://vx-underground.org/Samples/Families/AsyncRAT/ and download the sample manually\n",
    "local_path = \"./5e3588e8ddebd61c2bd6dab4b87f601bd6a4857b33eb281cb5059c29cfe62b80.7z\"\n",
    "async_rat_bytez = get_encrypted_archive(local_path, password=\"infected\")\n",
    "print(async_rat_bytez[0:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Trained MalConv Model\n",
    "\n",
    "MalConv is a binary classifier model that outputs a probability of the sample being malicious, proposed by group of researchers in this [paper](https://arxiv.org/abs/1710.09435). Under the hood it is a convolutional neural network (CNN) to extract features from the byte level of the malware sample. Schematic view of the model is as follows:\n",
    "\n",
    "<img src=\"./img/malconv.png\" width=\"600\">\n",
    "\n",
    "Let's download the pre-trained model and verify predictions on the AsyncRAT sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Downloaded MalConv weights | Size: 24.79 MB\n"
     ]
    }
   ],
   "source": [
    "malconv_weights_link = \"https://github.com/dtrizna/quo.vadis/raw/main/modules/sota/malconv/parameters/malconv.checkpoint\"\n",
    "malconv_weights = requests.get(malconv_weights_link).content\n",
    "print(f\"[+] Downloaded MalConv weights | Size: {len(malconv_weights) / 1024 / 1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] MalConv probability for Async RAT sample being malware: 63.90%\n"
     ]
    }
   ],
   "source": [
    "from lab_helpers import MalConvModel\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "malconv_model = MalConvModel()\n",
    "malconv_model.load_state(malconv_weights)\n",
    "\n",
    "score = malconv_model.get_score(async_rat_bytez)\n",
    "print(f\"[+] MalConv probability for Async RAT sample being malware: {score*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MalConv is neural network, and to understand how it works under the hood, we need to grasp basics of PyTorch.\n",
    "\n",
    "## PyTorch Introduction\n",
    "\n",
    "PyTorch is a Python library for implementing Deep Learning models. Deep Learning is a subfield of Machine Learning that uses **Neural Networks** to learn complex patterns in data. \n",
    "\n",
    "<img src=\"./img/ai_ml_dl.png\" width=\"400\">\n",
    "\n",
    "During last years PyTorch became a de-facto standard for Deep Learning research, substituting the previous leader TensorFlow. PyTorch is a very flexible library that allows to implement complex models with a few lines of code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors\n",
    "\n",
    "Any deep learning framework operate with tensors, which are multi-dimensional arrays. In PyTorch, tensors are the main data structure. They are similar to NumPy arrays, but with additional features that make them suitable for deep learning:\n",
    "\n",
    "<img src=\"./img/tensors.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 1-D tensor (aka vector)\n",
    "tensor_a = torch.Tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "print(tensor_a.shape)\n",
    "tensor_a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2-D tensor (aka matrix)\n",
    "tensor_b = tensor_a.reshape(3, 3)\n",
    "print(tensor_b.shape)\n",
    "tensor_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 2., 3.],\n",
       "         [4., 5., 6.],\n",
       "         [7., 8., 9.]],\n",
       "\n",
       "        [[1., 2., 3.],\n",
       "         [4., 5., 6.],\n",
       "         [7., 8., 9.]],\n",
       "\n",
       "        [[1., 2., 3.],\n",
       "         [4., 5., 6.],\n",
       "         [7., 8., 9.]]])"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_c = torch.vstack([tensor_a, tensor_a, tensor_a]).reshape(3, 3, 3)\n",
    "print(tensor_c.shape)\n",
    "tensor_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers\n",
    "\n",
    "#### Embeddings\n",
    "\n",
    "Now, let's see how we can use PyTorch to extract features from the byte level of the malware sample. First, raw MZ file bytes are converted to an integer array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 77,  90, 144,   0,   3], dtype=torch.uint8)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "FIRST_N_BYTES = 5\n",
    "torch.tensor( np.frombuffer(async_rat_bytez, dtype=np.uint8)[0:FIRST_N_BYTES].copy() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can confirm that the first bytes of the file are indeed the MZ header:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'MZ\\x90\\x00\\x03'"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bytes([77, 90, 144, 0, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the array passes through and **Embedding** layer. Embeddings are basically a lookup table that maps each byte to a vector representation, learned during the training process. Important property of embedded vectors is that after training similar inputs are mapped to similar locations in the embedded vectorspace, as depicted in the following figure which displays **3-dimensional embeddings**:\n",
    "\n",
    "<img src=\"./img/embedding_star_wars.gif\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MalConv too uses **embedding size of 8**, but it is common to use higher dimensionality in modern models, such as 256 or 512.\n",
    "\n",
    "Let's define an 8-dimensional embedding layer and pass the first 5 bytes of the AsyncRAT sample through it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# embedding that encodes each byte to 3 dimensions, 256 possible values\n",
    "nr_of_bytes = 256\n",
    "embedding_size = 8\n",
    "torch.manual_seed(0)\n",
    "example_embed = torch.nn.Embedding(nr_of_bytes, embedding_size)\n",
    "\n",
    "# get the embedding for the first 5 bytes of the Async RAT sample\n",
    "async_first_5_bytez = torch.tensor([77, 90, 144, 0, 3])\n",
    "async_first_5_bytez.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the embedded array each byte is expanded to a 8-dimensional vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 8])"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_embed(async_first_5_bytez).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7650, -0.4750, -0.4953, -0.1984,  2.2149, -0.1367, -1.0182,  0.1784],\n",
       "        [ 0.7049,  0.0305, -0.8542,  0.5388, -0.5265, -1.3320,  1.5451,  0.4086],\n",
       "        [ 0.4047, -0.6549,  0.0521,  0.3401, -0.2124,  1.5629, -0.9072, -1.5662],\n",
       "        [-1.1258, -1.1524, -0.2506, -0.4339,  0.8487,  0.6920, -0.3160, -2.1152],\n",
       "        [ 0.7502, -0.5855, -0.1734,  0.1835,  1.3894,  1.5863,  0.9463, -0.8437]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_embed(async_first_5_bytez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First byte: 77\n",
      "First byte embedding: tensor([-0.7650, -0.4750, -0.4953, -0.1984,  2.2149, -0.1367, -1.0182,  0.1784])\n"
     ]
    }
   ],
   "source": [
    "first_byte = async_first_5_bytez[0]\n",
    "with torch.no_grad():\n",
    "    first_byte_embed = example_embed(async_first_5_bytez)[0]\n",
    "\n",
    "print(f\"First byte: {first_byte}\")\n",
    "print(f\"First byte embedding: {first_byte_embed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea should be clear by now. Now, we need more representative information size -- take first 200000 bytes of the AsyncRAT sample and pass it through the embedding layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 200000])"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "async_tensor = torch.tensor(np.frombuffer(async_rat_bytez, dtype=np.uint8)[np.newaxis,:].copy())[:, :200000]\n",
    "async_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 200000, 8])"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded = example_embed(async_tensor.long())\n",
    "embedded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional Layer\n",
    "\n",
    "The output of the embedding layer is passed to a 1D convolutional layer, that take a raw byte sequence and extracts features from the byte sequence by applying a filter to a window of bytes at a time.\n",
    "\n",
    "1D convolutional example below depicts input with **embedding size** of **3**, and convolution having **kernel size** is **3** with **stride** of **1**:\n",
    "\n",
    "<img src=\"./img/conv_1D_time.gif\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to transpose the array to match the input shape of the convolutional layer, which expects the input dimensions to be:\n",
    "\n",
    "`(batch_size, embedding_size, sequence_length)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 200000])"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# switch the 1st and 2nd dimensions\n",
    "embedded_prep = torch.transpose(embedded, 2, 1)\n",
    "embedded_prep.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MalConv uses 1D convolutional layer with a **kernel size of 512**, applies 256 filters (number of independent convolutional extractors), and uses **stride** of **512**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "conv_layer = torch.nn.Conv1d(in_channels=8, out_channels=256, kernel_size=512, stride=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the stride, sequence length from original 200000 bytes are reduced to 390, with 256 independent convolutions applied to each window of 512 bytes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256, 390])"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer(embedded_prep).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3150,  0.1721,  0.0220,  ...,  0.9214,  0.5167, -0.5706],\n",
       "         [ 0.2943, -0.6932,  0.0379,  ...,  0.1647, -0.0668, -0.0521],\n",
       "         [ 0.0768, -0.9937,  0.2447,  ...,  0.3427, -0.8050, -0.1158],\n",
       "         ...,\n",
       "         [-0.0962, -0.2683,  1.5979,  ..., -0.9385,  0.0210, -1.0429],\n",
       "         [ 0.5865, -0.1245,  0.1460,  ..., -0.9941,  0.0721, -0.5876],\n",
       "         [-0.0677, -0.4522, -1.1285,  ...,  0.5529,  0.1676, -0.9465]]],\n",
       "       grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer(embedded_prep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each element in this output tensor is single number representation of 512 bytes of the original sample, extracted by the convolutional layer.\n",
    "\n",
    "This tensor is then passed through a max pooling layer, which takes the maximum value from each filter output, reducing the tensor to a single dimension.\n",
    "\n",
    "### Linear Layers\n",
    "\n",
    "Finally, the output is passed through a fully connected (aka **Linear**) layers, which is a standard neural network living in everyone heads:\n",
    "\n",
    "<img src=\"./img/linear.png\" width=\"300\">\n",
    "\n",
    "Linear layers can be considered as knowledge base of the model. These layers learn convoluted feature mapping to an actual label, and are used to make the final prediction of the sample being malicious or benign:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.19406840205192566"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "pooling = nn.AdaptiveMaxPool1d(1)\n",
    "linear = nn.Linear(256, 1)\n",
    "\n",
    "pooled = pooling(conv_layer(embedded_prep))\n",
    "logit = linear(pooled.squeeze())\n",
    "probability = torch.sigmoid(logit)\n",
    "\n",
    "probability[0].item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a `torch` Neural Model\n",
    "\n",
    "Let's put all these layers together to form an actual Neural Network model that can learn byte level features from the PE samples and identify malicious patterns. We will use the same model as in the original MalConv paper which uses few extra additions to previously described components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MalConv(nn.Module):\n",
    "    # trained to minimize cross-entropy loss: criterion = nn.CrossEntropyLoss()\n",
    "    def __init__(\n",
    "            self,\n",
    "            embd_size=8, # dimensionality of the byte embeddings\n",
    "            total_nr_of_bytes=256, # number of possible byte values\n",
    "            channels=256, # number of independent channels in the convolutional layer\n",
    "            window_size=512, # size of the convolutional window\n",
    "            stride=512, # stride (jump length) of the convolutional window\n",
    "            out_size=2 # size of the output layer, corresponds to the number of classes we want to detect\n",
    "    ):\n",
    "        super(MalConv, self).__init__()\n",
    "        bytes_with_padding = total_nr_of_bytes + 1\n",
    "        self.embd = nn.Embedding(bytes_with_padding, embd_size, padding_idx=0)\n",
    "        \n",
    "        self.window_size = window_size\n",
    "    \n",
    "        self.conv_1 = nn.Conv1d(embd_size, channels, window_size, stride=stride, bias=True)\n",
    "        self.conv_2 = nn.Conv1d(embd_size, channels, window_size, stride=stride, bias=True)\n",
    "        \n",
    "        self.pooling = nn.AdaptiveMaxPool1d(1)\n",
    "        \n",
    "        self.fc_1 = nn.Linear(channels, channels)\n",
    "        self.fc_2 = nn.Linear(channels, out_size)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.embd(x.long())\n",
    "        x = torch.transpose(x, 2, 1)\n",
    "        \n",
    "        cnn_value = self.conv_1(x)\n",
    "        gating_weight = torch.sigmoid(self.conv_2(x))\n",
    "        \n",
    "        x = cnn_value * gating_weight\n",
    "        \n",
    "        x = self.pooling(x)\n",
    "        \n",
    "        # flatten\n",
    "        x = x.view(x.size(0), -1)\n",
    "        \n",
    "        x = F.relu(self.fc_1(x))\n",
    "        x = self.fc_2(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    malconv = MalConv()\n",
    "    logits = malconv(async_tensor)\n",
    "\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] MalConv probability for Async RAT sample being malware: 47.52%\n"
     ]
    }
   ],
   "source": [
    "print(f\"[+] MalConv probability for Async RAT sample being malware: {torch.sigmoid(logits)[0, 1].item()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We haven't loaded the pre-trained model yet -- this is output from the randomly initialized model. \n",
    "\n",
    "We can try to change random seed and verify that the prediction probability changes, but stays highly uncertain, somewhere close to 50% all the time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed: 0 | Probability: 47.52%\n",
      "Seed: 1 | Probability: 52.60%\n",
      "Seed: 2 | Probability: 61.49%\n",
      "Seed: 3 | Probability: 48.25%\n",
      "Seed: 4 | Probability: 46.79%\n"
     ]
    }
   ],
   "source": [
    "for seed in range(5):\n",
    "    torch.manual_seed(seed)\n",
    "    malconv = MalConv()\n",
    "    logits = malconv(async_tensor)\n",
    "    print(f\"Seed: {seed} | Probability: {torch.sigmoid(logits)[0, 1].item()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the pre-trained model and verify predictions on the AsyncRAT sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "\n",
    "malconv_weights_dict = torch.load(io.BytesIO(malconv_weights))\n",
    "malconv.load_state_dict(malconv_weights_dict['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6389805"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "async_rat_bytez_200k = async_rat_bytez[:2000000]\n",
    "async_tensor = torch.tensor(np.frombuffer(async_rat_bytez_200k, dtype=np.uint8)[np.newaxis,:].copy())\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = torch.softmax(malconv(async_tensor), dim=-1)\n",
    "\n",
    "outputs.detach().numpy()[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainability\n",
    "\n",
    "We will now explore the model's predictions and try to understand why it classified the AsyncRAT sample as malicious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
