{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Black Hat USA Training (Early draft)\n",
    "\n",
    "## Lab 2: Feature Extraction from Byte Level Data with Neural Networks and PyTorch\n",
    "\n",
    "We will follow a \"Top-Down\" teaching methodology: We will start with higher level concepts familiar to our students in the cybersecurity domain, for instance, by introducing a specific library and demonstrating its use. Then, we delve deeper into the methods and parameters of these applications. Finally, we explore the underlying fundamentals, such as the specific PE format properties or mathematical concepts at the core of these ideas.\n",
    "\n",
    "**NOTE: This is a raw draft that will be populated with more material (especially visual) and explanations, especially, facilitating AI/ML intuition and more gradual familiriaztion with concepts.**\n",
    "\n",
    "Contents:\n",
    "- Downloading AsyncRAT Sample\n",
    "- Pre-Trained MalConv Model\n",
    "- PyTorch Introduction\n",
    "- PE File Path through Neural Network:\n",
    "  - Embeddings\n",
    "  - Convolutional Neural Network\n",
    "\n",
    "### Downloading AsyncRAT Sample\n",
    "\n",
    "We will use the same sample as in Lab 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "# force reimport of lab_helpers\n",
    "import sys\n",
    "if 'lab_helpers' in sys.modules:\n",
    "    del sys.modules['lab_helpers']\n",
    "\n",
    "from lab_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'MZ\\x90\\x00\\x03\\x00\\x00\\x00\\x04\\x00\\x00\\x00\\xff\\xff\\x00\\x00\\xb8\\x00\\x00\\x00'"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NOTE: for some reason download from vx-underground is denied by the server \n",
    "# works from browser, but not if using requests.get, user-agent browser mimic does not help\n",
    "vx_link = \"https://samples.vx-underground.org/Samples/Families/AsyncRAT/5e3588e8ddebd61c2bd6dab4b87f601bd6a4857b33eb281cb5059c29cfe62b80.7z\"\n",
    "# using a private hosted copy\n",
    "async_rat_path = \"http://malware-training.us.to/5e3588e8ddebd61c2bd6dab4b87f601bd6a4857b33eb281cb5059c29cfe62b80.7z\"\n",
    "async_rat_bytez = get_encrypted_archive(async_rat_path, password=\"infected\")\n",
    "async_rat_bytez[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Trained MalConv Model\n",
    "\n",
    "MalConv is a binary classifier model that outputs a probability of the sample being malicious, proposed by group of researchers in this [paper](https://arxiv.org/abs/1710.09435). Under the hood it is a convolutional neural network (CNN) to extract features from the byte level of the malware sample. Schematic view of the model is as follows:\n",
    "\n",
    "<img src=\"./img/malconv.png\" width=\"600\">\n",
    "\n",
    "Let's download the pre-trained model and verify predictions on the AsyncRAT sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Downloaded MalConv weights | Size: 24.79 MB\n"
     ]
    }
   ],
   "source": [
    "malconv_weights_link = \"https://github.com/dtrizna/quo.vadis/raw/main/modules/sota/malconv/parameters/malconv.checkpoint\"\n",
    "malconv_weights = requests.get(malconv_weights_link).content\n",
    "print(f\"[+] Downloaded MalConv weights | Size: {len(malconv_weights) / 1024 / 1024:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] MalConv probability for Async RAT sample being malware: 63.90%\n"
     ]
    }
   ],
   "source": [
    "from lab_helpers import MalConvModel\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "malconv = MalConvModel()\n",
    "malconv.load_state(malconv_weights)\n",
    "\n",
    "score = malconv.get_score(async_rat_bytez)\n",
    "print(f\"[+] MalConv probability for Async RAT sample being malware: {score*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MalConv(\n",
       "  (embd): Embedding(257, 8, padding_idx=0)\n",
       "  (conv_1): Conv1d(8, 256, kernel_size=(512,), stride=(512,))\n",
       "  (conv_2): Conv1d(8, 256, kernel_size=(512,), stride=(512,))\n",
       "  (pooling): AdaptiveMaxPool1d(output_size=1)\n",
       "  (fc_1): Linear(in_features=256, out_features=256, bias=True)\n",
       "  (fc_2): Linear(in_features=256, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "malconv.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MalConv is neural network, and to understand how it works under the hood, we need to grasp basics of PyTorch.\n",
    "\n",
    "## PyTorch Introduction\n",
    "\n",
    "PyTorch is a Python library for implementing Deep Learning models. Deep Learning is a subfield of Machine Learning that uses **Neural Networks** to learn complex patterns in data. \n",
    "\n",
    "<img src=\"./img/ai_ml_dl.png\" width=\"400\">\n",
    "\n",
    "During last years PyTorch became a de-facto standard for Deep Learning research, substituting the previous leader TensorFlow. PyTorch is a very flexible library that allows to implement complex models with a few lines of code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors\n",
    "\n",
    "Any deep learning framework operate with tensors, which are multi-dimensional arrays. In PyTorch, tensors are the main data structure. They are similar to NumPy arrays, but with additional features that make them suitable for deep learning:\n",
    "\n",
    "<img src=\"./img/tensors.png\" width=\"600\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.])"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 1-D tensor (aka vector)\n",
    "tensor_a = torch.Tensor([1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "print(tensor_a.shape)\n",
    "tensor_a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2-D tensor (aka matrix)\n",
    "tensor_b = tensor_a.reshape(3, 3)\n",
    "print(tensor_b.shape)\n",
    "tensor_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 2., 3.],\n",
       "         [4., 5., 6.],\n",
       "         [7., 8., 9.]],\n",
       "\n",
       "        [[1., 2., 3.],\n",
       "         [4., 5., 6.],\n",
       "         [7., 8., 9.]],\n",
       "\n",
       "        [[1., 2., 3.],\n",
       "         [4., 5., 6.],\n",
       "         [7., 8., 9.]]])"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_c = torch.vstack([tensor_a, tensor_a, tensor_a]).reshape(3, 3, 3)\n",
    "print(tensor_c.shape)\n",
    "tensor_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers\n",
    "\n",
    "#### Embeddings\n",
    "\n",
    "Now, let's see how we can use PyTorch to extract features from the byte level of the malware sample. First, raw MZ file bytes are converted to an integer array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 77,  90, 144,   0,   3], dtype=torch.uint8)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "FIRST_N_BYTES = 5\n",
    "torch.tensor( np.frombuffer(async_rat_bytez, dtype=np.uint8)[0:FIRST_N_BYTES].copy() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can confirm that the first bytes of the file are indeed the MZ header:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'MZ\\x90\\x00\\x03'"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bytes([77, 90, 144, 0, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In absolute majority of neural network architectures suited for textual analysis, first layer is an **Embedding** layer. Embeddings are basically a lookup table that maps each byte to a vector representation, learned during the training process. Important property of embedded vectors is that after training similar inputs are mapped to similar locations in the embedded vectorspace, as depicted in the following figure which displays **3-dimensional embeddings**:\n",
    "\n",
    "<img src=\"./img/embedding_star_wars.gif\" width=\"600\">\n",
    "\n",
    "[[Image Source]](https://medium.com/@marcusa314/visualizing-words-377624cb20c7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MalConv uses **embedding size of 8**, but it is common to use higher dimensionality in modern models, such as 64 or 128.\n",
    "\n",
    "Let's define an 8-dimensional embedding layer and pass the first 5 bytes of the AsyncRAT sample through it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Shape of data before embedding: torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "# embedding that encodes each byte to 3 dimensions, 256 possible values\n",
    "nr_of_bytes = 256\n",
    "embedding_size = 8\n",
    "torch.manual_seed(0)\n",
    "example_embed = torch.nn.Embedding(nr_of_bytes, embedding_size)\n",
    "\n",
    "# get the embedding for the first 5 bytes of the Async RAT sample\n",
    "async_first_5_bytez = torch.tensor([77, 90, 144, 0, 3])\n",
    "print(f\"[!] Shape of data before embedding: {async_first_5_bytez.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the embedded array each byte is expanded to a 8-dimensional vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Shape of data after embedding: torch.Size([5, 8])\n"
     ]
    }
   ],
   "source": [
    "print(f\"[!] Shape of data after embedding: {example_embed(async_first_5_bytez).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Data after embedding:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7650, -0.4750, -0.4953, -0.1984,  2.2149, -0.1367, -1.0182,  0.1784],\n",
       "        [ 0.7049,  0.0305, -0.8542,  0.5388, -0.5265, -1.3320,  1.5451,  0.4086],\n",
       "        [ 0.4047, -0.6549,  0.0521,  0.3401, -0.2124,  1.5629, -0.9072, -1.5662],\n",
       "        [-1.1258, -1.1524, -0.2506, -0.4339,  0.8487,  0.6920, -0.3160, -2.1152],\n",
       "        [ 0.7502, -0.5855, -0.1734,  0.1835,  1.3894,  1.5863,  0.9463, -0.8437]],\n",
       "       grad_fn=<EmbeddingBackward0>)"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"[!] Data after embedding:\")\n",
    "\n",
    "example_embed(async_first_5_bytez)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] First byte: 77\n",
      "[!] First byte's embedding: tensor([-0.7650, -0.4750, -0.4953, -0.1984,  2.2149, -0.1367, -1.0182,  0.1784])\n"
     ]
    }
   ],
   "source": [
    "first_byte = async_first_5_bytez[0]\n",
    "with torch.no_grad():\n",
    "    first_byte_embed = example_embed(async_first_5_bytez)[0]\n",
    "\n",
    "print(f\"[!] First byte: {first_byte}\")\n",
    "print(f\"[!] First byte's embedding: {first_byte_embed}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea should be clear by now. Now, we need more representative information size -- take **first 200000 bytes** of the AsyncRAT sample and pass it through the embedding layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 200000])"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asyncrat_tensor = torch.tensor(np.frombuffer(async_rat_bytez, dtype=np.uint8)[np.newaxis,:].copy())[:, :200000]\n",
    "asyncrat_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 200000, 8])"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asyncrat_embedded = example_embed(asyncrat_tensor.long())\n",
    "asyncrat_embedded.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convolutional Layer\n",
    "\n",
    "In MalConv, the output of the embedding layer is passed to a 1D convolutional layer, that take a raw byte sequence and extracts features from the byte sequence by applying a filter to a window of bytes at a time.\n",
    "\n",
    "1D convolutional example below depicts input with **embedding size** of **3**, and convolution having **kernel size** is **3** with **stride** of **1**:\n",
    "\n",
    "<img src=\"./img/conv_1D_time.gif\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to transpose the array to match the input shape of the convolutional layer, which expects the input dimensions to be:\n",
    "\n",
    "`(batch_size, embedding_size, sequence_length)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Shape of data before 1D convolutional layer: torch.Size([1, 8, 200000])\n"
     ]
    }
   ],
   "source": [
    "# switch the 1st and 2nd dimensions\n",
    "asyncrat_embedded_prep = torch.transpose(asyncrat_embedded, 2, 1)\n",
    "\n",
    "print(f\"[!] Shape of data before 1D convolutional layer: {asyncrat_embedded_prep.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MalConv uses 1D convolutional layer with a **kernel size of 512**, applies 256 filters (number of independent convolutional extractors), and uses **stride** of **512**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "conv_layer = torch.nn.Conv1d(in_channels=8, out_channels=256, kernel_size=512, stride=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of the stride, sequence length from original 200000 bytes are reduced to 390, with 256 independent convolutions applied to each window of 512 bytes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Shape of data after 1D convolutional layer: torch.Size([1, 256, 390])\n"
     ]
    }
   ],
   "source": [
    "print(f\"[!] Shape of data after 1D convolutional layer: {conv_layer(asyncrat_embedded_prep).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.3150,  0.1721,  0.0220,  ...,  0.9214,  0.5167, -0.5706],\n",
       "         [ 0.2943, -0.6932,  0.0379,  ...,  0.1647, -0.0668, -0.0521],\n",
       "         [ 0.0768, -0.9937,  0.2447,  ...,  0.3427, -0.8050, -0.1158],\n",
       "         ...,\n",
       "         [-0.0962, -0.2683,  1.5979,  ..., -0.9385,  0.0210, -1.0429],\n",
       "         [ 0.5865, -0.1245,  0.1460,  ..., -0.9941,  0.0721, -0.5876],\n",
       "         [-0.0677, -0.4522, -1.1285,  ...,  0.5529,  0.1676, -0.9465]]],\n",
       "       grad_fn=<ConvolutionBackward0>)"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer(asyncrat_embedded_prep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each element in this output tensor is single number representation of 512 bytes of the original sample, extracted by the convolutional layer.\n",
    "\n",
    "This tensor is then passed through a max pooling layer, which takes the maximum value from each filter output, reducing the tensor to a single dimension.\n",
    "\n",
    "### Linear Layers\n",
    "\n",
    "Finally, the output is passed through a fully connected (aka **Linear**) layers, which is a standard neural network living in everyone heads:\n",
    "\n",
    "<img src=\"./img/linear.png\" width=\"300\">\n",
    "\n",
    "Linear layers can be considered as knowledge base of the model. These layers learn convoluted feature mapping to an actual label, and are used to make the final prediction of the sample being malicious or benign.\n",
    "\n",
    "MalConv stacks two linear layers with **ReLU** activation function in between, and a final linear layer with **Sigmoid** activation function to output the probability of the sample being malicious:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Shape of data after 1D conv. layer:\t     torch.Size([1, 256, 390])\n",
      "[!] Shape of data after max pooling:\t     torch.Size([1, 256, 1])\n",
      "[!] Shape of data after first linear layer:  torch.Size([1, 256])\n",
      "[!] Shape of data after second linear layer: torch.Size([1, 1])\n",
      "\n",
      "[!] Final probability of Async RAT sample being malware:\n",
      "\n",
      "62.57%\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "print(f\"[!] Shape of data after 1D conv. layer:\\t     {conv_layer(asyncrat_embedded_prep).shape}\")\n",
    "pooling = nn.AdaptiveMaxPool1d(1)\n",
    "pooled = pooling(conv_layer(asyncrat_embedded_prep))\n",
    "print(f\"[!] Shape of data after max pooling:\\t     {pooled.shape}\")\n",
    "\n",
    "linear_1 = nn.Linear(256, 256)\n",
    "linear_1_out = torch.relu(linear_1(pooled.view(-1, 256)))\n",
    "print(f\"[!] Shape of data after first linear layer:  {linear_1_out.shape}\")\n",
    "\n",
    "linear_2 = nn.Linear(256, 1)\n",
    "logit = linear_2(linear_1_out)\n",
    "print(f\"[!] Shape of data after second linear layer: {logit.shape}\")\n",
    "\n",
    "probability = torch.sigmoid(logit)\n",
    "print(f\"\\n[!] Final probability of Async RAT sample being malware:\\n\\n{probability[0].item()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a `torch` Neural Model\n",
    "\n",
    "Let's put all these layers together to form an actual Neural Network model that can learn byte level features from the PE samples and identify malicious patterns. We will use the same model as in the original MalConv paper which uses few extra additions to previously described components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MalConv(nn.Module):\n",
    "    # trained to minimize cross-entropy loss: criterion = nn.CrossEntropyLoss()\n",
    "    def __init__(\n",
    "            self,\n",
    "            embd_size=8, # dimensionality of the byte embeddings\n",
    "            total_nr_of_bytes=256, # number of possible byte values\n",
    "            channels=256, # number of independent channels in the convolutional layer\n",
    "            window_size=512, # size of the convolutional window\n",
    "            stride=512, # stride (jump length) of the convolutional window\n",
    "            out_size=2 # size of the output layer, corresponds to the number of classes we want to detect\n",
    "    ):\n",
    "        super(MalConv, self).__init__()\n",
    "        bytes_with_padding = total_nr_of_bytes + 1\n",
    "        self.embd = nn.Embedding(bytes_with_padding, embd_size, padding_idx=0)\n",
    "        \n",
    "        self.window_size = window_size\n",
    "    \n",
    "        self.conv_1 = nn.Conv1d(embd_size, channels, window_size, stride=stride, bias=True)\n",
    "        self.conv_2 = nn.Conv1d(embd_size, channels, window_size, stride=stride, bias=True)\n",
    "        \n",
    "        self.pooling = nn.AdaptiveMaxPool1d(1)\n",
    "        \n",
    "        self.fc_1 = nn.Linear(channels, channels)\n",
    "        self.fc_2 = nn.Linear(channels, out_size)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.embd(x.long())\n",
    "        x = torch.transpose(x, 2, 1)\n",
    "        \n",
    "        cnn_value = self.conv_1(x)\n",
    "        gating_weight = torch.sigmoid(self.conv_2(x))\n",
    "        \n",
    "        x = cnn_value * gating_weight\n",
    "        \n",
    "        x = self.pooling(x)\n",
    "        \n",
    "        x = x.view(x.size(0), -1) # flatten\n",
    "        \n",
    "        x = F.relu(self.fc_1(x))\n",
    "        x = self.fc_2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    malconv = MalConv()\n",
    "    logits = malconv(asyncrat_tensor)\n",
    "\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] MalConv probability for Async RAT sample being malware: 47.52%\n"
     ]
    }
   ],
   "source": [
    "print(f\"[+] MalConv probability for Async RAT sample being malware: {torch.sigmoid(logits)[0, 1].item()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We haven't loaded the pre-trained model yet -- this is output from the randomly initialized model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the pre-trained model and verify predictions on the AsyncRAT sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import io\n",
    "\n",
    "malconv_weights_dict = torch.load(io.BytesIO(malconv_weights))\n",
    "malconv.load_state_dict(malconv_weights_dict['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6389805"
      ]
     },
     "execution_count": 480,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "async_rat_bytez_200k = async_rat_bytez[:2000000]\n",
    "asyncrat_tensor = torch.tensor(np.frombuffer(async_rat_bytez_200k, dtype=np.uint8)[np.newaxis,:].copy())\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = torch.softmax(malconv(asyncrat_tensor), dim=-1)\n",
    "\n",
    "outputs.detach().numpy()[0,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try to change random seed and verify that for the non-trained model probability changes, but stays highly uncertain, somewhere close to 50% all the time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Seed: 0\n",
      "\tProbability AsyncRAT:    48.19%\n",
      "\tProbability notepad.exe: 46.97%\n",
      "[!] Seed: 1\n",
      "\tProbability AsyncRAT:    52.60%\n",
      "\tProbability notepad.exe: 53.48%\n",
      "[!] Seed: 2\n",
      "\tProbability AsyncRAT:    52.01%\n",
      "\tProbability notepad.exe: 52.85%\n",
      "[!] Seed: 3\n",
      "\tProbability AsyncRAT:    54.57%\n",
      "\tProbability notepad.exe: 49.66%\n",
      "[!] Seed: 4\n",
      "\tProbability AsyncRAT:    46.05%\n",
      "\tProbability notepad.exe: 48.22%\n"
     ]
    }
   ],
   "source": [
    "for seed in range(5):\n",
    "    torch.manual_seed(seed)\n",
    "    malconv = MalConv()\n",
    "    logits = malconv(asyncrat_tensor)\n",
    "    print(f\"[!] Seed: {seed}\")\n",
    "    print(f\"\\tProbability AsyncRAT: {torch.softmax(logits, dim=-1)[0, 1].item()*100:>8.2f}%\")\n",
    "\n",
    "    if os.path.exists(r\"C:\\windows\\system32\\notepad.exe\"):\n",
    "        with open (r\"C:\\windows\\system32\\notepad.exe\", \"rb\") as f:\n",
    "            legit_bytez = f.read()\n",
    "        legit_tensor = torch.tensor(np.frombuffer(legit_bytez, dtype=np.uint8)[np.newaxis,:].copy())[:, :200000]\n",
    "        logits = malconv(legit_tensor)\n",
    "        print(f\"\\tProbability notepad.exe: {torch.softmax(logits, dim=-1)[0, 1].item()*100:>5.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-trained model, on the other hand, has the same score and differentiates between malicious and benign samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[!] Seed: 0\n",
      "\tProbability malicious AsyncRAT:    63.90%\n",
      "\tProbability malicious notepad.exe:  5.63%\n",
      "[!] Seed: 1\n",
      "\tProbability malicious AsyncRAT:    63.90%\n",
      "\tProbability malicious notepad.exe:  5.63%\n",
      "[!] Seed: 2\n",
      "\tProbability malicious AsyncRAT:    63.90%\n",
      "\tProbability malicious notepad.exe:  5.63%\n",
      "[!] Seed: 3\n",
      "\tProbability malicious AsyncRAT:    63.90%\n",
      "\tProbability malicious notepad.exe:  5.63%\n",
      "[!] Seed: 4\n",
      "\tProbability malicious AsyncRAT:    63.90%\n",
      "\tProbability malicious notepad.exe:  5.63%\n"
     ]
    }
   ],
   "source": [
    "for seed in range(5):\n",
    "    torch.manual_seed(seed)\n",
    "    malconv = MalConv()\n",
    "\n",
    "    # load the pre-trained weights\n",
    "    malconv_weights_dict = torch.load(io.BytesIO(malconv_weights))\n",
    "    malconv.load_state_dict(malconv_weights_dict['model_state_dict'])\n",
    "    \n",
    "    logits = malconv(asyncrat_tensor)\n",
    "    print(f\"[!] Seed: {seed}\")\n",
    "    print(f\"\\tProbability malicious AsyncRAT: {torch.softmax(logits, dim=-1)[0, 1].item()*100:>8.2f}%\")\n",
    "\n",
    "    if os.path.exists(r\"C:\\windows\\system32\\notepad.exe\"):\n",
    "        with open (r\"C:\\windows\\system32\\notepad.exe\", \"rb\") as f:\n",
    "            legit_bytez = f.read()\n",
    "        legit_tensor = torch.tensor(np.frombuffer(legit_bytez, dtype=np.uint8)[np.newaxis,:].copy())[:, :200000]\n",
    "        logits = malconv(legit_tensor)\n",
    "        print(f\"\\tProbability malicious notepad.exe: {torch.softmax(logits, dim=-1)[0, 1].item()*100:>5.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note, MalConv is still research prototype and these pre-trained weights are not usable in production environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] Probability malicious calc.exe: 98.65%\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(r\"C:\\windows\\system32\\calc.exe\"):\n",
    "    with open (r\"C:\\windows\\system32\\calc.exe\", \"rb\") as f:\n",
    "        legit_bytez = f.read()\n",
    "\n",
    "    malconv = MalConv()\n",
    "\n",
    "    # load the pre-trained weights\n",
    "    malconv_weights_dict = torch.load(io.BytesIO(malconv_weights))\n",
    "    malconv.load_state_dict(malconv_weights_dict['model_state_dict'])\n",
    "\n",
    "    legit_tensor = torch.tensor(np.frombuffer(legit_bytez, dtype=np.uint8)[np.newaxis,:].copy())[:, :200000]\n",
    "    logits = malconv(legit_tensor)\n",
    "    print(f\"[+] Probability malicious calc.exe: {torch.softmax(logits, dim=-1)[0, 1].item()*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explainability\n",
    "\n",
    "We will now explore the model's predictions and try to understand why it classified the AsyncRAT sample as malicious."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
